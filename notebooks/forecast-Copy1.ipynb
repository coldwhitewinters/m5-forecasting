{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e97f892-e21b-412e-9d7c-0401cd572d32",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01a074-52df-475b-a54a-a754b84f2251",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6ab9fc-2b2d-4c69-bccf-13a545604b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "372f5539-cb1b-4dd8-8d3d-2d9506e3d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import m5.config as cfg\n",
    "from m5.model import train, predict, train_level, predict_level, compile_fcst\n",
    "from m5.evaluate import accuracy_all_levels, collect_metrics\n",
    "from m5.plot import plot_fcst\n",
    "\n",
    "# Library settings\n",
    "pd.options.display.max_columns = 999\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6177b-3189-4b70-9542-ca825a007af1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca52ac99-bbcd-4bdd-9b6c-a8cc8e448eb2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "level = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ebb71-583a-4cd1-b60e-7006ebc85e82",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a462d470-398d-4f64-927f-7d9a0538508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"task\": \"train\",\n",
    "    \"objective\": \"tweedie\",\n",
    "    \"num_iterations\": 300,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 31,\n",
    "    \"num_threads\": 4,\n",
    "    \"early_stopping_round\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2b942-8df7-48d9-b027-f46bfe98b4bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Training model for level 1\n",
      "Training model for level 1 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1871, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442174\n",
      "[1]\tvalid_0's tweedie: 825.942\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.126\n",
      "[3]\tvalid_0's tweedie: 824.566\n",
      "[4]\tvalid_0's tweedie: 823.965\n",
      "[5]\tvalid_0's tweedie: 823.444\n",
      "[6]\tvalid_0's tweedie: 822.939\n",
      "[7]\tvalid_0's tweedie: 822.539\n",
      "[8]\tvalid_0's tweedie: 822.333\n",
      "[9]\tvalid_0's tweedie: 822.052\n",
      "[10]\tvalid_0's tweedie: 821.821\n",
      "[11]\tvalid_0's tweedie: 821.656\n",
      "[12]\tvalid_0's tweedie: 821.459\n",
      "[13]\tvalid_0's tweedie: 821.299\n",
      "[14]\tvalid_0's tweedie: 821.144\n",
      "[15]\tvalid_0's tweedie: 821.02\n",
      "[16]\tvalid_0's tweedie: 820.928\n",
      "[17]\tvalid_0's tweedie: 820.82\n",
      "[18]\tvalid_0's tweedie: 820.719\n",
      "[19]\tvalid_0's tweedie: 820.63\n",
      "[20]\tvalid_0's tweedie: 820.541\n",
      "[21]\tvalid_0's tweedie: 820.488\n",
      "[22]\tvalid_0's tweedie: 820.441\n",
      "[23]\tvalid_0's tweedie: 820.397\n",
      "[24]\tvalid_0's tweedie: 820.359\n",
      "[25]\tvalid_0's tweedie: 820.331\n",
      "[26]\tvalid_0's tweedie: 820.298\n",
      "[27]\tvalid_0's tweedie: 820.275\n",
      "[28]\tvalid_0's tweedie: 820.252\n",
      "[29]\tvalid_0's tweedie: 820.233\n",
      "[30]\tvalid_0's tweedie: 820.202\n",
      "[31]\tvalid_0's tweedie: 820.188\n",
      "[32]\tvalid_0's tweedie: 820.166\n",
      "[33]\tvalid_0's tweedie: 820.169\n",
      "[34]\tvalid_0's tweedie: 820.147\n",
      "[35]\tvalid_0's tweedie: 820.13\n",
      "[36]\tvalid_0's tweedie: 820.116\n",
      "[37]\tvalid_0's tweedie: 820.114\n",
      "[38]\tvalid_0's tweedie: 820.101\n",
      "[39]\tvalid_0's tweedie: 820.081\n",
      "[40]\tvalid_0's tweedie: 820.075\n",
      "[41]\tvalid_0's tweedie: 820.067\n",
      "[42]\tvalid_0's tweedie: 820.047\n",
      "[43]\tvalid_0's tweedie: 820.039\n",
      "[44]\tvalid_0's tweedie: 820.035\n",
      "[45]\tvalid_0's tweedie: 820.027\n",
      "[46]\tvalid_0's tweedie: 820.023\n",
      "[47]\tvalid_0's tweedie: 820.019\n",
      "[48]\tvalid_0's tweedie: 820.013\n",
      "[49]\tvalid_0's tweedie: 820.004\n",
      "[50]\tvalid_0's tweedie: 820\n",
      "[51]\tvalid_0's tweedie: 819.991\n",
      "[52]\tvalid_0's tweedie: 819.987\n",
      "[53]\tvalid_0's tweedie: 819.981\n",
      "[54]\tvalid_0's tweedie: 819.974\n",
      "[55]\tvalid_0's tweedie: 819.974\n",
      "[56]\tvalid_0's tweedie: 819.965\n",
      "[57]\tvalid_0's tweedie: 819.958\n",
      "[58]\tvalid_0's tweedie: 819.958\n",
      "[59]\tvalid_0's tweedie: 819.951\n",
      "[60]\tvalid_0's tweedie: 819.951\n",
      "[61]\tvalid_0's tweedie: 819.948\n",
      "[62]\tvalid_0's tweedie: 819.945\n",
      "[63]\tvalid_0's tweedie: 819.945\n",
      "[64]\tvalid_0's tweedie: 819.942\n",
      "[65]\tvalid_0's tweedie: 819.94\n",
      "[66]\tvalid_0's tweedie: 819.936\n",
      "[67]\tvalid_0's tweedie: 819.935\n",
      "[68]\tvalid_0's tweedie: 819.934\n",
      "[69]\tvalid_0's tweedie: 819.934\n",
      "[70]\tvalid_0's tweedie: 819.924\n",
      "[71]\tvalid_0's tweedie: 819.924\n",
      "[72]\tvalid_0's tweedie: 819.924\n",
      "[73]\tvalid_0's tweedie: 819.922\n",
      "[74]\tvalid_0's tweedie: 819.921\n",
      "[75]\tvalid_0's tweedie: 819.92\n",
      "[76]\tvalid_0's tweedie: 819.92\n",
      "[77]\tvalid_0's tweedie: 819.92\n",
      "[78]\tvalid_0's tweedie: 819.92\n",
      "[79]\tvalid_0's tweedie: 819.922\n",
      "[80]\tvalid_0's tweedie: 819.922\n",
      "[81]\tvalid_0's tweedie: 819.922\n",
      "[82]\tvalid_0's tweedie: 819.917\n",
      "[83]\tvalid_0's tweedie: 819.917\n",
      "[84]\tvalid_0's tweedie: 819.916\n",
      "[85]\tvalid_0's tweedie: 819.916\n",
      "[86]\tvalid_0's tweedie: 819.918\n",
      "[87]\tvalid_0's tweedie: 819.914\n",
      "[88]\tvalid_0's tweedie: 819.913\n",
      "[89]\tvalid_0's tweedie: 819.913\n",
      "[90]\tvalid_0's tweedie: 819.912\n",
      "[91]\tvalid_0's tweedie: 819.915\n",
      "[92]\tvalid_0's tweedie: 819.916\n",
      "[93]\tvalid_0's tweedie: 819.912\n",
      "[94]\tvalid_0's tweedie: 819.912\n",
      "[95]\tvalid_0's tweedie: 819.913\n",
      "[96]\tvalid_0's tweedie: 819.913\n",
      "[97]\tvalid_0's tweedie: 819.91\n",
      "[98]\tvalid_0's tweedie: 819.91\n",
      "[99]\tvalid_0's tweedie: 819.906\n",
      "[100]\tvalid_0's tweedie: 819.907\n",
      "[101]\tvalid_0's tweedie: 819.907\n",
      "[102]\tvalid_0's tweedie: 819.906\n",
      "[103]\tvalid_0's tweedie: 819.909\n",
      "[104]\tvalid_0's tweedie: 819.909\n",
      "[105]\tvalid_0's tweedie: 819.906\n",
      "[106]\tvalid_0's tweedie: 819.905\n",
      "[107]\tvalid_0's tweedie: 819.907\n",
      "[108]\tvalid_0's tweedie: 819.904\n",
      "[109]\tvalid_0's tweedie: 819.905\n",
      "[110]\tvalid_0's tweedie: 819.905\n",
      "[111]\tvalid_0's tweedie: 819.9\n",
      "[112]\tvalid_0's tweedie: 819.902\n",
      "[113]\tvalid_0's tweedie: 819.905\n",
      "[114]\tvalid_0's tweedie: 819.904\n",
      "[115]\tvalid_0's tweedie: 819.904\n",
      "[116]\tvalid_0's tweedie: 819.904\n",
      "[117]\tvalid_0's tweedie: 819.904\n",
      "[118]\tvalid_0's tweedie: 819.904\n",
      "[119]\tvalid_0's tweedie: 819.904\n",
      "[120]\tvalid_0's tweedie: 819.904\n",
      "[121]\tvalid_0's tweedie: 819.904\n",
      "[122]\tvalid_0's tweedie: 819.907\n",
      "[123]\tvalid_0's tweedie: 819.909\n",
      "[124]\tvalid_0's tweedie: 819.909\n",
      "[125]\tvalid_0's tweedie: 819.911\n",
      "[126]\tvalid_0's tweedie: 819.911\n",
      "[127]\tvalid_0's tweedie: 819.907\n",
      "[128]\tvalid_0's tweedie: 819.91\n",
      "[129]\tvalid_0's tweedie: 819.91\n",
      "[130]\tvalid_0's tweedie: 819.91\n",
      "[131]\tvalid_0's tweedie: 819.91\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's tweedie: 819.9\n",
      "Training model for level 1 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442165\n",
      "[1]\tvalid_0's tweedie: 825.959\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.267\n",
      "[3]\tvalid_0's tweedie: 824.508\n",
      "[4]\tvalid_0's tweedie: 823.83\n",
      "[5]\tvalid_0's tweedie: 823.432\n",
      "[6]\tvalid_0's tweedie: 822.978\n",
      "[7]\tvalid_0's tweedie: 822.589\n",
      "[8]\tvalid_0's tweedie: 822.287\n",
      "[9]\tvalid_0's tweedie: 822.121\n",
      "[10]\tvalid_0's tweedie: 821.898\n",
      "[11]\tvalid_0's tweedie: 821.663\n",
      "[12]\tvalid_0's tweedie: 821.49\n",
      "[13]\tvalid_0's tweedie: 821.296\n",
      "[14]\tvalid_0's tweedie: 821.116\n",
      "[15]\tvalid_0's tweedie: 820.985\n",
      "[16]\tvalid_0's tweedie: 820.936\n",
      "[17]\tvalid_0's tweedie: 820.822\n",
      "[18]\tvalid_0's tweedie: 820.788\n",
      "[19]\tvalid_0's tweedie: 820.704\n",
      "[20]\tvalid_0's tweedie: 820.623\n",
      "[21]\tvalid_0's tweedie: 820.562\n",
      "[22]\tvalid_0's tweedie: 820.506\n",
      "[23]\tvalid_0's tweedie: 820.452\n",
      "[24]\tvalid_0's tweedie: 820.413\n",
      "[25]\tvalid_0's tweedie: 820.402\n",
      "[26]\tvalid_0's tweedie: 820.367\n",
      "[27]\tvalid_0's tweedie: 820.329\n",
      "[28]\tvalid_0's tweedie: 820.302\n",
      "[29]\tvalid_0's tweedie: 820.272\n",
      "[30]\tvalid_0's tweedie: 820.245\n",
      "[31]\tvalid_0's tweedie: 820.211\n",
      "[32]\tvalid_0's tweedie: 820.191\n",
      "[33]\tvalid_0's tweedie: 820.18\n",
      "[34]\tvalid_0's tweedie: 820.163\n",
      "[35]\tvalid_0's tweedie: 820.148\n",
      "[36]\tvalid_0's tweedie: 820.133\n",
      "[37]\tvalid_0's tweedie: 820.12\n",
      "[38]\tvalid_0's tweedie: 820.103\n",
      "[39]\tvalid_0's tweedie: 820.098\n",
      "[40]\tvalid_0's tweedie: 820.086\n",
      "[41]\tvalid_0's tweedie: 820.07\n",
      "[42]\tvalid_0's tweedie: 820.062\n",
      "[43]\tvalid_0's tweedie: 820.049\n",
      "[44]\tvalid_0's tweedie: 820.051\n",
      "[45]\tvalid_0's tweedie: 820.042\n",
      "[46]\tvalid_0's tweedie: 820.029\n",
      "[47]\tvalid_0's tweedie: 820.024\n",
      "[48]\tvalid_0's tweedie: 820.014\n",
      "[49]\tvalid_0's tweedie: 820.007\n",
      "[50]\tvalid_0's tweedie: 820.003\n",
      "[51]\tvalid_0's tweedie: 819.996\n",
      "[52]\tvalid_0's tweedie: 819.993\n",
      "[53]\tvalid_0's tweedie: 819.99\n",
      "[54]\tvalid_0's tweedie: 819.987\n",
      "[55]\tvalid_0's tweedie: 819.984\n",
      "[56]\tvalid_0's tweedie: 819.978\n",
      "[57]\tvalid_0's tweedie: 819.977\n",
      "[58]\tvalid_0's tweedie: 819.966\n",
      "[59]\tvalid_0's tweedie: 819.965\n",
      "[60]\tvalid_0's tweedie: 819.958\n",
      "[61]\tvalid_0's tweedie: 819.958\n",
      "[62]\tvalid_0's tweedie: 819.956\n",
      "[63]\tvalid_0's tweedie: 819.956\n",
      "[64]\tvalid_0's tweedie: 819.954\n",
      "[65]\tvalid_0's tweedie: 819.953\n",
      "[66]\tvalid_0's tweedie: 819.954\n",
      "[67]\tvalid_0's tweedie: 819.954\n",
      "[68]\tvalid_0's tweedie: 819.95\n",
      "[69]\tvalid_0's tweedie: 819.949\n",
      "[70]\tvalid_0's tweedie: 819.947\n",
      "[71]\tvalid_0's tweedie: 819.948\n",
      "[72]\tvalid_0's tweedie: 819.948\n",
      "[73]\tvalid_0's tweedie: 819.944\n",
      "[74]\tvalid_0's tweedie: 819.941\n",
      "[75]\tvalid_0's tweedie: 819.941\n",
      "[76]\tvalid_0's tweedie: 819.94\n",
      "[77]\tvalid_0's tweedie: 819.943\n",
      "[78]\tvalid_0's tweedie: 819.943\n",
      "[79]\tvalid_0's tweedie: 819.938\n",
      "[80]\tvalid_0's tweedie: 819.937\n",
      "[81]\tvalid_0's tweedie: 819.943\n",
      "[82]\tvalid_0's tweedie: 819.943\n",
      "[83]\tvalid_0's tweedie: 819.94\n",
      "[84]\tvalid_0's tweedie: 819.936\n",
      "[85]\tvalid_0's tweedie: 819.936\n",
      "[86]\tvalid_0's tweedie: 819.936\n",
      "[87]\tvalid_0's tweedie: 819.933\n",
      "[88]\tvalid_0's tweedie: 819.934\n",
      "[89]\tvalid_0's tweedie: 819.933\n",
      "[90]\tvalid_0's tweedie: 819.932\n",
      "[91]\tvalid_0's tweedie: 819.93\n",
      "[92]\tvalid_0's tweedie: 819.934\n",
      "[93]\tvalid_0's tweedie: 819.935\n",
      "[94]\tvalid_0's tweedie: 819.935\n",
      "[95]\tvalid_0's tweedie: 819.935\n",
      "[96]\tvalid_0's tweedie: 819.934\n",
      "[97]\tvalid_0's tweedie: 819.932\n",
      "[98]\tvalid_0's tweedie: 819.933\n",
      "[99]\tvalid_0's tweedie: 819.933\n",
      "[100]\tvalid_0's tweedie: 819.935\n",
      "[101]\tvalid_0's tweedie: 819.934\n",
      "[102]\tvalid_0's tweedie: 819.93\n",
      "[103]\tvalid_0's tweedie: 819.931\n",
      "[104]\tvalid_0's tweedie: 819.928\n",
      "[105]\tvalid_0's tweedie: 819.931\n",
      "[106]\tvalid_0's tweedie: 819.93\n",
      "[107]\tvalid_0's tweedie: 819.93\n",
      "[108]\tvalid_0's tweedie: 819.93\n",
      "[109]\tvalid_0's tweedie: 819.931\n",
      "[110]\tvalid_0's tweedie: 819.931\n",
      "[111]\tvalid_0's tweedie: 819.929\n",
      "[112]\tvalid_0's tweedie: 819.929\n",
      "[113]\tvalid_0's tweedie: 819.927\n",
      "[114]\tvalid_0's tweedie: 819.927\n",
      "[115]\tvalid_0's tweedie: 819.927\n",
      "[116]\tvalid_0's tweedie: 819.927\n",
      "[117]\tvalid_0's tweedie: 819.927\n",
      "[118]\tvalid_0's tweedie: 819.927\n",
      "[119]\tvalid_0's tweedie: 819.93\n",
      "[120]\tvalid_0's tweedie: 819.93\n",
      "[121]\tvalid_0's tweedie: 819.929\n",
      "[122]\tvalid_0's tweedie: 819.928\n",
      "[123]\tvalid_0's tweedie: 819.928\n",
      "[124]\tvalid_0's tweedie: 819.926\n",
      "[125]\tvalid_0's tweedie: 819.924\n",
      "[126]\tvalid_0's tweedie: 819.924\n",
      "[127]\tvalid_0's tweedie: 819.924\n",
      "[128]\tvalid_0's tweedie: 819.921\n",
      "[129]\tvalid_0's tweedie: 819.92\n",
      "[130]\tvalid_0's tweedie: 819.92\n",
      "[131]\tvalid_0's tweedie: 819.921\n",
      "[132]\tvalid_0's tweedie: 819.92\n",
      "[133]\tvalid_0's tweedie: 819.92\n",
      "[134]\tvalid_0's tweedie: 819.919\n",
      "[135]\tvalid_0's tweedie: 819.918\n",
      "[136]\tvalid_0's tweedie: 819.917\n",
      "[137]\tvalid_0's tweedie: 819.918\n",
      "[138]\tvalid_0's tweedie: 819.919\n",
      "[139]\tvalid_0's tweedie: 819.917\n",
      "[140]\tvalid_0's tweedie: 819.914\n",
      "[141]\tvalid_0's tweedie: 819.914\n",
      "[142]\tvalid_0's tweedie: 819.916\n",
      "[143]\tvalid_0's tweedie: 819.916\n",
      "[144]\tvalid_0's tweedie: 819.917\n",
      "[145]\tvalid_0's tweedie: 819.915\n",
      "[146]\tvalid_0's tweedie: 819.915\n",
      "[147]\tvalid_0's tweedie: 819.915\n",
      "[148]\tvalid_0's tweedie: 819.916\n",
      "[149]\tvalid_0's tweedie: 819.915\n",
      "[150]\tvalid_0's tweedie: 819.916\n",
      "[151]\tvalid_0's tweedie: 819.916\n",
      "[152]\tvalid_0's tweedie: 819.916\n",
      "[153]\tvalid_0's tweedie: 819.917\n",
      "[154]\tvalid_0's tweedie: 819.92\n",
      "[155]\tvalid_0's tweedie: 819.92\n",
      "[156]\tvalid_0's tweedie: 819.92\n",
      "[157]\tvalid_0's tweedie: 819.92\n",
      "[158]\tvalid_0's tweedie: 819.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariel/anaconda3/envs/merlion/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/ariel/anaconda3/envs/merlion/lib/python3.9/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159]\tvalid_0's tweedie: 819.919\n",
      "[160]\tvalid_0's tweedie: 819.919\n",
      "[161]\tvalid_0's tweedie: 819.919\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's tweedie: 819.914\n",
      "Training model for level 1 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442132\n",
      "[1]\tvalid_0's tweedie: 826.136\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.455\n",
      "[3]\tvalid_0's tweedie: 824.887\n",
      "[4]\tvalid_0's tweedie: 824.167\n",
      "[5]\tvalid_0's tweedie: 823.672\n",
      "[6]\tvalid_0's tweedie: 823.182\n",
      "[7]\tvalid_0's tweedie: 822.737\n",
      "[8]\tvalid_0's tweedie: 822.428\n",
      "[9]\tvalid_0's tweedie: 822.153\n",
      "[10]\tvalid_0's tweedie: 821.894\n",
      "[11]\tvalid_0's tweedie: 821.666\n",
      "[12]\tvalid_0's tweedie: 821.493\n",
      "[13]\tvalid_0's tweedie: 821.317\n",
      "[14]\tvalid_0's tweedie: 821.216\n",
      "[15]\tvalid_0's tweedie: 821.087\n",
      "[16]\tvalid_0's tweedie: 820.968\n",
      "[17]\tvalid_0's tweedie: 820.854\n",
      "[18]\tvalid_0's tweedie: 820.765\n",
      "[19]\tvalid_0's tweedie: 820.684\n",
      "[20]\tvalid_0's tweedie: 820.657\n",
      "[21]\tvalid_0's tweedie: 820.591\n",
      "[22]\tvalid_0's tweedie: 820.535\n",
      "[23]\tvalid_0's tweedie: 820.486\n",
      "[24]\tvalid_0's tweedie: 820.438\n",
      "[25]\tvalid_0's tweedie: 820.388\n",
      "[26]\tvalid_0's tweedie: 820.352\n",
      "[27]\tvalid_0's tweedie: 820.313\n",
      "[28]\tvalid_0's tweedie: 820.285\n",
      "[29]\tvalid_0's tweedie: 820.262\n",
      "[30]\tvalid_0's tweedie: 820.243\n",
      "[31]\tvalid_0's tweedie: 820.249\n",
      "[32]\tvalid_0's tweedie: 820.234\n",
      "[33]\tvalid_0's tweedie: 820.224\n",
      "[34]\tvalid_0's tweedie: 820.204\n",
      "[35]\tvalid_0's tweedie: 820.187\n",
      "[36]\tvalid_0's tweedie: 820.176\n",
      "[37]\tvalid_0's tweedie: 820.165\n",
      "[38]\tvalid_0's tweedie: 820.146\n",
      "[39]\tvalid_0's tweedie: 820.131\n",
      "[40]\tvalid_0's tweedie: 820.118\n",
      "[41]\tvalid_0's tweedie: 820.1\n",
      "[42]\tvalid_0's tweedie: 820.091\n",
      "[43]\tvalid_0's tweedie: 820.081\n",
      "[44]\tvalid_0's tweedie: 820.09\n",
      "[45]\tvalid_0's tweedie: 820.089\n",
      "[46]\tvalid_0's tweedie: 820.083\n",
      "[47]\tvalid_0's tweedie: 820.081\n",
      "[48]\tvalid_0's tweedie: 820.073\n",
      "[49]\tvalid_0's tweedie: 820.064\n",
      "[50]\tvalid_0's tweedie: 820.052\n",
      "[51]\tvalid_0's tweedie: 820.052\n",
      "[52]\tvalid_0's tweedie: 820.047\n",
      "[53]\tvalid_0's tweedie: 820.037\n",
      "[54]\tvalid_0's tweedie: 820.035\n",
      "[55]\tvalid_0's tweedie: 820.03\n",
      "[56]\tvalid_0's tweedie: 820.029\n",
      "[57]\tvalid_0's tweedie: 820.029\n",
      "[58]\tvalid_0's tweedie: 820.02\n",
      "[59]\tvalid_0's tweedie: 820.016\n",
      "[60]\tvalid_0's tweedie: 820.004\n",
      "[61]\tvalid_0's tweedie: 820.003\n",
      "[62]\tvalid_0's tweedie: 819.997\n",
      "[63]\tvalid_0's tweedie: 819.997\n",
      "[64]\tvalid_0's tweedie: 819.995\n",
      "[65]\tvalid_0's tweedie: 819.992\n",
      "[66]\tvalid_0's tweedie: 819.991\n",
      "[67]\tvalid_0's tweedie: 819.988\n",
      "[68]\tvalid_0's tweedie: 819.986\n",
      "[69]\tvalid_0's tweedie: 819.987\n",
      "[70]\tvalid_0's tweedie: 819.987\n",
      "[71]\tvalid_0's tweedie: 819.978\n",
      "[72]\tvalid_0's tweedie: 819.979\n",
      "[73]\tvalid_0's tweedie: 819.98\n",
      "[74]\tvalid_0's tweedie: 819.981\n",
      "[75]\tvalid_0's tweedie: 819.985\n",
      "[76]\tvalid_0's tweedie: 819.979\n",
      "[77]\tvalid_0's tweedie: 819.979\n",
      "[78]\tvalid_0's tweedie: 819.977\n",
      "[79]\tvalid_0's tweedie: 819.975\n",
      "[80]\tvalid_0's tweedie: 819.974\n",
      "[81]\tvalid_0's tweedie: 819.974\n",
      "[82]\tvalid_0's tweedie: 819.97\n",
      "[83]\tvalid_0's tweedie: 819.968\n",
      "[84]\tvalid_0's tweedie: 819.963\n",
      "[85]\tvalid_0's tweedie: 819.961\n",
      "[86]\tvalid_0's tweedie: 819.962\n",
      "[87]\tvalid_0's tweedie: 819.963\n",
      "[88]\tvalid_0's tweedie: 819.964\n",
      "[89]\tvalid_0's tweedie: 819.964\n",
      "[90]\tvalid_0's tweedie: 819.958\n",
      "[91]\tvalid_0's tweedie: 819.957\n",
      "[92]\tvalid_0's tweedie: 819.957\n",
      "[93]\tvalid_0's tweedie: 819.957\n",
      "[94]\tvalid_0's tweedie: 819.961\n",
      "[95]\tvalid_0's tweedie: 819.961\n",
      "[96]\tvalid_0's tweedie: 819.961\n",
      "[97]\tvalid_0's tweedie: 819.961\n",
      "[98]\tvalid_0's tweedie: 819.961\n",
      "[99]\tvalid_0's tweedie: 819.961\n",
      "[100]\tvalid_0's tweedie: 819.961\n",
      "[101]\tvalid_0's tweedie: 819.96\n",
      "[102]\tvalid_0's tweedie: 819.96\n",
      "[103]\tvalid_0's tweedie: 819.965\n",
      "[104]\tvalid_0's tweedie: 819.965\n",
      "[105]\tvalid_0's tweedie: 819.96\n",
      "[106]\tvalid_0's tweedie: 819.956\n",
      "[107]\tvalid_0's tweedie: 819.956\n",
      "[108]\tvalid_0's tweedie: 819.956\n",
      "[109]\tvalid_0's tweedie: 819.958\n",
      "[110]\tvalid_0's tweedie: 819.958\n",
      "[111]\tvalid_0's tweedie: 819.959\n",
      "[112]\tvalid_0's tweedie: 819.959\n",
      "[113]\tvalid_0's tweedie: 819.959\n",
      "[114]\tvalid_0's tweedie: 819.959\n",
      "[115]\tvalid_0's tweedie: 819.959\n",
      "[116]\tvalid_0's tweedie: 819.96\n",
      "[117]\tvalid_0's tweedie: 819.955\n",
      "[118]\tvalid_0's tweedie: 819.953\n",
      "[119]\tvalid_0's tweedie: 819.956\n",
      "[120]\tvalid_0's tweedie: 819.956\n",
      "[121]\tvalid_0's tweedie: 819.955\n",
      "[122]\tvalid_0's tweedie: 819.953\n",
      "[123]\tvalid_0's tweedie: 819.952\n",
      "[124]\tvalid_0's tweedie: 819.951\n",
      "[125]\tvalid_0's tweedie: 819.951\n",
      "[126]\tvalid_0's tweedie: 819.954\n",
      "[127]\tvalid_0's tweedie: 819.95\n",
      "[128]\tvalid_0's tweedie: 819.95\n",
      "[129]\tvalid_0's tweedie: 819.95\n",
      "[130]\tvalid_0's tweedie: 819.948\n",
      "[131]\tvalid_0's tweedie: 819.948\n",
      "[132]\tvalid_0's tweedie: 819.946\n",
      "[133]\tvalid_0's tweedie: 819.944\n",
      "[134]\tvalid_0's tweedie: 819.947\n",
      "[135]\tvalid_0's tweedie: 819.945\n",
      "[136]\tvalid_0's tweedie: 819.945\n",
      "[137]\tvalid_0's tweedie: 819.944\n",
      "[138]\tvalid_0's tweedie: 819.945\n",
      "[139]\tvalid_0's tweedie: 819.945\n",
      "[140]\tvalid_0's tweedie: 819.946\n",
      "[141]\tvalid_0's tweedie: 819.947\n",
      "[142]\tvalid_0's tweedie: 819.949\n",
      "[143]\tvalid_0's tweedie: 819.95\n",
      "[144]\tvalid_0's tweedie: 819.95\n",
      "[145]\tvalid_0's tweedie: 819.95\n",
      "[146]\tvalid_0's tweedie: 819.949\n",
      "[147]\tvalid_0's tweedie: 819.948\n",
      "[148]\tvalid_0's tweedie: 819.949\n",
      "[149]\tvalid_0's tweedie: 819.948\n",
      "[150]\tvalid_0's tweedie: 819.945\n",
      "[151]\tvalid_0's tweedie: 819.946\n",
      "[152]\tvalid_0's tweedie: 819.945\n",
      "[153]\tvalid_0's tweedie: 819.945\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's tweedie: 819.944\n",
      "Training model for level 1 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442327\n",
      "[1]\tvalid_0's tweedie: 825.978\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.292\n",
      "[3]\tvalid_0's tweedie: 824.539\n",
      "[4]\tvalid_0's tweedie: 824.092\n",
      "[5]\tvalid_0's tweedie: 823.486\n",
      "[6]\tvalid_0's tweedie: 823.043\n",
      "[7]\tvalid_0's tweedie: 822.681\n",
      "[8]\tvalid_0's tweedie: 822.351\n",
      "[9]\tvalid_0's tweedie: 822.081\n",
      "[10]\tvalid_0's tweedie: 821.826\n",
      "[11]\tvalid_0's tweedie: 821.692\n",
      "[12]\tvalid_0's tweedie: 821.48\n",
      "[13]\tvalid_0's tweedie: 821.349\n",
      "[14]\tvalid_0's tweedie: 821.188\n",
      "[15]\tvalid_0's tweedie: 821.038\n",
      "[16]\tvalid_0's tweedie: 820.961\n",
      "[17]\tvalid_0's tweedie: 820.854\n",
      "[18]\tvalid_0's tweedie: 820.757\n",
      "[19]\tvalid_0's tweedie: 820.666\n",
      "[20]\tvalid_0's tweedie: 820.594\n",
      "[21]\tvalid_0's tweedie: 820.524\n",
      "[22]\tvalid_0's tweedie: 820.501\n",
      "[23]\tvalid_0's tweedie: 820.459\n",
      "[24]\tvalid_0's tweedie: 820.432\n",
      "[25]\tvalid_0's tweedie: 820.395\n",
      "[26]\tvalid_0's tweedie: 820.366\n",
      "[27]\tvalid_0's tweedie: 820.336\n",
      "[28]\tvalid_0's tweedie: 820.305\n",
      "[29]\tvalid_0's tweedie: 820.288\n",
      "[30]\tvalid_0's tweedie: 820.254\n",
      "[31]\tvalid_0's tweedie: 820.232\n",
      "[32]\tvalid_0's tweedie: 820.212\n",
      "[33]\tvalid_0's tweedie: 820.186\n",
      "[34]\tvalid_0's tweedie: 820.17\n",
      "[35]\tvalid_0's tweedie: 820.156\n",
      "[36]\tvalid_0's tweedie: 820.149\n",
      "[37]\tvalid_0's tweedie: 820.134\n",
      "[38]\tvalid_0's tweedie: 820.117\n",
      "[39]\tvalid_0's tweedie: 820.102\n",
      "[40]\tvalid_0's tweedie: 820.086\n",
      "[41]\tvalid_0's tweedie: 820.08\n",
      "[42]\tvalid_0's tweedie: 820.072\n",
      "[43]\tvalid_0's tweedie: 820.065\n",
      "[44]\tvalid_0's tweedie: 820.058\n",
      "[45]\tvalid_0's tweedie: 820.062\n",
      "[46]\tvalid_0's tweedie: 820.06\n",
      "[47]\tvalid_0's tweedie: 820.052\n",
      "[48]\tvalid_0's tweedie: 820.041\n",
      "[49]\tvalid_0's tweedie: 820.038\n",
      "[50]\tvalid_0's tweedie: 820.037\n",
      "[51]\tvalid_0's tweedie: 820.032\n",
      "[52]\tvalid_0's tweedie: 820.02\n",
      "[53]\tvalid_0's tweedie: 820.017\n",
      "[54]\tvalid_0's tweedie: 819.998\n",
      "[55]\tvalid_0's tweedie: 819.999\n",
      "[56]\tvalid_0's tweedie: 819.998\n",
      "[57]\tvalid_0's tweedie: 819.982\n",
      "[58]\tvalid_0's tweedie: 819.982\n",
      "[59]\tvalid_0's tweedie: 819.982\n",
      "[60]\tvalid_0's tweedie: 819.983\n",
      "[61]\tvalid_0's tweedie: 819.984\n",
      "[62]\tvalid_0's tweedie: 819.986\n",
      "[63]\tvalid_0's tweedie: 819.982\n",
      "[64]\tvalid_0's tweedie: 819.988\n",
      "[65]\tvalid_0's tweedie: 819.988\n",
      "[66]\tvalid_0's tweedie: 819.985\n",
      "[67]\tvalid_0's tweedie: 819.986\n",
      "[68]\tvalid_0's tweedie: 819.982\n",
      "[69]\tvalid_0's tweedie: 819.979\n",
      "[70]\tvalid_0's tweedie: 819.98\n",
      "[71]\tvalid_0's tweedie: 819.981\n",
      "[72]\tvalid_0's tweedie: 819.982\n",
      "[73]\tvalid_0's tweedie: 819.983\n",
      "[74]\tvalid_0's tweedie: 819.982\n",
      "[75]\tvalid_0's tweedie: 819.974\n",
      "[76]\tvalid_0's tweedie: 819.973\n",
      "[77]\tvalid_0's tweedie: 819.973\n",
      "[78]\tvalid_0's tweedie: 819.973\n",
      "[79]\tvalid_0's tweedie: 819.965\n",
      "[80]\tvalid_0's tweedie: 819.966\n",
      "[81]\tvalid_0's tweedie: 819.967\n",
      "[82]\tvalid_0's tweedie: 819.961\n",
      "[83]\tvalid_0's tweedie: 819.963\n",
      "[84]\tvalid_0's tweedie: 819.962\n",
      "[85]\tvalid_0's tweedie: 819.962\n",
      "[86]\tvalid_0's tweedie: 819.96\n",
      "[87]\tvalid_0's tweedie: 819.957\n",
      "[88]\tvalid_0's tweedie: 819.959\n",
      "[89]\tvalid_0's tweedie: 819.959\n",
      "[90]\tvalid_0's tweedie: 819.96\n",
      "[91]\tvalid_0's tweedie: 819.96\n",
      "[92]\tvalid_0's tweedie: 819.958\n",
      "[93]\tvalid_0's tweedie: 819.954\n",
      "[94]\tvalid_0's tweedie: 819.952\n",
      "[95]\tvalid_0's tweedie: 819.951\n",
      "[96]\tvalid_0's tweedie: 819.951\n",
      "[97]\tvalid_0's tweedie: 819.95\n",
      "[98]\tvalid_0's tweedie: 819.95\n",
      "[99]\tvalid_0's tweedie: 819.95\n",
      "[100]\tvalid_0's tweedie: 819.949\n",
      "[101]\tvalid_0's tweedie: 819.95\n",
      "[102]\tvalid_0's tweedie: 819.951\n",
      "[103]\tvalid_0's tweedie: 819.951\n",
      "[104]\tvalid_0's tweedie: 819.948\n",
      "[105]\tvalid_0's tweedie: 819.948\n",
      "[106]\tvalid_0's tweedie: 819.949\n",
      "[107]\tvalid_0's tweedie: 819.949\n",
      "[108]\tvalid_0's tweedie: 819.949\n",
      "[109]\tvalid_0's tweedie: 819.948\n",
      "[110]\tvalid_0's tweedie: 819.948\n",
      "[111]\tvalid_0's tweedie: 819.95\n",
      "[112]\tvalid_0's tweedie: 819.953\n",
      "[113]\tvalid_0's tweedie: 819.951\n",
      "[114]\tvalid_0's tweedie: 819.954\n",
      "[115]\tvalid_0's tweedie: 819.952\n",
      "[116]\tvalid_0's tweedie: 819.952\n",
      "[117]\tvalid_0's tweedie: 819.95\n",
      "[118]\tvalid_0's tweedie: 819.951\n",
      "[119]\tvalid_0's tweedie: 819.951\n",
      "[120]\tvalid_0's tweedie: 819.953\n",
      "[121]\tvalid_0's tweedie: 819.953\n",
      "[122]\tvalid_0's tweedie: 819.953\n",
      "[123]\tvalid_0's tweedie: 819.953\n",
      "[124]\tvalid_0's tweedie: 819.954\n",
      "[125]\tvalid_0's tweedie: 819.956\n",
      "[126]\tvalid_0's tweedie: 819.957\n",
      "[127]\tvalid_0's tweedie: 819.957\n",
      "[128]\tvalid_0's tweedie: 819.956\n",
      "[129]\tvalid_0's tweedie: 819.957\n",
      "[130]\tvalid_0's tweedie: 819.956\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's tweedie: 819.948\n",
      "Training model for level 1 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1867, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442486\n",
      "[1]\tvalid_0's tweedie: 825.972\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.287\n",
      "[3]\tvalid_0's tweedie: 824.534\n",
      "[4]\tvalid_0's tweedie: 824.085\n",
      "[5]\tvalid_0's tweedie: 823.552\n",
      "[6]\tvalid_0's tweedie: 823.104\n",
      "[7]\tvalid_0's tweedie: 822.713\n",
      "[8]\tvalid_0's tweedie: 822.37\n",
      "[9]\tvalid_0's tweedie: 822.092\n",
      "[10]\tvalid_0's tweedie: 821.843\n",
      "[11]\tvalid_0's tweedie: 821.712\n",
      "[12]\tvalid_0's tweedie: 821.495\n",
      "[13]\tvalid_0's tweedie: 821.338\n",
      "[14]\tvalid_0's tweedie: 821.163\n",
      "[15]\tvalid_0's tweedie: 821.077\n",
      "[16]\tvalid_0's tweedie: 820.936\n",
      "[17]\tvalid_0's tweedie: 820.837\n",
      "[18]\tvalid_0's tweedie: 820.741\n",
      "[19]\tvalid_0's tweedie: 820.667\n",
      "[20]\tvalid_0's tweedie: 820.583\n",
      "[21]\tvalid_0's tweedie: 820.518\n",
      "[22]\tvalid_0's tweedie: 820.495\n",
      "[23]\tvalid_0's tweedie: 820.452\n",
      "[24]\tvalid_0's tweedie: 820.416\n",
      "[25]\tvalid_0's tweedie: 820.384\n",
      "[26]\tvalid_0's tweedie: 820.352\n",
      "[27]\tvalid_0's tweedie: 820.354\n",
      "[28]\tvalid_0's tweedie: 820.325\n",
      "[29]\tvalid_0's tweedie: 820.3\n",
      "[30]\tvalid_0's tweedie: 820.279\n",
      "[31]\tvalid_0's tweedie: 820.254\n",
      "[32]\tvalid_0's tweedie: 820.236\n",
      "[33]\tvalid_0's tweedie: 820.22\n",
      "[34]\tvalid_0's tweedie: 820.21\n",
      "[35]\tvalid_0's tweedie: 820.195\n",
      "[36]\tvalid_0's tweedie: 820.187\n",
      "[37]\tvalid_0's tweedie: 820.179\n",
      "[38]\tvalid_0's tweedie: 820.162\n",
      "[39]\tvalid_0's tweedie: 820.158\n",
      "[40]\tvalid_0's tweedie: 820.142\n",
      "[41]\tvalid_0's tweedie: 820.131\n",
      "[42]\tvalid_0's tweedie: 820.123\n",
      "[43]\tvalid_0's tweedie: 820.111\n",
      "[44]\tvalid_0's tweedie: 820.097\n",
      "[45]\tvalid_0's tweedie: 820.093\n",
      "[46]\tvalid_0's tweedie: 820.096\n",
      "[47]\tvalid_0's tweedie: 820.091\n",
      "[48]\tvalid_0's tweedie: 820.081\n",
      "[49]\tvalid_0's tweedie: 820.074\n",
      "[50]\tvalid_0's tweedie: 820.072\n",
      "[51]\tvalid_0's tweedie: 820.07\n",
      "[52]\tvalid_0's tweedie: 820.069\n",
      "[53]\tvalid_0's tweedie: 820.051\n",
      "[54]\tvalid_0's tweedie: 820.047\n",
      "[55]\tvalid_0's tweedie: 820.045\n",
      "[56]\tvalid_0's tweedie: 820.038\n",
      "[57]\tvalid_0's tweedie: 820.04\n",
      "[58]\tvalid_0's tweedie: 820.04\n",
      "[59]\tvalid_0's tweedie: 820.042\n",
      "[60]\tvalid_0's tweedie: 820.038\n",
      "[61]\tvalid_0's tweedie: 820.037\n",
      "[62]\tvalid_0's tweedie: 820.031\n",
      "[63]\tvalid_0's tweedie: 820.031\n",
      "[64]\tvalid_0's tweedie: 820.035\n",
      "[65]\tvalid_0's tweedie: 820.038\n",
      "[66]\tvalid_0's tweedie: 820.025\n",
      "[67]\tvalid_0's tweedie: 820.022\n",
      "[68]\tvalid_0's tweedie: 820.021\n",
      "[69]\tvalid_0's tweedie: 820.023\n",
      "[70]\tvalid_0's tweedie: 820.028\n",
      "[71]\tvalid_0's tweedie: 820.02\n",
      "[72]\tvalid_0's tweedie: 820.018\n",
      "[73]\tvalid_0's tweedie: 820.017\n",
      "[74]\tvalid_0's tweedie: 820.015\n",
      "[75]\tvalid_0's tweedie: 820.015\n",
      "[76]\tvalid_0's tweedie: 820.02\n",
      "[77]\tvalid_0's tweedie: 820.02\n",
      "[78]\tvalid_0's tweedie: 820.022\n",
      "[79]\tvalid_0's tweedie: 820.027\n",
      "[80]\tvalid_0's tweedie: 820.03\n",
      "[81]\tvalid_0's tweedie: 820.029\n",
      "[82]\tvalid_0's tweedie: 820.028\n",
      "[83]\tvalid_0's tweedie: 820.025\n",
      "[84]\tvalid_0's tweedie: 820.022\n",
      "[85]\tvalid_0's tweedie: 820.023\n",
      "[86]\tvalid_0's tweedie: 820.023\n",
      "[87]\tvalid_0's tweedie: 820.023\n",
      "[88]\tvalid_0's tweedie: 820.019\n",
      "[89]\tvalid_0's tweedie: 820.016\n",
      "[90]\tvalid_0's tweedie: 820.011\n",
      "[91]\tvalid_0's tweedie: 820.011\n",
      "[92]\tvalid_0's tweedie: 820.011\n",
      "[93]\tvalid_0's tweedie: 820.007\n",
      "[94]\tvalid_0's tweedie: 820.005\n",
      "[95]\tvalid_0's tweedie: 820.009\n",
      "[96]\tvalid_0's tweedie: 820.011\n",
      "[97]\tvalid_0's tweedie: 820.011\n",
      "[98]\tvalid_0's tweedie: 820.012\n",
      "[99]\tvalid_0's tweedie: 820.01\n",
      "[100]\tvalid_0's tweedie: 820.014\n",
      "[101]\tvalid_0's tweedie: 820.006\n",
      "[102]\tvalid_0's tweedie: 820.007\n",
      "[103]\tvalid_0's tweedie: 820.005\n",
      "[104]\tvalid_0's tweedie: 820.004\n",
      "[105]\tvalid_0's tweedie: 820.006\n",
      "[106]\tvalid_0's tweedie: 820.006\n",
      "[107]\tvalid_0's tweedie: 819.999\n",
      "[108]\tvalid_0's tweedie: 819.998\n",
      "[109]\tvalid_0's tweedie: 819.998\n",
      "[110]\tvalid_0's tweedie: 819.997\n",
      "[111]\tvalid_0's tweedie: 819.998\n",
      "[112]\tvalid_0's tweedie: 819.998\n",
      "[113]\tvalid_0's tweedie: 820\n",
      "[114]\tvalid_0's tweedie: 820\n",
      "[115]\tvalid_0's tweedie: 819.996\n",
      "[116]\tvalid_0's tweedie: 819.993\n",
      "[117]\tvalid_0's tweedie: 819.995\n",
      "[118]\tvalid_0's tweedie: 819.995\n",
      "[119]\tvalid_0's tweedie: 819.996\n",
      "[120]\tvalid_0's tweedie: 819.997\n",
      "[121]\tvalid_0's tweedie: 819.993\n",
      "[122]\tvalid_0's tweedie: 819.993\n",
      "[123]\tvalid_0's tweedie: 819.993\n",
      "[124]\tvalid_0's tweedie: 819.993\n",
      "[125]\tvalid_0's tweedie: 819.993\n",
      "[126]\tvalid_0's tweedie: 819.994\n",
      "[127]\tvalid_0's tweedie: 819.994\n",
      "[128]\tvalid_0's tweedie: 819.995\n",
      "[129]\tvalid_0's tweedie: 819.995\n",
      "[130]\tvalid_0's tweedie: 819.991\n",
      "[131]\tvalid_0's tweedie: 819.99\n",
      "[132]\tvalid_0's tweedie: 819.99\n",
      "[133]\tvalid_0's tweedie: 819.99\n",
      "[134]\tvalid_0's tweedie: 819.99\n",
      "[135]\tvalid_0's tweedie: 819.99\n",
      "[136]\tvalid_0's tweedie: 819.99\n",
      "[137]\tvalid_0's tweedie: 819.99\n",
      "[138]\tvalid_0's tweedie: 819.993\n",
      "[139]\tvalid_0's tweedie: 819.989\n",
      "[140]\tvalid_0's tweedie: 819.987\n",
      "[141]\tvalid_0's tweedie: 819.986\n",
      "[142]\tvalid_0's tweedie: 819.984\n",
      "[143]\tvalid_0's tweedie: 819.986\n",
      "[144]\tvalid_0's tweedie: 819.987\n",
      "[145]\tvalid_0's tweedie: 819.987\n",
      "[146]\tvalid_0's tweedie: 819.987\n",
      "[147]\tvalid_0's tweedie: 819.987\n",
      "[148]\tvalid_0's tweedie: 819.987\n",
      "[149]\tvalid_0's tweedie: 819.987\n",
      "[150]\tvalid_0's tweedie: 819.989\n",
      "[151]\tvalid_0's tweedie: 819.989\n",
      "[152]\tvalid_0's tweedie: 819.991\n",
      "[153]\tvalid_0's tweedie: 819.991\n",
      "[154]\tvalid_0's tweedie: 819.992\n",
      "[155]\tvalid_0's tweedie: 819.993\n",
      "[156]\tvalid_0's tweedie: 819.992\n",
      "[157]\tvalid_0's tweedie: 819.99\n",
      "[158]\tvalid_0's tweedie: 819.989\n",
      "[159]\tvalid_0's tweedie: 819.99\n",
      "[160]\tvalid_0's tweedie: 819.992\n",
      "[161]\tvalid_0's tweedie: 819.993\n",
      "[162]\tvalid_0's tweedie: 819.994\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's tweedie: 819.984\n",
      "Training model for level 1 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1866, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442687\n",
      "[1]\tvalid_0's tweedie: 825.965\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.281\n",
      "[3]\tvalid_0's tweedie: 824.567\n",
      "[4]\tvalid_0's tweedie: 824.122\n",
      "[5]\tvalid_0's tweedie: 823.584\n",
      "[6]\tvalid_0's tweedie: 823.132\n",
      "[7]\tvalid_0's tweedie: 822.688\n",
      "[8]\tvalid_0's tweedie: 822.461\n",
      "[9]\tvalid_0's tweedie: 822.189\n",
      "[10]\tvalid_0's tweedie: 821.924\n",
      "[11]\tvalid_0's tweedie: 821.746\n",
      "[12]\tvalid_0's tweedie: 821.52\n",
      "[13]\tvalid_0's tweedie: 821.341\n",
      "[14]\tvalid_0's tweedie: 821.21\n",
      "[15]\tvalid_0's tweedie: 821.063\n",
      "[16]\tvalid_0's tweedie: 820.989\n",
      "[17]\tvalid_0's tweedie: 820.869\n",
      "[18]\tvalid_0's tweedie: 820.837\n",
      "[19]\tvalid_0's tweedie: 820.751\n",
      "[20]\tvalid_0's tweedie: 820.673\n",
      "[21]\tvalid_0's tweedie: 820.609\n",
      "[22]\tvalid_0's tweedie: 820.554\n",
      "[23]\tvalid_0's tweedie: 820.502\n",
      "[24]\tvalid_0's tweedie: 820.491\n",
      "[25]\tvalid_0's tweedie: 820.446\n",
      "[26]\tvalid_0's tweedie: 820.411\n",
      "[27]\tvalid_0's tweedie: 820.376\n",
      "[28]\tvalid_0's tweedie: 820.348\n",
      "[29]\tvalid_0's tweedie: 820.319\n",
      "[30]\tvalid_0's tweedie: 820.294\n",
      "[31]\tvalid_0's tweedie: 820.27\n",
      "[32]\tvalid_0's tweedie: 820.251\n",
      "[33]\tvalid_0's tweedie: 820.238\n",
      "[34]\tvalid_0's tweedie: 820.222\n",
      "[35]\tvalid_0's tweedie: 820.195\n",
      "[36]\tvalid_0's tweedie: 820.171\n",
      "[37]\tvalid_0's tweedie: 820.161\n",
      "[38]\tvalid_0's tweedie: 820.138\n",
      "[39]\tvalid_0's tweedie: 820.151\n",
      "[40]\tvalid_0's tweedie: 820.144\n",
      "[41]\tvalid_0's tweedie: 820.131\n",
      "[42]\tvalid_0's tweedie: 820.112\n",
      "[43]\tvalid_0's tweedie: 820.109\n",
      "[44]\tvalid_0's tweedie: 820.098\n",
      "[45]\tvalid_0's tweedie: 820.092\n",
      "[46]\tvalid_0's tweedie: 820.083\n",
      "[47]\tvalid_0's tweedie: 820.078\n",
      "[48]\tvalid_0's tweedie: 820.075\n",
      "[49]\tvalid_0's tweedie: 820.075\n",
      "[50]\tvalid_0's tweedie: 820.073\n",
      "[51]\tvalid_0's tweedie: 820.065\n",
      "[52]\tvalid_0's tweedie: 820.064\n",
      "[53]\tvalid_0's tweedie: 820.056\n",
      "[54]\tvalid_0's tweedie: 820.051\n",
      "[55]\tvalid_0's tweedie: 820.05\n",
      "[56]\tvalid_0's tweedie: 820.051\n",
      "[57]\tvalid_0's tweedie: 820.042\n",
      "[58]\tvalid_0's tweedie: 820.041\n",
      "[59]\tvalid_0's tweedie: 820.035\n",
      "[60]\tvalid_0's tweedie: 820.028\n",
      "[61]\tvalid_0's tweedie: 820.026\n",
      "[62]\tvalid_0's tweedie: 820.021\n",
      "[63]\tvalid_0's tweedie: 820.015\n",
      "[64]\tvalid_0's tweedie: 820.016\n",
      "[65]\tvalid_0's tweedie: 820.018\n",
      "[66]\tvalid_0's tweedie: 820.016\n",
      "[67]\tvalid_0's tweedie: 820.018\n",
      "[68]\tvalid_0's tweedie: 820.015\n",
      "[69]\tvalid_0's tweedie: 820.012\n",
      "[70]\tvalid_0's tweedie: 820.011\n",
      "[71]\tvalid_0's tweedie: 820.014\n",
      "[72]\tvalid_0's tweedie: 820.011\n",
      "[73]\tvalid_0's tweedie: 820.016\n",
      "[74]\tvalid_0's tweedie: 820.018\n",
      "[75]\tvalid_0's tweedie: 820.015\n",
      "[76]\tvalid_0's tweedie: 820.012\n",
      "[77]\tvalid_0's tweedie: 820.01\n",
      "[78]\tvalid_0's tweedie: 820.014\n",
      "[79]\tvalid_0's tweedie: 820.015\n",
      "[80]\tvalid_0's tweedie: 820.008\n",
      "[81]\tvalid_0's tweedie: 820.008\n",
      "[82]\tvalid_0's tweedie: 820.008\n",
      "[83]\tvalid_0's tweedie: 820.005\n",
      "[84]\tvalid_0's tweedie: 820.011\n",
      "[85]\tvalid_0's tweedie: 820.01\n",
      "[86]\tvalid_0's tweedie: 820.007\n",
      "[87]\tvalid_0's tweedie: 820.007\n",
      "[88]\tvalid_0's tweedie: 820.01\n",
      "[89]\tvalid_0's tweedie: 820.007\n",
      "[90]\tvalid_0's tweedie: 820.006\n",
      "[91]\tvalid_0's tweedie: 820.005\n",
      "[92]\tvalid_0's tweedie: 820.005\n",
      "[93]\tvalid_0's tweedie: 820.006\n",
      "[94]\tvalid_0's tweedie: 820.001\n",
      "[95]\tvalid_0's tweedie: 819.998\n",
      "[96]\tvalid_0's tweedie: 819.998\n",
      "[97]\tvalid_0's tweedie: 819.998\n",
      "[98]\tvalid_0's tweedie: 819.999\n",
      "[99]\tvalid_0's tweedie: 819.999\n",
      "[100]\tvalid_0's tweedie: 820.001\n",
      "[101]\tvalid_0's tweedie: 820.001\n",
      "[102]\tvalid_0's tweedie: 820.001\n",
      "[103]\tvalid_0's tweedie: 820\n",
      "[104]\tvalid_0's tweedie: 820\n",
      "[105]\tvalid_0's tweedie: 820.002\n",
      "[106]\tvalid_0's tweedie: 820.002\n",
      "[107]\tvalid_0's tweedie: 820.001\n",
      "[108]\tvalid_0's tweedie: 820.002\n",
      "[109]\tvalid_0's tweedie: 819.999\n",
      "[110]\tvalid_0's tweedie: 820\n",
      "[111]\tvalid_0's tweedie: 820.002\n",
      "[112]\tvalid_0's tweedie: 820.001\n",
      "[113]\tvalid_0's tweedie: 819.999\n",
      "[114]\tvalid_0's tweedie: 819.998\n",
      "[115]\tvalid_0's tweedie: 819.999\n",
      "[116]\tvalid_0's tweedie: 820.001\n",
      "[117]\tvalid_0's tweedie: 820.004\n",
      "[118]\tvalid_0's tweedie: 820.004\n",
      "[119]\tvalid_0's tweedie: 820.004\n",
      "[120]\tvalid_0's tweedie: 820.004\n",
      "[121]\tvalid_0's tweedie: 820\n",
      "[122]\tvalid_0's tweedie: 820.002\n",
      "[123]\tvalid_0's tweedie: 820.002\n",
      "[124]\tvalid_0's tweedie: 819.999\n",
      "[125]\tvalid_0's tweedie: 819.999\n",
      "[126]\tvalid_0's tweedie: 819.997\n",
      "[127]\tvalid_0's tweedie: 819.999\n",
      "[128]\tvalid_0's tweedie: 819.999\n",
      "[129]\tvalid_0's tweedie: 819.999\n",
      "[130]\tvalid_0's tweedie: 819.993\n",
      "[131]\tvalid_0's tweedie: 819.992\n",
      "[132]\tvalid_0's tweedie: 819.992\n",
      "[133]\tvalid_0's tweedie: 819.991\n",
      "[134]\tvalid_0's tweedie: 819.992\n",
      "[135]\tvalid_0's tweedie: 819.993\n",
      "[136]\tvalid_0's tweedie: 819.996\n",
      "[137]\tvalid_0's tweedie: 820.001\n",
      "[138]\tvalid_0's tweedie: 820.001\n",
      "[139]\tvalid_0's tweedie: 820.001\n",
      "[140]\tvalid_0's tweedie: 819.997\n",
      "[141]\tvalid_0's tweedie: 819.998\n",
      "[142]\tvalid_0's tweedie: 819.995\n",
      "[143]\tvalid_0's tweedie: 819.995\n",
      "[144]\tvalid_0's tweedie: 819.994\n",
      "[145]\tvalid_0's tweedie: 819.998\n",
      "[146]\tvalid_0's tweedie: 819.996\n",
      "[147]\tvalid_0's tweedie: 819.994\n",
      "[148]\tvalid_0's tweedie: 819.994\n",
      "[149]\tvalid_0's tweedie: 819.994\n",
      "[150]\tvalid_0's tweedie: 819.994\n",
      "[151]\tvalid_0's tweedie: 819.986\n",
      "[152]\tvalid_0's tweedie: 819.983\n",
      "[153]\tvalid_0's tweedie: 819.983\n",
      "[154]\tvalid_0's tweedie: 819.984\n",
      "[155]\tvalid_0's tweedie: 819.985\n",
      "[156]\tvalid_0's tweedie: 819.983\n",
      "[157]\tvalid_0's tweedie: 819.981\n",
      "[158]\tvalid_0's tweedie: 819.984\n",
      "[159]\tvalid_0's tweedie: 819.983\n",
      "[160]\tvalid_0's tweedie: 819.983\n",
      "[161]\tvalid_0's tweedie: 819.984\n",
      "[162]\tvalid_0's tweedie: 819.984\n",
      "[163]\tvalid_0's tweedie: 819.984\n",
      "[164]\tvalid_0's tweedie: 819.983\n",
      "[165]\tvalid_0's tweedie: 819.984\n",
      "[166]\tvalid_0's tweedie: 819.984\n",
      "[167]\tvalid_0's tweedie: 819.981\n",
      "[168]\tvalid_0's tweedie: 819.981\n",
      "[169]\tvalid_0's tweedie: 819.983\n",
      "[170]\tvalid_0's tweedie: 819.983\n",
      "[171]\tvalid_0's tweedie: 819.983\n",
      "[172]\tvalid_0's tweedie: 819.982\n",
      "[173]\tvalid_0's tweedie: 819.982\n",
      "[174]\tvalid_0's tweedie: 819.982\n",
      "[175]\tvalid_0's tweedie: 819.981\n",
      "[176]\tvalid_0's tweedie: 819.983\n",
      "[177]\tvalid_0's tweedie: 819.984\n",
      "[178]\tvalid_0's tweedie: 819.985\n",
      "[179]\tvalid_0's tweedie: 819.985\n",
      "[180]\tvalid_0's tweedie: 819.985\n",
      "[181]\tvalid_0's tweedie: 819.984\n",
      "[182]\tvalid_0's tweedie: 819.984\n",
      "[183]\tvalid_0's tweedie: 819.986\n",
      "[184]\tvalid_0's tweedie: 819.986\n",
      "[185]\tvalid_0's tweedie: 819.986\n",
      "[186]\tvalid_0's tweedie: 819.984\n",
      "[187]\tvalid_0's tweedie: 819.986\n",
      "[188]\tvalid_0's tweedie: 819.987\n",
      "[189]\tvalid_0's tweedie: 819.987\n",
      "[190]\tvalid_0's tweedie: 819.988\n",
      "[191]\tvalid_0's tweedie: 819.988\n",
      "[192]\tvalid_0's tweedie: 819.991\n",
      "[193]\tvalid_0's tweedie: 819.992\n",
      "[194]\tvalid_0's tweedie: 819.992\n",
      "[195]\tvalid_0's tweedie: 819.992\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's tweedie: 819.981\n",
      "Training model for level 1 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1865, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.442906\n",
      "[1]\tvalid_0's tweedie: 825.949\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.338\n",
      "[3]\tvalid_0's tweedie: 824.615\n",
      "[4]\tvalid_0's tweedie: 824.113\n",
      "[5]\tvalid_0's tweedie: 823.551\n",
      "[6]\tvalid_0's tweedie: 823.037\n",
      "[7]\tvalid_0's tweedie: 822.667\n",
      "[8]\tvalid_0's tweedie: 822.336\n",
      "[9]\tvalid_0's tweedie: 822.068\n",
      "[10]\tvalid_0's tweedie: 821.81\n",
      "[11]\tvalid_0's tweedie: 821.599\n",
      "[12]\tvalid_0's tweedie: 821.449\n",
      "[13]\tvalid_0's tweedie: 821.289\n",
      "[14]\tvalid_0's tweedie: 821.119\n",
      "[15]\tvalid_0's tweedie: 820.994\n",
      "[16]\tvalid_0's tweedie: 820.886\n",
      "[17]\tvalid_0's tweedie: 820.785\n",
      "[18]\tvalid_0's tweedie: 820.746\n",
      "[19]\tvalid_0's tweedie: 820.712\n",
      "[20]\tvalid_0's tweedie: 820.639\n",
      "[21]\tvalid_0's tweedie: 820.58\n",
      "[22]\tvalid_0's tweedie: 820.518\n",
      "[23]\tvalid_0's tweedie: 820.49\n",
      "[24]\tvalid_0's tweedie: 820.48\n",
      "[25]\tvalid_0's tweedie: 820.442\n",
      "[26]\tvalid_0's tweedie: 820.42\n",
      "[27]\tvalid_0's tweedie: 820.387\n",
      "[28]\tvalid_0's tweedie: 820.357\n",
      "[29]\tvalid_0's tweedie: 820.327\n",
      "[30]\tvalid_0's tweedie: 820.301\n",
      "[31]\tvalid_0's tweedie: 820.282\n",
      "[32]\tvalid_0's tweedie: 820.27\n",
      "[33]\tvalid_0's tweedie: 820.256\n",
      "[34]\tvalid_0's tweedie: 820.234\n",
      "[35]\tvalid_0's tweedie: 820.222\n",
      "[36]\tvalid_0's tweedie: 820.2\n",
      "[37]\tvalid_0's tweedie: 820.198\n",
      "[38]\tvalid_0's tweedie: 820.183\n",
      "[39]\tvalid_0's tweedie: 820.191\n",
      "[40]\tvalid_0's tweedie: 820.174\n",
      "[41]\tvalid_0's tweedie: 820.173\n",
      "[42]\tvalid_0's tweedie: 820.15\n",
      "[43]\tvalid_0's tweedie: 820.144\n",
      "[44]\tvalid_0's tweedie: 820.136\n",
      "[45]\tvalid_0's tweedie: 820.126\n",
      "[46]\tvalid_0's tweedie: 820.12\n",
      "[47]\tvalid_0's tweedie: 820.114\n",
      "[48]\tvalid_0's tweedie: 820.106\n",
      "[49]\tvalid_0's tweedie: 820.103\n",
      "[50]\tvalid_0's tweedie: 820.098\n",
      "[51]\tvalid_0's tweedie: 820.095\n",
      "[52]\tvalid_0's tweedie: 820.084\n",
      "[53]\tvalid_0's tweedie: 820.078\n",
      "[54]\tvalid_0's tweedie: 820.076\n",
      "[55]\tvalid_0's tweedie: 820.073\n",
      "[56]\tvalid_0's tweedie: 820.059\n",
      "[57]\tvalid_0's tweedie: 820.055\n",
      "[58]\tvalid_0's tweedie: 820.056\n",
      "[59]\tvalid_0's tweedie: 820.058\n",
      "[60]\tvalid_0's tweedie: 820.046\n",
      "[61]\tvalid_0's tweedie: 820.045\n",
      "[62]\tvalid_0's tweedie: 820.048\n",
      "[63]\tvalid_0's tweedie: 820.042\n",
      "[64]\tvalid_0's tweedie: 820.041\n",
      "[65]\tvalid_0's tweedie: 820.035\n",
      "[66]\tvalid_0's tweedie: 820.036\n",
      "[67]\tvalid_0's tweedie: 820.035\n",
      "[68]\tvalid_0's tweedie: 820.034\n",
      "[69]\tvalid_0's tweedie: 820.029\n",
      "[70]\tvalid_0's tweedie: 820.028\n",
      "[71]\tvalid_0's tweedie: 820.028\n",
      "[72]\tvalid_0's tweedie: 820.028\n",
      "[73]\tvalid_0's tweedie: 820.028\n",
      "[74]\tvalid_0's tweedie: 820.027\n",
      "[75]\tvalid_0's tweedie: 820.026\n",
      "[76]\tvalid_0's tweedie: 820.023\n",
      "[77]\tvalid_0's tweedie: 820.024\n",
      "[78]\tvalid_0's tweedie: 820.023\n",
      "[79]\tvalid_0's tweedie: 820.012\n",
      "[80]\tvalid_0's tweedie: 820.008\n",
      "[81]\tvalid_0's tweedie: 820.008\n",
      "[82]\tvalid_0's tweedie: 820.008\n",
      "[83]\tvalid_0's tweedie: 820.007\n",
      "[84]\tvalid_0's tweedie: 820.005\n",
      "[85]\tvalid_0's tweedie: 820.006\n",
      "[86]\tvalid_0's tweedie: 820.006\n",
      "[87]\tvalid_0's tweedie: 820.005\n",
      "[88]\tvalid_0's tweedie: 820.009\n",
      "[89]\tvalid_0's tweedie: 820.007\n",
      "[90]\tvalid_0's tweedie: 820.01\n",
      "[91]\tvalid_0's tweedie: 820.011\n",
      "[92]\tvalid_0's tweedie: 820.007\n",
      "[93]\tvalid_0's tweedie: 820\n",
      "[94]\tvalid_0's tweedie: 819.998\n",
      "[95]\tvalid_0's tweedie: 819.997\n",
      "[96]\tvalid_0's tweedie: 819.996\n",
      "[97]\tvalid_0's tweedie: 819.992\n",
      "[98]\tvalid_0's tweedie: 819.984\n",
      "[99]\tvalid_0's tweedie: 819.984\n",
      "[100]\tvalid_0's tweedie: 819.983\n",
      "[101]\tvalid_0's tweedie: 819.985\n",
      "[102]\tvalid_0's tweedie: 819.986\n",
      "[103]\tvalid_0's tweedie: 819.986\n",
      "[104]\tvalid_0's tweedie: 819.988\n",
      "[105]\tvalid_0's tweedie: 819.99\n",
      "[106]\tvalid_0's tweedie: 819.986\n",
      "[107]\tvalid_0's tweedie: 819.984\n",
      "[108]\tvalid_0's tweedie: 819.984\n",
      "[109]\tvalid_0's tweedie: 819.98\n",
      "[110]\tvalid_0's tweedie: 819.983\n",
      "[111]\tvalid_0's tweedie: 819.981\n",
      "[112]\tvalid_0's tweedie: 819.981\n",
      "[113]\tvalid_0's tweedie: 819.981\n",
      "[114]\tvalid_0's tweedie: 819.979\n",
      "[115]\tvalid_0's tweedie: 819.979\n",
      "[116]\tvalid_0's tweedie: 819.98\n",
      "[117]\tvalid_0's tweedie: 819.981\n",
      "[118]\tvalid_0's tweedie: 819.982\n",
      "[119]\tvalid_0's tweedie: 819.981\n",
      "[120]\tvalid_0's tweedie: 819.98\n",
      "[121]\tvalid_0's tweedie: 819.977\n",
      "[122]\tvalid_0's tweedie: 819.977\n",
      "[123]\tvalid_0's tweedie: 819.977\n",
      "[124]\tvalid_0's tweedie: 819.976\n",
      "[125]\tvalid_0's tweedie: 819.975\n",
      "[126]\tvalid_0's tweedie: 819.968\n",
      "[127]\tvalid_0's tweedie: 819.965\n",
      "[128]\tvalid_0's tweedie: 819.961\n",
      "[129]\tvalid_0's tweedie: 819.961\n",
      "[130]\tvalid_0's tweedie: 819.96\n",
      "[131]\tvalid_0's tweedie: 819.958\n",
      "[132]\tvalid_0's tweedie: 819.954\n",
      "[133]\tvalid_0's tweedie: 819.955\n",
      "[134]\tvalid_0's tweedie: 819.954\n",
      "[135]\tvalid_0's tweedie: 819.952\n",
      "[136]\tvalid_0's tweedie: 819.952\n",
      "[137]\tvalid_0's tweedie: 819.951\n",
      "[138]\tvalid_0's tweedie: 819.945\n",
      "[139]\tvalid_0's tweedie: 819.945\n",
      "[140]\tvalid_0's tweedie: 819.946\n",
      "[141]\tvalid_0's tweedie: 819.946\n",
      "[142]\tvalid_0's tweedie: 819.946\n",
      "[143]\tvalid_0's tweedie: 819.946\n",
      "[144]\tvalid_0's tweedie: 819.947\n",
      "[145]\tvalid_0's tweedie: 819.947\n",
      "[146]\tvalid_0's tweedie: 819.951\n",
      "[147]\tvalid_0's tweedie: 819.951\n",
      "[148]\tvalid_0's tweedie: 819.952\n",
      "[149]\tvalid_0's tweedie: 819.953\n",
      "[150]\tvalid_0's tweedie: 819.954\n",
      "[151]\tvalid_0's tweedie: 819.95\n",
      "[152]\tvalid_0's tweedie: 819.95\n",
      "[153]\tvalid_0's tweedie: 819.951\n",
      "[154]\tvalid_0's tweedie: 819.947\n",
      "[155]\tvalid_0's tweedie: 819.947\n",
      "[156]\tvalid_0's tweedie: 819.948\n",
      "[157]\tvalid_0's tweedie: 819.948\n",
      "[158]\tvalid_0's tweedie: 819.949\n",
      "[159]\tvalid_0's tweedie: 819.945\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's tweedie: 819.945\n",
      "Training model for level 1 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1864, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443071\n",
      "[1]\tvalid_0's tweedie: 825.928\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.02\n",
      "[3]\tvalid_0's tweedie: 824.461\n",
      "[4]\tvalid_0's tweedie: 823.891\n",
      "[5]\tvalid_0's tweedie: 823.478\n",
      "[6]\tvalid_0's tweedie: 823.02\n",
      "[7]\tvalid_0's tweedie: 822.667\n",
      "[8]\tvalid_0's tweedie: 822.338\n",
      "[9]\tvalid_0's tweedie: 822.054\n",
      "[10]\tvalid_0's tweedie: 821.81\n",
      "[11]\tvalid_0's tweedie: 821.594\n",
      "[12]\tvalid_0's tweedie: 821.398\n",
      "[13]\tvalid_0's tweedie: 821.239\n",
      "[14]\tvalid_0's tweedie: 821.129\n",
      "[15]\tvalid_0's tweedie: 821.002\n",
      "[16]\tvalid_0's tweedie: 820.942\n",
      "[17]\tvalid_0's tweedie: 820.901\n",
      "[18]\tvalid_0's tweedie: 820.815\n",
      "[19]\tvalid_0's tweedie: 820.789\n",
      "[20]\tvalid_0's tweedie: 820.709\n",
      "[21]\tvalid_0's tweedie: 820.647\n",
      "[22]\tvalid_0's tweedie: 820.612\n",
      "[23]\tvalid_0's tweedie: 820.558\n",
      "[24]\tvalid_0's tweedie: 820.502\n",
      "[25]\tvalid_0's tweedie: 820.465\n",
      "[26]\tvalid_0's tweedie: 820.425\n",
      "[27]\tvalid_0's tweedie: 820.383\n",
      "[28]\tvalid_0's tweedie: 820.344\n",
      "[29]\tvalid_0's tweedie: 820.303\n",
      "[30]\tvalid_0's tweedie: 820.281\n",
      "[31]\tvalid_0's tweedie: 820.252\n",
      "[32]\tvalid_0's tweedie: 820.211\n",
      "[33]\tvalid_0's tweedie: 820.195\n",
      "[34]\tvalid_0's tweedie: 820.174\n",
      "[35]\tvalid_0's tweedie: 820.154\n",
      "[36]\tvalid_0's tweedie: 820.137\n",
      "[37]\tvalid_0's tweedie: 820.115\n",
      "[38]\tvalid_0's tweedie: 820.099\n",
      "[39]\tvalid_0's tweedie: 820.088\n",
      "[40]\tvalid_0's tweedie: 820.062\n",
      "[41]\tvalid_0's tweedie: 820.048\n",
      "[42]\tvalid_0's tweedie: 820.034\n",
      "[43]\tvalid_0's tweedie: 820.038\n",
      "[44]\tvalid_0's tweedie: 820.022\n",
      "[45]\tvalid_0's tweedie: 820.016\n",
      "[46]\tvalid_0's tweedie: 820.017\n",
      "[47]\tvalid_0's tweedie: 820.012\n",
      "[48]\tvalid_0's tweedie: 820.008\n",
      "[49]\tvalid_0's tweedie: 820.007\n",
      "[50]\tvalid_0's tweedie: 820.001\n",
      "[51]\tvalid_0's tweedie: 820.002\n",
      "[52]\tvalid_0's tweedie: 820.001\n",
      "[53]\tvalid_0's tweedie: 819.998\n",
      "[54]\tvalid_0's tweedie: 819.992\n",
      "[55]\tvalid_0's tweedie: 819.982\n",
      "[56]\tvalid_0's tweedie: 819.974\n",
      "[57]\tvalid_0's tweedie: 819.966\n",
      "[58]\tvalid_0's tweedie: 819.965\n",
      "[59]\tvalid_0's tweedie: 819.966\n",
      "[60]\tvalid_0's tweedie: 819.961\n",
      "[61]\tvalid_0's tweedie: 819.967\n",
      "[62]\tvalid_0's tweedie: 819.973\n",
      "[63]\tvalid_0's tweedie: 819.964\n",
      "[64]\tvalid_0's tweedie: 819.957\n",
      "[65]\tvalid_0's tweedie: 819.953\n",
      "[66]\tvalid_0's tweedie: 819.952\n",
      "[67]\tvalid_0's tweedie: 819.949\n",
      "[68]\tvalid_0's tweedie: 819.948\n",
      "[69]\tvalid_0's tweedie: 819.948\n",
      "[70]\tvalid_0's tweedie: 819.943\n",
      "[71]\tvalid_0's tweedie: 819.934\n",
      "[72]\tvalid_0's tweedie: 819.935\n",
      "[73]\tvalid_0's tweedie: 819.937\n",
      "[74]\tvalid_0's tweedie: 819.934\n",
      "[75]\tvalid_0's tweedie: 819.934\n",
      "[76]\tvalid_0's tweedie: 819.931\n",
      "[77]\tvalid_0's tweedie: 819.932\n",
      "[78]\tvalid_0's tweedie: 819.932\n",
      "[79]\tvalid_0's tweedie: 819.931\n",
      "[80]\tvalid_0's tweedie: 819.923\n",
      "[81]\tvalid_0's tweedie: 819.922\n",
      "[82]\tvalid_0's tweedie: 819.922\n",
      "[83]\tvalid_0's tweedie: 819.923\n",
      "[84]\tvalid_0's tweedie: 819.914\n",
      "[85]\tvalid_0's tweedie: 819.918\n",
      "[86]\tvalid_0's tweedie: 819.918\n",
      "[87]\tvalid_0's tweedie: 819.92\n",
      "[88]\tvalid_0's tweedie: 819.911\n",
      "[89]\tvalid_0's tweedie: 819.911\n",
      "[90]\tvalid_0's tweedie: 819.911\n",
      "[91]\tvalid_0's tweedie: 819.908\n",
      "[92]\tvalid_0's tweedie: 819.908\n",
      "[93]\tvalid_0's tweedie: 819.903\n",
      "[94]\tvalid_0's tweedie: 819.901\n",
      "[95]\tvalid_0's tweedie: 819.903\n",
      "[96]\tvalid_0's tweedie: 819.894\n",
      "[97]\tvalid_0's tweedie: 819.888\n",
      "[98]\tvalid_0's tweedie: 819.886\n",
      "[99]\tvalid_0's tweedie: 819.887\n",
      "[100]\tvalid_0's tweedie: 819.888\n",
      "[101]\tvalid_0's tweedie: 819.887\n",
      "[102]\tvalid_0's tweedie: 819.887\n",
      "[103]\tvalid_0's tweedie: 819.879\n",
      "[104]\tvalid_0's tweedie: 819.874\n",
      "[105]\tvalid_0's tweedie: 819.874\n",
      "[106]\tvalid_0's tweedie: 819.875\n",
      "[107]\tvalid_0's tweedie: 819.872\n",
      "[108]\tvalid_0's tweedie: 819.867\n",
      "[109]\tvalid_0's tweedie: 819.867\n",
      "[110]\tvalid_0's tweedie: 819.858\n",
      "[111]\tvalid_0's tweedie: 819.856\n",
      "[112]\tvalid_0's tweedie: 819.855\n",
      "[113]\tvalid_0's tweedie: 819.855\n",
      "[114]\tvalid_0's tweedie: 819.85\n",
      "[115]\tvalid_0's tweedie: 819.85\n",
      "[116]\tvalid_0's tweedie: 819.851\n",
      "[117]\tvalid_0's tweedie: 819.848\n",
      "[118]\tvalid_0's tweedie: 819.847\n",
      "[119]\tvalid_0's tweedie: 819.847\n",
      "[120]\tvalid_0's tweedie: 819.842\n",
      "[121]\tvalid_0's tweedie: 819.842\n",
      "[122]\tvalid_0's tweedie: 819.842\n",
      "[123]\tvalid_0's tweedie: 819.843\n",
      "[124]\tvalid_0's tweedie: 819.845\n",
      "[125]\tvalid_0's tweedie: 819.84\n",
      "[126]\tvalid_0's tweedie: 819.84\n",
      "[127]\tvalid_0's tweedie: 819.839\n",
      "[128]\tvalid_0's tweedie: 819.839\n",
      "[129]\tvalid_0's tweedie: 819.84\n",
      "[130]\tvalid_0's tweedie: 819.84\n",
      "[131]\tvalid_0's tweedie: 819.837\n",
      "[132]\tvalid_0's tweedie: 819.837\n",
      "[133]\tvalid_0's tweedie: 819.837\n",
      "[134]\tvalid_0's tweedie: 819.838\n",
      "[135]\tvalid_0's tweedie: 819.837\n",
      "[136]\tvalid_0's tweedie: 819.836\n",
      "[137]\tvalid_0's tweedie: 819.836\n",
      "[138]\tvalid_0's tweedie: 819.836\n",
      "[139]\tvalid_0's tweedie: 819.834\n",
      "[140]\tvalid_0's tweedie: 819.835\n",
      "[141]\tvalid_0's tweedie: 819.836\n",
      "[142]\tvalid_0's tweedie: 819.84\n",
      "[143]\tvalid_0's tweedie: 819.838\n",
      "[144]\tvalid_0's tweedie: 819.838\n",
      "[145]\tvalid_0's tweedie: 819.838\n",
      "[146]\tvalid_0's tweedie: 819.835\n",
      "[147]\tvalid_0's tweedie: 819.836\n",
      "[148]\tvalid_0's tweedie: 819.836\n",
      "[149]\tvalid_0's tweedie: 819.836\n",
      "[150]\tvalid_0's tweedie: 819.836\n",
      "[151]\tvalid_0's tweedie: 819.835\n",
      "[152]\tvalid_0's tweedie: 819.835\n",
      "[153]\tvalid_0's tweedie: 819.835\n",
      "[154]\tvalid_0's tweedie: 819.832\n",
      "[155]\tvalid_0's tweedie: 819.834\n",
      "[156]\tvalid_0's tweedie: 819.833\n",
      "[157]\tvalid_0's tweedie: 819.832\n",
      "[158]\tvalid_0's tweedie: 819.832\n",
      "[159]\tvalid_0's tweedie: 819.832\n",
      "[160]\tvalid_0's tweedie: 819.831\n",
      "[161]\tvalid_0's tweedie: 819.833\n",
      "[162]\tvalid_0's tweedie: 819.831\n",
      "[163]\tvalid_0's tweedie: 819.83\n",
      "[164]\tvalid_0's tweedie: 819.83\n",
      "[165]\tvalid_0's tweedie: 819.83\n",
      "[166]\tvalid_0's tweedie: 819.831\n",
      "[167]\tvalid_0's tweedie: 819.831\n",
      "[168]\tvalid_0's tweedie: 819.833\n",
      "[169]\tvalid_0's tweedie: 819.831\n",
      "[170]\tvalid_0's tweedie: 819.831\n",
      "[171]\tvalid_0's tweedie: 819.831\n",
      "[172]\tvalid_0's tweedie: 819.829\n",
      "[173]\tvalid_0's tweedie: 819.83\n",
      "[174]\tvalid_0's tweedie: 819.828\n",
      "[175]\tvalid_0's tweedie: 819.83\n",
      "[176]\tvalid_0's tweedie: 819.828\n",
      "[177]\tvalid_0's tweedie: 819.829\n",
      "[178]\tvalid_0's tweedie: 819.829\n",
      "[179]\tvalid_0's tweedie: 819.829\n",
      "[180]\tvalid_0's tweedie: 819.829\n",
      "[181]\tvalid_0's tweedie: 819.829\n",
      "[182]\tvalid_0's tweedie: 819.828\n",
      "[183]\tvalid_0's tweedie: 819.828\n",
      "[184]\tvalid_0's tweedie: 819.829\n",
      "[185]\tvalid_0's tweedie: 819.827\n",
      "[186]\tvalid_0's tweedie: 819.824\n",
      "[187]\tvalid_0's tweedie: 819.825\n",
      "[188]\tvalid_0's tweedie: 819.825\n",
      "[189]\tvalid_0's tweedie: 819.825\n",
      "[190]\tvalid_0's tweedie: 819.825\n",
      "[191]\tvalid_0's tweedie: 819.824\n",
      "[192]\tvalid_0's tweedie: 819.824\n",
      "[193]\tvalid_0's tweedie: 819.824\n",
      "[194]\tvalid_0's tweedie: 819.825\n",
      "[195]\tvalid_0's tweedie: 819.824\n",
      "[196]\tvalid_0's tweedie: 819.824\n",
      "[197]\tvalid_0's tweedie: 819.824\n",
      "[198]\tvalid_0's tweedie: 819.826\n",
      "[199]\tvalid_0's tweedie: 819.826\n",
      "[200]\tvalid_0's tweedie: 819.826\n",
      "[201]\tvalid_0's tweedie: 819.826\n",
      "[202]\tvalid_0's tweedie: 819.826\n",
      "[203]\tvalid_0's tweedie: 819.824\n",
      "[204]\tvalid_0's tweedie: 819.824\n",
      "[205]\tvalid_0's tweedie: 819.825\n",
      "[206]\tvalid_0's tweedie: 819.824\n",
      "[207]\tvalid_0's tweedie: 819.824\n",
      "[208]\tvalid_0's tweedie: 819.825\n",
      "[209]\tvalid_0's tweedie: 819.825\n",
      "[210]\tvalid_0's tweedie: 819.825\n",
      "[211]\tvalid_0's tweedie: 819.824\n",
      "[212]\tvalid_0's tweedie: 819.826\n",
      "[213]\tvalid_0's tweedie: 819.828\n",
      "[214]\tvalid_0's tweedie: 819.826\n",
      "[215]\tvalid_0's tweedie: 819.826\n",
      "[216]\tvalid_0's tweedie: 819.826\n",
      "[217]\tvalid_0's tweedie: 819.826\n",
      "[218]\tvalid_0's tweedie: 819.827\n",
      "[219]\tvalid_0's tweedie: 819.827\n",
      "[220]\tvalid_0's tweedie: 819.827\n",
      "[221]\tvalid_0's tweedie: 819.828\n",
      "[222]\tvalid_0's tweedie: 819.829\n",
      "[223]\tvalid_0's tweedie: 819.83\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's tweedie: 819.824\n",
      "Training model for level 1 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1863, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443112\n",
      "[1]\tvalid_0's tweedie: 825.927\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.12\n",
      "[3]\tvalid_0's tweedie: 824.446\n",
      "[4]\tvalid_0's tweedie: 823.903\n",
      "[5]\tvalid_0's tweedie: 823.525\n",
      "[6]\tvalid_0's tweedie: 823.074\n",
      "[7]\tvalid_0's tweedie: 822.696\n",
      "[8]\tvalid_0's tweedie: 822.44\n",
      "[9]\tvalid_0's tweedie: 822.163\n",
      "[10]\tvalid_0's tweedie: 821.975\n",
      "[11]\tvalid_0's tweedie: 821.745\n",
      "[12]\tvalid_0's tweedie: 821.556\n",
      "[13]\tvalid_0's tweedie: 821.379\n",
      "[14]\tvalid_0's tweedie: 821.226\n",
      "[15]\tvalid_0's tweedie: 821.109\n",
      "[16]\tvalid_0's tweedie: 820.993\n",
      "[17]\tvalid_0's tweedie: 820.929\n",
      "[18]\tvalid_0's tweedie: 820.841\n",
      "[19]\tvalid_0's tweedie: 820.794\n",
      "[20]\tvalid_0's tweedie: 820.744\n",
      "[21]\tvalid_0's tweedie: 820.676\n",
      "[22]\tvalid_0's tweedie: 820.625\n",
      "[23]\tvalid_0's tweedie: 820.574\n",
      "[24]\tvalid_0's tweedie: 820.524\n",
      "[25]\tvalid_0's tweedie: 820.482\n",
      "[26]\tvalid_0's tweedie: 820.429\n",
      "[27]\tvalid_0's tweedie: 820.381\n",
      "[28]\tvalid_0's tweedie: 820.347\n",
      "[29]\tvalid_0's tweedie: 820.343\n",
      "[30]\tvalid_0's tweedie: 820.311\n",
      "[31]\tvalid_0's tweedie: 820.293\n",
      "[32]\tvalid_0's tweedie: 820.261\n",
      "[33]\tvalid_0's tweedie: 820.24\n",
      "[34]\tvalid_0's tweedie: 820.227\n",
      "[35]\tvalid_0's tweedie: 820.214\n",
      "[36]\tvalid_0's tweedie: 820.188\n",
      "[37]\tvalid_0's tweedie: 820.17\n",
      "[38]\tvalid_0's tweedie: 820.148\n",
      "[39]\tvalid_0's tweedie: 820.133\n",
      "[40]\tvalid_0's tweedie: 820.12\n",
      "[41]\tvalid_0's tweedie: 820.097\n",
      "[42]\tvalid_0's tweedie: 820.088\n",
      "[43]\tvalid_0's tweedie: 820.088\n",
      "[44]\tvalid_0's tweedie: 820.07\n",
      "[45]\tvalid_0's tweedie: 820.056\n",
      "[46]\tvalid_0's tweedie: 820.041\n",
      "[47]\tvalid_0's tweedie: 820.032\n",
      "[48]\tvalid_0's tweedie: 820.02\n",
      "[49]\tvalid_0's tweedie: 820.017\n",
      "[50]\tvalid_0's tweedie: 820.003\n",
      "[51]\tvalid_0's tweedie: 819.998\n",
      "[52]\tvalid_0's tweedie: 819.992\n",
      "[53]\tvalid_0's tweedie: 819.985\n",
      "[54]\tvalid_0's tweedie: 819.983\n",
      "[55]\tvalid_0's tweedie: 819.978\n",
      "[56]\tvalid_0's tweedie: 819.968\n",
      "[57]\tvalid_0's tweedie: 819.958\n",
      "[58]\tvalid_0's tweedie: 819.956\n",
      "[59]\tvalid_0's tweedie: 819.941\n",
      "[60]\tvalid_0's tweedie: 819.934\n",
      "[61]\tvalid_0's tweedie: 819.936\n",
      "[62]\tvalid_0's tweedie: 819.931\n",
      "[63]\tvalid_0's tweedie: 819.932\n",
      "[64]\tvalid_0's tweedie: 819.928\n",
      "[65]\tvalid_0's tweedie: 819.925\n",
      "[66]\tvalid_0's tweedie: 819.924\n",
      "[67]\tvalid_0's tweedie: 819.918\n",
      "[68]\tvalid_0's tweedie: 819.919\n",
      "[69]\tvalid_0's tweedie: 819.902\n",
      "[70]\tvalid_0's tweedie: 819.899\n",
      "[71]\tvalid_0's tweedie: 819.9\n",
      "[72]\tvalid_0's tweedie: 819.898\n",
      "[73]\tvalid_0's tweedie: 819.894\n",
      "[74]\tvalid_0's tweedie: 819.894\n",
      "[75]\tvalid_0's tweedie: 819.89\n",
      "[76]\tvalid_0's tweedie: 819.884\n",
      "[77]\tvalid_0's tweedie: 819.883\n",
      "[78]\tvalid_0's tweedie: 819.879\n",
      "[79]\tvalid_0's tweedie: 819.881\n",
      "[80]\tvalid_0's tweedie: 819.88\n",
      "[81]\tvalid_0's tweedie: 819.881\n",
      "[82]\tvalid_0's tweedie: 819.878\n",
      "[83]\tvalid_0's tweedie: 819.878\n",
      "[84]\tvalid_0's tweedie: 819.875\n",
      "[85]\tvalid_0's tweedie: 819.869\n",
      "[86]\tvalid_0's tweedie: 819.866\n",
      "[87]\tvalid_0's tweedie: 819.867\n",
      "[88]\tvalid_0's tweedie: 819.866\n",
      "[89]\tvalid_0's tweedie: 819.866\n",
      "[90]\tvalid_0's tweedie: 819.867\n",
      "[91]\tvalid_0's tweedie: 819.866\n",
      "[92]\tvalid_0's tweedie: 819.864\n",
      "[93]\tvalid_0's tweedie: 819.86\n",
      "[94]\tvalid_0's tweedie: 819.864\n",
      "[95]\tvalid_0's tweedie: 819.863\n",
      "[96]\tvalid_0's tweedie: 819.862\n",
      "[97]\tvalid_0's tweedie: 819.862\n",
      "[98]\tvalid_0's tweedie: 819.862\n",
      "[99]\tvalid_0's tweedie: 819.861\n",
      "[100]\tvalid_0's tweedie: 819.862\n",
      "[101]\tvalid_0's tweedie: 819.861\n",
      "[102]\tvalid_0's tweedie: 819.852\n",
      "[103]\tvalid_0's tweedie: 819.851\n",
      "[104]\tvalid_0's tweedie: 819.846\n",
      "[105]\tvalid_0's tweedie: 819.843\n",
      "[106]\tvalid_0's tweedie: 819.844\n",
      "[107]\tvalid_0's tweedie: 819.842\n",
      "[108]\tvalid_0's tweedie: 819.84\n",
      "[109]\tvalid_0's tweedie: 819.841\n",
      "[110]\tvalid_0's tweedie: 819.841\n",
      "[111]\tvalid_0's tweedie: 819.841\n",
      "[112]\tvalid_0's tweedie: 819.841\n",
      "[113]\tvalid_0's tweedie: 819.841\n",
      "[114]\tvalid_0's tweedie: 819.839\n",
      "[115]\tvalid_0's tweedie: 819.839\n",
      "[116]\tvalid_0's tweedie: 819.838\n",
      "[117]\tvalid_0's tweedie: 819.839\n",
      "[118]\tvalid_0's tweedie: 819.838\n",
      "[119]\tvalid_0's tweedie: 819.839\n",
      "[120]\tvalid_0's tweedie: 819.84\n",
      "[121]\tvalid_0's tweedie: 819.843\n",
      "[122]\tvalid_0's tweedie: 819.842\n",
      "[123]\tvalid_0's tweedie: 819.842\n",
      "[124]\tvalid_0's tweedie: 819.842\n",
      "[125]\tvalid_0's tweedie: 819.843\n",
      "[126]\tvalid_0's tweedie: 819.843\n",
      "[127]\tvalid_0's tweedie: 819.841\n",
      "[128]\tvalid_0's tweedie: 819.841\n",
      "[129]\tvalid_0's tweedie: 819.84\n",
      "[130]\tvalid_0's tweedie: 819.839\n",
      "[131]\tvalid_0's tweedie: 819.839\n",
      "[132]\tvalid_0's tweedie: 819.839\n",
      "[133]\tvalid_0's tweedie: 819.838\n",
      "[134]\tvalid_0's tweedie: 819.838\n",
      "[135]\tvalid_0's tweedie: 819.838\n",
      "[136]\tvalid_0's tweedie: 819.838\n",
      "[137]\tvalid_0's tweedie: 819.838\n",
      "[138]\tvalid_0's tweedie: 819.838\n",
      "[139]\tvalid_0's tweedie: 819.837\n",
      "[140]\tvalid_0's tweedie: 819.836\n",
      "[141]\tvalid_0's tweedie: 819.837\n",
      "[142]\tvalid_0's tweedie: 819.835\n",
      "[143]\tvalid_0's tweedie: 819.835\n",
      "[144]\tvalid_0's tweedie: 819.835\n",
      "[145]\tvalid_0's tweedie: 819.835\n",
      "[146]\tvalid_0's tweedie: 819.833\n",
      "[147]\tvalid_0's tweedie: 819.832\n",
      "[148]\tvalid_0's tweedie: 819.831\n",
      "[149]\tvalid_0's tweedie: 819.831\n",
      "[150]\tvalid_0's tweedie: 819.832\n",
      "[151]\tvalid_0's tweedie: 819.833\n",
      "[152]\tvalid_0's tweedie: 819.833\n",
      "[153]\tvalid_0's tweedie: 819.833\n",
      "[154]\tvalid_0's tweedie: 819.832\n",
      "[155]\tvalid_0's tweedie: 819.831\n",
      "[156]\tvalid_0's tweedie: 819.83\n",
      "[157]\tvalid_0's tweedie: 819.831\n",
      "[158]\tvalid_0's tweedie: 819.832\n",
      "[159]\tvalid_0's tweedie: 819.83\n",
      "[160]\tvalid_0's tweedie: 819.831\n",
      "[161]\tvalid_0's tweedie: 819.831\n",
      "[162]\tvalid_0's tweedie: 819.831\n",
      "[163]\tvalid_0's tweedie: 819.831\n",
      "[164]\tvalid_0's tweedie: 819.833\n",
      "[165]\tvalid_0's tweedie: 819.833\n",
      "[166]\tvalid_0's tweedie: 819.833\n",
      "[167]\tvalid_0's tweedie: 819.833\n",
      "[168]\tvalid_0's tweedie: 819.83\n",
      "[169]\tvalid_0's tweedie: 819.829\n",
      "[170]\tvalid_0's tweedie: 819.829\n",
      "[171]\tvalid_0's tweedie: 819.829\n",
      "[172]\tvalid_0's tweedie: 819.829\n",
      "[173]\tvalid_0's tweedie: 819.829\n",
      "[174]\tvalid_0's tweedie: 819.828\n",
      "[175]\tvalid_0's tweedie: 819.83\n",
      "[176]\tvalid_0's tweedie: 819.83\n",
      "[177]\tvalid_0's tweedie: 819.83\n",
      "[178]\tvalid_0's tweedie: 819.831\n",
      "[179]\tvalid_0's tweedie: 819.832\n",
      "[180]\tvalid_0's tweedie: 819.833\n",
      "[181]\tvalid_0's tweedie: 819.832\n",
      "[182]\tvalid_0's tweedie: 819.832\n",
      "[183]\tvalid_0's tweedie: 819.832\n",
      "[184]\tvalid_0's tweedie: 819.832\n",
      "[185]\tvalid_0's tweedie: 819.833\n",
      "[186]\tvalid_0's tweedie: 819.832\n",
      "[187]\tvalid_0's tweedie: 819.831\n",
      "[188]\tvalid_0's tweedie: 819.832\n",
      "[189]\tvalid_0's tweedie: 819.831\n",
      "[190]\tvalid_0's tweedie: 819.833\n",
      "[191]\tvalid_0's tweedie: 819.832\n",
      "[192]\tvalid_0's tweedie: 819.831\n",
      "[193]\tvalid_0's tweedie: 819.832\n",
      "[194]\tvalid_0's tweedie: 819.832\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's tweedie: 819.828\n",
      "Training model for level 1 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1862, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443191\n",
      "[1]\tvalid_0's tweedie: 825.924\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.118\n",
      "[3]\tvalid_0's tweedie: 824.457\n",
      "[4]\tvalid_0's tweedie: 823.914\n",
      "[5]\tvalid_0's tweedie: 823.531\n",
      "[6]\tvalid_0's tweedie: 823.11\n",
      "[7]\tvalid_0's tweedie: 822.749\n",
      "[8]\tvalid_0's tweedie: 822.492\n",
      "[9]\tvalid_0's tweedie: 822.169\n",
      "[10]\tvalid_0's tweedie: 821.869\n",
      "[11]\tvalid_0's tweedie: 821.633\n",
      "[12]\tvalid_0's tweedie: 821.524\n",
      "[13]\tvalid_0's tweedie: 821.366\n",
      "[14]\tvalid_0's tweedie: 821.238\n",
      "[15]\tvalid_0's tweedie: 821.115\n",
      "[16]\tvalid_0's tweedie: 820.997\n",
      "[17]\tvalid_0's tweedie: 820.917\n",
      "[18]\tvalid_0's tweedie: 820.824\n",
      "[19]\tvalid_0's tweedie: 820.749\n",
      "[20]\tvalid_0's tweedie: 820.714\n",
      "[21]\tvalid_0's tweedie: 820.671\n",
      "[22]\tvalid_0's tweedie: 820.616\n",
      "[23]\tvalid_0's tweedie: 820.582\n",
      "[24]\tvalid_0's tweedie: 820.541\n",
      "[25]\tvalid_0's tweedie: 820.495\n",
      "[26]\tvalid_0's tweedie: 820.465\n",
      "[27]\tvalid_0's tweedie: 820.467\n",
      "[28]\tvalid_0's tweedie: 820.425\n",
      "[29]\tvalid_0's tweedie: 820.4\n",
      "[30]\tvalid_0's tweedie: 820.38\n",
      "[31]\tvalid_0's tweedie: 820.353\n",
      "[32]\tvalid_0's tweedie: 820.331\n",
      "[33]\tvalid_0's tweedie: 820.317\n",
      "[34]\tvalid_0's tweedie: 820.298\n",
      "[35]\tvalid_0's tweedie: 820.286\n",
      "[36]\tvalid_0's tweedie: 820.262\n",
      "[37]\tvalid_0's tweedie: 820.228\n",
      "[38]\tvalid_0's tweedie: 820.21\n",
      "[39]\tvalid_0's tweedie: 820.203\n",
      "[40]\tvalid_0's tweedie: 820.19\n",
      "[41]\tvalid_0's tweedie: 820.191\n",
      "[42]\tvalid_0's tweedie: 820.156\n",
      "[43]\tvalid_0's tweedie: 820.128\n",
      "[44]\tvalid_0's tweedie: 820.109\n",
      "[45]\tvalid_0's tweedie: 820.098\n",
      "[46]\tvalid_0's tweedie: 820.088\n",
      "[47]\tvalid_0's tweedie: 820.086\n",
      "[48]\tvalid_0's tweedie: 820.084\n",
      "[49]\tvalid_0's tweedie: 820.069\n",
      "[50]\tvalid_0's tweedie: 820.056\n",
      "[51]\tvalid_0's tweedie: 820.051\n",
      "[52]\tvalid_0's tweedie: 820.04\n",
      "[53]\tvalid_0's tweedie: 820.035\n",
      "[54]\tvalid_0's tweedie: 820.02\n",
      "[55]\tvalid_0's tweedie: 820.008\n",
      "[56]\tvalid_0's tweedie: 820.002\n",
      "[57]\tvalid_0's tweedie: 819.994\n",
      "[58]\tvalid_0's tweedie: 819.991\n",
      "[59]\tvalid_0's tweedie: 819.981\n",
      "[60]\tvalid_0's tweedie: 819.979\n",
      "[61]\tvalid_0's tweedie: 819.98\n",
      "[62]\tvalid_0's tweedie: 819.977\n",
      "[63]\tvalid_0's tweedie: 819.976\n",
      "[64]\tvalid_0's tweedie: 819.971\n",
      "[65]\tvalid_0's tweedie: 819.972\n",
      "[66]\tvalid_0's tweedie: 819.972\n",
      "[67]\tvalid_0's tweedie: 819.971\n",
      "[68]\tvalid_0's tweedie: 819.965\n",
      "[69]\tvalid_0's tweedie: 819.962\n",
      "[70]\tvalid_0's tweedie: 819.961\n",
      "[71]\tvalid_0's tweedie: 819.961\n",
      "[72]\tvalid_0's tweedie: 819.961\n",
      "[73]\tvalid_0's tweedie: 819.957\n",
      "[74]\tvalid_0's tweedie: 819.954\n",
      "[75]\tvalid_0's tweedie: 819.956\n",
      "[76]\tvalid_0's tweedie: 819.955\n",
      "[77]\tvalid_0's tweedie: 819.948\n",
      "[78]\tvalid_0's tweedie: 819.944\n",
      "[79]\tvalid_0's tweedie: 819.947\n",
      "[80]\tvalid_0's tweedie: 819.943\n",
      "[81]\tvalid_0's tweedie: 819.944\n",
      "[82]\tvalid_0's tweedie: 819.944\n",
      "[83]\tvalid_0's tweedie: 819.944\n",
      "[84]\tvalid_0's tweedie: 819.944\n",
      "[85]\tvalid_0's tweedie: 819.945\n",
      "[86]\tvalid_0's tweedie: 819.947\n",
      "[87]\tvalid_0's tweedie: 819.948\n",
      "[88]\tvalid_0's tweedie: 819.948\n",
      "[89]\tvalid_0's tweedie: 819.948\n",
      "[90]\tvalid_0's tweedie: 819.947\n",
      "[91]\tvalid_0's tweedie: 819.946\n",
      "[92]\tvalid_0's tweedie: 819.943\n",
      "[93]\tvalid_0's tweedie: 819.941\n",
      "[94]\tvalid_0's tweedie: 819.938\n",
      "[95]\tvalid_0's tweedie: 819.931\n",
      "[96]\tvalid_0's tweedie: 819.931\n",
      "[97]\tvalid_0's tweedie: 819.93\n",
      "[98]\tvalid_0's tweedie: 819.93\n",
      "[99]\tvalid_0's tweedie: 819.93\n",
      "[100]\tvalid_0's tweedie: 819.929\n",
      "[101]\tvalid_0's tweedie: 819.93\n",
      "[102]\tvalid_0's tweedie: 819.926\n",
      "[103]\tvalid_0's tweedie: 819.927\n",
      "[104]\tvalid_0's tweedie: 819.926\n",
      "[105]\tvalid_0's tweedie: 819.926\n",
      "[106]\tvalid_0's tweedie: 819.925\n",
      "[107]\tvalid_0's tweedie: 819.924\n",
      "[108]\tvalid_0's tweedie: 819.924\n",
      "[109]\tvalid_0's tweedie: 819.923\n",
      "[110]\tvalid_0's tweedie: 819.922\n",
      "[111]\tvalid_0's tweedie: 819.923\n",
      "[112]\tvalid_0's tweedie: 819.92\n",
      "[113]\tvalid_0's tweedie: 819.921\n",
      "[114]\tvalid_0's tweedie: 819.92\n",
      "[115]\tvalid_0's tweedie: 819.915\n",
      "[116]\tvalid_0's tweedie: 819.916\n",
      "[117]\tvalid_0's tweedie: 819.919\n",
      "[118]\tvalid_0's tweedie: 819.917\n",
      "[119]\tvalid_0's tweedie: 819.916\n",
      "[120]\tvalid_0's tweedie: 819.915\n",
      "[121]\tvalid_0's tweedie: 819.915\n",
      "[122]\tvalid_0's tweedie: 819.915\n",
      "[123]\tvalid_0's tweedie: 819.915\n",
      "[124]\tvalid_0's tweedie: 819.914\n",
      "[125]\tvalid_0's tweedie: 819.912\n",
      "[126]\tvalid_0's tweedie: 819.912\n",
      "[127]\tvalid_0's tweedie: 819.911\n",
      "[128]\tvalid_0's tweedie: 819.909\n",
      "[129]\tvalid_0's tweedie: 819.909\n",
      "[130]\tvalid_0's tweedie: 819.909\n",
      "[131]\tvalid_0's tweedie: 819.909\n",
      "[132]\tvalid_0's tweedie: 819.909\n",
      "[133]\tvalid_0's tweedie: 819.909\n",
      "[134]\tvalid_0's tweedie: 819.911\n",
      "[135]\tvalid_0's tweedie: 819.91\n",
      "[136]\tvalid_0's tweedie: 819.911\n",
      "[137]\tvalid_0's tweedie: 819.912\n",
      "[138]\tvalid_0's tweedie: 819.912\n",
      "[139]\tvalid_0's tweedie: 819.912\n",
      "[140]\tvalid_0's tweedie: 819.91\n",
      "[141]\tvalid_0's tweedie: 819.916\n",
      "[142]\tvalid_0's tweedie: 819.914\n",
      "[143]\tvalid_0's tweedie: 819.915\n",
      "[144]\tvalid_0's tweedie: 819.913\n",
      "[145]\tvalid_0's tweedie: 819.913\n",
      "[146]\tvalid_0's tweedie: 819.913\n",
      "[147]\tvalid_0's tweedie: 819.913\n",
      "[148]\tvalid_0's tweedie: 819.912\n",
      "[149]\tvalid_0's tweedie: 819.914\n",
      "[150]\tvalid_0's tweedie: 819.913\n",
      "[151]\tvalid_0's tweedie: 819.908\n",
      "[152]\tvalid_0's tweedie: 819.908\n",
      "[153]\tvalid_0's tweedie: 819.908\n",
      "[154]\tvalid_0's tweedie: 819.91\n",
      "[155]\tvalid_0's tweedie: 819.911\n",
      "[156]\tvalid_0's tweedie: 819.908\n",
      "[157]\tvalid_0's tweedie: 819.907\n",
      "[158]\tvalid_0's tweedie: 819.907\n",
      "[159]\tvalid_0's tweedie: 819.907\n",
      "[160]\tvalid_0's tweedie: 819.907\n",
      "[161]\tvalid_0's tweedie: 819.906\n",
      "[162]\tvalid_0's tweedie: 819.905\n",
      "[163]\tvalid_0's tweedie: 819.904\n",
      "[164]\tvalid_0's tweedie: 819.904\n",
      "[165]\tvalid_0's tweedie: 819.903\n",
      "[166]\tvalid_0's tweedie: 819.903\n",
      "[167]\tvalid_0's tweedie: 819.902\n",
      "[168]\tvalid_0's tweedie: 819.901\n",
      "[169]\tvalid_0's tweedie: 819.902\n",
      "[170]\tvalid_0's tweedie: 819.905\n",
      "[171]\tvalid_0's tweedie: 819.905\n",
      "[172]\tvalid_0's tweedie: 819.905\n",
      "[173]\tvalid_0's tweedie: 819.905\n",
      "[174]\tvalid_0's tweedie: 819.905\n",
      "[175]\tvalid_0's tweedie: 819.904\n",
      "[176]\tvalid_0's tweedie: 819.904\n",
      "[177]\tvalid_0's tweedie: 819.904\n",
      "[178]\tvalid_0's tweedie: 819.904\n",
      "[179]\tvalid_0's tweedie: 819.905\n",
      "[180]\tvalid_0's tweedie: 819.905\n",
      "[181]\tvalid_0's tweedie: 819.905\n",
      "[182]\tvalid_0's tweedie: 819.904\n",
      "[183]\tvalid_0's tweedie: 819.904\n",
      "[184]\tvalid_0's tweedie: 819.903\n",
      "[185]\tvalid_0's tweedie: 819.903\n",
      "[186]\tvalid_0's tweedie: 819.903\n",
      "[187]\tvalid_0's tweedie: 819.903\n",
      "[188]\tvalid_0's tweedie: 819.903\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's tweedie: 819.901\n",
      "Training model for level 1 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1861, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443353\n",
      "[1]\tvalid_0's tweedie: 825.916\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.11\n",
      "[3]\tvalid_0's tweedie: 824.3\n",
      "[4]\tvalid_0's tweedie: 823.764\n",
      "[5]\tvalid_0's tweedie: 823.297\n",
      "[6]\tvalid_0's tweedie: 822.986\n",
      "[7]\tvalid_0's tweedie: 822.593\n",
      "[8]\tvalid_0's tweedie: 822.267\n",
      "[9]\tvalid_0's tweedie: 821.974\n",
      "[10]\tvalid_0's tweedie: 821.746\n",
      "[11]\tvalid_0's tweedie: 821.561\n",
      "[12]\tvalid_0's tweedie: 821.423\n",
      "[13]\tvalid_0's tweedie: 821.259\n",
      "[14]\tvalid_0's tweedie: 821.126\n",
      "[15]\tvalid_0's tweedie: 821.093\n",
      "[16]\tvalid_0's tweedie: 821.024\n",
      "[17]\tvalid_0's tweedie: 820.988\n",
      "[18]\tvalid_0's tweedie: 820.929\n",
      "[19]\tvalid_0's tweedie: 820.894\n",
      "[20]\tvalid_0's tweedie: 820.832\n",
      "[21]\tvalid_0's tweedie: 820.756\n",
      "[22]\tvalid_0's tweedie: 820.708\n",
      "[23]\tvalid_0's tweedie: 820.657\n",
      "[24]\tvalid_0's tweedie: 820.62\n",
      "[25]\tvalid_0's tweedie: 820.611\n",
      "[26]\tvalid_0's tweedie: 820.554\n",
      "[27]\tvalid_0's tweedie: 820.516\n",
      "[28]\tvalid_0's tweedie: 820.478\n",
      "[29]\tvalid_0's tweedie: 820.451\n",
      "[30]\tvalid_0's tweedie: 820.416\n",
      "[31]\tvalid_0's tweedie: 820.393\n",
      "[32]\tvalid_0's tweedie: 820.376\n",
      "[33]\tvalid_0's tweedie: 820.363\n",
      "[34]\tvalid_0's tweedie: 820.333\n",
      "[35]\tvalid_0's tweedie: 820.306\n",
      "[36]\tvalid_0's tweedie: 820.285\n",
      "[37]\tvalid_0's tweedie: 820.258\n",
      "[38]\tvalid_0's tweedie: 820.245\n",
      "[39]\tvalid_0's tweedie: 820.248\n",
      "[40]\tvalid_0's tweedie: 820.234\n",
      "[41]\tvalid_0's tweedie: 820.217\n",
      "[42]\tvalid_0's tweedie: 820.18\n",
      "[43]\tvalid_0's tweedie: 820.168\n",
      "[44]\tvalid_0's tweedie: 820.161\n",
      "[45]\tvalid_0's tweedie: 820.151\n",
      "[46]\tvalid_0's tweedie: 820.14\n",
      "[47]\tvalid_0's tweedie: 820.141\n",
      "[48]\tvalid_0's tweedie: 820.123\n",
      "[49]\tvalid_0's tweedie: 820.117\n",
      "[50]\tvalid_0's tweedie: 820.113\n",
      "[51]\tvalid_0's tweedie: 820.1\n",
      "[52]\tvalid_0's tweedie: 820.089\n",
      "[53]\tvalid_0's tweedie: 820.086\n",
      "[54]\tvalid_0's tweedie: 820.083\n",
      "[55]\tvalid_0's tweedie: 820.076\n",
      "[56]\tvalid_0's tweedie: 820.065\n",
      "[57]\tvalid_0's tweedie: 820.063\n",
      "[58]\tvalid_0's tweedie: 820.054\n",
      "[59]\tvalid_0's tweedie: 820.05\n",
      "[60]\tvalid_0's tweedie: 820.06\n",
      "[61]\tvalid_0's tweedie: 820.056\n",
      "[62]\tvalid_0's tweedie: 820.052\n",
      "[63]\tvalid_0's tweedie: 820.047\n",
      "[64]\tvalid_0's tweedie: 820.045\n",
      "[65]\tvalid_0's tweedie: 820.042\n",
      "[66]\tvalid_0's tweedie: 820.04\n",
      "[67]\tvalid_0's tweedie: 820.041\n",
      "[68]\tvalid_0's tweedie: 820.034\n",
      "[69]\tvalid_0's tweedie: 820.031\n",
      "[70]\tvalid_0's tweedie: 820.029\n",
      "[71]\tvalid_0's tweedie: 820.029\n",
      "[72]\tvalid_0's tweedie: 820.038\n",
      "[73]\tvalid_0's tweedie: 820.04\n",
      "[74]\tvalid_0's tweedie: 820.038\n",
      "[75]\tvalid_0's tweedie: 820.035\n",
      "[76]\tvalid_0's tweedie: 820.034\n",
      "[77]\tvalid_0's tweedie: 820.027\n",
      "[78]\tvalid_0's tweedie: 820.018\n",
      "[79]\tvalid_0's tweedie: 820.014\n",
      "[80]\tvalid_0's tweedie: 820.011\n",
      "[81]\tvalid_0's tweedie: 820.011\n",
      "[82]\tvalid_0's tweedie: 820.009\n",
      "[83]\tvalid_0's tweedie: 820.01\n",
      "[84]\tvalid_0's tweedie: 820.002\n",
      "[85]\tvalid_0's tweedie: 820.001\n",
      "[86]\tvalid_0's tweedie: 820.002\n",
      "[87]\tvalid_0's tweedie: 820.002\n",
      "[88]\tvalid_0's tweedie: 820.001\n",
      "[89]\tvalid_0's tweedie: 819.993\n",
      "[90]\tvalid_0's tweedie: 819.993\n",
      "[91]\tvalid_0's tweedie: 819.99\n",
      "[92]\tvalid_0's tweedie: 819.987\n",
      "[93]\tvalid_0's tweedie: 819.988\n",
      "[94]\tvalid_0's tweedie: 819.987\n",
      "[95]\tvalid_0's tweedie: 819.987\n",
      "[96]\tvalid_0's tweedie: 819.985\n",
      "[97]\tvalid_0's tweedie: 819.984\n",
      "[98]\tvalid_0's tweedie: 819.984\n",
      "[99]\tvalid_0's tweedie: 819.985\n",
      "[100]\tvalid_0's tweedie: 819.985\n",
      "[101]\tvalid_0's tweedie: 819.985\n",
      "[102]\tvalid_0's tweedie: 819.984\n",
      "[103]\tvalid_0's tweedie: 819.992\n",
      "[104]\tvalid_0's tweedie: 819.997\n",
      "[105]\tvalid_0's tweedie: 819.997\n",
      "[106]\tvalid_0's tweedie: 820.003\n",
      "[107]\tvalid_0's tweedie: 820.003\n",
      "[108]\tvalid_0's tweedie: 820.002\n",
      "[109]\tvalid_0's tweedie: 819.999\n",
      "[110]\tvalid_0's tweedie: 819.999\n",
      "[111]\tvalid_0's tweedie: 820.007\n",
      "[112]\tvalid_0's tweedie: 820.008\n",
      "[113]\tvalid_0's tweedie: 820.01\n",
      "[114]\tvalid_0's tweedie: 820.01\n",
      "[115]\tvalid_0's tweedie: 820.01\n",
      "[116]\tvalid_0's tweedie: 820.008\n",
      "[117]\tvalid_0's tweedie: 820.013\n",
      "[118]\tvalid_0's tweedie: 820.014\n",
      "[119]\tvalid_0's tweedie: 820.014\n",
      "[120]\tvalid_0's tweedie: 820.015\n",
      "[121]\tvalid_0's tweedie: 820.016\n",
      "[122]\tvalid_0's tweedie: 820.014\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's tweedie: 819.984\n",
      "Training model for level 1 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443569\n",
      "[1]\tvalid_0's tweedie: 826.107\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.258\n",
      "[3]\tvalid_0's tweedie: 824.487\n",
      "[4]\tvalid_0's tweedie: 823.915\n",
      "[5]\tvalid_0's tweedie: 823.431\n",
      "[6]\tvalid_0's tweedie: 823.017\n",
      "[7]\tvalid_0's tweedie: 822.652\n",
      "[8]\tvalid_0's tweedie: 822.317\n",
      "[9]\tvalid_0's tweedie: 822.117\n",
      "[10]\tvalid_0's tweedie: 821.862\n",
      "[11]\tvalid_0's tweedie: 821.649\n",
      "[12]\tvalid_0's tweedie: 821.534\n",
      "[13]\tvalid_0's tweedie: 821.379\n",
      "[14]\tvalid_0's tweedie: 821.233\n",
      "[15]\tvalid_0's tweedie: 821.158\n",
      "[16]\tvalid_0's tweedie: 821.046\n",
      "[17]\tvalid_0's tweedie: 820.945\n",
      "[18]\tvalid_0's tweedie: 820.889\n",
      "[19]\tvalid_0's tweedie: 820.809\n",
      "[20]\tvalid_0's tweedie: 820.771\n",
      "[21]\tvalid_0's tweedie: 820.726\n",
      "[22]\tvalid_0's tweedie: 820.665\n",
      "[23]\tvalid_0's tweedie: 820.602\n",
      "[24]\tvalid_0's tweedie: 820.608\n",
      "[25]\tvalid_0's tweedie: 820.576\n",
      "[26]\tvalid_0's tweedie: 820.52\n",
      "[27]\tvalid_0's tweedie: 820.465\n",
      "[28]\tvalid_0's tweedie: 820.438\n",
      "[29]\tvalid_0's tweedie: 820.403\n",
      "[30]\tvalid_0's tweedie: 820.419\n",
      "[31]\tvalid_0's tweedie: 820.394\n",
      "[32]\tvalid_0's tweedie: 820.369\n",
      "[33]\tvalid_0's tweedie: 820.366\n",
      "[34]\tvalid_0's tweedie: 820.347\n",
      "[35]\tvalid_0's tweedie: 820.336\n",
      "[36]\tvalid_0's tweedie: 820.303\n",
      "[37]\tvalid_0's tweedie: 820.282\n",
      "[38]\tvalid_0's tweedie: 820.26\n",
      "[39]\tvalid_0's tweedie: 820.244\n",
      "[40]\tvalid_0's tweedie: 820.238\n",
      "[41]\tvalid_0's tweedie: 820.226\n",
      "[42]\tvalid_0's tweedie: 820.226\n",
      "[43]\tvalid_0's tweedie: 820.221\n",
      "[44]\tvalid_0's tweedie: 820.218\n",
      "[45]\tvalid_0's tweedie: 820.201\n",
      "[46]\tvalid_0's tweedie: 820.177\n",
      "[47]\tvalid_0's tweedie: 820.159\n",
      "[48]\tvalid_0's tweedie: 820.153\n",
      "[49]\tvalid_0's tweedie: 820.142\n",
      "[50]\tvalid_0's tweedie: 820.133\n",
      "[51]\tvalid_0's tweedie: 820.132\n",
      "[52]\tvalid_0's tweedie: 820.128\n",
      "[53]\tvalid_0's tweedie: 820.12\n",
      "[54]\tvalid_0's tweedie: 820.112\n",
      "[55]\tvalid_0's tweedie: 820.102\n",
      "[56]\tvalid_0's tweedie: 820.086\n",
      "[57]\tvalid_0's tweedie: 820.083\n",
      "[58]\tvalid_0's tweedie: 820.075\n",
      "[59]\tvalid_0's tweedie: 820.068\n",
      "[60]\tvalid_0's tweedie: 820.06\n",
      "[61]\tvalid_0's tweedie: 820.052\n",
      "[62]\tvalid_0's tweedie: 820.048\n",
      "[63]\tvalid_0's tweedie: 820.04\n",
      "[64]\tvalid_0's tweedie: 820.039\n",
      "[65]\tvalid_0's tweedie: 820.029\n",
      "[66]\tvalid_0's tweedie: 820.022\n",
      "[67]\tvalid_0's tweedie: 820.021\n",
      "[68]\tvalid_0's tweedie: 820.018\n",
      "[69]\tvalid_0's tweedie: 820.009\n",
      "[70]\tvalid_0's tweedie: 820.012\n",
      "[71]\tvalid_0's tweedie: 820.01\n",
      "[72]\tvalid_0's tweedie: 820.008\n",
      "[73]\tvalid_0's tweedie: 820.002\n",
      "[74]\tvalid_0's tweedie: 820.002\n",
      "[75]\tvalid_0's tweedie: 819.998\n",
      "[76]\tvalid_0's tweedie: 820.003\n",
      "[77]\tvalid_0's tweedie: 820.002\n",
      "[78]\tvalid_0's tweedie: 819.998\n",
      "[79]\tvalid_0's tweedie: 819.992\n",
      "[80]\tvalid_0's tweedie: 819.992\n",
      "[81]\tvalid_0's tweedie: 819.992\n",
      "[82]\tvalid_0's tweedie: 819.991\n",
      "[83]\tvalid_0's tweedie: 819.992\n",
      "[84]\tvalid_0's tweedie: 819.993\n",
      "[85]\tvalid_0's tweedie: 820.002\n",
      "[86]\tvalid_0's tweedie: 819.997\n",
      "[87]\tvalid_0's tweedie: 819.997\n",
      "[88]\tvalid_0's tweedie: 819.991\n",
      "[89]\tvalid_0's tweedie: 819.99\n",
      "[90]\tvalid_0's tweedie: 819.99\n",
      "[91]\tvalid_0's tweedie: 819.99\n",
      "[92]\tvalid_0's tweedie: 819.987\n",
      "[93]\tvalid_0's tweedie: 819.986\n",
      "[94]\tvalid_0's tweedie: 819.986\n",
      "[95]\tvalid_0's tweedie: 819.985\n",
      "[96]\tvalid_0's tweedie: 819.986\n",
      "[97]\tvalid_0's tweedie: 819.985\n",
      "[98]\tvalid_0's tweedie: 819.987\n",
      "[99]\tvalid_0's tweedie: 819.981\n",
      "[100]\tvalid_0's tweedie: 819.981\n",
      "[101]\tvalid_0's tweedie: 819.981\n",
      "[102]\tvalid_0's tweedie: 819.98\n",
      "[103]\tvalid_0's tweedie: 819.981\n",
      "[104]\tvalid_0's tweedie: 819.983\n",
      "[105]\tvalid_0's tweedie: 819.98\n",
      "[106]\tvalid_0's tweedie: 819.981\n",
      "[107]\tvalid_0's tweedie: 819.979\n",
      "[108]\tvalid_0's tweedie: 819.983\n",
      "[109]\tvalid_0's tweedie: 819.981\n",
      "[110]\tvalid_0's tweedie: 819.98\n",
      "[111]\tvalid_0's tweedie: 819.98\n",
      "[112]\tvalid_0's tweedie: 819.974\n",
      "[113]\tvalid_0's tweedie: 819.973\n",
      "[114]\tvalid_0's tweedie: 819.972\n",
      "[115]\tvalid_0's tweedie: 819.971\n",
      "[116]\tvalid_0's tweedie: 819.972\n",
      "[117]\tvalid_0's tweedie: 819.974\n",
      "[118]\tvalid_0's tweedie: 819.972\n",
      "[119]\tvalid_0's tweedie: 819.972\n",
      "[120]\tvalid_0's tweedie: 819.974\n",
      "[121]\tvalid_0's tweedie: 819.974\n",
      "[122]\tvalid_0's tweedie: 819.976\n",
      "[123]\tvalid_0's tweedie: 819.976\n",
      "[124]\tvalid_0's tweedie: 819.978\n",
      "[125]\tvalid_0's tweedie: 819.976\n",
      "[126]\tvalid_0's tweedie: 819.976\n",
      "[127]\tvalid_0's tweedie: 819.979\n",
      "[128]\tvalid_0's tweedie: 819.979\n",
      "[129]\tvalid_0's tweedie: 819.976\n",
      "[130]\tvalid_0's tweedie: 819.977\n",
      "[131]\tvalid_0's tweedie: 819.985\n",
      "[132]\tvalid_0's tweedie: 819.983\n",
      "[133]\tvalid_0's tweedie: 819.984\n",
      "[134]\tvalid_0's tweedie: 819.983\n",
      "[135]\tvalid_0's tweedie: 819.981\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's tweedie: 819.971\n",
      "Training model for level 1 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1859, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.443782\n",
      "[1]\tvalid_0's tweedie: 826.098\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.28\n",
      "[3]\tvalid_0's tweedie: 824.49\n",
      "[4]\tvalid_0's tweedie: 824.075\n",
      "[5]\tvalid_0's tweedie: 823.485\n",
      "[6]\tvalid_0's tweedie: 823.019\n",
      "[7]\tvalid_0's tweedie: 822.647\n",
      "[8]\tvalid_0's tweedie: 822.408\n",
      "[9]\tvalid_0's tweedie: 822.142\n",
      "[10]\tvalid_0's tweedie: 821.912\n",
      "[11]\tvalid_0's tweedie: 821.7\n",
      "[12]\tvalid_0's tweedie: 821.556\n",
      "[13]\tvalid_0's tweedie: 821.394\n",
      "[14]\tvalid_0's tweedie: 821.259\n",
      "[15]\tvalid_0's tweedie: 821.128\n",
      "[16]\tvalid_0's tweedie: 821.008\n",
      "[17]\tvalid_0's tweedie: 820.915\n",
      "[18]\tvalid_0's tweedie: 820.87\n",
      "[19]\tvalid_0's tweedie: 820.797\n",
      "[20]\tvalid_0's tweedie: 820.759\n",
      "[21]\tvalid_0's tweedie: 820.727\n",
      "[22]\tvalid_0's tweedie: 820.671\n",
      "[23]\tvalid_0's tweedie: 820.632\n",
      "[24]\tvalid_0's tweedie: 820.627\n",
      "[25]\tvalid_0's tweedie: 820.59\n",
      "[26]\tvalid_0's tweedie: 820.547\n",
      "[27]\tvalid_0's tweedie: 820.501\n",
      "[28]\tvalid_0's tweedie: 820.469\n",
      "[29]\tvalid_0's tweedie: 820.431\n",
      "[30]\tvalid_0's tweedie: 820.407\n",
      "[31]\tvalid_0's tweedie: 820.382\n",
      "[32]\tvalid_0's tweedie: 820.345\n",
      "[33]\tvalid_0's tweedie: 820.328\n",
      "[34]\tvalid_0's tweedie: 820.335\n",
      "[35]\tvalid_0's tweedie: 820.314\n",
      "[36]\tvalid_0's tweedie: 820.293\n",
      "[37]\tvalid_0's tweedie: 820.285\n",
      "[38]\tvalid_0's tweedie: 820.266\n",
      "[39]\tvalid_0's tweedie: 820.262\n",
      "[40]\tvalid_0's tweedie: 820.225\n",
      "[41]\tvalid_0's tweedie: 820.221\n",
      "[42]\tvalid_0's tweedie: 820.216\n",
      "[43]\tvalid_0's tweedie: 820.209\n",
      "[44]\tvalid_0's tweedie: 820.196\n",
      "[45]\tvalid_0's tweedie: 820.187\n",
      "[46]\tvalid_0's tweedie: 820.185\n",
      "[47]\tvalid_0's tweedie: 820.179\n",
      "[48]\tvalid_0's tweedie: 820.156\n",
      "[49]\tvalid_0's tweedie: 820.143\n",
      "[50]\tvalid_0's tweedie: 820.126\n",
      "[51]\tvalid_0's tweedie: 820.121\n",
      "[52]\tvalid_0's tweedie: 820.114\n",
      "[53]\tvalid_0's tweedie: 820.099\n",
      "[54]\tvalid_0's tweedie: 820.097\n",
      "[55]\tvalid_0's tweedie: 820.09\n",
      "[56]\tvalid_0's tweedie: 820.079\n",
      "[57]\tvalid_0's tweedie: 820.074\n",
      "[58]\tvalid_0's tweedie: 820.062\n",
      "[59]\tvalid_0's tweedie: 820.057\n",
      "[60]\tvalid_0's tweedie: 820.057\n",
      "[61]\tvalid_0's tweedie: 820.054\n",
      "[62]\tvalid_0's tweedie: 820.04\n",
      "[63]\tvalid_0's tweedie: 820.035\n",
      "[64]\tvalid_0's tweedie: 820.045\n",
      "[65]\tvalid_0's tweedie: 820.042\n",
      "[66]\tvalid_0's tweedie: 820.04\n",
      "[67]\tvalid_0's tweedie: 820.031\n",
      "[68]\tvalid_0's tweedie: 820.031\n",
      "[69]\tvalid_0's tweedie: 820.029\n",
      "[70]\tvalid_0's tweedie: 820.031\n",
      "[71]\tvalid_0's tweedie: 820.03\n",
      "[72]\tvalid_0's tweedie: 820.029\n",
      "[73]\tvalid_0's tweedie: 820.027\n",
      "[74]\tvalid_0's tweedie: 820.025\n",
      "[75]\tvalid_0's tweedie: 820.023\n",
      "[76]\tvalid_0's tweedie: 820.028\n",
      "[77]\tvalid_0's tweedie: 820.028\n",
      "[78]\tvalid_0's tweedie: 820.03\n",
      "[79]\tvalid_0's tweedie: 820.034\n",
      "[80]\tvalid_0's tweedie: 820.035\n",
      "[81]\tvalid_0's tweedie: 820.027\n",
      "[82]\tvalid_0's tweedie: 820.03\n",
      "[83]\tvalid_0's tweedie: 820.028\n",
      "[84]\tvalid_0's tweedie: 820.028\n",
      "[85]\tvalid_0's tweedie: 820.031\n",
      "[86]\tvalid_0's tweedie: 820.032\n",
      "[87]\tvalid_0's tweedie: 820.024\n",
      "[88]\tvalid_0's tweedie: 820.024\n",
      "[89]\tvalid_0's tweedie: 820.024\n",
      "[90]\tvalid_0's tweedie: 820.024\n",
      "[91]\tvalid_0's tweedie: 820.024\n",
      "[92]\tvalid_0's tweedie: 820.021\n",
      "[93]\tvalid_0's tweedie: 820.02\n",
      "[94]\tvalid_0's tweedie: 820.018\n",
      "[95]\tvalid_0's tweedie: 820.019\n",
      "[96]\tvalid_0's tweedie: 820.011\n",
      "[97]\tvalid_0's tweedie: 820.011\n",
      "[98]\tvalid_0's tweedie: 820.01\n",
      "[99]\tvalid_0's tweedie: 820.009\n",
      "[100]\tvalid_0's tweedie: 820.008\n",
      "[101]\tvalid_0's tweedie: 820.007\n",
      "[102]\tvalid_0's tweedie: 820.005\n",
      "[103]\tvalid_0's tweedie: 820.007\n",
      "[104]\tvalid_0's tweedie: 820.005\n",
      "[105]\tvalid_0's tweedie: 820.005\n",
      "[106]\tvalid_0's tweedie: 820.006\n",
      "[107]\tvalid_0's tweedie: 820.005\n",
      "[108]\tvalid_0's tweedie: 820.005\n",
      "[109]\tvalid_0's tweedie: 820.003\n",
      "[110]\tvalid_0's tweedie: 820.002\n",
      "[111]\tvalid_0's tweedie: 819.998\n",
      "[112]\tvalid_0's tweedie: 819.998\n",
      "[113]\tvalid_0's tweedie: 819.993\n",
      "[114]\tvalid_0's tweedie: 819.993\n",
      "[115]\tvalid_0's tweedie: 819.993\n",
      "[116]\tvalid_0's tweedie: 819.99\n",
      "[117]\tvalid_0's tweedie: 819.988\n",
      "[118]\tvalid_0's tweedie: 819.986\n",
      "[119]\tvalid_0's tweedie: 819.985\n",
      "[120]\tvalid_0's tweedie: 819.985\n",
      "[121]\tvalid_0's tweedie: 819.985\n",
      "[122]\tvalid_0's tweedie: 819.979\n",
      "[123]\tvalid_0's tweedie: 819.978\n",
      "[124]\tvalid_0's tweedie: 819.977\n",
      "[125]\tvalid_0's tweedie: 819.977\n",
      "[126]\tvalid_0's tweedie: 819.976\n",
      "[127]\tvalid_0's tweedie: 819.971\n",
      "[128]\tvalid_0's tweedie: 819.966\n",
      "[129]\tvalid_0's tweedie: 819.966\n",
      "[130]\tvalid_0's tweedie: 819.967\n",
      "[131]\tvalid_0's tweedie: 819.967\n",
      "[132]\tvalid_0's tweedie: 819.967\n",
      "[133]\tvalid_0's tweedie: 819.965\n",
      "[134]\tvalid_0's tweedie: 819.967\n",
      "[135]\tvalid_0's tweedie: 819.967\n",
      "[136]\tvalid_0's tweedie: 819.968\n",
      "[137]\tvalid_0's tweedie: 819.969\n",
      "[138]\tvalid_0's tweedie: 819.971\n",
      "[139]\tvalid_0's tweedie: 819.971\n",
      "[140]\tvalid_0's tweedie: 819.975\n",
      "[141]\tvalid_0's tweedie: 819.976\n",
      "[142]\tvalid_0's tweedie: 819.979\n",
      "[143]\tvalid_0's tweedie: 819.978\n",
      "[144]\tvalid_0's tweedie: 819.979\n",
      "[145]\tvalid_0's tweedie: 819.979\n",
      "[146]\tvalid_0's tweedie: 819.979\n",
      "[147]\tvalid_0's tweedie: 819.976\n",
      "[148]\tvalid_0's tweedie: 819.976\n",
      "[149]\tvalid_0's tweedie: 819.98\n",
      "[150]\tvalid_0's tweedie: 819.98\n",
      "[151]\tvalid_0's tweedie: 819.98\n",
      "[152]\tvalid_0's tweedie: 819.981\n",
      "[153]\tvalid_0's tweedie: 819.981\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's tweedie: 819.965\n",
      "Training model for level 1 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1858, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444002\n",
      "[1]\tvalid_0's tweedie: 826.088\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.253\n",
      "[3]\tvalid_0's tweedie: 824.55\n",
      "[4]\tvalid_0's tweedie: 823.961\n",
      "[5]\tvalid_0's tweedie: 823.495\n",
      "[6]\tvalid_0's tweedie: 823.028\n",
      "[7]\tvalid_0's tweedie: 822.777\n",
      "[8]\tvalid_0's tweedie: 822.507\n",
      "[9]\tvalid_0's tweedie: 822.195\n",
      "[10]\tvalid_0's tweedie: 821.974\n",
      "[11]\tvalid_0's tweedie: 821.762\n",
      "[12]\tvalid_0's tweedie: 821.646\n",
      "[13]\tvalid_0's tweedie: 821.465\n",
      "[14]\tvalid_0's tweedie: 821.3\n",
      "[15]\tvalid_0's tweedie: 821.171\n",
      "[16]\tvalid_0's tweedie: 821.065\n",
      "[17]\tvalid_0's tweedie: 820.968\n",
      "[18]\tvalid_0's tweedie: 820.883\n",
      "[19]\tvalid_0's tweedie: 820.844\n",
      "[20]\tvalid_0's tweedie: 820.777\n",
      "[21]\tvalid_0's tweedie: 820.743\n",
      "[22]\tvalid_0's tweedie: 820.695\n",
      "[23]\tvalid_0's tweedie: 820.648\n",
      "[24]\tvalid_0's tweedie: 820.63\n",
      "[25]\tvalid_0's tweedie: 820.594\n",
      "[26]\tvalid_0's tweedie: 820.567\n",
      "[27]\tvalid_0's tweedie: 820.532\n",
      "[28]\tvalid_0's tweedie: 820.491\n",
      "[29]\tvalid_0's tweedie: 820.457\n",
      "[30]\tvalid_0's tweedie: 820.43\n",
      "[31]\tvalid_0's tweedie: 820.426\n",
      "[32]\tvalid_0's tweedie: 820.401\n",
      "[33]\tvalid_0's tweedie: 820.37\n",
      "[34]\tvalid_0's tweedie: 820.354\n",
      "[35]\tvalid_0's tweedie: 820.318\n",
      "[36]\tvalid_0's tweedie: 820.306\n",
      "[37]\tvalid_0's tweedie: 820.3\n",
      "[38]\tvalid_0's tweedie: 820.282\n",
      "[39]\tvalid_0's tweedie: 820.271\n",
      "[40]\tvalid_0's tweedie: 820.251\n",
      "[41]\tvalid_0's tweedie: 820.259\n",
      "[42]\tvalid_0's tweedie: 820.234\n",
      "[43]\tvalid_0's tweedie: 820.225\n",
      "[44]\tvalid_0's tweedie: 820.22\n",
      "[45]\tvalid_0's tweedie: 820.213\n",
      "[46]\tvalid_0's tweedie: 820.204\n",
      "[47]\tvalid_0's tweedie: 820.201\n",
      "[48]\tvalid_0's tweedie: 820.183\n",
      "[49]\tvalid_0's tweedie: 820.169\n",
      "[50]\tvalid_0's tweedie: 820.169\n",
      "[51]\tvalid_0's tweedie: 820.155\n",
      "[52]\tvalid_0's tweedie: 820.138\n",
      "[53]\tvalid_0's tweedie: 820.136\n",
      "[54]\tvalid_0's tweedie: 820.122\n",
      "[55]\tvalid_0's tweedie: 820.116\n",
      "[56]\tvalid_0's tweedie: 820.108\n",
      "[57]\tvalid_0's tweedie: 820.1\n",
      "[58]\tvalid_0's tweedie: 820.095\n",
      "[59]\tvalid_0's tweedie: 820.087\n",
      "[60]\tvalid_0's tweedie: 820.087\n",
      "[61]\tvalid_0's tweedie: 820.083\n",
      "[62]\tvalid_0's tweedie: 820.085\n",
      "[63]\tvalid_0's tweedie: 820.083\n",
      "[64]\tvalid_0's tweedie: 820.073\n",
      "[65]\tvalid_0's tweedie: 820.072\n",
      "[66]\tvalid_0's tweedie: 820.071\n",
      "[67]\tvalid_0's tweedie: 820.066\n",
      "[68]\tvalid_0's tweedie: 820.07\n",
      "[69]\tvalid_0's tweedie: 820.065\n",
      "[70]\tvalid_0's tweedie: 820.062\n",
      "[71]\tvalid_0's tweedie: 820.053\n",
      "[72]\tvalid_0's tweedie: 820.052\n",
      "[73]\tvalid_0's tweedie: 820.049\n",
      "[74]\tvalid_0's tweedie: 820.047\n",
      "[75]\tvalid_0's tweedie: 820.049\n",
      "[76]\tvalid_0's tweedie: 820.043\n",
      "[77]\tvalid_0's tweedie: 820.037\n",
      "[78]\tvalid_0's tweedie: 820.037\n",
      "[79]\tvalid_0's tweedie: 820.031\n",
      "[80]\tvalid_0's tweedie: 820.029\n",
      "[81]\tvalid_0's tweedie: 820.032\n",
      "[82]\tvalid_0's tweedie: 820.031\n",
      "[83]\tvalid_0's tweedie: 820.028\n",
      "[84]\tvalid_0's tweedie: 820.028\n",
      "[85]\tvalid_0's tweedie: 820.026\n",
      "[86]\tvalid_0's tweedie: 820.023\n",
      "[87]\tvalid_0's tweedie: 820.025\n",
      "[88]\tvalid_0's tweedie: 820.024\n",
      "[89]\tvalid_0's tweedie: 820.024\n",
      "[90]\tvalid_0's tweedie: 820.021\n",
      "[91]\tvalid_0's tweedie: 820.017\n",
      "[92]\tvalid_0's tweedie: 820.019\n",
      "[93]\tvalid_0's tweedie: 820.018\n",
      "[94]\tvalid_0's tweedie: 820.018\n",
      "[95]\tvalid_0's tweedie: 820.021\n",
      "[96]\tvalid_0's tweedie: 820.02\n",
      "[97]\tvalid_0's tweedie: 820.018\n",
      "[98]\tvalid_0's tweedie: 820.016\n",
      "[99]\tvalid_0's tweedie: 820.023\n",
      "[100]\tvalid_0's tweedie: 820.017\n",
      "[101]\tvalid_0's tweedie: 820.016\n",
      "[102]\tvalid_0's tweedie: 820.017\n",
      "[103]\tvalid_0's tweedie: 820.017\n",
      "[104]\tvalid_0's tweedie: 820.018\n",
      "[105]\tvalid_0's tweedie: 820.018\n",
      "[106]\tvalid_0's tweedie: 820.017\n",
      "[107]\tvalid_0's tweedie: 820.023\n",
      "[108]\tvalid_0's tweedie: 820.025\n",
      "[109]\tvalid_0's tweedie: 820.02\n",
      "[110]\tvalid_0's tweedie: 820.02\n",
      "[111]\tvalid_0's tweedie: 820.017\n",
      "[112]\tvalid_0's tweedie: 820.014\n",
      "[113]\tvalid_0's tweedie: 820.013\n",
      "[114]\tvalid_0's tweedie: 820.012\n",
      "[115]\tvalid_0's tweedie: 820.009\n",
      "[116]\tvalid_0's tweedie: 820.013\n",
      "[117]\tvalid_0's tweedie: 820.015\n",
      "[118]\tvalid_0's tweedie: 820.014\n",
      "[119]\tvalid_0's tweedie: 820.014\n",
      "[120]\tvalid_0's tweedie: 820.015\n",
      "[121]\tvalid_0's tweedie: 820.015\n",
      "[122]\tvalid_0's tweedie: 820.015\n",
      "[123]\tvalid_0's tweedie: 820.015\n",
      "[124]\tvalid_0's tweedie: 820.013\n",
      "[125]\tvalid_0's tweedie: 820.013\n",
      "[126]\tvalid_0's tweedie: 820.013\n",
      "[127]\tvalid_0's tweedie: 820.013\n",
      "[128]\tvalid_0's tweedie: 820.013\n",
      "[129]\tvalid_0's tweedie: 820.009\n",
      "[130]\tvalid_0's tweedie: 820.009\n",
      "[131]\tvalid_0's tweedie: 820.008\n",
      "[132]\tvalid_0's tweedie: 820.008\n",
      "[133]\tvalid_0's tweedie: 820.007\n",
      "[134]\tvalid_0's tweedie: 820.005\n",
      "[135]\tvalid_0's tweedie: 820.003\n",
      "[136]\tvalid_0's tweedie: 820.004\n",
      "[137]\tvalid_0's tweedie: 820.003\n",
      "[138]\tvalid_0's tweedie: 820\n",
      "[139]\tvalid_0's tweedie: 820\n",
      "[140]\tvalid_0's tweedie: 820.004\n",
      "[141]\tvalid_0's tweedie: 820.003\n",
      "[142]\tvalid_0's tweedie: 820.003\n",
      "[143]\tvalid_0's tweedie: 820.003\n",
      "[144]\tvalid_0's tweedie: 820.009\n",
      "[145]\tvalid_0's tweedie: 820.007\n",
      "[146]\tvalid_0's tweedie: 820.005\n",
      "[147]\tvalid_0's tweedie: 820.007\n",
      "[148]\tvalid_0's tweedie: 820.007\n",
      "[149]\tvalid_0's tweedie: 820.007\n",
      "[150]\tvalid_0's tweedie: 820.006\n",
      "[151]\tvalid_0's tweedie: 820.004\n",
      "[152]\tvalid_0's tweedie: 820.001\n",
      "[153]\tvalid_0's tweedie: 819.996\n",
      "[154]\tvalid_0's tweedie: 819.999\n",
      "[155]\tvalid_0's tweedie: 820.002\n",
      "[156]\tvalid_0's tweedie: 820\n",
      "[157]\tvalid_0's tweedie: 820.001\n",
      "[158]\tvalid_0's tweedie: 820.002\n",
      "[159]\tvalid_0's tweedie: 820.004\n",
      "[160]\tvalid_0's tweedie: 820.003\n",
      "[161]\tvalid_0's tweedie: 820.006\n",
      "[162]\tvalid_0's tweedie: 820.007\n",
      "[163]\tvalid_0's tweedie: 820.007\n",
      "[164]\tvalid_0's tweedie: 820.005\n",
      "[165]\tvalid_0's tweedie: 820.005\n",
      "[166]\tvalid_0's tweedie: 820.01\n",
      "[167]\tvalid_0's tweedie: 820.009\n",
      "[168]\tvalid_0's tweedie: 820.009\n",
      "[169]\tvalid_0's tweedie: 820.01\n",
      "[170]\tvalid_0's tweedie: 820.013\n",
      "[171]\tvalid_0's tweedie: 820.013\n",
      "[172]\tvalid_0's tweedie: 820.013\n",
      "[173]\tvalid_0's tweedie: 820.012\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's tweedie: 819.996\n",
      "Training model for level 1 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1857, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444187\n",
      "[1]\tvalid_0's tweedie: 825.833\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.999\n",
      "[3]\tvalid_0's tweedie: 824.434\n",
      "[4]\tvalid_0's tweedie: 823.835\n",
      "[5]\tvalid_0's tweedie: 823.315\n",
      "[6]\tvalid_0's tweedie: 822.877\n",
      "[7]\tvalid_0's tweedie: 822.518\n",
      "[8]\tvalid_0's tweedie: 822.213\n",
      "[9]\tvalid_0's tweedie: 821.967\n",
      "[10]\tvalid_0's tweedie: 821.776\n",
      "[11]\tvalid_0's tweedie: 821.63\n",
      "[12]\tvalid_0's tweedie: 821.459\n",
      "[13]\tvalid_0's tweedie: 821.306\n",
      "[14]\tvalid_0's tweedie: 821.174\n",
      "[15]\tvalid_0's tweedie: 821.045\n",
      "[16]\tvalid_0's tweedie: 820.947\n",
      "[17]\tvalid_0's tweedie: 820.851\n",
      "[18]\tvalid_0's tweedie: 820.789\n",
      "[19]\tvalid_0's tweedie: 820.738\n",
      "[20]\tvalid_0's tweedie: 820.711\n",
      "[21]\tvalid_0's tweedie: 820.659\n",
      "[22]\tvalid_0's tweedie: 820.628\n",
      "[23]\tvalid_0's tweedie: 820.602\n",
      "[24]\tvalid_0's tweedie: 820.576\n",
      "[25]\tvalid_0's tweedie: 820.534\n",
      "[26]\tvalid_0's tweedie: 820.495\n",
      "[27]\tvalid_0's tweedie: 820.481\n",
      "[28]\tvalid_0's tweedie: 820.445\n",
      "[29]\tvalid_0's tweedie: 820.441\n",
      "[30]\tvalid_0's tweedie: 820.413\n",
      "[31]\tvalid_0's tweedie: 820.397\n",
      "[32]\tvalid_0's tweedie: 820.381\n",
      "[33]\tvalid_0's tweedie: 820.369\n",
      "[34]\tvalid_0's tweedie: 820.346\n",
      "[35]\tvalid_0's tweedie: 820.323\n",
      "[36]\tvalid_0's tweedie: 820.324\n",
      "[37]\tvalid_0's tweedie: 820.303\n",
      "[38]\tvalid_0's tweedie: 820.29\n",
      "[39]\tvalid_0's tweedie: 820.265\n",
      "[40]\tvalid_0's tweedie: 820.247\n",
      "[41]\tvalid_0's tweedie: 820.26\n",
      "[42]\tvalid_0's tweedie: 820.243\n",
      "[43]\tvalid_0's tweedie: 820.256\n",
      "[44]\tvalid_0's tweedie: 820.239\n",
      "[45]\tvalid_0's tweedie: 820.235\n",
      "[46]\tvalid_0's tweedie: 820.208\n",
      "[47]\tvalid_0's tweedie: 820.196\n",
      "[48]\tvalid_0's tweedie: 820.192\n",
      "[49]\tvalid_0's tweedie: 820.19\n",
      "[50]\tvalid_0's tweedie: 820.177\n",
      "[51]\tvalid_0's tweedie: 820.172\n",
      "[52]\tvalid_0's tweedie: 820.159\n",
      "[53]\tvalid_0's tweedie: 820.15\n",
      "[54]\tvalid_0's tweedie: 820.139\n",
      "[55]\tvalid_0's tweedie: 820.13\n",
      "[56]\tvalid_0's tweedie: 820.127\n",
      "[57]\tvalid_0's tweedie: 820.129\n",
      "[58]\tvalid_0's tweedie: 820.108\n",
      "[59]\tvalid_0's tweedie: 820.105\n",
      "[60]\tvalid_0's tweedie: 820.1\n",
      "[61]\tvalid_0's tweedie: 820.083\n",
      "[62]\tvalid_0's tweedie: 820.079\n",
      "[63]\tvalid_0's tweedie: 820.077\n",
      "[64]\tvalid_0's tweedie: 820.076\n",
      "[65]\tvalid_0's tweedie: 820.073\n",
      "[66]\tvalid_0's tweedie: 820.075\n",
      "[67]\tvalid_0's tweedie: 820.074\n",
      "[68]\tvalid_0's tweedie: 820.07\n",
      "[69]\tvalid_0's tweedie: 820.07\n",
      "[70]\tvalid_0's tweedie: 820.064\n",
      "[71]\tvalid_0's tweedie: 820.059\n",
      "[72]\tvalid_0's tweedie: 820.061\n",
      "[73]\tvalid_0's tweedie: 820.059\n",
      "[74]\tvalid_0's tweedie: 820.058\n",
      "[75]\tvalid_0's tweedie: 820.057\n",
      "[76]\tvalid_0's tweedie: 820.054\n",
      "[77]\tvalid_0's tweedie: 820.053\n",
      "[78]\tvalid_0's tweedie: 820.047\n",
      "[79]\tvalid_0's tweedie: 820.045\n",
      "[80]\tvalid_0's tweedie: 820.045\n",
      "[81]\tvalid_0's tweedie: 820.045\n",
      "[82]\tvalid_0's tweedie: 820.04\n",
      "[83]\tvalid_0's tweedie: 820.045\n",
      "[84]\tvalid_0's tweedie: 820.04\n",
      "[85]\tvalid_0's tweedie: 820.036\n",
      "[86]\tvalid_0's tweedie: 820.035\n",
      "[87]\tvalid_0's tweedie: 820.035\n",
      "[88]\tvalid_0's tweedie: 820.036\n",
      "[89]\tvalid_0's tweedie: 820.041\n",
      "[90]\tvalid_0's tweedie: 820.053\n",
      "[91]\tvalid_0's tweedie: 820.053\n",
      "[92]\tvalid_0's tweedie: 820.051\n",
      "[93]\tvalid_0's tweedie: 820.053\n",
      "[94]\tvalid_0's tweedie: 820.048\n",
      "[95]\tvalid_0's tweedie: 820.047\n",
      "[96]\tvalid_0's tweedie: 820.058\n",
      "[97]\tvalid_0's tweedie: 820.058\n",
      "[98]\tvalid_0's tweedie: 820.059\n",
      "[99]\tvalid_0's tweedie: 820.058\n",
      "[100]\tvalid_0's tweedie: 820.062\n",
      "[101]\tvalid_0's tweedie: 820.064\n",
      "[102]\tvalid_0's tweedie: 820.064\n",
      "[103]\tvalid_0's tweedie: 820.063\n",
      "[104]\tvalid_0's tweedie: 820.067\n",
      "[105]\tvalid_0's tweedie: 820.067\n",
      "[106]\tvalid_0's tweedie: 820.065\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's tweedie: 820.035\n",
      "Training model for level 1 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1856, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444257\n",
      "[1]\tvalid_0's tweedie: 825.831\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.992\n",
      "[3]\tvalid_0's tweedie: 824.425\n",
      "[4]\tvalid_0's tweedie: 823.811\n",
      "[5]\tvalid_0's tweedie: 823.314\n",
      "[6]\tvalid_0's tweedie: 823.027\n",
      "[7]\tvalid_0's tweedie: 822.662\n",
      "[8]\tvalid_0's tweedie: 822.339\n",
      "[9]\tvalid_0's tweedie: 822.093\n",
      "[10]\tvalid_0's tweedie: 821.923\n",
      "[11]\tvalid_0's tweedie: 821.726\n",
      "[12]\tvalid_0's tweedie: 821.604\n",
      "[13]\tvalid_0's tweedie: 821.445\n",
      "[14]\tvalid_0's tweedie: 821.286\n",
      "[15]\tvalid_0's tweedie: 821.167\n",
      "[16]\tvalid_0's tweedie: 821.065\n",
      "[17]\tvalid_0's tweedie: 820.982\n",
      "[18]\tvalid_0's tweedie: 820.886\n",
      "[19]\tvalid_0's tweedie: 820.828\n",
      "[20]\tvalid_0's tweedie: 820.747\n",
      "[21]\tvalid_0's tweedie: 820.681\n",
      "[22]\tvalid_0's tweedie: 820.636\n",
      "[23]\tvalid_0's tweedie: 820.584\n",
      "[24]\tvalid_0's tweedie: 820.55\n",
      "[25]\tvalid_0's tweedie: 820.499\n",
      "[26]\tvalid_0's tweedie: 820.466\n",
      "[27]\tvalid_0's tweedie: 820.424\n",
      "[28]\tvalid_0's tweedie: 820.392\n",
      "[29]\tvalid_0's tweedie: 820.362\n",
      "[30]\tvalid_0's tweedie: 820.346\n",
      "[31]\tvalid_0's tweedie: 820.331\n",
      "[32]\tvalid_0's tweedie: 820.314\n",
      "[33]\tvalid_0's tweedie: 820.31\n",
      "[34]\tvalid_0's tweedie: 820.29\n",
      "[35]\tvalid_0's tweedie: 820.272\n",
      "[36]\tvalid_0's tweedie: 820.261\n",
      "[37]\tvalid_0's tweedie: 820.262\n",
      "[38]\tvalid_0's tweedie: 820.253\n",
      "[39]\tvalid_0's tweedie: 820.224\n",
      "[40]\tvalid_0's tweedie: 820.229\n",
      "[41]\tvalid_0's tweedie: 820.228\n",
      "[42]\tvalid_0's tweedie: 820.222\n",
      "[43]\tvalid_0's tweedie: 820.206\n",
      "[44]\tvalid_0's tweedie: 820.193\n",
      "[45]\tvalid_0's tweedie: 820.185\n",
      "[46]\tvalid_0's tweedie: 820.168\n",
      "[47]\tvalid_0's tweedie: 820.171\n",
      "[48]\tvalid_0's tweedie: 820.161\n",
      "[49]\tvalid_0's tweedie: 820.19\n",
      "[50]\tvalid_0's tweedie: 820.176\n",
      "[51]\tvalid_0's tweedie: 820.162\n",
      "[52]\tvalid_0's tweedie: 820.159\n",
      "[53]\tvalid_0's tweedie: 820.15\n",
      "[54]\tvalid_0's tweedie: 820.152\n",
      "[55]\tvalid_0's tweedie: 820.133\n",
      "[56]\tvalid_0's tweedie: 820.132\n",
      "[57]\tvalid_0's tweedie: 820.129\n",
      "[58]\tvalid_0's tweedie: 820.12\n",
      "[59]\tvalid_0's tweedie: 820.12\n",
      "[60]\tvalid_0's tweedie: 820.108\n",
      "[61]\tvalid_0's tweedie: 820.104\n",
      "[62]\tvalid_0's tweedie: 820.107\n",
      "[63]\tvalid_0's tweedie: 820.1\n",
      "[64]\tvalid_0's tweedie: 820.098\n",
      "[65]\tvalid_0's tweedie: 820.093\n",
      "[66]\tvalid_0's tweedie: 820.094\n",
      "[67]\tvalid_0's tweedie: 820.079\n",
      "[68]\tvalid_0's tweedie: 820.084\n",
      "[69]\tvalid_0's tweedie: 820.087\n",
      "[70]\tvalid_0's tweedie: 820.086\n",
      "[71]\tvalid_0's tweedie: 820.078\n",
      "[72]\tvalid_0's tweedie: 820.075\n",
      "[73]\tvalid_0's tweedie: 820.066\n",
      "[74]\tvalid_0's tweedie: 820.067\n",
      "[75]\tvalid_0's tweedie: 820.061\n",
      "[76]\tvalid_0's tweedie: 820.058\n",
      "[77]\tvalid_0's tweedie: 820.055\n",
      "[78]\tvalid_0's tweedie: 820.055\n",
      "[79]\tvalid_0's tweedie: 820.054\n",
      "[80]\tvalid_0's tweedie: 820.054\n",
      "[81]\tvalid_0's tweedie: 820.053\n",
      "[82]\tvalid_0's tweedie: 820.051\n",
      "[83]\tvalid_0's tweedie: 820.053\n",
      "[84]\tvalid_0's tweedie: 820.058\n",
      "[85]\tvalid_0's tweedie: 820.058\n",
      "[86]\tvalid_0's tweedie: 820.059\n",
      "[87]\tvalid_0's tweedie: 820.059\n",
      "[88]\tvalid_0's tweedie: 820.059\n",
      "[89]\tvalid_0's tweedie: 820.061\n",
      "[90]\tvalid_0's tweedie: 820.054\n",
      "[91]\tvalid_0's tweedie: 820.055\n",
      "[92]\tvalid_0's tweedie: 820.054\n",
      "[93]\tvalid_0's tweedie: 820.056\n",
      "[94]\tvalid_0's tweedie: 820.056\n",
      "[95]\tvalid_0's tweedie: 820.05\n",
      "[96]\tvalid_0's tweedie: 820.053\n",
      "[97]\tvalid_0's tweedie: 820.051\n",
      "[98]\tvalid_0's tweedie: 820.049\n",
      "[99]\tvalid_0's tweedie: 820.048\n",
      "[100]\tvalid_0's tweedie: 820.051\n",
      "[101]\tvalid_0's tweedie: 820.049\n",
      "[102]\tvalid_0's tweedie: 820.048\n",
      "[103]\tvalid_0's tweedie: 820.048\n",
      "[104]\tvalid_0's tweedie: 820.047\n",
      "[105]\tvalid_0's tweedie: 820.044\n",
      "[106]\tvalid_0's tweedie: 820.042\n",
      "[107]\tvalid_0's tweedie: 820.043\n",
      "[108]\tvalid_0's tweedie: 820.046\n",
      "[109]\tvalid_0's tweedie: 820.05\n",
      "[110]\tvalid_0's tweedie: 820.052\n",
      "[111]\tvalid_0's tweedie: 820.052\n",
      "[112]\tvalid_0's tweedie: 820.051\n",
      "[113]\tvalid_0's tweedie: 820.046\n",
      "[114]\tvalid_0's tweedie: 820.047\n",
      "[115]\tvalid_0's tweedie: 820.047\n",
      "[116]\tvalid_0's tweedie: 820.047\n",
      "[117]\tvalid_0's tweedie: 820.046\n",
      "[118]\tvalid_0's tweedie: 820.049\n",
      "[119]\tvalid_0's tweedie: 820.046\n",
      "[120]\tvalid_0's tweedie: 820.045\n",
      "[121]\tvalid_0's tweedie: 820.043\n",
      "[122]\tvalid_0's tweedie: 820.043\n",
      "[123]\tvalid_0's tweedie: 820.039\n",
      "[124]\tvalid_0's tweedie: 820.038\n",
      "[125]\tvalid_0's tweedie: 820.037\n",
      "[126]\tvalid_0's tweedie: 820.037\n",
      "[127]\tvalid_0's tweedie: 820.035\n",
      "[128]\tvalid_0's tweedie: 820.035\n",
      "[129]\tvalid_0's tweedie: 820.035\n",
      "[130]\tvalid_0's tweedie: 820.035\n",
      "[131]\tvalid_0's tweedie: 820.032\n",
      "[132]\tvalid_0's tweedie: 820.032\n",
      "[133]\tvalid_0's tweedie: 820.034\n",
      "[134]\tvalid_0's tweedie: 820.029\n",
      "[135]\tvalid_0's tweedie: 820.029\n",
      "[136]\tvalid_0's tweedie: 820.029\n",
      "[137]\tvalid_0's tweedie: 820.03\n",
      "[138]\tvalid_0's tweedie: 820.03\n",
      "[139]\tvalid_0's tweedie: 820.031\n",
      "[140]\tvalid_0's tweedie: 820.033\n",
      "[141]\tvalid_0's tweedie: 820.033\n",
      "[142]\tvalid_0's tweedie: 820.032\n",
      "[143]\tvalid_0's tweedie: 820.031\n",
      "[144]\tvalid_0's tweedie: 820.03\n",
      "[145]\tvalid_0's tweedie: 820.03\n",
      "[146]\tvalid_0's tweedie: 820.031\n",
      "[147]\tvalid_0's tweedie: 820.031\n",
      "[148]\tvalid_0's tweedie: 820.03\n",
      "[149]\tvalid_0's tweedie: 820.03\n",
      "[150]\tvalid_0's tweedie: 820.031\n",
      "[151]\tvalid_0's tweedie: 820.031\n",
      "[152]\tvalid_0's tweedie: 820.031\n",
      "[153]\tvalid_0's tweedie: 820.029\n",
      "[154]\tvalid_0's tweedie: 820.029\n",
      "[155]\tvalid_0's tweedie: 820.028\n",
      "[156]\tvalid_0's tweedie: 820.027\n",
      "[157]\tvalid_0's tweedie: 820.027\n",
      "[158]\tvalid_0's tweedie: 820.027\n",
      "[159]\tvalid_0's tweedie: 820.024\n",
      "[160]\tvalid_0's tweedie: 820.024\n",
      "[161]\tvalid_0's tweedie: 820.022\n",
      "[162]\tvalid_0's tweedie: 820.022\n",
      "[163]\tvalid_0's tweedie: 820.021\n",
      "[164]\tvalid_0's tweedie: 820.019\n",
      "[165]\tvalid_0's tweedie: 820.019\n",
      "[166]\tvalid_0's tweedie: 820.016\n",
      "[167]\tvalid_0's tweedie: 820.016\n",
      "[168]\tvalid_0's tweedie: 820.014\n",
      "[169]\tvalid_0's tweedie: 820.014\n",
      "[170]\tvalid_0's tweedie: 820.014\n",
      "[171]\tvalid_0's tweedie: 820.013\n",
      "[172]\tvalid_0's tweedie: 820.01\n",
      "[173]\tvalid_0's tweedie: 820.009\n",
      "[174]\tvalid_0's tweedie: 820.011\n",
      "[175]\tvalid_0's tweedie: 820.011\n",
      "[176]\tvalid_0's tweedie: 820.01\n",
      "[177]\tvalid_0's tweedie: 820.008\n",
      "[178]\tvalid_0's tweedie: 820.01\n",
      "[179]\tvalid_0's tweedie: 820.009\n",
      "[180]\tvalid_0's tweedie: 820.007\n",
      "[181]\tvalid_0's tweedie: 820.006\n",
      "[182]\tvalid_0's tweedie: 820.006\n",
      "[183]\tvalid_0's tweedie: 820.006\n",
      "[184]\tvalid_0's tweedie: 820.006\n",
      "[185]\tvalid_0's tweedie: 820.006\n",
      "[186]\tvalid_0's tweedie: 820.006\n",
      "[187]\tvalid_0's tweedie: 820.006\n",
      "[188]\tvalid_0's tweedie: 820.007\n",
      "[189]\tvalid_0's tweedie: 820.007\n",
      "[190]\tvalid_0's tweedie: 820.008\n",
      "[191]\tvalid_0's tweedie: 820.007\n",
      "[192]\tvalid_0's tweedie: 820.007\n",
      "[193]\tvalid_0's tweedie: 820.006\n",
      "[194]\tvalid_0's tweedie: 820.006\n",
      "[195]\tvalid_0's tweedie: 820.006\n",
      "[196]\tvalid_0's tweedie: 820.006\n",
      "[197]\tvalid_0's tweedie: 820.006\n",
      "[198]\tvalid_0's tweedie: 820.007\n",
      "[199]\tvalid_0's tweedie: 820.007\n",
      "[200]\tvalid_0's tweedie: 820.006\n",
      "[201]\tvalid_0's tweedie: 820.006\n",
      "[202]\tvalid_0's tweedie: 820.006\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's tweedie: 820.006\n",
      "Training model for level 1 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1855, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444345\n",
      "[1]\tvalid_0's tweedie: 825.834\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.995\n",
      "[3]\tvalid_0's tweedie: 824.307\n",
      "[4]\tvalid_0's tweedie: 823.681\n",
      "[5]\tvalid_0's tweedie: 823.171\n",
      "[6]\tvalid_0's tweedie: 822.872\n",
      "[7]\tvalid_0's tweedie: 822.497\n",
      "[8]\tvalid_0's tweedie: 822.185\n",
      "[9]\tvalid_0's tweedie: 821.894\n",
      "[10]\tvalid_0's tweedie: 821.667\n",
      "[11]\tvalid_0's tweedie: 821.483\n",
      "[12]\tvalid_0's tweedie: 821.317\n",
      "[13]\tvalid_0's tweedie: 821.145\n",
      "[14]\tvalid_0's tweedie: 821.039\n",
      "[15]\tvalid_0's tweedie: 820.978\n",
      "[16]\tvalid_0's tweedie: 820.869\n",
      "[17]\tvalid_0's tweedie: 820.787\n",
      "[18]\tvalid_0's tweedie: 820.709\n",
      "[19]\tvalid_0's tweedie: 820.645\n",
      "[20]\tvalid_0's tweedie: 820.579\n",
      "[21]\tvalid_0's tweedie: 820.522\n",
      "[22]\tvalid_0's tweedie: 820.47\n",
      "[23]\tvalid_0's tweedie: 820.427\n",
      "[24]\tvalid_0's tweedie: 820.394\n",
      "[25]\tvalid_0's tweedie: 820.35\n",
      "[26]\tvalid_0's tweedie: 820.305\n",
      "[27]\tvalid_0's tweedie: 820.274\n",
      "[28]\tvalid_0's tweedie: 820.245\n",
      "[29]\tvalid_0's tweedie: 820.216\n",
      "[30]\tvalid_0's tweedie: 820.202\n",
      "[31]\tvalid_0's tweedie: 820.19\n",
      "[32]\tvalid_0's tweedie: 820.184\n",
      "[33]\tvalid_0's tweedie: 820.179\n",
      "[34]\tvalid_0's tweedie: 820.167\n",
      "[35]\tvalid_0's tweedie: 820.15\n",
      "[36]\tvalid_0's tweedie: 820.14\n",
      "[37]\tvalid_0's tweedie: 820.131\n",
      "[38]\tvalid_0's tweedie: 820.124\n",
      "[39]\tvalid_0's tweedie: 820.136\n",
      "[40]\tvalid_0's tweedie: 820.133\n",
      "[41]\tvalid_0's tweedie: 820.132\n",
      "[42]\tvalid_0's tweedie: 820.124\n",
      "[43]\tvalid_0's tweedie: 820.124\n",
      "[44]\tvalid_0's tweedie: 820.111\n",
      "[45]\tvalid_0's tweedie: 820.116\n",
      "[46]\tvalid_0's tweedie: 820.117\n",
      "[47]\tvalid_0's tweedie: 820.107\n",
      "[48]\tvalid_0's tweedie: 820.097\n",
      "[49]\tvalid_0's tweedie: 820.09\n",
      "[50]\tvalid_0's tweedie: 820.085\n",
      "[51]\tvalid_0's tweedie: 820.081\n",
      "[52]\tvalid_0's tweedie: 820.083\n",
      "[53]\tvalid_0's tweedie: 820.078\n",
      "[54]\tvalid_0's tweedie: 820.068\n",
      "[55]\tvalid_0's tweedie: 820.065\n",
      "[56]\tvalid_0's tweedie: 820.057\n",
      "[57]\tvalid_0's tweedie: 820.049\n",
      "[58]\tvalid_0's tweedie: 820.043\n",
      "[59]\tvalid_0's tweedie: 820.034\n",
      "[60]\tvalid_0's tweedie: 820.032\n",
      "[61]\tvalid_0's tweedie: 820.026\n",
      "[62]\tvalid_0's tweedie: 820.03\n",
      "[63]\tvalid_0's tweedie: 820.028\n",
      "[64]\tvalid_0's tweedie: 820.026\n",
      "[65]\tvalid_0's tweedie: 820.014\n",
      "[66]\tvalid_0's tweedie: 820.014\n",
      "[67]\tvalid_0's tweedie: 820.012\n",
      "[68]\tvalid_0's tweedie: 820.008\n",
      "[69]\tvalid_0's tweedie: 820.003\n",
      "[70]\tvalid_0's tweedie: 820.007\n",
      "[71]\tvalid_0's tweedie: 820.016\n",
      "[72]\tvalid_0's tweedie: 820.017\n",
      "[73]\tvalid_0's tweedie: 820.017\n",
      "[74]\tvalid_0's tweedie: 820.019\n",
      "[75]\tvalid_0's tweedie: 820.021\n",
      "[76]\tvalid_0's tweedie: 820.016\n",
      "[77]\tvalid_0's tweedie: 820.016\n",
      "[78]\tvalid_0's tweedie: 820.017\n",
      "[79]\tvalid_0's tweedie: 820.016\n",
      "[80]\tvalid_0's tweedie: 820.008\n",
      "[81]\tvalid_0's tweedie: 820.007\n",
      "[82]\tvalid_0's tweedie: 820.007\n",
      "[83]\tvalid_0's tweedie: 820.01\n",
      "[84]\tvalid_0's tweedie: 820.008\n",
      "[85]\tvalid_0's tweedie: 820.006\n",
      "[86]\tvalid_0's tweedie: 820.004\n",
      "[87]\tvalid_0's tweedie: 820.003\n",
      "[88]\tvalid_0's tweedie: 820\n",
      "[89]\tvalid_0's tweedie: 820.001\n",
      "[90]\tvalid_0's tweedie: 819.999\n",
      "[91]\tvalid_0's tweedie: 819.998\n",
      "[92]\tvalid_0's tweedie: 820\n",
      "[93]\tvalid_0's tweedie: 819.999\n",
      "[94]\tvalid_0's tweedie: 819.997\n",
      "[95]\tvalid_0's tweedie: 819.992\n",
      "[96]\tvalid_0's tweedie: 819.99\n",
      "[97]\tvalid_0's tweedie: 819.988\n",
      "[98]\tvalid_0's tweedie: 819.988\n",
      "[99]\tvalid_0's tweedie: 819.988\n",
      "[100]\tvalid_0's tweedie: 819.986\n",
      "[101]\tvalid_0's tweedie: 819.978\n",
      "[102]\tvalid_0's tweedie: 819.979\n",
      "[103]\tvalid_0's tweedie: 819.98\n",
      "[104]\tvalid_0's tweedie: 819.978\n",
      "[105]\tvalid_0's tweedie: 819.977\n",
      "[106]\tvalid_0's tweedie: 819.978\n",
      "[107]\tvalid_0's tweedie: 819.978\n",
      "[108]\tvalid_0's tweedie: 819.978\n",
      "[109]\tvalid_0's tweedie: 819.977\n",
      "[110]\tvalid_0's tweedie: 819.973\n",
      "[111]\tvalid_0's tweedie: 819.976\n",
      "[112]\tvalid_0's tweedie: 819.976\n",
      "[113]\tvalid_0's tweedie: 819.971\n",
      "[114]\tvalid_0's tweedie: 819.972\n",
      "[115]\tvalid_0's tweedie: 819.972\n",
      "[116]\tvalid_0's tweedie: 819.972\n",
      "[117]\tvalid_0's tweedie: 819.968\n",
      "[118]\tvalid_0's tweedie: 819.969\n",
      "[119]\tvalid_0's tweedie: 819.97\n",
      "[120]\tvalid_0's tweedie: 819.97\n",
      "[121]\tvalid_0's tweedie: 819.968\n",
      "[122]\tvalid_0's tweedie: 819.968\n",
      "[123]\tvalid_0's tweedie: 819.97\n",
      "[124]\tvalid_0's tweedie: 819.97\n",
      "[125]\tvalid_0's tweedie: 819.969\n",
      "[126]\tvalid_0's tweedie: 819.969\n",
      "[127]\tvalid_0's tweedie: 819.97\n",
      "[128]\tvalid_0's tweedie: 819.971\n",
      "[129]\tvalid_0's tweedie: 819.971\n",
      "[130]\tvalid_0's tweedie: 819.973\n",
      "[131]\tvalid_0's tweedie: 819.973\n",
      "[132]\tvalid_0's tweedie: 819.972\n",
      "[133]\tvalid_0's tweedie: 819.972\n",
      "[134]\tvalid_0's tweedie: 819.971\n",
      "[135]\tvalid_0's tweedie: 819.972\n",
      "[136]\tvalid_0's tweedie: 819.972\n",
      "[137]\tvalid_0's tweedie: 819.973\n",
      "[138]\tvalid_0's tweedie: 819.97\n",
      "[139]\tvalid_0's tweedie: 819.975\n",
      "[140]\tvalid_0's tweedie: 819.973\n",
      "[141]\tvalid_0's tweedie: 819.971\n",
      "[142]\tvalid_0's tweedie: 819.971\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's tweedie: 819.968\n",
      "Training model for level 1 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1854, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444551\n",
      "[1]\tvalid_0's tweedie: 825.826\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825\n",
      "[3]\tvalid_0's tweedie: 824.303\n",
      "[4]\tvalid_0's tweedie: 823.672\n",
      "[5]\tvalid_0's tweedie: 823.116\n",
      "[6]\tvalid_0's tweedie: 822.716\n",
      "[7]\tvalid_0's tweedie: 822.354\n",
      "[8]\tvalid_0's tweedie: 822.016\n",
      "[9]\tvalid_0's tweedie: 821.767\n",
      "[10]\tvalid_0's tweedie: 821.556\n",
      "[11]\tvalid_0's tweedie: 821.343\n",
      "[12]\tvalid_0's tweedie: 821.187\n",
      "[13]\tvalid_0's tweedie: 821.044\n",
      "[14]\tvalid_0's tweedie: 820.911\n",
      "[15]\tvalid_0's tweedie: 820.797\n",
      "[16]\tvalid_0's tweedie: 820.704\n",
      "[17]\tvalid_0's tweedie: 820.628\n",
      "[18]\tvalid_0's tweedie: 820.629\n",
      "[19]\tvalid_0's tweedie: 820.563\n",
      "[20]\tvalid_0's tweedie: 820.502\n",
      "[21]\tvalid_0's tweedie: 820.448\n",
      "[22]\tvalid_0's tweedie: 820.405\n",
      "[23]\tvalid_0's tweedie: 820.369\n",
      "[24]\tvalid_0's tweedie: 820.319\n",
      "[25]\tvalid_0's tweedie: 820.28\n",
      "[26]\tvalid_0's tweedie: 820.249\n",
      "[27]\tvalid_0's tweedie: 820.227\n",
      "[28]\tvalid_0's tweedie: 820.207\n",
      "[29]\tvalid_0's tweedie: 820.18\n",
      "[30]\tvalid_0's tweedie: 820.168\n",
      "[31]\tvalid_0's tweedie: 820.161\n",
      "[32]\tvalid_0's tweedie: 820.153\n",
      "[33]\tvalid_0's tweedie: 820.138\n",
      "[34]\tvalid_0's tweedie: 820.163\n",
      "[35]\tvalid_0's tweedie: 820.152\n",
      "[36]\tvalid_0's tweedie: 820.154\n",
      "[37]\tvalid_0's tweedie: 820.132\n",
      "[38]\tvalid_0's tweedie: 820.107\n",
      "[39]\tvalid_0's tweedie: 820.1\n",
      "[40]\tvalid_0's tweedie: 820.097\n",
      "[41]\tvalid_0's tweedie: 820.088\n",
      "[42]\tvalid_0's tweedie: 820.075\n",
      "[43]\tvalid_0's tweedie: 820.069\n",
      "[44]\tvalid_0's tweedie: 820.066\n",
      "[45]\tvalid_0's tweedie: 820.054\n",
      "[46]\tvalid_0's tweedie: 820.057\n",
      "[47]\tvalid_0's tweedie: 820.052\n",
      "[48]\tvalid_0's tweedie: 820.051\n",
      "[49]\tvalid_0's tweedie: 820.049\n",
      "[50]\tvalid_0's tweedie: 820.035\n",
      "[51]\tvalid_0's tweedie: 820.026\n",
      "[52]\tvalid_0's tweedie: 820.021\n",
      "[53]\tvalid_0's tweedie: 820.018\n",
      "[54]\tvalid_0's tweedie: 820.016\n",
      "[55]\tvalid_0's tweedie: 820.009\n",
      "[56]\tvalid_0's tweedie: 820.002\n",
      "[57]\tvalid_0's tweedie: 820.001\n",
      "[58]\tvalid_0's tweedie: 820.002\n",
      "[59]\tvalid_0's tweedie: 820.004\n",
      "[60]\tvalid_0's tweedie: 820.006\n",
      "[61]\tvalid_0's tweedie: 820.008\n",
      "[62]\tvalid_0's tweedie: 820.005\n",
      "[63]\tvalid_0's tweedie: 819.993\n",
      "[64]\tvalid_0's tweedie: 819.991\n",
      "[65]\tvalid_0's tweedie: 819.99\n",
      "[66]\tvalid_0's tweedie: 819.993\n",
      "[67]\tvalid_0's tweedie: 819.99\n",
      "[68]\tvalid_0's tweedie: 819.99\n",
      "[69]\tvalid_0's tweedie: 819.99\n",
      "[70]\tvalid_0's tweedie: 819.987\n",
      "[71]\tvalid_0's tweedie: 819.987\n",
      "[72]\tvalid_0's tweedie: 819.985\n",
      "[73]\tvalid_0's tweedie: 819.986\n",
      "[74]\tvalid_0's tweedie: 819.984\n",
      "[75]\tvalid_0's tweedie: 819.986\n",
      "[76]\tvalid_0's tweedie: 819.984\n",
      "[77]\tvalid_0's tweedie: 819.985\n",
      "[78]\tvalid_0's tweedie: 819.996\n",
      "[79]\tvalid_0's tweedie: 819.993\n",
      "[80]\tvalid_0's tweedie: 819.99\n",
      "[81]\tvalid_0's tweedie: 819.984\n",
      "[82]\tvalid_0's tweedie: 819.982\n",
      "[83]\tvalid_0's tweedie: 819.981\n",
      "[84]\tvalid_0's tweedie: 819.979\n",
      "[85]\tvalid_0's tweedie: 819.981\n",
      "[86]\tvalid_0's tweedie: 819.975\n",
      "[87]\tvalid_0's tweedie: 819.975\n",
      "[88]\tvalid_0's tweedie: 819.976\n",
      "[89]\tvalid_0's tweedie: 819.97\n",
      "[90]\tvalid_0's tweedie: 819.966\n",
      "[91]\tvalid_0's tweedie: 819.966\n",
      "[92]\tvalid_0's tweedie: 819.965\n",
      "[93]\tvalid_0's tweedie: 819.964\n",
      "[94]\tvalid_0's tweedie: 819.965\n",
      "[95]\tvalid_0's tweedie: 819.965\n",
      "[96]\tvalid_0's tweedie: 819.962\n",
      "[97]\tvalid_0's tweedie: 819.955\n",
      "[98]\tvalid_0's tweedie: 819.956\n",
      "[99]\tvalid_0's tweedie: 819.951\n",
      "[100]\tvalid_0's tweedie: 819.952\n",
      "[101]\tvalid_0's tweedie: 819.954\n",
      "[102]\tvalid_0's tweedie: 819.955\n",
      "[103]\tvalid_0's tweedie: 819.951\n",
      "[104]\tvalid_0's tweedie: 819.952\n",
      "[105]\tvalid_0's tweedie: 819.953\n",
      "[106]\tvalid_0's tweedie: 819.956\n",
      "[107]\tvalid_0's tweedie: 819.955\n",
      "[108]\tvalid_0's tweedie: 819.953\n",
      "[109]\tvalid_0's tweedie: 819.954\n",
      "[110]\tvalid_0's tweedie: 819.953\n",
      "[111]\tvalid_0's tweedie: 819.952\n",
      "[112]\tvalid_0's tweedie: 819.955\n",
      "[113]\tvalid_0's tweedie: 819.955\n",
      "[114]\tvalid_0's tweedie: 819.957\n",
      "[115]\tvalid_0's tweedie: 819.957\n",
      "[116]\tvalid_0's tweedie: 819.956\n",
      "[117]\tvalid_0's tweedie: 819.956\n",
      "[118]\tvalid_0's tweedie: 819.955\n",
      "[119]\tvalid_0's tweedie: 819.956\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's tweedie: 819.951\n",
      "Training model for level 1 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1853, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444732\n",
      "[1]\tvalid_0's tweedie: 825.819\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.988\n",
      "[3]\tvalid_0's tweedie: 824.295\n",
      "[4]\tvalid_0's tweedie: 823.704\n",
      "[5]\tvalid_0's tweedie: 823.157\n",
      "[6]\tvalid_0's tweedie: 822.708\n",
      "[7]\tvalid_0's tweedie: 822.312\n",
      "[8]\tvalid_0's tweedie: 821.98\n",
      "[9]\tvalid_0's tweedie: 821.705\n",
      "[10]\tvalid_0's tweedie: 821.457\n",
      "[11]\tvalid_0's tweedie: 821.315\n",
      "[12]\tvalid_0's tweedie: 821.206\n",
      "[13]\tvalid_0's tweedie: 821.068\n",
      "[14]\tvalid_0's tweedie: 820.947\n",
      "[15]\tvalid_0's tweedie: 820.842\n",
      "[16]\tvalid_0's tweedie: 820.782\n",
      "[17]\tvalid_0's tweedie: 820.697\n",
      "[18]\tvalid_0's tweedie: 820.639\n",
      "[19]\tvalid_0's tweedie: 820.562\n",
      "[20]\tvalid_0's tweedie: 820.509\n",
      "[21]\tvalid_0's tweedie: 820.449\n",
      "[22]\tvalid_0's tweedie: 820.416\n",
      "[23]\tvalid_0's tweedie: 820.38\n",
      "[24]\tvalid_0's tweedie: 820.343\n",
      "[25]\tvalid_0's tweedie: 820.291\n",
      "[26]\tvalid_0's tweedie: 820.254\n",
      "[27]\tvalid_0's tweedie: 820.227\n",
      "[28]\tvalid_0's tweedie: 820.203\n",
      "[29]\tvalid_0's tweedie: 820.186\n",
      "[30]\tvalid_0's tweedie: 820.206\n",
      "[31]\tvalid_0's tweedie: 820.185\n",
      "[32]\tvalid_0's tweedie: 820.159\n",
      "[33]\tvalid_0's tweedie: 820.136\n",
      "[34]\tvalid_0's tweedie: 820.14\n",
      "[35]\tvalid_0's tweedie: 820.124\n",
      "[36]\tvalid_0's tweedie: 820.109\n",
      "[37]\tvalid_0's tweedie: 820.103\n",
      "[38]\tvalid_0's tweedie: 820.099\n",
      "[39]\tvalid_0's tweedie: 820.094\n",
      "[40]\tvalid_0's tweedie: 820.082\n",
      "[41]\tvalid_0's tweedie: 820.067\n",
      "[42]\tvalid_0's tweedie: 820.06\n",
      "[43]\tvalid_0's tweedie: 820.064\n",
      "[44]\tvalid_0's tweedie: 820.06\n",
      "[45]\tvalid_0's tweedie: 820.061\n",
      "[46]\tvalid_0's tweedie: 820.064\n",
      "[47]\tvalid_0's tweedie: 820.055\n",
      "[48]\tvalid_0's tweedie: 820.052\n",
      "[49]\tvalid_0's tweedie: 820.05\n",
      "[50]\tvalid_0's tweedie: 820.039\n",
      "[51]\tvalid_0's tweedie: 820.035\n",
      "[52]\tvalid_0's tweedie: 820.028\n",
      "[53]\tvalid_0's tweedie: 820.018\n",
      "[54]\tvalid_0's tweedie: 820.016\n",
      "[55]\tvalid_0's tweedie: 820.006\n",
      "[56]\tvalid_0's tweedie: 820.004\n",
      "[57]\tvalid_0's tweedie: 819.998\n",
      "[58]\tvalid_0's tweedie: 819.994\n",
      "[59]\tvalid_0's tweedie: 819.985\n",
      "[60]\tvalid_0's tweedie: 819.977\n",
      "[61]\tvalid_0's tweedie: 819.977\n",
      "[62]\tvalid_0's tweedie: 819.973\n",
      "[63]\tvalid_0's tweedie: 819.97\n",
      "[64]\tvalid_0's tweedie: 819.966\n",
      "[65]\tvalid_0's tweedie: 819.958\n",
      "[66]\tvalid_0's tweedie: 819.958\n",
      "[67]\tvalid_0's tweedie: 819.957\n",
      "[68]\tvalid_0's tweedie: 819.956\n",
      "[69]\tvalid_0's tweedie: 819.956\n",
      "[70]\tvalid_0's tweedie: 819.95\n",
      "[71]\tvalid_0's tweedie: 819.95\n",
      "[72]\tvalid_0's tweedie: 819.953\n",
      "[73]\tvalid_0's tweedie: 819.951\n",
      "[74]\tvalid_0's tweedie: 819.951\n",
      "[75]\tvalid_0's tweedie: 819.952\n",
      "[76]\tvalid_0's tweedie: 819.952\n",
      "[77]\tvalid_0's tweedie: 819.95\n",
      "[78]\tvalid_0's tweedie: 819.949\n",
      "[79]\tvalid_0's tweedie: 819.945\n",
      "[80]\tvalid_0's tweedie: 819.945\n",
      "[81]\tvalid_0's tweedie: 819.945\n",
      "[82]\tvalid_0's tweedie: 819.945\n",
      "[83]\tvalid_0's tweedie: 819.944\n",
      "[84]\tvalid_0's tweedie: 819.941\n",
      "[85]\tvalid_0's tweedie: 819.941\n",
      "[86]\tvalid_0's tweedie: 819.941\n",
      "[87]\tvalid_0's tweedie: 819.941\n",
      "[88]\tvalid_0's tweedie: 819.941\n",
      "[89]\tvalid_0's tweedie: 819.941\n",
      "[90]\tvalid_0's tweedie: 819.933\n",
      "[91]\tvalid_0's tweedie: 819.93\n",
      "[92]\tvalid_0's tweedie: 819.93\n",
      "[93]\tvalid_0's tweedie: 819.93\n",
      "[94]\tvalid_0's tweedie: 819.931\n",
      "[95]\tvalid_0's tweedie: 819.931\n",
      "[96]\tvalid_0's tweedie: 819.932\n",
      "[97]\tvalid_0's tweedie: 819.925\n",
      "[98]\tvalid_0's tweedie: 819.92\n",
      "[99]\tvalid_0's tweedie: 819.918\n",
      "[100]\tvalid_0's tweedie: 819.918\n",
      "[101]\tvalid_0's tweedie: 819.915\n",
      "[102]\tvalid_0's tweedie: 819.917\n",
      "[103]\tvalid_0's tweedie: 819.915\n",
      "[104]\tvalid_0's tweedie: 819.915\n",
      "[105]\tvalid_0's tweedie: 819.914\n",
      "[106]\tvalid_0's tweedie: 819.913\n",
      "[107]\tvalid_0's tweedie: 819.913\n",
      "[108]\tvalid_0's tweedie: 819.913\n",
      "[109]\tvalid_0's tweedie: 819.914\n",
      "[110]\tvalid_0's tweedie: 819.914\n",
      "[111]\tvalid_0's tweedie: 819.91\n",
      "[112]\tvalid_0's tweedie: 819.91\n",
      "[113]\tvalid_0's tweedie: 819.917\n",
      "[114]\tvalid_0's tweedie: 819.917\n",
      "[115]\tvalid_0's tweedie: 819.917\n",
      "[116]\tvalid_0's tweedie: 819.916\n",
      "[117]\tvalid_0's tweedie: 819.916\n",
      "[118]\tvalid_0's tweedie: 819.917\n",
      "[119]\tvalid_0's tweedie: 819.917\n",
      "[120]\tvalid_0's tweedie: 819.916\n",
      "[121]\tvalid_0's tweedie: 819.918\n",
      "[122]\tvalid_0's tweedie: 819.921\n",
      "[123]\tvalid_0's tweedie: 819.919\n",
      "[124]\tvalid_0's tweedie: 819.919\n",
      "[125]\tvalid_0's tweedie: 819.919\n",
      "[126]\tvalid_0's tweedie: 819.915\n",
      "[127]\tvalid_0's tweedie: 819.914\n",
      "[128]\tvalid_0's tweedie: 819.914\n",
      "[129]\tvalid_0's tweedie: 819.913\n",
      "[130]\tvalid_0's tweedie: 819.912\n",
      "[131]\tvalid_0's tweedie: 819.91\n",
      "[132]\tvalid_0's tweedie: 819.909\n",
      "[133]\tvalid_0's tweedie: 819.909\n",
      "[134]\tvalid_0's tweedie: 819.911\n",
      "[135]\tvalid_0's tweedie: 819.909\n",
      "[136]\tvalid_0's tweedie: 819.91\n",
      "[137]\tvalid_0's tweedie: 819.909\n",
      "[138]\tvalid_0's tweedie: 819.908\n",
      "[139]\tvalid_0's tweedie: 819.907\n",
      "[140]\tvalid_0's tweedie: 819.907\n",
      "[141]\tvalid_0's tweedie: 819.908\n",
      "[142]\tvalid_0's tweedie: 819.909\n",
      "[143]\tvalid_0's tweedie: 819.909\n",
      "[144]\tvalid_0's tweedie: 819.909\n",
      "[145]\tvalid_0's tweedie: 819.911\n",
      "[146]\tvalid_0's tweedie: 819.911\n",
      "[147]\tvalid_0's tweedie: 819.911\n",
      "[148]\tvalid_0's tweedie: 819.911\n",
      "[149]\tvalid_0's tweedie: 819.911\n",
      "[150]\tvalid_0's tweedie: 819.911\n",
      "[151]\tvalid_0's tweedie: 819.91\n",
      "[152]\tvalid_0's tweedie: 819.91\n",
      "[153]\tvalid_0's tweedie: 819.912\n",
      "[154]\tvalid_0's tweedie: 819.912\n",
      "[155]\tvalid_0's tweedie: 819.912\n",
      "[156]\tvalid_0's tweedie: 819.913\n",
      "[157]\tvalid_0's tweedie: 819.912\n",
      "[158]\tvalid_0's tweedie: 819.914\n",
      "[159]\tvalid_0's tweedie: 819.915\n",
      "[160]\tvalid_0's tweedie: 819.913\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's tweedie: 819.907\n",
      "Training model for level 1 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1852, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.444925\n",
      "[1]\tvalid_0's tweedie: 825.823\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.933\n",
      "[3]\tvalid_0's tweedie: 824.251\n",
      "[4]\tvalid_0's tweedie: 823.583\n",
      "[5]\tvalid_0's tweedie: 823.08\n",
      "[6]\tvalid_0's tweedie: 822.667\n",
      "[7]\tvalid_0's tweedie: 822.285\n",
      "[8]\tvalid_0's tweedie: 821.952\n",
      "[9]\tvalid_0's tweedie: 821.659\n",
      "[10]\tvalid_0's tweedie: 821.455\n",
      "[11]\tvalid_0's tweedie: 821.278\n",
      "[12]\tvalid_0's tweedie: 821.093\n",
      "[13]\tvalid_0's tweedie: 820.96\n",
      "[14]\tvalid_0's tweedie: 820.843\n",
      "[15]\tvalid_0's tweedie: 820.751\n",
      "[16]\tvalid_0's tweedie: 820.679\n",
      "[17]\tvalid_0's tweedie: 820.613\n",
      "[18]\tvalid_0's tweedie: 820.564\n",
      "[19]\tvalid_0's tweedie: 820.51\n",
      "[20]\tvalid_0's tweedie: 820.452\n",
      "[21]\tvalid_0's tweedie: 820.406\n",
      "[22]\tvalid_0's tweedie: 820.389\n",
      "[23]\tvalid_0's tweedie: 820.376\n",
      "[24]\tvalid_0's tweedie: 820.337\n",
      "[25]\tvalid_0's tweedie: 820.3\n",
      "[26]\tvalid_0's tweedie: 820.264\n",
      "[27]\tvalid_0's tweedie: 820.241\n",
      "[28]\tvalid_0's tweedie: 820.214\n",
      "[29]\tvalid_0's tweedie: 820.184\n",
      "[30]\tvalid_0's tweedie: 820.164\n",
      "[31]\tvalid_0's tweedie: 820.149\n",
      "[32]\tvalid_0's tweedie: 820.126\n",
      "[33]\tvalid_0's tweedie: 820.125\n",
      "[34]\tvalid_0's tweedie: 820.101\n",
      "[35]\tvalid_0's tweedie: 820.122\n",
      "[36]\tvalid_0's tweedie: 820.114\n",
      "[37]\tvalid_0's tweedie: 820.104\n",
      "[38]\tvalid_0's tweedie: 820.091\n",
      "[39]\tvalid_0's tweedie: 820.073\n",
      "[40]\tvalid_0's tweedie: 820.068\n",
      "[41]\tvalid_0's tweedie: 820.064\n",
      "[42]\tvalid_0's tweedie: 820.055\n",
      "[43]\tvalid_0's tweedie: 820.046\n",
      "[44]\tvalid_0's tweedie: 820.038\n",
      "[45]\tvalid_0's tweedie: 820.037\n",
      "[46]\tvalid_0's tweedie: 820.028\n",
      "[47]\tvalid_0's tweedie: 820.033\n",
      "[48]\tvalid_0's tweedie: 820.027\n",
      "[49]\tvalid_0's tweedie: 820.014\n",
      "[50]\tvalid_0's tweedie: 820.013\n",
      "[51]\tvalid_0's tweedie: 820.005\n",
      "[52]\tvalid_0's tweedie: 820.003\n",
      "[53]\tvalid_0's tweedie: 820.001\n",
      "[54]\tvalid_0's tweedie: 820.009\n",
      "[55]\tvalid_0's tweedie: 820.008\n",
      "[56]\tvalid_0's tweedie: 820.007\n",
      "[57]\tvalid_0's tweedie: 820.001\n",
      "[58]\tvalid_0's tweedie: 820\n",
      "[59]\tvalid_0's tweedie: 819.998\n",
      "[60]\tvalid_0's tweedie: 819.989\n",
      "[61]\tvalid_0's tweedie: 819.99\n",
      "[62]\tvalid_0's tweedie: 820\n",
      "[63]\tvalid_0's tweedie: 819.996\n",
      "[64]\tvalid_0's tweedie: 819.992\n",
      "[65]\tvalid_0's tweedie: 819.992\n",
      "[66]\tvalid_0's tweedie: 819.991\n",
      "[67]\tvalid_0's tweedie: 819.985\n",
      "[68]\tvalid_0's tweedie: 819.984\n",
      "[69]\tvalid_0's tweedie: 819.978\n",
      "[70]\tvalid_0's tweedie: 819.977\n",
      "[71]\tvalid_0's tweedie: 819.977\n",
      "[72]\tvalid_0's tweedie: 819.973\n",
      "[73]\tvalid_0's tweedie: 819.974\n",
      "[74]\tvalid_0's tweedie: 819.975\n",
      "[75]\tvalid_0's tweedie: 819.969\n",
      "[76]\tvalid_0's tweedie: 819.968\n",
      "[77]\tvalid_0's tweedie: 819.969\n",
      "[78]\tvalid_0's tweedie: 819.962\n",
      "[79]\tvalid_0's tweedie: 819.959\n",
      "[80]\tvalid_0's tweedie: 819.959\n",
      "[81]\tvalid_0's tweedie: 819.962\n",
      "[82]\tvalid_0's tweedie: 819.958\n",
      "[83]\tvalid_0's tweedie: 819.958\n",
      "[84]\tvalid_0's tweedie: 819.96\n",
      "[85]\tvalid_0's tweedie: 819.961\n",
      "[86]\tvalid_0's tweedie: 819.961\n",
      "[87]\tvalid_0's tweedie: 819.96\n",
      "[88]\tvalid_0's tweedie: 819.96\n",
      "[89]\tvalid_0's tweedie: 819.959\n",
      "[90]\tvalid_0's tweedie: 819.96\n",
      "[91]\tvalid_0's tweedie: 819.959\n",
      "[92]\tvalid_0's tweedie: 819.958\n",
      "[93]\tvalid_0's tweedie: 819.959\n",
      "[94]\tvalid_0's tweedie: 819.955\n",
      "[95]\tvalid_0's tweedie: 819.954\n",
      "[96]\tvalid_0's tweedie: 819.954\n",
      "[97]\tvalid_0's tweedie: 819.95\n",
      "[98]\tvalid_0's tweedie: 819.954\n",
      "[99]\tvalid_0's tweedie: 819.954\n",
      "[100]\tvalid_0's tweedie: 819.951\n",
      "[101]\tvalid_0's tweedie: 819.951\n",
      "[102]\tvalid_0's tweedie: 819.951\n",
      "[103]\tvalid_0's tweedie: 819.951\n",
      "[104]\tvalid_0's tweedie: 819.952\n",
      "[105]\tvalid_0's tweedie: 819.953\n",
      "[106]\tvalid_0's tweedie: 819.949\n",
      "[107]\tvalid_0's tweedie: 819.945\n",
      "[108]\tvalid_0's tweedie: 819.949\n",
      "[109]\tvalid_0's tweedie: 819.949\n",
      "[110]\tvalid_0's tweedie: 819.949\n",
      "[111]\tvalid_0's tweedie: 819.945\n",
      "[112]\tvalid_0's tweedie: 819.945\n",
      "[113]\tvalid_0's tweedie: 819.945\n",
      "[114]\tvalid_0's tweedie: 819.945\n",
      "[115]\tvalid_0's tweedie: 819.95\n",
      "[116]\tvalid_0's tweedie: 819.953\n",
      "[117]\tvalid_0's tweedie: 819.952\n",
      "[118]\tvalid_0's tweedie: 819.952\n",
      "[119]\tvalid_0's tweedie: 819.95\n",
      "[120]\tvalid_0's tweedie: 819.952\n",
      "[121]\tvalid_0's tweedie: 819.952\n",
      "[122]\tvalid_0's tweedie: 819.953\n",
      "[123]\tvalid_0's tweedie: 819.954\n",
      "[124]\tvalid_0's tweedie: 819.954\n",
      "[125]\tvalid_0's tweedie: 819.954\n",
      "[126]\tvalid_0's tweedie: 819.954\n",
      "[127]\tvalid_0's tweedie: 819.952\n",
      "[128]\tvalid_0's tweedie: 819.952\n",
      "[129]\tvalid_0's tweedie: 819.95\n",
      "[130]\tvalid_0's tweedie: 819.951\n",
      "[131]\tvalid_0's tweedie: 819.951\n",
      "[132]\tvalid_0's tweedie: 819.951\n",
      "[133]\tvalid_0's tweedie: 819.951\n",
      "[134]\tvalid_0's tweedie: 819.951\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's tweedie: 819.945\n",
      "Training model for level 1 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1851, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445096\n",
      "[1]\tvalid_0's tweedie: 825.792\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.941\n",
      "[3]\tvalid_0's tweedie: 824.248\n",
      "[4]\tvalid_0's tweedie: 823.617\n",
      "[5]\tvalid_0's tweedie: 823.085\n",
      "[6]\tvalid_0's tweedie: 822.645\n",
      "[7]\tvalid_0's tweedie: 822.309\n",
      "[8]\tvalid_0's tweedie: 821.975\n",
      "[9]\tvalid_0's tweedie: 821.688\n",
      "[10]\tvalid_0's tweedie: 821.542\n",
      "[11]\tvalid_0's tweedie: 821.354\n",
      "[12]\tvalid_0's tweedie: 821.169\n",
      "[13]\tvalid_0's tweedie: 821.024\n",
      "[14]\tvalid_0's tweedie: 820.928\n",
      "[15]\tvalid_0's tweedie: 820.825\n",
      "[16]\tvalid_0's tweedie: 820.73\n",
      "[17]\tvalid_0's tweedie: 820.651\n",
      "[18]\tvalid_0's tweedie: 820.582\n",
      "[19]\tvalid_0's tweedie: 820.496\n",
      "[20]\tvalid_0's tweedie: 820.446\n",
      "[21]\tvalid_0's tweedie: 820.385\n",
      "[22]\tvalid_0's tweedie: 820.329\n",
      "[23]\tvalid_0's tweedie: 820.302\n",
      "[24]\tvalid_0's tweedie: 820.255\n",
      "[25]\tvalid_0's tweedie: 820.243\n",
      "[26]\tvalid_0's tweedie: 820.21\n",
      "[27]\tvalid_0's tweedie: 820.162\n",
      "[28]\tvalid_0's tweedie: 820.13\n",
      "[29]\tvalid_0's tweedie: 820.095\n",
      "[30]\tvalid_0's tweedie: 820.08\n",
      "[31]\tvalid_0's tweedie: 820.064\n",
      "[32]\tvalid_0's tweedie: 820.085\n",
      "[33]\tvalid_0's tweedie: 820.064\n",
      "[34]\tvalid_0's tweedie: 820.054\n",
      "[35]\tvalid_0's tweedie: 820.032\n",
      "[36]\tvalid_0's tweedie: 820.022\n",
      "[37]\tvalid_0's tweedie: 820.01\n",
      "[38]\tvalid_0's tweedie: 820.007\n",
      "[39]\tvalid_0's tweedie: 820.002\n",
      "[40]\tvalid_0's tweedie: 819.997\n",
      "[41]\tvalid_0's tweedie: 819.996\n",
      "[42]\tvalid_0's tweedie: 819.985\n",
      "[43]\tvalid_0's tweedie: 819.98\n",
      "[44]\tvalid_0's tweedie: 819.982\n",
      "[45]\tvalid_0's tweedie: 819.982\n",
      "[46]\tvalid_0's tweedie: 819.98\n",
      "[47]\tvalid_0's tweedie: 819.985\n",
      "[48]\tvalid_0's tweedie: 819.98\n",
      "[49]\tvalid_0's tweedie: 819.965\n",
      "[50]\tvalid_0's tweedie: 819.962\n",
      "[51]\tvalid_0's tweedie: 819.955\n",
      "[52]\tvalid_0's tweedie: 819.951\n",
      "[53]\tvalid_0's tweedie: 819.943\n",
      "[54]\tvalid_0's tweedie: 819.942\n",
      "[55]\tvalid_0's tweedie: 819.93\n",
      "[56]\tvalid_0's tweedie: 819.922\n",
      "[57]\tvalid_0's tweedie: 819.917\n",
      "[58]\tvalid_0's tweedie: 819.914\n",
      "[59]\tvalid_0's tweedie: 819.909\n",
      "[60]\tvalid_0's tweedie: 819.91\n",
      "[61]\tvalid_0's tweedie: 819.91\n",
      "[62]\tvalid_0's tweedie: 819.908\n",
      "[63]\tvalid_0's tweedie: 819.908\n",
      "[64]\tvalid_0's tweedie: 819.911\n",
      "[65]\tvalid_0's tweedie: 819.913\n",
      "[66]\tvalid_0's tweedie: 819.919\n",
      "[67]\tvalid_0's tweedie: 819.915\n",
      "[68]\tvalid_0's tweedie: 819.916\n",
      "[69]\tvalid_0's tweedie: 819.917\n",
      "[70]\tvalid_0's tweedie: 819.911\n",
      "[71]\tvalid_0's tweedie: 819.912\n",
      "[72]\tvalid_0's tweedie: 819.906\n",
      "[73]\tvalid_0's tweedie: 819.906\n",
      "[74]\tvalid_0's tweedie: 819.909\n",
      "[75]\tvalid_0's tweedie: 819.913\n",
      "[76]\tvalid_0's tweedie: 819.908\n",
      "[77]\tvalid_0's tweedie: 819.91\n",
      "[78]\tvalid_0's tweedie: 819.91\n",
      "[79]\tvalid_0's tweedie: 819.91\n",
      "[80]\tvalid_0's tweedie: 819.91\n",
      "[81]\tvalid_0's tweedie: 819.909\n",
      "[82]\tvalid_0's tweedie: 819.908\n",
      "[83]\tvalid_0's tweedie: 819.912\n",
      "[84]\tvalid_0's tweedie: 819.915\n",
      "[85]\tvalid_0's tweedie: 819.91\n",
      "[86]\tvalid_0's tweedie: 819.914\n",
      "[87]\tvalid_0's tweedie: 819.914\n",
      "[88]\tvalid_0's tweedie: 819.916\n",
      "[89]\tvalid_0's tweedie: 819.918\n",
      "[90]\tvalid_0's tweedie: 819.916\n",
      "[91]\tvalid_0's tweedie: 819.918\n",
      "[92]\tvalid_0's tweedie: 819.918\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's tweedie: 819.906\n",
      "Training model for level 1 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1850, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445266\n",
      "[1]\tvalid_0's tweedie: 825.844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.014\n",
      "[3]\tvalid_0's tweedie: 824.301\n",
      "[4]\tvalid_0's tweedie: 823.686\n",
      "[5]\tvalid_0's tweedie: 823.164\n",
      "[6]\tvalid_0's tweedie: 822.716\n",
      "[7]\tvalid_0's tweedie: 822.421\n",
      "[8]\tvalid_0's tweedie: 822.075\n",
      "[9]\tvalid_0's tweedie: 821.879\n",
      "[10]\tvalid_0's tweedie: 821.668\n",
      "[11]\tvalid_0's tweedie: 821.445\n",
      "[12]\tvalid_0's tweedie: 821.271\n",
      "[13]\tvalid_0's tweedie: 821.111\n",
      "[14]\tvalid_0's tweedie: 820.987\n",
      "[15]\tvalid_0's tweedie: 820.868\n",
      "[16]\tvalid_0's tweedie: 820.747\n",
      "[17]\tvalid_0's tweedie: 820.671\n",
      "[18]\tvalid_0's tweedie: 820.603\n",
      "[19]\tvalid_0's tweedie: 820.551\n",
      "[20]\tvalid_0's tweedie: 820.497\n",
      "[21]\tvalid_0's tweedie: 820.433\n",
      "[22]\tvalid_0's tweedie: 820.39\n",
      "[23]\tvalid_0's tweedie: 820.349\n",
      "[24]\tvalid_0's tweedie: 820.298\n",
      "[25]\tvalid_0's tweedie: 820.252\n",
      "[26]\tvalid_0's tweedie: 820.226\n",
      "[27]\tvalid_0's tweedie: 820.202\n",
      "[28]\tvalid_0's tweedie: 820.166\n",
      "[29]\tvalid_0's tweedie: 820.142\n",
      "[30]\tvalid_0's tweedie: 820.116\n",
      "[31]\tvalid_0's tweedie: 820.112\n",
      "[32]\tvalid_0's tweedie: 820.088\n",
      "[33]\tvalid_0's tweedie: 820.071\n",
      "[34]\tvalid_0's tweedie: 820.068\n",
      "[35]\tvalid_0's tweedie: 820.054\n",
      "[36]\tvalid_0's tweedie: 820.051\n",
      "[37]\tvalid_0's tweedie: 820.041\n",
      "[38]\tvalid_0's tweedie: 820.033\n",
      "[39]\tvalid_0's tweedie: 820.017\n",
      "[40]\tvalid_0's tweedie: 820.003\n",
      "[41]\tvalid_0's tweedie: 820.013\n",
      "[42]\tvalid_0's tweedie: 820.003\n",
      "[43]\tvalid_0's tweedie: 820.001\n",
      "[44]\tvalid_0's tweedie: 819.998\n",
      "[45]\tvalid_0's tweedie: 819.999\n",
      "[46]\tvalid_0's tweedie: 819.993\n",
      "[47]\tvalid_0's tweedie: 819.994\n",
      "[48]\tvalid_0's tweedie: 819.985\n",
      "[49]\tvalid_0's tweedie: 819.981\n",
      "[50]\tvalid_0's tweedie: 819.976\n",
      "[51]\tvalid_0's tweedie: 819.974\n",
      "[52]\tvalid_0's tweedie: 819.969\n",
      "[53]\tvalid_0's tweedie: 819.966\n",
      "[54]\tvalid_0's tweedie: 819.964\n",
      "[55]\tvalid_0's tweedie: 819.956\n",
      "[56]\tvalid_0's tweedie: 819.951\n",
      "[57]\tvalid_0's tweedie: 819.947\n",
      "[58]\tvalid_0's tweedie: 819.946\n",
      "[59]\tvalid_0's tweedie: 819.947\n",
      "[60]\tvalid_0's tweedie: 819.937\n",
      "[61]\tvalid_0's tweedie: 819.934\n",
      "[62]\tvalid_0's tweedie: 819.934\n",
      "[63]\tvalid_0's tweedie: 819.927\n",
      "[64]\tvalid_0's tweedie: 819.92\n",
      "[65]\tvalid_0's tweedie: 819.92\n",
      "[66]\tvalid_0's tweedie: 819.919\n",
      "[67]\tvalid_0's tweedie: 819.916\n",
      "[68]\tvalid_0's tweedie: 819.915\n",
      "[69]\tvalid_0's tweedie: 819.908\n",
      "[70]\tvalid_0's tweedie: 819.908\n",
      "[71]\tvalid_0's tweedie: 819.908\n",
      "[72]\tvalid_0's tweedie: 819.906\n",
      "[73]\tvalid_0's tweedie: 819.904\n",
      "[74]\tvalid_0's tweedie: 819.901\n",
      "[75]\tvalid_0's tweedie: 819.895\n",
      "[76]\tvalid_0's tweedie: 819.889\n",
      "[77]\tvalid_0's tweedie: 819.889\n",
      "[78]\tvalid_0's tweedie: 819.885\n",
      "[79]\tvalid_0's tweedie: 819.879\n",
      "[80]\tvalid_0's tweedie: 819.878\n",
      "[81]\tvalid_0's tweedie: 819.876\n",
      "[82]\tvalid_0's tweedie: 819.876\n",
      "[83]\tvalid_0's tweedie: 819.875\n",
      "[84]\tvalid_0's tweedie: 819.876\n",
      "[85]\tvalid_0's tweedie: 819.873\n",
      "[86]\tvalid_0's tweedie: 819.87\n",
      "[87]\tvalid_0's tweedie: 819.87\n",
      "[88]\tvalid_0's tweedie: 819.869\n",
      "[89]\tvalid_0's tweedie: 819.869\n",
      "[90]\tvalid_0's tweedie: 819.871\n",
      "[91]\tvalid_0's tweedie: 819.874\n",
      "[92]\tvalid_0's tweedie: 819.869\n",
      "[93]\tvalid_0's tweedie: 819.866\n",
      "[94]\tvalid_0's tweedie: 819.866\n",
      "[95]\tvalid_0's tweedie: 819.866\n",
      "[96]\tvalid_0's tweedie: 819.865\n",
      "[97]\tvalid_0's tweedie: 819.866\n",
      "[98]\tvalid_0's tweedie: 819.868\n",
      "[99]\tvalid_0's tweedie: 819.862\n",
      "[100]\tvalid_0's tweedie: 819.862\n",
      "[101]\tvalid_0's tweedie: 819.864\n",
      "[102]\tvalid_0's tweedie: 819.864\n",
      "[103]\tvalid_0's tweedie: 819.864\n",
      "[104]\tvalid_0's tweedie: 819.863\n",
      "[105]\tvalid_0's tweedie: 819.863\n",
      "[106]\tvalid_0's tweedie: 819.863\n",
      "[107]\tvalid_0's tweedie: 819.86\n",
      "[108]\tvalid_0's tweedie: 819.86\n",
      "[109]\tvalid_0's tweedie: 819.855\n",
      "[110]\tvalid_0's tweedie: 819.852\n",
      "[111]\tvalid_0's tweedie: 819.848\n",
      "[112]\tvalid_0's tweedie: 819.847\n",
      "[113]\tvalid_0's tweedie: 819.847\n",
      "[114]\tvalid_0's tweedie: 819.844\n",
      "[115]\tvalid_0's tweedie: 819.845\n",
      "[116]\tvalid_0's tweedie: 819.845\n",
      "[117]\tvalid_0's tweedie: 819.845\n",
      "[118]\tvalid_0's tweedie: 819.845\n",
      "[119]\tvalid_0's tweedie: 819.845\n",
      "[120]\tvalid_0's tweedie: 819.848\n",
      "[121]\tvalid_0's tweedie: 819.849\n",
      "[122]\tvalid_0's tweedie: 819.848\n",
      "[123]\tvalid_0's tweedie: 819.851\n",
      "[124]\tvalid_0's tweedie: 819.849\n",
      "[125]\tvalid_0's tweedie: 819.849\n",
      "[126]\tvalid_0's tweedie: 819.847\n",
      "[127]\tvalid_0's tweedie: 819.844\n",
      "[128]\tvalid_0's tweedie: 819.844\n",
      "[129]\tvalid_0's tweedie: 819.841\n",
      "[130]\tvalid_0's tweedie: 819.841\n",
      "[131]\tvalid_0's tweedie: 819.841\n",
      "[132]\tvalid_0's tweedie: 819.843\n",
      "[133]\tvalid_0's tweedie: 819.839\n",
      "[134]\tvalid_0's tweedie: 819.839\n",
      "[135]\tvalid_0's tweedie: 819.839\n",
      "[136]\tvalid_0's tweedie: 819.84\n",
      "[137]\tvalid_0's tweedie: 819.838\n",
      "[138]\tvalid_0's tweedie: 819.838\n",
      "[139]\tvalid_0's tweedie: 819.837\n",
      "[140]\tvalid_0's tweedie: 819.837\n",
      "[141]\tvalid_0's tweedie: 819.837\n",
      "[142]\tvalid_0's tweedie: 819.839\n",
      "[143]\tvalid_0's tweedie: 819.839\n",
      "[144]\tvalid_0's tweedie: 819.839\n",
      "[145]\tvalid_0's tweedie: 819.838\n",
      "[146]\tvalid_0's tweedie: 819.837\n",
      "[147]\tvalid_0's tweedie: 819.838\n",
      "[148]\tvalid_0's tweedie: 819.838\n",
      "[149]\tvalid_0's tweedie: 819.838\n",
      "[150]\tvalid_0's tweedie: 819.838\n",
      "[151]\tvalid_0's tweedie: 819.838\n",
      "[152]\tvalid_0's tweedie: 819.839\n",
      "[153]\tvalid_0's tweedie: 819.839\n",
      "[154]\tvalid_0's tweedie: 819.839\n",
      "[155]\tvalid_0's tweedie: 819.839\n",
      "[156]\tvalid_0's tweedie: 819.839\n",
      "[157]\tvalid_0's tweedie: 819.839\n",
      "[158]\tvalid_0's tweedie: 819.841\n",
      "[159]\tvalid_0's tweedie: 819.843\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's tweedie: 819.837\n",
      "Training model for level 1 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1849, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445316\n",
      "[1]\tvalid_0's tweedie: 825.841\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.005\n",
      "[3]\tvalid_0's tweedie: 824.301\n",
      "[4]\tvalid_0's tweedie: 823.686\n",
      "[5]\tvalid_0's tweedie: 823.28\n",
      "[6]\tvalid_0's tweedie: 822.837\n",
      "[7]\tvalid_0's tweedie: 822.541\n",
      "[8]\tvalid_0's tweedie: 822.199\n",
      "[9]\tvalid_0's tweedie: 822.001\n",
      "[10]\tvalid_0's tweedie: 821.738\n",
      "[11]\tvalid_0's tweedie: 821.535\n",
      "[12]\tvalid_0's tweedie: 821.371\n",
      "[13]\tvalid_0's tweedie: 821.217\n",
      "[14]\tvalid_0's tweedie: 821.052\n",
      "[15]\tvalid_0's tweedie: 820.943\n",
      "[16]\tvalid_0's tweedie: 820.858\n",
      "[17]\tvalid_0's tweedie: 820.765\n",
      "[18]\tvalid_0's tweedie: 820.708\n",
      "[19]\tvalid_0's tweedie: 820.646\n",
      "[20]\tvalid_0's tweedie: 820.582\n",
      "[21]\tvalid_0's tweedie: 820.52\n",
      "[22]\tvalid_0's tweedie: 820.458\n",
      "[23]\tvalid_0's tweedie: 820.407\n",
      "[24]\tvalid_0's tweedie: 820.387\n",
      "[25]\tvalid_0's tweedie: 820.378\n",
      "[26]\tvalid_0's tweedie: 820.328\n",
      "[27]\tvalid_0's tweedie: 820.29\n",
      "[28]\tvalid_0's tweedie: 820.259\n",
      "[29]\tvalid_0's tweedie: 820.231\n",
      "[30]\tvalid_0's tweedie: 820.203\n",
      "[31]\tvalid_0's tweedie: 820.181\n",
      "[32]\tvalid_0's tweedie: 820.158\n",
      "[33]\tvalid_0's tweedie: 820.145\n",
      "[34]\tvalid_0's tweedie: 820.127\n",
      "[35]\tvalid_0's tweedie: 820.121\n",
      "[36]\tvalid_0's tweedie: 820.106\n",
      "[37]\tvalid_0's tweedie: 820.091\n",
      "[38]\tvalid_0's tweedie: 820.079\n",
      "[39]\tvalid_0's tweedie: 820.077\n",
      "[40]\tvalid_0's tweedie: 820.085\n",
      "[41]\tvalid_0's tweedie: 820.07\n",
      "[42]\tvalid_0's tweedie: 820.065\n",
      "[43]\tvalid_0's tweedie: 820.061\n",
      "[44]\tvalid_0's tweedie: 820.056\n",
      "[45]\tvalid_0's tweedie: 820.051\n",
      "[46]\tvalid_0's tweedie: 820.036\n",
      "[47]\tvalid_0's tweedie: 820.035\n",
      "[48]\tvalid_0's tweedie: 820.027\n",
      "[49]\tvalid_0's tweedie: 820.027\n",
      "[50]\tvalid_0's tweedie: 820.022\n",
      "[51]\tvalid_0's tweedie: 820.019\n",
      "[52]\tvalid_0's tweedie: 819.998\n",
      "[53]\tvalid_0's tweedie: 819.996\n",
      "[54]\tvalid_0's tweedie: 819.992\n",
      "[55]\tvalid_0's tweedie: 819.982\n",
      "[56]\tvalid_0's tweedie: 819.977\n",
      "[57]\tvalid_0's tweedie: 819.964\n",
      "[58]\tvalid_0's tweedie: 819.967\n",
      "[59]\tvalid_0's tweedie: 819.967\n",
      "[60]\tvalid_0's tweedie: 819.969\n",
      "[61]\tvalid_0's tweedie: 819.967\n",
      "[62]\tvalid_0's tweedie: 819.954\n",
      "[63]\tvalid_0's tweedie: 819.954\n",
      "[64]\tvalid_0's tweedie: 819.957\n",
      "[65]\tvalid_0's tweedie: 819.958\n",
      "[66]\tvalid_0's tweedie: 819.957\n",
      "[67]\tvalid_0's tweedie: 819.956\n",
      "[68]\tvalid_0's tweedie: 819.954\n",
      "[69]\tvalid_0's tweedie: 819.942\n",
      "[70]\tvalid_0's tweedie: 819.942\n",
      "[71]\tvalid_0's tweedie: 819.944\n",
      "[72]\tvalid_0's tweedie: 819.949\n",
      "[73]\tvalid_0's tweedie: 819.954\n",
      "[74]\tvalid_0's tweedie: 819.954\n",
      "[75]\tvalid_0's tweedie: 819.951\n",
      "[76]\tvalid_0's tweedie: 819.951\n",
      "[77]\tvalid_0's tweedie: 819.952\n",
      "[78]\tvalid_0's tweedie: 819.952\n",
      "[79]\tvalid_0's tweedie: 819.943\n",
      "[80]\tvalid_0's tweedie: 819.943\n",
      "[81]\tvalid_0's tweedie: 819.944\n",
      "[82]\tvalid_0's tweedie: 819.944\n",
      "[83]\tvalid_0's tweedie: 819.943\n",
      "[84]\tvalid_0's tweedie: 819.943\n",
      "[85]\tvalid_0's tweedie: 819.943\n",
      "[86]\tvalid_0's tweedie: 819.941\n",
      "[87]\tvalid_0's tweedie: 819.94\n",
      "[88]\tvalid_0's tweedie: 819.943\n",
      "[89]\tvalid_0's tweedie: 819.944\n",
      "[90]\tvalid_0's tweedie: 819.936\n",
      "[91]\tvalid_0's tweedie: 819.936\n",
      "[92]\tvalid_0's tweedie: 819.933\n",
      "[93]\tvalid_0's tweedie: 819.933\n",
      "[94]\tvalid_0's tweedie: 819.934\n",
      "[95]\tvalid_0's tweedie: 819.937\n",
      "[96]\tvalid_0's tweedie: 819.938\n",
      "[97]\tvalid_0's tweedie: 819.938\n",
      "[98]\tvalid_0's tweedie: 819.938\n",
      "[99]\tvalid_0's tweedie: 819.936\n",
      "[100]\tvalid_0's tweedie: 819.936\n",
      "[101]\tvalid_0's tweedie: 819.936\n",
      "[102]\tvalid_0's tweedie: 819.936\n",
      "[103]\tvalid_0's tweedie: 819.939\n",
      "[104]\tvalid_0's tweedie: 819.939\n",
      "[105]\tvalid_0's tweedie: 819.941\n",
      "[106]\tvalid_0's tweedie: 819.941\n",
      "[107]\tvalid_0's tweedie: 819.941\n",
      "[108]\tvalid_0's tweedie: 819.944\n",
      "[109]\tvalid_0's tweedie: 819.943\n",
      "[110]\tvalid_0's tweedie: 819.944\n",
      "[111]\tvalid_0's tweedie: 819.944\n",
      "[112]\tvalid_0's tweedie: 819.944\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's tweedie: 819.933\n",
      "Training model for level 1 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1848, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445308\n",
      "[1]\tvalid_0's tweedie: 825.841\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 825.006\n",
      "[3]\tvalid_0's tweedie: 824.302\n",
      "[4]\tvalid_0's tweedie: 823.687\n",
      "[5]\tvalid_0's tweedie: 823.279\n",
      "[6]\tvalid_0's tweedie: 822.833\n",
      "[7]\tvalid_0's tweedie: 822.538\n",
      "[8]\tvalid_0's tweedie: 822.196\n",
      "[9]\tvalid_0's tweedie: 821.903\n",
      "[10]\tvalid_0's tweedie: 821.664\n",
      "[11]\tvalid_0's tweedie: 821.454\n",
      "[12]\tvalid_0's tweedie: 821.283\n",
      "[13]\tvalid_0's tweedie: 821.102\n",
      "[14]\tvalid_0's tweedie: 820.97\n",
      "[15]\tvalid_0's tweedie: 820.869\n",
      "[16]\tvalid_0's tweedie: 820.779\n",
      "[17]\tvalid_0's tweedie: 820.706\n",
      "[18]\tvalid_0's tweedie: 820.631\n",
      "[19]\tvalid_0's tweedie: 820.557\n",
      "[20]\tvalid_0's tweedie: 820.499\n",
      "[21]\tvalid_0's tweedie: 820.466\n",
      "[22]\tvalid_0's tweedie: 820.425\n",
      "[23]\tvalid_0's tweedie: 820.388\n",
      "[24]\tvalid_0's tweedie: 820.36\n",
      "[25]\tvalid_0's tweedie: 820.393\n",
      "[26]\tvalid_0's tweedie: 820.377\n",
      "[27]\tvalid_0's tweedie: 820.403\n",
      "[28]\tvalid_0's tweedie: 820.377\n",
      "[29]\tvalid_0's tweedie: 820.336\n",
      "[30]\tvalid_0's tweedie: 820.306\n",
      "[31]\tvalid_0's tweedie: 820.288\n",
      "[32]\tvalid_0's tweedie: 820.27\n",
      "[33]\tvalid_0's tweedie: 820.259\n",
      "[34]\tvalid_0's tweedie: 820.236\n",
      "[35]\tvalid_0's tweedie: 820.217\n",
      "[36]\tvalid_0's tweedie: 820.212\n",
      "[37]\tvalid_0's tweedie: 820.185\n",
      "[38]\tvalid_0's tweedie: 820.171\n",
      "[39]\tvalid_0's tweedie: 820.165\n",
      "[40]\tvalid_0's tweedie: 820.145\n",
      "[41]\tvalid_0's tweedie: 820.136\n",
      "[42]\tvalid_0's tweedie: 820.128\n",
      "[43]\tvalid_0's tweedie: 820.121\n",
      "[44]\tvalid_0's tweedie: 820.118\n",
      "[45]\tvalid_0's tweedie: 820.117\n",
      "[46]\tvalid_0's tweedie: 820.109\n",
      "[47]\tvalid_0's tweedie: 820.09\n",
      "[48]\tvalid_0's tweedie: 820.086\n",
      "[49]\tvalid_0's tweedie: 820.083\n",
      "[50]\tvalid_0's tweedie: 820.081\n",
      "[51]\tvalid_0's tweedie: 820.082\n",
      "[52]\tvalid_0's tweedie: 820.07\n",
      "[53]\tvalid_0's tweedie: 820.068\n",
      "[54]\tvalid_0's tweedie: 820.062\n",
      "[55]\tvalid_0's tweedie: 820.046\n",
      "[56]\tvalid_0's tweedie: 820.041\n",
      "[57]\tvalid_0's tweedie: 820.041\n",
      "[58]\tvalid_0's tweedie: 820.038\n",
      "[59]\tvalid_0's tweedie: 820.038\n",
      "[60]\tvalid_0's tweedie: 820.039\n",
      "[61]\tvalid_0's tweedie: 820.034\n",
      "[62]\tvalid_0's tweedie: 820.022\n",
      "[63]\tvalid_0's tweedie: 820.025\n",
      "[64]\tvalid_0's tweedie: 820.024\n",
      "[65]\tvalid_0's tweedie: 820.02\n",
      "[66]\tvalid_0's tweedie: 820.011\n",
      "[67]\tvalid_0's tweedie: 820.011\n",
      "[68]\tvalid_0's tweedie: 820.011\n",
      "[69]\tvalid_0's tweedie: 820.011\n",
      "[70]\tvalid_0's tweedie: 820.011\n",
      "[71]\tvalid_0's tweedie: 820.01\n",
      "[72]\tvalid_0's tweedie: 820.009\n",
      "[73]\tvalid_0's tweedie: 820.003\n",
      "[74]\tvalid_0's tweedie: 820.007\n",
      "[75]\tvalid_0's tweedie: 820.006\n",
      "[76]\tvalid_0's tweedie: 820\n",
      "[77]\tvalid_0's tweedie: 819.995\n",
      "[78]\tvalid_0's tweedie: 819.993\n",
      "[79]\tvalid_0's tweedie: 819.993\n",
      "[80]\tvalid_0's tweedie: 819.986\n",
      "[81]\tvalid_0's tweedie: 819.983\n",
      "[82]\tvalid_0's tweedie: 819.982\n",
      "[83]\tvalid_0's tweedie: 819.983\n",
      "[84]\tvalid_0's tweedie: 819.982\n",
      "[85]\tvalid_0's tweedie: 819.985\n",
      "[86]\tvalid_0's tweedie: 819.986\n",
      "[87]\tvalid_0's tweedie: 819.986\n",
      "[88]\tvalid_0's tweedie: 819.986\n",
      "[89]\tvalid_0's tweedie: 819.982\n",
      "[90]\tvalid_0's tweedie: 819.982\n",
      "[91]\tvalid_0's tweedie: 819.978\n",
      "[92]\tvalid_0's tweedie: 819.98\n",
      "[93]\tvalid_0's tweedie: 819.982\n",
      "[94]\tvalid_0's tweedie: 819.983\n",
      "[95]\tvalid_0's tweedie: 819.982\n",
      "[96]\tvalid_0's tweedie: 819.979\n",
      "[97]\tvalid_0's tweedie: 819.978\n",
      "[98]\tvalid_0's tweedie: 819.976\n",
      "[99]\tvalid_0's tweedie: 819.975\n",
      "[100]\tvalid_0's tweedie: 819.976\n",
      "[101]\tvalid_0's tweedie: 819.976\n",
      "[102]\tvalid_0's tweedie: 819.977\n",
      "[103]\tvalid_0's tweedie: 819.975\n",
      "[104]\tvalid_0's tweedie: 819.973\n",
      "[105]\tvalid_0's tweedie: 819.973\n",
      "[106]\tvalid_0's tweedie: 819.973\n",
      "[107]\tvalid_0's tweedie: 819.975\n",
      "[108]\tvalid_0's tweedie: 819.976\n",
      "[109]\tvalid_0's tweedie: 819.977\n",
      "[110]\tvalid_0's tweedie: 819.98\n",
      "[111]\tvalid_0's tweedie: 819.983\n",
      "[112]\tvalid_0's tweedie: 819.984\n",
      "[113]\tvalid_0's tweedie: 819.976\n",
      "[114]\tvalid_0's tweedie: 819.976\n",
      "[115]\tvalid_0's tweedie: 819.976\n",
      "[116]\tvalid_0's tweedie: 819.976\n",
      "[117]\tvalid_0's tweedie: 819.975\n",
      "[118]\tvalid_0's tweedie: 819.976\n",
      "[119]\tvalid_0's tweedie: 819.978\n",
      "[120]\tvalid_0's tweedie: 819.974\n",
      "[121]\tvalid_0's tweedie: 819.974\n",
      "[122]\tvalid_0's tweedie: 819.974\n",
      "[123]\tvalid_0's tweedie: 819.974\n",
      "[124]\tvalid_0's tweedie: 819.974\n",
      "[125]\tvalid_0's tweedie: 819.974\n",
      "[126]\tvalid_0's tweedie: 819.973\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's tweedie: 819.973\n",
      "Training model for level 1 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1847, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445463\n",
      "[1]\tvalid_0's tweedie: 825.806\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.961\n",
      "[3]\tvalid_0's tweedie: 824.278\n",
      "[4]\tvalid_0's tweedie: 823.814\n",
      "[5]\tvalid_0's tweedie: 823.288\n",
      "[6]\tvalid_0's tweedie: 822.861\n",
      "[7]\tvalid_0's tweedie: 822.561\n",
      "[8]\tvalid_0's tweedie: 822.326\n",
      "[9]\tvalid_0's tweedie: 822.037\n",
      "[10]\tvalid_0's tweedie: 821.82\n",
      "[11]\tvalid_0's tweedie: 821.616\n",
      "[12]\tvalid_0's tweedie: 821.417\n",
      "[13]\tvalid_0's tweedie: 821.237\n",
      "[14]\tvalid_0's tweedie: 821.114\n",
      "[15]\tvalid_0's tweedie: 821.013\n",
      "[16]\tvalid_0's tweedie: 820.913\n",
      "[17]\tvalid_0's tweedie: 820.833\n",
      "[18]\tvalid_0's tweedie: 820.754\n",
      "[19]\tvalid_0's tweedie: 820.66\n",
      "[20]\tvalid_0's tweedie: 820.602\n",
      "[21]\tvalid_0's tweedie: 820.572\n",
      "[22]\tvalid_0's tweedie: 820.538\n",
      "[23]\tvalid_0's tweedie: 820.483\n",
      "[24]\tvalid_0's tweedie: 820.424\n",
      "[25]\tvalid_0's tweedie: 820.375\n",
      "[26]\tvalid_0's tweedie: 820.336\n",
      "[27]\tvalid_0's tweedie: 820.304\n",
      "[28]\tvalid_0's tweedie: 820.273\n",
      "[29]\tvalid_0's tweedie: 820.248\n",
      "[30]\tvalid_0's tweedie: 820.224\n",
      "[31]\tvalid_0's tweedie: 820.213\n",
      "[32]\tvalid_0's tweedie: 820.184\n",
      "[33]\tvalid_0's tweedie: 820.172\n",
      "[34]\tvalid_0's tweedie: 820.155\n",
      "[35]\tvalid_0's tweedie: 820.142\n",
      "[36]\tvalid_0's tweedie: 820.126\n",
      "[37]\tvalid_0's tweedie: 820.113\n",
      "[38]\tvalid_0's tweedie: 820.102\n",
      "[39]\tvalid_0's tweedie: 820.091\n",
      "[40]\tvalid_0's tweedie: 820.091\n",
      "[41]\tvalid_0's tweedie: 820.087\n",
      "[42]\tvalid_0's tweedie: 820.069\n",
      "[43]\tvalid_0's tweedie: 820.06\n",
      "[44]\tvalid_0's tweedie: 820.06\n",
      "[45]\tvalid_0's tweedie: 820.059\n",
      "[46]\tvalid_0's tweedie: 820.049\n",
      "[47]\tvalid_0's tweedie: 820.048\n",
      "[48]\tvalid_0's tweedie: 820.046\n",
      "[49]\tvalid_0's tweedie: 820.04\n",
      "[50]\tvalid_0's tweedie: 820.036\n",
      "[51]\tvalid_0's tweedie: 820.022\n",
      "[52]\tvalid_0's tweedie: 820.013\n",
      "[53]\tvalid_0's tweedie: 820.005\n",
      "[54]\tvalid_0's tweedie: 819.998\n",
      "[55]\tvalid_0's tweedie: 819.989\n",
      "[56]\tvalid_0's tweedie: 819.988\n",
      "[57]\tvalid_0's tweedie: 819.982\n",
      "[58]\tvalid_0's tweedie: 819.972\n",
      "[59]\tvalid_0's tweedie: 819.972\n",
      "[60]\tvalid_0's tweedie: 819.971\n",
      "[61]\tvalid_0's tweedie: 819.961\n",
      "[62]\tvalid_0's tweedie: 819.966\n",
      "[63]\tvalid_0's tweedie: 819.967\n",
      "[64]\tvalid_0's tweedie: 819.962\n",
      "[65]\tvalid_0's tweedie: 819.96\n",
      "[66]\tvalid_0's tweedie: 819.959\n",
      "[67]\tvalid_0's tweedie: 819.949\n",
      "[68]\tvalid_0's tweedie: 819.947\n",
      "[69]\tvalid_0's tweedie: 819.945\n",
      "[70]\tvalid_0's tweedie: 819.944\n",
      "[71]\tvalid_0's tweedie: 819.944\n",
      "[72]\tvalid_0's tweedie: 819.944\n",
      "[73]\tvalid_0's tweedie: 819.939\n",
      "[74]\tvalid_0's tweedie: 819.932\n",
      "[75]\tvalid_0's tweedie: 819.932\n",
      "[76]\tvalid_0's tweedie: 819.935\n",
      "[77]\tvalid_0's tweedie: 819.935\n",
      "[78]\tvalid_0's tweedie: 819.935\n",
      "[79]\tvalid_0's tweedie: 819.933\n",
      "[80]\tvalid_0's tweedie: 819.926\n",
      "[81]\tvalid_0's tweedie: 819.925\n",
      "[82]\tvalid_0's tweedie: 819.923\n",
      "[83]\tvalid_0's tweedie: 819.921\n",
      "[84]\tvalid_0's tweedie: 819.92\n",
      "[85]\tvalid_0's tweedie: 819.92\n",
      "[86]\tvalid_0's tweedie: 819.921\n",
      "[87]\tvalid_0's tweedie: 819.916\n",
      "[88]\tvalid_0's tweedie: 819.919\n",
      "[89]\tvalid_0's tweedie: 819.918\n",
      "[90]\tvalid_0's tweedie: 819.912\n",
      "[91]\tvalid_0's tweedie: 819.911\n",
      "[92]\tvalid_0's tweedie: 819.911\n",
      "[93]\tvalid_0's tweedie: 819.91\n",
      "[94]\tvalid_0's tweedie: 819.909\n",
      "[95]\tvalid_0's tweedie: 819.908\n",
      "[96]\tvalid_0's tweedie: 819.906\n",
      "[97]\tvalid_0's tweedie: 819.907\n",
      "[98]\tvalid_0's tweedie: 819.906\n",
      "[99]\tvalid_0's tweedie: 819.906\n",
      "[100]\tvalid_0's tweedie: 819.908\n",
      "[101]\tvalid_0's tweedie: 819.912\n",
      "[102]\tvalid_0's tweedie: 819.913\n",
      "[103]\tvalid_0's tweedie: 819.912\n",
      "[104]\tvalid_0's tweedie: 819.913\n",
      "[105]\tvalid_0's tweedie: 819.913\n",
      "[106]\tvalid_0's tweedie: 819.913\n",
      "[107]\tvalid_0's tweedie: 819.91\n",
      "[108]\tvalid_0's tweedie: 819.904\n",
      "[109]\tvalid_0's tweedie: 819.903\n",
      "[110]\tvalid_0's tweedie: 819.903\n",
      "[111]\tvalid_0's tweedie: 819.906\n",
      "[112]\tvalid_0's tweedie: 819.905\n",
      "[113]\tvalid_0's tweedie: 819.902\n",
      "[114]\tvalid_0's tweedie: 819.9\n",
      "[115]\tvalid_0's tweedie: 819.899\n",
      "[116]\tvalid_0's tweedie: 819.897\n",
      "[117]\tvalid_0's tweedie: 819.897\n",
      "[118]\tvalid_0's tweedie: 819.897\n",
      "[119]\tvalid_0's tweedie: 819.896\n",
      "[120]\tvalid_0's tweedie: 819.895\n",
      "[121]\tvalid_0's tweedie: 819.889\n",
      "[122]\tvalid_0's tweedie: 819.889\n",
      "[123]\tvalid_0's tweedie: 819.889\n",
      "[124]\tvalid_0's tweedie: 819.889\n",
      "[125]\tvalid_0's tweedie: 819.892\n",
      "[126]\tvalid_0's tweedie: 819.892\n",
      "[127]\tvalid_0's tweedie: 819.89\n",
      "[128]\tvalid_0's tweedie: 819.892\n",
      "[129]\tvalid_0's tweedie: 819.892\n",
      "[130]\tvalid_0's tweedie: 819.892\n",
      "[131]\tvalid_0's tweedie: 819.894\n",
      "[132]\tvalid_0's tweedie: 819.891\n",
      "[133]\tvalid_0's tweedie: 819.891\n",
      "[134]\tvalid_0's tweedie: 819.891\n",
      "[135]\tvalid_0's tweedie: 819.89\n",
      "[136]\tvalid_0's tweedie: 819.888\n",
      "[137]\tvalid_0's tweedie: 819.887\n",
      "[138]\tvalid_0's tweedie: 819.887\n",
      "[139]\tvalid_0's tweedie: 819.887\n",
      "[140]\tvalid_0's tweedie: 819.887\n",
      "[141]\tvalid_0's tweedie: 819.885\n",
      "[142]\tvalid_0's tweedie: 819.885\n",
      "[143]\tvalid_0's tweedie: 819.886\n",
      "[144]\tvalid_0's tweedie: 819.887\n",
      "[145]\tvalid_0's tweedie: 819.885\n",
      "[146]\tvalid_0's tweedie: 819.884\n",
      "[147]\tvalid_0's tweedie: 819.884\n",
      "[148]\tvalid_0's tweedie: 819.884\n",
      "[149]\tvalid_0's tweedie: 819.885\n",
      "[150]\tvalid_0's tweedie: 819.887\n",
      "[151]\tvalid_0's tweedie: 819.887\n",
      "[152]\tvalid_0's tweedie: 819.887\n",
      "[153]\tvalid_0's tweedie: 819.887\n",
      "[154]\tvalid_0's tweedie: 819.883\n",
      "[155]\tvalid_0's tweedie: 819.883\n",
      "[156]\tvalid_0's tweedie: 819.881\n",
      "[157]\tvalid_0's tweedie: 819.878\n",
      "[158]\tvalid_0's tweedie: 819.878\n",
      "[159]\tvalid_0's tweedie: 819.879\n",
      "[160]\tvalid_0's tweedie: 819.879\n",
      "[161]\tvalid_0's tweedie: 819.879\n",
      "[162]\tvalid_0's tweedie: 819.879\n",
      "[163]\tvalid_0's tweedie: 819.878\n",
      "[164]\tvalid_0's tweedie: 819.879\n",
      "[165]\tvalid_0's tweedie: 819.878\n",
      "[166]\tvalid_0's tweedie: 819.878\n",
      "[167]\tvalid_0's tweedie: 819.878\n",
      "[168]\tvalid_0's tweedie: 819.878\n",
      "[169]\tvalid_0's tweedie: 819.878\n",
      "[170]\tvalid_0's tweedie: 819.876\n",
      "[171]\tvalid_0's tweedie: 819.876\n",
      "[172]\tvalid_0's tweedie: 819.876\n",
      "[173]\tvalid_0's tweedie: 819.876\n",
      "[174]\tvalid_0's tweedie: 819.874\n",
      "[175]\tvalid_0's tweedie: 819.874\n",
      "[176]\tvalid_0's tweedie: 819.874\n",
      "[177]\tvalid_0's tweedie: 819.874\n",
      "[178]\tvalid_0's tweedie: 819.872\n",
      "[179]\tvalid_0's tweedie: 819.873\n",
      "[180]\tvalid_0's tweedie: 819.872\n",
      "[181]\tvalid_0's tweedie: 819.87\n",
      "[182]\tvalid_0's tweedie: 819.87\n",
      "[183]\tvalid_0's tweedie: 819.87\n",
      "[184]\tvalid_0's tweedie: 819.87\n",
      "[185]\tvalid_0's tweedie: 819.87\n",
      "[186]\tvalid_0's tweedie: 819.872\n",
      "[187]\tvalid_0's tweedie: 819.871\n",
      "[188]\tvalid_0's tweedie: 819.873\n",
      "[189]\tvalid_0's tweedie: 819.875\n",
      "[190]\tvalid_0's tweedie: 819.873\n",
      "[191]\tvalid_0's tweedie: 819.873\n",
      "[192]\tvalid_0's tweedie: 819.873\n",
      "[193]\tvalid_0's tweedie: 819.873\n",
      "[194]\tvalid_0's tweedie: 819.873\n",
      "[195]\tvalid_0's tweedie: 819.873\n",
      "[196]\tvalid_0's tweedie: 819.872\n",
      "[197]\tvalid_0's tweedie: 819.872\n",
      "[198]\tvalid_0's tweedie: 819.872\n",
      "[199]\tvalid_0's tweedie: 819.872\n",
      "[200]\tvalid_0's tweedie: 819.871\n",
      "[201]\tvalid_0's tweedie: 819.871\n",
      "[202]\tvalid_0's tweedie: 819.871\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's tweedie: 819.87\n",
      "Training model for level 1 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1846, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445646\n",
      "[1]\tvalid_0's tweedie: 825.802\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.961\n",
      "[3]\tvalid_0's tweedie: 824.246\n",
      "[4]\tvalid_0's tweedie: 823.79\n",
      "[5]\tvalid_0's tweedie: 823.27\n",
      "[6]\tvalid_0's tweedie: 822.836\n",
      "[7]\tvalid_0's tweedie: 822.522\n",
      "[8]\tvalid_0's tweedie: 822.226\n",
      "[9]\tvalid_0's tweedie: 822.023\n",
      "[10]\tvalid_0's tweedie: 821.78\n",
      "[11]\tvalid_0's tweedie: 821.547\n",
      "[12]\tvalid_0's tweedie: 821.371\n",
      "[13]\tvalid_0's tweedie: 821.225\n",
      "[14]\tvalid_0's tweedie: 821.109\n",
      "[15]\tvalid_0's tweedie: 821.003\n",
      "[16]\tvalid_0's tweedie: 820.888\n",
      "[17]\tvalid_0's tweedie: 820.781\n",
      "[18]\tvalid_0's tweedie: 820.722\n",
      "[19]\tvalid_0's tweedie: 820.645\n",
      "[20]\tvalid_0's tweedie: 820.588\n",
      "[21]\tvalid_0's tweedie: 820.555\n",
      "[22]\tvalid_0's tweedie: 820.509\n",
      "[23]\tvalid_0's tweedie: 820.456\n",
      "[24]\tvalid_0's tweedie: 820.411\n",
      "[25]\tvalid_0's tweedie: 820.433\n",
      "[26]\tvalid_0's tweedie: 820.428\n",
      "[27]\tvalid_0's tweedie: 820.413\n",
      "[28]\tvalid_0's tweedie: 820.388\n",
      "[29]\tvalid_0's tweedie: 820.369\n",
      "[30]\tvalid_0's tweedie: 820.353\n",
      "[31]\tvalid_0's tweedie: 820.317\n",
      "[32]\tvalid_0's tweedie: 820.292\n",
      "[33]\tvalid_0's tweedie: 820.283\n",
      "[34]\tvalid_0's tweedie: 820.251\n",
      "[35]\tvalid_0's tweedie: 820.242\n",
      "[36]\tvalid_0's tweedie: 820.236\n",
      "[37]\tvalid_0's tweedie: 820.222\n",
      "[38]\tvalid_0's tweedie: 820.205\n",
      "[39]\tvalid_0's tweedie: 820.187\n",
      "[40]\tvalid_0's tweedie: 820.173\n",
      "[41]\tvalid_0's tweedie: 820.161\n",
      "[42]\tvalid_0's tweedie: 820.159\n",
      "[43]\tvalid_0's tweedie: 820.14\n",
      "[44]\tvalid_0's tweedie: 820.133\n",
      "[45]\tvalid_0's tweedie: 820.132\n",
      "[46]\tvalid_0's tweedie: 820.129\n",
      "[47]\tvalid_0's tweedie: 820.128\n",
      "[48]\tvalid_0's tweedie: 820.128\n",
      "[49]\tvalid_0's tweedie: 820.124\n",
      "[50]\tvalid_0's tweedie: 820.121\n",
      "[51]\tvalid_0's tweedie: 820.114\n",
      "[52]\tvalid_0's tweedie: 820.11\n",
      "[53]\tvalid_0's tweedie: 820.108\n",
      "[54]\tvalid_0's tweedie: 820.107\n",
      "[55]\tvalid_0's tweedie: 820.113\n",
      "[56]\tvalid_0's tweedie: 820.103\n",
      "[57]\tvalid_0's tweedie: 820.099\n",
      "[58]\tvalid_0's tweedie: 820.094\n",
      "[59]\tvalid_0's tweedie: 820.093\n",
      "[60]\tvalid_0's tweedie: 820.091\n",
      "[61]\tvalid_0's tweedie: 820.089\n",
      "[62]\tvalid_0's tweedie: 820.094\n",
      "[63]\tvalid_0's tweedie: 820.084\n",
      "[64]\tvalid_0's tweedie: 820.083\n",
      "[65]\tvalid_0's tweedie: 820.078\n",
      "[66]\tvalid_0's tweedie: 820.078\n",
      "[67]\tvalid_0's tweedie: 820.077\n",
      "[68]\tvalid_0's tweedie: 820.08\n",
      "[69]\tvalid_0's tweedie: 820.078\n",
      "[70]\tvalid_0's tweedie: 820.077\n",
      "[71]\tvalid_0's tweedie: 820.076\n",
      "[72]\tvalid_0's tweedie: 820.08\n",
      "[73]\tvalid_0's tweedie: 820.07\n",
      "[74]\tvalid_0's tweedie: 820.07\n",
      "[75]\tvalid_0's tweedie: 820.07\n",
      "[76]\tvalid_0's tweedie: 820.059\n",
      "[77]\tvalid_0's tweedie: 820.056\n",
      "[78]\tvalid_0's tweedie: 820.054\n",
      "[79]\tvalid_0's tweedie: 820.057\n",
      "[80]\tvalid_0's tweedie: 820.056\n",
      "[81]\tvalid_0's tweedie: 820.057\n",
      "[82]\tvalid_0's tweedie: 820.057\n",
      "[83]\tvalid_0's tweedie: 820.058\n",
      "[84]\tvalid_0's tweedie: 820.058\n",
      "[85]\tvalid_0's tweedie: 820.057\n",
      "[86]\tvalid_0's tweedie: 820.052\n",
      "[87]\tvalid_0's tweedie: 820.052\n",
      "[88]\tvalid_0's tweedie: 820.052\n",
      "[89]\tvalid_0's tweedie: 820.052\n",
      "[90]\tvalid_0's tweedie: 820.052\n",
      "[91]\tvalid_0's tweedie: 820.052\n",
      "[92]\tvalid_0's tweedie: 820.055\n",
      "[93]\tvalid_0's tweedie: 820.056\n",
      "[94]\tvalid_0's tweedie: 820.059\n",
      "[95]\tvalid_0's tweedie: 820.057\n",
      "[96]\tvalid_0's tweedie: 820.047\n",
      "[97]\tvalid_0's tweedie: 820.048\n",
      "[98]\tvalid_0's tweedie: 820.047\n",
      "[99]\tvalid_0's tweedie: 820.048\n",
      "[100]\tvalid_0's tweedie: 820.056\n",
      "[101]\tvalid_0's tweedie: 820.056\n",
      "[102]\tvalid_0's tweedie: 820.057\n",
      "[103]\tvalid_0's tweedie: 820.055\n",
      "[104]\tvalid_0's tweedie: 820.056\n",
      "[105]\tvalid_0's tweedie: 820.051\n",
      "[106]\tvalid_0's tweedie: 820.05\n",
      "[107]\tvalid_0's tweedie: 820.042\n",
      "[108]\tvalid_0's tweedie: 820.043\n",
      "[109]\tvalid_0's tweedie: 820.043\n",
      "[110]\tvalid_0's tweedie: 820.043\n",
      "[111]\tvalid_0's tweedie: 820.042\n",
      "[112]\tvalid_0's tweedie: 820.042\n",
      "[113]\tvalid_0's tweedie: 820.049\n",
      "[114]\tvalid_0's tweedie: 820.05\n",
      "[115]\tvalid_0's tweedie: 820.044\n",
      "[116]\tvalid_0's tweedie: 820.045\n",
      "[117]\tvalid_0's tweedie: 820.045\n",
      "[118]\tvalid_0's tweedie: 820.044\n",
      "[119]\tvalid_0's tweedie: 820.041\n",
      "[120]\tvalid_0's tweedie: 820.041\n",
      "[121]\tvalid_0's tweedie: 820.037\n",
      "[122]\tvalid_0's tweedie: 820.037\n",
      "[123]\tvalid_0's tweedie: 820.037\n",
      "[124]\tvalid_0's tweedie: 820.04\n",
      "[125]\tvalid_0's tweedie: 820.04\n",
      "[126]\tvalid_0's tweedie: 820.043\n",
      "[127]\tvalid_0's tweedie: 820.043\n",
      "[128]\tvalid_0's tweedie: 820.042\n",
      "[129]\tvalid_0's tweedie: 820.042\n",
      "[130]\tvalid_0's tweedie: 820.043\n",
      "[131]\tvalid_0's tweedie: 820.043\n",
      "[132]\tvalid_0's tweedie: 820.048\n",
      "[133]\tvalid_0's tweedie: 820.046\n",
      "[134]\tvalid_0's tweedie: 820.047\n",
      "[135]\tvalid_0's tweedie: 820.049\n",
      "[136]\tvalid_0's tweedie: 820.049\n",
      "[137]\tvalid_0's tweedie: 820.047\n",
      "[138]\tvalid_0's tweedie: 820.046\n",
      "[139]\tvalid_0's tweedie: 820.046\n",
      "[140]\tvalid_0's tweedie: 820.045\n",
      "[141]\tvalid_0's tweedie: 820.045\n",
      "[142]\tvalid_0's tweedie: 820.044\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's tweedie: 820.037\n",
      "Training model for level 1 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1845, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.445833\n",
      "[1]\tvalid_0's tweedie: 825.793\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.95\n",
      "[3]\tvalid_0's tweedie: 824.225\n",
      "[4]\tvalid_0's tweedie: 823.774\n",
      "[5]\tvalid_0's tweedie: 823.26\n",
      "[6]\tvalid_0's tweedie: 822.827\n",
      "[7]\tvalid_0's tweedie: 822.528\n",
      "[8]\tvalid_0's tweedie: 822.229\n",
      "[9]\tvalid_0's tweedie: 822.03\n",
      "[10]\tvalid_0's tweedie: 821.789\n",
      "[11]\tvalid_0's tweedie: 821.563\n",
      "[12]\tvalid_0's tweedie: 821.395\n",
      "[13]\tvalid_0's tweedie: 821.237\n",
      "[14]\tvalid_0's tweedie: 821.092\n",
      "[15]\tvalid_0's tweedie: 820.981\n",
      "[16]\tvalid_0's tweedie: 820.894\n",
      "[17]\tvalid_0's tweedie: 820.802\n",
      "[18]\tvalid_0's tweedie: 820.726\n",
      "[19]\tvalid_0's tweedie: 820.658\n",
      "[20]\tvalid_0's tweedie: 820.608\n",
      "[21]\tvalid_0's tweedie: 820.538\n",
      "[22]\tvalid_0's tweedie: 820.48\n",
      "[23]\tvalid_0's tweedie: 820.451\n",
      "[24]\tvalid_0's tweedie: 820.425\n",
      "[25]\tvalid_0's tweedie: 820.396\n",
      "[26]\tvalid_0's tweedie: 820.371\n",
      "[27]\tvalid_0's tweedie: 820.342\n",
      "[28]\tvalid_0's tweedie: 820.337\n",
      "[29]\tvalid_0's tweedie: 820.366\n",
      "[30]\tvalid_0's tweedie: 820.333\n",
      "[31]\tvalid_0's tweedie: 820.312\n",
      "[32]\tvalid_0's tweedie: 820.29\n",
      "[33]\tvalid_0's tweedie: 820.273\n",
      "[34]\tvalid_0's tweedie: 820.264\n",
      "[35]\tvalid_0's tweedie: 820.238\n",
      "[36]\tvalid_0's tweedie: 820.227\n",
      "[37]\tvalid_0's tweedie: 820.203\n",
      "[38]\tvalid_0's tweedie: 820.192\n",
      "[39]\tvalid_0's tweedie: 820.18\n",
      "[40]\tvalid_0's tweedie: 820.178\n",
      "[41]\tvalid_0's tweedie: 820.175\n",
      "[42]\tvalid_0's tweedie: 820.156\n",
      "[43]\tvalid_0's tweedie: 820.152\n",
      "[44]\tvalid_0's tweedie: 820.137\n",
      "[45]\tvalid_0's tweedie: 820.136\n",
      "[46]\tvalid_0's tweedie: 820.136\n",
      "[47]\tvalid_0's tweedie: 820.137\n",
      "[48]\tvalid_0's tweedie: 820.124\n",
      "[49]\tvalid_0's tweedie: 820.116\n",
      "[50]\tvalid_0's tweedie: 820.112\n",
      "[51]\tvalid_0's tweedie: 820.105\n",
      "[52]\tvalid_0's tweedie: 820.107\n",
      "[53]\tvalid_0's tweedie: 820.102\n",
      "[54]\tvalid_0's tweedie: 820.086\n",
      "[55]\tvalid_0's tweedie: 820.084\n",
      "[56]\tvalid_0's tweedie: 820.08\n",
      "[57]\tvalid_0's tweedie: 820.079\n",
      "[58]\tvalid_0's tweedie: 820.077\n",
      "[59]\tvalid_0's tweedie: 820.07\n",
      "[60]\tvalid_0's tweedie: 820.064\n",
      "[61]\tvalid_0's tweedie: 820.069\n",
      "[62]\tvalid_0's tweedie: 820.064\n",
      "[63]\tvalid_0's tweedie: 820.063\n",
      "[64]\tvalid_0's tweedie: 820.064\n",
      "[65]\tvalid_0's tweedie: 820.055\n",
      "[66]\tvalid_0's tweedie: 820.059\n",
      "[67]\tvalid_0's tweedie: 820.055\n",
      "[68]\tvalid_0's tweedie: 820.053\n",
      "[69]\tvalid_0's tweedie: 820.044\n",
      "[70]\tvalid_0's tweedie: 820.043\n",
      "[71]\tvalid_0's tweedie: 820.038\n",
      "[72]\tvalid_0's tweedie: 820.042\n",
      "[73]\tvalid_0's tweedie: 820.044\n",
      "[74]\tvalid_0's tweedie: 820.044\n",
      "[75]\tvalid_0's tweedie: 820.037\n",
      "[76]\tvalid_0's tweedie: 820.029\n",
      "[77]\tvalid_0's tweedie: 820.028\n",
      "[78]\tvalid_0's tweedie: 820.028\n",
      "[79]\tvalid_0's tweedie: 820.026\n",
      "[80]\tvalid_0's tweedie: 820.03\n",
      "[81]\tvalid_0's tweedie: 820.027\n",
      "[82]\tvalid_0's tweedie: 820.024\n",
      "[83]\tvalid_0's tweedie: 820.024\n",
      "[84]\tvalid_0's tweedie: 820.025\n",
      "[85]\tvalid_0's tweedie: 820.03\n",
      "[86]\tvalid_0's tweedie: 820.028\n",
      "[87]\tvalid_0's tweedie: 820.028\n",
      "[88]\tvalid_0's tweedie: 820.029\n",
      "[89]\tvalid_0's tweedie: 820.037\n",
      "[90]\tvalid_0's tweedie: 820.036\n",
      "[91]\tvalid_0's tweedie: 820.034\n",
      "[92]\tvalid_0's tweedie: 820.029\n",
      "[93]\tvalid_0's tweedie: 820.028\n",
      "[94]\tvalid_0's tweedie: 820.026\n",
      "[95]\tvalid_0's tweedie: 820.023\n",
      "[96]\tvalid_0's tweedie: 820.026\n",
      "[97]\tvalid_0's tweedie: 820.027\n",
      "[98]\tvalid_0's tweedie: 820.028\n",
      "[99]\tvalid_0's tweedie: 820.026\n",
      "[100]\tvalid_0's tweedie: 820.024\n",
      "[101]\tvalid_0's tweedie: 820.021\n",
      "[102]\tvalid_0's tweedie: 820.017\n",
      "[103]\tvalid_0's tweedie: 820.013\n",
      "[104]\tvalid_0's tweedie: 820.015\n",
      "[105]\tvalid_0's tweedie: 820.013\n",
      "[106]\tvalid_0's tweedie: 820.011\n",
      "[107]\tvalid_0's tweedie: 820.009\n",
      "[108]\tvalid_0's tweedie: 820.01\n",
      "[109]\tvalid_0's tweedie: 820.015\n",
      "[110]\tvalid_0's tweedie: 820.013\n",
      "[111]\tvalid_0's tweedie: 820.01\n",
      "[112]\tvalid_0's tweedie: 820.003\n",
      "[113]\tvalid_0's tweedie: 819.999\n",
      "[114]\tvalid_0's tweedie: 819.999\n",
      "[115]\tvalid_0's tweedie: 820\n",
      "[116]\tvalid_0's tweedie: 820.005\n",
      "[117]\tvalid_0's tweedie: 820.002\n",
      "[118]\tvalid_0's tweedie: 820\n",
      "[119]\tvalid_0's tweedie: 819.999\n",
      "[120]\tvalid_0's tweedie: 819.995\n",
      "[121]\tvalid_0's tweedie: 819.991\n",
      "[122]\tvalid_0's tweedie: 819.991\n",
      "[123]\tvalid_0's tweedie: 819.987\n",
      "[124]\tvalid_0's tweedie: 819.987\n",
      "[125]\tvalid_0's tweedie: 819.99\n",
      "[126]\tvalid_0's tweedie: 819.988\n",
      "[127]\tvalid_0's tweedie: 819.987\n",
      "[128]\tvalid_0's tweedie: 819.982\n",
      "[129]\tvalid_0's tweedie: 819.982\n",
      "[130]\tvalid_0's tweedie: 819.982\n",
      "[131]\tvalid_0's tweedie: 819.982\n",
      "[132]\tvalid_0's tweedie: 819.982\n",
      "[133]\tvalid_0's tweedie: 819.982\n",
      "[134]\tvalid_0's tweedie: 819.986\n",
      "[135]\tvalid_0's tweedie: 819.986\n",
      "[136]\tvalid_0's tweedie: 819.988\n",
      "[137]\tvalid_0's tweedie: 819.989\n",
      "[138]\tvalid_0's tweedie: 819.988\n",
      "[139]\tvalid_0's tweedie: 819.988\n",
      "[140]\tvalid_0's tweedie: 819.991\n",
      "[141]\tvalid_0's tweedie: 819.988\n",
      "[142]\tvalid_0's tweedie: 819.988\n",
      "[143]\tvalid_0's tweedie: 819.984\n",
      "[144]\tvalid_0's tweedie: 819.988\n",
      "[145]\tvalid_0's tweedie: 819.985\n",
      "[146]\tvalid_0's tweedie: 819.983\n",
      "[147]\tvalid_0's tweedie: 819.982\n",
      "[148]\tvalid_0's tweedie: 819.981\n",
      "[149]\tvalid_0's tweedie: 819.978\n",
      "[150]\tvalid_0's tweedie: 819.978\n",
      "[151]\tvalid_0's tweedie: 819.979\n",
      "[152]\tvalid_0's tweedie: 819.975\n",
      "[153]\tvalid_0's tweedie: 819.975\n",
      "[154]\tvalid_0's tweedie: 819.976\n",
      "[155]\tvalid_0's tweedie: 819.978\n",
      "[156]\tvalid_0's tweedie: 819.976\n",
      "[157]\tvalid_0's tweedie: 819.975\n",
      "[158]\tvalid_0's tweedie: 819.978\n",
      "[159]\tvalid_0's tweedie: 819.976\n",
      "[160]\tvalid_0's tweedie: 819.974\n",
      "[161]\tvalid_0's tweedie: 819.972\n",
      "[162]\tvalid_0's tweedie: 819.973\n",
      "[163]\tvalid_0's tweedie: 819.978\n",
      "[164]\tvalid_0's tweedie: 819.976\n",
      "[165]\tvalid_0's tweedie: 819.975\n",
      "[166]\tvalid_0's tweedie: 819.974\n",
      "[167]\tvalid_0's tweedie: 819.973\n",
      "[168]\tvalid_0's tweedie: 819.974\n",
      "[169]\tvalid_0's tweedie: 819.974\n",
      "[170]\tvalid_0's tweedie: 819.978\n",
      "[171]\tvalid_0's tweedie: 819.974\n",
      "[172]\tvalid_0's tweedie: 819.973\n",
      "[173]\tvalid_0's tweedie: 819.972\n",
      "[174]\tvalid_0's tweedie: 819.97\n",
      "[175]\tvalid_0's tweedie: 819.969\n",
      "[176]\tvalid_0's tweedie: 819.97\n",
      "[177]\tvalid_0's tweedie: 819.973\n",
      "[178]\tvalid_0's tweedie: 819.973\n",
      "[179]\tvalid_0's tweedie: 819.973\n",
      "[180]\tvalid_0's tweedie: 819.972\n",
      "[181]\tvalid_0's tweedie: 819.972\n",
      "[182]\tvalid_0's tweedie: 819.969\n",
      "[183]\tvalid_0's tweedie: 819.969\n",
      "[184]\tvalid_0's tweedie: 819.971\n",
      "[185]\tvalid_0's tweedie: 819.969\n",
      "[186]\tvalid_0's tweedie: 819.965\n",
      "[187]\tvalid_0's tweedie: 819.964\n",
      "[188]\tvalid_0's tweedie: 819.966\n",
      "[189]\tvalid_0's tweedie: 819.963\n",
      "[190]\tvalid_0's tweedie: 819.959\n",
      "[191]\tvalid_0's tweedie: 819.966\n",
      "[192]\tvalid_0's tweedie: 819.964\n",
      "[193]\tvalid_0's tweedie: 819.963\n",
      "[194]\tvalid_0's tweedie: 819.961\n",
      "[195]\tvalid_0's tweedie: 819.958\n",
      "[196]\tvalid_0's tweedie: 819.961\n",
      "[197]\tvalid_0's tweedie: 819.959\n",
      "[198]\tvalid_0's tweedie: 819.958\n",
      "[199]\tvalid_0's tweedie: 819.957\n",
      "[200]\tvalid_0's tweedie: 819.955\n",
      "[201]\tvalid_0's tweedie: 819.956\n",
      "[202]\tvalid_0's tweedie: 819.96\n",
      "[203]\tvalid_0's tweedie: 819.959\n",
      "[204]\tvalid_0's tweedie: 819.958\n",
      "[205]\tvalid_0's tweedie: 819.957\n",
      "[206]\tvalid_0's tweedie: 819.955\n",
      "[207]\tvalid_0's tweedie: 819.954\n",
      "[208]\tvalid_0's tweedie: 819.958\n",
      "[209]\tvalid_0's tweedie: 819.955\n",
      "[210]\tvalid_0's tweedie: 819.955\n",
      "[211]\tvalid_0's tweedie: 819.955\n",
      "[212]\tvalid_0's tweedie: 819.955\n",
      "[213]\tvalid_0's tweedie: 819.955\n",
      "[214]\tvalid_0's tweedie: 819.958\n",
      "[215]\tvalid_0's tweedie: 819.957\n",
      "[216]\tvalid_0's tweedie: 819.955\n",
      "[217]\tvalid_0's tweedie: 819.954\n",
      "[218]\tvalid_0's tweedie: 819.954\n",
      "[219]\tvalid_0's tweedie: 819.953\n",
      "[220]\tvalid_0's tweedie: 819.952\n",
      "[221]\tvalid_0's tweedie: 819.955\n",
      "[222]\tvalid_0's tweedie: 819.954\n",
      "[223]\tvalid_0's tweedie: 819.952\n",
      "[224]\tvalid_0's tweedie: 819.951\n",
      "[225]\tvalid_0's tweedie: 819.951\n",
      "[226]\tvalid_0's tweedie: 819.955\n",
      "[227]\tvalid_0's tweedie: 819.953\n",
      "[228]\tvalid_0's tweedie: 819.953\n",
      "[229]\tvalid_0's tweedie: 819.954\n",
      "[230]\tvalid_0's tweedie: 819.953\n",
      "[231]\tvalid_0's tweedie: 819.957\n",
      "[232]\tvalid_0's tweedie: 819.956\n",
      "[233]\tvalid_0's tweedie: 819.956\n",
      "[234]\tvalid_0's tweedie: 819.954\n",
      "[235]\tvalid_0's tweedie: 819.953\n",
      "[236]\tvalid_0's tweedie: 819.952\n",
      "[237]\tvalid_0's tweedie: 819.952\n",
      "[238]\tvalid_0's tweedie: 819.955\n",
      "[239]\tvalid_0's tweedie: 819.954\n",
      "[240]\tvalid_0's tweedie: 819.954\n",
      "[241]\tvalid_0's tweedie: 819.953\n",
      "[242]\tvalid_0's tweedie: 819.953\n",
      "[243]\tvalid_0's tweedie: 819.956\n",
      "[244]\tvalid_0's tweedie: 819.955\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's tweedie: 819.951\n",
      "Training model for level 1 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/1/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1844, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 10.446018\n",
      "[1]\tvalid_0's tweedie: 825.787\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 824.944\n",
      "[3]\tvalid_0's tweedie: 824.221\n",
      "[4]\tvalid_0's tweedie: 823.725\n",
      "[5]\tvalid_0's tweedie: 823.243\n",
      "[6]\tvalid_0's tweedie: 822.81\n",
      "[7]\tvalid_0's tweedie: 822.514\n",
      "[8]\tvalid_0's tweedie: 822.175\n",
      "[9]\tvalid_0's tweedie: 821.936\n",
      "[10]\tvalid_0's tweedie: 821.704\n",
      "[11]\tvalid_0's tweedie: 821.482\n",
      "[12]\tvalid_0's tweedie: 821.321\n",
      "[13]\tvalid_0's tweedie: 821.149\n",
      "[14]\tvalid_0's tweedie: 821.016\n",
      "[15]\tvalid_0's tweedie: 820.906\n",
      "[16]\tvalid_0's tweedie: 820.833\n",
      "[17]\tvalid_0's tweedie: 820.775\n",
      "[18]\tvalid_0's tweedie: 820.697\n",
      "[19]\tvalid_0's tweedie: 820.625\n",
      "[20]\tvalid_0's tweedie: 820.561\n",
      "[21]\tvalid_0's tweedie: 820.502\n",
      "[22]\tvalid_0's tweedie: 820.454\n",
      "[23]\tvalid_0's tweedie: 820.406\n",
      "[24]\tvalid_0's tweedie: 820.364\n",
      "[25]\tvalid_0's tweedie: 820.348\n",
      "[26]\tvalid_0's tweedie: 820.345\n",
      "[27]\tvalid_0's tweedie: 820.358\n",
      "[28]\tvalid_0's tweedie: 820.334\n",
      "[29]\tvalid_0's tweedie: 820.327\n",
      "[30]\tvalid_0's tweedie: 820.302\n",
      "[31]\tvalid_0's tweedie: 820.28\n",
      "[32]\tvalid_0's tweedie: 820.256\n",
      "[33]\tvalid_0's tweedie: 820.253\n",
      "[34]\tvalid_0's tweedie: 820.236\n",
      "[35]\tvalid_0's tweedie: 820.225\n",
      "[36]\tvalid_0's tweedie: 820.205\n",
      "[37]\tvalid_0's tweedie: 820.184\n",
      "[38]\tvalid_0's tweedie: 820.167\n",
      "[39]\tvalid_0's tweedie: 820.162\n",
      "[40]\tvalid_0's tweedie: 820.152\n",
      "[41]\tvalid_0's tweedie: 820.139\n",
      "[42]\tvalid_0's tweedie: 820.129\n",
      "[43]\tvalid_0's tweedie: 820.112\n",
      "[44]\tvalid_0's tweedie: 820.111\n",
      "[45]\tvalid_0's tweedie: 820.107\n",
      "[46]\tvalid_0's tweedie: 820.107\n",
      "[47]\tvalid_0's tweedie: 820.098\n",
      "[48]\tvalid_0's tweedie: 820.098\n",
      "[49]\tvalid_0's tweedie: 820.08\n",
      "[50]\tvalid_0's tweedie: 820.075\n",
      "[51]\tvalid_0's tweedie: 820.076\n",
      "[52]\tvalid_0's tweedie: 820.071\n",
      "[53]\tvalid_0's tweedie: 820.065\n",
      "[54]\tvalid_0's tweedie: 820.058\n",
      "[55]\tvalid_0's tweedie: 820.059\n",
      "[56]\tvalid_0's tweedie: 820.058\n",
      "[57]\tvalid_0's tweedie: 820.047\n",
      "[58]\tvalid_0's tweedie: 820.043\n",
      "[59]\tvalid_0's tweedie: 820.042\n",
      "[60]\tvalid_0's tweedie: 820.03\n",
      "[61]\tvalid_0's tweedie: 820.025\n",
      "[62]\tvalid_0's tweedie: 820.024\n",
      "[63]\tvalid_0's tweedie: 820.024\n",
      "[64]\tvalid_0's tweedie: 820.02\n",
      "[65]\tvalid_0's tweedie: 820.017\n",
      "[66]\tvalid_0's tweedie: 820.011\n",
      "[67]\tvalid_0's tweedie: 819.998\n",
      "[68]\tvalid_0's tweedie: 819.999\n",
      "[69]\tvalid_0's tweedie: 819.993\n",
      "[70]\tvalid_0's tweedie: 819.993\n",
      "[71]\tvalid_0's tweedie: 819.995\n",
      "[72]\tvalid_0's tweedie: 819.995\n",
      "[73]\tvalid_0's tweedie: 819.991\n",
      "[74]\tvalid_0's tweedie: 819.989\n",
      "[75]\tvalid_0's tweedie: 819.991\n",
      "[76]\tvalid_0's tweedie: 819.983\n",
      "[77]\tvalid_0's tweedie: 819.983\n",
      "[78]\tvalid_0's tweedie: 819.981\n",
      "[79]\tvalid_0's tweedie: 819.985\n",
      "[80]\tvalid_0's tweedie: 819.981\n",
      "[81]\tvalid_0's tweedie: 819.975\n",
      "[82]\tvalid_0's tweedie: 819.975\n",
      "[83]\tvalid_0's tweedie: 819.976\n",
      "[84]\tvalid_0's tweedie: 819.97\n",
      "[85]\tvalid_0's tweedie: 819.97\n",
      "[86]\tvalid_0's tweedie: 819.968\n",
      "[87]\tvalid_0's tweedie: 819.967\n",
      "[88]\tvalid_0's tweedie: 819.964\n",
      "[89]\tvalid_0's tweedie: 819.965\n",
      "[90]\tvalid_0's tweedie: 819.966\n",
      "[91]\tvalid_0's tweedie: 819.962\n",
      "[92]\tvalid_0's tweedie: 819.959\n",
      "[93]\tvalid_0's tweedie: 819.961\n",
      "[94]\tvalid_0's tweedie: 819.966\n",
      "[95]\tvalid_0's tweedie: 819.96\n",
      "[96]\tvalid_0's tweedie: 819.959\n",
      "[97]\tvalid_0's tweedie: 819.962\n",
      "[98]\tvalid_0's tweedie: 819.963\n",
      "[99]\tvalid_0's tweedie: 819.964\n",
      "[100]\tvalid_0's tweedie: 819.964\n",
      "[101]\tvalid_0's tweedie: 819.964\n",
      "[102]\tvalid_0's tweedie: 819.963\n",
      "[103]\tvalid_0's tweedie: 819.965\n",
      "[104]\tvalid_0's tweedie: 819.963\n",
      "[105]\tvalid_0's tweedie: 819.96\n",
      "[106]\tvalid_0's tweedie: 819.96\n",
      "[107]\tvalid_0's tweedie: 819.96\n",
      "[108]\tvalid_0's tweedie: 819.96\n",
      "[109]\tvalid_0's tweedie: 819.959\n",
      "[110]\tvalid_0's tweedie: 819.956\n",
      "[111]\tvalid_0's tweedie: 819.956\n",
      "[112]\tvalid_0's tweedie: 819.955\n",
      "[113]\tvalid_0's tweedie: 819.956\n",
      "[114]\tvalid_0's tweedie: 819.956\n",
      "[115]\tvalid_0's tweedie: 819.953\n",
      "[116]\tvalid_0's tweedie: 819.956\n",
      "[117]\tvalid_0's tweedie: 819.956\n",
      "[118]\tvalid_0's tweedie: 819.959\n",
      "[119]\tvalid_0's tweedie: 819.959\n",
      "[120]\tvalid_0's tweedie: 819.958\n",
      "[121]\tvalid_0's tweedie: 819.959\n",
      "[122]\tvalid_0's tweedie: 819.959\n",
      "[123]\tvalid_0's tweedie: 819.959\n",
      "[124]\tvalid_0's tweedie: 819.959\n",
      "[125]\tvalid_0's tweedie: 819.958\n",
      "[126]\tvalid_0's tweedie: 819.958\n",
      "[127]\tvalid_0's tweedie: 819.951\n",
      "[128]\tvalid_0's tweedie: 819.95\n",
      "[129]\tvalid_0's tweedie: 819.952\n",
      "[130]\tvalid_0's tweedie: 819.951\n",
      "[131]\tvalid_0's tweedie: 819.951\n",
      "[132]\tvalid_0's tweedie: 819.951\n",
      "[133]\tvalid_0's tweedie: 819.955\n",
      "[134]\tvalid_0's tweedie: 819.954\n",
      "[135]\tvalid_0's tweedie: 819.954\n",
      "[136]\tvalid_0's tweedie: 819.952\n",
      "[137]\tvalid_0's tweedie: 819.955\n",
      "[138]\tvalid_0's tweedie: 819.954\n",
      "[139]\tvalid_0's tweedie: 819.954\n",
      "[140]\tvalid_0's tweedie: 819.954\n",
      "[141]\tvalid_0's tweedie: 819.953\n",
      "[142]\tvalid_0's tweedie: 819.953\n",
      "[143]\tvalid_0's tweedie: 819.952\n",
      "[144]\tvalid_0's tweedie: 819.952\n",
      "[145]\tvalid_0's tweedie: 819.95\n",
      "[146]\tvalid_0's tweedie: 819.95\n",
      "[147]\tvalid_0's tweedie: 819.953\n",
      "[148]\tvalid_0's tweedie: 819.953\n",
      "[149]\tvalid_0's tweedie: 819.954\n",
      "[150]\tvalid_0's tweedie: 819.955\n",
      "[151]\tvalid_0's tweedie: 819.955\n",
      "[152]\tvalid_0's tweedie: 819.956\n",
      "[153]\tvalid_0's tweedie: 819.954\n",
      "[154]\tvalid_0's tweedie: 819.959\n",
      "[155]\tvalid_0's tweedie: 819.957\n",
      "[156]\tvalid_0's tweedie: 819.954\n",
      "[157]\tvalid_0's tweedie: 819.954\n",
      "[158]\tvalid_0's tweedie: 819.954\n",
      "[159]\tvalid_0's tweedie: 819.953\n",
      "[160]\tvalid_0's tweedie: 819.952\n",
      "[161]\tvalid_0's tweedie: 819.951\n",
      "[162]\tvalid_0's tweedie: 819.95\n",
      "[163]\tvalid_0's tweedie: 819.949\n",
      "[164]\tvalid_0's tweedie: 819.949\n",
      "[165]\tvalid_0's tweedie: 819.952\n",
      "[166]\tvalid_0's tweedie: 819.953\n",
      "[167]\tvalid_0's tweedie: 819.953\n",
      "[168]\tvalid_0's tweedie: 819.951\n",
      "[169]\tvalid_0's tweedie: 819.951\n",
      "[170]\tvalid_0's tweedie: 819.951\n",
      "[171]\tvalid_0's tweedie: 819.951\n",
      "[172]\tvalid_0's tweedie: 819.95\n",
      "[173]\tvalid_0's tweedie: 819.949\n",
      "[174]\tvalid_0's tweedie: 819.95\n",
      "[175]\tvalid_0's tweedie: 819.948\n",
      "[176]\tvalid_0's tweedie: 819.944\n",
      "[177]\tvalid_0's tweedie: 819.945\n",
      "[178]\tvalid_0's tweedie: 819.946\n",
      "[179]\tvalid_0's tweedie: 819.946\n",
      "[180]\tvalid_0's tweedie: 819.946\n",
      "[181]\tvalid_0's tweedie: 819.946\n",
      "[182]\tvalid_0's tweedie: 819.946\n",
      "[183]\tvalid_0's tweedie: 819.946\n",
      "[184]\tvalid_0's tweedie: 819.946\n",
      "[185]\tvalid_0's tweedie: 819.946\n",
      "[186]\tvalid_0's tweedie: 819.947\n",
      "[187]\tvalid_0's tweedie: 819.947\n",
      "[188]\tvalid_0's tweedie: 819.947\n",
      "[189]\tvalid_0's tweedie: 819.946\n",
      "[190]\tvalid_0's tweedie: 819.946\n",
      "[191]\tvalid_0's tweedie: 819.946\n",
      "[192]\tvalid_0's tweedie: 819.944\n",
      "[193]\tvalid_0's tweedie: 819.947\n",
      "[194]\tvalid_0's tweedie: 819.945\n",
      "[195]\tvalid_0's tweedie: 819.946\n",
      "[196]\tvalid_0's tweedie: 819.946\n",
      "[197]\tvalid_0's tweedie: 819.945\n",
      "[198]\tvalid_0's tweedie: 819.947\n",
      "[199]\tvalid_0's tweedie: 819.947\n",
      "[200]\tvalid_0's tweedie: 819.947\n",
      "[201]\tvalid_0's tweedie: 819.949\n",
      "[202]\tvalid_0's tweedie: 819.95\n",
      "[203]\tvalid_0's tweedie: 819.949\n",
      "[204]\tvalid_0's tweedie: 819.948\n",
      "[205]\tvalid_0's tweedie: 819.948\n",
      "[206]\tvalid_0's tweedie: 819.95\n",
      "[207]\tvalid_0's tweedie: 819.95\n",
      "[208]\tvalid_0's tweedie: 819.952\n",
      "[209]\tvalid_0's tweedie: 819.954\n",
      "[210]\tvalid_0's tweedie: 819.953\n",
      "[211]\tvalid_0's tweedie: 819.954\n",
      "[212]\tvalid_0's tweedie: 819.958\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's tweedie: 819.944\n",
      "Training model for level 2\n",
      "Training model for level 2 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 5613, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343561\n",
      "[1]\tvalid_0's tweedie: 476.357\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.473\n",
      "[3]\tvalid_0's tweedie: 474.702\n",
      "[4]\tvalid_0's tweedie: 474.081\n",
      "[5]\tvalid_0's tweedie: 473.58\n",
      "[6]\tvalid_0's tweedie: 473.155\n",
      "[7]\tvalid_0's tweedie: 472.819\n",
      "[8]\tvalid_0's tweedie: 472.53\n",
      "[9]\tvalid_0's tweedie: 472.27\n",
      "[10]\tvalid_0's tweedie: 472.06\n",
      "[11]\tvalid_0's tweedie: 471.883\n",
      "[12]\tvalid_0's tweedie: 471.729\n",
      "[13]\tvalid_0's tweedie: 471.611\n",
      "[14]\tvalid_0's tweedie: 471.526\n",
      "[15]\tvalid_0's tweedie: 471.436\n",
      "[16]\tvalid_0's tweedie: 471.362\n",
      "[17]\tvalid_0's tweedie: 471.301\n",
      "[18]\tvalid_0's tweedie: 471.249\n",
      "[19]\tvalid_0's tweedie: 471.202\n",
      "[20]\tvalid_0's tweedie: 471.163\n",
      "[21]\tvalid_0's tweedie: 471.131\n",
      "[22]\tvalid_0's tweedie: 471.099\n",
      "[23]\tvalid_0's tweedie: 471.074\n",
      "[24]\tvalid_0's tweedie: 471.049\n",
      "[25]\tvalid_0's tweedie: 471.033\n",
      "[26]\tvalid_0's tweedie: 471.016\n",
      "[27]\tvalid_0's tweedie: 471\n",
      "[28]\tvalid_0's tweedie: 470.994\n",
      "[29]\tvalid_0's tweedie: 470.983\n",
      "[30]\tvalid_0's tweedie: 470.966\n",
      "[31]\tvalid_0's tweedie: 470.957\n",
      "[32]\tvalid_0's tweedie: 470.949\n",
      "[33]\tvalid_0's tweedie: 470.944\n",
      "[34]\tvalid_0's tweedie: 470.935\n",
      "[35]\tvalid_0's tweedie: 470.924\n",
      "[36]\tvalid_0's tweedie: 470.913\n",
      "[37]\tvalid_0's tweedie: 470.903\n",
      "[38]\tvalid_0's tweedie: 470.896\n",
      "[39]\tvalid_0's tweedie: 470.888\n",
      "[40]\tvalid_0's tweedie: 470.885\n",
      "[41]\tvalid_0's tweedie: 470.88\n",
      "[42]\tvalid_0's tweedie: 470.874\n",
      "[43]\tvalid_0's tweedie: 470.875\n",
      "[44]\tvalid_0's tweedie: 470.872\n",
      "[45]\tvalid_0's tweedie: 470.869\n",
      "[46]\tvalid_0's tweedie: 470.866\n",
      "[47]\tvalid_0's tweedie: 470.863\n",
      "[48]\tvalid_0's tweedie: 470.861\n",
      "[49]\tvalid_0's tweedie: 470.86\n",
      "[50]\tvalid_0's tweedie: 470.857\n",
      "[51]\tvalid_0's tweedie: 470.856\n",
      "[52]\tvalid_0's tweedie: 470.856\n",
      "[53]\tvalid_0's tweedie: 470.854\n",
      "[54]\tvalid_0's tweedie: 470.85\n",
      "[55]\tvalid_0's tweedie: 470.849\n",
      "[56]\tvalid_0's tweedie: 470.846\n",
      "[57]\tvalid_0's tweedie: 470.847\n",
      "[58]\tvalid_0's tweedie: 470.844\n",
      "[59]\tvalid_0's tweedie: 470.841\n",
      "[60]\tvalid_0's tweedie: 470.842\n",
      "[61]\tvalid_0's tweedie: 470.841\n",
      "[62]\tvalid_0's tweedie: 470.841\n",
      "[63]\tvalid_0's tweedie: 470.839\n",
      "[64]\tvalid_0's tweedie: 470.839\n",
      "[65]\tvalid_0's tweedie: 470.839\n",
      "[66]\tvalid_0's tweedie: 470.839\n",
      "[67]\tvalid_0's tweedie: 470.84\n",
      "[68]\tvalid_0's tweedie: 470.839\n",
      "[69]\tvalid_0's tweedie: 470.837\n",
      "[70]\tvalid_0's tweedie: 470.836\n",
      "[71]\tvalid_0's tweedie: 470.835\n",
      "[72]\tvalid_0's tweedie: 470.836\n",
      "[73]\tvalid_0's tweedie: 470.833\n",
      "[74]\tvalid_0's tweedie: 470.83\n",
      "[75]\tvalid_0's tweedie: 470.831\n",
      "[76]\tvalid_0's tweedie: 470.831\n",
      "[77]\tvalid_0's tweedie: 470.831\n",
      "[78]\tvalid_0's tweedie: 470.831\n",
      "[79]\tvalid_0's tweedie: 470.831\n",
      "[80]\tvalid_0's tweedie: 470.829\n",
      "[81]\tvalid_0's tweedie: 470.829\n",
      "[82]\tvalid_0's tweedie: 470.827\n",
      "[83]\tvalid_0's tweedie: 470.827\n",
      "[84]\tvalid_0's tweedie: 470.827\n",
      "[85]\tvalid_0's tweedie: 470.826\n",
      "[86]\tvalid_0's tweedie: 470.826\n",
      "[87]\tvalid_0's tweedie: 470.826\n",
      "[88]\tvalid_0's tweedie: 470.825\n",
      "[89]\tvalid_0's tweedie: 470.825\n",
      "[90]\tvalid_0's tweedie: 470.825\n",
      "[91]\tvalid_0's tweedie: 470.826\n",
      "[92]\tvalid_0's tweedie: 470.825\n",
      "[93]\tvalid_0's tweedie: 470.825\n",
      "[94]\tvalid_0's tweedie: 470.825\n",
      "[95]\tvalid_0's tweedie: 470.825\n",
      "[96]\tvalid_0's tweedie: 470.823\n",
      "[97]\tvalid_0's tweedie: 470.822\n",
      "[98]\tvalid_0's tweedie: 470.822\n",
      "[99]\tvalid_0's tweedie: 470.822\n",
      "[100]\tvalid_0's tweedie: 470.822\n",
      "[101]\tvalid_0's tweedie: 470.821\n",
      "[102]\tvalid_0's tweedie: 470.821\n",
      "[103]\tvalid_0's tweedie: 470.822\n",
      "[104]\tvalid_0's tweedie: 470.818\n",
      "[105]\tvalid_0's tweedie: 470.818\n",
      "[106]\tvalid_0's tweedie: 470.818\n",
      "[107]\tvalid_0's tweedie: 470.817\n",
      "[108]\tvalid_0's tweedie: 470.815\n",
      "[109]\tvalid_0's tweedie: 470.815\n",
      "[110]\tvalid_0's tweedie: 470.815\n",
      "[111]\tvalid_0's tweedie: 470.816\n",
      "[112]\tvalid_0's tweedie: 470.816\n",
      "[113]\tvalid_0's tweedie: 470.816\n",
      "[114]\tvalid_0's tweedie: 470.816\n",
      "[115]\tvalid_0's tweedie: 470.816\n",
      "[116]\tvalid_0's tweedie: 470.817\n",
      "[117]\tvalid_0's tweedie: 470.816\n",
      "[118]\tvalid_0's tweedie: 470.816\n",
      "[119]\tvalid_0's tweedie: 470.814\n",
      "[120]\tvalid_0's tweedie: 470.814\n",
      "[121]\tvalid_0's tweedie: 470.814\n",
      "[122]\tvalid_0's tweedie: 470.814\n",
      "[123]\tvalid_0's tweedie: 470.814\n",
      "[124]\tvalid_0's tweedie: 470.814\n",
      "[125]\tvalid_0's tweedie: 470.813\n",
      "[126]\tvalid_0's tweedie: 470.813\n",
      "[127]\tvalid_0's tweedie: 470.813\n",
      "[128]\tvalid_0's tweedie: 470.813\n",
      "[129]\tvalid_0's tweedie: 470.813\n",
      "[130]\tvalid_0's tweedie: 470.813\n",
      "[131]\tvalid_0's tweedie: 470.813\n",
      "[132]\tvalid_0's tweedie: 470.813\n",
      "[133]\tvalid_0's tweedie: 470.813\n",
      "[134]\tvalid_0's tweedie: 470.813\n",
      "[135]\tvalid_0's tweedie: 470.813\n",
      "[136]\tvalid_0's tweedie: 470.812\n",
      "[137]\tvalid_0's tweedie: 470.812\n",
      "[138]\tvalid_0's tweedie: 470.811\n",
      "[139]\tvalid_0's tweedie: 470.811\n",
      "[140]\tvalid_0's tweedie: 470.811\n",
      "[141]\tvalid_0's tweedie: 470.811\n",
      "[142]\tvalid_0's tweedie: 470.811\n",
      "[143]\tvalid_0's tweedie: 470.81\n",
      "[144]\tvalid_0's tweedie: 470.81\n",
      "[145]\tvalid_0's tweedie: 470.811\n",
      "[146]\tvalid_0's tweedie: 470.811\n",
      "[147]\tvalid_0's tweedie: 470.811\n",
      "[148]\tvalid_0's tweedie: 470.81\n",
      "[149]\tvalid_0's tweedie: 470.81\n",
      "[150]\tvalid_0's tweedie: 470.81\n",
      "[151]\tvalid_0's tweedie: 470.81\n",
      "[152]\tvalid_0's tweedie: 470.81\n",
      "[153]\tvalid_0's tweedie: 470.809\n",
      "[154]\tvalid_0's tweedie: 470.809\n",
      "[155]\tvalid_0's tweedie: 470.81\n",
      "[156]\tvalid_0's tweedie: 470.81\n",
      "[157]\tvalid_0's tweedie: 470.81\n",
      "[158]\tvalid_0's tweedie: 470.81\n",
      "[159]\tvalid_0's tweedie: 470.81\n",
      "[160]\tvalid_0's tweedie: 470.809\n",
      "[161]\tvalid_0's tweedie: 470.809\n",
      "[162]\tvalid_0's tweedie: 470.809\n",
      "[163]\tvalid_0's tweedie: 470.809\n",
      "[164]\tvalid_0's tweedie: 470.809\n",
      "[165]\tvalid_0's tweedie: 470.809\n",
      "[166]\tvalid_0's tweedie: 470.808\n",
      "[167]\tvalid_0's tweedie: 470.808\n",
      "[168]\tvalid_0's tweedie: 470.809\n",
      "[169]\tvalid_0's tweedie: 470.809\n",
      "[170]\tvalid_0's tweedie: 470.809\n",
      "[171]\tvalid_0's tweedie: 470.809\n",
      "[172]\tvalid_0's tweedie: 470.809\n",
      "[173]\tvalid_0's tweedie: 470.809\n",
      "[174]\tvalid_0's tweedie: 470.809\n",
      "[175]\tvalid_0's tweedie: 470.81\n",
      "[176]\tvalid_0's tweedie: 470.81\n",
      "[177]\tvalid_0's tweedie: 470.81\n",
      "[178]\tvalid_0's tweedie: 470.81\n",
      "[179]\tvalid_0's tweedie: 470.811\n",
      "[180]\tvalid_0's tweedie: 470.811\n",
      "[181]\tvalid_0's tweedie: 470.81\n",
      "[182]\tvalid_0's tweedie: 470.81\n",
      "[183]\tvalid_0's tweedie: 470.808\n",
      "[184]\tvalid_0's tweedie: 470.809\n",
      "[185]\tvalid_0's tweedie: 470.809\n",
      "[186]\tvalid_0's tweedie: 470.809\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's tweedie: 470.808\n",
      "Training model for level 2 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 5610, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343553\n",
      "[1]\tvalid_0's tweedie: 476.315\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.413\n",
      "[3]\tvalid_0's tweedie: 474.649\n",
      "[4]\tvalid_0's tweedie: 474.05\n",
      "[5]\tvalid_0's tweedie: 473.543\n",
      "[6]\tvalid_0's tweedie: 473.13\n",
      "[7]\tvalid_0's tweedie: 472.772\n",
      "[8]\tvalid_0's tweedie: 472.477\n",
      "[9]\tvalid_0's tweedie: 472.229\n",
      "[10]\tvalid_0's tweedie: 472.039\n",
      "[11]\tvalid_0's tweedie: 471.867\n",
      "[12]\tvalid_0's tweedie: 471.728\n",
      "[13]\tvalid_0's tweedie: 471.604\n",
      "[14]\tvalid_0's tweedie: 471.515\n",
      "[15]\tvalid_0's tweedie: 471.425\n",
      "[16]\tvalid_0's tweedie: 471.362\n",
      "[17]\tvalid_0's tweedie: 471.305\n",
      "[18]\tvalid_0's tweedie: 471.25\n",
      "[19]\tvalid_0's tweedie: 471.205\n",
      "[20]\tvalid_0's tweedie: 471.163\n",
      "[21]\tvalid_0's tweedie: 471.133\n",
      "[22]\tvalid_0's tweedie: 471.11\n",
      "[23]\tvalid_0's tweedie: 471.096\n",
      "[24]\tvalid_0's tweedie: 471.073\n",
      "[25]\tvalid_0's tweedie: 471.054\n",
      "[26]\tvalid_0's tweedie: 471.04\n",
      "[27]\tvalid_0's tweedie: 471.025\n",
      "[28]\tvalid_0's tweedie: 471.018\n",
      "[29]\tvalid_0's tweedie: 471.009\n",
      "[30]\tvalid_0's tweedie: 470.998\n",
      "[31]\tvalid_0's tweedie: 470.986\n",
      "[32]\tvalid_0's tweedie: 470.979\n",
      "[33]\tvalid_0's tweedie: 470.969\n",
      "[34]\tvalid_0's tweedie: 470.96\n",
      "[35]\tvalid_0's tweedie: 470.954\n",
      "[36]\tvalid_0's tweedie: 470.945\n",
      "[37]\tvalid_0's tweedie: 470.941\n",
      "[38]\tvalid_0's tweedie: 470.937\n",
      "[39]\tvalid_0's tweedie: 470.933\n",
      "[40]\tvalid_0's tweedie: 470.929\n",
      "[41]\tvalid_0's tweedie: 470.929\n",
      "[42]\tvalid_0's tweedie: 470.924\n",
      "[43]\tvalid_0's tweedie: 470.921\n",
      "[44]\tvalid_0's tweedie: 470.912\n",
      "[45]\tvalid_0's tweedie: 470.911\n",
      "[46]\tvalid_0's tweedie: 470.91\n",
      "[47]\tvalid_0's tweedie: 470.907\n",
      "[48]\tvalid_0's tweedie: 470.906\n",
      "[49]\tvalid_0's tweedie: 470.906\n",
      "[50]\tvalid_0's tweedie: 470.904\n",
      "[51]\tvalid_0's tweedie: 470.902\n",
      "[52]\tvalid_0's tweedie: 470.901\n",
      "[53]\tvalid_0's tweedie: 470.899\n",
      "[54]\tvalid_0's tweedie: 470.899\n",
      "[55]\tvalid_0's tweedie: 470.898\n",
      "[56]\tvalid_0's tweedie: 470.896\n",
      "[57]\tvalid_0's tweedie: 470.892\n",
      "[58]\tvalid_0's tweedie: 470.892\n",
      "[59]\tvalid_0's tweedie: 470.891\n",
      "[60]\tvalid_0's tweedie: 470.891\n",
      "[61]\tvalid_0's tweedie: 470.89\n",
      "[62]\tvalid_0's tweedie: 470.889\n",
      "[63]\tvalid_0's tweedie: 470.889\n",
      "[64]\tvalid_0's tweedie: 470.889\n",
      "[65]\tvalid_0's tweedie: 470.888\n",
      "[66]\tvalid_0's tweedie: 470.889\n",
      "[67]\tvalid_0's tweedie: 470.889\n",
      "[68]\tvalid_0's tweedie: 470.889\n",
      "[69]\tvalid_0's tweedie: 470.889\n",
      "[70]\tvalid_0's tweedie: 470.887\n",
      "[71]\tvalid_0's tweedie: 470.886\n",
      "[72]\tvalid_0's tweedie: 470.885\n",
      "[73]\tvalid_0's tweedie: 470.883\n",
      "[74]\tvalid_0's tweedie: 470.881\n",
      "[75]\tvalid_0's tweedie: 470.88\n",
      "[76]\tvalid_0's tweedie: 470.874\n",
      "[77]\tvalid_0's tweedie: 470.872\n",
      "[78]\tvalid_0's tweedie: 470.872\n",
      "[79]\tvalid_0's tweedie: 470.87\n",
      "[80]\tvalid_0's tweedie: 470.871\n",
      "[81]\tvalid_0's tweedie: 470.871\n",
      "[82]\tvalid_0's tweedie: 470.869\n",
      "[83]\tvalid_0's tweedie: 470.869\n",
      "[84]\tvalid_0's tweedie: 470.868\n",
      "[85]\tvalid_0's tweedie: 470.866\n",
      "[86]\tvalid_0's tweedie: 470.866\n",
      "[87]\tvalid_0's tweedie: 470.866\n",
      "[88]\tvalid_0's tweedie: 470.866\n",
      "[89]\tvalid_0's tweedie: 470.866\n",
      "[90]\tvalid_0's tweedie: 470.863\n",
      "[91]\tvalid_0's tweedie: 470.862\n",
      "[92]\tvalid_0's tweedie: 470.862\n",
      "[93]\tvalid_0's tweedie: 470.862\n",
      "[94]\tvalid_0's tweedie: 470.86\n",
      "[95]\tvalid_0's tweedie: 470.86\n",
      "[96]\tvalid_0's tweedie: 470.859\n",
      "[97]\tvalid_0's tweedie: 470.86\n",
      "[98]\tvalid_0's tweedie: 470.86\n",
      "[99]\tvalid_0's tweedie: 470.86\n",
      "[100]\tvalid_0's tweedie: 470.86\n",
      "[101]\tvalid_0's tweedie: 470.86\n",
      "[102]\tvalid_0's tweedie: 470.859\n",
      "[103]\tvalid_0's tweedie: 470.858\n",
      "[104]\tvalid_0's tweedie: 470.857\n",
      "[105]\tvalid_0's tweedie: 470.857\n",
      "[106]\tvalid_0's tweedie: 470.856\n",
      "[107]\tvalid_0's tweedie: 470.856\n",
      "[108]\tvalid_0's tweedie: 470.855\n",
      "[109]\tvalid_0's tweedie: 470.853\n",
      "[110]\tvalid_0's tweedie: 470.853\n",
      "[111]\tvalid_0's tweedie: 470.852\n",
      "[112]\tvalid_0's tweedie: 470.852\n",
      "[113]\tvalid_0's tweedie: 470.852\n",
      "[114]\tvalid_0's tweedie: 470.852\n",
      "[115]\tvalid_0's tweedie: 470.849\n",
      "[116]\tvalid_0's tweedie: 470.849\n",
      "[117]\tvalid_0's tweedie: 470.85\n",
      "[118]\tvalid_0's tweedie: 470.85\n",
      "[119]\tvalid_0's tweedie: 470.85\n",
      "[120]\tvalid_0's tweedie: 470.85\n",
      "[121]\tvalid_0's tweedie: 470.85\n",
      "[122]\tvalid_0's tweedie: 470.85\n",
      "[123]\tvalid_0's tweedie: 470.85\n",
      "[124]\tvalid_0's tweedie: 470.848\n",
      "[125]\tvalid_0's tweedie: 470.848\n",
      "[126]\tvalid_0's tweedie: 470.848\n",
      "[127]\tvalid_0's tweedie: 470.847\n",
      "[128]\tvalid_0's tweedie: 470.847\n",
      "[129]\tvalid_0's tweedie: 470.847\n",
      "[130]\tvalid_0's tweedie: 470.848\n",
      "[131]\tvalid_0's tweedie: 470.848\n",
      "[132]\tvalid_0's tweedie: 470.847\n",
      "[133]\tvalid_0's tweedie: 470.847\n",
      "[134]\tvalid_0's tweedie: 470.847\n",
      "[135]\tvalid_0's tweedie: 470.847\n",
      "[136]\tvalid_0's tweedie: 470.847\n",
      "[137]\tvalid_0's tweedie: 470.847\n",
      "[138]\tvalid_0's tweedie: 470.848\n",
      "[139]\tvalid_0's tweedie: 470.848\n",
      "[140]\tvalid_0's tweedie: 470.848\n",
      "[141]\tvalid_0's tweedie: 470.848\n",
      "[142]\tvalid_0's tweedie: 470.849\n",
      "[143]\tvalid_0's tweedie: 470.848\n",
      "[144]\tvalid_0's tweedie: 470.849\n",
      "[145]\tvalid_0's tweedie: 470.849\n",
      "[146]\tvalid_0's tweedie: 470.848\n",
      "[147]\tvalid_0's tweedie: 470.849\n",
      "[148]\tvalid_0's tweedie: 470.849\n",
      "[149]\tvalid_0's tweedie: 470.849\n",
      "[150]\tvalid_0's tweedie: 470.849\n",
      "[151]\tvalid_0's tweedie: 470.85\n",
      "[152]\tvalid_0's tweedie: 470.851\n",
      "[153]\tvalid_0's tweedie: 470.851\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's tweedie: 470.847\n",
      "Training model for level 2 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 5607, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343520\n",
      "[1]\tvalid_0's tweedie: 476.317\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.411\n",
      "[3]\tvalid_0's tweedie: 474.65\n",
      "[4]\tvalid_0's tweedie: 474.071\n",
      "[5]\tvalid_0's tweedie: 473.581\n",
      "[6]\tvalid_0's tweedie: 473.177\n",
      "[7]\tvalid_0's tweedie: 472.838\n",
      "[8]\tvalid_0's tweedie: 472.54\n",
      "[9]\tvalid_0's tweedie: 472.298\n",
      "[10]\tvalid_0's tweedie: 472.102\n",
      "[11]\tvalid_0's tweedie: 471.918\n",
      "[12]\tvalid_0's tweedie: 471.773\n",
      "[13]\tvalid_0's tweedie: 471.644\n",
      "[14]\tvalid_0's tweedie: 471.532\n",
      "[15]\tvalid_0's tweedie: 471.442\n",
      "[16]\tvalid_0's tweedie: 471.373\n",
      "[17]\tvalid_0's tweedie: 471.31\n",
      "[18]\tvalid_0's tweedie: 471.258\n",
      "[19]\tvalid_0's tweedie: 471.214\n",
      "[20]\tvalid_0's tweedie: 471.178\n",
      "[21]\tvalid_0's tweedie: 471.147\n",
      "[22]\tvalid_0's tweedie: 471.116\n",
      "[23]\tvalid_0's tweedie: 471.096\n",
      "[24]\tvalid_0's tweedie: 471.073\n",
      "[25]\tvalid_0's tweedie: 471.053\n",
      "[26]\tvalid_0's tweedie: 471.041\n",
      "[27]\tvalid_0's tweedie: 471.028\n",
      "[28]\tvalid_0's tweedie: 471.016\n",
      "[29]\tvalid_0's tweedie: 471.001\n",
      "[30]\tvalid_0's tweedie: 470.992\n",
      "[31]\tvalid_0's tweedie: 470.986\n",
      "[32]\tvalid_0's tweedie: 470.975\n",
      "[33]\tvalid_0's tweedie: 470.966\n",
      "[34]\tvalid_0's tweedie: 470.957\n",
      "[35]\tvalid_0's tweedie: 470.949\n",
      "[36]\tvalid_0's tweedie: 470.941\n",
      "[37]\tvalid_0's tweedie: 470.932\n",
      "[38]\tvalid_0's tweedie: 470.928\n",
      "[39]\tvalid_0's tweedie: 470.923\n",
      "[40]\tvalid_0's tweedie: 470.917\n",
      "[41]\tvalid_0's tweedie: 470.913\n",
      "[42]\tvalid_0's tweedie: 470.906\n",
      "[43]\tvalid_0's tweedie: 470.901\n",
      "[44]\tvalid_0's tweedie: 470.895\n",
      "[45]\tvalid_0's tweedie: 470.892\n",
      "[46]\tvalid_0's tweedie: 470.892\n",
      "[47]\tvalid_0's tweedie: 470.892\n",
      "[48]\tvalid_0's tweedie: 470.885\n",
      "[49]\tvalid_0's tweedie: 470.882\n",
      "[50]\tvalid_0's tweedie: 470.88\n",
      "[51]\tvalid_0's tweedie: 470.877\n",
      "[52]\tvalid_0's tweedie: 470.876\n",
      "[53]\tvalid_0's tweedie: 470.874\n",
      "[54]\tvalid_0's tweedie: 470.873\n",
      "[55]\tvalid_0's tweedie: 470.87\n",
      "[56]\tvalid_0's tweedie: 470.87\n",
      "[57]\tvalid_0's tweedie: 470.87\n",
      "[58]\tvalid_0's tweedie: 470.87\n",
      "[59]\tvalid_0's tweedie: 470.869\n",
      "[60]\tvalid_0's tweedie: 470.87\n",
      "[61]\tvalid_0's tweedie: 470.868\n",
      "[62]\tvalid_0's tweedie: 470.87\n",
      "[63]\tvalid_0's tweedie: 470.866\n",
      "[64]\tvalid_0's tweedie: 470.866\n",
      "[65]\tvalid_0's tweedie: 470.863\n",
      "[66]\tvalid_0's tweedie: 470.861\n",
      "[67]\tvalid_0's tweedie: 470.861\n",
      "[68]\tvalid_0's tweedie: 470.861\n",
      "[69]\tvalid_0's tweedie: 470.86\n",
      "[70]\tvalid_0's tweedie: 470.858\n",
      "[71]\tvalid_0's tweedie: 470.857\n",
      "[72]\tvalid_0's tweedie: 470.858\n",
      "[73]\tvalid_0's tweedie: 470.858\n",
      "[74]\tvalid_0's tweedie: 470.856\n",
      "[75]\tvalid_0's tweedie: 470.854\n",
      "[76]\tvalid_0's tweedie: 470.853\n",
      "[77]\tvalid_0's tweedie: 470.853\n",
      "[78]\tvalid_0's tweedie: 470.851\n",
      "[79]\tvalid_0's tweedie: 470.85\n",
      "[80]\tvalid_0's tweedie: 470.848\n",
      "[81]\tvalid_0's tweedie: 470.847\n",
      "[82]\tvalid_0's tweedie: 470.846\n",
      "[83]\tvalid_0's tweedie: 470.845\n",
      "[84]\tvalid_0's tweedie: 470.844\n",
      "[85]\tvalid_0's tweedie: 470.843\n",
      "[86]\tvalid_0's tweedie: 470.841\n",
      "[87]\tvalid_0's tweedie: 470.841\n",
      "[88]\tvalid_0's tweedie: 470.84\n",
      "[89]\tvalid_0's tweedie: 470.839\n",
      "[90]\tvalid_0's tweedie: 470.839\n",
      "[91]\tvalid_0's tweedie: 470.838\n",
      "[92]\tvalid_0's tweedie: 470.838\n",
      "[93]\tvalid_0's tweedie: 470.837\n",
      "[94]\tvalid_0's tweedie: 470.837\n",
      "[95]\tvalid_0's tweedie: 470.836\n",
      "[96]\tvalid_0's tweedie: 470.835\n",
      "[97]\tvalid_0's tweedie: 470.834\n",
      "[98]\tvalid_0's tweedie: 470.834\n",
      "[99]\tvalid_0's tweedie: 470.834\n",
      "[100]\tvalid_0's tweedie: 470.833\n",
      "[101]\tvalid_0's tweedie: 470.832\n",
      "[102]\tvalid_0's tweedie: 470.832\n",
      "[103]\tvalid_0's tweedie: 470.832\n",
      "[104]\tvalid_0's tweedie: 470.832\n",
      "[105]\tvalid_0's tweedie: 470.832\n",
      "[106]\tvalid_0's tweedie: 470.83\n",
      "[107]\tvalid_0's tweedie: 470.83\n",
      "[108]\tvalid_0's tweedie: 470.829\n",
      "[109]\tvalid_0's tweedie: 470.829\n",
      "[110]\tvalid_0's tweedie: 470.827\n",
      "[111]\tvalid_0's tweedie: 470.827\n",
      "[112]\tvalid_0's tweedie: 470.826\n",
      "[113]\tvalid_0's tweedie: 470.825\n",
      "[114]\tvalid_0's tweedie: 470.824\n",
      "[115]\tvalid_0's tweedie: 470.824\n",
      "[116]\tvalid_0's tweedie: 470.822\n",
      "[117]\tvalid_0's tweedie: 470.822\n",
      "[118]\tvalid_0's tweedie: 470.821\n",
      "[119]\tvalid_0's tweedie: 470.822\n",
      "[120]\tvalid_0's tweedie: 470.822\n",
      "[121]\tvalid_0's tweedie: 470.822\n",
      "[122]\tvalid_0's tweedie: 470.821\n",
      "[123]\tvalid_0's tweedie: 470.821\n",
      "[124]\tvalid_0's tweedie: 470.821\n",
      "[125]\tvalid_0's tweedie: 470.82\n",
      "[126]\tvalid_0's tweedie: 470.818\n",
      "[127]\tvalid_0's tweedie: 470.818\n",
      "[128]\tvalid_0's tweedie: 470.817\n",
      "[129]\tvalid_0's tweedie: 470.817\n",
      "[130]\tvalid_0's tweedie: 470.816\n",
      "[131]\tvalid_0's tweedie: 470.816\n",
      "[132]\tvalid_0's tweedie: 470.815\n",
      "[133]\tvalid_0's tweedie: 470.814\n",
      "[134]\tvalid_0's tweedie: 470.814\n",
      "[135]\tvalid_0's tweedie: 470.814\n",
      "[136]\tvalid_0's tweedie: 470.814\n",
      "[137]\tvalid_0's tweedie: 470.815\n",
      "[138]\tvalid_0's tweedie: 470.814\n",
      "[139]\tvalid_0's tweedie: 470.814\n",
      "[140]\tvalid_0's tweedie: 470.814\n",
      "[141]\tvalid_0's tweedie: 470.813\n",
      "[142]\tvalid_0's tweedie: 470.813\n",
      "[143]\tvalid_0's tweedie: 470.812\n",
      "[144]\tvalid_0's tweedie: 470.812\n",
      "[145]\tvalid_0's tweedie: 470.812\n",
      "[146]\tvalid_0's tweedie: 470.812\n",
      "[147]\tvalid_0's tweedie: 470.812\n",
      "[148]\tvalid_0's tweedie: 470.812\n",
      "[149]\tvalid_0's tweedie: 470.812\n",
      "[150]\tvalid_0's tweedie: 470.811\n",
      "[151]\tvalid_0's tweedie: 470.81\n",
      "[152]\tvalid_0's tweedie: 470.809\n",
      "[153]\tvalid_0's tweedie: 470.808\n",
      "[154]\tvalid_0's tweedie: 470.808\n",
      "[155]\tvalid_0's tweedie: 470.808\n",
      "[156]\tvalid_0's tweedie: 470.808\n",
      "[157]\tvalid_0's tweedie: 470.808\n",
      "[158]\tvalid_0's tweedie: 470.808\n",
      "[159]\tvalid_0's tweedie: 470.809\n",
      "[160]\tvalid_0's tweedie: 470.81\n",
      "[161]\tvalid_0's tweedie: 470.809\n",
      "[162]\tvalid_0's tweedie: 470.809\n",
      "[163]\tvalid_0's tweedie: 470.808\n",
      "[164]\tvalid_0's tweedie: 470.808\n",
      "[165]\tvalid_0's tweedie: 470.809\n",
      "[166]\tvalid_0's tweedie: 470.809\n",
      "[167]\tvalid_0's tweedie: 470.808\n",
      "[168]\tvalid_0's tweedie: 470.807\n",
      "[169]\tvalid_0's tweedie: 470.807\n",
      "[170]\tvalid_0's tweedie: 470.807\n",
      "[171]\tvalid_0's tweedie: 470.807\n",
      "[172]\tvalid_0's tweedie: 470.807\n",
      "[173]\tvalid_0's tweedie: 470.807\n",
      "[174]\tvalid_0's tweedie: 470.808\n",
      "[175]\tvalid_0's tweedie: 470.808\n",
      "[176]\tvalid_0's tweedie: 470.808\n",
      "[177]\tvalid_0's tweedie: 470.808\n",
      "[178]\tvalid_0's tweedie: 470.81\n",
      "[179]\tvalid_0's tweedie: 470.809\n",
      "[180]\tvalid_0's tweedie: 470.809\n",
      "[181]\tvalid_0's tweedie: 470.81\n",
      "[182]\tvalid_0's tweedie: 470.809\n",
      "[183]\tvalid_0's tweedie: 470.809\n",
      "[184]\tvalid_0's tweedie: 470.809\n",
      "[185]\tvalid_0's tweedie: 470.809\n",
      "[186]\tvalid_0's tweedie: 470.81\n",
      "[187]\tvalid_0's tweedie: 470.81\n",
      "[188]\tvalid_0's tweedie: 470.809\n",
      "[189]\tvalid_0's tweedie: 470.809\n",
      "[190]\tvalid_0's tweedie: 470.809\n",
      "[191]\tvalid_0's tweedie: 470.808\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's tweedie: 470.807\n",
      "Training model for level 2 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 5604, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343715\n",
      "[1]\tvalid_0's tweedie: 476.307\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.414\n",
      "[3]\tvalid_0's tweedie: 474.67\n",
      "[4]\tvalid_0's tweedie: 474.083\n",
      "[5]\tvalid_0's tweedie: 473.557\n",
      "[6]\tvalid_0's tweedie: 473.125\n",
      "[7]\tvalid_0's tweedie: 472.803\n",
      "[8]\tvalid_0's tweedie: 472.497\n",
      "[9]\tvalid_0's tweedie: 472.252\n",
      "[10]\tvalid_0's tweedie: 472.049\n",
      "[11]\tvalid_0's tweedie: 471.919\n",
      "[12]\tvalid_0's tweedie: 471.79\n",
      "[13]\tvalid_0's tweedie: 471.667\n",
      "[14]\tvalid_0's tweedie: 471.566\n",
      "[15]\tvalid_0's tweedie: 471.487\n",
      "[16]\tvalid_0's tweedie: 471.409\n",
      "[17]\tvalid_0's tweedie: 471.34\n",
      "[18]\tvalid_0's tweedie: 471.281\n",
      "[19]\tvalid_0's tweedie: 471.237\n",
      "[20]\tvalid_0's tweedie: 471.192\n",
      "[21]\tvalid_0's tweedie: 471.152\n",
      "[22]\tvalid_0's tweedie: 471.124\n",
      "[23]\tvalid_0's tweedie: 471.109\n",
      "[24]\tvalid_0's tweedie: 471.09\n",
      "[25]\tvalid_0's tweedie: 471.061\n",
      "[26]\tvalid_0's tweedie: 471.043\n",
      "[27]\tvalid_0's tweedie: 471.029\n",
      "[28]\tvalid_0's tweedie: 471.013\n",
      "[29]\tvalid_0's tweedie: 470.996\n",
      "[30]\tvalid_0's tweedie: 470.989\n",
      "[31]\tvalid_0's tweedie: 470.985\n",
      "[32]\tvalid_0's tweedie: 470.972\n",
      "[33]\tvalid_0's tweedie: 470.967\n",
      "[34]\tvalid_0's tweedie: 470.962\n",
      "[35]\tvalid_0's tweedie: 470.952\n",
      "[36]\tvalid_0's tweedie: 470.942\n",
      "[37]\tvalid_0's tweedie: 470.937\n",
      "[38]\tvalid_0's tweedie: 470.927\n",
      "[39]\tvalid_0's tweedie: 470.922\n",
      "[40]\tvalid_0's tweedie: 470.92\n",
      "[41]\tvalid_0's tweedie: 470.916\n",
      "[42]\tvalid_0's tweedie: 470.916\n",
      "[43]\tvalid_0's tweedie: 470.911\n",
      "[44]\tvalid_0's tweedie: 470.904\n",
      "[45]\tvalid_0's tweedie: 470.9\n",
      "[46]\tvalid_0's tweedie: 470.897\n",
      "[47]\tvalid_0's tweedie: 470.896\n",
      "[48]\tvalid_0's tweedie: 470.897\n",
      "[49]\tvalid_0's tweedie: 470.896\n",
      "[50]\tvalid_0's tweedie: 470.893\n",
      "[51]\tvalid_0's tweedie: 470.89\n",
      "[52]\tvalid_0's tweedie: 470.887\n",
      "[53]\tvalid_0's tweedie: 470.884\n",
      "[54]\tvalid_0's tweedie: 470.883\n",
      "[55]\tvalid_0's tweedie: 470.881\n",
      "[56]\tvalid_0's tweedie: 470.881\n",
      "[57]\tvalid_0's tweedie: 470.878\n",
      "[58]\tvalid_0's tweedie: 470.879\n",
      "[59]\tvalid_0's tweedie: 470.879\n",
      "[60]\tvalid_0's tweedie: 470.878\n",
      "[61]\tvalid_0's tweedie: 470.872\n",
      "[62]\tvalid_0's tweedie: 470.871\n",
      "[63]\tvalid_0's tweedie: 470.872\n",
      "[64]\tvalid_0's tweedie: 470.869\n",
      "[65]\tvalid_0's tweedie: 470.868\n",
      "[66]\tvalid_0's tweedie: 470.864\n",
      "[67]\tvalid_0's tweedie: 470.863\n",
      "[68]\tvalid_0's tweedie: 470.863\n",
      "[69]\tvalid_0's tweedie: 470.863\n",
      "[70]\tvalid_0's tweedie: 470.862\n",
      "[71]\tvalid_0's tweedie: 470.862\n",
      "[72]\tvalid_0's tweedie: 470.861\n",
      "[73]\tvalid_0's tweedie: 470.861\n",
      "[74]\tvalid_0's tweedie: 470.858\n",
      "[75]\tvalid_0's tweedie: 470.856\n",
      "[76]\tvalid_0's tweedie: 470.856\n",
      "[77]\tvalid_0's tweedie: 470.856\n",
      "[78]\tvalid_0's tweedie: 470.851\n",
      "[79]\tvalid_0's tweedie: 470.85\n",
      "[80]\tvalid_0's tweedie: 470.85\n",
      "[81]\tvalid_0's tweedie: 470.848\n",
      "[82]\tvalid_0's tweedie: 470.848\n",
      "[83]\tvalid_0's tweedie: 470.848\n",
      "[84]\tvalid_0's tweedie: 470.847\n",
      "[85]\tvalid_0's tweedie: 470.845\n",
      "[86]\tvalid_0's tweedie: 470.845\n",
      "[87]\tvalid_0's tweedie: 470.845\n",
      "[88]\tvalid_0's tweedie: 470.843\n",
      "[89]\tvalid_0's tweedie: 470.844\n",
      "[90]\tvalid_0's tweedie: 470.844\n",
      "[91]\tvalid_0's tweedie: 470.844\n",
      "[92]\tvalid_0's tweedie: 470.844\n",
      "[93]\tvalid_0's tweedie: 470.844\n",
      "[94]\tvalid_0's tweedie: 470.844\n",
      "[95]\tvalid_0's tweedie: 470.844\n",
      "[96]\tvalid_0's tweedie: 470.844\n",
      "[97]\tvalid_0's tweedie: 470.845\n",
      "[98]\tvalid_0's tweedie: 470.845\n",
      "[99]\tvalid_0's tweedie: 470.846\n",
      "[100]\tvalid_0's tweedie: 470.845\n",
      "[101]\tvalid_0's tweedie: 470.844\n",
      "[102]\tvalid_0's tweedie: 470.844\n",
      "[103]\tvalid_0's tweedie: 470.842\n",
      "[104]\tvalid_0's tweedie: 470.842\n",
      "[105]\tvalid_0's tweedie: 470.842\n",
      "[106]\tvalid_0's tweedie: 470.841\n",
      "[107]\tvalid_0's tweedie: 470.841\n",
      "[108]\tvalid_0's tweedie: 470.841\n",
      "[109]\tvalid_0's tweedie: 470.841\n",
      "[110]\tvalid_0's tweedie: 470.841\n",
      "[111]\tvalid_0's tweedie: 470.84\n",
      "[112]\tvalid_0's tweedie: 470.84\n",
      "[113]\tvalid_0's tweedie: 470.84\n",
      "[114]\tvalid_0's tweedie: 470.839\n",
      "[115]\tvalid_0's tweedie: 470.838\n",
      "[116]\tvalid_0's tweedie: 470.838\n",
      "[117]\tvalid_0's tweedie: 470.837\n",
      "[118]\tvalid_0's tweedie: 470.838\n",
      "[119]\tvalid_0's tweedie: 470.837\n",
      "[120]\tvalid_0's tweedie: 470.837\n",
      "[121]\tvalid_0's tweedie: 470.837\n",
      "[122]\tvalid_0's tweedie: 470.836\n",
      "[123]\tvalid_0's tweedie: 470.836\n",
      "[124]\tvalid_0's tweedie: 470.836\n",
      "[125]\tvalid_0's tweedie: 470.835\n",
      "[126]\tvalid_0's tweedie: 470.835\n",
      "[127]\tvalid_0's tweedie: 470.834\n",
      "[128]\tvalid_0's tweedie: 470.834\n",
      "[129]\tvalid_0's tweedie: 470.834\n",
      "[130]\tvalid_0's tweedie: 470.834\n",
      "[131]\tvalid_0's tweedie: 470.834\n",
      "[132]\tvalid_0's tweedie: 470.834\n",
      "[133]\tvalid_0's tweedie: 470.834\n",
      "[134]\tvalid_0's tweedie: 470.833\n",
      "[135]\tvalid_0's tweedie: 470.833\n",
      "[136]\tvalid_0's tweedie: 470.832\n",
      "[137]\tvalid_0's tweedie: 470.831\n",
      "[138]\tvalid_0's tweedie: 470.831\n",
      "[139]\tvalid_0's tweedie: 470.833\n",
      "[140]\tvalid_0's tweedie: 470.833\n",
      "[141]\tvalid_0's tweedie: 470.833\n",
      "[142]\tvalid_0's tweedie: 470.834\n",
      "[143]\tvalid_0's tweedie: 470.834\n",
      "[144]\tvalid_0's tweedie: 470.834\n",
      "[145]\tvalid_0's tweedie: 470.834\n",
      "[146]\tvalid_0's tweedie: 470.835\n",
      "[147]\tvalid_0's tweedie: 470.835\n",
      "[148]\tvalid_0's tweedie: 470.833\n",
      "[149]\tvalid_0's tweedie: 470.833\n",
      "[150]\tvalid_0's tweedie: 470.833\n",
      "[151]\tvalid_0's tweedie: 470.834\n",
      "[152]\tvalid_0's tweedie: 470.834\n",
      "[153]\tvalid_0's tweedie: 470.832\n",
      "[154]\tvalid_0's tweedie: 470.832\n",
      "[155]\tvalid_0's tweedie: 470.832\n",
      "[156]\tvalid_0's tweedie: 470.832\n",
      "[157]\tvalid_0's tweedie: 470.833\n",
      "[158]\tvalid_0's tweedie: 470.833\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's tweedie: 470.831\n",
      "Training model for level 2 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 5601, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343874\n",
      "[1]\tvalid_0's tweedie: 476.304\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.412\n",
      "[3]\tvalid_0's tweedie: 474.668\n",
      "[4]\tvalid_0's tweedie: 474.067\n",
      "[5]\tvalid_0's tweedie: 473.555\n",
      "[6]\tvalid_0's tweedie: 473.116\n",
      "[7]\tvalid_0's tweedie: 472.792\n",
      "[8]\tvalid_0's tweedie: 472.5\n",
      "[9]\tvalid_0's tweedie: 472.244\n",
      "[10]\tvalid_0's tweedie: 472.049\n",
      "[11]\tvalid_0's tweedie: 471.877\n",
      "[12]\tvalid_0's tweedie: 471.73\n",
      "[13]\tvalid_0's tweedie: 471.602\n",
      "[14]\tvalid_0's tweedie: 471.502\n",
      "[15]\tvalid_0's tweedie: 471.425\n",
      "[16]\tvalid_0's tweedie: 471.351\n",
      "[17]\tvalid_0's tweedie: 471.299\n",
      "[18]\tvalid_0's tweedie: 471.247\n",
      "[19]\tvalid_0's tweedie: 471.198\n",
      "[20]\tvalid_0's tweedie: 471.163\n",
      "[21]\tvalid_0's tweedie: 471.128\n",
      "[22]\tvalid_0's tweedie: 471.097\n",
      "[23]\tvalid_0's tweedie: 471.074\n",
      "[24]\tvalid_0's tweedie: 471.052\n",
      "[25]\tvalid_0's tweedie: 471.041\n",
      "[26]\tvalid_0's tweedie: 471.026\n",
      "[27]\tvalid_0's tweedie: 471.011\n",
      "[28]\tvalid_0's tweedie: 471.004\n",
      "[29]\tvalid_0's tweedie: 470.995\n",
      "[30]\tvalid_0's tweedie: 470.983\n",
      "[31]\tvalid_0's tweedie: 470.973\n",
      "[32]\tvalid_0's tweedie: 470.964\n",
      "[33]\tvalid_0's tweedie: 470.958\n",
      "[34]\tvalid_0's tweedie: 470.95\n",
      "[35]\tvalid_0's tweedie: 470.945\n",
      "[36]\tvalid_0's tweedie: 470.94\n",
      "[37]\tvalid_0's tweedie: 470.932\n",
      "[38]\tvalid_0's tweedie: 470.928\n",
      "[39]\tvalid_0's tweedie: 470.929\n",
      "[40]\tvalid_0's tweedie: 470.921\n",
      "[41]\tvalid_0's tweedie: 470.924\n",
      "[42]\tvalid_0's tweedie: 470.921\n",
      "[43]\tvalid_0's tweedie: 470.918\n",
      "[44]\tvalid_0's tweedie: 470.914\n",
      "[45]\tvalid_0's tweedie: 470.913\n",
      "[46]\tvalid_0's tweedie: 470.91\n",
      "[47]\tvalid_0's tweedie: 470.909\n",
      "[48]\tvalid_0's tweedie: 470.908\n",
      "[49]\tvalid_0's tweedie: 470.906\n",
      "[50]\tvalid_0's tweedie: 470.904\n",
      "[51]\tvalid_0's tweedie: 470.9\n",
      "[52]\tvalid_0's tweedie: 470.898\n",
      "[53]\tvalid_0's tweedie: 470.897\n",
      "[54]\tvalid_0's tweedie: 470.892\n",
      "[55]\tvalid_0's tweedie: 470.886\n",
      "[56]\tvalid_0's tweedie: 470.886\n",
      "[57]\tvalid_0's tweedie: 470.885\n",
      "[58]\tvalid_0's tweedie: 470.885\n",
      "[59]\tvalid_0's tweedie: 470.883\n",
      "[60]\tvalid_0's tweedie: 470.883\n",
      "[61]\tvalid_0's tweedie: 470.882\n",
      "[62]\tvalid_0's tweedie: 470.88\n",
      "[63]\tvalid_0's tweedie: 470.881\n",
      "[64]\tvalid_0's tweedie: 470.88\n",
      "[65]\tvalid_0's tweedie: 470.88\n",
      "[66]\tvalid_0's tweedie: 470.881\n",
      "[67]\tvalid_0's tweedie: 470.872\n",
      "[68]\tvalid_0's tweedie: 470.872\n",
      "[69]\tvalid_0's tweedie: 470.872\n",
      "[70]\tvalid_0's tweedie: 470.872\n",
      "[71]\tvalid_0's tweedie: 470.872\n",
      "[72]\tvalid_0's tweedie: 470.87\n",
      "[73]\tvalid_0's tweedie: 470.868\n",
      "[74]\tvalid_0's tweedie: 470.868\n",
      "[75]\tvalid_0's tweedie: 470.869\n",
      "[76]\tvalid_0's tweedie: 470.865\n",
      "[77]\tvalid_0's tweedie: 470.864\n",
      "[78]\tvalid_0's tweedie: 470.863\n",
      "[79]\tvalid_0's tweedie: 470.862\n",
      "[80]\tvalid_0's tweedie: 470.857\n",
      "[81]\tvalid_0's tweedie: 470.857\n",
      "[82]\tvalid_0's tweedie: 470.857\n",
      "[83]\tvalid_0's tweedie: 470.856\n",
      "[84]\tvalid_0's tweedie: 470.856\n",
      "[85]\tvalid_0's tweedie: 470.858\n",
      "[86]\tvalid_0's tweedie: 470.857\n",
      "[87]\tvalid_0's tweedie: 470.855\n",
      "[88]\tvalid_0's tweedie: 470.854\n",
      "[89]\tvalid_0's tweedie: 470.854\n",
      "[90]\tvalid_0's tweedie: 470.854\n",
      "[91]\tvalid_0's tweedie: 470.855\n",
      "[92]\tvalid_0's tweedie: 470.855\n",
      "[93]\tvalid_0's tweedie: 470.855\n",
      "[94]\tvalid_0's tweedie: 470.855\n",
      "[95]\tvalid_0's tweedie: 470.855\n",
      "[96]\tvalid_0's tweedie: 470.85\n",
      "[97]\tvalid_0's tweedie: 470.85\n",
      "[98]\tvalid_0's tweedie: 470.851\n",
      "[99]\tvalid_0's tweedie: 470.851\n",
      "[100]\tvalid_0's tweedie: 470.853\n",
      "[101]\tvalid_0's tweedie: 470.853\n",
      "[102]\tvalid_0's tweedie: 470.853\n",
      "[103]\tvalid_0's tweedie: 470.851\n",
      "[104]\tvalid_0's tweedie: 470.851\n",
      "[105]\tvalid_0's tweedie: 470.849\n",
      "[106]\tvalid_0's tweedie: 470.85\n",
      "[107]\tvalid_0's tweedie: 470.85\n",
      "[108]\tvalid_0's tweedie: 470.85\n",
      "[109]\tvalid_0's tweedie: 470.85\n",
      "[110]\tvalid_0's tweedie: 470.851\n",
      "[111]\tvalid_0's tweedie: 470.848\n",
      "[112]\tvalid_0's tweedie: 470.847\n",
      "[113]\tvalid_0's tweedie: 470.846\n",
      "[114]\tvalid_0's tweedie: 470.845\n",
      "[115]\tvalid_0's tweedie: 470.848\n",
      "[116]\tvalid_0's tweedie: 470.847\n",
      "[117]\tvalid_0's tweedie: 470.847\n",
      "[118]\tvalid_0's tweedie: 470.847\n",
      "[119]\tvalid_0's tweedie: 470.846\n",
      "[120]\tvalid_0's tweedie: 470.846\n",
      "[121]\tvalid_0's tweedie: 470.846\n",
      "[122]\tvalid_0's tweedie: 470.844\n",
      "[123]\tvalid_0's tweedie: 470.844\n",
      "[124]\tvalid_0's tweedie: 470.846\n",
      "[125]\tvalid_0's tweedie: 470.846\n",
      "[126]\tvalid_0's tweedie: 470.846\n",
      "[127]\tvalid_0's tweedie: 470.845\n",
      "[128]\tvalid_0's tweedie: 470.845\n",
      "[129]\tvalid_0's tweedie: 470.844\n",
      "[130]\tvalid_0's tweedie: 470.843\n",
      "[131]\tvalid_0's tweedie: 470.843\n",
      "[132]\tvalid_0's tweedie: 470.842\n",
      "[133]\tvalid_0's tweedie: 470.842\n",
      "[134]\tvalid_0's tweedie: 470.842\n",
      "[135]\tvalid_0's tweedie: 470.841\n",
      "[136]\tvalid_0's tweedie: 470.841\n",
      "[137]\tvalid_0's tweedie: 470.841\n",
      "[138]\tvalid_0's tweedie: 470.841\n",
      "[139]\tvalid_0's tweedie: 470.841\n",
      "[140]\tvalid_0's tweedie: 470.841\n",
      "[141]\tvalid_0's tweedie: 470.841\n",
      "[142]\tvalid_0's tweedie: 470.841\n",
      "[143]\tvalid_0's tweedie: 470.841\n",
      "[144]\tvalid_0's tweedie: 470.841\n",
      "[145]\tvalid_0's tweedie: 470.841\n",
      "[146]\tvalid_0's tweedie: 470.84\n",
      "[147]\tvalid_0's tweedie: 470.84\n",
      "[148]\tvalid_0's tweedie: 470.84\n",
      "[149]\tvalid_0's tweedie: 470.84\n",
      "[150]\tvalid_0's tweedie: 470.84\n",
      "[151]\tvalid_0's tweedie: 470.84\n",
      "[152]\tvalid_0's tweedie: 470.84\n",
      "[153]\tvalid_0's tweedie: 470.84\n",
      "[154]\tvalid_0's tweedie: 470.84\n",
      "[155]\tvalid_0's tweedie: 470.84\n",
      "[156]\tvalid_0's tweedie: 470.84\n",
      "[157]\tvalid_0's tweedie: 470.84\n",
      "[158]\tvalid_0's tweedie: 470.84\n",
      "[159]\tvalid_0's tweedie: 470.84\n",
      "[160]\tvalid_0's tweedie: 470.84\n",
      "[161]\tvalid_0's tweedie: 470.84\n",
      "[162]\tvalid_0's tweedie: 470.835\n",
      "[163]\tvalid_0's tweedie: 470.836\n",
      "[164]\tvalid_0's tweedie: 470.836\n",
      "[165]\tvalid_0's tweedie: 470.836\n",
      "[166]\tvalid_0's tweedie: 470.836\n",
      "[167]\tvalid_0's tweedie: 470.836\n",
      "[168]\tvalid_0's tweedie: 470.836\n",
      "[169]\tvalid_0's tweedie: 470.836\n",
      "[170]\tvalid_0's tweedie: 470.834\n",
      "[171]\tvalid_0's tweedie: 470.834\n",
      "[172]\tvalid_0's tweedie: 470.835\n",
      "[173]\tvalid_0's tweedie: 470.835\n",
      "[174]\tvalid_0's tweedie: 470.835\n",
      "[175]\tvalid_0's tweedie: 470.835\n",
      "[176]\tvalid_0's tweedie: 470.835\n",
      "[177]\tvalid_0's tweedie: 470.835\n",
      "[178]\tvalid_0's tweedie: 470.835\n",
      "[179]\tvalid_0's tweedie: 470.835\n",
      "[180]\tvalid_0's tweedie: 470.835\n",
      "[181]\tvalid_0's tweedie: 470.835\n",
      "[182]\tvalid_0's tweedie: 470.835\n",
      "[183]\tvalid_0's tweedie: 470.835\n",
      "[184]\tvalid_0's tweedie: 470.835\n",
      "[185]\tvalid_0's tweedie: 470.835\n",
      "[186]\tvalid_0's tweedie: 470.835\n",
      "[187]\tvalid_0's tweedie: 470.835\n",
      "[188]\tvalid_0's tweedie: 470.836\n",
      "[189]\tvalid_0's tweedie: 470.836\n",
      "[190]\tvalid_0's tweedie: 470.836\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's tweedie: 470.834\n",
      "Training model for level 2 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 5598, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344075\n",
      "[1]\tvalid_0's tweedie: 476.3\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.409\n",
      "[3]\tvalid_0's tweedie: 474.658\n",
      "[4]\tvalid_0's tweedie: 474.055\n",
      "[5]\tvalid_0's tweedie: 473.541\n",
      "[6]\tvalid_0's tweedie: 473.114\n",
      "[7]\tvalid_0's tweedie: 472.77\n",
      "[8]\tvalid_0's tweedie: 472.481\n",
      "[9]\tvalid_0's tweedie: 472.246\n",
      "[10]\tvalid_0's tweedie: 472.028\n",
      "[11]\tvalid_0's tweedie: 471.864\n",
      "[12]\tvalid_0's tweedie: 471.727\n",
      "[13]\tvalid_0's tweedie: 471.592\n",
      "[14]\tvalid_0's tweedie: 471.49\n",
      "[15]\tvalid_0's tweedie: 471.398\n",
      "[16]\tvalid_0's tweedie: 471.332\n",
      "[17]\tvalid_0's tweedie: 471.284\n",
      "[18]\tvalid_0's tweedie: 471.233\n",
      "[19]\tvalid_0's tweedie: 471.187\n",
      "[20]\tvalid_0's tweedie: 471.151\n",
      "[21]\tvalid_0's tweedie: 471.122\n",
      "[22]\tvalid_0's tweedie: 471.096\n",
      "[23]\tvalid_0's tweedie: 471.071\n",
      "[24]\tvalid_0's tweedie: 471.048\n",
      "[25]\tvalid_0's tweedie: 471.04\n",
      "[26]\tvalid_0's tweedie: 471.027\n",
      "[27]\tvalid_0's tweedie: 471.007\n",
      "[28]\tvalid_0's tweedie: 470.992\n",
      "[29]\tvalid_0's tweedie: 470.982\n",
      "[30]\tvalid_0's tweedie: 470.97\n",
      "[31]\tvalid_0's tweedie: 470.963\n",
      "[32]\tvalid_0's tweedie: 470.959\n",
      "[33]\tvalid_0's tweedie: 470.95\n",
      "[34]\tvalid_0's tweedie: 470.945\n",
      "[35]\tvalid_0's tweedie: 470.936\n",
      "[36]\tvalid_0's tweedie: 470.93\n",
      "[37]\tvalid_0's tweedie: 470.925\n",
      "[38]\tvalid_0's tweedie: 470.919\n",
      "[39]\tvalid_0's tweedie: 470.914\n",
      "[40]\tvalid_0's tweedie: 470.905\n",
      "[41]\tvalid_0's tweedie: 470.897\n",
      "[42]\tvalid_0's tweedie: 470.894\n",
      "[43]\tvalid_0's tweedie: 470.889\n",
      "[44]\tvalid_0's tweedie: 470.884\n",
      "[45]\tvalid_0's tweedie: 470.883\n",
      "[46]\tvalid_0's tweedie: 470.88\n",
      "[47]\tvalid_0's tweedie: 470.876\n",
      "[48]\tvalid_0's tweedie: 470.875\n",
      "[49]\tvalid_0's tweedie: 470.871\n",
      "[50]\tvalid_0's tweedie: 470.871\n",
      "[51]\tvalid_0's tweedie: 470.87\n",
      "[52]\tvalid_0's tweedie: 470.869\n",
      "[53]\tvalid_0's tweedie: 470.869\n",
      "[54]\tvalid_0's tweedie: 470.865\n",
      "[55]\tvalid_0's tweedie: 470.865\n",
      "[56]\tvalid_0's tweedie: 470.864\n",
      "[57]\tvalid_0's tweedie: 470.862\n",
      "[58]\tvalid_0's tweedie: 470.863\n",
      "[59]\tvalid_0's tweedie: 470.862\n",
      "[60]\tvalid_0's tweedie: 470.86\n",
      "[61]\tvalid_0's tweedie: 470.859\n",
      "[62]\tvalid_0's tweedie: 470.858\n",
      "[63]\tvalid_0's tweedie: 470.851\n",
      "[64]\tvalid_0's tweedie: 470.853\n",
      "[65]\tvalid_0's tweedie: 470.852\n",
      "[66]\tvalid_0's tweedie: 470.852\n",
      "[67]\tvalid_0's tweedie: 470.852\n",
      "[68]\tvalid_0's tweedie: 470.852\n",
      "[69]\tvalid_0's tweedie: 470.853\n",
      "[70]\tvalid_0's tweedie: 470.852\n",
      "[71]\tvalid_0's tweedie: 470.855\n",
      "[72]\tvalid_0's tweedie: 470.855\n",
      "[73]\tvalid_0's tweedie: 470.855\n",
      "[74]\tvalid_0's tweedie: 470.854\n",
      "[75]\tvalid_0's tweedie: 470.854\n",
      "[76]\tvalid_0's tweedie: 470.854\n",
      "[77]\tvalid_0's tweedie: 470.853\n",
      "[78]\tvalid_0's tweedie: 470.851\n",
      "[79]\tvalid_0's tweedie: 470.851\n",
      "[80]\tvalid_0's tweedie: 470.851\n",
      "[81]\tvalid_0's tweedie: 470.851\n",
      "[82]\tvalid_0's tweedie: 470.851\n",
      "[83]\tvalid_0's tweedie: 470.851\n",
      "[84]\tvalid_0's tweedie: 470.85\n",
      "[85]\tvalid_0's tweedie: 470.848\n",
      "[86]\tvalid_0's tweedie: 470.849\n",
      "[87]\tvalid_0's tweedie: 470.848\n",
      "[88]\tvalid_0's tweedie: 470.846\n",
      "[89]\tvalid_0's tweedie: 470.846\n",
      "[90]\tvalid_0's tweedie: 470.846\n",
      "[91]\tvalid_0's tweedie: 470.845\n",
      "[92]\tvalid_0's tweedie: 470.845\n",
      "[93]\tvalid_0's tweedie: 470.844\n",
      "[94]\tvalid_0's tweedie: 470.845\n",
      "[95]\tvalid_0's tweedie: 470.845\n",
      "[96]\tvalid_0's tweedie: 470.844\n",
      "[97]\tvalid_0's tweedie: 470.843\n",
      "[98]\tvalid_0's tweedie: 470.843\n",
      "[99]\tvalid_0's tweedie: 470.843\n",
      "[100]\tvalid_0's tweedie: 470.843\n",
      "[101]\tvalid_0's tweedie: 470.843\n",
      "[102]\tvalid_0's tweedie: 470.843\n",
      "[103]\tvalid_0's tweedie: 470.842\n",
      "[104]\tvalid_0's tweedie: 470.842\n",
      "[105]\tvalid_0's tweedie: 470.842\n",
      "[106]\tvalid_0's tweedie: 470.84\n",
      "[107]\tvalid_0's tweedie: 470.84\n",
      "[108]\tvalid_0's tweedie: 470.839\n",
      "[109]\tvalid_0's tweedie: 470.838\n",
      "[110]\tvalid_0's tweedie: 470.838\n",
      "[111]\tvalid_0's tweedie: 470.837\n",
      "[112]\tvalid_0's tweedie: 470.838\n",
      "[113]\tvalid_0's tweedie: 470.838\n",
      "[114]\tvalid_0's tweedie: 470.838\n",
      "[115]\tvalid_0's tweedie: 470.839\n",
      "[116]\tvalid_0's tweedie: 470.839\n",
      "[117]\tvalid_0's tweedie: 470.839\n",
      "[118]\tvalid_0's tweedie: 470.838\n",
      "[119]\tvalid_0's tweedie: 470.838\n",
      "[120]\tvalid_0's tweedie: 470.838\n",
      "[121]\tvalid_0's tweedie: 470.837\n",
      "[122]\tvalid_0's tweedie: 470.837\n",
      "[123]\tvalid_0's tweedie: 470.835\n",
      "[124]\tvalid_0's tweedie: 470.835\n",
      "[125]\tvalid_0's tweedie: 470.835\n",
      "[126]\tvalid_0's tweedie: 470.835\n",
      "[127]\tvalid_0's tweedie: 470.835\n",
      "[128]\tvalid_0's tweedie: 470.835\n",
      "[129]\tvalid_0's tweedie: 470.833\n",
      "[130]\tvalid_0's tweedie: 470.832\n",
      "[131]\tvalid_0's tweedie: 470.833\n",
      "[132]\tvalid_0's tweedie: 470.833\n",
      "[133]\tvalid_0's tweedie: 470.831\n",
      "[134]\tvalid_0's tweedie: 470.831\n",
      "[135]\tvalid_0's tweedie: 470.831\n",
      "[136]\tvalid_0's tweedie: 470.831\n",
      "[137]\tvalid_0's tweedie: 470.831\n",
      "[138]\tvalid_0's tweedie: 470.831\n",
      "[139]\tvalid_0's tweedie: 470.831\n",
      "[140]\tvalid_0's tweedie: 470.831\n",
      "[141]\tvalid_0's tweedie: 470.831\n",
      "[142]\tvalid_0's tweedie: 470.831\n",
      "[143]\tvalid_0's tweedie: 470.83\n",
      "[144]\tvalid_0's tweedie: 470.83\n",
      "[145]\tvalid_0's tweedie: 470.828\n",
      "[146]\tvalid_0's tweedie: 470.828\n",
      "[147]\tvalid_0's tweedie: 470.828\n",
      "[148]\tvalid_0's tweedie: 470.828\n",
      "[149]\tvalid_0's tweedie: 470.828\n",
      "[150]\tvalid_0's tweedie: 470.828\n",
      "[151]\tvalid_0's tweedie: 470.828\n",
      "[152]\tvalid_0's tweedie: 470.827\n",
      "[153]\tvalid_0's tweedie: 470.827\n",
      "[154]\tvalid_0's tweedie: 470.829\n",
      "[155]\tvalid_0's tweedie: 470.827\n",
      "[156]\tvalid_0's tweedie: 470.827\n",
      "[157]\tvalid_0's tweedie: 470.827\n",
      "[158]\tvalid_0's tweedie: 470.827\n",
      "[159]\tvalid_0's tweedie: 470.827\n",
      "[160]\tvalid_0's tweedie: 470.826\n",
      "[161]\tvalid_0's tweedie: 470.825\n",
      "[162]\tvalid_0's tweedie: 470.824\n",
      "[163]\tvalid_0's tweedie: 470.823\n",
      "[164]\tvalid_0's tweedie: 470.823\n",
      "[165]\tvalid_0's tweedie: 470.823\n",
      "[166]\tvalid_0's tweedie: 470.823\n",
      "[167]\tvalid_0's tweedie: 470.822\n",
      "[168]\tvalid_0's tweedie: 470.822\n",
      "[169]\tvalid_0's tweedie: 470.822\n",
      "[170]\tvalid_0's tweedie: 470.822\n",
      "[171]\tvalid_0's tweedie: 470.822\n",
      "[172]\tvalid_0's tweedie: 470.821\n",
      "[173]\tvalid_0's tweedie: 470.821\n",
      "[174]\tvalid_0's tweedie: 470.821\n",
      "[175]\tvalid_0's tweedie: 470.822\n",
      "[176]\tvalid_0's tweedie: 470.821\n",
      "[177]\tvalid_0's tweedie: 470.822\n",
      "[178]\tvalid_0's tweedie: 470.821\n",
      "[179]\tvalid_0's tweedie: 470.821\n",
      "[180]\tvalid_0's tweedie: 470.821\n",
      "[181]\tvalid_0's tweedie: 470.821\n",
      "[182]\tvalid_0's tweedie: 470.821\n",
      "[183]\tvalid_0's tweedie: 470.821\n",
      "[184]\tvalid_0's tweedie: 470.821\n",
      "[185]\tvalid_0's tweedie: 470.821\n",
      "[186]\tvalid_0's tweedie: 470.821\n",
      "[187]\tvalid_0's tweedie: 470.819\n",
      "[188]\tvalid_0's tweedie: 470.819\n",
      "[189]\tvalid_0's tweedie: 470.819\n",
      "[190]\tvalid_0's tweedie: 470.818\n",
      "[191]\tvalid_0's tweedie: 470.818\n",
      "[192]\tvalid_0's tweedie: 470.819\n",
      "[193]\tvalid_0's tweedie: 470.818\n",
      "[194]\tvalid_0's tweedie: 470.818\n",
      "[195]\tvalid_0's tweedie: 470.818\n",
      "[196]\tvalid_0's tweedie: 470.818\n",
      "[197]\tvalid_0's tweedie: 470.818\n",
      "[198]\tvalid_0's tweedie: 470.818\n",
      "[199]\tvalid_0's tweedie: 470.819\n",
      "[200]\tvalid_0's tweedie: 470.819\n",
      "[201]\tvalid_0's tweedie: 470.817\n",
      "[202]\tvalid_0's tweedie: 470.817\n",
      "[203]\tvalid_0's tweedie: 470.817\n",
      "[204]\tvalid_0's tweedie: 470.818\n",
      "[205]\tvalid_0's tweedie: 470.819\n",
      "[206]\tvalid_0's tweedie: 470.818\n",
      "[207]\tvalid_0's tweedie: 470.819\n",
      "[208]\tvalid_0's tweedie: 470.818\n",
      "[209]\tvalid_0's tweedie: 470.818\n",
      "[210]\tvalid_0's tweedie: 470.818\n",
      "[211]\tvalid_0's tweedie: 470.818\n",
      "[212]\tvalid_0's tweedie: 470.818\n",
      "[213]\tvalid_0's tweedie: 470.817\n",
      "[214]\tvalid_0's tweedie: 470.817\n",
      "[215]\tvalid_0's tweedie: 470.817\n",
      "[216]\tvalid_0's tweedie: 470.817\n",
      "[217]\tvalid_0's tweedie: 470.817\n",
      "[218]\tvalid_0's tweedie: 470.817\n",
      "[219]\tvalid_0's tweedie: 470.818\n",
      "[220]\tvalid_0's tweedie: 470.818\n",
      "[221]\tvalid_0's tweedie: 470.818\n",
      "[222]\tvalid_0's tweedie: 470.816\n",
      "[223]\tvalid_0's tweedie: 470.816\n",
      "[224]\tvalid_0's tweedie: 470.816\n",
      "[225]\tvalid_0's tweedie: 470.816\n",
      "[226]\tvalid_0's tweedie: 470.816\n",
      "[227]\tvalid_0's tweedie: 470.817\n",
      "[228]\tvalid_0's tweedie: 470.817\n",
      "[229]\tvalid_0's tweedie: 470.816\n",
      "[230]\tvalid_0's tweedie: 470.816\n",
      "[231]\tvalid_0's tweedie: 470.816\n",
      "[232]\tvalid_0's tweedie: 470.816\n",
      "[233]\tvalid_0's tweedie: 470.816\n",
      "[234]\tvalid_0's tweedie: 470.816\n",
      "[235]\tvalid_0's tweedie: 470.816\n",
      "[236]\tvalid_0's tweedie: 470.816\n",
      "[237]\tvalid_0's tweedie: 470.816\n",
      "[238]\tvalid_0's tweedie: 470.816\n",
      "[239]\tvalid_0's tweedie: 470.816\n",
      "[240]\tvalid_0's tweedie: 470.816\n",
      "[241]\tvalid_0's tweedie: 470.816\n",
      "[242]\tvalid_0's tweedie: 470.816\n",
      "[243]\tvalid_0's tweedie: 470.816\n",
      "[244]\tvalid_0's tweedie: 470.816\n",
      "[245]\tvalid_0's tweedie: 470.815\n",
      "[246]\tvalid_0's tweedie: 470.815\n",
      "[247]\tvalid_0's tweedie: 470.815\n",
      "[248]\tvalid_0's tweedie: 470.816\n",
      "[249]\tvalid_0's tweedie: 470.816\n",
      "[250]\tvalid_0's tweedie: 470.816\n",
      "[251]\tvalid_0's tweedie: 470.816\n",
      "[252]\tvalid_0's tweedie: 470.815\n",
      "[253]\tvalid_0's tweedie: 470.816\n",
      "[254]\tvalid_0's tweedie: 470.816\n",
      "[255]\tvalid_0's tweedie: 470.816\n",
      "[256]\tvalid_0's tweedie: 470.816\n",
      "[257]\tvalid_0's tweedie: 470.816\n",
      "[258]\tvalid_0's tweedie: 470.816\n",
      "[259]\tvalid_0's tweedie: 470.816\n",
      "[260]\tvalid_0's tweedie: 470.816\n",
      "[261]\tvalid_0's tweedie: 470.815\n",
      "[262]\tvalid_0's tweedie: 470.814\n",
      "[263]\tvalid_0's tweedie: 470.814\n",
      "[264]\tvalid_0's tweedie: 470.815\n",
      "[265]\tvalid_0's tweedie: 470.815\n",
      "[266]\tvalid_0's tweedie: 470.815\n",
      "[267]\tvalid_0's tweedie: 470.815\n",
      "[268]\tvalid_0's tweedie: 470.815\n",
      "[269]\tvalid_0's tweedie: 470.815\n",
      "[270]\tvalid_0's tweedie: 470.815\n",
      "[271]\tvalid_0's tweedie: 470.815\n",
      "[272]\tvalid_0's tweedie: 470.815\n",
      "[273]\tvalid_0's tweedie: 470.814\n",
      "[274]\tvalid_0's tweedie: 470.814\n",
      "[275]\tvalid_0's tweedie: 470.814\n",
      "[276]\tvalid_0's tweedie: 470.814\n",
      "[277]\tvalid_0's tweedie: 470.814\n",
      "[278]\tvalid_0's tweedie: 470.814\n",
      "[279]\tvalid_0's tweedie: 470.813\n",
      "[280]\tvalid_0's tweedie: 470.813\n",
      "[281]\tvalid_0's tweedie: 470.813\n",
      "[282]\tvalid_0's tweedie: 470.813\n",
      "[283]\tvalid_0's tweedie: 470.813\n",
      "[284]\tvalid_0's tweedie: 470.814\n",
      "[285]\tvalid_0's tweedie: 470.814\n",
      "[286]\tvalid_0's tweedie: 470.813\n",
      "[287]\tvalid_0's tweedie: 470.813\n",
      "[288]\tvalid_0's tweedie: 470.813\n",
      "[289]\tvalid_0's tweedie: 470.813\n",
      "[290]\tvalid_0's tweedie: 470.813\n",
      "[291]\tvalid_0's tweedie: 470.813\n",
      "[292]\tvalid_0's tweedie: 470.813\n",
      "[293]\tvalid_0's tweedie: 470.813\n",
      "[294]\tvalid_0's tweedie: 470.813\n",
      "[295]\tvalid_0's tweedie: 470.813\n",
      "[296]\tvalid_0's tweedie: 470.812\n",
      "[297]\tvalid_0's tweedie: 470.813\n",
      "[298]\tvalid_0's tweedie: 470.813\n",
      "[299]\tvalid_0's tweedie: 470.813\n",
      "[300]\tvalid_0's tweedie: 470.812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 470.812\n",
      "Training model for level 2 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 5595, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344293\n",
      "[1]\tvalid_0's tweedie: 476.295\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.403\n",
      "[3]\tvalid_0's tweedie: 474.658\n",
      "[4]\tvalid_0's tweedie: 474.041\n",
      "[5]\tvalid_0's tweedie: 473.55\n",
      "[6]\tvalid_0's tweedie: 473.103\n",
      "[7]\tvalid_0's tweedie: 472.753\n",
      "[8]\tvalid_0's tweedie: 472.457\n",
      "[9]\tvalid_0's tweedie: 472.225\n",
      "[10]\tvalid_0's tweedie: 472.032\n",
      "[11]\tvalid_0's tweedie: 471.872\n",
      "[12]\tvalid_0's tweedie: 471.727\n",
      "[13]\tvalid_0's tweedie: 471.61\n",
      "[14]\tvalid_0's tweedie: 471.511\n",
      "[15]\tvalid_0's tweedie: 471.421\n",
      "[16]\tvalid_0's tweedie: 471.352\n",
      "[17]\tvalid_0's tweedie: 471.28\n",
      "[18]\tvalid_0's tweedie: 471.232\n",
      "[19]\tvalid_0's tweedie: 471.185\n",
      "[20]\tvalid_0's tweedie: 471.143\n",
      "[21]\tvalid_0's tweedie: 471.101\n",
      "[22]\tvalid_0's tweedie: 471.082\n",
      "[23]\tvalid_0's tweedie: 471.053\n",
      "[24]\tvalid_0's tweedie: 471.031\n",
      "[25]\tvalid_0's tweedie: 471.009\n",
      "[26]\tvalid_0's tweedie: 470.988\n",
      "[27]\tvalid_0's tweedie: 470.973\n",
      "[28]\tvalid_0's tweedie: 470.961\n",
      "[29]\tvalid_0's tweedie: 470.956\n",
      "[30]\tvalid_0's tweedie: 470.945\n",
      "[31]\tvalid_0's tweedie: 470.936\n",
      "[32]\tvalid_0's tweedie: 470.925\n",
      "[33]\tvalid_0's tweedie: 470.919\n",
      "[34]\tvalid_0's tweedie: 470.911\n",
      "[35]\tvalid_0's tweedie: 470.903\n",
      "[36]\tvalid_0's tweedie: 470.897\n",
      "[37]\tvalid_0's tweedie: 470.889\n",
      "[38]\tvalid_0's tweedie: 470.881\n",
      "[39]\tvalid_0's tweedie: 470.877\n",
      "[40]\tvalid_0's tweedie: 470.876\n",
      "[41]\tvalid_0's tweedie: 470.872\n",
      "[42]\tvalid_0's tweedie: 470.863\n",
      "[43]\tvalid_0's tweedie: 470.861\n",
      "[44]\tvalid_0's tweedie: 470.855\n",
      "[45]\tvalid_0's tweedie: 470.85\n",
      "[46]\tvalid_0's tweedie: 470.848\n",
      "[47]\tvalid_0's tweedie: 470.844\n",
      "[48]\tvalid_0's tweedie: 470.844\n",
      "[49]\tvalid_0's tweedie: 470.843\n",
      "[50]\tvalid_0's tweedie: 470.842\n",
      "[51]\tvalid_0's tweedie: 470.841\n",
      "[52]\tvalid_0's tweedie: 470.839\n",
      "[53]\tvalid_0's tweedie: 470.836\n",
      "[54]\tvalid_0's tweedie: 470.836\n",
      "[55]\tvalid_0's tweedie: 470.834\n",
      "[56]\tvalid_0's tweedie: 470.836\n",
      "[57]\tvalid_0's tweedie: 470.83\n",
      "[58]\tvalid_0's tweedie: 470.83\n",
      "[59]\tvalid_0's tweedie: 470.828\n",
      "[60]\tvalid_0's tweedie: 470.829\n",
      "[61]\tvalid_0's tweedie: 470.828\n",
      "[62]\tvalid_0's tweedie: 470.822\n",
      "[63]\tvalid_0's tweedie: 470.819\n",
      "[64]\tvalid_0's tweedie: 470.818\n",
      "[65]\tvalid_0's tweedie: 470.818\n",
      "[66]\tvalid_0's tweedie: 470.817\n",
      "[67]\tvalid_0's tweedie: 470.814\n",
      "[68]\tvalid_0's tweedie: 470.813\n",
      "[69]\tvalid_0's tweedie: 470.813\n",
      "[70]\tvalid_0's tweedie: 470.814\n",
      "[71]\tvalid_0's tweedie: 470.816\n",
      "[72]\tvalid_0's tweedie: 470.815\n",
      "[73]\tvalid_0's tweedie: 470.815\n",
      "[74]\tvalid_0's tweedie: 470.815\n",
      "[75]\tvalid_0's tweedie: 470.817\n",
      "[76]\tvalid_0's tweedie: 470.817\n",
      "[77]\tvalid_0's tweedie: 470.816\n",
      "[78]\tvalid_0's tweedie: 470.816\n",
      "[79]\tvalid_0's tweedie: 470.816\n",
      "[80]\tvalid_0's tweedie: 470.816\n",
      "[81]\tvalid_0's tweedie: 470.816\n",
      "[82]\tvalid_0's tweedie: 470.819\n",
      "[83]\tvalid_0's tweedie: 470.817\n",
      "[84]\tvalid_0's tweedie: 470.817\n",
      "[85]\tvalid_0's tweedie: 470.816\n",
      "[86]\tvalid_0's tweedie: 470.817\n",
      "[87]\tvalid_0's tweedie: 470.817\n",
      "[88]\tvalid_0's tweedie: 470.817\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's tweedie: 470.813\n",
      "Training model for level 2 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 5592, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344459\n",
      "[1]\tvalid_0's tweedie: 476.426\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.579\n",
      "[3]\tvalid_0's tweedie: 474.842\n",
      "[4]\tvalid_0's tweedie: 474.222\n",
      "[5]\tvalid_0's tweedie: 473.724\n",
      "[6]\tvalid_0's tweedie: 473.267\n",
      "[7]\tvalid_0's tweedie: 472.921\n",
      "[8]\tvalid_0's tweedie: 472.639\n",
      "[9]\tvalid_0's tweedie: 472.395\n",
      "[10]\tvalid_0's tweedie: 472.19\n",
      "[11]\tvalid_0's tweedie: 472.048\n",
      "[12]\tvalid_0's tweedie: 471.914\n",
      "[13]\tvalid_0's tweedie: 471.786\n",
      "[14]\tvalid_0's tweedie: 471.672\n",
      "[15]\tvalid_0's tweedie: 471.576\n",
      "[16]\tvalid_0's tweedie: 471.516\n",
      "[17]\tvalid_0's tweedie: 471.469\n",
      "[18]\tvalid_0's tweedie: 471.414\n",
      "[19]\tvalid_0's tweedie: 471.361\n",
      "[20]\tvalid_0's tweedie: 471.321\n",
      "[21]\tvalid_0's tweedie: 471.283\n",
      "[22]\tvalid_0's tweedie: 471.248\n",
      "[23]\tvalid_0's tweedie: 471.218\n",
      "[24]\tvalid_0's tweedie: 471.188\n",
      "[25]\tvalid_0's tweedie: 471.17\n",
      "[26]\tvalid_0's tweedie: 471.159\n",
      "[27]\tvalid_0's tweedie: 471.134\n",
      "[28]\tvalid_0's tweedie: 471.113\n",
      "[29]\tvalid_0's tweedie: 471.105\n",
      "[30]\tvalid_0's tweedie: 471.095\n",
      "[31]\tvalid_0's tweedie: 471.083\n",
      "[32]\tvalid_0's tweedie: 471.072\n",
      "[33]\tvalid_0's tweedie: 471.064\n",
      "[34]\tvalid_0's tweedie: 471.056\n",
      "[35]\tvalid_0's tweedie: 471.04\n",
      "[36]\tvalid_0's tweedie: 471.033\n",
      "[37]\tvalid_0's tweedie: 471.021\n",
      "[38]\tvalid_0's tweedie: 471.017\n",
      "[39]\tvalid_0's tweedie: 471.012\n",
      "[40]\tvalid_0's tweedie: 471.001\n",
      "[41]\tvalid_0's tweedie: 470.997\n",
      "[42]\tvalid_0's tweedie: 470.99\n",
      "[43]\tvalid_0's tweedie: 470.983\n",
      "[44]\tvalid_0's tweedie: 470.98\n",
      "[45]\tvalid_0's tweedie: 470.978\n",
      "[46]\tvalid_0's tweedie: 470.977\n",
      "[47]\tvalid_0's tweedie: 470.976\n",
      "[48]\tvalid_0's tweedie: 470.973\n",
      "[49]\tvalid_0's tweedie: 470.971\n",
      "[50]\tvalid_0's tweedie: 470.966\n",
      "[51]\tvalid_0's tweedie: 470.962\n",
      "[52]\tvalid_0's tweedie: 470.961\n",
      "[53]\tvalid_0's tweedie: 470.958\n",
      "[54]\tvalid_0's tweedie: 470.959\n",
      "[55]\tvalid_0's tweedie: 470.958\n",
      "[56]\tvalid_0's tweedie: 470.954\n",
      "[57]\tvalid_0's tweedie: 470.951\n",
      "[58]\tvalid_0's tweedie: 470.95\n",
      "[59]\tvalid_0's tweedie: 470.942\n",
      "[60]\tvalid_0's tweedie: 470.942\n",
      "[61]\tvalid_0's tweedie: 470.939\n",
      "[62]\tvalid_0's tweedie: 470.936\n",
      "[63]\tvalid_0's tweedie: 470.934\n",
      "[64]\tvalid_0's tweedie: 470.931\n",
      "[65]\tvalid_0's tweedie: 470.929\n",
      "[66]\tvalid_0's tweedie: 470.928\n",
      "[67]\tvalid_0's tweedie: 470.928\n",
      "[68]\tvalid_0's tweedie: 470.928\n",
      "[69]\tvalid_0's tweedie: 470.928\n",
      "[70]\tvalid_0's tweedie: 470.927\n",
      "[71]\tvalid_0's tweedie: 470.927\n",
      "[72]\tvalid_0's tweedie: 470.927\n",
      "[73]\tvalid_0's tweedie: 470.921\n",
      "[74]\tvalid_0's tweedie: 470.918\n",
      "[75]\tvalid_0's tweedie: 470.919\n",
      "[76]\tvalid_0's tweedie: 470.919\n",
      "[77]\tvalid_0's tweedie: 470.919\n",
      "[78]\tvalid_0's tweedie: 470.917\n",
      "[79]\tvalid_0's tweedie: 470.913\n",
      "[80]\tvalid_0's tweedie: 470.913\n",
      "[81]\tvalid_0's tweedie: 470.909\n",
      "[82]\tvalid_0's tweedie: 470.906\n",
      "[83]\tvalid_0's tweedie: 470.906\n",
      "[84]\tvalid_0's tweedie: 470.903\n",
      "[85]\tvalid_0's tweedie: 470.901\n",
      "[86]\tvalid_0's tweedie: 470.898\n",
      "[87]\tvalid_0's tweedie: 470.895\n",
      "[88]\tvalid_0's tweedie: 470.896\n",
      "[89]\tvalid_0's tweedie: 470.895\n",
      "[90]\tvalid_0's tweedie: 470.896\n",
      "[91]\tvalid_0's tweedie: 470.897\n",
      "[92]\tvalid_0's tweedie: 470.897\n",
      "[93]\tvalid_0's tweedie: 470.896\n",
      "[94]\tvalid_0's tweedie: 470.897\n",
      "[95]\tvalid_0's tweedie: 470.896\n",
      "[96]\tvalid_0's tweedie: 470.897\n",
      "[97]\tvalid_0's tweedie: 470.898\n",
      "[98]\tvalid_0's tweedie: 470.896\n",
      "[99]\tvalid_0's tweedie: 470.896\n",
      "[100]\tvalid_0's tweedie: 470.895\n",
      "[101]\tvalid_0's tweedie: 470.894\n",
      "[102]\tvalid_0's tweedie: 470.894\n",
      "[103]\tvalid_0's tweedie: 470.894\n",
      "[104]\tvalid_0's tweedie: 470.895\n",
      "[105]\tvalid_0's tweedie: 470.895\n",
      "[106]\tvalid_0's tweedie: 470.895\n",
      "[107]\tvalid_0's tweedie: 470.894\n",
      "[108]\tvalid_0's tweedie: 470.892\n",
      "[109]\tvalid_0's tweedie: 470.89\n",
      "[110]\tvalid_0's tweedie: 470.89\n",
      "[111]\tvalid_0's tweedie: 470.89\n",
      "[112]\tvalid_0's tweedie: 470.89\n",
      "[113]\tvalid_0's tweedie: 470.887\n",
      "[114]\tvalid_0's tweedie: 470.887\n",
      "[115]\tvalid_0's tweedie: 470.886\n",
      "[116]\tvalid_0's tweedie: 470.886\n",
      "[117]\tvalid_0's tweedie: 470.886\n",
      "[118]\tvalid_0's tweedie: 470.886\n",
      "[119]\tvalid_0's tweedie: 470.886\n",
      "[120]\tvalid_0's tweedie: 470.886\n",
      "[121]\tvalid_0's tweedie: 470.886\n",
      "[122]\tvalid_0's tweedie: 470.886\n",
      "[123]\tvalid_0's tweedie: 470.886\n",
      "[124]\tvalid_0's tweedie: 470.884\n",
      "[125]\tvalid_0's tweedie: 470.884\n",
      "[126]\tvalid_0's tweedie: 470.884\n",
      "[127]\tvalid_0's tweedie: 470.884\n",
      "[128]\tvalid_0's tweedie: 470.885\n",
      "[129]\tvalid_0's tweedie: 470.883\n",
      "[130]\tvalid_0's tweedie: 470.883\n",
      "[131]\tvalid_0's tweedie: 470.883\n",
      "[132]\tvalid_0's tweedie: 470.882\n",
      "[133]\tvalid_0's tweedie: 470.883\n",
      "[134]\tvalid_0's tweedie: 470.883\n",
      "[135]\tvalid_0's tweedie: 470.882\n",
      "[136]\tvalid_0's tweedie: 470.882\n",
      "[137]\tvalid_0's tweedie: 470.882\n",
      "[138]\tvalid_0's tweedie: 470.88\n",
      "[139]\tvalid_0's tweedie: 470.879\n",
      "[140]\tvalid_0's tweedie: 470.879\n",
      "[141]\tvalid_0's tweedie: 470.878\n",
      "[142]\tvalid_0's tweedie: 470.876\n",
      "[143]\tvalid_0's tweedie: 470.876\n",
      "[144]\tvalid_0's tweedie: 470.876\n",
      "[145]\tvalid_0's tweedie: 470.876\n",
      "[146]\tvalid_0's tweedie: 470.876\n",
      "[147]\tvalid_0's tweedie: 470.876\n",
      "[148]\tvalid_0's tweedie: 470.876\n",
      "[149]\tvalid_0's tweedie: 470.876\n",
      "[150]\tvalid_0's tweedie: 470.875\n",
      "[151]\tvalid_0's tweedie: 470.875\n",
      "[152]\tvalid_0's tweedie: 470.877\n",
      "[153]\tvalid_0's tweedie: 470.875\n",
      "[154]\tvalid_0's tweedie: 470.875\n",
      "[155]\tvalid_0's tweedie: 470.875\n",
      "[156]\tvalid_0's tweedie: 470.874\n",
      "[157]\tvalid_0's tweedie: 470.874\n",
      "[158]\tvalid_0's tweedie: 470.874\n",
      "[159]\tvalid_0's tweedie: 470.874\n",
      "[160]\tvalid_0's tweedie: 470.874\n",
      "[161]\tvalid_0's tweedie: 470.873\n",
      "[162]\tvalid_0's tweedie: 470.873\n",
      "[163]\tvalid_0's tweedie: 470.874\n",
      "[164]\tvalid_0's tweedie: 470.875\n",
      "[165]\tvalid_0's tweedie: 470.874\n",
      "[166]\tvalid_0's tweedie: 470.874\n",
      "[167]\tvalid_0's tweedie: 470.874\n",
      "[168]\tvalid_0's tweedie: 470.874\n",
      "[169]\tvalid_0's tweedie: 470.873\n",
      "[170]\tvalid_0's tweedie: 470.873\n",
      "[171]\tvalid_0's tweedie: 470.874\n",
      "[172]\tvalid_0's tweedie: 470.874\n",
      "[173]\tvalid_0's tweedie: 470.874\n",
      "[174]\tvalid_0's tweedie: 470.874\n",
      "[175]\tvalid_0's tweedie: 470.874\n",
      "[176]\tvalid_0's tweedie: 470.874\n",
      "[177]\tvalid_0's tweedie: 470.874\n",
      "[178]\tvalid_0's tweedie: 470.875\n",
      "[179]\tvalid_0's tweedie: 470.875\n",
      "[180]\tvalid_0's tweedie: 470.875\n",
      "[181]\tvalid_0's tweedie: 470.875\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's tweedie: 470.873\n",
      "Training model for level 2 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 5589, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344500\n",
      "[1]\tvalid_0's tweedie: 476.424\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.594\n",
      "[3]\tvalid_0's tweedie: 474.868\n",
      "[4]\tvalid_0's tweedie: 474.244\n",
      "[5]\tvalid_0's tweedie: 473.764\n",
      "[6]\tvalid_0's tweedie: 473.323\n",
      "[7]\tvalid_0's tweedie: 473.001\n",
      "[8]\tvalid_0's tweedie: 472.71\n",
      "[9]\tvalid_0's tweedie: 472.456\n",
      "[10]\tvalid_0's tweedie: 472.259\n",
      "[11]\tvalid_0's tweedie: 472.088\n",
      "[12]\tvalid_0's tweedie: 471.96\n",
      "[13]\tvalid_0's tweedie: 471.856\n",
      "[14]\tvalid_0's tweedie: 471.743\n",
      "[15]\tvalid_0's tweedie: 471.666\n",
      "[16]\tvalid_0's tweedie: 471.582\n",
      "[17]\tvalid_0's tweedie: 471.517\n",
      "[18]\tvalid_0's tweedie: 471.468\n",
      "[19]\tvalid_0's tweedie: 471.416\n",
      "[20]\tvalid_0's tweedie: 471.389\n",
      "[21]\tvalid_0's tweedie: 471.355\n",
      "[22]\tvalid_0's tweedie: 471.318\n",
      "[23]\tvalid_0's tweedie: 471.291\n",
      "[24]\tvalid_0's tweedie: 471.264\n",
      "[25]\tvalid_0's tweedie: 471.245\n",
      "[26]\tvalid_0's tweedie: 471.225\n",
      "[27]\tvalid_0's tweedie: 471.204\n",
      "[28]\tvalid_0's tweedie: 471.189\n",
      "[29]\tvalid_0's tweedie: 471.172\n",
      "[30]\tvalid_0's tweedie: 471.148\n",
      "[31]\tvalid_0's tweedie: 471.132\n",
      "[32]\tvalid_0's tweedie: 471.115\n",
      "[33]\tvalid_0's tweedie: 471.1\n",
      "[34]\tvalid_0's tweedie: 471.095\n",
      "[35]\tvalid_0's tweedie: 471.09\n",
      "[36]\tvalid_0's tweedie: 471.085\n",
      "[37]\tvalid_0's tweedie: 471.069\n",
      "[38]\tvalid_0's tweedie: 471.064\n",
      "[39]\tvalid_0's tweedie: 471.059\n",
      "[40]\tvalid_0's tweedie: 471.047\n",
      "[41]\tvalid_0's tweedie: 471.046\n",
      "[42]\tvalid_0's tweedie: 471.038\n",
      "[43]\tvalid_0's tweedie: 471.036\n",
      "[44]\tvalid_0's tweedie: 471.029\n",
      "[45]\tvalid_0's tweedie: 471.021\n",
      "[46]\tvalid_0's tweedie: 471.014\n",
      "[47]\tvalid_0's tweedie: 471.008\n",
      "[48]\tvalid_0's tweedie: 471.008\n",
      "[49]\tvalid_0's tweedie: 471.003\n",
      "[50]\tvalid_0's tweedie: 471.004\n",
      "[51]\tvalid_0's tweedie: 471.002\n",
      "[52]\tvalid_0's tweedie: 470.997\n",
      "[53]\tvalid_0's tweedie: 470.993\n",
      "[54]\tvalid_0's tweedie: 470.991\n",
      "[55]\tvalid_0's tweedie: 470.988\n",
      "[56]\tvalid_0's tweedie: 470.984\n",
      "[57]\tvalid_0's tweedie: 470.984\n",
      "[58]\tvalid_0's tweedie: 470.984\n",
      "[59]\tvalid_0's tweedie: 470.979\n",
      "[60]\tvalid_0's tweedie: 470.979\n",
      "[61]\tvalid_0's tweedie: 470.976\n",
      "[62]\tvalid_0's tweedie: 470.976\n",
      "[63]\tvalid_0's tweedie: 470.974\n",
      "[64]\tvalid_0's tweedie: 470.972\n",
      "[65]\tvalid_0's tweedie: 470.971\n",
      "[66]\tvalid_0's tweedie: 470.971\n",
      "[67]\tvalid_0's tweedie: 470.97\n",
      "[68]\tvalid_0's tweedie: 470.967\n",
      "[69]\tvalid_0's tweedie: 470.966\n",
      "[70]\tvalid_0's tweedie: 470.966\n",
      "[71]\tvalid_0's tweedie: 470.965\n",
      "[72]\tvalid_0's tweedie: 470.963\n",
      "[73]\tvalid_0's tweedie: 470.963\n",
      "[74]\tvalid_0's tweedie: 470.96\n",
      "[75]\tvalid_0's tweedie: 470.959\n",
      "[76]\tvalid_0's tweedie: 470.958\n",
      "[77]\tvalid_0's tweedie: 470.958\n",
      "[78]\tvalid_0's tweedie: 470.955\n",
      "[79]\tvalid_0's tweedie: 470.954\n",
      "[80]\tvalid_0's tweedie: 470.952\n",
      "[81]\tvalid_0's tweedie: 470.952\n",
      "[82]\tvalid_0's tweedie: 470.953\n",
      "[83]\tvalid_0's tweedie: 470.951\n",
      "[84]\tvalid_0's tweedie: 470.947\n",
      "[85]\tvalid_0's tweedie: 470.948\n",
      "[86]\tvalid_0's tweedie: 470.948\n",
      "[87]\tvalid_0's tweedie: 470.948\n",
      "[88]\tvalid_0's tweedie: 470.948\n",
      "[89]\tvalid_0's tweedie: 470.947\n",
      "[90]\tvalid_0's tweedie: 470.946\n",
      "[91]\tvalid_0's tweedie: 470.945\n",
      "[92]\tvalid_0's tweedie: 470.937\n",
      "[93]\tvalid_0's tweedie: 470.935\n",
      "[94]\tvalid_0's tweedie: 470.933\n",
      "[95]\tvalid_0's tweedie: 470.928\n",
      "[96]\tvalid_0's tweedie: 470.929\n",
      "[97]\tvalid_0's tweedie: 470.928\n",
      "[98]\tvalid_0's tweedie: 470.929\n",
      "[99]\tvalid_0's tweedie: 470.926\n",
      "[100]\tvalid_0's tweedie: 470.926\n",
      "[101]\tvalid_0's tweedie: 470.926\n",
      "[102]\tvalid_0's tweedie: 470.925\n",
      "[103]\tvalid_0's tweedie: 470.924\n",
      "[104]\tvalid_0's tweedie: 470.924\n",
      "[105]\tvalid_0's tweedie: 470.924\n",
      "[106]\tvalid_0's tweedie: 470.924\n",
      "[107]\tvalid_0's tweedie: 470.924\n",
      "[108]\tvalid_0's tweedie: 470.923\n",
      "[109]\tvalid_0's tweedie: 470.923\n",
      "[110]\tvalid_0's tweedie: 470.922\n",
      "[111]\tvalid_0's tweedie: 470.922\n",
      "[112]\tvalid_0's tweedie: 470.921\n",
      "[113]\tvalid_0's tweedie: 470.921\n",
      "[114]\tvalid_0's tweedie: 470.919\n",
      "[115]\tvalid_0's tweedie: 470.916\n",
      "[116]\tvalid_0's tweedie: 470.916\n",
      "[117]\tvalid_0's tweedie: 470.916\n",
      "[118]\tvalid_0's tweedie: 470.915\n",
      "[119]\tvalid_0's tweedie: 470.912\n",
      "[120]\tvalid_0's tweedie: 470.912\n",
      "[121]\tvalid_0's tweedie: 470.912\n",
      "[122]\tvalid_0's tweedie: 470.912\n",
      "[123]\tvalid_0's tweedie: 470.912\n",
      "[124]\tvalid_0's tweedie: 470.912\n",
      "[125]\tvalid_0's tweedie: 470.912\n",
      "[126]\tvalid_0's tweedie: 470.912\n",
      "[127]\tvalid_0's tweedie: 470.912\n",
      "[128]\tvalid_0's tweedie: 470.912\n",
      "[129]\tvalid_0's tweedie: 470.912\n",
      "[130]\tvalid_0's tweedie: 470.913\n",
      "[131]\tvalid_0's tweedie: 470.913\n",
      "[132]\tvalid_0's tweedie: 470.913\n",
      "[133]\tvalid_0's tweedie: 470.913\n",
      "[134]\tvalid_0's tweedie: 470.913\n",
      "[135]\tvalid_0's tweedie: 470.913\n",
      "[136]\tvalid_0's tweedie: 470.912\n",
      "[137]\tvalid_0's tweedie: 470.912\n",
      "[138]\tvalid_0's tweedie: 470.912\n",
      "[139]\tvalid_0's tweedie: 470.912\n",
      "[140]\tvalid_0's tweedie: 470.912\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's tweedie: 470.912\n",
      "Training model for level 2 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 5586, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344578\n",
      "[1]\tvalid_0's tweedie: 476.423\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.593\n",
      "[3]\tvalid_0's tweedie: 474.867\n",
      "[4]\tvalid_0's tweedie: 474.243\n",
      "[5]\tvalid_0's tweedie: 473.763\n",
      "[6]\tvalid_0's tweedie: 473.332\n",
      "[7]\tvalid_0's tweedie: 472.979\n",
      "[8]\tvalid_0's tweedie: 472.702\n",
      "[9]\tvalid_0's tweedie: 472.455\n",
      "[10]\tvalid_0's tweedie: 472.254\n",
      "[11]\tvalid_0's tweedie: 472.069\n",
      "[12]\tvalid_0's tweedie: 471.923\n",
      "[13]\tvalid_0's tweedie: 471.797\n",
      "[14]\tvalid_0's tweedie: 471.69\n",
      "[15]\tvalid_0's tweedie: 471.599\n",
      "[16]\tvalid_0's tweedie: 471.525\n",
      "[17]\tvalid_0's tweedie: 471.449\n",
      "[18]\tvalid_0's tweedie: 471.414\n",
      "[19]\tvalid_0's tweedie: 471.371\n",
      "[20]\tvalid_0's tweedie: 471.338\n",
      "[21]\tvalid_0's tweedie: 471.298\n",
      "[22]\tvalid_0's tweedie: 471.266\n",
      "[23]\tvalid_0's tweedie: 471.243\n",
      "[24]\tvalid_0's tweedie: 471.234\n",
      "[25]\tvalid_0's tweedie: 471.202\n",
      "[26]\tvalid_0's tweedie: 471.18\n",
      "[27]\tvalid_0's tweedie: 471.17\n",
      "[28]\tvalid_0's tweedie: 471.149\n",
      "[29]\tvalid_0's tweedie: 471.139\n",
      "[30]\tvalid_0's tweedie: 471.123\n",
      "[31]\tvalid_0's tweedie: 471.113\n",
      "[32]\tvalid_0's tweedie: 471.102\n",
      "[33]\tvalid_0's tweedie: 471.084\n",
      "[34]\tvalid_0's tweedie: 471.075\n",
      "[35]\tvalid_0's tweedie: 471.058\n",
      "[36]\tvalid_0's tweedie: 471.051\n",
      "[37]\tvalid_0's tweedie: 471.043\n",
      "[38]\tvalid_0's tweedie: 471.031\n",
      "[39]\tvalid_0's tweedie: 471.02\n",
      "[40]\tvalid_0's tweedie: 471.012\n",
      "[41]\tvalid_0's tweedie: 471.001\n",
      "[42]\tvalid_0's tweedie: 470.995\n",
      "[43]\tvalid_0's tweedie: 470.991\n",
      "[44]\tvalid_0's tweedie: 470.989\n",
      "[45]\tvalid_0's tweedie: 470.987\n",
      "[46]\tvalid_0's tweedie: 470.981\n",
      "[47]\tvalid_0's tweedie: 470.981\n",
      "[48]\tvalid_0's tweedie: 470.972\n",
      "[49]\tvalid_0's tweedie: 470.968\n",
      "[50]\tvalid_0's tweedie: 470.963\n",
      "[51]\tvalid_0's tweedie: 470.96\n",
      "[52]\tvalid_0's tweedie: 470.957\n",
      "[53]\tvalid_0's tweedie: 470.95\n",
      "[54]\tvalid_0's tweedie: 470.946\n",
      "[55]\tvalid_0's tweedie: 470.946\n",
      "[56]\tvalid_0's tweedie: 470.945\n",
      "[57]\tvalid_0's tweedie: 470.945\n",
      "[58]\tvalid_0's tweedie: 470.942\n",
      "[59]\tvalid_0's tweedie: 470.943\n",
      "[60]\tvalid_0's tweedie: 470.939\n",
      "[61]\tvalid_0's tweedie: 470.939\n",
      "[62]\tvalid_0's tweedie: 470.938\n",
      "[63]\tvalid_0's tweedie: 470.939\n",
      "[64]\tvalid_0's tweedie: 470.938\n",
      "[65]\tvalid_0's tweedie: 470.938\n",
      "[66]\tvalid_0's tweedie: 470.937\n",
      "[67]\tvalid_0's tweedie: 470.936\n",
      "[68]\tvalid_0's tweedie: 470.935\n",
      "[69]\tvalid_0's tweedie: 470.93\n",
      "[70]\tvalid_0's tweedie: 470.93\n",
      "[71]\tvalid_0's tweedie: 470.928\n",
      "[72]\tvalid_0's tweedie: 470.922\n",
      "[73]\tvalid_0's tweedie: 470.921\n",
      "[74]\tvalid_0's tweedie: 470.918\n",
      "[75]\tvalid_0's tweedie: 470.916\n",
      "[76]\tvalid_0's tweedie: 470.916\n",
      "[77]\tvalid_0's tweedie: 470.915\n",
      "[78]\tvalid_0's tweedie: 470.915\n",
      "[79]\tvalid_0's tweedie: 470.913\n",
      "[80]\tvalid_0's tweedie: 470.912\n",
      "[81]\tvalid_0's tweedie: 470.91\n",
      "[82]\tvalid_0's tweedie: 470.91\n",
      "[83]\tvalid_0's tweedie: 470.909\n",
      "[84]\tvalid_0's tweedie: 470.908\n",
      "[85]\tvalid_0's tweedie: 470.907\n",
      "[86]\tvalid_0's tweedie: 470.907\n",
      "[87]\tvalid_0's tweedie: 470.907\n",
      "[88]\tvalid_0's tweedie: 470.906\n",
      "[89]\tvalid_0's tweedie: 470.905\n",
      "[90]\tvalid_0's tweedie: 470.905\n",
      "[91]\tvalid_0's tweedie: 470.905\n",
      "[92]\tvalid_0's tweedie: 470.905\n",
      "[93]\tvalid_0's tweedie: 470.905\n",
      "[94]\tvalid_0's tweedie: 470.905\n",
      "[95]\tvalid_0's tweedie: 470.904\n",
      "[96]\tvalid_0's tweedie: 470.904\n",
      "[97]\tvalid_0's tweedie: 470.903\n",
      "[98]\tvalid_0's tweedie: 470.903\n",
      "[99]\tvalid_0's tweedie: 470.903\n",
      "[100]\tvalid_0's tweedie: 470.902\n",
      "[101]\tvalid_0's tweedie: 470.903\n",
      "[102]\tvalid_0's tweedie: 470.9\n",
      "[103]\tvalid_0's tweedie: 470.9\n",
      "[104]\tvalid_0's tweedie: 470.9\n",
      "[105]\tvalid_0's tweedie: 470.9\n",
      "[106]\tvalid_0's tweedie: 470.9\n",
      "[107]\tvalid_0's tweedie: 470.898\n",
      "[108]\tvalid_0's tweedie: 470.899\n",
      "[109]\tvalid_0's tweedie: 470.902\n",
      "[110]\tvalid_0's tweedie: 470.902\n",
      "[111]\tvalid_0's tweedie: 470.902\n",
      "[112]\tvalid_0's tweedie: 470.9\n",
      "[113]\tvalid_0's tweedie: 470.9\n",
      "[114]\tvalid_0's tweedie: 470.9\n",
      "[115]\tvalid_0's tweedie: 470.9\n",
      "[116]\tvalid_0's tweedie: 470.898\n",
      "[117]\tvalid_0's tweedie: 470.898\n",
      "[118]\tvalid_0's tweedie: 470.899\n",
      "[119]\tvalid_0's tweedie: 470.899\n",
      "[120]\tvalid_0's tweedie: 470.898\n",
      "[121]\tvalid_0's tweedie: 470.896\n",
      "[122]\tvalid_0's tweedie: 470.894\n",
      "[123]\tvalid_0's tweedie: 470.895\n",
      "[124]\tvalid_0's tweedie: 470.893\n",
      "[125]\tvalid_0's tweedie: 470.892\n",
      "[126]\tvalid_0's tweedie: 470.892\n",
      "[127]\tvalid_0's tweedie: 470.893\n",
      "[128]\tvalid_0's tweedie: 470.893\n",
      "[129]\tvalid_0's tweedie: 470.893\n",
      "[130]\tvalid_0's tweedie: 470.893\n",
      "[131]\tvalid_0's tweedie: 470.892\n",
      "[132]\tvalid_0's tweedie: 470.89\n",
      "[133]\tvalid_0's tweedie: 470.89\n",
      "[134]\tvalid_0's tweedie: 470.89\n",
      "[135]\tvalid_0's tweedie: 470.89\n",
      "[136]\tvalid_0's tweedie: 470.89\n",
      "[137]\tvalid_0's tweedie: 470.889\n",
      "[138]\tvalid_0's tweedie: 470.885\n",
      "[139]\tvalid_0's tweedie: 470.885\n",
      "[140]\tvalid_0's tweedie: 470.883\n",
      "[141]\tvalid_0's tweedie: 470.883\n",
      "[142]\tvalid_0's tweedie: 470.882\n",
      "[143]\tvalid_0's tweedie: 470.882\n",
      "[144]\tvalid_0's tweedie: 470.882\n",
      "[145]\tvalid_0's tweedie: 470.882\n",
      "[146]\tvalid_0's tweedie: 470.882\n",
      "[147]\tvalid_0's tweedie: 470.883\n",
      "[148]\tvalid_0's tweedie: 470.883\n",
      "[149]\tvalid_0's tweedie: 470.883\n",
      "[150]\tvalid_0's tweedie: 470.883\n",
      "[151]\tvalid_0's tweedie: 470.882\n",
      "[152]\tvalid_0's tweedie: 470.883\n",
      "[153]\tvalid_0's tweedie: 470.882\n",
      "[154]\tvalid_0's tweedie: 470.882\n",
      "[155]\tvalid_0's tweedie: 470.881\n",
      "[156]\tvalid_0's tweedie: 470.882\n",
      "[157]\tvalid_0's tweedie: 470.882\n",
      "[158]\tvalid_0's tweedie: 470.882\n",
      "[159]\tvalid_0's tweedie: 470.881\n",
      "[160]\tvalid_0's tweedie: 470.879\n",
      "[161]\tvalid_0's tweedie: 470.88\n",
      "[162]\tvalid_0's tweedie: 470.879\n",
      "[163]\tvalid_0's tweedie: 470.879\n",
      "[164]\tvalid_0's tweedie: 470.879\n",
      "[165]\tvalid_0's tweedie: 470.877\n",
      "[166]\tvalid_0's tweedie: 470.874\n",
      "[167]\tvalid_0's tweedie: 470.874\n",
      "[168]\tvalid_0's tweedie: 470.874\n",
      "[169]\tvalid_0's tweedie: 470.874\n",
      "[170]\tvalid_0's tweedie: 470.875\n",
      "[171]\tvalid_0's tweedie: 470.876\n",
      "[172]\tvalid_0's tweedie: 470.877\n",
      "[173]\tvalid_0's tweedie: 470.877\n",
      "[174]\tvalid_0's tweedie: 470.877\n",
      "[175]\tvalid_0's tweedie: 470.877\n",
      "[176]\tvalid_0's tweedie: 470.877\n",
      "[177]\tvalid_0's tweedie: 470.874\n",
      "[178]\tvalid_0's tweedie: 470.874\n",
      "[179]\tvalid_0's tweedie: 470.874\n",
      "[180]\tvalid_0's tweedie: 470.874\n",
      "[181]\tvalid_0's tweedie: 470.874\n",
      "[182]\tvalid_0's tweedie: 470.875\n",
      "[183]\tvalid_0's tweedie: 470.874\n",
      "[184]\tvalid_0's tweedie: 470.873\n",
      "[185]\tvalid_0's tweedie: 470.871\n",
      "[186]\tvalid_0's tweedie: 470.872\n",
      "[187]\tvalid_0's tweedie: 470.873\n",
      "[188]\tvalid_0's tweedie: 470.873\n",
      "[189]\tvalid_0's tweedie: 470.873\n",
      "[190]\tvalid_0's tweedie: 470.872\n",
      "[191]\tvalid_0's tweedie: 470.872\n",
      "[192]\tvalid_0's tweedie: 470.872\n",
      "[193]\tvalid_0's tweedie: 470.872\n",
      "[194]\tvalid_0's tweedie: 470.871\n",
      "[195]\tvalid_0's tweedie: 470.871\n",
      "[196]\tvalid_0's tweedie: 470.871\n",
      "[197]\tvalid_0's tweedie: 470.87\n",
      "[198]\tvalid_0's tweedie: 470.871\n",
      "[199]\tvalid_0's tweedie: 470.87\n",
      "[200]\tvalid_0's tweedie: 470.87\n",
      "[201]\tvalid_0's tweedie: 470.869\n",
      "[202]\tvalid_0's tweedie: 470.868\n",
      "[203]\tvalid_0's tweedie: 470.868\n",
      "[204]\tvalid_0's tweedie: 470.868\n",
      "[205]\tvalid_0's tweedie: 470.868\n",
      "[206]\tvalid_0's tweedie: 470.867\n",
      "[207]\tvalid_0's tweedie: 470.868\n",
      "[208]\tvalid_0's tweedie: 470.867\n",
      "[209]\tvalid_0's tweedie: 470.867\n",
      "[210]\tvalid_0's tweedie: 470.867\n",
      "[211]\tvalid_0's tweedie: 470.866\n",
      "[212]\tvalid_0's tweedie: 470.866\n",
      "[213]\tvalid_0's tweedie: 470.866\n",
      "[214]\tvalid_0's tweedie: 470.865\n",
      "[215]\tvalid_0's tweedie: 470.865\n",
      "[216]\tvalid_0's tweedie: 470.865\n",
      "[217]\tvalid_0's tweedie: 470.864\n",
      "[218]\tvalid_0's tweedie: 470.864\n",
      "[219]\tvalid_0's tweedie: 470.863\n",
      "[220]\tvalid_0's tweedie: 470.863\n",
      "[221]\tvalid_0's tweedie: 470.863\n",
      "[222]\tvalid_0's tweedie: 470.863\n",
      "[223]\tvalid_0's tweedie: 470.863\n",
      "[224]\tvalid_0's tweedie: 470.866\n",
      "[225]\tvalid_0's tweedie: 470.866\n",
      "[226]\tvalid_0's tweedie: 470.864\n",
      "[227]\tvalid_0's tweedie: 470.865\n",
      "[228]\tvalid_0's tweedie: 470.865\n",
      "[229]\tvalid_0's tweedie: 470.864\n",
      "[230]\tvalid_0's tweedie: 470.864\n",
      "[231]\tvalid_0's tweedie: 470.864\n",
      "[232]\tvalid_0's tweedie: 470.864\n",
      "[233]\tvalid_0's tweedie: 470.864\n",
      "[234]\tvalid_0's tweedie: 470.861\n",
      "[235]\tvalid_0's tweedie: 470.86\n",
      "[236]\tvalid_0's tweedie: 470.859\n",
      "[237]\tvalid_0's tweedie: 470.859\n",
      "[238]\tvalid_0's tweedie: 470.859\n",
      "[239]\tvalid_0's tweedie: 470.863\n",
      "[240]\tvalid_0's tweedie: 470.863\n",
      "[241]\tvalid_0's tweedie: 470.863\n",
      "[242]\tvalid_0's tweedie: 470.862\n",
      "[243]\tvalid_0's tweedie: 470.862\n",
      "[244]\tvalid_0's tweedie: 470.862\n",
      "[245]\tvalid_0's tweedie: 470.861\n",
      "[246]\tvalid_0's tweedie: 470.861\n",
      "[247]\tvalid_0's tweedie: 470.862\n",
      "[248]\tvalid_0's tweedie: 470.862\n",
      "[249]\tvalid_0's tweedie: 470.862\n",
      "[250]\tvalid_0's tweedie: 470.861\n",
      "[251]\tvalid_0's tweedie: 470.861\n",
      "[252]\tvalid_0's tweedie: 470.861\n",
      "[253]\tvalid_0's tweedie: 470.861\n",
      "[254]\tvalid_0's tweedie: 470.861\n",
      "[255]\tvalid_0's tweedie: 470.861\n",
      "[256]\tvalid_0's tweedie: 470.86\n",
      "[257]\tvalid_0's tweedie: 470.859\n",
      "[258]\tvalid_0's tweedie: 470.86\n",
      "[259]\tvalid_0's tweedie: 470.86\n",
      "[260]\tvalid_0's tweedie: 470.86\n",
      "[261]\tvalid_0's tweedie: 470.86\n",
      "[262]\tvalid_0's tweedie: 470.86\n",
      "[263]\tvalid_0's tweedie: 470.86\n",
      "[264]\tvalid_0's tweedie: 470.86\n",
      "[265]\tvalid_0's tweedie: 470.859\n",
      "[266]\tvalid_0's tweedie: 470.859\n",
      "[267]\tvalid_0's tweedie: 470.859\n",
      "[268]\tvalid_0's tweedie: 470.859\n",
      "[269]\tvalid_0's tweedie: 470.859\n",
      "[270]\tvalid_0's tweedie: 470.858\n",
      "[271]\tvalid_0's tweedie: 470.858\n",
      "[272]\tvalid_0's tweedie: 470.858\n",
      "[273]\tvalid_0's tweedie: 470.858\n",
      "[274]\tvalid_0's tweedie: 470.858\n",
      "[275]\tvalid_0's tweedie: 470.858\n",
      "[276]\tvalid_0's tweedie: 470.858\n",
      "[277]\tvalid_0's tweedie: 470.857\n",
      "[278]\tvalid_0's tweedie: 470.856\n",
      "[279]\tvalid_0's tweedie: 470.856\n",
      "[280]\tvalid_0's tweedie: 470.855\n",
      "[281]\tvalid_0's tweedie: 470.855\n",
      "[282]\tvalid_0's tweedie: 470.852\n",
      "[283]\tvalid_0's tweedie: 470.852\n",
      "[284]\tvalid_0's tweedie: 470.852\n",
      "[285]\tvalid_0's tweedie: 470.852\n",
      "[286]\tvalid_0's tweedie: 470.851\n",
      "[287]\tvalid_0's tweedie: 470.851\n",
      "[288]\tvalid_0's tweedie: 470.851\n",
      "[289]\tvalid_0's tweedie: 470.851\n",
      "[290]\tvalid_0's tweedie: 470.851\n",
      "[291]\tvalid_0's tweedie: 470.851\n",
      "[292]\tvalid_0's tweedie: 470.85\n",
      "[293]\tvalid_0's tweedie: 470.85\n",
      "[294]\tvalid_0's tweedie: 470.851\n",
      "[295]\tvalid_0's tweedie: 470.851\n",
      "[296]\tvalid_0's tweedie: 470.85\n",
      "[297]\tvalid_0's tweedie: 470.85\n",
      "[298]\tvalid_0's tweedie: 470.85\n",
      "[299]\tvalid_0's tweedie: 470.85\n",
      "[300]\tvalid_0's tweedie: 470.849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 470.849\n",
      "Training model for level 2 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 5583, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344740\n",
      "[1]\tvalid_0's tweedie: 476.432\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.61\n",
      "[3]\tvalid_0's tweedie: 474.938\n",
      "[4]\tvalid_0's tweedie: 474.334\n",
      "[5]\tvalid_0's tweedie: 473.798\n",
      "[6]\tvalid_0's tweedie: 473.383\n",
      "[7]\tvalid_0's tweedie: 473.013\n",
      "[8]\tvalid_0's tweedie: 472.713\n",
      "[9]\tvalid_0's tweedie: 472.476\n",
      "[10]\tvalid_0's tweedie: 472.272\n",
      "[11]\tvalid_0's tweedie: 472.094\n",
      "[12]\tvalid_0's tweedie: 471.956\n",
      "[13]\tvalid_0's tweedie: 471.825\n",
      "[14]\tvalid_0's tweedie: 471.703\n",
      "[15]\tvalid_0's tweedie: 471.604\n",
      "[16]\tvalid_0's tweedie: 471.528\n",
      "[17]\tvalid_0's tweedie: 471.469\n",
      "[18]\tvalid_0's tweedie: 471.43\n",
      "[19]\tvalid_0's tweedie: 471.38\n",
      "[20]\tvalid_0's tweedie: 471.345\n",
      "[21]\tvalid_0's tweedie: 471.303\n",
      "[22]\tvalid_0's tweedie: 471.277\n",
      "[23]\tvalid_0's tweedie: 471.249\n",
      "[24]\tvalid_0's tweedie: 471.238\n",
      "[25]\tvalid_0's tweedie: 471.214\n",
      "[26]\tvalid_0's tweedie: 471.189\n",
      "[27]\tvalid_0's tweedie: 471.192\n",
      "[28]\tvalid_0's tweedie: 471.187\n",
      "[29]\tvalid_0's tweedie: 471.174\n",
      "[30]\tvalid_0's tweedie: 471.164\n",
      "[31]\tvalid_0's tweedie: 471.153\n",
      "[32]\tvalid_0's tweedie: 471.133\n",
      "[33]\tvalid_0's tweedie: 471.117\n",
      "[34]\tvalid_0's tweedie: 471.112\n",
      "[35]\tvalid_0's tweedie: 471.099\n",
      "[36]\tvalid_0's tweedie: 471.091\n",
      "[37]\tvalid_0's tweedie: 471.076\n",
      "[38]\tvalid_0's tweedie: 471.06\n",
      "[39]\tvalid_0's tweedie: 471.049\n",
      "[40]\tvalid_0's tweedie: 471.038\n",
      "[41]\tvalid_0's tweedie: 471.029\n",
      "[42]\tvalid_0's tweedie: 471.022\n",
      "[43]\tvalid_0's tweedie: 471.014\n",
      "[44]\tvalid_0's tweedie: 470.998\n",
      "[45]\tvalid_0's tweedie: 470.994\n",
      "[46]\tvalid_0's tweedie: 470.988\n",
      "[47]\tvalid_0's tweedie: 470.987\n",
      "[48]\tvalid_0's tweedie: 470.984\n",
      "[49]\tvalid_0's tweedie: 470.976\n",
      "[50]\tvalid_0's tweedie: 470.972\n",
      "[51]\tvalid_0's tweedie: 470.972\n",
      "[52]\tvalid_0's tweedie: 470.97\n",
      "[53]\tvalid_0's tweedie: 470.968\n",
      "[54]\tvalid_0's tweedie: 470.962\n",
      "[55]\tvalid_0's tweedie: 470.959\n",
      "[56]\tvalid_0's tweedie: 470.958\n",
      "[57]\tvalid_0's tweedie: 470.954\n",
      "[58]\tvalid_0's tweedie: 470.954\n",
      "[59]\tvalid_0's tweedie: 470.952\n",
      "[60]\tvalid_0's tweedie: 470.951\n",
      "[61]\tvalid_0's tweedie: 470.948\n",
      "[62]\tvalid_0's tweedie: 470.941\n",
      "[63]\tvalid_0's tweedie: 470.934\n",
      "[64]\tvalid_0's tweedie: 470.932\n",
      "[65]\tvalid_0's tweedie: 470.932\n",
      "[66]\tvalid_0's tweedie: 470.93\n",
      "[67]\tvalid_0's tweedie: 470.93\n",
      "[68]\tvalid_0's tweedie: 470.928\n",
      "[69]\tvalid_0's tweedie: 470.924\n",
      "[70]\tvalid_0's tweedie: 470.922\n",
      "[71]\tvalid_0's tweedie: 470.921\n",
      "[72]\tvalid_0's tweedie: 470.916\n",
      "[73]\tvalid_0's tweedie: 470.915\n",
      "[74]\tvalid_0's tweedie: 470.915\n",
      "[75]\tvalid_0's tweedie: 470.913\n",
      "[76]\tvalid_0's tweedie: 470.909\n",
      "[77]\tvalid_0's tweedie: 470.907\n",
      "[78]\tvalid_0's tweedie: 470.905\n",
      "[79]\tvalid_0's tweedie: 470.905\n",
      "[80]\tvalid_0's tweedie: 470.905\n",
      "[81]\tvalid_0's tweedie: 470.904\n",
      "[82]\tvalid_0's tweedie: 470.904\n",
      "[83]\tvalid_0's tweedie: 470.903\n",
      "[84]\tvalid_0's tweedie: 470.904\n",
      "[85]\tvalid_0's tweedie: 470.9\n",
      "[86]\tvalid_0's tweedie: 470.9\n",
      "[87]\tvalid_0's tweedie: 470.899\n",
      "[88]\tvalid_0's tweedie: 470.899\n",
      "[89]\tvalid_0's tweedie: 470.898\n",
      "[90]\tvalid_0's tweedie: 470.898\n",
      "[91]\tvalid_0's tweedie: 470.897\n",
      "[92]\tvalid_0's tweedie: 470.898\n",
      "[93]\tvalid_0's tweedie: 470.896\n",
      "[94]\tvalid_0's tweedie: 470.896\n",
      "[95]\tvalid_0's tweedie: 470.894\n",
      "[96]\tvalid_0's tweedie: 470.893\n",
      "[97]\tvalid_0's tweedie: 470.893\n",
      "[98]\tvalid_0's tweedie: 470.893\n",
      "[99]\tvalid_0's tweedie: 470.893\n",
      "[100]\tvalid_0's tweedie: 470.893\n",
      "[101]\tvalid_0's tweedie: 470.89\n",
      "[102]\tvalid_0's tweedie: 470.89\n",
      "[103]\tvalid_0's tweedie: 470.89\n",
      "[104]\tvalid_0's tweedie: 470.89\n",
      "[105]\tvalid_0's tweedie: 470.887\n",
      "[106]\tvalid_0's tweedie: 470.885\n",
      "[107]\tvalid_0's tweedie: 470.885\n",
      "[108]\tvalid_0's tweedie: 470.883\n",
      "[109]\tvalid_0's tweedie: 470.883\n",
      "[110]\tvalid_0's tweedie: 470.883\n",
      "[111]\tvalid_0's tweedie: 470.881\n",
      "[112]\tvalid_0's tweedie: 470.881\n",
      "[113]\tvalid_0's tweedie: 470.877\n",
      "[114]\tvalid_0's tweedie: 470.875\n",
      "[115]\tvalid_0's tweedie: 470.875\n",
      "[116]\tvalid_0's tweedie: 470.875\n",
      "[117]\tvalid_0's tweedie: 470.875\n",
      "[118]\tvalid_0's tweedie: 470.875\n",
      "[119]\tvalid_0's tweedie: 470.874\n",
      "[120]\tvalid_0's tweedie: 470.873\n",
      "[121]\tvalid_0's tweedie: 470.873\n",
      "[122]\tvalid_0's tweedie: 470.873\n",
      "[123]\tvalid_0's tweedie: 470.873\n",
      "[124]\tvalid_0's tweedie: 470.872\n",
      "[125]\tvalid_0's tweedie: 470.872\n",
      "[126]\tvalid_0's tweedie: 470.872\n",
      "[127]\tvalid_0's tweedie: 470.872\n",
      "[128]\tvalid_0's tweedie: 470.872\n",
      "[129]\tvalid_0's tweedie: 470.872\n",
      "[130]\tvalid_0's tweedie: 470.872\n",
      "[131]\tvalid_0's tweedie: 470.872\n",
      "[132]\tvalid_0's tweedie: 470.875\n",
      "[133]\tvalid_0's tweedie: 470.874\n",
      "[134]\tvalid_0's tweedie: 470.872\n",
      "[135]\tvalid_0's tweedie: 470.872\n",
      "[136]\tvalid_0's tweedie: 470.868\n",
      "[137]\tvalid_0's tweedie: 470.868\n",
      "[138]\tvalid_0's tweedie: 470.865\n",
      "[139]\tvalid_0's tweedie: 470.865\n",
      "[140]\tvalid_0's tweedie: 470.864\n",
      "[141]\tvalid_0's tweedie: 470.864\n",
      "[142]\tvalid_0's tweedie: 470.863\n",
      "[143]\tvalid_0's tweedie: 470.862\n",
      "[144]\tvalid_0's tweedie: 470.859\n",
      "[145]\tvalid_0's tweedie: 470.859\n",
      "[146]\tvalid_0's tweedie: 470.858\n",
      "[147]\tvalid_0's tweedie: 470.858\n",
      "[148]\tvalid_0's tweedie: 470.858\n",
      "[149]\tvalid_0's tweedie: 470.855\n",
      "[150]\tvalid_0's tweedie: 470.855\n",
      "[151]\tvalid_0's tweedie: 470.855\n",
      "[152]\tvalid_0's tweedie: 470.855\n",
      "[153]\tvalid_0's tweedie: 470.851\n",
      "[154]\tvalid_0's tweedie: 470.85\n",
      "[155]\tvalid_0's tweedie: 470.85\n",
      "[156]\tvalid_0's tweedie: 470.85\n",
      "[157]\tvalid_0's tweedie: 470.85\n",
      "[158]\tvalid_0's tweedie: 470.85\n",
      "[159]\tvalid_0's tweedie: 470.851\n",
      "[160]\tvalid_0's tweedie: 470.851\n",
      "[161]\tvalid_0's tweedie: 470.85\n",
      "[162]\tvalid_0's tweedie: 470.85\n",
      "[163]\tvalid_0's tweedie: 470.85\n",
      "[164]\tvalid_0's tweedie: 470.849\n",
      "[165]\tvalid_0's tweedie: 470.848\n",
      "[166]\tvalid_0's tweedie: 470.848\n",
      "[167]\tvalid_0's tweedie: 470.848\n",
      "[168]\tvalid_0's tweedie: 470.849\n",
      "[169]\tvalid_0's tweedie: 470.849\n",
      "[170]\tvalid_0's tweedie: 470.849\n",
      "[171]\tvalid_0's tweedie: 470.847\n",
      "[172]\tvalid_0's tweedie: 470.849\n",
      "[173]\tvalid_0's tweedie: 470.847\n",
      "[174]\tvalid_0's tweedie: 470.846\n",
      "[175]\tvalid_0's tweedie: 470.846\n",
      "[176]\tvalid_0's tweedie: 470.846\n",
      "[177]\tvalid_0's tweedie: 470.844\n",
      "[178]\tvalid_0's tweedie: 470.844\n",
      "[179]\tvalid_0's tweedie: 470.843\n",
      "[180]\tvalid_0's tweedie: 470.843\n",
      "[181]\tvalid_0's tweedie: 470.842\n",
      "[182]\tvalid_0's tweedie: 470.843\n",
      "[183]\tvalid_0's tweedie: 470.843\n",
      "[184]\tvalid_0's tweedie: 470.843\n",
      "[185]\tvalid_0's tweedie: 470.84\n",
      "[186]\tvalid_0's tweedie: 470.837\n",
      "[187]\tvalid_0's tweedie: 470.837\n",
      "[188]\tvalid_0's tweedie: 470.837\n",
      "[189]\tvalid_0's tweedie: 470.837\n",
      "[190]\tvalid_0's tweedie: 470.836\n",
      "[191]\tvalid_0's tweedie: 470.837\n",
      "[192]\tvalid_0's tweedie: 470.836\n",
      "[193]\tvalid_0's tweedie: 470.836\n",
      "[194]\tvalid_0's tweedie: 470.835\n",
      "[195]\tvalid_0's tweedie: 470.834\n",
      "[196]\tvalid_0's tweedie: 470.834\n",
      "[197]\tvalid_0's tweedie: 470.835\n",
      "[198]\tvalid_0's tweedie: 470.835\n",
      "[199]\tvalid_0's tweedie: 470.834\n",
      "[200]\tvalid_0's tweedie: 470.834\n",
      "[201]\tvalid_0's tweedie: 470.834\n",
      "[202]\tvalid_0's tweedie: 470.833\n",
      "[203]\tvalid_0's tweedie: 470.833\n",
      "[204]\tvalid_0's tweedie: 470.833\n",
      "[205]\tvalid_0's tweedie: 470.833\n",
      "[206]\tvalid_0's tweedie: 470.833\n",
      "[207]\tvalid_0's tweedie: 470.833\n",
      "[208]\tvalid_0's tweedie: 470.833\n",
      "[209]\tvalid_0's tweedie: 470.833\n",
      "[210]\tvalid_0's tweedie: 470.833\n",
      "[211]\tvalid_0's tweedie: 470.833\n",
      "[212]\tvalid_0's tweedie: 470.833\n",
      "[213]\tvalid_0's tweedie: 470.833\n",
      "[214]\tvalid_0's tweedie: 470.832\n",
      "[215]\tvalid_0's tweedie: 470.831\n",
      "[216]\tvalid_0's tweedie: 470.83\n",
      "[217]\tvalid_0's tweedie: 470.83\n",
      "[218]\tvalid_0's tweedie: 470.83\n",
      "[219]\tvalid_0's tweedie: 470.83\n",
      "[220]\tvalid_0's tweedie: 470.83\n",
      "[221]\tvalid_0's tweedie: 470.83\n",
      "[222]\tvalid_0's tweedie: 470.83\n",
      "[223]\tvalid_0's tweedie: 470.831\n",
      "[224]\tvalid_0's tweedie: 470.832\n",
      "[225]\tvalid_0's tweedie: 470.832\n",
      "[226]\tvalid_0's tweedie: 470.832\n",
      "[227]\tvalid_0's tweedie: 470.832\n",
      "[228]\tvalid_0's tweedie: 470.832\n",
      "[229]\tvalid_0's tweedie: 470.831\n",
      "[230]\tvalid_0's tweedie: 470.831\n",
      "[231]\tvalid_0's tweedie: 470.831\n",
      "[232]\tvalid_0's tweedie: 470.83\n",
      "[233]\tvalid_0's tweedie: 470.829\n",
      "[234]\tvalid_0's tweedie: 470.829\n",
      "[235]\tvalid_0's tweedie: 470.828\n",
      "[236]\tvalid_0's tweedie: 470.828\n",
      "[237]\tvalid_0's tweedie: 470.827\n",
      "[238]\tvalid_0's tweedie: 470.827\n",
      "[239]\tvalid_0's tweedie: 470.827\n",
      "[240]\tvalid_0's tweedie: 470.826\n",
      "[241]\tvalid_0's tweedie: 470.826\n",
      "[242]\tvalid_0's tweedie: 470.826\n",
      "[243]\tvalid_0's tweedie: 470.826\n",
      "[244]\tvalid_0's tweedie: 470.825\n",
      "[245]\tvalid_0's tweedie: 470.825\n",
      "[246]\tvalid_0's tweedie: 470.824\n",
      "[247]\tvalid_0's tweedie: 470.824\n",
      "[248]\tvalid_0's tweedie: 470.824\n",
      "[249]\tvalid_0's tweedie: 470.824\n",
      "[250]\tvalid_0's tweedie: 470.824\n",
      "[251]\tvalid_0's tweedie: 470.824\n",
      "[252]\tvalid_0's tweedie: 470.824\n",
      "[253]\tvalid_0's tweedie: 470.824\n",
      "[254]\tvalid_0's tweedie: 470.824\n",
      "[255]\tvalid_0's tweedie: 470.823\n",
      "[256]\tvalid_0's tweedie: 470.823\n",
      "[257]\tvalid_0's tweedie: 470.823\n",
      "[258]\tvalid_0's tweedie: 470.824\n",
      "[259]\tvalid_0's tweedie: 470.823\n",
      "[260]\tvalid_0's tweedie: 470.823\n",
      "[261]\tvalid_0's tweedie: 470.823\n",
      "[262]\tvalid_0's tweedie: 470.823\n",
      "[263]\tvalid_0's tweedie: 470.823\n",
      "[264]\tvalid_0's tweedie: 470.823\n",
      "[265]\tvalid_0's tweedie: 470.823\n",
      "[266]\tvalid_0's tweedie: 470.823\n",
      "[267]\tvalid_0's tweedie: 470.823\n",
      "[268]\tvalid_0's tweedie: 470.825\n",
      "[269]\tvalid_0's tweedie: 470.825\n",
      "[270]\tvalid_0's tweedie: 470.825\n",
      "[271]\tvalid_0's tweedie: 470.826\n",
      "[272]\tvalid_0's tweedie: 470.826\n",
      "[273]\tvalid_0's tweedie: 470.826\n",
      "[274]\tvalid_0's tweedie: 470.826\n",
      "[275]\tvalid_0's tweedie: 470.825\n",
      "[276]\tvalid_0's tweedie: 470.825\n",
      "[277]\tvalid_0's tweedie: 470.825\n",
      "[278]\tvalid_0's tweedie: 470.825\n",
      "[279]\tvalid_0's tweedie: 470.825\n",
      "[280]\tvalid_0's tweedie: 470.825\n",
      "[281]\tvalid_0's tweedie: 470.825\n",
      "[282]\tvalid_0's tweedie: 470.825\n",
      "[283]\tvalid_0's tweedie: 470.825\n",
      "[284]\tvalid_0's tweedie: 470.826\n",
      "[285]\tvalid_0's tweedie: 470.826\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's tweedie: 470.823\n",
      "Training model for level 2 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 5580, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344957\n",
      "[1]\tvalid_0's tweedie: 476.412\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.582\n",
      "[3]\tvalid_0's tweedie: 474.893\n",
      "[4]\tvalid_0's tweedie: 474.286\n",
      "[5]\tvalid_0's tweedie: 473.76\n",
      "[6]\tvalid_0's tweedie: 473.354\n",
      "[7]\tvalid_0's tweedie: 472.971\n",
      "[8]\tvalid_0's tweedie: 472.707\n",
      "[9]\tvalid_0's tweedie: 472.47\n",
      "[10]\tvalid_0's tweedie: 472.259\n",
      "[11]\tvalid_0's tweedie: 472.089\n",
      "[12]\tvalid_0's tweedie: 471.943\n",
      "[13]\tvalid_0's tweedie: 471.824\n",
      "[14]\tvalid_0's tweedie: 471.722\n",
      "[15]\tvalid_0's tweedie: 471.635\n",
      "[16]\tvalid_0's tweedie: 471.55\n",
      "[17]\tvalid_0's tweedie: 471.486\n",
      "[18]\tvalid_0's tweedie: 471.426\n",
      "[19]\tvalid_0's tweedie: 471.386\n",
      "[20]\tvalid_0's tweedie: 471.339\n",
      "[21]\tvalid_0's tweedie: 471.308\n",
      "[22]\tvalid_0's tweedie: 471.284\n",
      "[23]\tvalid_0's tweedie: 471.269\n",
      "[24]\tvalid_0's tweedie: 471.243\n",
      "[25]\tvalid_0's tweedie: 471.214\n",
      "[26]\tvalid_0's tweedie: 471.198\n",
      "[27]\tvalid_0's tweedie: 471.184\n",
      "[28]\tvalid_0's tweedie: 471.173\n",
      "[29]\tvalid_0's tweedie: 471.156\n",
      "[30]\tvalid_0's tweedie: 471.143\n",
      "[31]\tvalid_0's tweedie: 471.127\n",
      "[32]\tvalid_0's tweedie: 471.112\n",
      "[33]\tvalid_0's tweedie: 471.101\n",
      "[34]\tvalid_0's tweedie: 471.096\n",
      "[35]\tvalid_0's tweedie: 471.089\n",
      "[36]\tvalid_0's tweedie: 471.081\n",
      "[37]\tvalid_0's tweedie: 471.069\n",
      "[38]\tvalid_0's tweedie: 471.07\n",
      "[39]\tvalid_0's tweedie: 471.061\n",
      "[40]\tvalid_0's tweedie: 471.051\n",
      "[41]\tvalid_0's tweedie: 471.041\n",
      "[42]\tvalid_0's tweedie: 471.039\n",
      "[43]\tvalid_0's tweedie: 471.031\n",
      "[44]\tvalid_0's tweedie: 471.026\n",
      "[45]\tvalid_0's tweedie: 471.015\n",
      "[46]\tvalid_0's tweedie: 471.011\n",
      "[47]\tvalid_0's tweedie: 471.006\n",
      "[48]\tvalid_0's tweedie: 471.003\n",
      "[49]\tvalid_0's tweedie: 471\n",
      "[50]\tvalid_0's tweedie: 470.989\n",
      "[51]\tvalid_0's tweedie: 470.99\n",
      "[52]\tvalid_0's tweedie: 470.986\n",
      "[53]\tvalid_0's tweedie: 470.982\n",
      "[54]\tvalid_0's tweedie: 470.981\n",
      "[55]\tvalid_0's tweedie: 470.981\n",
      "[56]\tvalid_0's tweedie: 470.972\n",
      "[57]\tvalid_0's tweedie: 470.967\n",
      "[58]\tvalid_0's tweedie: 470.964\n",
      "[59]\tvalid_0's tweedie: 470.961\n",
      "[60]\tvalid_0's tweedie: 470.958\n",
      "[61]\tvalid_0's tweedie: 470.959\n",
      "[62]\tvalid_0's tweedie: 470.954\n",
      "[63]\tvalid_0's tweedie: 470.954\n",
      "[64]\tvalid_0's tweedie: 470.953\n",
      "[65]\tvalid_0's tweedie: 470.95\n",
      "[66]\tvalid_0's tweedie: 470.948\n",
      "[67]\tvalid_0's tweedie: 470.947\n",
      "[68]\tvalid_0's tweedie: 470.946\n",
      "[69]\tvalid_0's tweedie: 470.944\n",
      "[70]\tvalid_0's tweedie: 470.94\n",
      "[71]\tvalid_0's tweedie: 470.94\n",
      "[72]\tvalid_0's tweedie: 470.938\n",
      "[73]\tvalid_0's tweedie: 470.936\n",
      "[74]\tvalid_0's tweedie: 470.936\n",
      "[75]\tvalid_0's tweedie: 470.934\n",
      "[76]\tvalid_0's tweedie: 470.936\n",
      "[77]\tvalid_0's tweedie: 470.934\n",
      "[78]\tvalid_0's tweedie: 470.933\n",
      "[79]\tvalid_0's tweedie: 470.928\n",
      "[80]\tvalid_0's tweedie: 470.928\n",
      "[81]\tvalid_0's tweedie: 470.928\n",
      "[82]\tvalid_0's tweedie: 470.924\n",
      "[83]\tvalid_0's tweedie: 470.92\n",
      "[84]\tvalid_0's tweedie: 470.92\n",
      "[85]\tvalid_0's tweedie: 470.919\n",
      "[86]\tvalid_0's tweedie: 470.919\n",
      "[87]\tvalid_0's tweedie: 470.918\n",
      "[88]\tvalid_0's tweedie: 470.916\n",
      "[89]\tvalid_0's tweedie: 470.915\n",
      "[90]\tvalid_0's tweedie: 470.915\n",
      "[91]\tvalid_0's tweedie: 470.916\n",
      "[92]\tvalid_0's tweedie: 470.916\n",
      "[93]\tvalid_0's tweedie: 470.915\n",
      "[94]\tvalid_0's tweedie: 470.915\n",
      "[95]\tvalid_0's tweedie: 470.916\n",
      "[96]\tvalid_0's tweedie: 470.915\n",
      "[97]\tvalid_0's tweedie: 470.915\n",
      "[98]\tvalid_0's tweedie: 470.91\n",
      "[99]\tvalid_0's tweedie: 470.909\n",
      "[100]\tvalid_0's tweedie: 470.907\n",
      "[101]\tvalid_0's tweedie: 470.907\n",
      "[102]\tvalid_0's tweedie: 470.91\n",
      "[103]\tvalid_0's tweedie: 470.91\n",
      "[104]\tvalid_0's tweedie: 470.909\n",
      "[105]\tvalid_0's tweedie: 470.909\n",
      "[106]\tvalid_0's tweedie: 470.909\n",
      "[107]\tvalid_0's tweedie: 470.907\n",
      "[108]\tvalid_0's tweedie: 470.907\n",
      "[109]\tvalid_0's tweedie: 470.905\n",
      "[110]\tvalid_0's tweedie: 470.902\n",
      "[111]\tvalid_0's tweedie: 470.902\n",
      "[112]\tvalid_0's tweedie: 470.902\n",
      "[113]\tvalid_0's tweedie: 470.902\n",
      "[114]\tvalid_0's tweedie: 470.902\n",
      "[115]\tvalid_0's tweedie: 470.902\n",
      "[116]\tvalid_0's tweedie: 470.901\n",
      "[117]\tvalid_0's tweedie: 470.899\n",
      "[118]\tvalid_0's tweedie: 470.901\n",
      "[119]\tvalid_0's tweedie: 470.901\n",
      "[120]\tvalid_0's tweedie: 470.901\n",
      "[121]\tvalid_0's tweedie: 470.901\n",
      "[122]\tvalid_0's tweedie: 470.899\n",
      "[123]\tvalid_0's tweedie: 470.9\n",
      "[124]\tvalid_0's tweedie: 470.899\n",
      "[125]\tvalid_0's tweedie: 470.899\n",
      "[126]\tvalid_0's tweedie: 470.898\n",
      "[127]\tvalid_0's tweedie: 470.896\n",
      "[128]\tvalid_0's tweedie: 470.891\n",
      "[129]\tvalid_0's tweedie: 470.889\n",
      "[130]\tvalid_0's tweedie: 470.889\n",
      "[131]\tvalid_0's tweedie: 470.888\n",
      "[132]\tvalid_0's tweedie: 470.889\n",
      "[133]\tvalid_0's tweedie: 470.889\n",
      "[134]\tvalid_0's tweedie: 470.888\n",
      "[135]\tvalid_0's tweedie: 470.888\n",
      "[136]\tvalid_0's tweedie: 470.889\n",
      "[137]\tvalid_0's tweedie: 470.89\n",
      "[138]\tvalid_0's tweedie: 470.89\n",
      "[139]\tvalid_0's tweedie: 470.89\n",
      "[140]\tvalid_0's tweedie: 470.889\n",
      "[141]\tvalid_0's tweedie: 470.889\n",
      "[142]\tvalid_0's tweedie: 470.887\n",
      "[143]\tvalid_0's tweedie: 470.888\n",
      "[144]\tvalid_0's tweedie: 470.888\n",
      "[145]\tvalid_0's tweedie: 470.888\n",
      "[146]\tvalid_0's tweedie: 470.887\n",
      "[147]\tvalid_0's tweedie: 470.887\n",
      "[148]\tvalid_0's tweedie: 470.888\n",
      "[149]\tvalid_0's tweedie: 470.887\n",
      "[150]\tvalid_0's tweedie: 470.887\n",
      "[151]\tvalid_0's tweedie: 470.886\n",
      "[152]\tvalid_0's tweedie: 470.887\n",
      "[153]\tvalid_0's tweedie: 470.887\n",
      "[154]\tvalid_0's tweedie: 470.886\n",
      "[155]\tvalid_0's tweedie: 470.888\n",
      "[156]\tvalid_0's tweedie: 470.887\n",
      "[157]\tvalid_0's tweedie: 470.887\n",
      "[158]\tvalid_0's tweedie: 470.887\n",
      "[159]\tvalid_0's tweedie: 470.887\n",
      "[160]\tvalid_0's tweedie: 470.887\n",
      "[161]\tvalid_0's tweedie: 470.887\n",
      "[162]\tvalid_0's tweedie: 470.886\n",
      "[163]\tvalid_0's tweedie: 470.886\n",
      "[164]\tvalid_0's tweedie: 470.882\n",
      "[165]\tvalid_0's tweedie: 470.882\n",
      "[166]\tvalid_0's tweedie: 470.883\n",
      "[167]\tvalid_0's tweedie: 470.883\n",
      "[168]\tvalid_0's tweedie: 470.883\n",
      "[169]\tvalid_0's tweedie: 470.884\n",
      "[170]\tvalid_0's tweedie: 470.884\n",
      "[171]\tvalid_0's tweedie: 470.883\n",
      "[172]\tvalid_0's tweedie: 470.883\n",
      "[173]\tvalid_0's tweedie: 470.884\n",
      "[174]\tvalid_0's tweedie: 470.885\n",
      "[175]\tvalid_0's tweedie: 470.885\n",
      "[176]\tvalid_0's tweedie: 470.886\n",
      "[177]\tvalid_0's tweedie: 470.886\n",
      "[178]\tvalid_0's tweedie: 470.886\n",
      "[179]\tvalid_0's tweedie: 470.885\n",
      "[180]\tvalid_0's tweedie: 470.885\n",
      "[181]\tvalid_0's tweedie: 470.885\n",
      "[182]\tvalid_0's tweedie: 470.884\n",
      "[183]\tvalid_0's tweedie: 470.883\n",
      "[184]\tvalid_0's tweedie: 470.885\n",
      "[185]\tvalid_0's tweedie: 470.884\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's tweedie: 470.882\n",
      "Training model for level 2 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 5577, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345169\n",
      "[1]\tvalid_0's tweedie: 476.43\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.593\n",
      "[3]\tvalid_0's tweedie: 474.895\n",
      "[4]\tvalid_0's tweedie: 474.291\n",
      "[5]\tvalid_0's tweedie: 473.787\n",
      "[6]\tvalid_0's tweedie: 473.364\n",
      "[7]\tvalid_0's tweedie: 473.008\n",
      "[8]\tvalid_0's tweedie: 472.736\n",
      "[9]\tvalid_0's tweedie: 472.483\n",
      "[10]\tvalid_0's tweedie: 472.288\n",
      "[11]\tvalid_0's tweedie: 472.121\n",
      "[12]\tvalid_0's tweedie: 471.974\n",
      "[13]\tvalid_0's tweedie: 471.862\n",
      "[14]\tvalid_0's tweedie: 471.754\n",
      "[15]\tvalid_0's tweedie: 471.653\n",
      "[16]\tvalid_0's tweedie: 471.587\n",
      "[17]\tvalid_0's tweedie: 471.523\n",
      "[18]\tvalid_0's tweedie: 471.458\n",
      "[19]\tvalid_0's tweedie: 471.41\n",
      "[20]\tvalid_0's tweedie: 471.374\n",
      "[21]\tvalid_0's tweedie: 471.331\n",
      "[22]\tvalid_0's tweedie: 471.294\n",
      "[23]\tvalid_0's tweedie: 471.273\n",
      "[24]\tvalid_0's tweedie: 471.252\n",
      "[25]\tvalid_0's tweedie: 471.228\n",
      "[26]\tvalid_0's tweedie: 471.202\n",
      "[27]\tvalid_0's tweedie: 471.183\n",
      "[28]\tvalid_0's tweedie: 471.164\n",
      "[29]\tvalid_0's tweedie: 471.154\n",
      "[30]\tvalid_0's tweedie: 471.139\n",
      "[31]\tvalid_0's tweedie: 471.12\n",
      "[32]\tvalid_0's tweedie: 471.106\n",
      "[33]\tvalid_0's tweedie: 471.087\n",
      "[34]\tvalid_0's tweedie: 471.072\n",
      "[35]\tvalid_0's tweedie: 471.065\n",
      "[36]\tvalid_0's tweedie: 471.05\n",
      "[37]\tvalid_0's tweedie: 471.034\n",
      "[38]\tvalid_0's tweedie: 471.031\n",
      "[39]\tvalid_0's tweedie: 471.021\n",
      "[40]\tvalid_0's tweedie: 471.01\n",
      "[41]\tvalid_0's tweedie: 471.003\n",
      "[42]\tvalid_0's tweedie: 470.991\n",
      "[43]\tvalid_0's tweedie: 470.988\n",
      "[44]\tvalid_0's tweedie: 470.985\n",
      "[45]\tvalid_0's tweedie: 470.976\n",
      "[46]\tvalid_0's tweedie: 470.97\n",
      "[47]\tvalid_0's tweedie: 470.966\n",
      "[48]\tvalid_0's tweedie: 470.964\n",
      "[49]\tvalid_0's tweedie: 470.963\n",
      "[50]\tvalid_0's tweedie: 470.96\n",
      "[51]\tvalid_0's tweedie: 470.957\n",
      "[52]\tvalid_0's tweedie: 470.956\n",
      "[53]\tvalid_0's tweedie: 470.949\n",
      "[54]\tvalid_0's tweedie: 470.945\n",
      "[55]\tvalid_0's tweedie: 470.938\n",
      "[56]\tvalid_0's tweedie: 470.932\n",
      "[57]\tvalid_0's tweedie: 470.931\n",
      "[58]\tvalid_0's tweedie: 470.929\n",
      "[59]\tvalid_0's tweedie: 470.929\n",
      "[60]\tvalid_0's tweedie: 470.928\n",
      "[61]\tvalid_0's tweedie: 470.925\n",
      "[62]\tvalid_0's tweedie: 470.923\n",
      "[63]\tvalid_0's tweedie: 470.922\n",
      "[64]\tvalid_0's tweedie: 470.921\n",
      "[65]\tvalid_0's tweedie: 470.919\n",
      "[66]\tvalid_0's tweedie: 470.917\n",
      "[67]\tvalid_0's tweedie: 470.917\n",
      "[68]\tvalid_0's tweedie: 470.916\n",
      "[69]\tvalid_0's tweedie: 470.914\n",
      "[70]\tvalid_0's tweedie: 470.914\n",
      "[71]\tvalid_0's tweedie: 470.913\n",
      "[72]\tvalid_0's tweedie: 470.912\n",
      "[73]\tvalid_0's tweedie: 470.912\n",
      "[74]\tvalid_0's tweedie: 470.912\n",
      "[75]\tvalid_0's tweedie: 470.908\n",
      "[76]\tvalid_0's tweedie: 470.908\n",
      "[77]\tvalid_0's tweedie: 470.907\n",
      "[78]\tvalid_0's tweedie: 470.9\n",
      "[79]\tvalid_0's tweedie: 470.899\n",
      "[80]\tvalid_0's tweedie: 470.898\n",
      "[81]\tvalid_0's tweedie: 470.899\n",
      "[82]\tvalid_0's tweedie: 470.9\n",
      "[83]\tvalid_0's tweedie: 470.898\n",
      "[84]\tvalid_0's tweedie: 470.897\n",
      "[85]\tvalid_0's tweedie: 470.897\n",
      "[86]\tvalid_0's tweedie: 470.894\n",
      "[87]\tvalid_0's tweedie: 470.893\n",
      "[88]\tvalid_0's tweedie: 470.892\n",
      "[89]\tvalid_0's tweedie: 470.89\n",
      "[90]\tvalid_0's tweedie: 470.89\n",
      "[91]\tvalid_0's tweedie: 470.889\n",
      "[92]\tvalid_0's tweedie: 470.887\n",
      "[93]\tvalid_0's tweedie: 470.886\n",
      "[94]\tvalid_0's tweedie: 470.886\n",
      "[95]\tvalid_0's tweedie: 470.886\n",
      "[96]\tvalid_0's tweedie: 470.886\n",
      "[97]\tvalid_0's tweedie: 470.886\n",
      "[98]\tvalid_0's tweedie: 470.886\n",
      "[99]\tvalid_0's tweedie: 470.887\n",
      "[100]\tvalid_0's tweedie: 470.887\n",
      "[101]\tvalid_0's tweedie: 470.885\n",
      "[102]\tvalid_0's tweedie: 470.884\n",
      "[103]\tvalid_0's tweedie: 470.885\n",
      "[104]\tvalid_0's tweedie: 470.884\n",
      "[105]\tvalid_0's tweedie: 470.881\n",
      "[106]\tvalid_0's tweedie: 470.881\n",
      "[107]\tvalid_0's tweedie: 470.88\n",
      "[108]\tvalid_0's tweedie: 470.88\n",
      "[109]\tvalid_0's tweedie: 470.874\n",
      "[110]\tvalid_0's tweedie: 470.874\n",
      "[111]\tvalid_0's tweedie: 470.875\n",
      "[112]\tvalid_0's tweedie: 470.874\n",
      "[113]\tvalid_0's tweedie: 470.874\n",
      "[114]\tvalid_0's tweedie: 470.875\n",
      "[115]\tvalid_0's tweedie: 470.875\n",
      "[116]\tvalid_0's tweedie: 470.875\n",
      "[117]\tvalid_0's tweedie: 470.875\n",
      "[118]\tvalid_0's tweedie: 470.874\n",
      "[119]\tvalid_0's tweedie: 470.874\n",
      "[120]\tvalid_0's tweedie: 470.872\n",
      "[121]\tvalid_0's tweedie: 470.872\n",
      "[122]\tvalid_0's tweedie: 470.872\n",
      "[123]\tvalid_0's tweedie: 470.872\n",
      "[124]\tvalid_0's tweedie: 470.872\n",
      "[125]\tvalid_0's tweedie: 470.87\n",
      "[126]\tvalid_0's tweedie: 470.869\n",
      "[127]\tvalid_0's tweedie: 470.869\n",
      "[128]\tvalid_0's tweedie: 470.869\n",
      "[129]\tvalid_0's tweedie: 470.868\n",
      "[130]\tvalid_0's tweedie: 470.867\n",
      "[131]\tvalid_0's tweedie: 470.868\n",
      "[132]\tvalid_0's tweedie: 470.865\n",
      "[133]\tvalid_0's tweedie: 470.865\n",
      "[134]\tvalid_0's tweedie: 470.865\n",
      "[135]\tvalid_0's tweedie: 470.864\n",
      "[136]\tvalid_0's tweedie: 470.862\n",
      "[137]\tvalid_0's tweedie: 470.864\n",
      "[138]\tvalid_0's tweedie: 470.865\n",
      "[139]\tvalid_0's tweedie: 470.865\n",
      "[140]\tvalid_0's tweedie: 470.865\n",
      "[141]\tvalid_0's tweedie: 470.865\n",
      "[142]\tvalid_0's tweedie: 470.866\n",
      "[143]\tvalid_0's tweedie: 470.866\n",
      "[144]\tvalid_0's tweedie: 470.866\n",
      "[145]\tvalid_0's tweedie: 470.866\n",
      "[146]\tvalid_0's tweedie: 470.866\n",
      "[147]\tvalid_0's tweedie: 470.867\n",
      "[148]\tvalid_0's tweedie: 470.865\n",
      "[149]\tvalid_0's tweedie: 470.865\n",
      "[150]\tvalid_0's tweedie: 470.863\n",
      "[151]\tvalid_0's tweedie: 470.864\n",
      "[152]\tvalid_0's tweedie: 470.864\n",
      "[153]\tvalid_0's tweedie: 470.864\n",
      "[154]\tvalid_0's tweedie: 470.864\n",
      "[155]\tvalid_0's tweedie: 470.864\n",
      "[156]\tvalid_0's tweedie: 470.864\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's tweedie: 470.862\n",
      "Training model for level 2 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 5574, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345390\n",
      "[1]\tvalid_0's tweedie: 476.363\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.531\n",
      "[3]\tvalid_0's tweedie: 474.813\n",
      "[4]\tvalid_0's tweedie: 474.236\n",
      "[5]\tvalid_0's tweedie: 473.76\n",
      "[6]\tvalid_0's tweedie: 473.332\n",
      "[7]\tvalid_0's tweedie: 472.973\n",
      "[8]\tvalid_0's tweedie: 472.694\n",
      "[9]\tvalid_0's tweedie: 472.444\n",
      "[10]\tvalid_0's tweedie: 472.24\n",
      "[11]\tvalid_0's tweedie: 472.074\n",
      "[12]\tvalid_0's tweedie: 471.928\n",
      "[13]\tvalid_0's tweedie: 471.796\n",
      "[14]\tvalid_0's tweedie: 471.696\n",
      "[15]\tvalid_0's tweedie: 471.608\n",
      "[16]\tvalid_0's tweedie: 471.551\n",
      "[17]\tvalid_0's tweedie: 471.485\n",
      "[18]\tvalid_0's tweedie: 471.416\n",
      "[19]\tvalid_0's tweedie: 471.361\n",
      "[20]\tvalid_0's tweedie: 471.313\n",
      "[21]\tvalid_0's tweedie: 471.275\n",
      "[22]\tvalid_0's tweedie: 471.245\n",
      "[23]\tvalid_0's tweedie: 471.211\n",
      "[24]\tvalid_0's tweedie: 471.186\n",
      "[25]\tvalid_0's tweedie: 471.161\n",
      "[26]\tvalid_0's tweedie: 471.143\n",
      "[27]\tvalid_0's tweedie: 471.125\n",
      "[28]\tvalid_0's tweedie: 471.107\n",
      "[29]\tvalid_0's tweedie: 471.087\n",
      "[30]\tvalid_0's tweedie: 471.077\n",
      "[31]\tvalid_0's tweedie: 471.063\n",
      "[32]\tvalid_0's tweedie: 471.05\n",
      "[33]\tvalid_0's tweedie: 471.04\n",
      "[34]\tvalid_0's tweedie: 471.037\n",
      "[35]\tvalid_0's tweedie: 471.031\n",
      "[36]\tvalid_0's tweedie: 471.021\n",
      "[37]\tvalid_0's tweedie: 471.013\n",
      "[38]\tvalid_0's tweedie: 471.005\n",
      "[39]\tvalid_0's tweedie: 470.994\n",
      "[40]\tvalid_0's tweedie: 470.985\n",
      "[41]\tvalid_0's tweedie: 470.977\n",
      "[42]\tvalid_0's tweedie: 470.964\n",
      "[43]\tvalid_0's tweedie: 470.96\n",
      "[44]\tvalid_0's tweedie: 470.958\n",
      "[45]\tvalid_0's tweedie: 470.957\n",
      "[46]\tvalid_0's tweedie: 470.955\n",
      "[47]\tvalid_0's tweedie: 470.953\n",
      "[48]\tvalid_0's tweedie: 470.948\n",
      "[49]\tvalid_0's tweedie: 470.948\n",
      "[50]\tvalid_0's tweedie: 470.945\n",
      "[51]\tvalid_0's tweedie: 470.942\n",
      "[52]\tvalid_0's tweedie: 470.938\n",
      "[53]\tvalid_0's tweedie: 470.934\n",
      "[54]\tvalid_0's tweedie: 470.93\n",
      "[55]\tvalid_0's tweedie: 470.929\n",
      "[56]\tvalid_0's tweedie: 470.927\n",
      "[57]\tvalid_0's tweedie: 470.926\n",
      "[58]\tvalid_0's tweedie: 470.919\n",
      "[59]\tvalid_0's tweedie: 470.915\n",
      "[60]\tvalid_0's tweedie: 470.912\n",
      "[61]\tvalid_0's tweedie: 470.911\n",
      "[62]\tvalid_0's tweedie: 470.911\n",
      "[63]\tvalid_0's tweedie: 470.912\n",
      "[64]\tvalid_0's tweedie: 470.911\n",
      "[65]\tvalid_0's tweedie: 470.909\n",
      "[66]\tvalid_0's tweedie: 470.908\n",
      "[67]\tvalid_0's tweedie: 470.908\n",
      "[68]\tvalid_0's tweedie: 470.908\n",
      "[69]\tvalid_0's tweedie: 470.91\n",
      "[70]\tvalid_0's tweedie: 470.909\n",
      "[71]\tvalid_0's tweedie: 470.906\n",
      "[72]\tvalid_0's tweedie: 470.904\n",
      "[73]\tvalid_0's tweedie: 470.902\n",
      "[74]\tvalid_0's tweedie: 470.902\n",
      "[75]\tvalid_0's tweedie: 470.904\n",
      "[76]\tvalid_0's tweedie: 470.904\n",
      "[77]\tvalid_0's tweedie: 470.905\n",
      "[78]\tvalid_0's tweedie: 470.904\n",
      "[79]\tvalid_0's tweedie: 470.902\n",
      "[80]\tvalid_0's tweedie: 470.901\n",
      "[81]\tvalid_0's tweedie: 470.9\n",
      "[82]\tvalid_0's tweedie: 470.901\n",
      "[83]\tvalid_0's tweedie: 470.902\n",
      "[84]\tvalid_0's tweedie: 470.901\n",
      "[85]\tvalid_0's tweedie: 470.902\n",
      "[86]\tvalid_0's tweedie: 470.902\n",
      "[87]\tvalid_0's tweedie: 470.902\n",
      "[88]\tvalid_0's tweedie: 470.902\n",
      "[89]\tvalid_0's tweedie: 470.904\n",
      "[90]\tvalid_0's tweedie: 470.906\n",
      "[91]\tvalid_0's tweedie: 470.909\n",
      "[92]\tvalid_0's tweedie: 470.907\n",
      "[93]\tvalid_0's tweedie: 470.906\n",
      "[94]\tvalid_0's tweedie: 470.905\n",
      "[95]\tvalid_0's tweedie: 470.906\n",
      "[96]\tvalid_0's tweedie: 470.905\n",
      "[97]\tvalid_0's tweedie: 470.904\n",
      "[98]\tvalid_0's tweedie: 470.904\n",
      "[99]\tvalid_0's tweedie: 470.904\n",
      "[100]\tvalid_0's tweedie: 470.905\n",
      "[101]\tvalid_0's tweedie: 470.905\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's tweedie: 470.9\n",
      "Training model for level 2 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 5571, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345575\n",
      "[1]\tvalid_0's tweedie: 476.324\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.462\n",
      "[3]\tvalid_0's tweedie: 474.727\n",
      "[4]\tvalid_0's tweedie: 474.138\n",
      "[5]\tvalid_0's tweedie: 473.687\n",
      "[6]\tvalid_0's tweedie: 473.274\n",
      "[7]\tvalid_0's tweedie: 472.926\n",
      "[8]\tvalid_0's tweedie: 472.617\n",
      "[9]\tvalid_0's tweedie: 472.386\n",
      "[10]\tvalid_0's tweedie: 472.196\n",
      "[11]\tvalid_0's tweedie: 472.041\n",
      "[12]\tvalid_0's tweedie: 471.903\n",
      "[13]\tvalid_0's tweedie: 471.788\n",
      "[14]\tvalid_0's tweedie: 471.678\n",
      "[15]\tvalid_0's tweedie: 471.592\n",
      "[16]\tvalid_0's tweedie: 471.529\n",
      "[17]\tvalid_0's tweedie: 471.458\n",
      "[18]\tvalid_0's tweedie: 471.419\n",
      "[19]\tvalid_0's tweedie: 471.367\n",
      "[20]\tvalid_0's tweedie: 471.324\n",
      "[21]\tvalid_0's tweedie: 471.297\n",
      "[22]\tvalid_0's tweedie: 471.27\n",
      "[23]\tvalid_0's tweedie: 471.249\n",
      "[24]\tvalid_0's tweedie: 471.224\n",
      "[25]\tvalid_0's tweedie: 471.212\n",
      "[26]\tvalid_0's tweedie: 471.204\n",
      "[27]\tvalid_0's tweedie: 471.182\n",
      "[28]\tvalid_0's tweedie: 471.16\n",
      "[29]\tvalid_0's tweedie: 471.139\n",
      "[30]\tvalid_0's tweedie: 471.125\n",
      "[31]\tvalid_0's tweedie: 471.109\n",
      "[32]\tvalid_0's tweedie: 471.096\n",
      "[33]\tvalid_0's tweedie: 471.088\n",
      "[34]\tvalid_0's tweedie: 471.079\n",
      "[35]\tvalid_0's tweedie: 471.065\n",
      "[36]\tvalid_0's tweedie: 471.052\n",
      "[37]\tvalid_0's tweedie: 471.045\n",
      "[38]\tvalid_0's tweedie: 471.035\n",
      "[39]\tvalid_0's tweedie: 471.027\n",
      "[40]\tvalid_0's tweedie: 471.019\n",
      "[41]\tvalid_0's tweedie: 471.018\n",
      "[42]\tvalid_0's tweedie: 471.007\n",
      "[43]\tvalid_0's tweedie: 471.002\n",
      "[44]\tvalid_0's tweedie: 471\n",
      "[45]\tvalid_0's tweedie: 470.996\n",
      "[46]\tvalid_0's tweedie: 470.992\n",
      "[47]\tvalid_0's tweedie: 470.995\n",
      "[48]\tvalid_0's tweedie: 470.993\n",
      "[49]\tvalid_0's tweedie: 470.99\n",
      "[50]\tvalid_0's tweedie: 470.987\n",
      "[51]\tvalid_0's tweedie: 470.983\n",
      "[52]\tvalid_0's tweedie: 470.981\n",
      "[53]\tvalid_0's tweedie: 470.979\n",
      "[54]\tvalid_0's tweedie: 470.98\n",
      "[55]\tvalid_0's tweedie: 470.976\n",
      "[56]\tvalid_0's tweedie: 470.979\n",
      "[57]\tvalid_0's tweedie: 470.977\n",
      "[58]\tvalid_0's tweedie: 470.975\n",
      "[59]\tvalid_0's tweedie: 470.971\n",
      "[60]\tvalid_0's tweedie: 470.965\n",
      "[61]\tvalid_0's tweedie: 470.963\n",
      "[62]\tvalid_0's tweedie: 470.961\n",
      "[63]\tvalid_0's tweedie: 470.961\n",
      "[64]\tvalid_0's tweedie: 470.962\n",
      "[65]\tvalid_0's tweedie: 470.96\n",
      "[66]\tvalid_0's tweedie: 470.959\n",
      "[67]\tvalid_0's tweedie: 470.959\n",
      "[68]\tvalid_0's tweedie: 470.956\n",
      "[69]\tvalid_0's tweedie: 470.952\n",
      "[70]\tvalid_0's tweedie: 470.95\n",
      "[71]\tvalid_0's tweedie: 470.947\n",
      "[72]\tvalid_0's tweedie: 470.947\n",
      "[73]\tvalid_0's tweedie: 470.946\n",
      "[74]\tvalid_0's tweedie: 470.946\n",
      "[75]\tvalid_0's tweedie: 470.942\n",
      "[76]\tvalid_0's tweedie: 470.941\n",
      "[77]\tvalid_0's tweedie: 470.945\n",
      "[78]\tvalid_0's tweedie: 470.942\n",
      "[79]\tvalid_0's tweedie: 470.941\n",
      "[80]\tvalid_0's tweedie: 470.941\n",
      "[81]\tvalid_0's tweedie: 470.941\n",
      "[82]\tvalid_0's tweedie: 470.939\n",
      "[83]\tvalid_0's tweedie: 470.94\n",
      "[84]\tvalid_0's tweedie: 470.937\n",
      "[85]\tvalid_0's tweedie: 470.938\n",
      "[86]\tvalid_0's tweedie: 470.938\n",
      "[87]\tvalid_0's tweedie: 470.938\n",
      "[88]\tvalid_0's tweedie: 470.938\n",
      "[89]\tvalid_0's tweedie: 470.938\n",
      "[90]\tvalid_0's tweedie: 470.934\n",
      "[91]\tvalid_0's tweedie: 470.935\n",
      "[92]\tvalid_0's tweedie: 470.935\n",
      "[93]\tvalid_0's tweedie: 470.934\n",
      "[94]\tvalid_0's tweedie: 470.934\n",
      "[95]\tvalid_0's tweedie: 470.934\n",
      "[96]\tvalid_0's tweedie: 470.935\n",
      "[97]\tvalid_0's tweedie: 470.935\n",
      "[98]\tvalid_0's tweedie: 470.935\n",
      "[99]\tvalid_0's tweedie: 470.936\n",
      "[100]\tvalid_0's tweedie: 470.934\n",
      "[101]\tvalid_0's tweedie: 470.933\n",
      "[102]\tvalid_0's tweedie: 470.931\n",
      "[103]\tvalid_0's tweedie: 470.93\n",
      "[104]\tvalid_0's tweedie: 470.931\n",
      "[105]\tvalid_0's tweedie: 470.931\n",
      "[106]\tvalid_0's tweedie: 470.931\n",
      "[107]\tvalid_0's tweedie: 470.931\n",
      "[108]\tvalid_0's tweedie: 470.931\n",
      "[109]\tvalid_0's tweedie: 470.931\n",
      "[110]\tvalid_0's tweedie: 470.931\n",
      "[111]\tvalid_0's tweedie: 470.931\n",
      "[112]\tvalid_0's tweedie: 470.929\n",
      "[113]\tvalid_0's tweedie: 470.926\n",
      "[114]\tvalid_0's tweedie: 470.926\n",
      "[115]\tvalid_0's tweedie: 470.925\n",
      "[116]\tvalid_0's tweedie: 470.925\n",
      "[117]\tvalid_0's tweedie: 470.925\n",
      "[118]\tvalid_0's tweedie: 470.923\n",
      "[119]\tvalid_0's tweedie: 470.923\n",
      "[120]\tvalid_0's tweedie: 470.923\n",
      "[121]\tvalid_0's tweedie: 470.923\n",
      "[122]\tvalid_0's tweedie: 470.923\n",
      "[123]\tvalid_0's tweedie: 470.923\n",
      "[124]\tvalid_0's tweedie: 470.923\n",
      "[125]\tvalid_0's tweedie: 470.923\n",
      "[126]\tvalid_0's tweedie: 470.921\n",
      "[127]\tvalid_0's tweedie: 470.921\n",
      "[128]\tvalid_0's tweedie: 470.921\n",
      "[129]\tvalid_0's tweedie: 470.922\n",
      "[130]\tvalid_0's tweedie: 470.922\n",
      "[131]\tvalid_0's tweedie: 470.923\n",
      "[132]\tvalid_0's tweedie: 470.923\n",
      "[133]\tvalid_0's tweedie: 470.922\n",
      "[134]\tvalid_0's tweedie: 470.921\n",
      "[135]\tvalid_0's tweedie: 470.919\n",
      "[136]\tvalid_0's tweedie: 470.919\n",
      "[137]\tvalid_0's tweedie: 470.917\n",
      "[138]\tvalid_0's tweedie: 470.918\n",
      "[139]\tvalid_0's tweedie: 470.918\n",
      "[140]\tvalid_0's tweedie: 470.917\n",
      "[141]\tvalid_0's tweedie: 470.917\n",
      "[142]\tvalid_0's tweedie: 470.915\n",
      "[143]\tvalid_0's tweedie: 470.917\n",
      "[144]\tvalid_0's tweedie: 470.917\n",
      "[145]\tvalid_0's tweedie: 470.917\n",
      "[146]\tvalid_0's tweedie: 470.917\n",
      "[147]\tvalid_0's tweedie: 470.915\n",
      "[148]\tvalid_0's tweedie: 470.914\n",
      "[149]\tvalid_0's tweedie: 470.914\n",
      "[150]\tvalid_0's tweedie: 470.914\n",
      "[151]\tvalid_0's tweedie: 470.914\n",
      "[152]\tvalid_0's tweedie: 470.914\n",
      "[153]\tvalid_0's tweedie: 470.914\n",
      "[154]\tvalid_0's tweedie: 470.913\n",
      "[155]\tvalid_0's tweedie: 470.912\n",
      "[156]\tvalid_0's tweedie: 470.912\n",
      "[157]\tvalid_0's tweedie: 470.912\n",
      "[158]\tvalid_0's tweedie: 470.912\n",
      "[159]\tvalid_0's tweedie: 470.91\n",
      "[160]\tvalid_0's tweedie: 470.911\n",
      "[161]\tvalid_0's tweedie: 470.91\n",
      "[162]\tvalid_0's tweedie: 470.909\n",
      "[163]\tvalid_0's tweedie: 470.909\n",
      "[164]\tvalid_0's tweedie: 470.909\n",
      "[165]\tvalid_0's tweedie: 470.909\n",
      "[166]\tvalid_0's tweedie: 470.909\n",
      "[167]\tvalid_0's tweedie: 470.909\n",
      "[168]\tvalid_0's tweedie: 470.909\n",
      "[169]\tvalid_0's tweedie: 470.909\n",
      "[170]\tvalid_0's tweedie: 470.907\n",
      "[171]\tvalid_0's tweedie: 470.908\n",
      "[172]\tvalid_0's tweedie: 470.908\n",
      "[173]\tvalid_0's tweedie: 470.908\n",
      "[174]\tvalid_0's tweedie: 470.908\n",
      "[175]\tvalid_0's tweedie: 470.908\n",
      "[176]\tvalid_0's tweedie: 470.908\n",
      "[177]\tvalid_0's tweedie: 470.908\n",
      "[178]\tvalid_0's tweedie: 470.908\n",
      "[179]\tvalid_0's tweedie: 470.908\n",
      "[180]\tvalid_0's tweedie: 470.908\n",
      "[181]\tvalid_0's tweedie: 470.908\n",
      "[182]\tvalid_0's tweedie: 470.909\n",
      "[183]\tvalid_0's tweedie: 470.909\n",
      "[184]\tvalid_0's tweedie: 470.909\n",
      "[185]\tvalid_0's tweedie: 470.909\n",
      "[186]\tvalid_0's tweedie: 470.909\n",
      "[187]\tvalid_0's tweedie: 470.909\n",
      "[188]\tvalid_0's tweedie: 470.909\n",
      "[189]\tvalid_0's tweedie: 470.909\n",
      "[190]\tvalid_0's tweedie: 470.909\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's tweedie: 470.907\n",
      "Training model for level 2 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345644\n",
      "[1]\tvalid_0's tweedie: 476.321\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.45\n",
      "[3]\tvalid_0's tweedie: 474.715\n",
      "[4]\tvalid_0's tweedie: 474.105\n",
      "[5]\tvalid_0's tweedie: 473.648\n",
      "[6]\tvalid_0's tweedie: 473.244\n",
      "[7]\tvalid_0's tweedie: 472.907\n",
      "[8]\tvalid_0's tweedie: 472.625\n",
      "[9]\tvalid_0's tweedie: 472.405\n",
      "[10]\tvalid_0's tweedie: 472.19\n",
      "[11]\tvalid_0's tweedie: 472.037\n",
      "[12]\tvalid_0's tweedie: 471.9\n",
      "[13]\tvalid_0's tweedie: 471.778\n",
      "[14]\tvalid_0's tweedie: 471.661\n",
      "[15]\tvalid_0's tweedie: 471.585\n",
      "[16]\tvalid_0's tweedie: 471.524\n",
      "[17]\tvalid_0's tweedie: 471.451\n",
      "[18]\tvalid_0's tweedie: 471.398\n",
      "[19]\tvalid_0's tweedie: 471.354\n",
      "[20]\tvalid_0's tweedie: 471.311\n",
      "[21]\tvalid_0's tweedie: 471.275\n",
      "[22]\tvalid_0's tweedie: 471.243\n",
      "[23]\tvalid_0's tweedie: 471.219\n",
      "[24]\tvalid_0's tweedie: 471.192\n",
      "[25]\tvalid_0's tweedie: 471.178\n",
      "[26]\tvalid_0's tweedie: 471.156\n",
      "[27]\tvalid_0's tweedie: 471.132\n",
      "[28]\tvalid_0's tweedie: 471.123\n",
      "[29]\tvalid_0's tweedie: 471.107\n",
      "[30]\tvalid_0's tweedie: 471.095\n",
      "[31]\tvalid_0's tweedie: 471.082\n",
      "[32]\tvalid_0's tweedie: 471.075\n",
      "[33]\tvalid_0's tweedie: 471.069\n",
      "[34]\tvalid_0's tweedie: 471.062\n",
      "[35]\tvalid_0's tweedie: 471.058\n",
      "[36]\tvalid_0's tweedie: 471.056\n",
      "[37]\tvalid_0's tweedie: 471.045\n",
      "[38]\tvalid_0's tweedie: 471.041\n",
      "[39]\tvalid_0's tweedie: 471.03\n",
      "[40]\tvalid_0's tweedie: 471.021\n",
      "[41]\tvalid_0's tweedie: 471.015\n",
      "[42]\tvalid_0's tweedie: 471.008\n",
      "[43]\tvalid_0's tweedie: 471.002\n",
      "[44]\tvalid_0's tweedie: 470.998\n",
      "[45]\tvalid_0's tweedie: 470.996\n",
      "[46]\tvalid_0's tweedie: 470.994\n",
      "[47]\tvalid_0's tweedie: 470.99\n",
      "[48]\tvalid_0's tweedie: 470.988\n",
      "[49]\tvalid_0's tweedie: 470.985\n",
      "[50]\tvalid_0's tweedie: 470.984\n",
      "[51]\tvalid_0's tweedie: 470.981\n",
      "[52]\tvalid_0's tweedie: 470.979\n",
      "[53]\tvalid_0's tweedie: 470.976\n",
      "[54]\tvalid_0's tweedie: 470.964\n",
      "[55]\tvalid_0's tweedie: 470.963\n",
      "[56]\tvalid_0's tweedie: 470.959\n",
      "[57]\tvalid_0's tweedie: 470.957\n",
      "[58]\tvalid_0's tweedie: 470.957\n",
      "[59]\tvalid_0's tweedie: 470.957\n",
      "[60]\tvalid_0's tweedie: 470.956\n",
      "[61]\tvalid_0's tweedie: 470.955\n",
      "[62]\tvalid_0's tweedie: 470.954\n",
      "[63]\tvalid_0's tweedie: 470.954\n",
      "[64]\tvalid_0's tweedie: 470.955\n",
      "[65]\tvalid_0's tweedie: 470.955\n",
      "[66]\tvalid_0's tweedie: 470.953\n",
      "[67]\tvalid_0's tweedie: 470.95\n",
      "[68]\tvalid_0's tweedie: 470.95\n",
      "[69]\tvalid_0's tweedie: 470.949\n",
      "[70]\tvalid_0's tweedie: 470.951\n",
      "[71]\tvalid_0's tweedie: 470.952\n",
      "[72]\tvalid_0's tweedie: 470.954\n",
      "[73]\tvalid_0's tweedie: 470.954\n",
      "[74]\tvalid_0's tweedie: 470.952\n",
      "[75]\tvalid_0's tweedie: 470.947\n",
      "[76]\tvalid_0's tweedie: 470.948\n",
      "[77]\tvalid_0's tweedie: 470.947\n",
      "[78]\tvalid_0's tweedie: 470.945\n",
      "[79]\tvalid_0's tweedie: 470.945\n",
      "[80]\tvalid_0's tweedie: 470.943\n",
      "[81]\tvalid_0's tweedie: 470.943\n",
      "[82]\tvalid_0's tweedie: 470.945\n",
      "[83]\tvalid_0's tweedie: 470.944\n",
      "[84]\tvalid_0's tweedie: 470.944\n",
      "[85]\tvalid_0's tweedie: 470.944\n",
      "[86]\tvalid_0's tweedie: 470.94\n",
      "[87]\tvalid_0's tweedie: 470.94\n",
      "[88]\tvalid_0's tweedie: 470.94\n",
      "[89]\tvalid_0's tweedie: 470.94\n",
      "[90]\tvalid_0's tweedie: 470.94\n",
      "[91]\tvalid_0's tweedie: 470.94\n",
      "[92]\tvalid_0's tweedie: 470.94\n",
      "[93]\tvalid_0's tweedie: 470.94\n",
      "[94]\tvalid_0's tweedie: 470.937\n",
      "[95]\tvalid_0's tweedie: 470.936\n",
      "[96]\tvalid_0's tweedie: 470.937\n",
      "[97]\tvalid_0's tweedie: 470.934\n",
      "[98]\tvalid_0's tweedie: 470.934\n",
      "[99]\tvalid_0's tweedie: 470.934\n",
      "[100]\tvalid_0's tweedie: 470.933\n",
      "[101]\tvalid_0's tweedie: 470.93\n",
      "[102]\tvalid_0's tweedie: 470.929\n",
      "[103]\tvalid_0's tweedie: 470.928\n",
      "[104]\tvalid_0's tweedie: 470.927\n",
      "[105]\tvalid_0's tweedie: 470.927\n",
      "[106]\tvalid_0's tweedie: 470.927\n",
      "[107]\tvalid_0's tweedie: 470.924\n",
      "[108]\tvalid_0's tweedie: 470.923\n",
      "[109]\tvalid_0's tweedie: 470.923\n",
      "[110]\tvalid_0's tweedie: 470.922\n",
      "[111]\tvalid_0's tweedie: 470.921\n",
      "[112]\tvalid_0's tweedie: 470.921\n",
      "[113]\tvalid_0's tweedie: 470.919\n",
      "[114]\tvalid_0's tweedie: 470.919\n",
      "[115]\tvalid_0's tweedie: 470.919\n",
      "[116]\tvalid_0's tweedie: 470.919\n",
      "[117]\tvalid_0's tweedie: 470.919\n",
      "[118]\tvalid_0's tweedie: 470.919\n",
      "[119]\tvalid_0's tweedie: 470.919\n",
      "[120]\tvalid_0's tweedie: 470.918\n",
      "[121]\tvalid_0's tweedie: 470.918\n",
      "[122]\tvalid_0's tweedie: 470.918\n",
      "[123]\tvalid_0's tweedie: 470.918\n",
      "[124]\tvalid_0's tweedie: 470.918\n",
      "[125]\tvalid_0's tweedie: 470.917\n",
      "[126]\tvalid_0's tweedie: 470.917\n",
      "[127]\tvalid_0's tweedie: 470.916\n",
      "[128]\tvalid_0's tweedie: 470.917\n",
      "[129]\tvalid_0's tweedie: 470.917\n",
      "[130]\tvalid_0's tweedie: 470.916\n",
      "[131]\tvalid_0's tweedie: 470.916\n",
      "[132]\tvalid_0's tweedie: 470.916\n",
      "[133]\tvalid_0's tweedie: 470.916\n",
      "[134]\tvalid_0's tweedie: 470.915\n",
      "[135]\tvalid_0's tweedie: 470.915\n",
      "[136]\tvalid_0's tweedie: 470.914\n",
      "[137]\tvalid_0's tweedie: 470.913\n",
      "[138]\tvalid_0's tweedie: 470.914\n",
      "[139]\tvalid_0's tweedie: 470.913\n",
      "[140]\tvalid_0's tweedie: 470.913\n",
      "[141]\tvalid_0's tweedie: 470.911\n",
      "[142]\tvalid_0's tweedie: 470.911\n",
      "[143]\tvalid_0's tweedie: 470.909\n",
      "[144]\tvalid_0's tweedie: 470.909\n",
      "[145]\tvalid_0's tweedie: 470.909\n",
      "[146]\tvalid_0's tweedie: 470.909\n",
      "[147]\tvalid_0's tweedie: 470.91\n",
      "[148]\tvalid_0's tweedie: 470.911\n",
      "[149]\tvalid_0's tweedie: 470.911\n",
      "[150]\tvalid_0's tweedie: 470.911\n",
      "[151]\tvalid_0's tweedie: 470.911\n",
      "[152]\tvalid_0's tweedie: 470.913\n",
      "[153]\tvalid_0's tweedie: 470.913\n",
      "[154]\tvalid_0's tweedie: 470.913\n",
      "[155]\tvalid_0's tweedie: 470.913\n",
      "[156]\tvalid_0's tweedie: 470.913\n",
      "[157]\tvalid_0's tweedie: 470.913\n",
      "[158]\tvalid_0's tweedie: 470.913\n",
      "[159]\tvalid_0's tweedie: 470.91\n",
      "[160]\tvalid_0's tweedie: 470.91\n",
      "[161]\tvalid_0's tweedie: 470.91\n",
      "[162]\tvalid_0's tweedie: 470.909\n",
      "[163]\tvalid_0's tweedie: 470.909\n",
      "[164]\tvalid_0's tweedie: 470.909\n",
      "[165]\tvalid_0's tweedie: 470.909\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's tweedie: 470.909\n",
      "Training model for level 2 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 5565, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345733\n",
      "[1]\tvalid_0's tweedie: 476.303\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.442\n",
      "[3]\tvalid_0's tweedie: 474.709\n",
      "[4]\tvalid_0's tweedie: 474.101\n",
      "[5]\tvalid_0's tweedie: 473.598\n",
      "[6]\tvalid_0's tweedie: 473.196\n",
      "[7]\tvalid_0's tweedie: 472.863\n",
      "[8]\tvalid_0's tweedie: 472.576\n",
      "[9]\tvalid_0's tweedie: 472.371\n",
      "[10]\tvalid_0's tweedie: 472.183\n",
      "[11]\tvalid_0's tweedie: 472.029\n",
      "[12]\tvalid_0's tweedie: 471.889\n",
      "[13]\tvalid_0's tweedie: 471.761\n",
      "[14]\tvalid_0's tweedie: 471.663\n",
      "[15]\tvalid_0's tweedie: 471.576\n",
      "[16]\tvalid_0's tweedie: 471.499\n",
      "[17]\tvalid_0's tweedie: 471.446\n",
      "[18]\tvalid_0's tweedie: 471.389\n",
      "[19]\tvalid_0's tweedie: 471.338\n",
      "[20]\tvalid_0's tweedie: 471.297\n",
      "[21]\tvalid_0's tweedie: 471.264\n",
      "[22]\tvalid_0's tweedie: 471.234\n",
      "[23]\tvalid_0's tweedie: 471.202\n",
      "[24]\tvalid_0's tweedie: 471.173\n",
      "[25]\tvalid_0's tweedie: 471.161\n",
      "[26]\tvalid_0's tweedie: 471.137\n",
      "[27]\tvalid_0's tweedie: 471.121\n",
      "[28]\tvalid_0's tweedie: 471.104\n",
      "[29]\tvalid_0's tweedie: 471.086\n",
      "[30]\tvalid_0's tweedie: 471.07\n",
      "[31]\tvalid_0's tweedie: 471.062\n",
      "[32]\tvalid_0's tweedie: 471.047\n",
      "[33]\tvalid_0's tweedie: 471.043\n",
      "[34]\tvalid_0's tweedie: 471.031\n",
      "[35]\tvalid_0's tweedie: 471.025\n",
      "[36]\tvalid_0's tweedie: 471.012\n",
      "[37]\tvalid_0's tweedie: 471.009\n",
      "[38]\tvalid_0's tweedie: 471.001\n",
      "[39]\tvalid_0's tweedie: 470.996\n",
      "[40]\tvalid_0's tweedie: 470.984\n",
      "[41]\tvalid_0's tweedie: 470.978\n",
      "[42]\tvalid_0's tweedie: 470.979\n",
      "[43]\tvalid_0's tweedie: 470.973\n",
      "[44]\tvalid_0's tweedie: 470.972\n",
      "[45]\tvalid_0's tweedie: 470.969\n",
      "[46]\tvalid_0's tweedie: 470.966\n",
      "[47]\tvalid_0's tweedie: 470.963\n",
      "[48]\tvalid_0's tweedie: 470.956\n",
      "[49]\tvalid_0's tweedie: 470.952\n",
      "[50]\tvalid_0's tweedie: 470.952\n",
      "[51]\tvalid_0's tweedie: 470.947\n",
      "[52]\tvalid_0's tweedie: 470.946\n",
      "[53]\tvalid_0's tweedie: 470.941\n",
      "[54]\tvalid_0's tweedie: 470.94\n",
      "[55]\tvalid_0's tweedie: 470.941\n",
      "[56]\tvalid_0's tweedie: 470.939\n",
      "[57]\tvalid_0's tweedie: 470.935\n",
      "[58]\tvalid_0's tweedie: 470.935\n",
      "[59]\tvalid_0's tweedie: 470.934\n",
      "[60]\tvalid_0's tweedie: 470.933\n",
      "[61]\tvalid_0's tweedie: 470.931\n",
      "[62]\tvalid_0's tweedie: 470.93\n",
      "[63]\tvalid_0's tweedie: 470.93\n",
      "[64]\tvalid_0's tweedie: 470.931\n",
      "[65]\tvalid_0's tweedie: 470.931\n",
      "[66]\tvalid_0's tweedie: 470.931\n",
      "[67]\tvalid_0's tweedie: 470.931\n",
      "[68]\tvalid_0's tweedie: 470.929\n",
      "[69]\tvalid_0's tweedie: 470.926\n",
      "[70]\tvalid_0's tweedie: 470.926\n",
      "[71]\tvalid_0's tweedie: 470.926\n",
      "[72]\tvalid_0's tweedie: 470.925\n",
      "[73]\tvalid_0's tweedie: 470.924\n",
      "[74]\tvalid_0's tweedie: 470.923\n",
      "[75]\tvalid_0's tweedie: 470.92\n",
      "[76]\tvalid_0's tweedie: 470.92\n",
      "[77]\tvalid_0's tweedie: 470.918\n",
      "[78]\tvalid_0's tweedie: 470.917\n",
      "[79]\tvalid_0's tweedie: 470.919\n",
      "[80]\tvalid_0's tweedie: 470.915\n",
      "[81]\tvalid_0's tweedie: 470.915\n",
      "[82]\tvalid_0's tweedie: 470.916\n",
      "[83]\tvalid_0's tweedie: 470.915\n",
      "[84]\tvalid_0's tweedie: 470.914\n",
      "[85]\tvalid_0's tweedie: 470.911\n",
      "[86]\tvalid_0's tweedie: 470.909\n",
      "[87]\tvalid_0's tweedie: 470.909\n",
      "[88]\tvalid_0's tweedie: 470.909\n",
      "[89]\tvalid_0's tweedie: 470.906\n",
      "[90]\tvalid_0's tweedie: 470.905\n",
      "[91]\tvalid_0's tweedie: 470.905\n",
      "[92]\tvalid_0's tweedie: 470.904\n",
      "[93]\tvalid_0's tweedie: 470.904\n",
      "[94]\tvalid_0's tweedie: 470.904\n",
      "[95]\tvalid_0's tweedie: 470.904\n",
      "[96]\tvalid_0's tweedie: 470.904\n",
      "[97]\tvalid_0's tweedie: 470.901\n",
      "[98]\tvalid_0's tweedie: 470.901\n",
      "[99]\tvalid_0's tweedie: 470.902\n",
      "[100]\tvalid_0's tweedie: 470.902\n",
      "[101]\tvalid_0's tweedie: 470.902\n",
      "[102]\tvalid_0's tweedie: 470.904\n",
      "[103]\tvalid_0's tweedie: 470.902\n",
      "[104]\tvalid_0's tweedie: 470.9\n",
      "[105]\tvalid_0's tweedie: 470.899\n",
      "[106]\tvalid_0's tweedie: 470.899\n",
      "[107]\tvalid_0's tweedie: 470.899\n",
      "[108]\tvalid_0's tweedie: 470.899\n",
      "[109]\tvalid_0's tweedie: 470.899\n",
      "[110]\tvalid_0's tweedie: 470.899\n",
      "[111]\tvalid_0's tweedie: 470.898\n",
      "[112]\tvalid_0's tweedie: 470.898\n",
      "[113]\tvalid_0's tweedie: 470.898\n",
      "[114]\tvalid_0's tweedie: 470.897\n",
      "[115]\tvalid_0's tweedie: 470.897\n",
      "[116]\tvalid_0's tweedie: 470.895\n",
      "[117]\tvalid_0's tweedie: 470.894\n",
      "[118]\tvalid_0's tweedie: 470.894\n",
      "[119]\tvalid_0's tweedie: 470.894\n",
      "[120]\tvalid_0's tweedie: 470.895\n",
      "[121]\tvalid_0's tweedie: 470.894\n",
      "[122]\tvalid_0's tweedie: 470.894\n",
      "[123]\tvalid_0's tweedie: 470.895\n",
      "[124]\tvalid_0's tweedie: 470.894\n",
      "[125]\tvalid_0's tweedie: 470.894\n",
      "[126]\tvalid_0's tweedie: 470.894\n",
      "[127]\tvalid_0's tweedie: 470.891\n",
      "[128]\tvalid_0's tweedie: 470.891\n",
      "[129]\tvalid_0's tweedie: 470.89\n",
      "[130]\tvalid_0's tweedie: 470.888\n",
      "[131]\tvalid_0's tweedie: 470.888\n",
      "[132]\tvalid_0's tweedie: 470.888\n",
      "[133]\tvalid_0's tweedie: 470.888\n",
      "[134]\tvalid_0's tweedie: 470.888\n",
      "[135]\tvalid_0's tweedie: 470.888\n",
      "[136]\tvalid_0's tweedie: 470.888\n",
      "[137]\tvalid_0's tweedie: 470.888\n",
      "[138]\tvalid_0's tweedie: 470.889\n",
      "[139]\tvalid_0's tweedie: 470.89\n",
      "[140]\tvalid_0's tweedie: 470.889\n",
      "[141]\tvalid_0's tweedie: 470.889\n",
      "[142]\tvalid_0's tweedie: 470.889\n",
      "[143]\tvalid_0's tweedie: 470.889\n",
      "[144]\tvalid_0's tweedie: 470.889\n",
      "[145]\tvalid_0's tweedie: 470.887\n",
      "[146]\tvalid_0's tweedie: 470.887\n",
      "[147]\tvalid_0's tweedie: 470.887\n",
      "[148]\tvalid_0's tweedie: 470.886\n",
      "[149]\tvalid_0's tweedie: 470.886\n",
      "[150]\tvalid_0's tweedie: 470.886\n",
      "[151]\tvalid_0's tweedie: 470.886\n",
      "[152]\tvalid_0's tweedie: 470.886\n",
      "[153]\tvalid_0's tweedie: 470.886\n",
      "[154]\tvalid_0's tweedie: 470.885\n",
      "[155]\tvalid_0's tweedie: 470.884\n",
      "[156]\tvalid_0's tweedie: 470.883\n",
      "[157]\tvalid_0's tweedie: 470.883\n",
      "[158]\tvalid_0's tweedie: 470.883\n",
      "[159]\tvalid_0's tweedie: 470.882\n",
      "[160]\tvalid_0's tweedie: 470.882\n",
      "[161]\tvalid_0's tweedie: 470.883\n",
      "[162]\tvalid_0's tweedie: 470.886\n",
      "[163]\tvalid_0's tweedie: 470.886\n",
      "[164]\tvalid_0's tweedie: 470.887\n",
      "[165]\tvalid_0's tweedie: 470.887\n",
      "[166]\tvalid_0's tweedie: 470.887\n",
      "[167]\tvalid_0's tweedie: 470.889\n",
      "[168]\tvalid_0's tweedie: 470.889\n",
      "[169]\tvalid_0's tweedie: 470.888\n",
      "[170]\tvalid_0's tweedie: 470.888\n",
      "[171]\tvalid_0's tweedie: 470.888\n",
      "[172]\tvalid_0's tweedie: 470.888\n",
      "[173]\tvalid_0's tweedie: 470.886\n",
      "[174]\tvalid_0's tweedie: 470.886\n",
      "[175]\tvalid_0's tweedie: 470.886\n",
      "[176]\tvalid_0's tweedie: 470.886\n",
      "[177]\tvalid_0's tweedie: 470.886\n",
      "[178]\tvalid_0's tweedie: 470.886\n",
      "[179]\tvalid_0's tweedie: 470.886\n",
      "[180]\tvalid_0's tweedie: 470.883\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's tweedie: 470.882\n",
      "Training model for level 2 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 5562, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345939\n",
      "[1]\tvalid_0's tweedie: 476.286\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.419\n",
      "[3]\tvalid_0's tweedie: 474.7\n",
      "[4]\tvalid_0's tweedie: 474.118\n",
      "[5]\tvalid_0's tweedie: 473.622\n",
      "[6]\tvalid_0's tweedie: 473.215\n",
      "[7]\tvalid_0's tweedie: 472.869\n",
      "[8]\tvalid_0's tweedie: 472.615\n",
      "[9]\tvalid_0's tweedie: 472.404\n",
      "[10]\tvalid_0's tweedie: 472.205\n",
      "[11]\tvalid_0's tweedie: 472.029\n",
      "[12]\tvalid_0's tweedie: 471.89\n",
      "[13]\tvalid_0's tweedie: 471.773\n",
      "[14]\tvalid_0's tweedie: 471.676\n",
      "[15]\tvalid_0's tweedie: 471.593\n",
      "[16]\tvalid_0's tweedie: 471.521\n",
      "[17]\tvalid_0's tweedie: 471.455\n",
      "[18]\tvalid_0's tweedie: 471.398\n",
      "[19]\tvalid_0's tweedie: 471.358\n",
      "[20]\tvalid_0's tweedie: 471.316\n",
      "[21]\tvalid_0's tweedie: 471.282\n",
      "[22]\tvalid_0's tweedie: 471.251\n",
      "[23]\tvalid_0's tweedie: 471.232\n",
      "[24]\tvalid_0's tweedie: 471.21\n",
      "[25]\tvalid_0's tweedie: 471.185\n",
      "[26]\tvalid_0's tweedie: 471.171\n",
      "[27]\tvalid_0's tweedie: 471.161\n",
      "[28]\tvalid_0's tweedie: 471.143\n",
      "[29]\tvalid_0's tweedie: 471.129\n",
      "[30]\tvalid_0's tweedie: 471.113\n",
      "[31]\tvalid_0's tweedie: 471.106\n",
      "[32]\tvalid_0's tweedie: 471.093\n",
      "[33]\tvalid_0's tweedie: 471.084\n",
      "[34]\tvalid_0's tweedie: 471.074\n",
      "[35]\tvalid_0's tweedie: 471.068\n",
      "[36]\tvalid_0's tweedie: 471.06\n",
      "[37]\tvalid_0's tweedie: 471.062\n",
      "[38]\tvalid_0's tweedie: 471.05\n",
      "[39]\tvalid_0's tweedie: 471.048\n",
      "[40]\tvalid_0's tweedie: 471.042\n",
      "[41]\tvalid_0's tweedie: 471.04\n",
      "[42]\tvalid_0's tweedie: 471.035\n",
      "[43]\tvalid_0's tweedie: 471.031\n",
      "[44]\tvalid_0's tweedie: 471.029\n",
      "[45]\tvalid_0's tweedie: 471.026\n",
      "[46]\tvalid_0's tweedie: 471.024\n",
      "[47]\tvalid_0's tweedie: 471.022\n",
      "[48]\tvalid_0's tweedie: 471.021\n",
      "[49]\tvalid_0's tweedie: 471.02\n",
      "[50]\tvalid_0's tweedie: 471.018\n",
      "[51]\tvalid_0's tweedie: 471.017\n",
      "[52]\tvalid_0's tweedie: 471.01\n",
      "[53]\tvalid_0's tweedie: 471.007\n",
      "[54]\tvalid_0's tweedie: 471.004\n",
      "[55]\tvalid_0's tweedie: 471.003\n",
      "[56]\tvalid_0's tweedie: 471.002\n",
      "[57]\tvalid_0's tweedie: 471.002\n",
      "[58]\tvalid_0's tweedie: 471.002\n",
      "[59]\tvalid_0's tweedie: 471\n",
      "[60]\tvalid_0's tweedie: 470.999\n",
      "[61]\tvalid_0's tweedie: 470.992\n",
      "[62]\tvalid_0's tweedie: 470.99\n",
      "[63]\tvalid_0's tweedie: 470.991\n",
      "[64]\tvalid_0's tweedie: 470.99\n",
      "[65]\tvalid_0's tweedie: 470.989\n",
      "[66]\tvalid_0's tweedie: 470.989\n",
      "[67]\tvalid_0's tweedie: 470.989\n",
      "[68]\tvalid_0's tweedie: 470.988\n",
      "[69]\tvalid_0's tweedie: 470.992\n",
      "[70]\tvalid_0's tweedie: 470.992\n",
      "[71]\tvalid_0's tweedie: 470.991\n",
      "[72]\tvalid_0's tweedie: 470.989\n",
      "[73]\tvalid_0's tweedie: 470.989\n",
      "[74]\tvalid_0's tweedie: 470.988\n",
      "[75]\tvalid_0's tweedie: 470.985\n",
      "[76]\tvalid_0's tweedie: 470.985\n",
      "[77]\tvalid_0's tweedie: 470.985\n",
      "[78]\tvalid_0's tweedie: 470.985\n",
      "[79]\tvalid_0's tweedie: 470.98\n",
      "[80]\tvalid_0's tweedie: 470.979\n",
      "[81]\tvalid_0's tweedie: 470.978\n",
      "[82]\tvalid_0's tweedie: 470.974\n",
      "[83]\tvalid_0's tweedie: 470.975\n",
      "[84]\tvalid_0's tweedie: 470.969\n",
      "[85]\tvalid_0's tweedie: 470.968\n",
      "[86]\tvalid_0's tweedie: 470.966\n",
      "[87]\tvalid_0's tweedie: 470.966\n",
      "[88]\tvalid_0's tweedie: 470.963\n",
      "[89]\tvalid_0's tweedie: 470.963\n",
      "[90]\tvalid_0's tweedie: 470.962\n",
      "[91]\tvalid_0's tweedie: 470.962\n",
      "[92]\tvalid_0's tweedie: 470.96\n",
      "[93]\tvalid_0's tweedie: 470.961\n",
      "[94]\tvalid_0's tweedie: 470.96\n",
      "[95]\tvalid_0's tweedie: 470.955\n",
      "[96]\tvalid_0's tweedie: 470.955\n",
      "[97]\tvalid_0's tweedie: 470.955\n",
      "[98]\tvalid_0's tweedie: 470.955\n",
      "[99]\tvalid_0's tweedie: 470.956\n",
      "[100]\tvalid_0's tweedie: 470.956\n",
      "[101]\tvalid_0's tweedie: 470.956\n",
      "[102]\tvalid_0's tweedie: 470.954\n",
      "[103]\tvalid_0's tweedie: 470.953\n",
      "[104]\tvalid_0's tweedie: 470.954\n",
      "[105]\tvalid_0's tweedie: 470.954\n",
      "[106]\tvalid_0's tweedie: 470.954\n",
      "[107]\tvalid_0's tweedie: 470.953\n",
      "[108]\tvalid_0's tweedie: 470.953\n",
      "[109]\tvalid_0's tweedie: 470.952\n",
      "[110]\tvalid_0's tweedie: 470.952\n",
      "[111]\tvalid_0's tweedie: 470.951\n",
      "[112]\tvalid_0's tweedie: 470.951\n",
      "[113]\tvalid_0's tweedie: 470.951\n",
      "[114]\tvalid_0's tweedie: 470.949\n",
      "[115]\tvalid_0's tweedie: 470.945\n",
      "[116]\tvalid_0's tweedie: 470.945\n",
      "[117]\tvalid_0's tweedie: 470.945\n",
      "[118]\tvalid_0's tweedie: 470.944\n",
      "[119]\tvalid_0's tweedie: 470.944\n",
      "[120]\tvalid_0's tweedie: 470.944\n",
      "[121]\tvalid_0's tweedie: 470.944\n",
      "[122]\tvalid_0's tweedie: 470.943\n",
      "[123]\tvalid_0's tweedie: 470.944\n",
      "[124]\tvalid_0's tweedie: 470.944\n",
      "[125]\tvalid_0's tweedie: 470.943\n",
      "[126]\tvalid_0's tweedie: 470.943\n",
      "[127]\tvalid_0's tweedie: 470.941\n",
      "[128]\tvalid_0's tweedie: 470.941\n",
      "[129]\tvalid_0's tweedie: 470.941\n",
      "[130]\tvalid_0's tweedie: 470.937\n",
      "[131]\tvalid_0's tweedie: 470.937\n",
      "[132]\tvalid_0's tweedie: 470.937\n",
      "[133]\tvalid_0's tweedie: 470.936\n",
      "[134]\tvalid_0's tweedie: 470.936\n",
      "[135]\tvalid_0's tweedie: 470.936\n",
      "[136]\tvalid_0's tweedie: 470.935\n",
      "[137]\tvalid_0's tweedie: 470.934\n",
      "[138]\tvalid_0's tweedie: 470.936\n",
      "[139]\tvalid_0's tweedie: 470.936\n",
      "[140]\tvalid_0's tweedie: 470.937\n",
      "[141]\tvalid_0's tweedie: 470.937\n",
      "[142]\tvalid_0's tweedie: 470.936\n",
      "[143]\tvalid_0's tweedie: 470.938\n",
      "[144]\tvalid_0's tweedie: 470.937\n",
      "[145]\tvalid_0's tweedie: 470.935\n",
      "[146]\tvalid_0's tweedie: 470.935\n",
      "[147]\tvalid_0's tweedie: 470.933\n",
      "[148]\tvalid_0's tweedie: 470.933\n",
      "[149]\tvalid_0's tweedie: 470.932\n",
      "[150]\tvalid_0's tweedie: 470.932\n",
      "[151]\tvalid_0's tweedie: 470.932\n",
      "[152]\tvalid_0's tweedie: 470.931\n",
      "[153]\tvalid_0's tweedie: 470.931\n",
      "[154]\tvalid_0's tweedie: 470.932\n",
      "[155]\tvalid_0's tweedie: 470.931\n",
      "[156]\tvalid_0's tweedie: 470.93\n",
      "[157]\tvalid_0's tweedie: 470.93\n",
      "[158]\tvalid_0's tweedie: 470.93\n",
      "[159]\tvalid_0's tweedie: 470.931\n",
      "[160]\tvalid_0's tweedie: 470.93\n",
      "[161]\tvalid_0's tweedie: 470.931\n",
      "[162]\tvalid_0's tweedie: 470.932\n",
      "[163]\tvalid_0's tweedie: 470.932\n",
      "[164]\tvalid_0's tweedie: 470.932\n",
      "[165]\tvalid_0's tweedie: 470.932\n",
      "[166]\tvalid_0's tweedie: 470.931\n",
      "[167]\tvalid_0's tweedie: 470.931\n",
      "[168]\tvalid_0's tweedie: 470.931\n",
      "[169]\tvalid_0's tweedie: 470.93\n",
      "[170]\tvalid_0's tweedie: 470.931\n",
      "[171]\tvalid_0's tweedie: 470.931\n",
      "[172]\tvalid_0's tweedie: 470.929\n",
      "[173]\tvalid_0's tweedie: 470.928\n",
      "[174]\tvalid_0's tweedie: 470.928\n",
      "[175]\tvalid_0's tweedie: 470.929\n",
      "[176]\tvalid_0's tweedie: 470.929\n",
      "[177]\tvalid_0's tweedie: 470.929\n",
      "[178]\tvalid_0's tweedie: 470.928\n",
      "[179]\tvalid_0's tweedie: 470.926\n",
      "[180]\tvalid_0's tweedie: 470.925\n",
      "[181]\tvalid_0's tweedie: 470.925\n",
      "[182]\tvalid_0's tweedie: 470.925\n",
      "[183]\tvalid_0's tweedie: 470.924\n",
      "[184]\tvalid_0's tweedie: 470.923\n",
      "[185]\tvalid_0's tweedie: 470.923\n",
      "[186]\tvalid_0's tweedie: 470.923\n",
      "[187]\tvalid_0's tweedie: 470.922\n",
      "[188]\tvalid_0's tweedie: 470.922\n",
      "[189]\tvalid_0's tweedie: 470.923\n",
      "[190]\tvalid_0's tweedie: 470.922\n",
      "[191]\tvalid_0's tweedie: 470.922\n",
      "[192]\tvalid_0's tweedie: 470.923\n",
      "[193]\tvalid_0's tweedie: 470.924\n",
      "[194]\tvalid_0's tweedie: 470.922\n",
      "[195]\tvalid_0's tweedie: 470.922\n",
      "[196]\tvalid_0's tweedie: 470.922\n",
      "[197]\tvalid_0's tweedie: 470.922\n",
      "[198]\tvalid_0's tweedie: 470.922\n",
      "[199]\tvalid_0's tweedie: 470.921\n",
      "[200]\tvalid_0's tweedie: 470.921\n",
      "[201]\tvalid_0's tweedie: 470.92\n",
      "[202]\tvalid_0's tweedie: 470.92\n",
      "[203]\tvalid_0's tweedie: 470.919\n",
      "[204]\tvalid_0's tweedie: 470.918\n",
      "[205]\tvalid_0's tweedie: 470.917\n",
      "[206]\tvalid_0's tweedie: 470.916\n",
      "[207]\tvalid_0's tweedie: 470.915\n",
      "[208]\tvalid_0's tweedie: 470.915\n",
      "[209]\tvalid_0's tweedie: 470.915\n",
      "[210]\tvalid_0's tweedie: 470.915\n",
      "[211]\tvalid_0's tweedie: 470.915\n",
      "[212]\tvalid_0's tweedie: 470.915\n",
      "[213]\tvalid_0's tweedie: 470.915\n",
      "[214]\tvalid_0's tweedie: 470.916\n",
      "[215]\tvalid_0's tweedie: 470.916\n",
      "[216]\tvalid_0's tweedie: 470.916\n",
      "[217]\tvalid_0's tweedie: 470.916\n",
      "[218]\tvalid_0's tweedie: 470.916\n",
      "[219]\tvalid_0's tweedie: 470.915\n",
      "[220]\tvalid_0's tweedie: 470.915\n",
      "[221]\tvalid_0's tweedie: 470.917\n",
      "[222]\tvalid_0's tweedie: 470.917\n",
      "[223]\tvalid_0's tweedie: 470.917\n",
      "[224]\tvalid_0's tweedie: 470.917\n",
      "[225]\tvalid_0's tweedie: 470.917\n",
      "[226]\tvalid_0's tweedie: 470.917\n",
      "[227]\tvalid_0's tweedie: 470.917\n",
      "[228]\tvalid_0's tweedie: 470.916\n",
      "[229]\tvalid_0's tweedie: 470.916\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's tweedie: 470.915\n",
      "Training model for level 2 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 5559, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346119\n",
      "[1]\tvalid_0's tweedie: 476.276\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.409\n",
      "[3]\tvalid_0's tweedie: 474.709\n",
      "[4]\tvalid_0's tweedie: 474.103\n",
      "[5]\tvalid_0's tweedie: 473.608\n",
      "[6]\tvalid_0's tweedie: 473.213\n",
      "[7]\tvalid_0's tweedie: 472.877\n",
      "[8]\tvalid_0's tweedie: 472.623\n",
      "[9]\tvalid_0's tweedie: 472.39\n",
      "[10]\tvalid_0's tweedie: 472.215\n",
      "[11]\tvalid_0's tweedie: 472.03\n",
      "[12]\tvalid_0's tweedie: 471.884\n",
      "[13]\tvalid_0's tweedie: 471.764\n",
      "[14]\tvalid_0's tweedie: 471.658\n",
      "[15]\tvalid_0's tweedie: 471.562\n",
      "[16]\tvalid_0's tweedie: 471.495\n",
      "[17]\tvalid_0's tweedie: 471.436\n",
      "[18]\tvalid_0's tweedie: 471.378\n",
      "[19]\tvalid_0's tweedie: 471.331\n",
      "[20]\tvalid_0's tweedie: 471.286\n",
      "[21]\tvalid_0's tweedie: 471.258\n",
      "[22]\tvalid_0's tweedie: 471.236\n",
      "[23]\tvalid_0's tweedie: 471.206\n",
      "[24]\tvalid_0's tweedie: 471.181\n",
      "[25]\tvalid_0's tweedie: 471.156\n",
      "[26]\tvalid_0's tweedie: 471.132\n",
      "[27]\tvalid_0's tweedie: 471.113\n",
      "[28]\tvalid_0's tweedie: 471.1\n",
      "[29]\tvalid_0's tweedie: 471.086\n",
      "[30]\tvalid_0's tweedie: 471.078\n",
      "[31]\tvalid_0's tweedie: 471.068\n",
      "[32]\tvalid_0's tweedie: 471.061\n",
      "[33]\tvalid_0's tweedie: 471.041\n",
      "[34]\tvalid_0's tweedie: 471.027\n",
      "[35]\tvalid_0's tweedie: 471.011\n",
      "[36]\tvalid_0's tweedie: 471.001\n",
      "[37]\tvalid_0's tweedie: 470.994\n",
      "[38]\tvalid_0's tweedie: 470.987\n",
      "[39]\tvalid_0's tweedie: 470.981\n",
      "[40]\tvalid_0's tweedie: 470.976\n",
      "[41]\tvalid_0's tweedie: 470.971\n",
      "[42]\tvalid_0's tweedie: 470.966\n",
      "[43]\tvalid_0's tweedie: 470.963\n",
      "[44]\tvalid_0's tweedie: 470.962\n",
      "[45]\tvalid_0's tweedie: 470.96\n",
      "[46]\tvalid_0's tweedie: 470.957\n",
      "[47]\tvalid_0's tweedie: 470.955\n",
      "[48]\tvalid_0's tweedie: 470.954\n",
      "[49]\tvalid_0's tweedie: 470.953\n",
      "[50]\tvalid_0's tweedie: 470.949\n",
      "[51]\tvalid_0's tweedie: 470.948\n",
      "[52]\tvalid_0's tweedie: 470.946\n",
      "[53]\tvalid_0's tweedie: 470.944\n",
      "[54]\tvalid_0's tweedie: 470.942\n",
      "[55]\tvalid_0's tweedie: 470.941\n",
      "[56]\tvalid_0's tweedie: 470.943\n",
      "[57]\tvalid_0's tweedie: 470.941\n",
      "[58]\tvalid_0's tweedie: 470.94\n",
      "[59]\tvalid_0's tweedie: 470.94\n",
      "[60]\tvalid_0's tweedie: 470.937\n",
      "[61]\tvalid_0's tweedie: 470.933\n",
      "[62]\tvalid_0's tweedie: 470.93\n",
      "[63]\tvalid_0's tweedie: 470.929\n",
      "[64]\tvalid_0's tweedie: 470.929\n",
      "[65]\tvalid_0's tweedie: 470.928\n",
      "[66]\tvalid_0's tweedie: 470.928\n",
      "[67]\tvalid_0's tweedie: 470.927\n",
      "[68]\tvalid_0's tweedie: 470.927\n",
      "[69]\tvalid_0's tweedie: 470.927\n",
      "[70]\tvalid_0's tweedie: 470.923\n",
      "[71]\tvalid_0's tweedie: 470.922\n",
      "[72]\tvalid_0's tweedie: 470.924\n",
      "[73]\tvalid_0's tweedie: 470.924\n",
      "[74]\tvalid_0's tweedie: 470.924\n",
      "[75]\tvalid_0's tweedie: 470.921\n",
      "[76]\tvalid_0's tweedie: 470.918\n",
      "[77]\tvalid_0's tweedie: 470.917\n",
      "[78]\tvalid_0's tweedie: 470.918\n",
      "[79]\tvalid_0's tweedie: 470.915\n",
      "[80]\tvalid_0's tweedie: 470.915\n",
      "[81]\tvalid_0's tweedie: 470.914\n",
      "[82]\tvalid_0's tweedie: 470.913\n",
      "[83]\tvalid_0's tweedie: 470.909\n",
      "[84]\tvalid_0's tweedie: 470.909\n",
      "[85]\tvalid_0's tweedie: 470.909\n",
      "[86]\tvalid_0's tweedie: 470.909\n",
      "[87]\tvalid_0's tweedie: 470.907\n",
      "[88]\tvalid_0's tweedie: 470.905\n",
      "[89]\tvalid_0's tweedie: 470.906\n",
      "[90]\tvalid_0's tweedie: 470.905\n",
      "[91]\tvalid_0's tweedie: 470.904\n",
      "[92]\tvalid_0's tweedie: 470.901\n",
      "[93]\tvalid_0's tweedie: 470.902\n",
      "[94]\tvalid_0's tweedie: 470.901\n",
      "[95]\tvalid_0's tweedie: 470.901\n",
      "[96]\tvalid_0's tweedie: 470.899\n",
      "[97]\tvalid_0's tweedie: 470.899\n",
      "[98]\tvalid_0's tweedie: 470.899\n",
      "[99]\tvalid_0's tweedie: 470.9\n",
      "[100]\tvalid_0's tweedie: 470.9\n",
      "[101]\tvalid_0's tweedie: 470.899\n",
      "[102]\tvalid_0's tweedie: 470.899\n",
      "[103]\tvalid_0's tweedie: 470.897\n",
      "[104]\tvalid_0's tweedie: 470.898\n",
      "[105]\tvalid_0's tweedie: 470.898\n",
      "[106]\tvalid_0's tweedie: 470.896\n",
      "[107]\tvalid_0's tweedie: 470.894\n",
      "[108]\tvalid_0's tweedie: 470.895\n",
      "[109]\tvalid_0's tweedie: 470.894\n",
      "[110]\tvalid_0's tweedie: 470.891\n",
      "[111]\tvalid_0's tweedie: 470.891\n",
      "[112]\tvalid_0's tweedie: 470.889\n",
      "[113]\tvalid_0's tweedie: 470.889\n",
      "[114]\tvalid_0's tweedie: 470.889\n",
      "[115]\tvalid_0's tweedie: 470.889\n",
      "[116]\tvalid_0's tweedie: 470.889\n",
      "[117]\tvalid_0's tweedie: 470.886\n",
      "[118]\tvalid_0's tweedie: 470.886\n",
      "[119]\tvalid_0's tweedie: 470.886\n",
      "[120]\tvalid_0's tweedie: 470.884\n",
      "[121]\tvalid_0's tweedie: 470.885\n",
      "[122]\tvalid_0's tweedie: 470.883\n",
      "[123]\tvalid_0's tweedie: 470.882\n",
      "[124]\tvalid_0's tweedie: 470.882\n",
      "[125]\tvalid_0's tweedie: 470.883\n",
      "[126]\tvalid_0's tweedie: 470.883\n",
      "[127]\tvalid_0's tweedie: 470.883\n",
      "[128]\tvalid_0's tweedie: 470.883\n",
      "[129]\tvalid_0's tweedie: 470.883\n",
      "[130]\tvalid_0's tweedie: 470.883\n",
      "[131]\tvalid_0's tweedie: 470.882\n",
      "[132]\tvalid_0's tweedie: 470.882\n",
      "[133]\tvalid_0's tweedie: 470.882\n",
      "[134]\tvalid_0's tweedie: 470.881\n",
      "[135]\tvalid_0's tweedie: 470.88\n",
      "[136]\tvalid_0's tweedie: 470.879\n",
      "[137]\tvalid_0's tweedie: 470.879\n",
      "[138]\tvalid_0's tweedie: 470.879\n",
      "[139]\tvalid_0's tweedie: 470.879\n",
      "[140]\tvalid_0's tweedie: 470.879\n",
      "[141]\tvalid_0's tweedie: 470.879\n",
      "[142]\tvalid_0's tweedie: 470.879\n",
      "[143]\tvalid_0's tweedie: 470.879\n",
      "[144]\tvalid_0's tweedie: 470.879\n",
      "[145]\tvalid_0's tweedie: 470.878\n",
      "[146]\tvalid_0's tweedie: 470.878\n",
      "[147]\tvalid_0's tweedie: 470.878\n",
      "[148]\tvalid_0's tweedie: 470.878\n",
      "[149]\tvalid_0's tweedie: 470.877\n",
      "[150]\tvalid_0's tweedie: 470.877\n",
      "[151]\tvalid_0's tweedie: 470.877\n",
      "[152]\tvalid_0's tweedie: 470.877\n",
      "[153]\tvalid_0's tweedie: 470.877\n",
      "[154]\tvalid_0's tweedie: 470.877\n",
      "[155]\tvalid_0's tweedie: 470.877\n",
      "[156]\tvalid_0's tweedie: 470.879\n",
      "[157]\tvalid_0's tweedie: 470.878\n",
      "[158]\tvalid_0's tweedie: 470.878\n",
      "[159]\tvalid_0's tweedie: 470.878\n",
      "[160]\tvalid_0's tweedie: 470.879\n",
      "[161]\tvalid_0's tweedie: 470.879\n",
      "[162]\tvalid_0's tweedie: 470.879\n",
      "[163]\tvalid_0's tweedie: 470.879\n",
      "[164]\tvalid_0's tweedie: 470.879\n",
      "[165]\tvalid_0's tweedie: 470.878\n",
      "[166]\tvalid_0's tweedie: 470.878\n",
      "[167]\tvalid_0's tweedie: 470.878\n",
      "[168]\tvalid_0's tweedie: 470.878\n",
      "[169]\tvalid_0's tweedie: 470.878\n",
      "[170]\tvalid_0's tweedie: 470.877\n",
      "[171]\tvalid_0's tweedie: 470.877\n",
      "[172]\tvalid_0's tweedie: 470.877\n",
      "[173]\tvalid_0's tweedie: 470.877\n",
      "[174]\tvalid_0's tweedie: 470.878\n",
      "[175]\tvalid_0's tweedie: 470.878\n",
      "[176]\tvalid_0's tweedie: 470.878\n",
      "[177]\tvalid_0's tweedie: 470.878\n",
      "[178]\tvalid_0's tweedie: 470.877\n",
      "[179]\tvalid_0's tweedie: 470.877\n",
      "[180]\tvalid_0's tweedie: 470.877\n",
      "[181]\tvalid_0's tweedie: 470.877\n",
      "[182]\tvalid_0's tweedie: 470.876\n",
      "[183]\tvalid_0's tweedie: 470.877\n",
      "[184]\tvalid_0's tweedie: 470.877\n",
      "[185]\tvalid_0's tweedie: 470.877\n",
      "[186]\tvalid_0's tweedie: 470.876\n",
      "[187]\tvalid_0's tweedie: 470.876\n",
      "[188]\tvalid_0's tweedie: 470.875\n",
      "[189]\tvalid_0's tweedie: 470.875\n",
      "[190]\tvalid_0's tweedie: 470.875\n",
      "[191]\tvalid_0's tweedie: 470.878\n",
      "[192]\tvalid_0's tweedie: 470.877\n",
      "[193]\tvalid_0's tweedie: 470.878\n",
      "[194]\tvalid_0's tweedie: 470.878\n",
      "[195]\tvalid_0's tweedie: 470.878\n",
      "[196]\tvalid_0's tweedie: 470.878\n",
      "[197]\tvalid_0's tweedie: 470.878\n",
      "[198]\tvalid_0's tweedie: 470.878\n",
      "[199]\tvalid_0's tweedie: 470.877\n",
      "[200]\tvalid_0's tweedie: 470.877\n",
      "[201]\tvalid_0's tweedie: 470.876\n",
      "[202]\tvalid_0's tweedie: 470.876\n",
      "[203]\tvalid_0's tweedie: 470.875\n",
      "[204]\tvalid_0's tweedie: 470.875\n",
      "[205]\tvalid_0's tweedie: 470.874\n",
      "[206]\tvalid_0's tweedie: 470.874\n",
      "[207]\tvalid_0's tweedie: 470.874\n",
      "[208]\tvalid_0's tweedie: 470.875\n",
      "[209]\tvalid_0's tweedie: 470.875\n",
      "[210]\tvalid_0's tweedie: 470.875\n",
      "[211]\tvalid_0's tweedie: 470.874\n",
      "[212]\tvalid_0's tweedie: 470.874\n",
      "[213]\tvalid_0's tweedie: 470.874\n",
      "[214]\tvalid_0's tweedie: 470.873\n",
      "[215]\tvalid_0's tweedie: 470.873\n",
      "[216]\tvalid_0's tweedie: 470.873\n",
      "[217]\tvalid_0's tweedie: 470.872\n",
      "[218]\tvalid_0's tweedie: 470.872\n",
      "[219]\tvalid_0's tweedie: 470.872\n",
      "[220]\tvalid_0's tweedie: 470.872\n",
      "[221]\tvalid_0's tweedie: 470.872\n",
      "[222]\tvalid_0's tweedie: 470.872\n",
      "[223]\tvalid_0's tweedie: 470.872\n",
      "[224]\tvalid_0's tweedie: 470.872\n",
      "[225]\tvalid_0's tweedie: 470.872\n",
      "[226]\tvalid_0's tweedie: 470.872\n",
      "[227]\tvalid_0's tweedie: 470.872\n",
      "[228]\tvalid_0's tweedie: 470.873\n",
      "[229]\tvalid_0's tweedie: 470.872\n",
      "[230]\tvalid_0's tweedie: 470.872\n",
      "[231]\tvalid_0's tweedie: 470.872\n",
      "[232]\tvalid_0's tweedie: 470.873\n",
      "[233]\tvalid_0's tweedie: 470.873\n",
      "[234]\tvalid_0's tweedie: 470.873\n",
      "[235]\tvalid_0's tweedie: 470.873\n",
      "[236]\tvalid_0's tweedie: 470.873\n",
      "[237]\tvalid_0's tweedie: 470.873\n",
      "[238]\tvalid_0's tweedie: 470.873\n",
      "[239]\tvalid_0's tweedie: 470.873\n",
      "[240]\tvalid_0's tweedie: 470.872\n",
      "[241]\tvalid_0's tweedie: 470.872\n",
      "[242]\tvalid_0's tweedie: 470.872\n",
      "[243]\tvalid_0's tweedie: 470.872\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's tweedie: 470.872\n",
      "Training model for level 2 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 5556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346313\n",
      "[1]\tvalid_0's tweedie: 476.275\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.399\n",
      "[3]\tvalid_0's tweedie: 474.674\n",
      "[4]\tvalid_0's tweedie: 474.075\n",
      "[5]\tvalid_0's tweedie: 473.599\n",
      "[6]\tvalid_0's tweedie: 473.224\n",
      "[7]\tvalid_0's tweedie: 472.888\n",
      "[8]\tvalid_0's tweedie: 472.6\n",
      "[9]\tvalid_0's tweedie: 472.367\n",
      "[10]\tvalid_0's tweedie: 472.174\n",
      "[11]\tvalid_0's tweedie: 472.007\n",
      "[12]\tvalid_0's tweedie: 471.871\n",
      "[13]\tvalid_0's tweedie: 471.747\n",
      "[14]\tvalid_0's tweedie: 471.643\n",
      "[15]\tvalid_0's tweedie: 471.566\n",
      "[16]\tvalid_0's tweedie: 471.495\n",
      "[17]\tvalid_0's tweedie: 471.429\n",
      "[18]\tvalid_0's tweedie: 471.37\n",
      "[19]\tvalid_0's tweedie: 471.335\n",
      "[20]\tvalid_0's tweedie: 471.295\n",
      "[21]\tvalid_0's tweedie: 471.259\n",
      "[22]\tvalid_0's tweedie: 471.229\n",
      "[23]\tvalid_0's tweedie: 471.204\n",
      "[24]\tvalid_0's tweedie: 471.173\n",
      "[25]\tvalid_0's tweedie: 471.154\n",
      "[26]\tvalid_0's tweedie: 471.138\n",
      "[27]\tvalid_0's tweedie: 471.123\n",
      "[28]\tvalid_0's tweedie: 471.104\n",
      "[29]\tvalid_0's tweedie: 471.093\n",
      "[30]\tvalid_0's tweedie: 471.087\n",
      "[31]\tvalid_0's tweedie: 471.074\n",
      "[32]\tvalid_0's tweedie: 471.062\n",
      "[33]\tvalid_0's tweedie: 471.053\n",
      "[34]\tvalid_0's tweedie: 471.048\n",
      "[35]\tvalid_0's tweedie: 471.038\n",
      "[36]\tvalid_0's tweedie: 471.027\n",
      "[37]\tvalid_0's tweedie: 471.016\n",
      "[38]\tvalid_0's tweedie: 471.008\n",
      "[39]\tvalid_0's tweedie: 471.003\n",
      "[40]\tvalid_0's tweedie: 470.997\n",
      "[41]\tvalid_0's tweedie: 470.991\n",
      "[42]\tvalid_0's tweedie: 470.985\n",
      "[43]\tvalid_0's tweedie: 470.981\n",
      "[44]\tvalid_0's tweedie: 470.977\n",
      "[45]\tvalid_0's tweedie: 470.976\n",
      "[46]\tvalid_0's tweedie: 470.974\n",
      "[47]\tvalid_0's tweedie: 470.97\n",
      "[48]\tvalid_0's tweedie: 470.969\n",
      "[49]\tvalid_0's tweedie: 470.967\n",
      "[50]\tvalid_0's tweedie: 470.967\n",
      "[51]\tvalid_0's tweedie: 470.965\n",
      "[52]\tvalid_0's tweedie: 470.963\n",
      "[53]\tvalid_0's tweedie: 470.962\n",
      "[54]\tvalid_0's tweedie: 470.962\n",
      "[55]\tvalid_0's tweedie: 470.96\n",
      "[56]\tvalid_0's tweedie: 470.96\n",
      "[57]\tvalid_0's tweedie: 470.961\n",
      "[58]\tvalid_0's tweedie: 470.961\n",
      "[59]\tvalid_0's tweedie: 470.961\n",
      "[60]\tvalid_0's tweedie: 470.961\n",
      "[61]\tvalid_0's tweedie: 470.96\n",
      "[62]\tvalid_0's tweedie: 470.958\n",
      "[63]\tvalid_0's tweedie: 470.958\n",
      "[64]\tvalid_0's tweedie: 470.956\n",
      "[65]\tvalid_0's tweedie: 470.956\n",
      "[66]\tvalid_0's tweedie: 470.953\n",
      "[67]\tvalid_0's tweedie: 470.949\n",
      "[68]\tvalid_0's tweedie: 470.947\n",
      "[69]\tvalid_0's tweedie: 470.947\n",
      "[70]\tvalid_0's tweedie: 470.942\n",
      "[71]\tvalid_0's tweedie: 470.942\n",
      "[72]\tvalid_0's tweedie: 470.94\n",
      "[73]\tvalid_0's tweedie: 470.938\n",
      "[74]\tvalid_0's tweedie: 470.939\n",
      "[75]\tvalid_0's tweedie: 470.935\n",
      "[76]\tvalid_0's tweedie: 470.932\n",
      "[77]\tvalid_0's tweedie: 470.932\n",
      "[78]\tvalid_0's tweedie: 470.933\n",
      "[79]\tvalid_0's tweedie: 470.933\n",
      "[80]\tvalid_0's tweedie: 470.929\n",
      "[81]\tvalid_0's tweedie: 470.929\n",
      "[82]\tvalid_0's tweedie: 470.93\n",
      "[83]\tvalid_0's tweedie: 470.928\n",
      "[84]\tvalid_0's tweedie: 470.928\n",
      "[85]\tvalid_0's tweedie: 470.927\n",
      "[86]\tvalid_0's tweedie: 470.928\n",
      "[87]\tvalid_0's tweedie: 470.927\n",
      "[88]\tvalid_0's tweedie: 470.928\n",
      "[89]\tvalid_0's tweedie: 470.928\n",
      "[90]\tvalid_0's tweedie: 470.926\n",
      "[91]\tvalid_0's tweedie: 470.924\n",
      "[92]\tvalid_0's tweedie: 470.924\n",
      "[93]\tvalid_0's tweedie: 470.924\n",
      "[94]\tvalid_0's tweedie: 470.924\n",
      "[95]\tvalid_0's tweedie: 470.924\n",
      "[96]\tvalid_0's tweedie: 470.923\n",
      "[97]\tvalid_0's tweedie: 470.923\n",
      "[98]\tvalid_0's tweedie: 470.922\n",
      "[99]\tvalid_0's tweedie: 470.921\n",
      "[100]\tvalid_0's tweedie: 470.92\n",
      "[101]\tvalid_0's tweedie: 470.918\n",
      "[102]\tvalid_0's tweedie: 470.917\n",
      "[103]\tvalid_0's tweedie: 470.918\n",
      "[104]\tvalid_0's tweedie: 470.92\n",
      "[105]\tvalid_0's tweedie: 470.919\n",
      "[106]\tvalid_0's tweedie: 470.916\n",
      "[107]\tvalid_0's tweedie: 470.916\n",
      "[108]\tvalid_0's tweedie: 470.916\n",
      "[109]\tvalid_0's tweedie: 470.915\n",
      "[110]\tvalid_0's tweedie: 470.915\n",
      "[111]\tvalid_0's tweedie: 470.915\n",
      "[112]\tvalid_0's tweedie: 470.917\n",
      "[113]\tvalid_0's tweedie: 470.917\n",
      "[114]\tvalid_0's tweedie: 470.918\n",
      "[115]\tvalid_0's tweedie: 470.918\n",
      "[116]\tvalid_0's tweedie: 470.917\n",
      "[117]\tvalid_0's tweedie: 470.917\n",
      "[118]\tvalid_0's tweedie: 470.916\n",
      "[119]\tvalid_0's tweedie: 470.915\n",
      "[120]\tvalid_0's tweedie: 470.914\n",
      "[121]\tvalid_0's tweedie: 470.914\n",
      "[122]\tvalid_0's tweedie: 470.914\n",
      "[123]\tvalid_0's tweedie: 470.915\n",
      "[124]\tvalid_0's tweedie: 470.915\n",
      "[125]\tvalid_0's tweedie: 470.912\n",
      "[126]\tvalid_0's tweedie: 470.911\n",
      "[127]\tvalid_0's tweedie: 470.913\n",
      "[128]\tvalid_0's tweedie: 470.912\n",
      "[129]\tvalid_0's tweedie: 470.912\n",
      "[130]\tvalid_0's tweedie: 470.911\n",
      "[131]\tvalid_0's tweedie: 470.911\n",
      "[132]\tvalid_0's tweedie: 470.911\n",
      "[133]\tvalid_0's tweedie: 470.911\n",
      "[134]\tvalid_0's tweedie: 470.908\n",
      "[135]\tvalid_0's tweedie: 470.908\n",
      "[136]\tvalid_0's tweedie: 470.908\n",
      "[137]\tvalid_0's tweedie: 470.907\n",
      "[138]\tvalid_0's tweedie: 470.908\n",
      "[139]\tvalid_0's tweedie: 470.907\n",
      "[140]\tvalid_0's tweedie: 470.907\n",
      "[141]\tvalid_0's tweedie: 470.907\n",
      "[142]\tvalid_0's tweedie: 470.906\n",
      "[143]\tvalid_0's tweedie: 470.905\n",
      "[144]\tvalid_0's tweedie: 470.905\n",
      "[145]\tvalid_0's tweedie: 470.905\n",
      "[146]\tvalid_0's tweedie: 470.905\n",
      "[147]\tvalid_0's tweedie: 470.905\n",
      "[148]\tvalid_0's tweedie: 470.905\n",
      "[149]\tvalid_0's tweedie: 470.905\n",
      "[150]\tvalid_0's tweedie: 470.905\n",
      "[151]\tvalid_0's tweedie: 470.902\n",
      "[152]\tvalid_0's tweedie: 470.901\n",
      "[153]\tvalid_0's tweedie: 470.902\n",
      "[154]\tvalid_0's tweedie: 470.9\n",
      "[155]\tvalid_0's tweedie: 470.9\n",
      "[156]\tvalid_0's tweedie: 470.9\n",
      "[157]\tvalid_0's tweedie: 470.899\n",
      "[158]\tvalid_0's tweedie: 470.897\n",
      "[159]\tvalid_0's tweedie: 470.894\n",
      "[160]\tvalid_0's tweedie: 470.894\n",
      "[161]\tvalid_0's tweedie: 470.895\n",
      "[162]\tvalid_0's tweedie: 470.893\n",
      "[163]\tvalid_0's tweedie: 470.892\n",
      "[164]\tvalid_0's tweedie: 470.893\n",
      "[165]\tvalid_0's tweedie: 470.893\n",
      "[166]\tvalid_0's tweedie: 470.892\n",
      "[167]\tvalid_0's tweedie: 470.891\n",
      "[168]\tvalid_0's tweedie: 470.89\n",
      "[169]\tvalid_0's tweedie: 470.89\n",
      "[170]\tvalid_0's tweedie: 470.89\n",
      "[171]\tvalid_0's tweedie: 470.888\n",
      "[172]\tvalid_0's tweedie: 470.889\n",
      "[173]\tvalid_0's tweedie: 470.888\n",
      "[174]\tvalid_0's tweedie: 470.888\n",
      "[175]\tvalid_0's tweedie: 470.888\n",
      "[176]\tvalid_0's tweedie: 470.888\n",
      "[177]\tvalid_0's tweedie: 470.887\n",
      "[178]\tvalid_0's tweedie: 470.887\n",
      "[179]\tvalid_0's tweedie: 470.888\n",
      "[180]\tvalid_0's tweedie: 470.888\n",
      "[181]\tvalid_0's tweedie: 470.887\n",
      "[182]\tvalid_0's tweedie: 470.887\n",
      "[183]\tvalid_0's tweedie: 470.888\n",
      "[184]\tvalid_0's tweedie: 470.887\n",
      "[185]\tvalid_0's tweedie: 470.887\n",
      "[186]\tvalid_0's tweedie: 470.887\n",
      "[187]\tvalid_0's tweedie: 470.887\n",
      "[188]\tvalid_0's tweedie: 470.887\n",
      "[189]\tvalid_0's tweedie: 470.887\n",
      "[190]\tvalid_0's tweedie: 470.887\n",
      "[191]\tvalid_0's tweedie: 470.887\n",
      "[192]\tvalid_0's tweedie: 470.887\n",
      "[193]\tvalid_0's tweedie: 470.886\n",
      "[194]\tvalid_0's tweedie: 470.886\n",
      "[195]\tvalid_0's tweedie: 470.885\n",
      "[196]\tvalid_0's tweedie: 470.886\n",
      "[197]\tvalid_0's tweedie: 470.887\n",
      "[198]\tvalid_0's tweedie: 470.887\n",
      "[199]\tvalid_0's tweedie: 470.887\n",
      "[200]\tvalid_0's tweedie: 470.884\n",
      "[201]\tvalid_0's tweedie: 470.883\n",
      "[202]\tvalid_0's tweedie: 470.883\n",
      "[203]\tvalid_0's tweedie: 470.883\n",
      "[204]\tvalid_0's tweedie: 470.883\n",
      "[205]\tvalid_0's tweedie: 470.882\n",
      "[206]\tvalid_0's tweedie: 470.882\n",
      "[207]\tvalid_0's tweedie: 470.882\n",
      "[208]\tvalid_0's tweedie: 470.882\n",
      "[209]\tvalid_0's tweedie: 470.882\n",
      "[210]\tvalid_0's tweedie: 470.883\n",
      "[211]\tvalid_0's tweedie: 470.883\n",
      "[212]\tvalid_0's tweedie: 470.881\n",
      "[213]\tvalid_0's tweedie: 470.882\n",
      "[214]\tvalid_0's tweedie: 470.883\n",
      "[215]\tvalid_0's tweedie: 470.883\n",
      "[216]\tvalid_0's tweedie: 470.883\n",
      "[217]\tvalid_0's tweedie: 470.883\n",
      "[218]\tvalid_0's tweedie: 470.884\n",
      "[219]\tvalid_0's tweedie: 470.884\n",
      "[220]\tvalid_0's tweedie: 470.884\n",
      "[221]\tvalid_0's tweedie: 470.882\n",
      "[222]\tvalid_0's tweedie: 470.881\n",
      "[223]\tvalid_0's tweedie: 470.881\n",
      "[224]\tvalid_0's tweedie: 470.881\n",
      "[225]\tvalid_0's tweedie: 470.881\n",
      "[226]\tvalid_0's tweedie: 470.881\n",
      "[227]\tvalid_0's tweedie: 470.881\n",
      "[228]\tvalid_0's tweedie: 470.881\n",
      "[229]\tvalid_0's tweedie: 470.88\n",
      "[230]\tvalid_0's tweedie: 470.88\n",
      "[231]\tvalid_0's tweedie: 470.88\n",
      "[232]\tvalid_0's tweedie: 470.88\n",
      "[233]\tvalid_0's tweedie: 470.88\n",
      "[234]\tvalid_0's tweedie: 470.88\n",
      "[235]\tvalid_0's tweedie: 470.88\n",
      "[236]\tvalid_0's tweedie: 470.88\n",
      "[237]\tvalid_0's tweedie: 470.879\n",
      "[238]\tvalid_0's tweedie: 470.879\n",
      "[239]\tvalid_0's tweedie: 470.879\n",
      "[240]\tvalid_0's tweedie: 470.879\n",
      "[241]\tvalid_0's tweedie: 470.879\n",
      "[242]\tvalid_0's tweedie: 470.879\n",
      "[243]\tvalid_0's tweedie: 470.879\n",
      "[244]\tvalid_0's tweedie: 470.879\n",
      "[245]\tvalid_0's tweedie: 470.879\n",
      "[246]\tvalid_0's tweedie: 470.878\n",
      "[247]\tvalid_0's tweedie: 470.88\n",
      "[248]\tvalid_0's tweedie: 470.88\n",
      "[249]\tvalid_0's tweedie: 470.879\n",
      "[250]\tvalid_0's tweedie: 470.879\n",
      "[251]\tvalid_0's tweedie: 470.879\n",
      "[252]\tvalid_0's tweedie: 470.878\n",
      "[253]\tvalid_0's tweedie: 470.879\n",
      "[254]\tvalid_0's tweedie: 470.879\n",
      "[255]\tvalid_0's tweedie: 470.88\n",
      "[256]\tvalid_0's tweedie: 470.88\n",
      "[257]\tvalid_0's tweedie: 470.879\n",
      "[258]\tvalid_0's tweedie: 470.878\n",
      "[259]\tvalid_0's tweedie: 470.877\n",
      "[260]\tvalid_0's tweedie: 470.877\n",
      "[261]\tvalid_0's tweedie: 470.877\n",
      "[262]\tvalid_0's tweedie: 470.877\n",
      "[263]\tvalid_0's tweedie: 470.877\n",
      "[264]\tvalid_0's tweedie: 470.877\n",
      "[265]\tvalid_0's tweedie: 470.876\n",
      "[266]\tvalid_0's tweedie: 470.876\n",
      "[267]\tvalid_0's tweedie: 470.876\n",
      "[268]\tvalid_0's tweedie: 470.876\n",
      "[269]\tvalid_0's tweedie: 470.876\n",
      "[270]\tvalid_0's tweedie: 470.878\n",
      "[271]\tvalid_0's tweedie: 470.878\n",
      "[272]\tvalid_0's tweedie: 470.878\n",
      "[273]\tvalid_0's tweedie: 470.878\n",
      "[274]\tvalid_0's tweedie: 470.877\n",
      "[275]\tvalid_0's tweedie: 470.875\n",
      "[276]\tvalid_0's tweedie: 470.874\n",
      "[277]\tvalid_0's tweedie: 470.874\n",
      "[278]\tvalid_0's tweedie: 470.874\n",
      "[279]\tvalid_0's tweedie: 470.874\n",
      "[280]\tvalid_0's tweedie: 470.875\n",
      "[281]\tvalid_0's tweedie: 470.874\n",
      "[282]\tvalid_0's tweedie: 470.874\n",
      "[283]\tvalid_0's tweedie: 470.874\n",
      "[284]\tvalid_0's tweedie: 470.874\n",
      "[285]\tvalid_0's tweedie: 470.874\n",
      "[286]\tvalid_0's tweedie: 470.874\n",
      "[287]\tvalid_0's tweedie: 470.873\n",
      "[288]\tvalid_0's tweedie: 470.873\n",
      "[289]\tvalid_0's tweedie: 470.873\n",
      "[290]\tvalid_0's tweedie: 470.871\n",
      "[291]\tvalid_0's tweedie: 470.871\n",
      "[292]\tvalid_0's tweedie: 470.871\n",
      "[293]\tvalid_0's tweedie: 470.871\n",
      "[294]\tvalid_0's tweedie: 470.871\n",
      "[295]\tvalid_0's tweedie: 470.87\n",
      "[296]\tvalid_0's tweedie: 470.87\n",
      "[297]\tvalid_0's tweedie: 470.869\n",
      "[298]\tvalid_0's tweedie: 470.869\n",
      "[299]\tvalid_0's tweedie: 470.869\n",
      "[300]\tvalid_0's tweedie: 470.869\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[297]\tvalid_0's tweedie: 470.869\n",
      "Training model for level 2 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5489\n",
      "[LightGBM] [Info] Number of data points in the train set: 5553, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346484\n",
      "[1]\tvalid_0's tweedie: 476.279\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.401\n",
      "[3]\tvalid_0's tweedie: 474.684\n",
      "[4]\tvalid_0's tweedie: 474.084\n",
      "[5]\tvalid_0's tweedie: 473.605\n",
      "[6]\tvalid_0's tweedie: 473.234\n",
      "[7]\tvalid_0's tweedie: 472.887\n",
      "[8]\tvalid_0's tweedie: 472.638\n",
      "[9]\tvalid_0's tweedie: 472.404\n",
      "[10]\tvalid_0's tweedie: 472.208\n",
      "[11]\tvalid_0's tweedie: 472.032\n",
      "[12]\tvalid_0's tweedie: 471.888\n",
      "[13]\tvalid_0's tweedie: 471.773\n",
      "[14]\tvalid_0's tweedie: 471.657\n",
      "[15]\tvalid_0's tweedie: 471.578\n",
      "[16]\tvalid_0's tweedie: 471.49\n",
      "[17]\tvalid_0's tweedie: 471.417\n",
      "[18]\tvalid_0's tweedie: 471.364\n",
      "[19]\tvalid_0's tweedie: 471.313\n",
      "[20]\tvalid_0's tweedie: 471.265\n",
      "[21]\tvalid_0's tweedie: 471.233\n",
      "[22]\tvalid_0's tweedie: 471.2\n",
      "[23]\tvalid_0's tweedie: 471.169\n",
      "[24]\tvalid_0's tweedie: 471.145\n",
      "[25]\tvalid_0's tweedie: 471.132\n",
      "[26]\tvalid_0's tweedie: 471.112\n",
      "[27]\tvalid_0's tweedie: 471.095\n",
      "[28]\tvalid_0's tweedie: 471.073\n",
      "[29]\tvalid_0's tweedie: 471.058\n",
      "[30]\tvalid_0's tweedie: 471.045\n",
      "[31]\tvalid_0's tweedie: 471.031\n",
      "[32]\tvalid_0's tweedie: 471.019\n",
      "[33]\tvalid_0's tweedie: 471.009\n",
      "[34]\tvalid_0's tweedie: 470.997\n",
      "[35]\tvalid_0's tweedie: 470.988\n",
      "[36]\tvalid_0's tweedie: 470.98\n",
      "[37]\tvalid_0's tweedie: 470.972\n",
      "[38]\tvalid_0's tweedie: 470.969\n",
      "[39]\tvalid_0's tweedie: 470.965\n",
      "[40]\tvalid_0's tweedie: 470.96\n",
      "[41]\tvalid_0's tweedie: 470.954\n",
      "[42]\tvalid_0's tweedie: 470.946\n",
      "[43]\tvalid_0's tweedie: 470.943\n",
      "[44]\tvalid_0's tweedie: 470.941\n",
      "[45]\tvalid_0's tweedie: 470.937\n",
      "[46]\tvalid_0's tweedie: 470.936\n",
      "[47]\tvalid_0's tweedie: 470.934\n",
      "[48]\tvalid_0's tweedie: 470.934\n",
      "[49]\tvalid_0's tweedie: 470.933\n",
      "[50]\tvalid_0's tweedie: 470.932\n",
      "[51]\tvalid_0's tweedie: 470.932\n",
      "[52]\tvalid_0's tweedie: 470.929\n",
      "[53]\tvalid_0's tweedie: 470.929\n",
      "[54]\tvalid_0's tweedie: 470.929\n",
      "[55]\tvalid_0's tweedie: 470.927\n",
      "[56]\tvalid_0's tweedie: 470.926\n",
      "[57]\tvalid_0's tweedie: 470.924\n",
      "[58]\tvalid_0's tweedie: 470.923\n",
      "[59]\tvalid_0's tweedie: 470.923\n",
      "[60]\tvalid_0's tweedie: 470.923\n",
      "[61]\tvalid_0's tweedie: 470.918\n",
      "[62]\tvalid_0's tweedie: 470.916\n",
      "[63]\tvalid_0's tweedie: 470.91\n",
      "[64]\tvalid_0's tweedie: 470.91\n",
      "[65]\tvalid_0's tweedie: 470.91\n",
      "[66]\tvalid_0's tweedie: 470.909\n",
      "[67]\tvalid_0's tweedie: 470.907\n",
      "[68]\tvalid_0's tweedie: 470.904\n",
      "[69]\tvalid_0's tweedie: 470.901\n",
      "[70]\tvalid_0's tweedie: 470.899\n",
      "[71]\tvalid_0's tweedie: 470.899\n",
      "[72]\tvalid_0's tweedie: 470.897\n",
      "[73]\tvalid_0's tweedie: 470.901\n",
      "[74]\tvalid_0's tweedie: 470.9\n",
      "[75]\tvalid_0's tweedie: 470.9\n",
      "[76]\tvalid_0's tweedie: 470.898\n",
      "[77]\tvalid_0's tweedie: 470.899\n",
      "[78]\tvalid_0's tweedie: 470.896\n",
      "[79]\tvalid_0's tweedie: 470.896\n",
      "[80]\tvalid_0's tweedie: 470.893\n",
      "[81]\tvalid_0's tweedie: 470.893\n",
      "[82]\tvalid_0's tweedie: 470.894\n",
      "[83]\tvalid_0's tweedie: 470.893\n",
      "[84]\tvalid_0's tweedie: 470.892\n",
      "[85]\tvalid_0's tweedie: 470.887\n",
      "[86]\tvalid_0's tweedie: 470.887\n",
      "[87]\tvalid_0's tweedie: 470.887\n",
      "[88]\tvalid_0's tweedie: 470.887\n",
      "[89]\tvalid_0's tweedie: 470.883\n",
      "[90]\tvalid_0's tweedie: 470.881\n",
      "[91]\tvalid_0's tweedie: 470.881\n",
      "[92]\tvalid_0's tweedie: 470.881\n",
      "[93]\tvalid_0's tweedie: 470.881\n",
      "[94]\tvalid_0's tweedie: 470.879\n",
      "[95]\tvalid_0's tweedie: 470.879\n",
      "[96]\tvalid_0's tweedie: 470.878\n",
      "[97]\tvalid_0's tweedie: 470.878\n",
      "[98]\tvalid_0's tweedie: 470.88\n",
      "[99]\tvalid_0's tweedie: 470.88\n",
      "[100]\tvalid_0's tweedie: 470.878\n",
      "[101]\tvalid_0's tweedie: 470.878\n",
      "[102]\tvalid_0's tweedie: 470.878\n",
      "[103]\tvalid_0's tweedie: 470.877\n",
      "[104]\tvalid_0's tweedie: 470.877\n",
      "[105]\tvalid_0's tweedie: 470.874\n",
      "[106]\tvalid_0's tweedie: 470.873\n",
      "[107]\tvalid_0's tweedie: 470.87\n",
      "[108]\tvalid_0's tweedie: 470.868\n",
      "[109]\tvalid_0's tweedie: 470.868\n",
      "[110]\tvalid_0's tweedie: 470.868\n",
      "[111]\tvalid_0's tweedie: 470.867\n",
      "[112]\tvalid_0's tweedie: 470.866\n",
      "[113]\tvalid_0's tweedie: 470.863\n",
      "[114]\tvalid_0's tweedie: 470.864\n",
      "[115]\tvalid_0's tweedie: 470.864\n",
      "[116]\tvalid_0's tweedie: 470.864\n",
      "[117]\tvalid_0's tweedie: 470.864\n",
      "[118]\tvalid_0's tweedie: 470.862\n",
      "[119]\tvalid_0's tweedie: 470.861\n",
      "[120]\tvalid_0's tweedie: 470.86\n",
      "[121]\tvalid_0's tweedie: 470.86\n",
      "[122]\tvalid_0's tweedie: 470.86\n",
      "[123]\tvalid_0's tweedie: 470.859\n",
      "[124]\tvalid_0's tweedie: 470.859\n",
      "[125]\tvalid_0's tweedie: 470.859\n",
      "[126]\tvalid_0's tweedie: 470.859\n",
      "[127]\tvalid_0's tweedie: 470.859\n",
      "[128]\tvalid_0's tweedie: 470.858\n",
      "[129]\tvalid_0's tweedie: 470.858\n",
      "[130]\tvalid_0's tweedie: 470.858\n",
      "[131]\tvalid_0's tweedie: 470.858\n",
      "[132]\tvalid_0's tweedie: 470.857\n",
      "[133]\tvalid_0's tweedie: 470.857\n",
      "[134]\tvalid_0's tweedie: 470.857\n",
      "[135]\tvalid_0's tweedie: 470.857\n",
      "[136]\tvalid_0's tweedie: 470.856\n",
      "[137]\tvalid_0's tweedie: 470.855\n",
      "[138]\tvalid_0's tweedie: 470.855\n",
      "[139]\tvalid_0's tweedie: 470.856\n",
      "[140]\tvalid_0's tweedie: 470.854\n",
      "[141]\tvalid_0's tweedie: 470.854\n",
      "[142]\tvalid_0's tweedie: 470.854\n",
      "[143]\tvalid_0's tweedie: 470.851\n",
      "[144]\tvalid_0's tweedie: 470.851\n",
      "[145]\tvalid_0's tweedie: 470.854\n",
      "[146]\tvalid_0's tweedie: 470.854\n",
      "[147]\tvalid_0's tweedie: 470.852\n",
      "[148]\tvalid_0's tweedie: 470.852\n",
      "[149]\tvalid_0's tweedie: 470.851\n",
      "[150]\tvalid_0's tweedie: 470.85\n",
      "[151]\tvalid_0's tweedie: 470.85\n",
      "[152]\tvalid_0's tweedie: 470.85\n",
      "[153]\tvalid_0's tweedie: 470.85\n",
      "[154]\tvalid_0's tweedie: 470.85\n",
      "[155]\tvalid_0's tweedie: 470.85\n",
      "[156]\tvalid_0's tweedie: 470.849\n",
      "[157]\tvalid_0's tweedie: 470.85\n",
      "[158]\tvalid_0's tweedie: 470.85\n",
      "[159]\tvalid_0's tweedie: 470.85\n",
      "[160]\tvalid_0's tweedie: 470.85\n",
      "[161]\tvalid_0's tweedie: 470.852\n",
      "[162]\tvalid_0's tweedie: 470.852\n",
      "[163]\tvalid_0's tweedie: 470.852\n",
      "[164]\tvalid_0's tweedie: 470.852\n",
      "[165]\tvalid_0's tweedie: 470.853\n",
      "[166]\tvalid_0's tweedie: 470.853\n",
      "[167]\tvalid_0's tweedie: 470.853\n",
      "[168]\tvalid_0's tweedie: 470.853\n",
      "[169]\tvalid_0's tweedie: 470.852\n",
      "[170]\tvalid_0's tweedie: 470.852\n",
      "[171]\tvalid_0's tweedie: 470.851\n",
      "[172]\tvalid_0's tweedie: 470.851\n",
      "[173]\tvalid_0's tweedie: 470.851\n",
      "[174]\tvalid_0's tweedie: 470.852\n",
      "[175]\tvalid_0's tweedie: 470.852\n",
      "[176]\tvalid_0's tweedie: 470.851\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's tweedie: 470.849\n",
      "Training model for level 2 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5488\n",
      "[LightGBM] [Info] Number of data points in the train set: 5550, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346654\n",
      "[1]\tvalid_0's tweedie: 476.269\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.397\n",
      "[3]\tvalid_0's tweedie: 474.67\n",
      "[4]\tvalid_0's tweedie: 474.07\n",
      "[5]\tvalid_0's tweedie: 473.615\n",
      "[6]\tvalid_0's tweedie: 473.203\n",
      "[7]\tvalid_0's tweedie: 472.854\n",
      "[8]\tvalid_0's tweedie: 472.548\n",
      "[9]\tvalid_0's tweedie: 472.346\n",
      "[10]\tvalid_0's tweedie: 472.145\n",
      "[11]\tvalid_0's tweedie: 471.976\n",
      "[12]\tvalid_0's tweedie: 471.826\n",
      "[13]\tvalid_0's tweedie: 471.696\n",
      "[14]\tvalid_0's tweedie: 471.605\n",
      "[15]\tvalid_0's tweedie: 471.51\n",
      "[16]\tvalid_0's tweedie: 471.453\n",
      "[17]\tvalid_0's tweedie: 471.393\n",
      "[18]\tvalid_0's tweedie: 471.347\n",
      "[19]\tvalid_0's tweedie: 471.291\n",
      "[20]\tvalid_0's tweedie: 471.243\n",
      "[21]\tvalid_0's tweedie: 471.199\n",
      "[22]\tvalid_0's tweedie: 471.164\n",
      "[23]\tvalid_0's tweedie: 471.15\n",
      "[24]\tvalid_0's tweedie: 471.128\n",
      "[25]\tvalid_0's tweedie: 471.105\n",
      "[26]\tvalid_0's tweedie: 471.087\n",
      "[27]\tvalid_0's tweedie: 471.064\n",
      "[28]\tvalid_0's tweedie: 471.043\n",
      "[29]\tvalid_0's tweedie: 471.031\n",
      "[30]\tvalid_0's tweedie: 471.015\n",
      "[31]\tvalid_0's tweedie: 471.012\n",
      "[32]\tvalid_0's tweedie: 471.004\n",
      "[33]\tvalid_0's tweedie: 470.99\n",
      "[34]\tvalid_0's tweedie: 470.981\n",
      "[35]\tvalid_0's tweedie: 470.971\n",
      "[36]\tvalid_0's tweedie: 470.963\n",
      "[37]\tvalid_0's tweedie: 470.956\n",
      "[38]\tvalid_0's tweedie: 470.949\n",
      "[39]\tvalid_0's tweedie: 470.944\n",
      "[40]\tvalid_0's tweedie: 470.944\n",
      "[41]\tvalid_0's tweedie: 470.94\n",
      "[42]\tvalid_0's tweedie: 470.935\n",
      "[43]\tvalid_0's tweedie: 470.931\n",
      "[44]\tvalid_0's tweedie: 470.927\n",
      "[45]\tvalid_0's tweedie: 470.922\n",
      "[46]\tvalid_0's tweedie: 470.92\n",
      "[47]\tvalid_0's tweedie: 470.914\n",
      "[48]\tvalid_0's tweedie: 470.912\n",
      "[49]\tvalid_0's tweedie: 470.907\n",
      "[50]\tvalid_0's tweedie: 470.907\n",
      "[51]\tvalid_0's tweedie: 470.905\n",
      "[52]\tvalid_0's tweedie: 470.903\n",
      "[53]\tvalid_0's tweedie: 470.898\n",
      "[54]\tvalid_0's tweedie: 470.895\n",
      "[55]\tvalid_0's tweedie: 470.891\n",
      "[56]\tvalid_0's tweedie: 470.888\n",
      "[57]\tvalid_0's tweedie: 470.888\n",
      "[58]\tvalid_0's tweedie: 470.887\n",
      "[59]\tvalid_0's tweedie: 470.887\n",
      "[60]\tvalid_0's tweedie: 470.885\n",
      "[61]\tvalid_0's tweedie: 470.884\n",
      "[62]\tvalid_0's tweedie: 470.882\n",
      "[63]\tvalid_0's tweedie: 470.879\n",
      "[64]\tvalid_0's tweedie: 470.879\n",
      "[65]\tvalid_0's tweedie: 470.877\n",
      "[66]\tvalid_0's tweedie: 470.874\n",
      "[67]\tvalid_0's tweedie: 470.873\n",
      "[68]\tvalid_0's tweedie: 470.875\n",
      "[69]\tvalid_0's tweedie: 470.873\n",
      "[70]\tvalid_0's tweedie: 470.872\n",
      "[71]\tvalid_0's tweedie: 470.871\n",
      "[72]\tvalid_0's tweedie: 470.866\n",
      "[73]\tvalid_0's tweedie: 470.866\n",
      "[74]\tvalid_0's tweedie: 470.866\n",
      "[75]\tvalid_0's tweedie: 470.863\n",
      "[76]\tvalid_0's tweedie: 470.862\n",
      "[77]\tvalid_0's tweedie: 470.861\n",
      "[78]\tvalid_0's tweedie: 470.861\n",
      "[79]\tvalid_0's tweedie: 470.861\n",
      "[80]\tvalid_0's tweedie: 470.861\n",
      "[81]\tvalid_0's tweedie: 470.859\n",
      "[82]\tvalid_0's tweedie: 470.858\n",
      "[83]\tvalid_0's tweedie: 470.855\n",
      "[84]\tvalid_0's tweedie: 470.856\n",
      "[85]\tvalid_0's tweedie: 470.854\n",
      "[86]\tvalid_0's tweedie: 470.854\n",
      "[87]\tvalid_0's tweedie: 470.854\n",
      "[88]\tvalid_0's tweedie: 470.854\n",
      "[89]\tvalid_0's tweedie: 470.853\n",
      "[90]\tvalid_0's tweedie: 470.853\n",
      "[91]\tvalid_0's tweedie: 470.853\n",
      "[92]\tvalid_0's tweedie: 470.853\n",
      "[93]\tvalid_0's tweedie: 470.853\n",
      "[94]\tvalid_0's tweedie: 470.852\n",
      "[95]\tvalid_0's tweedie: 470.852\n",
      "[96]\tvalid_0's tweedie: 470.851\n",
      "[97]\tvalid_0's tweedie: 470.851\n",
      "[98]\tvalid_0's tweedie: 470.85\n",
      "[99]\tvalid_0's tweedie: 470.851\n",
      "[100]\tvalid_0's tweedie: 470.849\n",
      "[101]\tvalid_0's tweedie: 470.85\n",
      "[102]\tvalid_0's tweedie: 470.85\n",
      "[103]\tvalid_0's tweedie: 470.85\n",
      "[104]\tvalid_0's tweedie: 470.849\n",
      "[105]\tvalid_0's tweedie: 470.849\n",
      "[106]\tvalid_0's tweedie: 470.85\n",
      "[107]\tvalid_0's tweedie: 470.85\n",
      "[108]\tvalid_0's tweedie: 470.85\n",
      "[109]\tvalid_0's tweedie: 470.85\n",
      "[110]\tvalid_0's tweedie: 470.85\n",
      "[111]\tvalid_0's tweedie: 470.85\n",
      "[112]\tvalid_0's tweedie: 470.849\n",
      "[113]\tvalid_0's tweedie: 470.849\n",
      "[114]\tvalid_0's tweedie: 470.852\n",
      "[115]\tvalid_0's tweedie: 470.851\n",
      "[116]\tvalid_0's tweedie: 470.85\n",
      "[117]\tvalid_0's tweedie: 470.849\n",
      "[118]\tvalid_0's tweedie: 470.849\n",
      "[119]\tvalid_0's tweedie: 470.849\n",
      "[120]\tvalid_0's tweedie: 470.849\n",
      "[121]\tvalid_0's tweedie: 470.849\n",
      "[122]\tvalid_0's tweedie: 470.848\n",
      "[123]\tvalid_0's tweedie: 470.848\n",
      "[124]\tvalid_0's tweedie: 470.848\n",
      "[125]\tvalid_0's tweedie: 470.846\n",
      "[126]\tvalid_0's tweedie: 470.846\n",
      "[127]\tvalid_0's tweedie: 470.846\n",
      "[128]\tvalid_0's tweedie: 470.848\n",
      "[129]\tvalid_0's tweedie: 470.848\n",
      "[130]\tvalid_0's tweedie: 470.848\n",
      "[131]\tvalid_0's tweedie: 470.846\n",
      "[132]\tvalid_0's tweedie: 470.846\n",
      "[133]\tvalid_0's tweedie: 470.846\n",
      "[134]\tvalid_0's tweedie: 470.846\n",
      "[135]\tvalid_0's tweedie: 470.846\n",
      "[136]\tvalid_0's tweedie: 470.845\n",
      "[137]\tvalid_0's tweedie: 470.845\n",
      "[138]\tvalid_0's tweedie: 470.846\n",
      "[139]\tvalid_0's tweedie: 470.846\n",
      "[140]\tvalid_0's tweedie: 470.848\n",
      "[141]\tvalid_0's tweedie: 470.848\n",
      "[142]\tvalid_0's tweedie: 470.848\n",
      "[143]\tvalid_0's tweedie: 470.847\n",
      "[144]\tvalid_0's tweedie: 470.848\n",
      "[145]\tvalid_0's tweedie: 470.847\n",
      "[146]\tvalid_0's tweedie: 470.847\n",
      "[147]\tvalid_0's tweedie: 470.846\n",
      "[148]\tvalid_0's tweedie: 470.847\n",
      "[149]\tvalid_0's tweedie: 470.847\n",
      "[150]\tvalid_0's tweedie: 470.848\n",
      "[151]\tvalid_0's tweedie: 470.849\n",
      "[152]\tvalid_0's tweedie: 470.85\n",
      "[153]\tvalid_0's tweedie: 470.85\n",
      "[154]\tvalid_0's tweedie: 470.85\n",
      "[155]\tvalid_0's tweedie: 470.849\n",
      "[156]\tvalid_0's tweedie: 470.848\n",
      "[157]\tvalid_0's tweedie: 470.847\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's tweedie: 470.845\n",
      "Training model for level 2 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5487\n",
      "[LightGBM] [Info] Number of data points in the train set: 5547, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346704\n",
      "[1]\tvalid_0's tweedie: 476.267\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.397\n",
      "[3]\tvalid_0's tweedie: 474.66\n",
      "[4]\tvalid_0's tweedie: 474.081\n",
      "[5]\tvalid_0's tweedie: 473.599\n",
      "[6]\tvalid_0's tweedie: 473.175\n",
      "[7]\tvalid_0's tweedie: 472.864\n",
      "[8]\tvalid_0's tweedie: 472.598\n",
      "[9]\tvalid_0's tweedie: 472.363\n",
      "[10]\tvalid_0's tweedie: 472.182\n",
      "[11]\tvalid_0's tweedie: 472.002\n",
      "[12]\tvalid_0's tweedie: 471.855\n",
      "[13]\tvalid_0's tweedie: 471.733\n",
      "[14]\tvalid_0's tweedie: 471.632\n",
      "[15]\tvalid_0's tweedie: 471.535\n",
      "[16]\tvalid_0's tweedie: 471.478\n",
      "[17]\tvalid_0's tweedie: 471.418\n",
      "[18]\tvalid_0's tweedie: 471.355\n",
      "[19]\tvalid_0's tweedie: 471.3\n",
      "[20]\tvalid_0's tweedie: 471.26\n",
      "[21]\tvalid_0's tweedie: 471.218\n",
      "[22]\tvalid_0's tweedie: 471.188\n",
      "[23]\tvalid_0's tweedie: 471.164\n",
      "[24]\tvalid_0's tweedie: 471.138\n",
      "[25]\tvalid_0's tweedie: 471.112\n",
      "[26]\tvalid_0's tweedie: 471.09\n",
      "[27]\tvalid_0's tweedie: 471.071\n",
      "[28]\tvalid_0's tweedie: 471.052\n",
      "[29]\tvalid_0's tweedie: 471.038\n",
      "[30]\tvalid_0's tweedie: 471.022\n",
      "[31]\tvalid_0's tweedie: 471.01\n",
      "[32]\tvalid_0's tweedie: 471.001\n",
      "[33]\tvalid_0's tweedie: 470.985\n",
      "[34]\tvalid_0's tweedie: 470.976\n",
      "[35]\tvalid_0's tweedie: 470.97\n",
      "[36]\tvalid_0's tweedie: 470.962\n",
      "[37]\tvalid_0's tweedie: 470.954\n",
      "[38]\tvalid_0's tweedie: 470.947\n",
      "[39]\tvalid_0's tweedie: 470.939\n",
      "[40]\tvalid_0's tweedie: 470.93\n",
      "[41]\tvalid_0's tweedie: 470.927\n",
      "[42]\tvalid_0's tweedie: 470.92\n",
      "[43]\tvalid_0's tweedie: 470.913\n",
      "[44]\tvalid_0's tweedie: 470.91\n",
      "[45]\tvalid_0's tweedie: 470.909\n",
      "[46]\tvalid_0's tweedie: 470.907\n",
      "[47]\tvalid_0's tweedie: 470.904\n",
      "[48]\tvalid_0's tweedie: 470.907\n",
      "[49]\tvalid_0's tweedie: 470.901\n",
      "[50]\tvalid_0's tweedie: 470.9\n",
      "[51]\tvalid_0's tweedie: 470.896\n",
      "[52]\tvalid_0's tweedie: 470.895\n",
      "[53]\tvalid_0's tweedie: 470.893\n",
      "[54]\tvalid_0's tweedie: 470.891\n",
      "[55]\tvalid_0's tweedie: 470.889\n",
      "[56]\tvalid_0's tweedie: 470.886\n",
      "[57]\tvalid_0's tweedie: 470.886\n",
      "[58]\tvalid_0's tweedie: 470.885\n",
      "[59]\tvalid_0's tweedie: 470.887\n",
      "[60]\tvalid_0's tweedie: 470.882\n",
      "[61]\tvalid_0's tweedie: 470.881\n",
      "[62]\tvalid_0's tweedie: 470.879\n",
      "[63]\tvalid_0's tweedie: 470.879\n",
      "[64]\tvalid_0's tweedie: 470.876\n",
      "[65]\tvalid_0's tweedie: 470.876\n",
      "[66]\tvalid_0's tweedie: 470.875\n",
      "[67]\tvalid_0's tweedie: 470.873\n",
      "[68]\tvalid_0's tweedie: 470.871\n",
      "[69]\tvalid_0's tweedie: 470.87\n",
      "[70]\tvalid_0's tweedie: 470.869\n",
      "[71]\tvalid_0's tweedie: 470.868\n",
      "[72]\tvalid_0's tweedie: 470.868\n",
      "[73]\tvalid_0's tweedie: 470.866\n",
      "[74]\tvalid_0's tweedie: 470.866\n",
      "[75]\tvalid_0's tweedie: 470.866\n",
      "[76]\tvalid_0's tweedie: 470.866\n",
      "[77]\tvalid_0's tweedie: 470.864\n",
      "[78]\tvalid_0's tweedie: 470.864\n",
      "[79]\tvalid_0's tweedie: 470.862\n",
      "[80]\tvalid_0's tweedie: 470.861\n",
      "[81]\tvalid_0's tweedie: 470.865\n",
      "[82]\tvalid_0's tweedie: 470.864\n",
      "[83]\tvalid_0's tweedie: 470.863\n",
      "[84]\tvalid_0's tweedie: 470.863\n",
      "[85]\tvalid_0's tweedie: 470.862\n",
      "[86]\tvalid_0's tweedie: 470.86\n",
      "[87]\tvalid_0's tweedie: 470.86\n",
      "[88]\tvalid_0's tweedie: 470.86\n",
      "[89]\tvalid_0's tweedie: 470.857\n",
      "[90]\tvalid_0's tweedie: 470.856\n",
      "[91]\tvalid_0's tweedie: 470.857\n",
      "[92]\tvalid_0's tweedie: 470.857\n",
      "[93]\tvalid_0's tweedie: 470.857\n",
      "[94]\tvalid_0's tweedie: 470.857\n",
      "[95]\tvalid_0's tweedie: 470.858\n",
      "[96]\tvalid_0's tweedie: 470.857\n",
      "[97]\tvalid_0's tweedie: 470.857\n",
      "[98]\tvalid_0's tweedie: 470.857\n",
      "[99]\tvalid_0's tweedie: 470.861\n",
      "[100]\tvalid_0's tweedie: 470.861\n",
      "[101]\tvalid_0's tweedie: 470.861\n",
      "[102]\tvalid_0's tweedie: 470.861\n",
      "[103]\tvalid_0's tweedie: 470.86\n",
      "[104]\tvalid_0's tweedie: 470.858\n",
      "[105]\tvalid_0's tweedie: 470.858\n",
      "[106]\tvalid_0's tweedie: 470.857\n",
      "[107]\tvalid_0's tweedie: 470.857\n",
      "[108]\tvalid_0's tweedie: 470.858\n",
      "[109]\tvalid_0's tweedie: 470.858\n",
      "[110]\tvalid_0's tweedie: 470.857\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's tweedie: 470.856\n",
      "Training model for level 2 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5486\n",
      "[LightGBM] [Info] Number of data points in the train set: 5544, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346696\n",
      "[1]\tvalid_0's tweedie: 476.269\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.402\n",
      "[3]\tvalid_0's tweedie: 474.661\n",
      "[4]\tvalid_0's tweedie: 474.058\n",
      "[5]\tvalid_0's tweedie: 473.589\n",
      "[6]\tvalid_0's tweedie: 473.191\n",
      "[7]\tvalid_0's tweedie: 472.853\n",
      "[8]\tvalid_0's tweedie: 472.56\n",
      "[9]\tvalid_0's tweedie: 472.341\n",
      "[10]\tvalid_0's tweedie: 472.129\n",
      "[11]\tvalid_0's tweedie: 471.963\n",
      "[12]\tvalid_0's tweedie: 471.804\n",
      "[13]\tvalid_0's tweedie: 471.682\n",
      "[14]\tvalid_0's tweedie: 471.596\n",
      "[15]\tvalid_0's tweedie: 471.507\n",
      "[16]\tvalid_0's tweedie: 471.425\n",
      "[17]\tvalid_0's tweedie: 471.365\n",
      "[18]\tvalid_0's tweedie: 471.31\n",
      "[19]\tvalid_0's tweedie: 471.263\n",
      "[20]\tvalid_0's tweedie: 471.223\n",
      "[21]\tvalid_0's tweedie: 471.181\n",
      "[22]\tvalid_0's tweedie: 471.152\n",
      "[23]\tvalid_0's tweedie: 471.121\n",
      "[24]\tvalid_0's tweedie: 471.095\n",
      "[25]\tvalid_0's tweedie: 471.069\n",
      "[26]\tvalid_0's tweedie: 471.063\n",
      "[27]\tvalid_0's tweedie: 471.047\n",
      "[28]\tvalid_0's tweedie: 471.042\n",
      "[29]\tvalid_0's tweedie: 471.029\n",
      "[30]\tvalid_0's tweedie: 471.024\n",
      "[31]\tvalid_0's tweedie: 471.025\n",
      "[32]\tvalid_0's tweedie: 471.013\n",
      "[33]\tvalid_0's tweedie: 471.002\n",
      "[34]\tvalid_0's tweedie: 470.992\n",
      "[35]\tvalid_0's tweedie: 470.982\n",
      "[36]\tvalid_0's tweedie: 470.98\n",
      "[37]\tvalid_0's tweedie: 470.975\n",
      "[38]\tvalid_0's tweedie: 470.971\n",
      "[39]\tvalid_0's tweedie: 470.957\n",
      "[40]\tvalid_0's tweedie: 470.945\n",
      "[41]\tvalid_0's tweedie: 470.944\n",
      "[42]\tvalid_0's tweedie: 470.939\n",
      "[43]\tvalid_0's tweedie: 470.934\n",
      "[44]\tvalid_0's tweedie: 470.927\n",
      "[45]\tvalid_0's tweedie: 470.923\n",
      "[46]\tvalid_0's tweedie: 470.922\n",
      "[47]\tvalid_0's tweedie: 470.914\n",
      "[48]\tvalid_0's tweedie: 470.911\n",
      "[49]\tvalid_0's tweedie: 470.905\n",
      "[50]\tvalid_0's tweedie: 470.902\n",
      "[51]\tvalid_0's tweedie: 470.899\n",
      "[52]\tvalid_0's tweedie: 470.896\n",
      "[53]\tvalid_0's tweedie: 470.895\n",
      "[54]\tvalid_0's tweedie: 470.893\n",
      "[55]\tvalid_0's tweedie: 470.893\n",
      "[56]\tvalid_0's tweedie: 470.894\n",
      "[57]\tvalid_0's tweedie: 470.892\n",
      "[58]\tvalid_0's tweedie: 470.89\n",
      "[59]\tvalid_0's tweedie: 470.891\n",
      "[60]\tvalid_0's tweedie: 470.889\n",
      "[61]\tvalid_0's tweedie: 470.889\n",
      "[62]\tvalid_0's tweedie: 470.885\n",
      "[63]\tvalid_0's tweedie: 470.883\n",
      "[64]\tvalid_0's tweedie: 470.881\n",
      "[65]\tvalid_0's tweedie: 470.881\n",
      "[66]\tvalid_0's tweedie: 470.88\n",
      "[67]\tvalid_0's tweedie: 470.877\n",
      "[68]\tvalid_0's tweedie: 470.875\n",
      "[69]\tvalid_0's tweedie: 470.88\n",
      "[70]\tvalid_0's tweedie: 470.876\n",
      "[71]\tvalid_0's tweedie: 470.875\n",
      "[72]\tvalid_0's tweedie: 470.875\n",
      "[73]\tvalid_0's tweedie: 470.875\n",
      "[74]\tvalid_0's tweedie: 470.875\n",
      "[75]\tvalid_0's tweedie: 470.874\n",
      "[76]\tvalid_0's tweedie: 470.874\n",
      "[77]\tvalid_0's tweedie: 470.873\n",
      "[78]\tvalid_0's tweedie: 470.873\n",
      "[79]\tvalid_0's tweedie: 470.87\n",
      "[80]\tvalid_0's tweedie: 470.868\n",
      "[81]\tvalid_0's tweedie: 470.868\n",
      "[82]\tvalid_0's tweedie: 470.864\n",
      "[83]\tvalid_0's tweedie: 470.869\n",
      "[84]\tvalid_0's tweedie: 470.869\n",
      "[85]\tvalid_0's tweedie: 470.869\n",
      "[86]\tvalid_0's tweedie: 470.869\n",
      "[87]\tvalid_0's tweedie: 470.868\n",
      "[88]\tvalid_0's tweedie: 470.867\n",
      "[89]\tvalid_0's tweedie: 470.866\n",
      "[90]\tvalid_0's tweedie: 470.866\n",
      "[91]\tvalid_0's tweedie: 470.865\n",
      "[92]\tvalid_0's tweedie: 470.865\n",
      "[93]\tvalid_0's tweedie: 470.864\n",
      "[94]\tvalid_0's tweedie: 470.864\n",
      "[95]\tvalid_0's tweedie: 470.863\n",
      "[96]\tvalid_0's tweedie: 470.864\n",
      "[97]\tvalid_0's tweedie: 470.863\n",
      "[98]\tvalid_0's tweedie: 470.863\n",
      "[99]\tvalid_0's tweedie: 470.863\n",
      "[100]\tvalid_0's tweedie: 470.863\n",
      "[101]\tvalid_0's tweedie: 470.86\n",
      "[102]\tvalid_0's tweedie: 470.86\n",
      "[103]\tvalid_0's tweedie: 470.861\n",
      "[104]\tvalid_0's tweedie: 470.859\n",
      "[105]\tvalid_0's tweedie: 470.859\n",
      "[106]\tvalid_0's tweedie: 470.86\n",
      "[107]\tvalid_0's tweedie: 470.858\n",
      "[108]\tvalid_0's tweedie: 470.857\n",
      "[109]\tvalid_0's tweedie: 470.857\n",
      "[110]\tvalid_0's tweedie: 470.856\n",
      "[111]\tvalid_0's tweedie: 470.854\n",
      "[112]\tvalid_0's tweedie: 470.854\n",
      "[113]\tvalid_0's tweedie: 470.853\n",
      "[114]\tvalid_0's tweedie: 470.853\n",
      "[115]\tvalid_0's tweedie: 470.853\n",
      "[116]\tvalid_0's tweedie: 470.852\n",
      "[117]\tvalid_0's tweedie: 470.851\n",
      "[118]\tvalid_0's tweedie: 470.851\n",
      "[119]\tvalid_0's tweedie: 470.851\n",
      "[120]\tvalid_0's tweedie: 470.852\n",
      "[121]\tvalid_0's tweedie: 470.851\n",
      "[122]\tvalid_0's tweedie: 470.851\n",
      "[123]\tvalid_0's tweedie: 470.852\n",
      "[124]\tvalid_0's tweedie: 470.852\n",
      "[125]\tvalid_0's tweedie: 470.851\n",
      "[126]\tvalid_0's tweedie: 470.852\n",
      "[127]\tvalid_0's tweedie: 470.852\n",
      "[128]\tvalid_0's tweedie: 470.852\n",
      "[129]\tvalid_0's tweedie: 470.852\n",
      "[130]\tvalid_0's tweedie: 470.852\n",
      "[131]\tvalid_0's tweedie: 470.852\n",
      "[132]\tvalid_0's tweedie: 470.852\n",
      "[133]\tvalid_0's tweedie: 470.851\n",
      "[134]\tvalid_0's tweedie: 470.851\n",
      "[135]\tvalid_0's tweedie: 470.85\n",
      "[136]\tvalid_0's tweedie: 470.85\n",
      "[137]\tvalid_0's tweedie: 470.85\n",
      "[138]\tvalid_0's tweedie: 470.85\n",
      "[139]\tvalid_0's tweedie: 470.848\n",
      "[140]\tvalid_0's tweedie: 470.848\n",
      "[141]\tvalid_0's tweedie: 470.848\n",
      "[142]\tvalid_0's tweedie: 470.849\n",
      "[143]\tvalid_0's tweedie: 470.848\n",
      "[144]\tvalid_0's tweedie: 470.848\n",
      "[145]\tvalid_0's tweedie: 470.847\n",
      "[146]\tvalid_0's tweedie: 470.848\n",
      "[147]\tvalid_0's tweedie: 470.846\n",
      "[148]\tvalid_0's tweedie: 470.847\n",
      "[149]\tvalid_0's tweedie: 470.846\n",
      "[150]\tvalid_0's tweedie: 470.845\n",
      "[151]\tvalid_0's tweedie: 470.846\n",
      "[152]\tvalid_0's tweedie: 470.846\n",
      "[153]\tvalid_0's tweedie: 470.846\n",
      "[154]\tvalid_0's tweedie: 470.846\n",
      "[155]\tvalid_0's tweedie: 470.846\n",
      "[156]\tvalid_0's tweedie: 470.846\n",
      "[157]\tvalid_0's tweedie: 470.847\n",
      "[158]\tvalid_0's tweedie: 470.847\n",
      "[159]\tvalid_0's tweedie: 470.847\n",
      "[160]\tvalid_0's tweedie: 470.847\n",
      "[161]\tvalid_0's tweedie: 470.846\n",
      "[162]\tvalid_0's tweedie: 470.845\n",
      "[163]\tvalid_0's tweedie: 470.845\n",
      "[164]\tvalid_0's tweedie: 470.845\n",
      "[165]\tvalid_0's tweedie: 470.845\n",
      "[166]\tvalid_0's tweedie: 470.845\n",
      "[167]\tvalid_0's tweedie: 470.845\n",
      "[168]\tvalid_0's tweedie: 470.844\n",
      "[169]\tvalid_0's tweedie: 470.844\n",
      "[170]\tvalid_0's tweedie: 470.844\n",
      "[171]\tvalid_0's tweedie: 470.843\n",
      "[172]\tvalid_0's tweedie: 470.843\n",
      "[173]\tvalid_0's tweedie: 470.843\n",
      "[174]\tvalid_0's tweedie: 470.844\n",
      "[175]\tvalid_0's tweedie: 470.844\n",
      "[176]\tvalid_0's tweedie: 470.844\n",
      "[177]\tvalid_0's tweedie: 470.844\n",
      "[178]\tvalid_0's tweedie: 470.843\n",
      "[179]\tvalid_0's tweedie: 470.842\n",
      "[180]\tvalid_0's tweedie: 470.843\n",
      "[181]\tvalid_0's tweedie: 470.842\n",
      "[182]\tvalid_0's tweedie: 470.842\n",
      "[183]\tvalid_0's tweedie: 470.841\n",
      "[184]\tvalid_0's tweedie: 470.841\n",
      "[185]\tvalid_0's tweedie: 470.842\n",
      "[186]\tvalid_0's tweedie: 470.841\n",
      "[187]\tvalid_0's tweedie: 470.841\n",
      "[188]\tvalid_0's tweedie: 470.84\n",
      "[189]\tvalid_0's tweedie: 470.84\n",
      "[190]\tvalid_0's tweedie: 470.839\n",
      "[191]\tvalid_0's tweedie: 470.839\n",
      "[192]\tvalid_0's tweedie: 470.839\n",
      "[193]\tvalid_0's tweedie: 470.839\n",
      "[194]\tvalid_0's tweedie: 470.838\n",
      "[195]\tvalid_0's tweedie: 470.838\n",
      "[196]\tvalid_0's tweedie: 470.837\n",
      "[197]\tvalid_0's tweedie: 470.838\n",
      "[198]\tvalid_0's tweedie: 470.838\n",
      "[199]\tvalid_0's tweedie: 470.838\n",
      "[200]\tvalid_0's tweedie: 470.838\n",
      "[201]\tvalid_0's tweedie: 470.838\n",
      "[202]\tvalid_0's tweedie: 470.837\n",
      "[203]\tvalid_0's tweedie: 470.837\n",
      "[204]\tvalid_0's tweedie: 470.837\n",
      "[205]\tvalid_0's tweedie: 470.837\n",
      "[206]\tvalid_0's tweedie: 470.839\n",
      "[207]\tvalid_0's tweedie: 470.838\n",
      "[208]\tvalid_0's tweedie: 470.837\n",
      "[209]\tvalid_0's tweedie: 470.836\n",
      "[210]\tvalid_0's tweedie: 470.836\n",
      "[211]\tvalid_0's tweedie: 470.836\n",
      "[212]\tvalid_0's tweedie: 470.836\n",
      "[213]\tvalid_0's tweedie: 470.837\n",
      "[214]\tvalid_0's tweedie: 470.837\n",
      "[215]\tvalid_0's tweedie: 470.837\n",
      "[216]\tvalid_0's tweedie: 470.837\n",
      "[217]\tvalid_0's tweedie: 470.838\n",
      "[218]\tvalid_0's tweedie: 470.837\n",
      "[219]\tvalid_0's tweedie: 470.838\n",
      "[220]\tvalid_0's tweedie: 470.838\n",
      "[221]\tvalid_0's tweedie: 470.838\n",
      "[222]\tvalid_0's tweedie: 470.839\n",
      "[223]\tvalid_0's tweedie: 470.838\n",
      "[224]\tvalid_0's tweedie: 470.838\n",
      "[225]\tvalid_0's tweedie: 470.839\n",
      "[226]\tvalid_0's tweedie: 470.838\n",
      "[227]\tvalid_0's tweedie: 470.839\n",
      "[228]\tvalid_0's tweedie: 470.84\n",
      "[229]\tvalid_0's tweedie: 470.839\n",
      "[230]\tvalid_0's tweedie: 470.839\n",
      "[231]\tvalid_0's tweedie: 470.839\n",
      "[232]\tvalid_0's tweedie: 470.839\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's tweedie: 470.836\n",
      "Training model for level 2 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5485\n",
      "[LightGBM] [Info] Number of data points in the train set: 5541, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346851\n",
      "[1]\tvalid_0's tweedie: 476.288\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.413\n",
      "[3]\tvalid_0's tweedie: 474.698\n",
      "[4]\tvalid_0's tweedie: 474.101\n",
      "[5]\tvalid_0's tweedie: 473.635\n",
      "[6]\tvalid_0's tweedie: 473.221\n",
      "[7]\tvalid_0's tweedie: 472.865\n",
      "[8]\tvalid_0's tweedie: 472.571\n",
      "[9]\tvalid_0's tweedie: 472.338\n",
      "[10]\tvalid_0's tweedie: 472.163\n",
      "[11]\tvalid_0's tweedie: 471.997\n",
      "[12]\tvalid_0's tweedie: 471.845\n",
      "[13]\tvalid_0's tweedie: 471.718\n",
      "[14]\tvalid_0's tweedie: 471.617\n",
      "[15]\tvalid_0's tweedie: 471.521\n",
      "[16]\tvalid_0's tweedie: 471.438\n",
      "[17]\tvalid_0's tweedie: 471.362\n",
      "[18]\tvalid_0's tweedie: 471.313\n",
      "[19]\tvalid_0's tweedie: 471.274\n",
      "[20]\tvalid_0's tweedie: 471.226\n",
      "[21]\tvalid_0's tweedie: 471.184\n",
      "[22]\tvalid_0's tweedie: 471.154\n",
      "[23]\tvalid_0's tweedie: 471.124\n",
      "[24]\tvalid_0's tweedie: 471.109\n",
      "[25]\tvalid_0's tweedie: 471.098\n",
      "[26]\tvalid_0's tweedie: 471.068\n",
      "[27]\tvalid_0's tweedie: 471.049\n",
      "[28]\tvalid_0's tweedie: 471.034\n",
      "[29]\tvalid_0's tweedie: 471.02\n",
      "[30]\tvalid_0's tweedie: 471.007\n",
      "[31]\tvalid_0's tweedie: 470.995\n",
      "[32]\tvalid_0's tweedie: 470.98\n",
      "[33]\tvalid_0's tweedie: 470.97\n",
      "[34]\tvalid_0's tweedie: 470.958\n",
      "[35]\tvalid_0's tweedie: 470.953\n",
      "[36]\tvalid_0's tweedie: 470.946\n",
      "[37]\tvalid_0's tweedie: 470.938\n",
      "[38]\tvalid_0's tweedie: 470.933\n",
      "[39]\tvalid_0's tweedie: 470.929\n",
      "[40]\tvalid_0's tweedie: 470.924\n",
      "[41]\tvalid_0's tweedie: 470.915\n",
      "[42]\tvalid_0's tweedie: 470.909\n",
      "[43]\tvalid_0's tweedie: 470.906\n",
      "[44]\tvalid_0's tweedie: 470.902\n",
      "[45]\tvalid_0's tweedie: 470.898\n",
      "[46]\tvalid_0's tweedie: 470.893\n",
      "[47]\tvalid_0's tweedie: 470.89\n",
      "[48]\tvalid_0's tweedie: 470.887\n",
      "[49]\tvalid_0's tweedie: 470.887\n",
      "[50]\tvalid_0's tweedie: 470.885\n",
      "[51]\tvalid_0's tweedie: 470.884\n",
      "[52]\tvalid_0's tweedie: 470.883\n",
      "[53]\tvalid_0's tweedie: 470.882\n",
      "[54]\tvalid_0's tweedie: 470.879\n",
      "[55]\tvalid_0's tweedie: 470.878\n",
      "[56]\tvalid_0's tweedie: 470.876\n",
      "[57]\tvalid_0's tweedie: 470.875\n",
      "[58]\tvalid_0's tweedie: 470.873\n",
      "[59]\tvalid_0's tweedie: 470.872\n",
      "[60]\tvalid_0's tweedie: 470.877\n",
      "[61]\tvalid_0's tweedie: 470.872\n",
      "[62]\tvalid_0's tweedie: 470.872\n",
      "[63]\tvalid_0's tweedie: 470.872\n",
      "[64]\tvalid_0's tweedie: 470.871\n",
      "[65]\tvalid_0's tweedie: 470.87\n",
      "[66]\tvalid_0's tweedie: 470.87\n",
      "[67]\tvalid_0's tweedie: 470.864\n",
      "[68]\tvalid_0's tweedie: 470.864\n",
      "[69]\tvalid_0's tweedie: 470.864\n",
      "[70]\tvalid_0's tweedie: 470.863\n",
      "[71]\tvalid_0's tweedie: 470.861\n",
      "[72]\tvalid_0's tweedie: 470.861\n",
      "[73]\tvalid_0's tweedie: 470.86\n",
      "[74]\tvalid_0's tweedie: 470.859\n",
      "[75]\tvalid_0's tweedie: 470.86\n",
      "[76]\tvalid_0's tweedie: 470.858\n",
      "[77]\tvalid_0's tweedie: 470.857\n",
      "[78]\tvalid_0's tweedie: 470.858\n",
      "[79]\tvalid_0's tweedie: 470.858\n",
      "[80]\tvalid_0's tweedie: 470.854\n",
      "[81]\tvalid_0's tweedie: 470.855\n",
      "[82]\tvalid_0's tweedie: 470.852\n",
      "[83]\tvalid_0's tweedie: 470.852\n",
      "[84]\tvalid_0's tweedie: 470.851\n",
      "[85]\tvalid_0's tweedie: 470.851\n",
      "[86]\tvalid_0's tweedie: 470.85\n",
      "[87]\tvalid_0's tweedie: 470.848\n",
      "[88]\tvalid_0's tweedie: 470.848\n",
      "[89]\tvalid_0's tweedie: 470.847\n",
      "[90]\tvalid_0's tweedie: 470.847\n",
      "[91]\tvalid_0's tweedie: 470.845\n",
      "[92]\tvalid_0's tweedie: 470.844\n",
      "[93]\tvalid_0's tweedie: 470.842\n",
      "[94]\tvalid_0's tweedie: 470.839\n",
      "[95]\tvalid_0's tweedie: 470.838\n",
      "[96]\tvalid_0's tweedie: 470.838\n",
      "[97]\tvalid_0's tweedie: 470.838\n",
      "[98]\tvalid_0's tweedie: 470.837\n",
      "[99]\tvalid_0's tweedie: 470.837\n",
      "[100]\tvalid_0's tweedie: 470.837\n",
      "[101]\tvalid_0's tweedie: 470.837\n",
      "[102]\tvalid_0's tweedie: 470.837\n",
      "[103]\tvalid_0's tweedie: 470.838\n",
      "[104]\tvalid_0's tweedie: 470.838\n",
      "[105]\tvalid_0's tweedie: 470.836\n",
      "[106]\tvalid_0's tweedie: 470.836\n",
      "[107]\tvalid_0's tweedie: 470.835\n",
      "[108]\tvalid_0's tweedie: 470.835\n",
      "[109]\tvalid_0's tweedie: 470.835\n",
      "[110]\tvalid_0's tweedie: 470.835\n",
      "[111]\tvalid_0's tweedie: 470.834\n",
      "[112]\tvalid_0's tweedie: 470.834\n",
      "[113]\tvalid_0's tweedie: 470.834\n",
      "[114]\tvalid_0's tweedie: 470.834\n",
      "[115]\tvalid_0's tweedie: 470.831\n",
      "[116]\tvalid_0's tweedie: 470.83\n",
      "[117]\tvalid_0's tweedie: 470.827\n",
      "[118]\tvalid_0's tweedie: 470.827\n",
      "[119]\tvalid_0's tweedie: 470.827\n",
      "[120]\tvalid_0's tweedie: 470.827\n",
      "[121]\tvalid_0's tweedie: 470.827\n",
      "[122]\tvalid_0's tweedie: 470.827\n",
      "[123]\tvalid_0's tweedie: 470.826\n",
      "[124]\tvalid_0's tweedie: 470.826\n",
      "[125]\tvalid_0's tweedie: 470.825\n",
      "[126]\tvalid_0's tweedie: 470.825\n",
      "[127]\tvalid_0's tweedie: 470.825\n",
      "[128]\tvalid_0's tweedie: 470.824\n",
      "[129]\tvalid_0's tweedie: 470.824\n",
      "[130]\tvalid_0's tweedie: 470.824\n",
      "[131]\tvalid_0's tweedie: 470.824\n",
      "[132]\tvalid_0's tweedie: 470.823\n",
      "[133]\tvalid_0's tweedie: 470.823\n",
      "[134]\tvalid_0's tweedie: 470.823\n",
      "[135]\tvalid_0's tweedie: 470.822\n",
      "[136]\tvalid_0's tweedie: 470.823\n",
      "[137]\tvalid_0's tweedie: 470.822\n",
      "[138]\tvalid_0's tweedie: 470.822\n",
      "[139]\tvalid_0's tweedie: 470.822\n",
      "[140]\tvalid_0's tweedie: 470.822\n",
      "[141]\tvalid_0's tweedie: 470.822\n",
      "[142]\tvalid_0's tweedie: 470.822\n",
      "[143]\tvalid_0's tweedie: 470.822\n",
      "[144]\tvalid_0's tweedie: 470.822\n",
      "[145]\tvalid_0's tweedie: 470.821\n",
      "[146]\tvalid_0's tweedie: 470.825\n",
      "[147]\tvalid_0's tweedie: 470.826\n",
      "[148]\tvalid_0's tweedie: 470.828\n",
      "[149]\tvalid_0's tweedie: 470.828\n",
      "[150]\tvalid_0's tweedie: 470.826\n",
      "[151]\tvalid_0's tweedie: 470.826\n",
      "[152]\tvalid_0's tweedie: 470.826\n",
      "[153]\tvalid_0's tweedie: 470.827\n",
      "[154]\tvalid_0's tweedie: 470.827\n",
      "[155]\tvalid_0's tweedie: 470.827\n",
      "[156]\tvalid_0's tweedie: 470.826\n",
      "[157]\tvalid_0's tweedie: 470.826\n",
      "[158]\tvalid_0's tweedie: 470.826\n",
      "[159]\tvalid_0's tweedie: 470.826\n",
      "[160]\tvalid_0's tweedie: 470.826\n",
      "[161]\tvalid_0's tweedie: 470.825\n",
      "[162]\tvalid_0's tweedie: 470.823\n",
      "[163]\tvalid_0's tweedie: 470.823\n",
      "[164]\tvalid_0's tweedie: 470.823\n",
      "[165]\tvalid_0's tweedie: 470.823\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's tweedie: 470.821\n",
      "Training model for level 2 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5484\n",
      "[LightGBM] [Info] Number of data points in the train set: 5538, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347034\n",
      "[1]\tvalid_0's tweedie: 476.28\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.409\n",
      "[3]\tvalid_0's tweedie: 474.672\n",
      "[4]\tvalid_0's tweedie: 474.063\n",
      "[5]\tvalid_0's tweedie: 473.577\n",
      "[6]\tvalid_0's tweedie: 473.201\n",
      "[7]\tvalid_0's tweedie: 472.85\n",
      "[8]\tvalid_0's tweedie: 472.561\n",
      "[9]\tvalid_0's tweedie: 472.342\n",
      "[10]\tvalid_0's tweedie: 472.142\n",
      "[11]\tvalid_0's tweedie: 471.995\n",
      "[12]\tvalid_0's tweedie: 471.841\n",
      "[13]\tvalid_0's tweedie: 471.719\n",
      "[14]\tvalid_0's tweedie: 471.598\n",
      "[15]\tvalid_0's tweedie: 471.52\n",
      "[16]\tvalid_0's tweedie: 471.436\n",
      "[17]\tvalid_0's tweedie: 471.373\n",
      "[18]\tvalid_0's tweedie: 471.317\n",
      "[19]\tvalid_0's tweedie: 471.273\n",
      "[20]\tvalid_0's tweedie: 471.238\n",
      "[21]\tvalid_0's tweedie: 471.196\n",
      "[22]\tvalid_0's tweedie: 471.161\n",
      "[23]\tvalid_0's tweedie: 471.126\n",
      "[24]\tvalid_0's tweedie: 471.112\n",
      "[25]\tvalid_0's tweedie: 471.092\n",
      "[26]\tvalid_0's tweedie: 471.081\n",
      "[27]\tvalid_0's tweedie: 471.076\n",
      "[28]\tvalid_0's tweedie: 471.053\n",
      "[29]\tvalid_0's tweedie: 471.033\n",
      "[30]\tvalid_0's tweedie: 471.022\n",
      "[31]\tvalid_0's tweedie: 471.009\n",
      "[32]\tvalid_0's tweedie: 471.001\n",
      "[33]\tvalid_0's tweedie: 470.989\n",
      "[34]\tvalid_0's tweedie: 470.987\n",
      "[35]\tvalid_0's tweedie: 470.982\n",
      "[36]\tvalid_0's tweedie: 470.971\n",
      "[37]\tvalid_0's tweedie: 470.963\n",
      "[38]\tvalid_0's tweedie: 470.956\n",
      "[39]\tvalid_0's tweedie: 470.946\n",
      "[40]\tvalid_0's tweedie: 470.945\n",
      "[41]\tvalid_0's tweedie: 470.94\n",
      "[42]\tvalid_0's tweedie: 470.931\n",
      "[43]\tvalid_0's tweedie: 470.925\n",
      "[44]\tvalid_0's tweedie: 470.923\n",
      "[45]\tvalid_0's tweedie: 470.922\n",
      "[46]\tvalid_0's tweedie: 470.915\n",
      "[47]\tvalid_0's tweedie: 470.914\n",
      "[48]\tvalid_0's tweedie: 470.912\n",
      "[49]\tvalid_0's tweedie: 470.909\n",
      "[50]\tvalid_0's tweedie: 470.907\n",
      "[51]\tvalid_0's tweedie: 470.904\n",
      "[52]\tvalid_0's tweedie: 470.904\n",
      "[53]\tvalid_0's tweedie: 470.904\n",
      "[54]\tvalid_0's tweedie: 470.904\n",
      "[55]\tvalid_0's tweedie: 470.904\n",
      "[56]\tvalid_0's tweedie: 470.903\n",
      "[57]\tvalid_0's tweedie: 470.901\n",
      "[58]\tvalid_0's tweedie: 470.901\n",
      "[59]\tvalid_0's tweedie: 470.898\n",
      "[60]\tvalid_0's tweedie: 470.896\n",
      "[61]\tvalid_0's tweedie: 470.893\n",
      "[62]\tvalid_0's tweedie: 470.892\n",
      "[63]\tvalid_0's tweedie: 470.892\n",
      "[64]\tvalid_0's tweedie: 470.892\n",
      "[65]\tvalid_0's tweedie: 470.892\n",
      "[66]\tvalid_0's tweedie: 470.89\n",
      "[67]\tvalid_0's tweedie: 470.887\n",
      "[68]\tvalid_0's tweedie: 470.883\n",
      "[69]\tvalid_0's tweedie: 470.883\n",
      "[70]\tvalid_0's tweedie: 470.882\n",
      "[71]\tvalid_0's tweedie: 470.877\n",
      "[72]\tvalid_0's tweedie: 470.872\n",
      "[73]\tvalid_0's tweedie: 470.872\n",
      "[74]\tvalid_0's tweedie: 470.873\n",
      "[75]\tvalid_0's tweedie: 470.872\n",
      "[76]\tvalid_0's tweedie: 470.872\n",
      "[77]\tvalid_0's tweedie: 470.872\n",
      "[78]\tvalid_0's tweedie: 470.872\n",
      "[79]\tvalid_0's tweedie: 470.87\n",
      "[80]\tvalid_0's tweedie: 470.868\n",
      "[81]\tvalid_0's tweedie: 470.864\n",
      "[82]\tvalid_0's tweedie: 470.864\n",
      "[83]\tvalid_0's tweedie: 470.864\n",
      "[84]\tvalid_0's tweedie: 470.864\n",
      "[85]\tvalid_0's tweedie: 470.863\n",
      "[86]\tvalid_0's tweedie: 470.863\n",
      "[87]\tvalid_0's tweedie: 470.865\n",
      "[88]\tvalid_0's tweedie: 470.864\n",
      "[89]\tvalid_0's tweedie: 470.864\n",
      "[90]\tvalid_0's tweedie: 470.863\n",
      "[91]\tvalid_0's tweedie: 470.862\n",
      "[92]\tvalid_0's tweedie: 470.86\n",
      "[93]\tvalid_0's tweedie: 470.86\n",
      "[94]\tvalid_0's tweedie: 470.858\n",
      "[95]\tvalid_0's tweedie: 470.858\n",
      "[96]\tvalid_0's tweedie: 470.859\n",
      "[97]\tvalid_0's tweedie: 470.859\n",
      "[98]\tvalid_0's tweedie: 470.859\n",
      "[99]\tvalid_0's tweedie: 470.859\n",
      "[100]\tvalid_0's tweedie: 470.86\n",
      "[101]\tvalid_0's tweedie: 470.86\n",
      "[102]\tvalid_0's tweedie: 470.859\n",
      "[103]\tvalid_0's tweedie: 470.858\n",
      "[104]\tvalid_0's tweedie: 470.858\n",
      "[105]\tvalid_0's tweedie: 470.858\n",
      "[106]\tvalid_0's tweedie: 470.858\n",
      "[107]\tvalid_0's tweedie: 470.858\n",
      "[108]\tvalid_0's tweedie: 470.858\n",
      "[109]\tvalid_0's tweedie: 470.857\n",
      "[110]\tvalid_0's tweedie: 470.857\n",
      "[111]\tvalid_0's tweedie: 470.857\n",
      "[112]\tvalid_0's tweedie: 470.857\n",
      "[113]\tvalid_0's tweedie: 470.855\n",
      "[114]\tvalid_0's tweedie: 470.856\n",
      "[115]\tvalid_0's tweedie: 470.856\n",
      "[116]\tvalid_0's tweedie: 470.856\n",
      "[117]\tvalid_0's tweedie: 470.856\n",
      "[118]\tvalid_0's tweedie: 470.856\n",
      "[119]\tvalid_0's tweedie: 470.855\n",
      "[120]\tvalid_0's tweedie: 470.855\n",
      "[121]\tvalid_0's tweedie: 470.855\n",
      "[122]\tvalid_0's tweedie: 470.854\n",
      "[123]\tvalid_0's tweedie: 470.854\n",
      "[124]\tvalid_0's tweedie: 470.854\n",
      "[125]\tvalid_0's tweedie: 470.852\n",
      "[126]\tvalid_0's tweedie: 470.851\n",
      "[127]\tvalid_0's tweedie: 470.851\n",
      "[128]\tvalid_0's tweedie: 470.851\n",
      "[129]\tvalid_0's tweedie: 470.85\n",
      "[130]\tvalid_0's tweedie: 470.85\n",
      "[131]\tvalid_0's tweedie: 470.85\n",
      "[132]\tvalid_0's tweedie: 470.851\n",
      "[133]\tvalid_0's tweedie: 470.851\n",
      "[134]\tvalid_0's tweedie: 470.851\n",
      "[135]\tvalid_0's tweedie: 470.848\n",
      "[136]\tvalid_0's tweedie: 470.848\n",
      "[137]\tvalid_0's tweedie: 470.848\n",
      "[138]\tvalid_0's tweedie: 470.847\n",
      "[139]\tvalid_0's tweedie: 470.849\n",
      "[140]\tvalid_0's tweedie: 470.849\n",
      "[141]\tvalid_0's tweedie: 470.848\n",
      "[142]\tvalid_0's tweedie: 470.85\n",
      "[143]\tvalid_0's tweedie: 470.85\n",
      "[144]\tvalid_0's tweedie: 470.85\n",
      "[145]\tvalid_0's tweedie: 470.85\n",
      "[146]\tvalid_0's tweedie: 470.85\n",
      "[147]\tvalid_0's tweedie: 470.85\n",
      "[148]\tvalid_0's tweedie: 470.85\n",
      "[149]\tvalid_0's tweedie: 470.851\n",
      "[150]\tvalid_0's tweedie: 470.852\n",
      "[151]\tvalid_0's tweedie: 470.852\n",
      "[152]\tvalid_0's tweedie: 470.852\n",
      "[153]\tvalid_0's tweedie: 470.851\n",
      "[154]\tvalid_0's tweedie: 470.851\n",
      "[155]\tvalid_0's tweedie: 470.851\n",
      "[156]\tvalid_0's tweedie: 470.85\n",
      "[157]\tvalid_0's tweedie: 470.847\n",
      "[158]\tvalid_0's tweedie: 470.846\n",
      "[159]\tvalid_0's tweedie: 470.847\n",
      "[160]\tvalid_0's tweedie: 470.847\n",
      "[161]\tvalid_0's tweedie: 470.847\n",
      "[162]\tvalid_0's tweedie: 470.847\n",
      "[163]\tvalid_0's tweedie: 470.847\n",
      "[164]\tvalid_0's tweedie: 470.848\n",
      "[165]\tvalid_0's tweedie: 470.848\n",
      "[166]\tvalid_0's tweedie: 470.848\n",
      "[167]\tvalid_0's tweedie: 470.848\n",
      "[168]\tvalid_0's tweedie: 470.848\n",
      "[169]\tvalid_0's tweedie: 470.848\n",
      "[170]\tvalid_0's tweedie: 470.848\n",
      "[171]\tvalid_0's tweedie: 470.848\n",
      "[172]\tvalid_0's tweedie: 470.847\n",
      "[173]\tvalid_0's tweedie: 470.846\n",
      "[174]\tvalid_0's tweedie: 470.846\n",
      "[175]\tvalid_0's tweedie: 470.845\n",
      "[176]\tvalid_0's tweedie: 470.845\n",
      "[177]\tvalid_0's tweedie: 470.845\n",
      "[178]\tvalid_0's tweedie: 470.845\n",
      "[179]\tvalid_0's tweedie: 470.844\n",
      "[180]\tvalid_0's tweedie: 470.844\n",
      "[181]\tvalid_0's tweedie: 470.844\n",
      "[182]\tvalid_0's tweedie: 470.844\n",
      "[183]\tvalid_0's tweedie: 470.845\n",
      "[184]\tvalid_0's tweedie: 470.846\n",
      "[185]\tvalid_0's tweedie: 470.847\n",
      "[186]\tvalid_0's tweedie: 470.847\n",
      "[187]\tvalid_0's tweedie: 470.847\n",
      "[188]\tvalid_0's tweedie: 470.847\n",
      "[189]\tvalid_0's tweedie: 470.847\n",
      "[190]\tvalid_0's tweedie: 470.848\n",
      "[191]\tvalid_0's tweedie: 470.848\n",
      "[192]\tvalid_0's tweedie: 470.848\n",
      "[193]\tvalid_0's tweedie: 470.848\n",
      "[194]\tvalid_0's tweedie: 470.847\n",
      "[195]\tvalid_0's tweedie: 470.847\n",
      "[196]\tvalid_0's tweedie: 470.848\n",
      "[197]\tvalid_0's tweedie: 470.848\n",
      "[198]\tvalid_0's tweedie: 470.848\n",
      "[199]\tvalid_0's tweedie: 470.847\n",
      "[200]\tvalid_0's tweedie: 470.847\n",
      "[201]\tvalid_0's tweedie: 470.847\n",
      "[202]\tvalid_0's tweedie: 470.848\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's tweedie: 470.844\n",
      "Training model for level 2 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5483\n",
      "[LightGBM] [Info] Number of data points in the train set: 5535, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347220\n",
      "[1]\tvalid_0's tweedie: 476.279\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.408\n",
      "[3]\tvalid_0's tweedie: 474.669\n",
      "[4]\tvalid_0's tweedie: 474.07\n",
      "[5]\tvalid_0's tweedie: 473.615\n",
      "[6]\tvalid_0's tweedie: 473.213\n",
      "[7]\tvalid_0's tweedie: 472.873\n",
      "[8]\tvalid_0's tweedie: 472.571\n",
      "[9]\tvalid_0's tweedie: 472.339\n",
      "[10]\tvalid_0's tweedie: 472.159\n",
      "[11]\tvalid_0's tweedie: 471.989\n",
      "[12]\tvalid_0's tweedie: 471.845\n",
      "[13]\tvalid_0's tweedie: 471.714\n",
      "[14]\tvalid_0's tweedie: 471.62\n",
      "[15]\tvalid_0's tweedie: 471.553\n",
      "[16]\tvalid_0's tweedie: 471.472\n",
      "[17]\tvalid_0's tweedie: 471.396\n",
      "[18]\tvalid_0's tweedie: 471.333\n",
      "[19]\tvalid_0's tweedie: 471.286\n",
      "[20]\tvalid_0's tweedie: 471.245\n",
      "[21]\tvalid_0's tweedie: 471.206\n",
      "[22]\tvalid_0's tweedie: 471.175\n",
      "[23]\tvalid_0's tweedie: 471.154\n",
      "[24]\tvalid_0's tweedie: 471.132\n",
      "[25]\tvalid_0's tweedie: 471.12\n",
      "[26]\tvalid_0's tweedie: 471.097\n",
      "[27]\tvalid_0's tweedie: 471.074\n",
      "[28]\tvalid_0's tweedie: 471.059\n",
      "[29]\tvalid_0's tweedie: 471.04\n",
      "[30]\tvalid_0's tweedie: 471.025\n",
      "[31]\tvalid_0's tweedie: 471.011\n",
      "[32]\tvalid_0's tweedie: 470.997\n",
      "[33]\tvalid_0's tweedie: 470.986\n",
      "[34]\tvalid_0's tweedie: 470.979\n",
      "[35]\tvalid_0's tweedie: 470.97\n",
      "[36]\tvalid_0's tweedie: 470.958\n",
      "[37]\tvalid_0's tweedie: 470.952\n",
      "[38]\tvalid_0's tweedie: 470.942\n",
      "[39]\tvalid_0's tweedie: 470.938\n",
      "[40]\tvalid_0's tweedie: 470.933\n",
      "[41]\tvalid_0's tweedie: 470.93\n",
      "[42]\tvalid_0's tweedie: 470.924\n",
      "[43]\tvalid_0's tweedie: 470.92\n",
      "[44]\tvalid_0's tweedie: 470.917\n",
      "[45]\tvalid_0's tweedie: 470.909\n",
      "[46]\tvalid_0's tweedie: 470.907\n",
      "[47]\tvalid_0's tweedie: 470.903\n",
      "[48]\tvalid_0's tweedie: 470.899\n",
      "[49]\tvalid_0's tweedie: 470.899\n",
      "[50]\tvalid_0's tweedie: 470.895\n",
      "[51]\tvalid_0's tweedie: 470.893\n",
      "[52]\tvalid_0's tweedie: 470.889\n",
      "[53]\tvalid_0's tweedie: 470.889\n",
      "[54]\tvalid_0's tweedie: 470.887\n",
      "[55]\tvalid_0's tweedie: 470.885\n",
      "[56]\tvalid_0's tweedie: 470.882\n",
      "[57]\tvalid_0's tweedie: 470.88\n",
      "[58]\tvalid_0's tweedie: 470.876\n",
      "[59]\tvalid_0's tweedie: 470.875\n",
      "[60]\tvalid_0's tweedie: 470.874\n",
      "[61]\tvalid_0's tweedie: 470.873\n",
      "[62]\tvalid_0's tweedie: 470.869\n",
      "[63]\tvalid_0's tweedie: 470.866\n",
      "[64]\tvalid_0's tweedie: 470.866\n",
      "[65]\tvalid_0's tweedie: 470.866\n",
      "[66]\tvalid_0's tweedie: 470.864\n",
      "[67]\tvalid_0's tweedie: 470.857\n",
      "[68]\tvalid_0's tweedie: 470.858\n",
      "[69]\tvalid_0's tweedie: 470.857\n",
      "[70]\tvalid_0's tweedie: 470.856\n",
      "[71]\tvalid_0's tweedie: 470.856\n",
      "[72]\tvalid_0's tweedie: 470.855\n",
      "[73]\tvalid_0's tweedie: 470.855\n",
      "[74]\tvalid_0's tweedie: 470.854\n",
      "[75]\tvalid_0's tweedie: 470.852\n",
      "[76]\tvalid_0's tweedie: 470.85\n",
      "[77]\tvalid_0's tweedie: 470.848\n",
      "[78]\tvalid_0's tweedie: 470.846\n",
      "[79]\tvalid_0's tweedie: 470.846\n",
      "[80]\tvalid_0's tweedie: 470.846\n",
      "[81]\tvalid_0's tweedie: 470.845\n",
      "[82]\tvalid_0's tweedie: 470.844\n",
      "[83]\tvalid_0's tweedie: 470.844\n",
      "[84]\tvalid_0's tweedie: 470.844\n",
      "[85]\tvalid_0's tweedie: 470.843\n",
      "[86]\tvalid_0's tweedie: 470.842\n",
      "[87]\tvalid_0's tweedie: 470.839\n",
      "[88]\tvalid_0's tweedie: 470.839\n",
      "[89]\tvalid_0's tweedie: 470.837\n",
      "[90]\tvalid_0's tweedie: 470.837\n",
      "[91]\tvalid_0's tweedie: 470.836\n",
      "[92]\tvalid_0's tweedie: 470.836\n",
      "[93]\tvalid_0's tweedie: 470.836\n",
      "[94]\tvalid_0's tweedie: 470.84\n",
      "[95]\tvalid_0's tweedie: 470.84\n",
      "[96]\tvalid_0's tweedie: 470.841\n",
      "[97]\tvalid_0's tweedie: 470.84\n",
      "[98]\tvalid_0's tweedie: 470.841\n",
      "[99]\tvalid_0's tweedie: 470.84\n",
      "[100]\tvalid_0's tweedie: 470.84\n",
      "[101]\tvalid_0's tweedie: 470.84\n",
      "[102]\tvalid_0's tweedie: 470.838\n",
      "[103]\tvalid_0's tweedie: 470.838\n",
      "[104]\tvalid_0's tweedie: 470.836\n",
      "[105]\tvalid_0's tweedie: 470.836\n",
      "[106]\tvalid_0's tweedie: 470.836\n",
      "[107]\tvalid_0's tweedie: 470.835\n",
      "[108]\tvalid_0's tweedie: 470.835\n",
      "[109]\tvalid_0's tweedie: 470.835\n",
      "[110]\tvalid_0's tweedie: 470.834\n",
      "[111]\tvalid_0's tweedie: 470.834\n",
      "[112]\tvalid_0's tweedie: 470.833\n",
      "[113]\tvalid_0's tweedie: 470.833\n",
      "[114]\tvalid_0's tweedie: 470.833\n",
      "[115]\tvalid_0's tweedie: 470.833\n",
      "[116]\tvalid_0's tweedie: 470.832\n",
      "[117]\tvalid_0's tweedie: 470.832\n",
      "[118]\tvalid_0's tweedie: 470.831\n",
      "[119]\tvalid_0's tweedie: 470.831\n",
      "[120]\tvalid_0's tweedie: 470.831\n",
      "[121]\tvalid_0's tweedie: 470.831\n",
      "[122]\tvalid_0's tweedie: 470.832\n",
      "[123]\tvalid_0's tweedie: 470.831\n",
      "[124]\tvalid_0's tweedie: 470.829\n",
      "[125]\tvalid_0's tweedie: 470.829\n",
      "[126]\tvalid_0's tweedie: 470.829\n",
      "[127]\tvalid_0's tweedie: 470.828\n",
      "[128]\tvalid_0's tweedie: 470.826\n",
      "[129]\tvalid_0's tweedie: 470.829\n",
      "[130]\tvalid_0's tweedie: 470.829\n",
      "[131]\tvalid_0's tweedie: 470.829\n",
      "[132]\tvalid_0's tweedie: 470.828\n",
      "[133]\tvalid_0's tweedie: 470.829\n",
      "[134]\tvalid_0's tweedie: 470.829\n",
      "[135]\tvalid_0's tweedie: 470.827\n",
      "[136]\tvalid_0's tweedie: 470.826\n",
      "[137]\tvalid_0's tweedie: 470.826\n",
      "[138]\tvalid_0's tweedie: 470.826\n",
      "[139]\tvalid_0's tweedie: 470.825\n",
      "[140]\tvalid_0's tweedie: 470.825\n",
      "[141]\tvalid_0's tweedie: 470.824\n",
      "[142]\tvalid_0's tweedie: 470.824\n",
      "[143]\tvalid_0's tweedie: 470.824\n",
      "[144]\tvalid_0's tweedie: 470.825\n",
      "[145]\tvalid_0's tweedie: 470.825\n",
      "[146]\tvalid_0's tweedie: 470.826\n",
      "[147]\tvalid_0's tweedie: 470.826\n",
      "[148]\tvalid_0's tweedie: 470.825\n",
      "[149]\tvalid_0's tweedie: 470.824\n",
      "[150]\tvalid_0's tweedie: 470.825\n",
      "[151]\tvalid_0's tweedie: 470.825\n",
      "[152]\tvalid_0's tweedie: 470.825\n",
      "[153]\tvalid_0's tweedie: 470.824\n",
      "[154]\tvalid_0's tweedie: 470.825\n",
      "[155]\tvalid_0's tweedie: 470.825\n",
      "[156]\tvalid_0's tweedie: 470.825\n",
      "[157]\tvalid_0's tweedie: 470.824\n",
      "[158]\tvalid_0's tweedie: 470.824\n",
      "[159]\tvalid_0's tweedie: 470.824\n",
      "[160]\tvalid_0's tweedie: 470.824\n",
      "[161]\tvalid_0's tweedie: 470.824\n",
      "[162]\tvalid_0's tweedie: 470.823\n",
      "[163]\tvalid_0's tweedie: 470.821\n",
      "[164]\tvalid_0's tweedie: 470.821\n",
      "[165]\tvalid_0's tweedie: 470.821\n",
      "[166]\tvalid_0's tweedie: 470.821\n",
      "[167]\tvalid_0's tweedie: 470.821\n",
      "[168]\tvalid_0's tweedie: 470.82\n",
      "[169]\tvalid_0's tweedie: 470.821\n",
      "[170]\tvalid_0's tweedie: 470.821\n",
      "[171]\tvalid_0's tweedie: 470.821\n",
      "[172]\tvalid_0's tweedie: 470.82\n",
      "[173]\tvalid_0's tweedie: 470.82\n",
      "[174]\tvalid_0's tweedie: 470.819\n",
      "[175]\tvalid_0's tweedie: 470.819\n",
      "[176]\tvalid_0's tweedie: 470.819\n",
      "[177]\tvalid_0's tweedie: 470.819\n",
      "[178]\tvalid_0's tweedie: 470.819\n",
      "[179]\tvalid_0's tweedie: 470.819\n",
      "[180]\tvalid_0's tweedie: 470.819\n",
      "[181]\tvalid_0's tweedie: 470.819\n",
      "[182]\tvalid_0's tweedie: 470.819\n",
      "[183]\tvalid_0's tweedie: 470.817\n",
      "[184]\tvalid_0's tweedie: 470.817\n",
      "[185]\tvalid_0's tweedie: 470.817\n",
      "[186]\tvalid_0's tweedie: 470.816\n",
      "[187]\tvalid_0's tweedie: 470.816\n",
      "[188]\tvalid_0's tweedie: 470.816\n",
      "[189]\tvalid_0's tweedie: 470.815\n",
      "[190]\tvalid_0's tweedie: 470.814\n",
      "[191]\tvalid_0's tweedie: 470.814\n",
      "[192]\tvalid_0's tweedie: 470.814\n",
      "[193]\tvalid_0's tweedie: 470.814\n",
      "[194]\tvalid_0's tweedie: 470.814\n",
      "[195]\tvalid_0's tweedie: 470.814\n",
      "[196]\tvalid_0's tweedie: 470.814\n",
      "[197]\tvalid_0's tweedie: 470.813\n",
      "[198]\tvalid_0's tweedie: 470.813\n",
      "[199]\tvalid_0's tweedie: 470.813\n",
      "[200]\tvalid_0's tweedie: 470.813\n",
      "[201]\tvalid_0's tweedie: 470.813\n",
      "[202]\tvalid_0's tweedie: 470.811\n",
      "[203]\tvalid_0's tweedie: 470.811\n",
      "[204]\tvalid_0's tweedie: 470.811\n",
      "[205]\tvalid_0's tweedie: 470.812\n",
      "[206]\tvalid_0's tweedie: 470.812\n",
      "[207]\tvalid_0's tweedie: 470.812\n",
      "[208]\tvalid_0's tweedie: 470.812\n",
      "[209]\tvalid_0's tweedie: 470.812\n",
      "[210]\tvalid_0's tweedie: 470.811\n",
      "[211]\tvalid_0's tweedie: 470.811\n",
      "[212]\tvalid_0's tweedie: 470.811\n",
      "[213]\tvalid_0's tweedie: 470.811\n",
      "[214]\tvalid_0's tweedie: 470.811\n",
      "[215]\tvalid_0's tweedie: 470.811\n",
      "[216]\tvalid_0's tweedie: 470.811\n",
      "[217]\tvalid_0's tweedie: 470.811\n",
      "[218]\tvalid_0's tweedie: 470.812\n",
      "[219]\tvalid_0's tweedie: 470.812\n",
      "[220]\tvalid_0's tweedie: 470.812\n",
      "[221]\tvalid_0's tweedie: 470.812\n",
      "[222]\tvalid_0's tweedie: 470.812\n",
      "[223]\tvalid_0's tweedie: 470.812\n",
      "[224]\tvalid_0's tweedie: 470.812\n",
      "[225]\tvalid_0's tweedie: 470.812\n",
      "[226]\tvalid_0's tweedie: 470.812\n",
      "[227]\tvalid_0's tweedie: 470.812\n",
      "[228]\tvalid_0's tweedie: 470.811\n",
      "[229]\tvalid_0's tweedie: 470.811\n",
      "[230]\tvalid_0's tweedie: 470.811\n",
      "[231]\tvalid_0's tweedie: 470.811\n",
      "[232]\tvalid_0's tweedie: 470.812\n",
      "[233]\tvalid_0's tweedie: 470.812\n",
      "[234]\tvalid_0's tweedie: 470.812\n",
      "[235]\tvalid_0's tweedie: 470.812\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's tweedie: 470.811\n",
      "Training model for level 2 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/2/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5482\n",
      "[LightGBM] [Info] Number of data points in the train set: 5532, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347406\n",
      "[1]\tvalid_0's tweedie: 476.28\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 475.407\n",
      "[3]\tvalid_0's tweedie: 474.667\n",
      "[4]\tvalid_0's tweedie: 474.068\n",
      "[5]\tvalid_0's tweedie: 473.614\n",
      "[6]\tvalid_0's tweedie: 473.203\n",
      "[7]\tvalid_0's tweedie: 472.87\n",
      "[8]\tvalid_0's tweedie: 472.604\n",
      "[9]\tvalid_0's tweedie: 472.377\n",
      "[10]\tvalid_0's tweedie: 472.169\n",
      "[11]\tvalid_0's tweedie: 471.996\n",
      "[12]\tvalid_0's tweedie: 471.844\n",
      "[13]\tvalid_0's tweedie: 471.728\n",
      "[14]\tvalid_0's tweedie: 471.613\n",
      "[15]\tvalid_0's tweedie: 471.53\n",
      "[16]\tvalid_0's tweedie: 471.451\n",
      "[17]\tvalid_0's tweedie: 471.381\n",
      "[18]\tvalid_0's tweedie: 471.323\n",
      "[19]\tvalid_0's tweedie: 471.275\n",
      "[20]\tvalid_0's tweedie: 471.224\n",
      "[21]\tvalid_0's tweedie: 471.183\n",
      "[22]\tvalid_0's tweedie: 471.147\n",
      "[23]\tvalid_0's tweedie: 471.13\n",
      "[24]\tvalid_0's tweedie: 471.104\n",
      "[25]\tvalid_0's tweedie: 471.09\n",
      "[26]\tvalid_0's tweedie: 471.065\n",
      "[27]\tvalid_0's tweedie: 471.048\n",
      "[28]\tvalid_0's tweedie: 471.028\n",
      "[29]\tvalid_0's tweedie: 471.009\n",
      "[30]\tvalid_0's tweedie: 470.996\n",
      "[31]\tvalid_0's tweedie: 470.98\n",
      "[32]\tvalid_0's tweedie: 470.972\n",
      "[33]\tvalid_0's tweedie: 470.963\n",
      "[34]\tvalid_0's tweedie: 470.956\n",
      "[35]\tvalid_0's tweedie: 470.949\n",
      "[36]\tvalid_0's tweedie: 470.939\n",
      "[37]\tvalid_0's tweedie: 470.932\n",
      "[38]\tvalid_0's tweedie: 470.926\n",
      "[39]\tvalid_0's tweedie: 470.915\n",
      "[40]\tvalid_0's tweedie: 470.905\n",
      "[41]\tvalid_0's tweedie: 470.901\n",
      "[42]\tvalid_0's tweedie: 470.896\n",
      "[43]\tvalid_0's tweedie: 470.889\n",
      "[44]\tvalid_0's tweedie: 470.887\n",
      "[45]\tvalid_0's tweedie: 470.886\n",
      "[46]\tvalid_0's tweedie: 470.885\n",
      "[47]\tvalid_0's tweedie: 470.883\n",
      "[48]\tvalid_0's tweedie: 470.879\n",
      "[49]\tvalid_0's tweedie: 470.877\n",
      "[50]\tvalid_0's tweedie: 470.873\n",
      "[51]\tvalid_0's tweedie: 470.869\n",
      "[52]\tvalid_0's tweedie: 470.866\n",
      "[53]\tvalid_0's tweedie: 470.864\n",
      "[54]\tvalid_0's tweedie: 470.863\n",
      "[55]\tvalid_0's tweedie: 470.861\n",
      "[56]\tvalid_0's tweedie: 470.861\n",
      "[57]\tvalid_0's tweedie: 470.858\n",
      "[58]\tvalid_0's tweedie: 470.858\n",
      "[59]\tvalid_0's tweedie: 470.855\n",
      "[60]\tvalid_0's tweedie: 470.852\n",
      "[61]\tvalid_0's tweedie: 470.852\n",
      "[62]\tvalid_0's tweedie: 470.851\n",
      "[63]\tvalid_0's tweedie: 470.848\n",
      "[64]\tvalid_0's tweedie: 470.848\n",
      "[65]\tvalid_0's tweedie: 470.848\n",
      "[66]\tvalid_0's tweedie: 470.852\n",
      "[67]\tvalid_0's tweedie: 470.851\n",
      "[68]\tvalid_0's tweedie: 470.851\n",
      "[69]\tvalid_0's tweedie: 470.851\n",
      "[70]\tvalid_0's tweedie: 470.851\n",
      "[71]\tvalid_0's tweedie: 470.85\n",
      "[72]\tvalid_0's tweedie: 470.848\n",
      "[73]\tvalid_0's tweedie: 470.849\n",
      "[74]\tvalid_0's tweedie: 470.848\n",
      "[75]\tvalid_0's tweedie: 470.847\n",
      "[76]\tvalid_0's tweedie: 470.845\n",
      "[77]\tvalid_0's tweedie: 470.846\n",
      "[78]\tvalid_0's tweedie: 470.844\n",
      "[79]\tvalid_0's tweedie: 470.844\n",
      "[80]\tvalid_0's tweedie: 470.843\n",
      "[81]\tvalid_0's tweedie: 470.843\n",
      "[82]\tvalid_0's tweedie: 470.843\n",
      "[83]\tvalid_0's tweedie: 470.843\n",
      "[84]\tvalid_0's tweedie: 470.843\n",
      "[85]\tvalid_0's tweedie: 470.842\n",
      "[86]\tvalid_0's tweedie: 470.842\n",
      "[87]\tvalid_0's tweedie: 470.841\n",
      "[88]\tvalid_0's tweedie: 470.841\n",
      "[89]\tvalid_0's tweedie: 470.841\n",
      "[90]\tvalid_0's tweedie: 470.842\n",
      "[91]\tvalid_0's tweedie: 470.842\n",
      "[92]\tvalid_0's tweedie: 470.842\n",
      "[93]\tvalid_0's tweedie: 470.841\n",
      "[94]\tvalid_0's tweedie: 470.841\n",
      "[95]\tvalid_0's tweedie: 470.839\n",
      "[96]\tvalid_0's tweedie: 470.839\n",
      "[97]\tvalid_0's tweedie: 470.838\n",
      "[98]\tvalid_0's tweedie: 470.837\n",
      "[99]\tvalid_0's tweedie: 470.837\n",
      "[100]\tvalid_0's tweedie: 470.835\n",
      "[101]\tvalid_0's tweedie: 470.833\n",
      "[102]\tvalid_0's tweedie: 470.833\n",
      "[103]\tvalid_0's tweedie: 470.833\n",
      "[104]\tvalid_0's tweedie: 470.832\n",
      "[105]\tvalid_0's tweedie: 470.831\n",
      "[106]\tvalid_0's tweedie: 470.83\n",
      "[107]\tvalid_0's tweedie: 470.83\n",
      "[108]\tvalid_0's tweedie: 470.83\n",
      "[109]\tvalid_0's tweedie: 470.829\n",
      "[110]\tvalid_0's tweedie: 470.829\n",
      "[111]\tvalid_0's tweedie: 470.829\n",
      "[112]\tvalid_0's tweedie: 470.824\n",
      "[113]\tvalid_0's tweedie: 470.824\n",
      "[114]\tvalid_0's tweedie: 470.824\n",
      "[115]\tvalid_0's tweedie: 470.824\n",
      "[116]\tvalid_0's tweedie: 470.824\n",
      "[117]\tvalid_0's tweedie: 470.823\n",
      "[118]\tvalid_0's tweedie: 470.823\n",
      "[119]\tvalid_0's tweedie: 470.823\n",
      "[120]\tvalid_0's tweedie: 470.823\n",
      "[121]\tvalid_0's tweedie: 470.823\n",
      "[122]\tvalid_0's tweedie: 470.823\n",
      "[123]\tvalid_0's tweedie: 470.823\n",
      "[124]\tvalid_0's tweedie: 470.823\n",
      "[125]\tvalid_0's tweedie: 470.823\n",
      "[126]\tvalid_0's tweedie: 470.823\n",
      "[127]\tvalid_0's tweedie: 470.822\n",
      "[128]\tvalid_0's tweedie: 470.822\n",
      "[129]\tvalid_0's tweedie: 470.822\n",
      "[130]\tvalid_0's tweedie: 470.822\n",
      "[131]\tvalid_0's tweedie: 470.822\n",
      "[132]\tvalid_0's tweedie: 470.822\n",
      "[133]\tvalid_0's tweedie: 470.82\n",
      "[134]\tvalid_0's tweedie: 470.82\n",
      "[135]\tvalid_0's tweedie: 470.819\n",
      "[136]\tvalid_0's tweedie: 470.819\n",
      "[137]\tvalid_0's tweedie: 470.819\n",
      "[138]\tvalid_0's tweedie: 470.819\n",
      "[139]\tvalid_0's tweedie: 470.818\n",
      "[140]\tvalid_0's tweedie: 470.818\n",
      "[141]\tvalid_0's tweedie: 470.818\n",
      "[142]\tvalid_0's tweedie: 470.818\n",
      "[143]\tvalid_0's tweedie: 470.818\n",
      "[144]\tvalid_0's tweedie: 470.818\n",
      "[145]\tvalid_0's tweedie: 470.818\n",
      "[146]\tvalid_0's tweedie: 470.817\n",
      "[147]\tvalid_0's tweedie: 470.817\n",
      "[148]\tvalid_0's tweedie: 470.817\n",
      "[149]\tvalid_0's tweedie: 470.817\n",
      "[150]\tvalid_0's tweedie: 470.818\n",
      "[151]\tvalid_0's tweedie: 470.819\n",
      "[152]\tvalid_0's tweedie: 470.819\n",
      "[153]\tvalid_0's tweedie: 470.819\n",
      "[154]\tvalid_0's tweedie: 470.819\n",
      "[155]\tvalid_0's tweedie: 470.819\n",
      "[156]\tvalid_0's tweedie: 470.819\n",
      "[157]\tvalid_0's tweedie: 470.818\n",
      "[158]\tvalid_0's tweedie: 470.819\n",
      "[159]\tvalid_0's tweedie: 470.818\n",
      "[160]\tvalid_0's tweedie: 470.816\n",
      "[161]\tvalid_0's tweedie: 470.816\n",
      "[162]\tvalid_0's tweedie: 470.816\n",
      "[163]\tvalid_0's tweedie: 470.817\n",
      "[164]\tvalid_0's tweedie: 470.817\n",
      "[165]\tvalid_0's tweedie: 470.817\n",
      "[166]\tvalid_0's tweedie: 470.817\n",
      "[167]\tvalid_0's tweedie: 470.816\n",
      "[168]\tvalid_0's tweedie: 470.816\n",
      "[169]\tvalid_0's tweedie: 470.816\n",
      "[170]\tvalid_0's tweedie: 470.816\n",
      "[171]\tvalid_0's tweedie: 470.816\n",
      "[172]\tvalid_0's tweedie: 470.816\n",
      "[173]\tvalid_0's tweedie: 470.816\n",
      "[174]\tvalid_0's tweedie: 470.816\n",
      "[175]\tvalid_0's tweedie: 470.815\n",
      "[176]\tvalid_0's tweedie: 470.815\n",
      "[177]\tvalid_0's tweedie: 470.816\n",
      "[178]\tvalid_0's tweedie: 470.816\n",
      "[179]\tvalid_0's tweedie: 470.815\n",
      "[180]\tvalid_0's tweedie: 470.815\n",
      "[181]\tvalid_0's tweedie: 470.815\n",
      "[182]\tvalid_0's tweedie: 470.815\n",
      "[183]\tvalid_0's tweedie: 470.815\n",
      "[184]\tvalid_0's tweedie: 470.816\n",
      "[185]\tvalid_0's tweedie: 470.816\n",
      "[186]\tvalid_0's tweedie: 470.816\n",
      "[187]\tvalid_0's tweedie: 470.816\n",
      "[188]\tvalid_0's tweedie: 470.816\n",
      "[189]\tvalid_0's tweedie: 470.815\n",
      "[190]\tvalid_0's tweedie: 470.815\n",
      "[191]\tvalid_0's tweedie: 470.815\n",
      "[192]\tvalid_0's tweedie: 470.815\n",
      "[193]\tvalid_0's tweedie: 470.815\n",
      "[194]\tvalid_0's tweedie: 470.814\n",
      "[195]\tvalid_0's tweedie: 470.815\n",
      "[196]\tvalid_0's tweedie: 470.815\n",
      "[197]\tvalid_0's tweedie: 470.815\n",
      "[198]\tvalid_0's tweedie: 470.815\n",
      "[199]\tvalid_0's tweedie: 470.815\n",
      "[200]\tvalid_0's tweedie: 470.815\n",
      "[201]\tvalid_0's tweedie: 470.815\n",
      "[202]\tvalid_0's tweedie: 470.815\n",
      "[203]\tvalid_0's tweedie: 470.815\n",
      "[204]\tvalid_0's tweedie: 470.814\n",
      "[205]\tvalid_0's tweedie: 470.814\n",
      "[206]\tvalid_0's tweedie: 470.815\n",
      "[207]\tvalid_0's tweedie: 470.815\n",
      "[208]\tvalid_0's tweedie: 470.815\n",
      "[209]\tvalid_0's tweedie: 470.815\n",
      "[210]\tvalid_0's tweedie: 470.813\n",
      "[211]\tvalid_0's tweedie: 470.813\n",
      "[212]\tvalid_0's tweedie: 470.814\n",
      "[213]\tvalid_0's tweedie: 470.814\n",
      "[214]\tvalid_0's tweedie: 470.814\n",
      "[215]\tvalid_0's tweedie: 470.815\n",
      "[216]\tvalid_0's tweedie: 470.815\n",
      "[217]\tvalid_0's tweedie: 470.815\n",
      "[218]\tvalid_0's tweedie: 470.814\n",
      "[219]\tvalid_0's tweedie: 470.814\n",
      "[220]\tvalid_0's tweedie: 470.814\n",
      "[221]\tvalid_0's tweedie: 470.814\n",
      "[222]\tvalid_0's tweedie: 470.813\n",
      "[223]\tvalid_0's tweedie: 470.813\n",
      "[224]\tvalid_0's tweedie: 470.814\n",
      "[225]\tvalid_0's tweedie: 470.814\n",
      "[226]\tvalid_0's tweedie: 470.814\n",
      "[227]\tvalid_0's tweedie: 470.814\n",
      "[228]\tvalid_0's tweedie: 470.814\n",
      "[229]\tvalid_0's tweedie: 470.813\n",
      "[230]\tvalid_0's tweedie: 470.814\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's tweedie: 470.813\n",
      "Training model for level 3\n",
      "Training model for level 3 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5516\n",
      "[LightGBM] [Info] Number of data points in the train set: 18710, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.139589\n",
      "[1]\tvalid_0's tweedie: 260.808\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.237\n",
      "[3]\tvalid_0's tweedie: 259.773\n",
      "[4]\tvalid_0's tweedie: 259.389\n",
      "[5]\tvalid_0's tweedie: 259.086\n",
      "[6]\tvalid_0's tweedie: 258.815\n",
      "[7]\tvalid_0's tweedie: 258.597\n",
      "[8]\tvalid_0's tweedie: 258.413\n",
      "[9]\tvalid_0's tweedie: 258.263\n",
      "[10]\tvalid_0's tweedie: 258.144\n",
      "[11]\tvalid_0's tweedie: 258.037\n",
      "[12]\tvalid_0's tweedie: 257.951\n",
      "[13]\tvalid_0's tweedie: 257.88\n",
      "[14]\tvalid_0's tweedie: 257.821\n",
      "[15]\tvalid_0's tweedie: 257.772\n",
      "[16]\tvalid_0's tweedie: 257.729\n",
      "[17]\tvalid_0's tweedie: 257.696\n",
      "[18]\tvalid_0's tweedie: 257.663\n",
      "[19]\tvalid_0's tweedie: 257.637\n",
      "[20]\tvalid_0's tweedie: 257.616\n",
      "[21]\tvalid_0's tweedie: 257.595\n",
      "[22]\tvalid_0's tweedie: 257.579\n",
      "[23]\tvalid_0's tweedie: 257.566\n",
      "[24]\tvalid_0's tweedie: 257.555\n",
      "[25]\tvalid_0's tweedie: 257.545\n",
      "[26]\tvalid_0's tweedie: 257.538\n",
      "[27]\tvalid_0's tweedie: 257.532\n",
      "[28]\tvalid_0's tweedie: 257.525\n",
      "[29]\tvalid_0's tweedie: 257.521\n",
      "[30]\tvalid_0's tweedie: 257.515\n",
      "[31]\tvalid_0's tweedie: 257.511\n",
      "[32]\tvalid_0's tweedie: 257.507\n",
      "[33]\tvalid_0's tweedie: 257.504\n",
      "[34]\tvalid_0's tweedie: 257.502\n",
      "[35]\tvalid_0's tweedie: 257.501\n",
      "[36]\tvalid_0's tweedie: 257.499\n",
      "[37]\tvalid_0's tweedie: 257.499\n",
      "[38]\tvalid_0's tweedie: 257.497\n",
      "[39]\tvalid_0's tweedie: 257.497\n",
      "[40]\tvalid_0's tweedie: 257.497\n",
      "[41]\tvalid_0's tweedie: 257.496\n",
      "[42]\tvalid_0's tweedie: 257.496\n",
      "[43]\tvalid_0's tweedie: 257.493\n",
      "[44]\tvalid_0's tweedie: 257.495\n",
      "[45]\tvalid_0's tweedie: 257.494\n",
      "[46]\tvalid_0's tweedie: 257.497\n",
      "[47]\tvalid_0's tweedie: 257.496\n",
      "[48]\tvalid_0's tweedie: 257.496\n",
      "[49]\tvalid_0's tweedie: 257.495\n",
      "[50]\tvalid_0's tweedie: 257.496\n",
      "[51]\tvalid_0's tweedie: 257.496\n",
      "[52]\tvalid_0's tweedie: 257.495\n",
      "[53]\tvalid_0's tweedie: 257.494\n",
      "[54]\tvalid_0's tweedie: 257.493\n",
      "[55]\tvalid_0's tweedie: 257.492\n",
      "[56]\tvalid_0's tweedie: 257.49\n",
      "[57]\tvalid_0's tweedie: 257.491\n",
      "[58]\tvalid_0's tweedie: 257.491\n",
      "[59]\tvalid_0's tweedie: 257.493\n",
      "[60]\tvalid_0's tweedie: 257.492\n",
      "[61]\tvalid_0's tweedie: 257.492\n",
      "[62]\tvalid_0's tweedie: 257.491\n",
      "[63]\tvalid_0's tweedie: 257.491\n",
      "[64]\tvalid_0's tweedie: 257.493\n",
      "[65]\tvalid_0's tweedie: 257.491\n",
      "[66]\tvalid_0's tweedie: 257.489\n",
      "[67]\tvalid_0's tweedie: 257.488\n",
      "[68]\tvalid_0's tweedie: 257.488\n",
      "[69]\tvalid_0's tweedie: 257.487\n",
      "[70]\tvalid_0's tweedie: 257.485\n",
      "[71]\tvalid_0's tweedie: 257.484\n",
      "[72]\tvalid_0's tweedie: 257.484\n",
      "[73]\tvalid_0's tweedie: 257.484\n",
      "[74]\tvalid_0's tweedie: 257.484\n",
      "[75]\tvalid_0's tweedie: 257.483\n",
      "[76]\tvalid_0's tweedie: 257.484\n",
      "[77]\tvalid_0's tweedie: 257.483\n",
      "[78]\tvalid_0's tweedie: 257.483\n",
      "[79]\tvalid_0's tweedie: 257.482\n",
      "[80]\tvalid_0's tweedie: 257.481\n",
      "[81]\tvalid_0's tweedie: 257.481\n",
      "[82]\tvalid_0's tweedie: 257.481\n",
      "[83]\tvalid_0's tweedie: 257.481\n",
      "[84]\tvalid_0's tweedie: 257.479\n",
      "[85]\tvalid_0's tweedie: 257.478\n",
      "[86]\tvalid_0's tweedie: 257.478\n",
      "[87]\tvalid_0's tweedie: 257.478\n",
      "[88]\tvalid_0's tweedie: 257.478\n",
      "[89]\tvalid_0's tweedie: 257.478\n",
      "[90]\tvalid_0's tweedie: 257.478\n",
      "[91]\tvalid_0's tweedie: 257.478\n",
      "[92]\tvalid_0's tweedie: 257.479\n",
      "[93]\tvalid_0's tweedie: 257.479\n",
      "[94]\tvalid_0's tweedie: 257.479\n",
      "[95]\tvalid_0's tweedie: 257.478\n",
      "[96]\tvalid_0's tweedie: 257.478\n",
      "[97]\tvalid_0's tweedie: 257.479\n",
      "[98]\tvalid_0's tweedie: 257.478\n",
      "[99]\tvalid_0's tweedie: 257.478\n",
      "[100]\tvalid_0's tweedie: 257.478\n",
      "[101]\tvalid_0's tweedie: 257.477\n",
      "[102]\tvalid_0's tweedie: 257.477\n",
      "[103]\tvalid_0's tweedie: 257.477\n",
      "[104]\tvalid_0's tweedie: 257.477\n",
      "[105]\tvalid_0's tweedie: 257.477\n",
      "[106]\tvalid_0's tweedie: 257.477\n",
      "[107]\tvalid_0's tweedie: 257.478\n",
      "[108]\tvalid_0's tweedie: 257.477\n",
      "[109]\tvalid_0's tweedie: 257.477\n",
      "[110]\tvalid_0's tweedie: 257.477\n",
      "[111]\tvalid_0's tweedie: 257.477\n",
      "[112]\tvalid_0's tweedie: 257.477\n",
      "[113]\tvalid_0's tweedie: 257.477\n",
      "[114]\tvalid_0's tweedie: 257.477\n",
      "[115]\tvalid_0's tweedie: 257.477\n",
      "[116]\tvalid_0's tweedie: 257.476\n",
      "[117]\tvalid_0's tweedie: 257.477\n",
      "[118]\tvalid_0's tweedie: 257.477\n",
      "[119]\tvalid_0's tweedie: 257.477\n",
      "[120]\tvalid_0's tweedie: 257.477\n",
      "[121]\tvalid_0's tweedie: 257.477\n",
      "[122]\tvalid_0's tweedie: 257.477\n",
      "[123]\tvalid_0's tweedie: 257.477\n",
      "[124]\tvalid_0's tweedie: 257.477\n",
      "[125]\tvalid_0's tweedie: 257.477\n",
      "[126]\tvalid_0's tweedie: 257.477\n",
      "[127]\tvalid_0's tweedie: 257.477\n",
      "[128]\tvalid_0's tweedie: 257.476\n",
      "[129]\tvalid_0's tweedie: 257.476\n",
      "[130]\tvalid_0's tweedie: 257.476\n",
      "[131]\tvalid_0's tweedie: 257.476\n",
      "[132]\tvalid_0's tweedie: 257.476\n",
      "[133]\tvalid_0's tweedie: 257.476\n",
      "[134]\tvalid_0's tweedie: 257.475\n",
      "[135]\tvalid_0's tweedie: 257.475\n",
      "[136]\tvalid_0's tweedie: 257.475\n",
      "[137]\tvalid_0's tweedie: 257.475\n",
      "[138]\tvalid_0's tweedie: 257.475\n",
      "[139]\tvalid_0's tweedie: 257.475\n",
      "[140]\tvalid_0's tweedie: 257.475\n",
      "[141]\tvalid_0's tweedie: 257.475\n",
      "[142]\tvalid_0's tweedie: 257.475\n",
      "[143]\tvalid_0's tweedie: 257.475\n",
      "[144]\tvalid_0's tweedie: 257.475\n",
      "[145]\tvalid_0's tweedie: 257.475\n",
      "[146]\tvalid_0's tweedie: 257.475\n",
      "[147]\tvalid_0's tweedie: 257.475\n",
      "[148]\tvalid_0's tweedie: 257.475\n",
      "[149]\tvalid_0's tweedie: 257.475\n",
      "[150]\tvalid_0's tweedie: 257.474\n",
      "[151]\tvalid_0's tweedie: 257.474\n",
      "[152]\tvalid_0's tweedie: 257.474\n",
      "[153]\tvalid_0's tweedie: 257.474\n",
      "[154]\tvalid_0's tweedie: 257.474\n",
      "[155]\tvalid_0's tweedie: 257.474\n",
      "[156]\tvalid_0's tweedie: 257.474\n",
      "[157]\tvalid_0's tweedie: 257.474\n",
      "[158]\tvalid_0's tweedie: 257.474\n",
      "[159]\tvalid_0's tweedie: 257.474\n",
      "[160]\tvalid_0's tweedie: 257.474\n",
      "[161]\tvalid_0's tweedie: 257.474\n",
      "[162]\tvalid_0's tweedie: 257.475\n",
      "[163]\tvalid_0's tweedie: 257.475\n",
      "[164]\tvalid_0's tweedie: 257.475\n",
      "[165]\tvalid_0's tweedie: 257.475\n",
      "[166]\tvalid_0's tweedie: 257.475\n",
      "[167]\tvalid_0's tweedie: 257.475\n",
      "[168]\tvalid_0's tweedie: 257.474\n",
      "[169]\tvalid_0's tweedie: 257.475\n",
      "[170]\tvalid_0's tweedie: 257.474\n",
      "[171]\tvalid_0's tweedie: 257.474\n",
      "[172]\tvalid_0's tweedie: 257.474\n",
      "[173]\tvalid_0's tweedie: 257.474\n",
      "[174]\tvalid_0's tweedie: 257.474\n",
      "[175]\tvalid_0's tweedie: 257.474\n",
      "[176]\tvalid_0's tweedie: 257.474\n",
      "[177]\tvalid_0's tweedie: 257.474\n",
      "[178]\tvalid_0's tweedie: 257.474\n",
      "[179]\tvalid_0's tweedie: 257.473\n",
      "[180]\tvalid_0's tweedie: 257.473\n",
      "[181]\tvalid_0's tweedie: 257.473\n",
      "[182]\tvalid_0's tweedie: 257.473\n",
      "[183]\tvalid_0's tweedie: 257.474\n",
      "[184]\tvalid_0's tweedie: 257.474\n",
      "[185]\tvalid_0's tweedie: 257.474\n",
      "[186]\tvalid_0's tweedie: 257.474\n",
      "[187]\tvalid_0's tweedie: 257.474\n",
      "[188]\tvalid_0's tweedie: 257.474\n",
      "[189]\tvalid_0's tweedie: 257.474\n",
      "[190]\tvalid_0's tweedie: 257.474\n",
      "[191]\tvalid_0's tweedie: 257.474\n",
      "[192]\tvalid_0's tweedie: 257.474\n",
      "[193]\tvalid_0's tweedie: 257.474\n",
      "[194]\tvalid_0's tweedie: 257.474\n",
      "[195]\tvalid_0's tweedie: 257.474\n",
      "[196]\tvalid_0's tweedie: 257.474\n",
      "[197]\tvalid_0's tweedie: 257.474\n",
      "[198]\tvalid_0's tweedie: 257.474\n",
      "[199]\tvalid_0's tweedie: 257.474\n",
      "[200]\tvalid_0's tweedie: 257.474\n",
      "[201]\tvalid_0's tweedie: 257.474\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's tweedie: 257.473\n",
      "Training model for level 3 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5515\n",
      "[LightGBM] [Info] Number of data points in the train set: 18700, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.139580\n",
      "[1]\tvalid_0's tweedie: 260.813\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.223\n",
      "[3]\tvalid_0's tweedie: 259.752\n",
      "[4]\tvalid_0's tweedie: 259.362\n",
      "[5]\tvalid_0's tweedie: 259.054\n",
      "[6]\tvalid_0's tweedie: 258.789\n",
      "[7]\tvalid_0's tweedie: 258.579\n",
      "[8]\tvalid_0's tweedie: 258.4\n",
      "[9]\tvalid_0's tweedie: 258.256\n",
      "[10]\tvalid_0's tweedie: 258.137\n",
      "[11]\tvalid_0's tweedie: 258.034\n",
      "[12]\tvalid_0's tweedie: 257.96\n",
      "[13]\tvalid_0's tweedie: 257.9\n",
      "[14]\tvalid_0's tweedie: 257.842\n",
      "[15]\tvalid_0's tweedie: 257.788\n",
      "[16]\tvalid_0's tweedie: 257.745\n",
      "[17]\tvalid_0's tweedie: 257.712\n",
      "[18]\tvalid_0's tweedie: 257.684\n",
      "[19]\tvalid_0's tweedie: 257.661\n",
      "[20]\tvalid_0's tweedie: 257.642\n",
      "[21]\tvalid_0's tweedie: 257.626\n",
      "[22]\tvalid_0's tweedie: 257.61\n",
      "[23]\tvalid_0's tweedie: 257.595\n",
      "[24]\tvalid_0's tweedie: 257.586\n",
      "[25]\tvalid_0's tweedie: 257.578\n",
      "[26]\tvalid_0's tweedie: 257.572\n",
      "[27]\tvalid_0's tweedie: 257.565\n",
      "[28]\tvalid_0's tweedie: 257.561\n",
      "[29]\tvalid_0's tweedie: 257.556\n",
      "[30]\tvalid_0's tweedie: 257.552\n",
      "[31]\tvalid_0's tweedie: 257.547\n",
      "[32]\tvalid_0's tweedie: 257.545\n",
      "[33]\tvalid_0's tweedie: 257.543\n",
      "[34]\tvalid_0's tweedie: 257.541\n",
      "[35]\tvalid_0's tweedie: 257.543\n",
      "[36]\tvalid_0's tweedie: 257.541\n",
      "[37]\tvalid_0's tweedie: 257.54\n",
      "[38]\tvalid_0's tweedie: 257.541\n",
      "[39]\tvalid_0's tweedie: 257.54\n",
      "[40]\tvalid_0's tweedie: 257.537\n",
      "[41]\tvalid_0's tweedie: 257.536\n",
      "[42]\tvalid_0's tweedie: 257.538\n",
      "[43]\tvalid_0's tweedie: 257.535\n",
      "[44]\tvalid_0's tweedie: 257.533\n",
      "[45]\tvalid_0's tweedie: 257.532\n",
      "[46]\tvalid_0's tweedie: 257.531\n",
      "[47]\tvalid_0's tweedie: 257.534\n",
      "[48]\tvalid_0's tweedie: 257.533\n",
      "[49]\tvalid_0's tweedie: 257.531\n",
      "[50]\tvalid_0's tweedie: 257.53\n",
      "[51]\tvalid_0's tweedie: 257.529\n",
      "[52]\tvalid_0's tweedie: 257.528\n",
      "[53]\tvalid_0's tweedie: 257.528\n",
      "[54]\tvalid_0's tweedie: 257.527\n",
      "[55]\tvalid_0's tweedie: 257.527\n",
      "[56]\tvalid_0's tweedie: 257.526\n",
      "[57]\tvalid_0's tweedie: 257.525\n",
      "[58]\tvalid_0's tweedie: 257.528\n",
      "[59]\tvalid_0's tweedie: 257.528\n",
      "[60]\tvalid_0's tweedie: 257.527\n",
      "[61]\tvalid_0's tweedie: 257.526\n",
      "[62]\tvalid_0's tweedie: 257.526\n",
      "[63]\tvalid_0's tweedie: 257.525\n",
      "[64]\tvalid_0's tweedie: 257.523\n",
      "[65]\tvalid_0's tweedie: 257.524\n",
      "[66]\tvalid_0's tweedie: 257.522\n",
      "[67]\tvalid_0's tweedie: 257.52\n",
      "[68]\tvalid_0's tweedie: 257.522\n",
      "[69]\tvalid_0's tweedie: 257.522\n",
      "[70]\tvalid_0's tweedie: 257.521\n",
      "[71]\tvalid_0's tweedie: 257.521\n",
      "[72]\tvalid_0's tweedie: 257.522\n",
      "[73]\tvalid_0's tweedie: 257.522\n",
      "[74]\tvalid_0's tweedie: 257.52\n",
      "[75]\tvalid_0's tweedie: 257.52\n",
      "[76]\tvalid_0's tweedie: 257.52\n",
      "[77]\tvalid_0's tweedie: 257.519\n",
      "[78]\tvalid_0's tweedie: 257.52\n",
      "[79]\tvalid_0's tweedie: 257.519\n",
      "[80]\tvalid_0's tweedie: 257.516\n",
      "[81]\tvalid_0's tweedie: 257.516\n",
      "[82]\tvalid_0's tweedie: 257.516\n",
      "[83]\tvalid_0's tweedie: 257.516\n",
      "[84]\tvalid_0's tweedie: 257.516\n",
      "[85]\tvalid_0's tweedie: 257.516\n",
      "[86]\tvalid_0's tweedie: 257.515\n",
      "[87]\tvalid_0's tweedie: 257.513\n",
      "[88]\tvalid_0's tweedie: 257.513\n",
      "[89]\tvalid_0's tweedie: 257.513\n",
      "[90]\tvalid_0's tweedie: 257.513\n",
      "[91]\tvalid_0's tweedie: 257.513\n",
      "[92]\tvalid_0's tweedie: 257.513\n",
      "[93]\tvalid_0's tweedie: 257.513\n",
      "[94]\tvalid_0's tweedie: 257.514\n",
      "[95]\tvalid_0's tweedie: 257.514\n",
      "[96]\tvalid_0's tweedie: 257.511\n",
      "[97]\tvalid_0's tweedie: 257.51\n",
      "[98]\tvalid_0's tweedie: 257.51\n",
      "[99]\tvalid_0's tweedie: 257.51\n",
      "[100]\tvalid_0's tweedie: 257.51\n",
      "[101]\tvalid_0's tweedie: 257.51\n",
      "[102]\tvalid_0's tweedie: 257.511\n",
      "[103]\tvalid_0's tweedie: 257.511\n",
      "[104]\tvalid_0's tweedie: 257.511\n",
      "[105]\tvalid_0's tweedie: 257.511\n",
      "[106]\tvalid_0's tweedie: 257.51\n",
      "[107]\tvalid_0's tweedie: 257.509\n",
      "[108]\tvalid_0's tweedie: 257.509\n",
      "[109]\tvalid_0's tweedie: 257.509\n",
      "[110]\tvalid_0's tweedie: 257.509\n",
      "[111]\tvalid_0's tweedie: 257.509\n",
      "[112]\tvalid_0's tweedie: 257.509\n",
      "[113]\tvalid_0's tweedie: 257.508\n",
      "[114]\tvalid_0's tweedie: 257.507\n",
      "[115]\tvalid_0's tweedie: 257.506\n",
      "[116]\tvalid_0's tweedie: 257.506\n",
      "[117]\tvalid_0's tweedie: 257.506\n",
      "[118]\tvalid_0's tweedie: 257.506\n",
      "[119]\tvalid_0's tweedie: 257.506\n",
      "[120]\tvalid_0's tweedie: 257.506\n",
      "[121]\tvalid_0's tweedie: 257.506\n",
      "[122]\tvalid_0's tweedie: 257.506\n",
      "[123]\tvalid_0's tweedie: 257.506\n",
      "[124]\tvalid_0's tweedie: 257.505\n",
      "[125]\tvalid_0's tweedie: 257.506\n",
      "[126]\tvalid_0's tweedie: 257.504\n",
      "[127]\tvalid_0's tweedie: 257.504\n",
      "[128]\tvalid_0's tweedie: 257.503\n",
      "[129]\tvalid_0's tweedie: 257.504\n",
      "[130]\tvalid_0's tweedie: 257.504\n",
      "[131]\tvalid_0's tweedie: 257.503\n",
      "[132]\tvalid_0's tweedie: 257.503\n",
      "[133]\tvalid_0's tweedie: 257.503\n",
      "[134]\tvalid_0's tweedie: 257.504\n",
      "[135]\tvalid_0's tweedie: 257.504\n",
      "[136]\tvalid_0's tweedie: 257.505\n",
      "[137]\tvalid_0's tweedie: 257.505\n",
      "[138]\tvalid_0's tweedie: 257.504\n",
      "[139]\tvalid_0's tweedie: 257.505\n",
      "[140]\tvalid_0's tweedie: 257.505\n",
      "[141]\tvalid_0's tweedie: 257.506\n",
      "[142]\tvalid_0's tweedie: 257.505\n",
      "[143]\tvalid_0's tweedie: 257.505\n",
      "[144]\tvalid_0's tweedie: 257.505\n",
      "[145]\tvalid_0's tweedie: 257.504\n",
      "[146]\tvalid_0's tweedie: 257.504\n",
      "[147]\tvalid_0's tweedie: 257.504\n",
      "[148]\tvalid_0's tweedie: 257.504\n",
      "[149]\tvalid_0's tweedie: 257.504\n",
      "[150]\tvalid_0's tweedie: 257.505\n",
      "[151]\tvalid_0's tweedie: 257.505\n",
      "[152]\tvalid_0's tweedie: 257.504\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's tweedie: 257.503\n",
      "Training model for level 3 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5514\n",
      "[LightGBM] [Info] Number of data points in the train set: 18690, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.139547\n",
      "[1]\tvalid_0's tweedie: 260.813\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.222\n",
      "[3]\tvalid_0's tweedie: 259.753\n",
      "[4]\tvalid_0's tweedie: 259.353\n",
      "[5]\tvalid_0's tweedie: 259.032\n",
      "[6]\tvalid_0's tweedie: 258.771\n",
      "[7]\tvalid_0's tweedie: 258.565\n",
      "[8]\tvalid_0's tweedie: 258.393\n",
      "[9]\tvalid_0's tweedie: 258.237\n",
      "[10]\tvalid_0's tweedie: 258.114\n",
      "[11]\tvalid_0's tweedie: 258.014\n",
      "[12]\tvalid_0's tweedie: 257.937\n",
      "[13]\tvalid_0's tweedie: 257.87\n",
      "[14]\tvalid_0's tweedie: 257.812\n",
      "[15]\tvalid_0's tweedie: 257.768\n",
      "[16]\tvalid_0's tweedie: 257.731\n",
      "[17]\tvalid_0's tweedie: 257.695\n",
      "[18]\tvalid_0's tweedie: 257.668\n",
      "[19]\tvalid_0's tweedie: 257.643\n",
      "[20]\tvalid_0's tweedie: 257.623\n",
      "[21]\tvalid_0's tweedie: 257.606\n",
      "[22]\tvalid_0's tweedie: 257.593\n",
      "[23]\tvalid_0's tweedie: 257.582\n",
      "[24]\tvalid_0's tweedie: 257.576\n",
      "[25]\tvalid_0's tweedie: 257.567\n",
      "[26]\tvalid_0's tweedie: 257.559\n",
      "[27]\tvalid_0's tweedie: 257.551\n",
      "[28]\tvalid_0's tweedie: 257.547\n",
      "[29]\tvalid_0's tweedie: 257.544\n",
      "[30]\tvalid_0's tweedie: 257.54\n",
      "[31]\tvalid_0's tweedie: 257.537\n",
      "[32]\tvalid_0's tweedie: 257.534\n",
      "[33]\tvalid_0's tweedie: 257.532\n",
      "[34]\tvalid_0's tweedie: 257.531\n",
      "[35]\tvalid_0's tweedie: 257.529\n",
      "[36]\tvalid_0's tweedie: 257.528\n",
      "[37]\tvalid_0's tweedie: 257.527\n",
      "[38]\tvalid_0's tweedie: 257.525\n",
      "[39]\tvalid_0's tweedie: 257.526\n",
      "[40]\tvalid_0's tweedie: 257.526\n",
      "[41]\tvalid_0's tweedie: 257.525\n",
      "[42]\tvalid_0's tweedie: 257.524\n",
      "[43]\tvalid_0's tweedie: 257.523\n",
      "[44]\tvalid_0's tweedie: 257.522\n",
      "[45]\tvalid_0's tweedie: 257.521\n",
      "[46]\tvalid_0's tweedie: 257.523\n",
      "[47]\tvalid_0's tweedie: 257.523\n",
      "[48]\tvalid_0's tweedie: 257.522\n",
      "[49]\tvalid_0's tweedie: 257.522\n",
      "[50]\tvalid_0's tweedie: 257.522\n",
      "[51]\tvalid_0's tweedie: 257.521\n",
      "[52]\tvalid_0's tweedie: 257.52\n",
      "[53]\tvalid_0's tweedie: 257.518\n",
      "[54]\tvalid_0's tweedie: 257.517\n",
      "[55]\tvalid_0's tweedie: 257.516\n",
      "[56]\tvalid_0's tweedie: 257.514\n",
      "[57]\tvalid_0's tweedie: 257.511\n",
      "[58]\tvalid_0's tweedie: 257.511\n",
      "[59]\tvalid_0's tweedie: 257.514\n",
      "[60]\tvalid_0's tweedie: 257.512\n",
      "[61]\tvalid_0's tweedie: 257.512\n",
      "[62]\tvalid_0's tweedie: 257.512\n",
      "[63]\tvalid_0's tweedie: 257.512\n",
      "[64]\tvalid_0's tweedie: 257.511\n",
      "[65]\tvalid_0's tweedie: 257.512\n",
      "[66]\tvalid_0's tweedie: 257.513\n",
      "[67]\tvalid_0's tweedie: 257.513\n",
      "[68]\tvalid_0's tweedie: 257.513\n",
      "[69]\tvalid_0's tweedie: 257.513\n",
      "[70]\tvalid_0's tweedie: 257.512\n",
      "[71]\tvalid_0's tweedie: 257.511\n",
      "[72]\tvalid_0's tweedie: 257.512\n",
      "[73]\tvalid_0's tweedie: 257.511\n",
      "[74]\tvalid_0's tweedie: 257.508\n",
      "[75]\tvalid_0's tweedie: 257.505\n",
      "[76]\tvalid_0's tweedie: 257.505\n",
      "[77]\tvalid_0's tweedie: 257.505\n",
      "[78]\tvalid_0's tweedie: 257.505\n",
      "[79]\tvalid_0's tweedie: 257.505\n",
      "[80]\tvalid_0's tweedie: 257.506\n",
      "[81]\tvalid_0's tweedie: 257.505\n",
      "[82]\tvalid_0's tweedie: 257.504\n",
      "[83]\tvalid_0's tweedie: 257.505\n",
      "[84]\tvalid_0's tweedie: 257.502\n",
      "[85]\tvalid_0's tweedie: 257.502\n",
      "[86]\tvalid_0's tweedie: 257.501\n",
      "[87]\tvalid_0's tweedie: 257.501\n",
      "[88]\tvalid_0's tweedie: 257.499\n",
      "[89]\tvalid_0's tweedie: 257.499\n",
      "[90]\tvalid_0's tweedie: 257.5\n",
      "[91]\tvalid_0's tweedie: 257.5\n",
      "[92]\tvalid_0's tweedie: 257.5\n",
      "[93]\tvalid_0's tweedie: 257.5\n",
      "[94]\tvalid_0's tweedie: 257.5\n",
      "[95]\tvalid_0's tweedie: 257.501\n",
      "[96]\tvalid_0's tweedie: 257.501\n",
      "[97]\tvalid_0's tweedie: 257.501\n",
      "[98]\tvalid_0's tweedie: 257.501\n",
      "[99]\tvalid_0's tweedie: 257.501\n",
      "[100]\tvalid_0's tweedie: 257.501\n",
      "[101]\tvalid_0's tweedie: 257.501\n",
      "[102]\tvalid_0's tweedie: 257.501\n",
      "[103]\tvalid_0's tweedie: 257.501\n",
      "[104]\tvalid_0's tweedie: 257.5\n",
      "[105]\tvalid_0's tweedie: 257.5\n",
      "[106]\tvalid_0's tweedie: 257.5\n",
      "[107]\tvalid_0's tweedie: 257.5\n",
      "[108]\tvalid_0's tweedie: 257.5\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's tweedie: 257.499\n",
      "Training model for level 3 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 18680, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.139742\n",
      "[1]\tvalid_0's tweedie: 260.811\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.22\n",
      "[3]\tvalid_0's tweedie: 259.751\n",
      "[4]\tvalid_0's tweedie: 259.352\n",
      "[5]\tvalid_0's tweedie: 259.028\n",
      "[6]\tvalid_0's tweedie: 258.776\n",
      "[7]\tvalid_0's tweedie: 258.565\n",
      "[8]\tvalid_0's tweedie: 258.399\n",
      "[9]\tvalid_0's tweedie: 258.243\n",
      "[10]\tvalid_0's tweedie: 258.122\n",
      "[11]\tvalid_0's tweedie: 258.024\n",
      "[12]\tvalid_0's tweedie: 257.942\n",
      "[13]\tvalid_0's tweedie: 257.872\n",
      "[14]\tvalid_0's tweedie: 257.815\n",
      "[15]\tvalid_0's tweedie: 257.771\n",
      "[16]\tvalid_0's tweedie: 257.732\n",
      "[17]\tvalid_0's tweedie: 257.699\n",
      "[18]\tvalid_0's tweedie: 257.671\n",
      "[19]\tvalid_0's tweedie: 257.648\n",
      "[20]\tvalid_0's tweedie: 257.63\n",
      "[21]\tvalid_0's tweedie: 257.612\n",
      "[22]\tvalid_0's tweedie: 257.599\n",
      "[23]\tvalid_0's tweedie: 257.584\n",
      "[24]\tvalid_0's tweedie: 257.575\n",
      "[25]\tvalid_0's tweedie: 257.57\n",
      "[26]\tvalid_0's tweedie: 257.565\n",
      "[27]\tvalid_0's tweedie: 257.56\n",
      "[28]\tvalid_0's tweedie: 257.556\n",
      "[29]\tvalid_0's tweedie: 257.552\n",
      "[30]\tvalid_0's tweedie: 257.548\n",
      "[31]\tvalid_0's tweedie: 257.545\n",
      "[32]\tvalid_0's tweedie: 257.541\n",
      "[33]\tvalid_0's tweedie: 257.54\n",
      "[34]\tvalid_0's tweedie: 257.538\n",
      "[35]\tvalid_0's tweedie: 257.537\n",
      "[36]\tvalid_0's tweedie: 257.535\n",
      "[37]\tvalid_0's tweedie: 257.534\n",
      "[38]\tvalid_0's tweedie: 257.531\n",
      "[39]\tvalid_0's tweedie: 257.531\n",
      "[40]\tvalid_0's tweedie: 257.528\n",
      "[41]\tvalid_0's tweedie: 257.53\n",
      "[42]\tvalid_0's tweedie: 257.529\n",
      "[43]\tvalid_0's tweedie: 257.529\n",
      "[44]\tvalid_0's tweedie: 257.527\n",
      "[45]\tvalid_0's tweedie: 257.529\n",
      "[46]\tvalid_0's tweedie: 257.528\n",
      "[47]\tvalid_0's tweedie: 257.527\n",
      "[48]\tvalid_0's tweedie: 257.526\n",
      "[49]\tvalid_0's tweedie: 257.527\n",
      "[50]\tvalid_0's tweedie: 257.524\n",
      "[51]\tvalid_0's tweedie: 257.527\n",
      "[52]\tvalid_0's tweedie: 257.524\n",
      "[53]\tvalid_0's tweedie: 257.522\n",
      "[54]\tvalid_0's tweedie: 257.52\n",
      "[55]\tvalid_0's tweedie: 257.52\n",
      "[56]\tvalid_0's tweedie: 257.521\n",
      "[57]\tvalid_0's tweedie: 257.519\n",
      "[58]\tvalid_0's tweedie: 257.519\n",
      "[59]\tvalid_0's tweedie: 257.518\n",
      "[60]\tvalid_0's tweedie: 257.517\n",
      "[61]\tvalid_0's tweedie: 257.515\n",
      "[62]\tvalid_0's tweedie: 257.516\n",
      "[63]\tvalid_0's tweedie: 257.514\n",
      "[64]\tvalid_0's tweedie: 257.514\n",
      "[65]\tvalid_0's tweedie: 257.511\n",
      "[66]\tvalid_0's tweedie: 257.511\n",
      "[67]\tvalid_0's tweedie: 257.51\n",
      "[68]\tvalid_0's tweedie: 257.509\n",
      "[69]\tvalid_0's tweedie: 257.509\n",
      "[70]\tvalid_0's tweedie: 257.508\n",
      "[71]\tvalid_0's tweedie: 257.508\n",
      "[72]\tvalid_0's tweedie: 257.509\n",
      "[73]\tvalid_0's tweedie: 257.507\n",
      "[74]\tvalid_0's tweedie: 257.506\n",
      "[75]\tvalid_0's tweedie: 257.506\n",
      "[76]\tvalid_0's tweedie: 257.505\n",
      "[77]\tvalid_0's tweedie: 257.503\n",
      "[78]\tvalid_0's tweedie: 257.503\n",
      "[79]\tvalid_0's tweedie: 257.503\n",
      "[80]\tvalid_0's tweedie: 257.503\n",
      "[81]\tvalid_0's tweedie: 257.502\n",
      "[82]\tvalid_0's tweedie: 257.502\n",
      "[83]\tvalid_0's tweedie: 257.503\n",
      "[84]\tvalid_0's tweedie: 257.501\n",
      "[85]\tvalid_0's tweedie: 257.502\n",
      "[86]\tvalid_0's tweedie: 257.501\n",
      "[87]\tvalid_0's tweedie: 257.501\n",
      "[88]\tvalid_0's tweedie: 257.501\n",
      "[89]\tvalid_0's tweedie: 257.499\n",
      "[90]\tvalid_0's tweedie: 257.499\n",
      "[91]\tvalid_0's tweedie: 257.499\n",
      "[92]\tvalid_0's tweedie: 257.499\n",
      "[93]\tvalid_0's tweedie: 257.5\n",
      "[94]\tvalid_0's tweedie: 257.5\n",
      "[95]\tvalid_0's tweedie: 257.499\n",
      "[96]\tvalid_0's tweedie: 257.499\n",
      "[97]\tvalid_0's tweedie: 257.499\n",
      "[98]\tvalid_0's tweedie: 257.499\n",
      "[99]\tvalid_0's tweedie: 257.499\n",
      "[100]\tvalid_0's tweedie: 257.499\n",
      "[101]\tvalid_0's tweedie: 257.498\n",
      "[102]\tvalid_0's tweedie: 257.499\n",
      "[103]\tvalid_0's tweedie: 257.498\n",
      "[104]\tvalid_0's tweedie: 257.497\n",
      "[105]\tvalid_0's tweedie: 257.498\n",
      "[106]\tvalid_0's tweedie: 257.498\n",
      "[107]\tvalid_0's tweedie: 257.497\n",
      "[108]\tvalid_0's tweedie: 257.497\n",
      "[109]\tvalid_0's tweedie: 257.497\n",
      "[110]\tvalid_0's tweedie: 257.497\n",
      "[111]\tvalid_0's tweedie: 257.497\n",
      "[112]\tvalid_0's tweedie: 257.497\n",
      "[113]\tvalid_0's tweedie: 257.497\n",
      "[114]\tvalid_0's tweedie: 257.498\n",
      "[115]\tvalid_0's tweedie: 257.498\n",
      "[116]\tvalid_0's tweedie: 257.498\n",
      "[117]\tvalid_0's tweedie: 257.498\n",
      "[118]\tvalid_0's tweedie: 257.498\n",
      "[119]\tvalid_0's tweedie: 257.498\n",
      "[120]\tvalid_0's tweedie: 257.498\n",
      "[121]\tvalid_0's tweedie: 257.498\n",
      "[122]\tvalid_0's tweedie: 257.498\n",
      "[123]\tvalid_0's tweedie: 257.499\n",
      "[124]\tvalid_0's tweedie: 257.499\n",
      "[125]\tvalid_0's tweedie: 257.499\n",
      "[126]\tvalid_0's tweedie: 257.499\n",
      "[127]\tvalid_0's tweedie: 257.499\n",
      "[128]\tvalid_0's tweedie: 257.499\n",
      "[129]\tvalid_0's tweedie: 257.499\n",
      "[130]\tvalid_0's tweedie: 257.499\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's tweedie: 257.497\n",
      "Training model for level 3 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5512\n",
      "[LightGBM] [Info] Number of data points in the train set: 18670, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.139901\n",
      "[1]\tvalid_0's tweedie: 260.809\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.22\n",
      "[3]\tvalid_0's tweedie: 259.741\n",
      "[4]\tvalid_0's tweedie: 259.359\n",
      "[5]\tvalid_0's tweedie: 259.046\n",
      "[6]\tvalid_0's tweedie: 258.787\n",
      "[7]\tvalid_0's tweedie: 258.575\n",
      "[8]\tvalid_0's tweedie: 258.395\n",
      "[9]\tvalid_0's tweedie: 258.242\n",
      "[10]\tvalid_0's tweedie: 258.122\n",
      "[11]\tvalid_0's tweedie: 258.022\n",
      "[12]\tvalid_0's tweedie: 257.94\n",
      "[13]\tvalid_0's tweedie: 257.872\n",
      "[14]\tvalid_0's tweedie: 257.818\n",
      "[15]\tvalid_0's tweedie: 257.768\n",
      "[16]\tvalid_0's tweedie: 257.731\n",
      "[17]\tvalid_0's tweedie: 257.701\n",
      "[18]\tvalid_0's tweedie: 257.676\n",
      "[19]\tvalid_0's tweedie: 257.652\n",
      "[20]\tvalid_0's tweedie: 257.633\n",
      "[21]\tvalid_0's tweedie: 257.614\n",
      "[22]\tvalid_0's tweedie: 257.597\n",
      "[23]\tvalid_0's tweedie: 257.588\n",
      "[24]\tvalid_0's tweedie: 257.579\n",
      "[25]\tvalid_0's tweedie: 257.574\n",
      "[26]\tvalid_0's tweedie: 257.569\n",
      "[27]\tvalid_0's tweedie: 257.562\n",
      "[28]\tvalid_0's tweedie: 257.556\n",
      "[29]\tvalid_0's tweedie: 257.552\n",
      "[30]\tvalid_0's tweedie: 257.549\n",
      "[31]\tvalid_0's tweedie: 257.546\n",
      "[32]\tvalid_0's tweedie: 257.544\n",
      "[33]\tvalid_0's tweedie: 257.541\n",
      "[34]\tvalid_0's tweedie: 257.538\n",
      "[35]\tvalid_0's tweedie: 257.536\n",
      "[36]\tvalid_0's tweedie: 257.535\n",
      "[37]\tvalid_0's tweedie: 257.534\n",
      "[38]\tvalid_0's tweedie: 257.531\n",
      "[39]\tvalid_0's tweedie: 257.53\n",
      "[40]\tvalid_0's tweedie: 257.533\n",
      "[41]\tvalid_0's tweedie: 257.529\n",
      "[42]\tvalid_0's tweedie: 257.529\n",
      "[43]\tvalid_0's tweedie: 257.53\n",
      "[44]\tvalid_0's tweedie: 257.528\n",
      "[45]\tvalid_0's tweedie: 257.526\n",
      "[46]\tvalid_0's tweedie: 257.528\n",
      "[47]\tvalid_0's tweedie: 257.527\n",
      "[48]\tvalid_0's tweedie: 257.528\n",
      "[49]\tvalid_0's tweedie: 257.527\n",
      "[50]\tvalid_0's tweedie: 257.526\n",
      "[51]\tvalid_0's tweedie: 257.525\n",
      "[52]\tvalid_0's tweedie: 257.524\n",
      "[53]\tvalid_0's tweedie: 257.523\n",
      "[54]\tvalid_0's tweedie: 257.524\n",
      "[55]\tvalid_0's tweedie: 257.522\n",
      "[56]\tvalid_0's tweedie: 257.522\n",
      "[57]\tvalid_0's tweedie: 257.52\n",
      "[58]\tvalid_0's tweedie: 257.52\n",
      "[59]\tvalid_0's tweedie: 257.521\n",
      "[60]\tvalid_0's tweedie: 257.521\n",
      "[61]\tvalid_0's tweedie: 257.517\n",
      "[62]\tvalid_0's tweedie: 257.519\n",
      "[63]\tvalid_0's tweedie: 257.52\n",
      "[64]\tvalid_0's tweedie: 257.52\n",
      "[65]\tvalid_0's tweedie: 257.519\n",
      "[66]\tvalid_0's tweedie: 257.519\n",
      "[67]\tvalid_0's tweedie: 257.517\n",
      "[68]\tvalid_0's tweedie: 257.515\n",
      "[69]\tvalid_0's tweedie: 257.516\n",
      "[70]\tvalid_0's tweedie: 257.516\n",
      "[71]\tvalid_0's tweedie: 257.515\n",
      "[72]\tvalid_0's tweedie: 257.513\n",
      "[73]\tvalid_0's tweedie: 257.513\n",
      "[74]\tvalid_0's tweedie: 257.513\n",
      "[75]\tvalid_0's tweedie: 257.513\n",
      "[76]\tvalid_0's tweedie: 257.514\n",
      "[77]\tvalid_0's tweedie: 257.513\n",
      "[78]\tvalid_0's tweedie: 257.513\n",
      "[79]\tvalid_0's tweedie: 257.511\n",
      "[80]\tvalid_0's tweedie: 257.51\n",
      "[81]\tvalid_0's tweedie: 257.51\n",
      "[82]\tvalid_0's tweedie: 257.51\n",
      "[83]\tvalid_0's tweedie: 257.51\n",
      "[84]\tvalid_0's tweedie: 257.51\n",
      "[85]\tvalid_0's tweedie: 257.51\n",
      "[86]\tvalid_0's tweedie: 257.51\n",
      "[87]\tvalid_0's tweedie: 257.51\n",
      "[88]\tvalid_0's tweedie: 257.509\n",
      "[89]\tvalid_0's tweedie: 257.509\n",
      "[90]\tvalid_0's tweedie: 257.51\n",
      "[91]\tvalid_0's tweedie: 257.51\n",
      "[92]\tvalid_0's tweedie: 257.51\n",
      "[93]\tvalid_0's tweedie: 257.51\n",
      "[94]\tvalid_0's tweedie: 257.51\n",
      "[95]\tvalid_0's tweedie: 257.51\n",
      "[96]\tvalid_0's tweedie: 257.51\n",
      "[97]\tvalid_0's tweedie: 257.509\n",
      "[98]\tvalid_0's tweedie: 257.507\n",
      "[99]\tvalid_0's tweedie: 257.507\n",
      "[100]\tvalid_0's tweedie: 257.507\n",
      "[101]\tvalid_0's tweedie: 257.507\n",
      "[102]\tvalid_0's tweedie: 257.507\n",
      "[103]\tvalid_0's tweedie: 257.507\n",
      "[104]\tvalid_0's tweedie: 257.506\n",
      "[105]\tvalid_0's tweedie: 257.506\n",
      "[106]\tvalid_0's tweedie: 257.506\n",
      "[107]\tvalid_0's tweedie: 257.507\n",
      "[108]\tvalid_0's tweedie: 257.506\n",
      "[109]\tvalid_0's tweedie: 257.506\n",
      "[110]\tvalid_0's tweedie: 257.506\n",
      "[111]\tvalid_0's tweedie: 257.506\n",
      "[112]\tvalid_0's tweedie: 257.506\n",
      "[113]\tvalid_0's tweedie: 257.506\n",
      "[114]\tvalid_0's tweedie: 257.506\n",
      "[115]\tvalid_0's tweedie: 257.506\n",
      "[116]\tvalid_0's tweedie: 257.506\n",
      "[117]\tvalid_0's tweedie: 257.506\n",
      "[118]\tvalid_0's tweedie: 257.506\n",
      "[119]\tvalid_0's tweedie: 257.506\n",
      "[120]\tvalid_0's tweedie: 257.506\n",
      "[121]\tvalid_0's tweedie: 257.505\n",
      "[122]\tvalid_0's tweedie: 257.505\n",
      "[123]\tvalid_0's tweedie: 257.505\n",
      "[124]\tvalid_0's tweedie: 257.505\n",
      "[125]\tvalid_0's tweedie: 257.505\n",
      "[126]\tvalid_0's tweedie: 257.505\n",
      "[127]\tvalid_0's tweedie: 257.506\n",
      "[128]\tvalid_0's tweedie: 257.506\n",
      "[129]\tvalid_0's tweedie: 257.506\n",
      "[130]\tvalid_0's tweedie: 257.506\n",
      "[131]\tvalid_0's tweedie: 257.505\n",
      "[132]\tvalid_0's tweedie: 257.505\n",
      "[133]\tvalid_0's tweedie: 257.505\n",
      "[134]\tvalid_0's tweedie: 257.505\n",
      "[135]\tvalid_0's tweedie: 257.505\n",
      "[136]\tvalid_0's tweedie: 257.505\n",
      "[137]\tvalid_0's tweedie: 257.505\n",
      "[138]\tvalid_0's tweedie: 257.505\n",
      "[139]\tvalid_0's tweedie: 257.505\n",
      "[140]\tvalid_0's tweedie: 257.505\n",
      "[141]\tvalid_0's tweedie: 257.505\n",
      "[142]\tvalid_0's tweedie: 257.504\n",
      "[143]\tvalid_0's tweedie: 257.505\n",
      "[144]\tvalid_0's tweedie: 257.505\n",
      "[145]\tvalid_0's tweedie: 257.505\n",
      "[146]\tvalid_0's tweedie: 257.504\n",
      "[147]\tvalid_0's tweedie: 257.504\n",
      "[148]\tvalid_0's tweedie: 257.503\n",
      "[149]\tvalid_0's tweedie: 257.503\n",
      "[150]\tvalid_0's tweedie: 257.503\n",
      "[151]\tvalid_0's tweedie: 257.504\n",
      "[152]\tvalid_0's tweedie: 257.503\n",
      "[153]\tvalid_0's tweedie: 257.502\n",
      "[154]\tvalid_0's tweedie: 257.502\n",
      "[155]\tvalid_0's tweedie: 257.502\n",
      "[156]\tvalid_0's tweedie: 257.502\n",
      "[157]\tvalid_0's tweedie: 257.502\n",
      "[158]\tvalid_0's tweedie: 257.502\n",
      "[159]\tvalid_0's tweedie: 257.501\n",
      "[160]\tvalid_0's tweedie: 257.501\n",
      "[161]\tvalid_0's tweedie: 257.501\n",
      "[162]\tvalid_0's tweedie: 257.502\n",
      "[163]\tvalid_0's tweedie: 257.502\n",
      "[164]\tvalid_0's tweedie: 257.501\n",
      "[165]\tvalid_0's tweedie: 257.501\n",
      "[166]\tvalid_0's tweedie: 257.501\n",
      "[167]\tvalid_0's tweedie: 257.501\n",
      "[168]\tvalid_0's tweedie: 257.501\n",
      "[169]\tvalid_0's tweedie: 257.501\n",
      "[170]\tvalid_0's tweedie: 257.501\n",
      "[171]\tvalid_0's tweedie: 257.501\n",
      "[172]\tvalid_0's tweedie: 257.501\n",
      "[173]\tvalid_0's tweedie: 257.501\n",
      "[174]\tvalid_0's tweedie: 257.501\n",
      "[175]\tvalid_0's tweedie: 257.502\n",
      "[176]\tvalid_0's tweedie: 257.502\n",
      "[177]\tvalid_0's tweedie: 257.502\n",
      "[178]\tvalid_0's tweedie: 257.502\n",
      "[179]\tvalid_0's tweedie: 257.502\n",
      "[180]\tvalid_0's tweedie: 257.502\n",
      "[181]\tvalid_0's tweedie: 257.502\n",
      "[182]\tvalid_0's tweedie: 257.502\n",
      "[183]\tvalid_0's tweedie: 257.503\n",
      "[184]\tvalid_0's tweedie: 257.503\n",
      "[185]\tvalid_0's tweedie: 257.503\n",
      "[186]\tvalid_0's tweedie: 257.503\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's tweedie: 257.501\n",
      "Training model for level 3 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5511\n",
      "[LightGBM] [Info] Number of data points in the train set: 18660, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140102\n",
      "[1]\tvalid_0's tweedie: 260.801\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.214\n",
      "[3]\tvalid_0's tweedie: 259.744\n",
      "[4]\tvalid_0's tweedie: 259.355\n",
      "[5]\tvalid_0's tweedie: 259.037\n",
      "[6]\tvalid_0's tweedie: 258.771\n",
      "[7]\tvalid_0's tweedie: 258.563\n",
      "[8]\tvalid_0's tweedie: 258.399\n",
      "[9]\tvalid_0's tweedie: 258.259\n",
      "[10]\tvalid_0's tweedie: 258.138\n",
      "[11]\tvalid_0's tweedie: 258.035\n",
      "[12]\tvalid_0's tweedie: 257.955\n",
      "[13]\tvalid_0's tweedie: 257.889\n",
      "[14]\tvalid_0's tweedie: 257.835\n",
      "[15]\tvalid_0's tweedie: 257.784\n",
      "[16]\tvalid_0's tweedie: 257.743\n",
      "[17]\tvalid_0's tweedie: 257.709\n",
      "[18]\tvalid_0's tweedie: 257.68\n",
      "[19]\tvalid_0's tweedie: 257.658\n",
      "[20]\tvalid_0's tweedie: 257.64\n",
      "[21]\tvalid_0's tweedie: 257.623\n",
      "[22]\tvalid_0's tweedie: 257.609\n",
      "[23]\tvalid_0's tweedie: 257.597\n",
      "[24]\tvalid_0's tweedie: 257.588\n",
      "[25]\tvalid_0's tweedie: 257.58\n",
      "[26]\tvalid_0's tweedie: 257.573\n",
      "[27]\tvalid_0's tweedie: 257.57\n",
      "[28]\tvalid_0's tweedie: 257.565\n",
      "[29]\tvalid_0's tweedie: 257.558\n",
      "[30]\tvalid_0's tweedie: 257.554\n",
      "[31]\tvalid_0's tweedie: 257.551\n",
      "[32]\tvalid_0's tweedie: 257.547\n",
      "[33]\tvalid_0's tweedie: 257.543\n",
      "[34]\tvalid_0's tweedie: 257.54\n",
      "[35]\tvalid_0's tweedie: 257.541\n",
      "[36]\tvalid_0's tweedie: 257.54\n",
      "[37]\tvalid_0's tweedie: 257.537\n",
      "[38]\tvalid_0's tweedie: 257.536\n",
      "[39]\tvalid_0's tweedie: 257.535\n",
      "[40]\tvalid_0's tweedie: 257.534\n",
      "[41]\tvalid_0's tweedie: 257.537\n",
      "[42]\tvalid_0's tweedie: 257.535\n",
      "[43]\tvalid_0's tweedie: 257.533\n",
      "[44]\tvalid_0's tweedie: 257.532\n",
      "[45]\tvalid_0's tweedie: 257.531\n",
      "[46]\tvalid_0's tweedie: 257.531\n",
      "[47]\tvalid_0's tweedie: 257.528\n",
      "[48]\tvalid_0's tweedie: 257.53\n",
      "[49]\tvalid_0's tweedie: 257.529\n",
      "[50]\tvalid_0's tweedie: 257.527\n",
      "[51]\tvalid_0's tweedie: 257.525\n",
      "[52]\tvalid_0's tweedie: 257.525\n",
      "[53]\tvalid_0's tweedie: 257.525\n",
      "[54]\tvalid_0's tweedie: 257.522\n",
      "[55]\tvalid_0's tweedie: 257.521\n",
      "[56]\tvalid_0's tweedie: 257.52\n",
      "[57]\tvalid_0's tweedie: 257.519\n",
      "[58]\tvalid_0's tweedie: 257.518\n",
      "[59]\tvalid_0's tweedie: 257.516\n",
      "[60]\tvalid_0's tweedie: 257.516\n",
      "[61]\tvalid_0's tweedie: 257.515\n",
      "[62]\tvalid_0's tweedie: 257.517\n",
      "[63]\tvalid_0's tweedie: 257.518\n",
      "[64]\tvalid_0's tweedie: 257.518\n",
      "[65]\tvalid_0's tweedie: 257.516\n",
      "[66]\tvalid_0's tweedie: 257.515\n",
      "[67]\tvalid_0's tweedie: 257.514\n",
      "[68]\tvalid_0's tweedie: 257.514\n",
      "[69]\tvalid_0's tweedie: 257.514\n",
      "[70]\tvalid_0's tweedie: 257.514\n",
      "[71]\tvalid_0's tweedie: 257.515\n",
      "[72]\tvalid_0's tweedie: 257.513\n",
      "[73]\tvalid_0's tweedie: 257.512\n",
      "[74]\tvalid_0's tweedie: 257.512\n",
      "[75]\tvalid_0's tweedie: 257.512\n",
      "[76]\tvalid_0's tweedie: 257.512\n",
      "[77]\tvalid_0's tweedie: 257.512\n",
      "[78]\tvalid_0's tweedie: 257.512\n",
      "[79]\tvalid_0's tweedie: 257.513\n",
      "[80]\tvalid_0's tweedie: 257.512\n",
      "[81]\tvalid_0's tweedie: 257.509\n",
      "[82]\tvalid_0's tweedie: 257.509\n",
      "[83]\tvalid_0's tweedie: 257.509\n",
      "[84]\tvalid_0's tweedie: 257.509\n",
      "[85]\tvalid_0's tweedie: 257.51\n",
      "[86]\tvalid_0's tweedie: 257.509\n",
      "[87]\tvalid_0's tweedie: 257.509\n",
      "[88]\tvalid_0's tweedie: 257.508\n",
      "[89]\tvalid_0's tweedie: 257.508\n",
      "[90]\tvalid_0's tweedie: 257.509\n",
      "[91]\tvalid_0's tweedie: 257.508\n",
      "[92]\tvalid_0's tweedie: 257.508\n",
      "[93]\tvalid_0's tweedie: 257.508\n",
      "[94]\tvalid_0's tweedie: 257.507\n",
      "[95]\tvalid_0's tweedie: 257.507\n",
      "[96]\tvalid_0's tweedie: 257.507\n",
      "[97]\tvalid_0's tweedie: 257.508\n",
      "[98]\tvalid_0's tweedie: 257.508\n",
      "[99]\tvalid_0's tweedie: 257.509\n",
      "[100]\tvalid_0's tweedie: 257.508\n",
      "[101]\tvalid_0's tweedie: 257.508\n",
      "[102]\tvalid_0's tweedie: 257.508\n",
      "[103]\tvalid_0's tweedie: 257.508\n",
      "[104]\tvalid_0's tweedie: 257.508\n",
      "[105]\tvalid_0's tweedie: 257.508\n",
      "[106]\tvalid_0's tweedie: 257.505\n",
      "[107]\tvalid_0's tweedie: 257.505\n",
      "[108]\tvalid_0's tweedie: 257.505\n",
      "[109]\tvalid_0's tweedie: 257.505\n",
      "[110]\tvalid_0's tweedie: 257.502\n",
      "[111]\tvalid_0's tweedie: 257.502\n",
      "[112]\tvalid_0's tweedie: 257.502\n",
      "[113]\tvalid_0's tweedie: 257.502\n",
      "[114]\tvalid_0's tweedie: 257.502\n",
      "[115]\tvalid_0's tweedie: 257.502\n",
      "[116]\tvalid_0's tweedie: 257.502\n",
      "[117]\tvalid_0's tweedie: 257.502\n",
      "[118]\tvalid_0's tweedie: 257.502\n",
      "[119]\tvalid_0's tweedie: 257.502\n",
      "[120]\tvalid_0's tweedie: 257.502\n",
      "[121]\tvalid_0's tweedie: 257.502\n",
      "[122]\tvalid_0's tweedie: 257.502\n",
      "[123]\tvalid_0's tweedie: 257.502\n",
      "[124]\tvalid_0's tweedie: 257.502\n",
      "[125]\tvalid_0's tweedie: 257.501\n",
      "[126]\tvalid_0's tweedie: 257.501\n",
      "[127]\tvalid_0's tweedie: 257.501\n",
      "[128]\tvalid_0's tweedie: 257.501\n",
      "[129]\tvalid_0's tweedie: 257.5\n",
      "[130]\tvalid_0's tweedie: 257.5\n",
      "[131]\tvalid_0's tweedie: 257.5\n",
      "[132]\tvalid_0's tweedie: 257.5\n",
      "[133]\tvalid_0's tweedie: 257.498\n",
      "[134]\tvalid_0's tweedie: 257.499\n",
      "[135]\tvalid_0's tweedie: 257.499\n",
      "[136]\tvalid_0's tweedie: 257.499\n",
      "[137]\tvalid_0's tweedie: 257.498\n",
      "[138]\tvalid_0's tweedie: 257.498\n",
      "[139]\tvalid_0's tweedie: 257.498\n",
      "[140]\tvalid_0's tweedie: 257.498\n",
      "[141]\tvalid_0's tweedie: 257.498\n",
      "[142]\tvalid_0's tweedie: 257.497\n",
      "[143]\tvalid_0's tweedie: 257.497\n",
      "[144]\tvalid_0's tweedie: 257.497\n",
      "[145]\tvalid_0's tweedie: 257.497\n",
      "[146]\tvalid_0's tweedie: 257.496\n",
      "[147]\tvalid_0's tweedie: 257.497\n",
      "[148]\tvalid_0's tweedie: 257.496\n",
      "[149]\tvalid_0's tweedie: 257.496\n",
      "[150]\tvalid_0's tweedie: 257.496\n",
      "[151]\tvalid_0's tweedie: 257.496\n",
      "[152]\tvalid_0's tweedie: 257.496\n",
      "[153]\tvalid_0's tweedie: 257.496\n",
      "[154]\tvalid_0's tweedie: 257.496\n",
      "[155]\tvalid_0's tweedie: 257.496\n",
      "[156]\tvalid_0's tweedie: 257.496\n",
      "[157]\tvalid_0's tweedie: 257.496\n",
      "[158]\tvalid_0's tweedie: 257.496\n",
      "[159]\tvalid_0's tweedie: 257.496\n",
      "[160]\tvalid_0's tweedie: 257.496\n",
      "[161]\tvalid_0's tweedie: 257.496\n",
      "[162]\tvalid_0's tweedie: 257.496\n",
      "[163]\tvalid_0's tweedie: 257.496\n",
      "[164]\tvalid_0's tweedie: 257.496\n",
      "[165]\tvalid_0's tweedie: 257.496\n",
      "[166]\tvalid_0's tweedie: 257.496\n",
      "[167]\tvalid_0's tweedie: 257.496\n",
      "[168]\tvalid_0's tweedie: 257.496\n",
      "[169]\tvalid_0's tweedie: 257.496\n",
      "[170]\tvalid_0's tweedie: 257.497\n",
      "[171]\tvalid_0's tweedie: 257.496\n",
      "[172]\tvalid_0's tweedie: 257.496\n",
      "[173]\tvalid_0's tweedie: 257.496\n",
      "[174]\tvalid_0's tweedie: 257.496\n",
      "[175]\tvalid_0's tweedie: 257.496\n",
      "[176]\tvalid_0's tweedie: 257.496\n",
      "[177]\tvalid_0's tweedie: 257.496\n",
      "[178]\tvalid_0's tweedie: 257.496\n",
      "[179]\tvalid_0's tweedie: 257.496\n",
      "[180]\tvalid_0's tweedie: 257.496\n",
      "[181]\tvalid_0's tweedie: 257.496\n",
      "[182]\tvalid_0's tweedie: 257.496\n",
      "[183]\tvalid_0's tweedie: 257.496\n",
      "[184]\tvalid_0's tweedie: 257.496\n",
      "[185]\tvalid_0's tweedie: 257.496\n",
      "[186]\tvalid_0's tweedie: 257.497\n",
      "[187]\tvalid_0's tweedie: 257.497\n",
      "[188]\tvalid_0's tweedie: 257.497\n",
      "[189]\tvalid_0's tweedie: 257.498\n",
      "[190]\tvalid_0's tweedie: 257.498\n",
      "[191]\tvalid_0's tweedie: 257.498\n",
      "[192]\tvalid_0's tweedie: 257.498\n",
      "[193]\tvalid_0's tweedie: 257.499\n",
      "[194]\tvalid_0's tweedie: 257.499\n",
      "[195]\tvalid_0's tweedie: 257.499\n",
      "[196]\tvalid_0's tweedie: 257.499\n",
      "[197]\tvalid_0's tweedie: 257.499\n",
      "[198]\tvalid_0's tweedie: 257.499\n",
      "[199]\tvalid_0's tweedie: 257.499\n",
      "[200]\tvalid_0's tweedie: 257.499\n",
      "[201]\tvalid_0's tweedie: 257.499\n",
      "[202]\tvalid_0's tweedie: 257.499\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's tweedie: 257.496\n",
      "Training model for level 3 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5510\n",
      "[LightGBM] [Info] Number of data points in the train set: 18650, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140321\n",
      "[1]\tvalid_0's tweedie: 260.804\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.215\n",
      "[3]\tvalid_0's tweedie: 259.733\n",
      "[4]\tvalid_0's tweedie: 259.349\n",
      "[5]\tvalid_0's tweedie: 259.029\n",
      "[6]\tvalid_0's tweedie: 258.767\n",
      "[7]\tvalid_0's tweedie: 258.563\n",
      "[8]\tvalid_0's tweedie: 258.385\n",
      "[9]\tvalid_0's tweedie: 258.238\n",
      "[10]\tvalid_0's tweedie: 258.118\n",
      "[11]\tvalid_0's tweedie: 258.016\n",
      "[12]\tvalid_0's tweedie: 257.936\n",
      "[13]\tvalid_0's tweedie: 257.873\n",
      "[14]\tvalid_0's tweedie: 257.819\n",
      "[15]\tvalid_0's tweedie: 257.777\n",
      "[16]\tvalid_0's tweedie: 257.737\n",
      "[17]\tvalid_0's tweedie: 257.708\n",
      "[18]\tvalid_0's tweedie: 257.674\n",
      "[19]\tvalid_0's tweedie: 257.652\n",
      "[20]\tvalid_0's tweedie: 257.631\n",
      "[21]\tvalid_0's tweedie: 257.613\n",
      "[22]\tvalid_0's tweedie: 257.6\n",
      "[23]\tvalid_0's tweedie: 257.592\n",
      "[24]\tvalid_0's tweedie: 257.581\n",
      "[25]\tvalid_0's tweedie: 257.574\n",
      "[26]\tvalid_0's tweedie: 257.567\n",
      "[27]\tvalid_0's tweedie: 257.561\n",
      "[28]\tvalid_0's tweedie: 257.554\n",
      "[29]\tvalid_0's tweedie: 257.55\n",
      "[30]\tvalid_0's tweedie: 257.544\n",
      "[31]\tvalid_0's tweedie: 257.541\n",
      "[32]\tvalid_0's tweedie: 257.537\n",
      "[33]\tvalid_0's tweedie: 257.533\n",
      "[34]\tvalid_0's tweedie: 257.533\n",
      "[35]\tvalid_0's tweedie: 257.531\n",
      "[36]\tvalid_0's tweedie: 257.53\n",
      "[37]\tvalid_0's tweedie: 257.527\n",
      "[38]\tvalid_0's tweedie: 257.526\n",
      "[39]\tvalid_0's tweedie: 257.527\n",
      "[40]\tvalid_0's tweedie: 257.526\n",
      "[41]\tvalid_0's tweedie: 257.528\n",
      "[42]\tvalid_0's tweedie: 257.527\n",
      "[43]\tvalid_0's tweedie: 257.526\n",
      "[44]\tvalid_0's tweedie: 257.523\n",
      "[45]\tvalid_0's tweedie: 257.523\n",
      "[46]\tvalid_0's tweedie: 257.524\n",
      "[47]\tvalid_0's tweedie: 257.528\n",
      "[48]\tvalid_0's tweedie: 257.525\n",
      "[49]\tvalid_0's tweedie: 257.524\n",
      "[50]\tvalid_0's tweedie: 257.523\n",
      "[51]\tvalid_0's tweedie: 257.522\n",
      "[52]\tvalid_0's tweedie: 257.523\n",
      "[53]\tvalid_0's tweedie: 257.522\n",
      "[54]\tvalid_0's tweedie: 257.521\n",
      "[55]\tvalid_0's tweedie: 257.522\n",
      "[56]\tvalid_0's tweedie: 257.522\n",
      "[57]\tvalid_0's tweedie: 257.523\n",
      "[58]\tvalid_0's tweedie: 257.522\n",
      "[59]\tvalid_0's tweedie: 257.52\n",
      "[60]\tvalid_0's tweedie: 257.518\n",
      "[61]\tvalid_0's tweedie: 257.518\n",
      "[62]\tvalid_0's tweedie: 257.516\n",
      "[63]\tvalid_0's tweedie: 257.513\n",
      "[64]\tvalid_0's tweedie: 257.513\n",
      "[65]\tvalid_0's tweedie: 257.513\n",
      "[66]\tvalid_0's tweedie: 257.514\n",
      "[67]\tvalid_0's tweedie: 257.513\n",
      "[68]\tvalid_0's tweedie: 257.513\n",
      "[69]\tvalid_0's tweedie: 257.511\n",
      "[70]\tvalid_0's tweedie: 257.511\n",
      "[71]\tvalid_0's tweedie: 257.51\n",
      "[72]\tvalid_0's tweedie: 257.509\n",
      "[73]\tvalid_0's tweedie: 257.508\n",
      "[74]\tvalid_0's tweedie: 257.508\n",
      "[75]\tvalid_0's tweedie: 257.508\n",
      "[76]\tvalid_0's tweedie: 257.507\n",
      "[77]\tvalid_0's tweedie: 257.507\n",
      "[78]\tvalid_0's tweedie: 257.507\n",
      "[79]\tvalid_0's tweedie: 257.504\n",
      "[80]\tvalid_0's tweedie: 257.504\n",
      "[81]\tvalid_0's tweedie: 257.504\n",
      "[82]\tvalid_0's tweedie: 257.505\n",
      "[83]\tvalid_0's tweedie: 257.505\n",
      "[84]\tvalid_0's tweedie: 257.505\n",
      "[85]\tvalid_0's tweedie: 257.505\n",
      "[86]\tvalid_0's tweedie: 257.505\n",
      "[87]\tvalid_0's tweedie: 257.505\n",
      "[88]\tvalid_0's tweedie: 257.505\n",
      "[89]\tvalid_0's tweedie: 257.505\n",
      "[90]\tvalid_0's tweedie: 257.504\n",
      "[91]\tvalid_0's tweedie: 257.503\n",
      "[92]\tvalid_0's tweedie: 257.503\n",
      "[93]\tvalid_0's tweedie: 257.502\n",
      "[94]\tvalid_0's tweedie: 257.502\n",
      "[95]\tvalid_0's tweedie: 257.501\n",
      "[96]\tvalid_0's tweedie: 257.501\n",
      "[97]\tvalid_0's tweedie: 257.501\n",
      "[98]\tvalid_0's tweedie: 257.502\n",
      "[99]\tvalid_0's tweedie: 257.502\n",
      "[100]\tvalid_0's tweedie: 257.502\n",
      "[101]\tvalid_0's tweedie: 257.502\n",
      "[102]\tvalid_0's tweedie: 257.502\n",
      "[103]\tvalid_0's tweedie: 257.501\n",
      "[104]\tvalid_0's tweedie: 257.501\n",
      "[105]\tvalid_0's tweedie: 257.501\n",
      "[106]\tvalid_0's tweedie: 257.501\n",
      "[107]\tvalid_0's tweedie: 257.501\n",
      "[108]\tvalid_0's tweedie: 257.501\n",
      "[109]\tvalid_0's tweedie: 257.5\n",
      "[110]\tvalid_0's tweedie: 257.5\n",
      "[111]\tvalid_0's tweedie: 257.499\n",
      "[112]\tvalid_0's tweedie: 257.498\n",
      "[113]\tvalid_0's tweedie: 257.499\n",
      "[114]\tvalid_0's tweedie: 257.499\n",
      "[115]\tvalid_0's tweedie: 257.499\n",
      "[116]\tvalid_0's tweedie: 257.499\n",
      "[117]\tvalid_0's tweedie: 257.499\n",
      "[118]\tvalid_0's tweedie: 257.499\n",
      "[119]\tvalid_0's tweedie: 257.498\n",
      "[120]\tvalid_0's tweedie: 257.498\n",
      "[121]\tvalid_0's tweedie: 257.498\n",
      "[122]\tvalid_0's tweedie: 257.498\n",
      "[123]\tvalid_0's tweedie: 257.498\n",
      "[124]\tvalid_0's tweedie: 257.498\n",
      "[125]\tvalid_0's tweedie: 257.498\n",
      "[126]\tvalid_0's tweedie: 257.498\n",
      "[127]\tvalid_0's tweedie: 257.498\n",
      "[128]\tvalid_0's tweedie: 257.497\n",
      "[129]\tvalid_0's tweedie: 257.497\n",
      "[130]\tvalid_0's tweedie: 257.497\n",
      "[131]\tvalid_0's tweedie: 257.497\n",
      "[132]\tvalid_0's tweedie: 257.498\n",
      "[133]\tvalid_0's tweedie: 257.498\n",
      "[134]\tvalid_0's tweedie: 257.498\n",
      "[135]\tvalid_0's tweedie: 257.498\n",
      "[136]\tvalid_0's tweedie: 257.498\n",
      "[137]\tvalid_0's tweedie: 257.498\n",
      "[138]\tvalid_0's tweedie: 257.498\n",
      "[139]\tvalid_0's tweedie: 257.5\n",
      "[140]\tvalid_0's tweedie: 257.499\n",
      "[141]\tvalid_0's tweedie: 257.499\n",
      "[142]\tvalid_0's tweedie: 257.499\n",
      "[143]\tvalid_0's tweedie: 257.499\n",
      "[144]\tvalid_0's tweedie: 257.499\n",
      "[145]\tvalid_0's tweedie: 257.499\n",
      "[146]\tvalid_0's tweedie: 257.499\n",
      "[147]\tvalid_0's tweedie: 257.499\n",
      "[148]\tvalid_0's tweedie: 257.499\n",
      "[149]\tvalid_0's tweedie: 257.499\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's tweedie: 257.497\n",
      "Training model for level 3 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 18640, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140486\n",
      "[1]\tvalid_0's tweedie: 260.853\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.347\n",
      "[3]\tvalid_0's tweedie: 259.899\n",
      "[4]\tvalid_0's tweedie: 259.516\n",
      "[5]\tvalid_0's tweedie: 259.192\n",
      "[6]\tvalid_0's tweedie: 258.948\n",
      "[7]\tvalid_0's tweedie: 258.73\n",
      "[8]\tvalid_0's tweedie: 258.574\n",
      "[9]\tvalid_0's tweedie: 258.425\n",
      "[10]\tvalid_0's tweedie: 258.32\n",
      "[11]\tvalid_0's tweedie: 258.215\n",
      "[12]\tvalid_0's tweedie: 258.126\n",
      "[13]\tvalid_0's tweedie: 258.053\n",
      "[14]\tvalid_0's tweedie: 257.989\n",
      "[15]\tvalid_0's tweedie: 257.932\n",
      "[16]\tvalid_0's tweedie: 257.885\n",
      "[17]\tvalid_0's tweedie: 257.846\n",
      "[18]\tvalid_0's tweedie: 257.816\n",
      "[19]\tvalid_0's tweedie: 257.787\n",
      "[20]\tvalid_0's tweedie: 257.762\n",
      "[21]\tvalid_0's tweedie: 257.742\n",
      "[22]\tvalid_0's tweedie: 257.722\n",
      "[23]\tvalid_0's tweedie: 257.709\n",
      "[24]\tvalid_0's tweedie: 257.696\n",
      "[25]\tvalid_0's tweedie: 257.69\n",
      "[26]\tvalid_0's tweedie: 257.681\n",
      "[27]\tvalid_0's tweedie: 257.673\n",
      "[28]\tvalid_0's tweedie: 257.667\n",
      "[29]\tvalid_0's tweedie: 257.66\n",
      "[30]\tvalid_0's tweedie: 257.653\n",
      "[31]\tvalid_0's tweedie: 257.647\n",
      "[32]\tvalid_0's tweedie: 257.645\n",
      "[33]\tvalid_0's tweedie: 257.642\n",
      "[34]\tvalid_0's tweedie: 257.641\n",
      "[35]\tvalid_0's tweedie: 257.64\n",
      "[36]\tvalid_0's tweedie: 257.64\n",
      "[37]\tvalid_0's tweedie: 257.637\n",
      "[38]\tvalid_0's tweedie: 257.64\n",
      "[39]\tvalid_0's tweedie: 257.638\n",
      "[40]\tvalid_0's tweedie: 257.636\n",
      "[41]\tvalid_0's tweedie: 257.634\n",
      "[42]\tvalid_0's tweedie: 257.633\n",
      "[43]\tvalid_0's tweedie: 257.636\n",
      "[44]\tvalid_0's tweedie: 257.634\n",
      "[45]\tvalid_0's tweedie: 257.633\n",
      "[46]\tvalid_0's tweedie: 257.631\n",
      "[47]\tvalid_0's tweedie: 257.626\n",
      "[48]\tvalid_0's tweedie: 257.631\n",
      "[49]\tvalid_0's tweedie: 257.63\n",
      "[50]\tvalid_0's tweedie: 257.63\n",
      "[51]\tvalid_0's tweedie: 257.626\n",
      "[52]\tvalid_0's tweedie: 257.626\n",
      "[53]\tvalid_0's tweedie: 257.627\n",
      "[54]\tvalid_0's tweedie: 257.625\n",
      "[55]\tvalid_0's tweedie: 257.623\n",
      "[56]\tvalid_0's tweedie: 257.621\n",
      "[57]\tvalid_0's tweedie: 257.618\n",
      "[58]\tvalid_0's tweedie: 257.616\n",
      "[59]\tvalid_0's tweedie: 257.614\n",
      "[60]\tvalid_0's tweedie: 257.614\n",
      "[61]\tvalid_0's tweedie: 257.613\n",
      "[62]\tvalid_0's tweedie: 257.612\n",
      "[63]\tvalid_0's tweedie: 257.611\n",
      "[64]\tvalid_0's tweedie: 257.61\n",
      "[65]\tvalid_0's tweedie: 257.609\n",
      "[66]\tvalid_0's tweedie: 257.608\n",
      "[67]\tvalid_0's tweedie: 257.609\n",
      "[68]\tvalid_0's tweedie: 257.609\n",
      "[69]\tvalid_0's tweedie: 257.609\n",
      "[70]\tvalid_0's tweedie: 257.609\n",
      "[71]\tvalid_0's tweedie: 257.608\n",
      "[72]\tvalid_0's tweedie: 257.605\n",
      "[73]\tvalid_0's tweedie: 257.605\n",
      "[74]\tvalid_0's tweedie: 257.605\n",
      "[75]\tvalid_0's tweedie: 257.605\n",
      "[76]\tvalid_0's tweedie: 257.605\n",
      "[77]\tvalid_0's tweedie: 257.605\n",
      "[78]\tvalid_0's tweedie: 257.604\n",
      "[79]\tvalid_0's tweedie: 257.604\n",
      "[80]\tvalid_0's tweedie: 257.602\n",
      "[81]\tvalid_0's tweedie: 257.602\n",
      "[82]\tvalid_0's tweedie: 257.599\n",
      "[83]\tvalid_0's tweedie: 257.598\n",
      "[84]\tvalid_0's tweedie: 257.597\n",
      "[85]\tvalid_0's tweedie: 257.597\n",
      "[86]\tvalid_0's tweedie: 257.598\n",
      "[87]\tvalid_0's tweedie: 257.598\n",
      "[88]\tvalid_0's tweedie: 257.597\n",
      "[89]\tvalid_0's tweedie: 257.597\n",
      "[90]\tvalid_0's tweedie: 257.597\n",
      "[91]\tvalid_0's tweedie: 257.597\n",
      "[92]\tvalid_0's tweedie: 257.597\n",
      "[93]\tvalid_0's tweedie: 257.597\n",
      "[94]\tvalid_0's tweedie: 257.596\n",
      "[95]\tvalid_0's tweedie: 257.594\n",
      "[96]\tvalid_0's tweedie: 257.593\n",
      "[97]\tvalid_0's tweedie: 257.593\n",
      "[98]\tvalid_0's tweedie: 257.593\n",
      "[99]\tvalid_0's tweedie: 257.592\n",
      "[100]\tvalid_0's tweedie: 257.593\n",
      "[101]\tvalid_0's tweedie: 257.593\n",
      "[102]\tvalid_0's tweedie: 257.593\n",
      "[103]\tvalid_0's tweedie: 257.593\n",
      "[104]\tvalid_0's tweedie: 257.592\n",
      "[105]\tvalid_0's tweedie: 257.592\n",
      "[106]\tvalid_0's tweedie: 257.592\n",
      "[107]\tvalid_0's tweedie: 257.592\n",
      "[108]\tvalid_0's tweedie: 257.591\n",
      "[109]\tvalid_0's tweedie: 257.59\n",
      "[110]\tvalid_0's tweedie: 257.589\n",
      "[111]\tvalid_0's tweedie: 257.589\n",
      "[112]\tvalid_0's tweedie: 257.589\n",
      "[113]\tvalid_0's tweedie: 257.589\n",
      "[114]\tvalid_0's tweedie: 257.588\n",
      "[115]\tvalid_0's tweedie: 257.588\n",
      "[116]\tvalid_0's tweedie: 257.588\n",
      "[117]\tvalid_0's tweedie: 257.588\n",
      "[118]\tvalid_0's tweedie: 257.589\n",
      "[119]\tvalid_0's tweedie: 257.589\n",
      "[120]\tvalid_0's tweedie: 257.589\n",
      "[121]\tvalid_0's tweedie: 257.59\n",
      "[122]\tvalid_0's tweedie: 257.589\n",
      "[123]\tvalid_0's tweedie: 257.589\n",
      "[124]\tvalid_0's tweedie: 257.589\n",
      "[125]\tvalid_0's tweedie: 257.589\n",
      "[126]\tvalid_0's tweedie: 257.589\n",
      "[127]\tvalid_0's tweedie: 257.59\n",
      "[128]\tvalid_0's tweedie: 257.589\n",
      "[129]\tvalid_0's tweedie: 257.589\n",
      "[130]\tvalid_0's tweedie: 257.588\n",
      "[131]\tvalid_0's tweedie: 257.587\n",
      "[132]\tvalid_0's tweedie: 257.586\n",
      "[133]\tvalid_0's tweedie: 257.587\n",
      "[134]\tvalid_0's tweedie: 257.587\n",
      "[135]\tvalid_0's tweedie: 257.587\n",
      "[136]\tvalid_0's tweedie: 257.587\n",
      "[137]\tvalid_0's tweedie: 257.587\n",
      "[138]\tvalid_0's tweedie: 257.587\n",
      "[139]\tvalid_0's tweedie: 257.587\n",
      "[140]\tvalid_0's tweedie: 257.587\n",
      "[141]\tvalid_0's tweedie: 257.587\n",
      "[142]\tvalid_0's tweedie: 257.587\n",
      "[143]\tvalid_0's tweedie: 257.585\n",
      "[144]\tvalid_0's tweedie: 257.585\n",
      "[145]\tvalid_0's tweedie: 257.585\n",
      "[146]\tvalid_0's tweedie: 257.585\n",
      "[147]\tvalid_0's tweedie: 257.585\n",
      "[148]\tvalid_0's tweedie: 257.584\n",
      "[149]\tvalid_0's tweedie: 257.585\n",
      "[150]\tvalid_0's tweedie: 257.584\n",
      "[151]\tvalid_0's tweedie: 257.584\n",
      "[152]\tvalid_0's tweedie: 257.584\n",
      "[153]\tvalid_0's tweedie: 257.583\n",
      "[154]\tvalid_0's tweedie: 257.583\n",
      "[155]\tvalid_0's tweedie: 257.582\n",
      "[156]\tvalid_0's tweedie: 257.58\n",
      "[157]\tvalid_0's tweedie: 257.58\n",
      "[158]\tvalid_0's tweedie: 257.58\n",
      "[159]\tvalid_0's tweedie: 257.58\n",
      "[160]\tvalid_0's tweedie: 257.58\n",
      "[161]\tvalid_0's tweedie: 257.58\n",
      "[162]\tvalid_0's tweedie: 257.581\n",
      "[163]\tvalid_0's tweedie: 257.582\n",
      "[164]\tvalid_0's tweedie: 257.582\n",
      "[165]\tvalid_0's tweedie: 257.581\n",
      "[166]\tvalid_0's tweedie: 257.581\n",
      "[167]\tvalid_0's tweedie: 257.581\n",
      "[168]\tvalid_0's tweedie: 257.582\n",
      "[169]\tvalid_0's tweedie: 257.581\n",
      "[170]\tvalid_0's tweedie: 257.581\n",
      "[171]\tvalid_0's tweedie: 257.581\n",
      "[172]\tvalid_0's tweedie: 257.579\n",
      "[173]\tvalid_0's tweedie: 257.579\n",
      "[174]\tvalid_0's tweedie: 257.579\n",
      "[175]\tvalid_0's tweedie: 257.579\n",
      "[176]\tvalid_0's tweedie: 257.579\n",
      "[177]\tvalid_0's tweedie: 257.58\n",
      "[178]\tvalid_0's tweedie: 257.58\n",
      "[179]\tvalid_0's tweedie: 257.58\n",
      "[180]\tvalid_0's tweedie: 257.579\n",
      "[181]\tvalid_0's tweedie: 257.58\n",
      "[182]\tvalid_0's tweedie: 257.579\n",
      "[183]\tvalid_0's tweedie: 257.58\n",
      "[184]\tvalid_0's tweedie: 257.58\n",
      "[185]\tvalid_0's tweedie: 257.58\n",
      "[186]\tvalid_0's tweedie: 257.58\n",
      "[187]\tvalid_0's tweedie: 257.58\n",
      "[188]\tvalid_0's tweedie: 257.581\n",
      "[189]\tvalid_0's tweedie: 257.581\n",
      "[190]\tvalid_0's tweedie: 257.582\n",
      "[191]\tvalid_0's tweedie: 257.581\n",
      "[192]\tvalid_0's tweedie: 257.582\n",
      "[193]\tvalid_0's tweedie: 257.582\n",
      "[194]\tvalid_0's tweedie: 257.582\n",
      "[195]\tvalid_0's tweedie: 257.582\n",
      "[196]\tvalid_0's tweedie: 257.581\n",
      "[197]\tvalid_0's tweedie: 257.581\n",
      "[198]\tvalid_0's tweedie: 257.581\n",
      "[199]\tvalid_0's tweedie: 257.581\n",
      "[200]\tvalid_0's tweedie: 257.581\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's tweedie: 257.579\n",
      "Training model for level 3 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 18630, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140527\n",
      "[1]\tvalid_0's tweedie: 260.846\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.331\n",
      "[3]\tvalid_0's tweedie: 259.886\n",
      "[4]\tvalid_0's tweedie: 259.525\n",
      "[5]\tvalid_0's tweedie: 259.23\n",
      "[6]\tvalid_0's tweedie: 258.978\n",
      "[7]\tvalid_0's tweedie: 258.772\n",
      "[8]\tvalid_0's tweedie: 258.602\n",
      "[9]\tvalid_0's tweedie: 258.471\n",
      "[10]\tvalid_0's tweedie: 258.339\n",
      "[11]\tvalid_0's tweedie: 258.248\n",
      "[12]\tvalid_0's tweedie: 258.169\n",
      "[13]\tvalid_0's tweedie: 258.1\n",
      "[14]\tvalid_0's tweedie: 258.042\n",
      "[15]\tvalid_0's tweedie: 257.994\n",
      "[16]\tvalid_0's tweedie: 257.949\n",
      "[17]\tvalid_0's tweedie: 257.921\n",
      "[18]\tvalid_0's tweedie: 257.885\n",
      "[19]\tvalid_0's tweedie: 257.857\n",
      "[20]\tvalid_0's tweedie: 257.831\n",
      "[21]\tvalid_0's tweedie: 257.813\n",
      "[22]\tvalid_0's tweedie: 257.793\n",
      "[23]\tvalid_0's tweedie: 257.777\n",
      "[24]\tvalid_0's tweedie: 257.766\n",
      "[25]\tvalid_0's tweedie: 257.756\n",
      "[26]\tvalid_0's tweedie: 257.748\n",
      "[27]\tvalid_0's tweedie: 257.741\n",
      "[28]\tvalid_0's tweedie: 257.738\n",
      "[29]\tvalid_0's tweedie: 257.73\n",
      "[30]\tvalid_0's tweedie: 257.725\n",
      "[31]\tvalid_0's tweedie: 257.721\n",
      "[32]\tvalid_0's tweedie: 257.719\n",
      "[33]\tvalid_0's tweedie: 257.716\n",
      "[34]\tvalid_0's tweedie: 257.711\n",
      "[35]\tvalid_0's tweedie: 257.71\n",
      "[36]\tvalid_0's tweedie: 257.709\n",
      "[37]\tvalid_0's tweedie: 257.712\n",
      "[38]\tvalid_0's tweedie: 257.71\n",
      "[39]\tvalid_0's tweedie: 257.714\n",
      "[40]\tvalid_0's tweedie: 257.71\n",
      "[41]\tvalid_0's tweedie: 257.705\n",
      "[42]\tvalid_0's tweedie: 257.7\n",
      "[43]\tvalid_0's tweedie: 257.698\n",
      "[44]\tvalid_0's tweedie: 257.692\n",
      "[45]\tvalid_0's tweedie: 257.69\n",
      "[46]\tvalid_0's tweedie: 257.686\n",
      "[47]\tvalid_0's tweedie: 257.684\n",
      "[48]\tvalid_0's tweedie: 257.685\n",
      "[49]\tvalid_0's tweedie: 257.684\n",
      "[50]\tvalid_0's tweedie: 257.684\n",
      "[51]\tvalid_0's tweedie: 257.68\n",
      "[52]\tvalid_0's tweedie: 257.677\n",
      "[53]\tvalid_0's tweedie: 257.675\n",
      "[54]\tvalid_0's tweedie: 257.674\n",
      "[55]\tvalid_0's tweedie: 257.673\n",
      "[56]\tvalid_0's tweedie: 257.671\n",
      "[57]\tvalid_0's tweedie: 257.67\n",
      "[58]\tvalid_0's tweedie: 257.67\n",
      "[59]\tvalid_0's tweedie: 257.668\n",
      "[60]\tvalid_0's tweedie: 257.667\n",
      "[61]\tvalid_0's tweedie: 257.663\n",
      "[62]\tvalid_0's tweedie: 257.658\n",
      "[63]\tvalid_0's tweedie: 257.655\n",
      "[64]\tvalid_0's tweedie: 257.653\n",
      "[65]\tvalid_0's tweedie: 257.653\n",
      "[66]\tvalid_0's tweedie: 257.652\n",
      "[67]\tvalid_0's tweedie: 257.653\n",
      "[68]\tvalid_0's tweedie: 257.652\n",
      "[69]\tvalid_0's tweedie: 257.652\n",
      "[70]\tvalid_0's tweedie: 257.651\n",
      "[71]\tvalid_0's tweedie: 257.65\n",
      "[72]\tvalid_0's tweedie: 257.648\n",
      "[73]\tvalid_0's tweedie: 257.647\n",
      "[74]\tvalid_0's tweedie: 257.642\n",
      "[75]\tvalid_0's tweedie: 257.642\n",
      "[76]\tvalid_0's tweedie: 257.641\n",
      "[77]\tvalid_0's tweedie: 257.64\n",
      "[78]\tvalid_0's tweedie: 257.639\n",
      "[79]\tvalid_0's tweedie: 257.64\n",
      "[80]\tvalid_0's tweedie: 257.639\n",
      "[81]\tvalid_0's tweedie: 257.64\n",
      "[82]\tvalid_0's tweedie: 257.64\n",
      "[83]\tvalid_0's tweedie: 257.64\n",
      "[84]\tvalid_0's tweedie: 257.64\n",
      "[85]\tvalid_0's tweedie: 257.639\n",
      "[86]\tvalid_0's tweedie: 257.639\n",
      "[87]\tvalid_0's tweedie: 257.639\n",
      "[88]\tvalid_0's tweedie: 257.639\n",
      "[89]\tvalid_0's tweedie: 257.638\n",
      "[90]\tvalid_0's tweedie: 257.637\n",
      "[91]\tvalid_0's tweedie: 257.638\n",
      "[92]\tvalid_0's tweedie: 257.637\n",
      "[93]\tvalid_0's tweedie: 257.636\n",
      "[94]\tvalid_0's tweedie: 257.631\n",
      "[95]\tvalid_0's tweedie: 257.631\n",
      "[96]\tvalid_0's tweedie: 257.631\n",
      "[97]\tvalid_0's tweedie: 257.63\n",
      "[98]\tvalid_0's tweedie: 257.632\n",
      "[99]\tvalid_0's tweedie: 257.629\n",
      "[100]\tvalid_0's tweedie: 257.628\n",
      "[101]\tvalid_0's tweedie: 257.628\n",
      "[102]\tvalid_0's tweedie: 257.628\n",
      "[103]\tvalid_0's tweedie: 257.629\n",
      "[104]\tvalid_0's tweedie: 257.629\n",
      "[105]\tvalid_0's tweedie: 257.628\n",
      "[106]\tvalid_0's tweedie: 257.626\n",
      "[107]\tvalid_0's tweedie: 257.624\n",
      "[108]\tvalid_0's tweedie: 257.621\n",
      "[109]\tvalid_0's tweedie: 257.621\n",
      "[110]\tvalid_0's tweedie: 257.622\n",
      "[111]\tvalid_0's tweedie: 257.621\n",
      "[112]\tvalid_0's tweedie: 257.619\n",
      "[113]\tvalid_0's tweedie: 257.619\n",
      "[114]\tvalid_0's tweedie: 257.618\n",
      "[115]\tvalid_0's tweedie: 257.618\n",
      "[116]\tvalid_0's tweedie: 257.618\n",
      "[117]\tvalid_0's tweedie: 257.618\n",
      "[118]\tvalid_0's tweedie: 257.618\n",
      "[119]\tvalid_0's tweedie: 257.618\n",
      "[120]\tvalid_0's tweedie: 257.616\n",
      "[121]\tvalid_0's tweedie: 257.616\n",
      "[122]\tvalid_0's tweedie: 257.616\n",
      "[123]\tvalid_0's tweedie: 257.616\n",
      "[124]\tvalid_0's tweedie: 257.617\n",
      "[125]\tvalid_0's tweedie: 257.616\n",
      "[126]\tvalid_0's tweedie: 257.615\n",
      "[127]\tvalid_0's tweedie: 257.615\n",
      "[128]\tvalid_0's tweedie: 257.614\n",
      "[129]\tvalid_0's tweedie: 257.614\n",
      "[130]\tvalid_0's tweedie: 257.614\n",
      "[131]\tvalid_0's tweedie: 257.614\n",
      "[132]\tvalid_0's tweedie: 257.614\n",
      "[133]\tvalid_0's tweedie: 257.614\n",
      "[134]\tvalid_0's tweedie: 257.614\n",
      "[135]\tvalid_0's tweedie: 257.612\n",
      "[136]\tvalid_0's tweedie: 257.612\n",
      "[137]\tvalid_0's tweedie: 257.61\n",
      "[138]\tvalid_0's tweedie: 257.61\n",
      "[139]\tvalid_0's tweedie: 257.61\n",
      "[140]\tvalid_0's tweedie: 257.61\n",
      "[141]\tvalid_0's tweedie: 257.609\n",
      "[142]\tvalid_0's tweedie: 257.608\n",
      "[143]\tvalid_0's tweedie: 257.608\n",
      "[144]\tvalid_0's tweedie: 257.609\n",
      "[145]\tvalid_0's tweedie: 257.609\n",
      "[146]\tvalid_0's tweedie: 257.608\n",
      "[147]\tvalid_0's tweedie: 257.609\n",
      "[148]\tvalid_0's tweedie: 257.609\n",
      "[149]\tvalid_0's tweedie: 257.608\n",
      "[150]\tvalid_0's tweedie: 257.608\n",
      "[151]\tvalid_0's tweedie: 257.608\n",
      "[152]\tvalid_0's tweedie: 257.608\n",
      "[153]\tvalid_0's tweedie: 257.608\n",
      "[154]\tvalid_0's tweedie: 257.608\n",
      "[155]\tvalid_0's tweedie: 257.609\n",
      "[156]\tvalid_0's tweedie: 257.609\n",
      "[157]\tvalid_0's tweedie: 257.609\n",
      "[158]\tvalid_0's tweedie: 257.609\n",
      "[159]\tvalid_0's tweedie: 257.609\n",
      "[160]\tvalid_0's tweedie: 257.608\n",
      "[161]\tvalid_0's tweedie: 257.609\n",
      "[162]\tvalid_0's tweedie: 257.609\n",
      "[163]\tvalid_0's tweedie: 257.607\n",
      "[164]\tvalid_0's tweedie: 257.607\n",
      "[165]\tvalid_0's tweedie: 257.605\n",
      "[166]\tvalid_0's tweedie: 257.606\n",
      "[167]\tvalid_0's tweedie: 257.605\n",
      "[168]\tvalid_0's tweedie: 257.605\n",
      "[169]\tvalid_0's tweedie: 257.605\n",
      "[170]\tvalid_0's tweedie: 257.605\n",
      "[171]\tvalid_0's tweedie: 257.605\n",
      "[172]\tvalid_0's tweedie: 257.605\n",
      "[173]\tvalid_0's tweedie: 257.605\n",
      "[174]\tvalid_0's tweedie: 257.605\n",
      "[175]\tvalid_0's tweedie: 257.605\n",
      "[176]\tvalid_0's tweedie: 257.605\n",
      "[177]\tvalid_0's tweedie: 257.602\n",
      "[178]\tvalid_0's tweedie: 257.603\n",
      "[179]\tvalid_0's tweedie: 257.602\n",
      "[180]\tvalid_0's tweedie: 257.602\n",
      "[181]\tvalid_0's tweedie: 257.603\n",
      "[182]\tvalid_0's tweedie: 257.603\n",
      "[183]\tvalid_0's tweedie: 257.603\n",
      "[184]\tvalid_0's tweedie: 257.603\n",
      "[185]\tvalid_0's tweedie: 257.603\n",
      "[186]\tvalid_0's tweedie: 257.602\n",
      "[187]\tvalid_0's tweedie: 257.602\n",
      "[188]\tvalid_0's tweedie: 257.602\n",
      "[189]\tvalid_0's tweedie: 257.602\n",
      "[190]\tvalid_0's tweedie: 257.603\n",
      "[191]\tvalid_0's tweedie: 257.604\n",
      "[192]\tvalid_0's tweedie: 257.604\n",
      "[193]\tvalid_0's tweedie: 257.603\n",
      "[194]\tvalid_0's tweedie: 257.604\n",
      "[195]\tvalid_0's tweedie: 257.604\n",
      "[196]\tvalid_0's tweedie: 257.604\n",
      "[197]\tvalid_0's tweedie: 257.603\n",
      "[198]\tvalid_0's tweedie: 257.603\n",
      "[199]\tvalid_0's tweedie: 257.603\n",
      "[200]\tvalid_0's tweedie: 257.603\n",
      "[201]\tvalid_0's tweedie: 257.603\n",
      "[202]\tvalid_0's tweedie: 257.603\n",
      "[203]\tvalid_0's tweedie: 257.603\n",
      "[204]\tvalid_0's tweedie: 257.603\n",
      "[205]\tvalid_0's tweedie: 257.602\n",
      "[206]\tvalid_0's tweedie: 257.602\n",
      "[207]\tvalid_0's tweedie: 257.602\n",
      "[208]\tvalid_0's tweedie: 257.602\n",
      "[209]\tvalid_0's tweedie: 257.602\n",
      "[210]\tvalid_0's tweedie: 257.602\n",
      "[211]\tvalid_0's tweedie: 257.601\n",
      "[212]\tvalid_0's tweedie: 257.602\n",
      "[213]\tvalid_0's tweedie: 257.601\n",
      "[214]\tvalid_0's tweedie: 257.601\n",
      "[215]\tvalid_0's tweedie: 257.602\n",
      "[216]\tvalid_0's tweedie: 257.602\n",
      "[217]\tvalid_0's tweedie: 257.601\n",
      "[218]\tvalid_0's tweedie: 257.601\n",
      "[219]\tvalid_0's tweedie: 257.601\n",
      "[220]\tvalid_0's tweedie: 257.6\n",
      "[221]\tvalid_0's tweedie: 257.6\n",
      "[222]\tvalid_0's tweedie: 257.6\n",
      "[223]\tvalid_0's tweedie: 257.6\n",
      "[224]\tvalid_0's tweedie: 257.6\n",
      "[225]\tvalid_0's tweedie: 257.6\n",
      "[226]\tvalid_0's tweedie: 257.599\n",
      "[227]\tvalid_0's tweedie: 257.599\n",
      "[228]\tvalid_0's tweedie: 257.6\n",
      "[229]\tvalid_0's tweedie: 257.6\n",
      "[230]\tvalid_0's tweedie: 257.6\n",
      "[231]\tvalid_0's tweedie: 257.6\n",
      "[232]\tvalid_0's tweedie: 257.6\n",
      "[233]\tvalid_0's tweedie: 257.6\n",
      "[234]\tvalid_0's tweedie: 257.601\n",
      "[235]\tvalid_0's tweedie: 257.6\n",
      "[236]\tvalid_0's tweedie: 257.601\n",
      "[237]\tvalid_0's tweedie: 257.601\n",
      "[238]\tvalid_0's tweedie: 257.601\n",
      "[239]\tvalid_0's tweedie: 257.601\n",
      "[240]\tvalid_0's tweedie: 257.6\n",
      "[241]\tvalid_0's tweedie: 257.6\n",
      "[242]\tvalid_0's tweedie: 257.6\n",
      "[243]\tvalid_0's tweedie: 257.6\n",
      "[244]\tvalid_0's tweedie: 257.6\n",
      "[245]\tvalid_0's tweedie: 257.6\n",
      "[246]\tvalid_0's tweedie: 257.6\n",
      "[247]\tvalid_0's tweedie: 257.6\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's tweedie: 257.599\n",
      "Training model for level 3 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 18620, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140606\n",
      "[1]\tvalid_0's tweedie: 260.849\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.334\n",
      "[3]\tvalid_0's tweedie: 259.887\n",
      "[4]\tvalid_0's tweedie: 259.527\n",
      "[5]\tvalid_0's tweedie: 259.24\n",
      "[6]\tvalid_0's tweedie: 258.987\n",
      "[7]\tvalid_0's tweedie: 258.804\n",
      "[8]\tvalid_0's tweedie: 258.636\n",
      "[9]\tvalid_0's tweedie: 258.488\n",
      "[10]\tvalid_0's tweedie: 258.354\n",
      "[11]\tvalid_0's tweedie: 258.265\n",
      "[12]\tvalid_0's tweedie: 258.181\n",
      "[13]\tvalid_0's tweedie: 258.103\n",
      "[14]\tvalid_0's tweedie: 258.045\n",
      "[15]\tvalid_0's tweedie: 258\n",
      "[16]\tvalid_0's tweedie: 257.964\n",
      "[17]\tvalid_0's tweedie: 257.924\n",
      "[18]\tvalid_0's tweedie: 257.891\n",
      "[19]\tvalid_0's tweedie: 257.866\n",
      "[20]\tvalid_0's tweedie: 257.85\n",
      "[21]\tvalid_0's tweedie: 257.831\n",
      "[22]\tvalid_0's tweedie: 257.813\n",
      "[23]\tvalid_0's tweedie: 257.797\n",
      "[24]\tvalid_0's tweedie: 257.784\n",
      "[25]\tvalid_0's tweedie: 257.772\n",
      "[26]\tvalid_0's tweedie: 257.764\n",
      "[27]\tvalid_0's tweedie: 257.756\n",
      "[28]\tvalid_0's tweedie: 257.748\n",
      "[29]\tvalid_0's tweedie: 257.744\n",
      "[30]\tvalid_0's tweedie: 257.734\n",
      "[31]\tvalid_0's tweedie: 257.729\n",
      "[32]\tvalid_0's tweedie: 257.726\n",
      "[33]\tvalid_0's tweedie: 257.721\n",
      "[34]\tvalid_0's tweedie: 257.717\n",
      "[35]\tvalid_0's tweedie: 257.719\n",
      "[36]\tvalid_0's tweedie: 257.717\n",
      "[37]\tvalid_0's tweedie: 257.72\n",
      "[38]\tvalid_0's tweedie: 257.716\n",
      "[39]\tvalid_0's tweedie: 257.714\n",
      "[40]\tvalid_0's tweedie: 257.715\n",
      "[41]\tvalid_0's tweedie: 257.715\n",
      "[42]\tvalid_0's tweedie: 257.713\n",
      "[43]\tvalid_0's tweedie: 257.712\n",
      "[44]\tvalid_0's tweedie: 257.71\n",
      "[45]\tvalid_0's tweedie: 257.708\n",
      "[46]\tvalid_0's tweedie: 257.702\n",
      "[47]\tvalid_0's tweedie: 257.7\n",
      "[48]\tvalid_0's tweedie: 257.694\n",
      "[49]\tvalid_0's tweedie: 257.698\n",
      "[50]\tvalid_0's tweedie: 257.702\n",
      "[51]\tvalid_0's tweedie: 257.7\n",
      "[52]\tvalid_0's tweedie: 257.695\n",
      "[53]\tvalid_0's tweedie: 257.697\n",
      "[54]\tvalid_0's tweedie: 257.693\n",
      "[55]\tvalid_0's tweedie: 257.692\n",
      "[56]\tvalid_0's tweedie: 257.691\n",
      "[57]\tvalid_0's tweedie: 257.69\n",
      "[58]\tvalid_0's tweedie: 257.69\n",
      "[59]\tvalid_0's tweedie: 257.684\n",
      "[60]\tvalid_0's tweedie: 257.683\n",
      "[61]\tvalid_0's tweedie: 257.681\n",
      "[62]\tvalid_0's tweedie: 257.686\n",
      "[63]\tvalid_0's tweedie: 257.685\n",
      "[64]\tvalid_0's tweedie: 257.685\n",
      "[65]\tvalid_0's tweedie: 257.686\n",
      "[66]\tvalid_0's tweedie: 257.687\n",
      "[67]\tvalid_0's tweedie: 257.686\n",
      "[68]\tvalid_0's tweedie: 257.684\n",
      "[69]\tvalid_0's tweedie: 257.683\n",
      "[70]\tvalid_0's tweedie: 257.678\n",
      "[71]\tvalid_0's tweedie: 257.676\n",
      "[72]\tvalid_0's tweedie: 257.674\n",
      "[73]\tvalid_0's tweedie: 257.67\n",
      "[74]\tvalid_0's tweedie: 257.67\n",
      "[75]\tvalid_0's tweedie: 257.67\n",
      "[76]\tvalid_0's tweedie: 257.67\n",
      "[77]\tvalid_0's tweedie: 257.67\n",
      "[78]\tvalid_0's tweedie: 257.666\n",
      "[79]\tvalid_0's tweedie: 257.663\n",
      "[80]\tvalid_0's tweedie: 257.661\n",
      "[81]\tvalid_0's tweedie: 257.661\n",
      "[82]\tvalid_0's tweedie: 257.661\n",
      "[83]\tvalid_0's tweedie: 257.661\n",
      "[84]\tvalid_0's tweedie: 257.661\n",
      "[85]\tvalid_0's tweedie: 257.66\n",
      "[86]\tvalid_0's tweedie: 257.66\n",
      "[87]\tvalid_0's tweedie: 257.659\n",
      "[88]\tvalid_0's tweedie: 257.659\n",
      "[89]\tvalid_0's tweedie: 257.659\n",
      "[90]\tvalid_0's tweedie: 257.659\n",
      "[91]\tvalid_0's tweedie: 257.659\n",
      "[92]\tvalid_0's tweedie: 257.659\n",
      "[93]\tvalid_0's tweedie: 257.658\n",
      "[94]\tvalid_0's tweedie: 257.657\n",
      "[95]\tvalid_0's tweedie: 257.658\n",
      "[96]\tvalid_0's tweedie: 257.658\n",
      "[97]\tvalid_0's tweedie: 257.658\n",
      "[98]\tvalid_0's tweedie: 257.657\n",
      "[99]\tvalid_0's tweedie: 257.657\n",
      "[100]\tvalid_0's tweedie: 257.658\n",
      "[101]\tvalid_0's tweedie: 257.658\n",
      "[102]\tvalid_0's tweedie: 257.657\n",
      "[103]\tvalid_0's tweedie: 257.657\n",
      "[104]\tvalid_0's tweedie: 257.657\n",
      "[105]\tvalid_0's tweedie: 257.656\n",
      "[106]\tvalid_0's tweedie: 257.657\n",
      "[107]\tvalid_0's tweedie: 257.653\n",
      "[108]\tvalid_0's tweedie: 257.653\n",
      "[109]\tvalid_0's tweedie: 257.649\n",
      "[110]\tvalid_0's tweedie: 257.646\n",
      "[111]\tvalid_0's tweedie: 257.647\n",
      "[112]\tvalid_0's tweedie: 257.647\n",
      "[113]\tvalid_0's tweedie: 257.647\n",
      "[114]\tvalid_0's tweedie: 257.647\n",
      "[115]\tvalid_0's tweedie: 257.647\n",
      "[116]\tvalid_0's tweedie: 257.647\n",
      "[117]\tvalid_0's tweedie: 257.647\n",
      "[118]\tvalid_0's tweedie: 257.646\n",
      "[119]\tvalid_0's tweedie: 257.646\n",
      "[120]\tvalid_0's tweedie: 257.646\n",
      "[121]\tvalid_0's tweedie: 257.645\n",
      "[122]\tvalid_0's tweedie: 257.645\n",
      "[123]\tvalid_0's tweedie: 257.644\n",
      "[124]\tvalid_0's tweedie: 257.644\n",
      "[125]\tvalid_0's tweedie: 257.644\n",
      "[126]\tvalid_0's tweedie: 257.644\n",
      "[127]\tvalid_0's tweedie: 257.644\n",
      "[128]\tvalid_0's tweedie: 257.644\n",
      "[129]\tvalid_0's tweedie: 257.644\n",
      "[130]\tvalid_0's tweedie: 257.643\n",
      "[131]\tvalid_0's tweedie: 257.643\n",
      "[132]\tvalid_0's tweedie: 257.642\n",
      "[133]\tvalid_0's tweedie: 257.643\n",
      "[134]\tvalid_0's tweedie: 257.643\n",
      "[135]\tvalid_0's tweedie: 257.642\n",
      "[136]\tvalid_0's tweedie: 257.641\n",
      "[137]\tvalid_0's tweedie: 257.641\n",
      "[138]\tvalid_0's tweedie: 257.641\n",
      "[139]\tvalid_0's tweedie: 257.641\n",
      "[140]\tvalid_0's tweedie: 257.638\n",
      "[141]\tvalid_0's tweedie: 257.638\n",
      "[142]\tvalid_0's tweedie: 257.638\n",
      "[143]\tvalid_0's tweedie: 257.638\n",
      "[144]\tvalid_0's tweedie: 257.635\n",
      "[145]\tvalid_0's tweedie: 257.634\n",
      "[146]\tvalid_0's tweedie: 257.635\n",
      "[147]\tvalid_0's tweedie: 257.635\n",
      "[148]\tvalid_0's tweedie: 257.635\n",
      "[149]\tvalid_0's tweedie: 257.636\n",
      "[150]\tvalid_0's tweedie: 257.636\n",
      "[151]\tvalid_0's tweedie: 257.634\n",
      "[152]\tvalid_0's tweedie: 257.63\n",
      "[153]\tvalid_0's tweedie: 257.63\n",
      "[154]\tvalid_0's tweedie: 257.63\n",
      "[155]\tvalid_0's tweedie: 257.63\n",
      "[156]\tvalid_0's tweedie: 257.629\n",
      "[157]\tvalid_0's tweedie: 257.629\n",
      "[158]\tvalid_0's tweedie: 257.628\n",
      "[159]\tvalid_0's tweedie: 257.628\n",
      "[160]\tvalid_0's tweedie: 257.628\n",
      "[161]\tvalid_0's tweedie: 257.628\n",
      "[162]\tvalid_0's tweedie: 257.625\n",
      "[163]\tvalid_0's tweedie: 257.625\n",
      "[164]\tvalid_0's tweedie: 257.626\n",
      "[165]\tvalid_0's tweedie: 257.625\n",
      "[166]\tvalid_0's tweedie: 257.623\n",
      "[167]\tvalid_0's tweedie: 257.623\n",
      "[168]\tvalid_0's tweedie: 257.623\n",
      "[169]\tvalid_0's tweedie: 257.623\n",
      "[170]\tvalid_0's tweedie: 257.623\n",
      "[171]\tvalid_0's tweedie: 257.624\n",
      "[172]\tvalid_0's tweedie: 257.624\n",
      "[173]\tvalid_0's tweedie: 257.624\n",
      "[174]\tvalid_0's tweedie: 257.623\n",
      "[175]\tvalid_0's tweedie: 257.623\n",
      "[176]\tvalid_0's tweedie: 257.624\n",
      "[177]\tvalid_0's tweedie: 257.624\n",
      "[178]\tvalid_0's tweedie: 257.625\n",
      "[179]\tvalid_0's tweedie: 257.625\n",
      "[180]\tvalid_0's tweedie: 257.624\n",
      "[181]\tvalid_0's tweedie: 257.625\n",
      "[182]\tvalid_0's tweedie: 257.625\n",
      "[183]\tvalid_0's tweedie: 257.624\n",
      "[184]\tvalid_0's tweedie: 257.624\n",
      "[185]\tvalid_0's tweedie: 257.624\n",
      "[186]\tvalid_0's tweedie: 257.623\n",
      "[187]\tvalid_0's tweedie: 257.624\n",
      "[188]\tvalid_0's tweedie: 257.623\n",
      "[189]\tvalid_0's tweedie: 257.624\n",
      "[190]\tvalid_0's tweedie: 257.623\n",
      "[191]\tvalid_0's tweedie: 257.623\n",
      "[192]\tvalid_0's tweedie: 257.624\n",
      "[193]\tvalid_0's tweedie: 257.624\n",
      "[194]\tvalid_0's tweedie: 257.624\n",
      "[195]\tvalid_0's tweedie: 257.623\n",
      "[196]\tvalid_0's tweedie: 257.624\n",
      "[197]\tvalid_0's tweedie: 257.624\n",
      "[198]\tvalid_0's tweedie: 257.624\n",
      "[199]\tvalid_0's tweedie: 257.625\n",
      "[200]\tvalid_0's tweedie: 257.623\n",
      "[201]\tvalid_0's tweedie: 257.623\n",
      "[202]\tvalid_0's tweedie: 257.623\n",
      "[203]\tvalid_0's tweedie: 257.623\n",
      "[204]\tvalid_0's tweedie: 257.623\n",
      "[205]\tvalid_0's tweedie: 257.624\n",
      "[206]\tvalid_0's tweedie: 257.624\n",
      "[207]\tvalid_0's tweedie: 257.624\n",
      "[208]\tvalid_0's tweedie: 257.623\n",
      "[209]\tvalid_0's tweedie: 257.622\n",
      "[210]\tvalid_0's tweedie: 257.622\n",
      "[211]\tvalid_0's tweedie: 257.622\n",
      "[212]\tvalid_0's tweedie: 257.622\n",
      "[213]\tvalid_0's tweedie: 257.622\n",
      "[214]\tvalid_0's tweedie: 257.622\n",
      "[215]\tvalid_0's tweedie: 257.622\n",
      "[216]\tvalid_0's tweedie: 257.622\n",
      "[217]\tvalid_0's tweedie: 257.622\n",
      "[218]\tvalid_0's tweedie: 257.621\n",
      "[219]\tvalid_0's tweedie: 257.621\n",
      "[220]\tvalid_0's tweedie: 257.621\n",
      "[221]\tvalid_0's tweedie: 257.62\n",
      "[222]\tvalid_0's tweedie: 257.618\n",
      "[223]\tvalid_0's tweedie: 257.618\n",
      "[224]\tvalid_0's tweedie: 257.618\n",
      "[225]\tvalid_0's tweedie: 257.618\n",
      "[226]\tvalid_0's tweedie: 257.618\n",
      "[227]\tvalid_0's tweedie: 257.618\n",
      "[228]\tvalid_0's tweedie: 257.618\n",
      "[229]\tvalid_0's tweedie: 257.618\n",
      "[230]\tvalid_0's tweedie: 257.618\n",
      "[231]\tvalid_0's tweedie: 257.618\n",
      "[232]\tvalid_0's tweedie: 257.618\n",
      "[233]\tvalid_0's tweedie: 257.618\n",
      "[234]\tvalid_0's tweedie: 257.618\n",
      "[235]\tvalid_0's tweedie: 257.618\n",
      "[236]\tvalid_0's tweedie: 257.618\n",
      "[237]\tvalid_0's tweedie: 257.618\n",
      "[238]\tvalid_0's tweedie: 257.618\n",
      "[239]\tvalid_0's tweedie: 257.617\n",
      "[240]\tvalid_0's tweedie: 257.617\n",
      "[241]\tvalid_0's tweedie: 257.616\n",
      "[242]\tvalid_0's tweedie: 257.616\n",
      "[243]\tvalid_0's tweedie: 257.617\n",
      "[244]\tvalid_0's tweedie: 257.617\n",
      "[245]\tvalid_0's tweedie: 257.617\n",
      "[246]\tvalid_0's tweedie: 257.617\n",
      "[247]\tvalid_0's tweedie: 257.617\n",
      "[248]\tvalid_0's tweedie: 257.617\n",
      "[249]\tvalid_0's tweedie: 257.617\n",
      "[250]\tvalid_0's tweedie: 257.617\n",
      "[251]\tvalid_0's tweedie: 257.617\n",
      "[252]\tvalid_0's tweedie: 257.617\n",
      "[253]\tvalid_0's tweedie: 257.618\n",
      "[254]\tvalid_0's tweedie: 257.618\n",
      "[255]\tvalid_0's tweedie: 257.619\n",
      "[256]\tvalid_0's tweedie: 257.618\n",
      "[257]\tvalid_0's tweedie: 257.619\n",
      "[258]\tvalid_0's tweedie: 257.619\n",
      "[259]\tvalid_0's tweedie: 257.618\n",
      "[260]\tvalid_0's tweedie: 257.618\n",
      "[261]\tvalid_0's tweedie: 257.618\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's tweedie: 257.616\n",
      "Training model for level 3 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 18610, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140768\n",
      "[1]\tvalid_0's tweedie: 260.847\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.333\n",
      "[3]\tvalid_0's tweedie: 259.886\n",
      "[4]\tvalid_0's tweedie: 259.527\n",
      "[5]\tvalid_0's tweedie: 259.23\n",
      "[6]\tvalid_0's tweedie: 258.996\n",
      "[7]\tvalid_0's tweedie: 258.811\n",
      "[8]\tvalid_0's tweedie: 258.639\n",
      "[9]\tvalid_0's tweedie: 258.492\n",
      "[10]\tvalid_0's tweedie: 258.375\n",
      "[11]\tvalid_0's tweedie: 258.261\n",
      "[12]\tvalid_0's tweedie: 258.188\n",
      "[13]\tvalid_0's tweedie: 258.125\n",
      "[14]\tvalid_0's tweedie: 258.051\n",
      "[15]\tvalid_0's tweedie: 258.014\n",
      "[16]\tvalid_0's tweedie: 257.967\n",
      "[17]\tvalid_0's tweedie: 257.942\n",
      "[18]\tvalid_0's tweedie: 257.911\n",
      "[19]\tvalid_0's tweedie: 257.89\n",
      "[20]\tvalid_0's tweedie: 257.866\n",
      "[21]\tvalid_0's tweedie: 257.847\n",
      "[22]\tvalid_0's tweedie: 257.83\n",
      "[23]\tvalid_0's tweedie: 257.817\n",
      "[24]\tvalid_0's tweedie: 257.802\n",
      "[25]\tvalid_0's tweedie: 257.794\n",
      "[26]\tvalid_0's tweedie: 257.788\n",
      "[27]\tvalid_0's tweedie: 257.776\n",
      "[28]\tvalid_0's tweedie: 257.768\n",
      "[29]\tvalid_0's tweedie: 257.762\n",
      "[30]\tvalid_0's tweedie: 257.755\n",
      "[31]\tvalid_0's tweedie: 257.749\n",
      "[32]\tvalid_0's tweedie: 257.739\n",
      "[33]\tvalid_0's tweedie: 257.736\n",
      "[34]\tvalid_0's tweedie: 257.734\n",
      "[35]\tvalid_0's tweedie: 257.729\n",
      "[36]\tvalid_0's tweedie: 257.722\n",
      "[37]\tvalid_0's tweedie: 257.719\n",
      "[38]\tvalid_0's tweedie: 257.724\n",
      "[39]\tvalid_0's tweedie: 257.721\n",
      "[40]\tvalid_0's tweedie: 257.718\n",
      "[41]\tvalid_0's tweedie: 257.713\n",
      "[42]\tvalid_0's tweedie: 257.709\n",
      "[43]\tvalid_0's tweedie: 257.706\n",
      "[44]\tvalid_0's tweedie: 257.705\n",
      "[45]\tvalid_0's tweedie: 257.705\n",
      "[46]\tvalid_0's tweedie: 257.702\n",
      "[47]\tvalid_0's tweedie: 257.7\n",
      "[48]\tvalid_0's tweedie: 257.707\n",
      "[49]\tvalid_0's tweedie: 257.706\n",
      "[50]\tvalid_0's tweedie: 257.706\n",
      "[51]\tvalid_0's tweedie: 257.699\n",
      "[52]\tvalid_0's tweedie: 257.696\n",
      "[53]\tvalid_0's tweedie: 257.696\n",
      "[54]\tvalid_0's tweedie: 257.695\n",
      "[55]\tvalid_0's tweedie: 257.69\n",
      "[56]\tvalid_0's tweedie: 257.686\n",
      "[57]\tvalid_0's tweedie: 257.684\n",
      "[58]\tvalid_0's tweedie: 257.683\n",
      "[59]\tvalid_0's tweedie: 257.68\n",
      "[60]\tvalid_0's tweedie: 257.68\n",
      "[61]\tvalid_0's tweedie: 257.679\n",
      "[62]\tvalid_0's tweedie: 257.676\n",
      "[63]\tvalid_0's tweedie: 257.676\n",
      "[64]\tvalid_0's tweedie: 257.671\n",
      "[65]\tvalid_0's tweedie: 257.666\n",
      "[66]\tvalid_0's tweedie: 257.663\n",
      "[67]\tvalid_0's tweedie: 257.661\n",
      "[68]\tvalid_0's tweedie: 257.66\n",
      "[69]\tvalid_0's tweedie: 257.659\n",
      "[70]\tvalid_0's tweedie: 257.658\n",
      "[71]\tvalid_0's tweedie: 257.659\n",
      "[72]\tvalid_0's tweedie: 257.659\n",
      "[73]\tvalid_0's tweedie: 257.658\n",
      "[74]\tvalid_0's tweedie: 257.658\n",
      "[75]\tvalid_0's tweedie: 257.658\n",
      "[76]\tvalid_0's tweedie: 257.657\n",
      "[77]\tvalid_0's tweedie: 257.656\n",
      "[78]\tvalid_0's tweedie: 257.656\n",
      "[79]\tvalid_0's tweedie: 257.656\n",
      "[80]\tvalid_0's tweedie: 257.653\n",
      "[81]\tvalid_0's tweedie: 257.653\n",
      "[82]\tvalid_0's tweedie: 257.649\n",
      "[83]\tvalid_0's tweedie: 257.648\n",
      "[84]\tvalid_0's tweedie: 257.647\n",
      "[85]\tvalid_0's tweedie: 257.642\n",
      "[86]\tvalid_0's tweedie: 257.641\n",
      "[87]\tvalid_0's tweedie: 257.641\n",
      "[88]\tvalid_0's tweedie: 257.64\n",
      "[89]\tvalid_0's tweedie: 257.64\n",
      "[90]\tvalid_0's tweedie: 257.639\n",
      "[91]\tvalid_0's tweedie: 257.64\n",
      "[92]\tvalid_0's tweedie: 257.64\n",
      "[93]\tvalid_0's tweedie: 257.64\n",
      "[94]\tvalid_0's tweedie: 257.638\n",
      "[95]\tvalid_0's tweedie: 257.64\n",
      "[96]\tvalid_0's tweedie: 257.64\n",
      "[97]\tvalid_0's tweedie: 257.639\n",
      "[98]\tvalid_0's tweedie: 257.639\n",
      "[99]\tvalid_0's tweedie: 257.639\n",
      "[100]\tvalid_0's tweedie: 257.639\n",
      "[101]\tvalid_0's tweedie: 257.639\n",
      "[102]\tvalid_0's tweedie: 257.639\n",
      "[103]\tvalid_0's tweedie: 257.639\n",
      "[104]\tvalid_0's tweedie: 257.639\n",
      "[105]\tvalid_0's tweedie: 257.637\n",
      "[106]\tvalid_0's tweedie: 257.637\n",
      "[107]\tvalid_0's tweedie: 257.636\n",
      "[108]\tvalid_0's tweedie: 257.636\n",
      "[109]\tvalid_0's tweedie: 257.635\n",
      "[110]\tvalid_0's tweedie: 257.632\n",
      "[111]\tvalid_0's tweedie: 257.632\n",
      "[112]\tvalid_0's tweedie: 257.63\n",
      "[113]\tvalid_0's tweedie: 257.63\n",
      "[114]\tvalid_0's tweedie: 257.63\n",
      "[115]\tvalid_0's tweedie: 257.629\n",
      "[116]\tvalid_0's tweedie: 257.629\n",
      "[117]\tvalid_0's tweedie: 257.629\n",
      "[118]\tvalid_0's tweedie: 257.629\n",
      "[119]\tvalid_0's tweedie: 257.629\n",
      "[120]\tvalid_0's tweedie: 257.628\n",
      "[121]\tvalid_0's tweedie: 257.628\n",
      "[122]\tvalid_0's tweedie: 257.628\n",
      "[123]\tvalid_0's tweedie: 257.627\n",
      "[124]\tvalid_0's tweedie: 257.627\n",
      "[125]\tvalid_0's tweedie: 257.627\n",
      "[126]\tvalid_0's tweedie: 257.626\n",
      "[127]\tvalid_0's tweedie: 257.622\n",
      "[128]\tvalid_0's tweedie: 257.622\n",
      "[129]\tvalid_0's tweedie: 257.622\n",
      "[130]\tvalid_0's tweedie: 257.624\n",
      "[131]\tvalid_0's tweedie: 257.624\n",
      "[132]\tvalid_0's tweedie: 257.624\n",
      "[133]\tvalid_0's tweedie: 257.623\n",
      "[134]\tvalid_0's tweedie: 257.621\n",
      "[135]\tvalid_0's tweedie: 257.622\n",
      "[136]\tvalid_0's tweedie: 257.622\n",
      "[137]\tvalid_0's tweedie: 257.623\n",
      "[138]\tvalid_0's tweedie: 257.623\n",
      "[139]\tvalid_0's tweedie: 257.622\n",
      "[140]\tvalid_0's tweedie: 257.62\n",
      "[141]\tvalid_0's tweedie: 257.621\n",
      "[142]\tvalid_0's tweedie: 257.62\n",
      "[143]\tvalid_0's tweedie: 257.62\n",
      "[144]\tvalid_0's tweedie: 257.62\n",
      "[145]\tvalid_0's tweedie: 257.62\n",
      "[146]\tvalid_0's tweedie: 257.62\n",
      "[147]\tvalid_0's tweedie: 257.62\n",
      "[148]\tvalid_0's tweedie: 257.617\n",
      "[149]\tvalid_0's tweedie: 257.617\n",
      "[150]\tvalid_0's tweedie: 257.617\n",
      "[151]\tvalid_0's tweedie: 257.617\n",
      "[152]\tvalid_0's tweedie: 257.618\n",
      "[153]\tvalid_0's tweedie: 257.618\n",
      "[154]\tvalid_0's tweedie: 257.618\n",
      "[155]\tvalid_0's tweedie: 257.619\n",
      "[156]\tvalid_0's tweedie: 257.62\n",
      "[157]\tvalid_0's tweedie: 257.62\n",
      "[158]\tvalid_0's tweedie: 257.619\n",
      "[159]\tvalid_0's tweedie: 257.62\n",
      "[160]\tvalid_0's tweedie: 257.62\n",
      "[161]\tvalid_0's tweedie: 257.62\n",
      "[162]\tvalid_0's tweedie: 257.62\n",
      "[163]\tvalid_0's tweedie: 257.62\n",
      "[164]\tvalid_0's tweedie: 257.619\n",
      "[165]\tvalid_0's tweedie: 257.619\n",
      "[166]\tvalid_0's tweedie: 257.619\n",
      "[167]\tvalid_0's tweedie: 257.62\n",
      "[168]\tvalid_0's tweedie: 257.62\n",
      "[169]\tvalid_0's tweedie: 257.619\n",
      "[170]\tvalid_0's tweedie: 257.618\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's tweedie: 257.617\n",
      "Training model for level 3 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 18600, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.140984\n",
      "[1]\tvalid_0's tweedie: 260.846\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.33\n",
      "[3]\tvalid_0's tweedie: 259.883\n",
      "[4]\tvalid_0's tweedie: 259.522\n",
      "[5]\tvalid_0's tweedie: 259.226\n",
      "[6]\tvalid_0's tweedie: 258.975\n",
      "[7]\tvalid_0's tweedie: 258.767\n",
      "[8]\tvalid_0's tweedie: 258.594\n",
      "[9]\tvalid_0's tweedie: 258.467\n",
      "[10]\tvalid_0's tweedie: 258.337\n",
      "[11]\tvalid_0's tweedie: 258.251\n",
      "[12]\tvalid_0's tweedie: 258.178\n",
      "[13]\tvalid_0's tweedie: 258.1\n",
      "[14]\tvalid_0's tweedie: 258.042\n",
      "[15]\tvalid_0's tweedie: 257.991\n",
      "[16]\tvalid_0's tweedie: 257.962\n",
      "[17]\tvalid_0's tweedie: 257.932\n",
      "[18]\tvalid_0's tweedie: 257.891\n",
      "[19]\tvalid_0's tweedie: 257.863\n",
      "[20]\tvalid_0's tweedie: 257.843\n",
      "[21]\tvalid_0's tweedie: 257.826\n",
      "[22]\tvalid_0's tweedie: 257.811\n",
      "[23]\tvalid_0's tweedie: 257.797\n",
      "[24]\tvalid_0's tweedie: 257.784\n",
      "[25]\tvalid_0's tweedie: 257.774\n",
      "[26]\tvalid_0's tweedie: 257.764\n",
      "[27]\tvalid_0's tweedie: 257.751\n",
      "[28]\tvalid_0's tweedie: 257.744\n",
      "[29]\tvalid_0's tweedie: 257.735\n",
      "[30]\tvalid_0's tweedie: 257.729\n",
      "[31]\tvalid_0's tweedie: 257.726\n",
      "[32]\tvalid_0's tweedie: 257.72\n",
      "[33]\tvalid_0's tweedie: 257.718\n",
      "[34]\tvalid_0's tweedie: 257.721\n",
      "[35]\tvalid_0's tweedie: 257.719\n",
      "[36]\tvalid_0's tweedie: 257.713\n",
      "[37]\tvalid_0's tweedie: 257.708\n",
      "[38]\tvalid_0's tweedie: 257.709\n",
      "[39]\tvalid_0's tweedie: 257.706\n",
      "[40]\tvalid_0's tweedie: 257.712\n",
      "[41]\tvalid_0's tweedie: 257.709\n",
      "[42]\tvalid_0's tweedie: 257.706\n",
      "[43]\tvalid_0's tweedie: 257.711\n",
      "[44]\tvalid_0's tweedie: 257.71\n",
      "[45]\tvalid_0's tweedie: 257.705\n",
      "[46]\tvalid_0's tweedie: 257.714\n",
      "[47]\tvalid_0's tweedie: 257.712\n",
      "[48]\tvalid_0's tweedie: 257.709\n",
      "[49]\tvalid_0's tweedie: 257.709\n",
      "[50]\tvalid_0's tweedie: 257.704\n",
      "[51]\tvalid_0's tweedie: 257.702\n",
      "[52]\tvalid_0's tweedie: 257.705\n",
      "[53]\tvalid_0's tweedie: 257.704\n",
      "[54]\tvalid_0's tweedie: 257.703\n",
      "[55]\tvalid_0's tweedie: 257.701\n",
      "[56]\tvalid_0's tweedie: 257.702\n",
      "[57]\tvalid_0's tweedie: 257.697\n",
      "[58]\tvalid_0's tweedie: 257.696\n",
      "[59]\tvalid_0's tweedie: 257.692\n",
      "[60]\tvalid_0's tweedie: 257.691\n",
      "[61]\tvalid_0's tweedie: 257.689\n",
      "[62]\tvalid_0's tweedie: 257.682\n",
      "[63]\tvalid_0's tweedie: 257.675\n",
      "[64]\tvalid_0's tweedie: 257.669\n",
      "[65]\tvalid_0's tweedie: 257.664\n",
      "[66]\tvalid_0's tweedie: 257.662\n",
      "[67]\tvalid_0's tweedie: 257.659\n",
      "[68]\tvalid_0's tweedie: 257.659\n",
      "[69]\tvalid_0's tweedie: 257.658\n",
      "[70]\tvalid_0's tweedie: 257.657\n",
      "[71]\tvalid_0's tweedie: 257.654\n",
      "[72]\tvalid_0's tweedie: 257.654\n",
      "[73]\tvalid_0's tweedie: 257.654\n",
      "[74]\tvalid_0's tweedie: 257.655\n",
      "[75]\tvalid_0's tweedie: 257.655\n",
      "[76]\tvalid_0's tweedie: 257.653\n",
      "[77]\tvalid_0's tweedie: 257.653\n",
      "[78]\tvalid_0's tweedie: 257.653\n",
      "[79]\tvalid_0's tweedie: 257.653\n",
      "[80]\tvalid_0's tweedie: 257.653\n",
      "[81]\tvalid_0's tweedie: 257.653\n",
      "[82]\tvalid_0's tweedie: 257.652\n",
      "[83]\tvalid_0's tweedie: 257.647\n",
      "[84]\tvalid_0's tweedie: 257.646\n",
      "[85]\tvalid_0's tweedie: 257.647\n",
      "[86]\tvalid_0's tweedie: 257.649\n",
      "[87]\tvalid_0's tweedie: 257.649\n",
      "[88]\tvalid_0's tweedie: 257.649\n",
      "[89]\tvalid_0's tweedie: 257.649\n",
      "[90]\tvalid_0's tweedie: 257.649\n",
      "[91]\tvalid_0's tweedie: 257.648\n",
      "[92]\tvalid_0's tweedie: 257.649\n",
      "[93]\tvalid_0's tweedie: 257.649\n",
      "[94]\tvalid_0's tweedie: 257.647\n",
      "[95]\tvalid_0's tweedie: 257.647\n",
      "[96]\tvalid_0's tweedie: 257.647\n",
      "[97]\tvalid_0's tweedie: 257.648\n",
      "[98]\tvalid_0's tweedie: 257.649\n",
      "[99]\tvalid_0's tweedie: 257.648\n",
      "[100]\tvalid_0's tweedie: 257.646\n",
      "[101]\tvalid_0's tweedie: 257.646\n",
      "[102]\tvalid_0's tweedie: 257.645\n",
      "[103]\tvalid_0's tweedie: 257.645\n",
      "[104]\tvalid_0's tweedie: 257.644\n",
      "[105]\tvalid_0's tweedie: 257.644\n",
      "[106]\tvalid_0's tweedie: 257.644\n",
      "[107]\tvalid_0's tweedie: 257.644\n",
      "[108]\tvalid_0's tweedie: 257.644\n",
      "[109]\tvalid_0's tweedie: 257.644\n",
      "[110]\tvalid_0's tweedie: 257.642\n",
      "[111]\tvalid_0's tweedie: 257.643\n",
      "[112]\tvalid_0's tweedie: 257.643\n",
      "[113]\tvalid_0's tweedie: 257.643\n",
      "[114]\tvalid_0's tweedie: 257.643\n",
      "[115]\tvalid_0's tweedie: 257.642\n",
      "[116]\tvalid_0's tweedie: 257.642\n",
      "[117]\tvalid_0's tweedie: 257.642\n",
      "[118]\tvalid_0's tweedie: 257.642\n",
      "[119]\tvalid_0's tweedie: 257.642\n",
      "[120]\tvalid_0's tweedie: 257.642\n",
      "[121]\tvalid_0's tweedie: 257.641\n",
      "[122]\tvalid_0's tweedie: 257.64\n",
      "[123]\tvalid_0's tweedie: 257.64\n",
      "[124]\tvalid_0's tweedie: 257.64\n",
      "[125]\tvalid_0's tweedie: 257.64\n",
      "[126]\tvalid_0's tweedie: 257.64\n",
      "[127]\tvalid_0's tweedie: 257.64\n",
      "[128]\tvalid_0's tweedie: 257.638\n",
      "[129]\tvalid_0's tweedie: 257.638\n",
      "[130]\tvalid_0's tweedie: 257.637\n",
      "[131]\tvalid_0's tweedie: 257.637\n",
      "[132]\tvalid_0's tweedie: 257.637\n",
      "[133]\tvalid_0's tweedie: 257.634\n",
      "[134]\tvalid_0's tweedie: 257.635\n",
      "[135]\tvalid_0's tweedie: 257.634\n",
      "[136]\tvalid_0's tweedie: 257.634\n",
      "[137]\tvalid_0's tweedie: 257.633\n",
      "[138]\tvalid_0's tweedie: 257.631\n",
      "[139]\tvalid_0's tweedie: 257.63\n",
      "[140]\tvalid_0's tweedie: 257.63\n",
      "[141]\tvalid_0's tweedie: 257.63\n",
      "[142]\tvalid_0's tweedie: 257.628\n",
      "[143]\tvalid_0's tweedie: 257.628\n",
      "[144]\tvalid_0's tweedie: 257.628\n",
      "[145]\tvalid_0's tweedie: 257.627\n",
      "[146]\tvalid_0's tweedie: 257.627\n",
      "[147]\tvalid_0's tweedie: 257.627\n",
      "[148]\tvalid_0's tweedie: 257.627\n",
      "[149]\tvalid_0's tweedie: 257.628\n",
      "[150]\tvalid_0's tweedie: 257.627\n",
      "[151]\tvalid_0's tweedie: 257.627\n",
      "[152]\tvalid_0's tweedie: 257.627\n",
      "[153]\tvalid_0's tweedie: 257.627\n",
      "[154]\tvalid_0's tweedie: 257.627\n",
      "[155]\tvalid_0's tweedie: 257.627\n",
      "[156]\tvalid_0's tweedie: 257.627\n",
      "[157]\tvalid_0's tweedie: 257.627\n",
      "[158]\tvalid_0's tweedie: 257.627\n",
      "[159]\tvalid_0's tweedie: 257.627\n",
      "[160]\tvalid_0's tweedie: 257.627\n",
      "[161]\tvalid_0's tweedie: 257.626\n",
      "[162]\tvalid_0's tweedie: 257.626\n",
      "[163]\tvalid_0's tweedie: 257.627\n",
      "[164]\tvalid_0's tweedie: 257.626\n",
      "[165]\tvalid_0's tweedie: 257.626\n",
      "[166]\tvalid_0's tweedie: 257.625\n",
      "[167]\tvalid_0's tweedie: 257.625\n",
      "[168]\tvalid_0's tweedie: 257.625\n",
      "[169]\tvalid_0's tweedie: 257.625\n",
      "[170]\tvalid_0's tweedie: 257.625\n",
      "[171]\tvalid_0's tweedie: 257.625\n",
      "[172]\tvalid_0's tweedie: 257.625\n",
      "[173]\tvalid_0's tweedie: 257.625\n",
      "[174]\tvalid_0's tweedie: 257.625\n",
      "[175]\tvalid_0's tweedie: 257.625\n",
      "[176]\tvalid_0's tweedie: 257.625\n",
      "[177]\tvalid_0's tweedie: 257.622\n",
      "[178]\tvalid_0's tweedie: 257.622\n",
      "[179]\tvalid_0's tweedie: 257.622\n",
      "[180]\tvalid_0's tweedie: 257.621\n",
      "[181]\tvalid_0's tweedie: 257.621\n",
      "[182]\tvalid_0's tweedie: 257.622\n",
      "[183]\tvalid_0's tweedie: 257.621\n",
      "[184]\tvalid_0's tweedie: 257.621\n",
      "[185]\tvalid_0's tweedie: 257.622\n",
      "[186]\tvalid_0's tweedie: 257.621\n",
      "[187]\tvalid_0's tweedie: 257.62\n",
      "[188]\tvalid_0's tweedie: 257.619\n",
      "[189]\tvalid_0's tweedie: 257.619\n",
      "[190]\tvalid_0's tweedie: 257.616\n",
      "[191]\tvalid_0's tweedie: 257.616\n",
      "[192]\tvalid_0's tweedie: 257.615\n",
      "[193]\tvalid_0's tweedie: 257.614\n",
      "[194]\tvalid_0's tweedie: 257.614\n",
      "[195]\tvalid_0's tweedie: 257.614\n",
      "[196]\tvalid_0's tweedie: 257.614\n",
      "[197]\tvalid_0's tweedie: 257.614\n",
      "[198]\tvalid_0's tweedie: 257.614\n",
      "[199]\tvalid_0's tweedie: 257.614\n",
      "[200]\tvalid_0's tweedie: 257.614\n",
      "[201]\tvalid_0's tweedie: 257.612\n",
      "[202]\tvalid_0's tweedie: 257.612\n",
      "[203]\tvalid_0's tweedie: 257.612\n",
      "[204]\tvalid_0's tweedie: 257.612\n",
      "[205]\tvalid_0's tweedie: 257.611\n",
      "[206]\tvalid_0's tweedie: 257.611\n",
      "[207]\tvalid_0's tweedie: 257.611\n",
      "[208]\tvalid_0's tweedie: 257.61\n",
      "[209]\tvalid_0's tweedie: 257.61\n",
      "[210]\tvalid_0's tweedie: 257.61\n",
      "[211]\tvalid_0's tweedie: 257.611\n",
      "[212]\tvalid_0's tweedie: 257.611\n",
      "[213]\tvalid_0's tweedie: 257.611\n",
      "[214]\tvalid_0's tweedie: 257.61\n",
      "[215]\tvalid_0's tweedie: 257.61\n",
      "[216]\tvalid_0's tweedie: 257.611\n",
      "[217]\tvalid_0's tweedie: 257.611\n",
      "[218]\tvalid_0's tweedie: 257.611\n",
      "[219]\tvalid_0's tweedie: 257.611\n",
      "[220]\tvalid_0's tweedie: 257.611\n",
      "[221]\tvalid_0's tweedie: 257.611\n",
      "[222]\tvalid_0's tweedie: 257.608\n",
      "[223]\tvalid_0's tweedie: 257.609\n",
      "[224]\tvalid_0's tweedie: 257.608\n",
      "[225]\tvalid_0's tweedie: 257.607\n",
      "[226]\tvalid_0's tweedie: 257.606\n",
      "[227]\tvalid_0's tweedie: 257.607\n",
      "[228]\tvalid_0's tweedie: 257.606\n",
      "[229]\tvalid_0's tweedie: 257.606\n",
      "[230]\tvalid_0's tweedie: 257.606\n",
      "[231]\tvalid_0's tweedie: 257.606\n",
      "[232]\tvalid_0's tweedie: 257.606\n",
      "[233]\tvalid_0's tweedie: 257.606\n",
      "[234]\tvalid_0's tweedie: 257.606\n",
      "[235]\tvalid_0's tweedie: 257.606\n",
      "[236]\tvalid_0's tweedie: 257.603\n",
      "[237]\tvalid_0's tweedie: 257.603\n",
      "[238]\tvalid_0's tweedie: 257.603\n",
      "[239]\tvalid_0's tweedie: 257.603\n",
      "[240]\tvalid_0's tweedie: 257.603\n",
      "[241]\tvalid_0's tweedie: 257.603\n",
      "[242]\tvalid_0's tweedie: 257.602\n",
      "[243]\tvalid_0's tweedie: 257.603\n",
      "[244]\tvalid_0's tweedie: 257.603\n",
      "[245]\tvalid_0's tweedie: 257.603\n",
      "[246]\tvalid_0's tweedie: 257.603\n",
      "[247]\tvalid_0's tweedie: 257.603\n",
      "[248]\tvalid_0's tweedie: 257.603\n",
      "[249]\tvalid_0's tweedie: 257.602\n",
      "[250]\tvalid_0's tweedie: 257.602\n",
      "[251]\tvalid_0's tweedie: 257.602\n",
      "[252]\tvalid_0's tweedie: 257.602\n",
      "[253]\tvalid_0's tweedie: 257.602\n",
      "[254]\tvalid_0's tweedie: 257.603\n",
      "[255]\tvalid_0's tweedie: 257.603\n",
      "[256]\tvalid_0's tweedie: 257.604\n",
      "[257]\tvalid_0's tweedie: 257.603\n",
      "[258]\tvalid_0's tweedie: 257.603\n",
      "[259]\tvalid_0's tweedie: 257.603\n",
      "[260]\tvalid_0's tweedie: 257.603\n",
      "[261]\tvalid_0's tweedie: 257.603\n",
      "[262]\tvalid_0's tweedie: 257.603\n",
      "[263]\tvalid_0's tweedie: 257.604\n",
      "[264]\tvalid_0's tweedie: 257.604\n",
      "[265]\tvalid_0's tweedie: 257.604\n",
      "[266]\tvalid_0's tweedie: 257.604\n",
      "[267]\tvalid_0's tweedie: 257.604\n",
      "[268]\tvalid_0's tweedie: 257.604\n",
      "[269]\tvalid_0's tweedie: 257.604\n",
      "[270]\tvalid_0's tweedie: 257.604\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's tweedie: 257.602\n",
      "Training model for level 3 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 18590, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141197\n",
      "[1]\tvalid_0's tweedie: 260.843\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.331\n",
      "[3]\tvalid_0's tweedie: 259.887\n",
      "[4]\tvalid_0's tweedie: 259.528\n",
      "[5]\tvalid_0's tweedie: 259.239\n",
      "[6]\tvalid_0's tweedie: 258.988\n",
      "[7]\tvalid_0's tweedie: 258.776\n",
      "[8]\tvalid_0's tweedie: 258.608\n",
      "[9]\tvalid_0's tweedie: 258.448\n",
      "[10]\tvalid_0's tweedie: 258.346\n",
      "[11]\tvalid_0's tweedie: 258.254\n",
      "[12]\tvalid_0's tweedie: 258.173\n",
      "[13]\tvalid_0's tweedie: 258.111\n",
      "[14]\tvalid_0's tweedie: 258.048\n",
      "[15]\tvalid_0's tweedie: 257.993\n",
      "[16]\tvalid_0's tweedie: 257.948\n",
      "[17]\tvalid_0's tweedie: 257.916\n",
      "[18]\tvalid_0's tweedie: 257.881\n",
      "[19]\tvalid_0's tweedie: 257.854\n",
      "[20]\tvalid_0's tweedie: 257.833\n",
      "[21]\tvalid_0's tweedie: 257.813\n",
      "[22]\tvalid_0's tweedie: 257.796\n",
      "[23]\tvalid_0's tweedie: 257.782\n",
      "[24]\tvalid_0's tweedie: 257.768\n",
      "[25]\tvalid_0's tweedie: 257.757\n",
      "[26]\tvalid_0's tweedie: 257.749\n",
      "[27]\tvalid_0's tweedie: 257.736\n",
      "[28]\tvalid_0's tweedie: 257.728\n",
      "[29]\tvalid_0's tweedie: 257.724\n",
      "[30]\tvalid_0's tweedie: 257.713\n",
      "[31]\tvalid_0's tweedie: 257.707\n",
      "[32]\tvalid_0's tweedie: 257.706\n",
      "[33]\tvalid_0's tweedie: 257.697\n",
      "[34]\tvalid_0's tweedie: 257.696\n",
      "[35]\tvalid_0's tweedie: 257.695\n",
      "[36]\tvalid_0's tweedie: 257.685\n",
      "[37]\tvalid_0's tweedie: 257.686\n",
      "[38]\tvalid_0's tweedie: 257.685\n",
      "[39]\tvalid_0's tweedie: 257.678\n",
      "[40]\tvalid_0's tweedie: 257.677\n",
      "[41]\tvalid_0's tweedie: 257.676\n",
      "[42]\tvalid_0's tweedie: 257.677\n",
      "[43]\tvalid_0's tweedie: 257.675\n",
      "[44]\tvalid_0's tweedie: 257.671\n",
      "[45]\tvalid_0's tweedie: 257.669\n",
      "[46]\tvalid_0's tweedie: 257.668\n",
      "[47]\tvalid_0's tweedie: 257.661\n",
      "[48]\tvalid_0's tweedie: 257.665\n",
      "[49]\tvalid_0's tweedie: 257.663\n",
      "[50]\tvalid_0's tweedie: 257.662\n",
      "[51]\tvalid_0's tweedie: 257.657\n",
      "[52]\tvalid_0's tweedie: 257.655\n",
      "[53]\tvalid_0's tweedie: 257.653\n",
      "[54]\tvalid_0's tweedie: 257.65\n",
      "[55]\tvalid_0's tweedie: 257.646\n",
      "[56]\tvalid_0's tweedie: 257.643\n",
      "[57]\tvalid_0's tweedie: 257.64\n",
      "[58]\tvalid_0's tweedie: 257.639\n",
      "[59]\tvalid_0's tweedie: 257.64\n",
      "[60]\tvalid_0's tweedie: 257.636\n",
      "[61]\tvalid_0's tweedie: 257.639\n",
      "[62]\tvalid_0's tweedie: 257.635\n",
      "[63]\tvalid_0's tweedie: 257.635\n",
      "[64]\tvalid_0's tweedie: 257.633\n",
      "[65]\tvalid_0's tweedie: 257.633\n",
      "[66]\tvalid_0's tweedie: 257.631\n",
      "[67]\tvalid_0's tweedie: 257.629\n",
      "[68]\tvalid_0's tweedie: 257.626\n",
      "[69]\tvalid_0's tweedie: 257.622\n",
      "[70]\tvalid_0's tweedie: 257.623\n",
      "[71]\tvalid_0's tweedie: 257.622\n",
      "[72]\tvalid_0's tweedie: 257.622\n",
      "[73]\tvalid_0's tweedie: 257.622\n",
      "[74]\tvalid_0's tweedie: 257.622\n",
      "[75]\tvalid_0's tweedie: 257.621\n",
      "[76]\tvalid_0's tweedie: 257.621\n",
      "[77]\tvalid_0's tweedie: 257.622\n",
      "[78]\tvalid_0's tweedie: 257.621\n",
      "[79]\tvalid_0's tweedie: 257.62\n",
      "[80]\tvalid_0's tweedie: 257.619\n",
      "[81]\tvalid_0's tweedie: 257.619\n",
      "[82]\tvalid_0's tweedie: 257.618\n",
      "[83]\tvalid_0's tweedie: 257.618\n",
      "[84]\tvalid_0's tweedie: 257.618\n",
      "[85]\tvalid_0's tweedie: 257.618\n",
      "[86]\tvalid_0's tweedie: 257.618\n",
      "[87]\tvalid_0's tweedie: 257.618\n",
      "[88]\tvalid_0's tweedie: 257.619\n",
      "[89]\tvalid_0's tweedie: 257.618\n",
      "[90]\tvalid_0's tweedie: 257.618\n",
      "[91]\tvalid_0's tweedie: 257.618\n",
      "[92]\tvalid_0's tweedie: 257.615\n",
      "[93]\tvalid_0's tweedie: 257.612\n",
      "[94]\tvalid_0's tweedie: 257.612\n",
      "[95]\tvalid_0's tweedie: 257.612\n",
      "[96]\tvalid_0's tweedie: 257.611\n",
      "[97]\tvalid_0's tweedie: 257.611\n",
      "[98]\tvalid_0's tweedie: 257.608\n",
      "[99]\tvalid_0's tweedie: 257.607\n",
      "[100]\tvalid_0's tweedie: 257.608\n",
      "[101]\tvalid_0's tweedie: 257.607\n",
      "[102]\tvalid_0's tweedie: 257.607\n",
      "[103]\tvalid_0's tweedie: 257.606\n",
      "[104]\tvalid_0's tweedie: 257.606\n",
      "[105]\tvalid_0's tweedie: 257.606\n",
      "[106]\tvalid_0's tweedie: 257.606\n",
      "[107]\tvalid_0's tweedie: 257.606\n",
      "[108]\tvalid_0's tweedie: 257.606\n",
      "[109]\tvalid_0's tweedie: 257.606\n",
      "[110]\tvalid_0's tweedie: 257.607\n",
      "[111]\tvalid_0's tweedie: 257.606\n",
      "[112]\tvalid_0's tweedie: 257.606\n",
      "[113]\tvalid_0's tweedie: 257.607\n",
      "[114]\tvalid_0's tweedie: 257.607\n",
      "[115]\tvalid_0's tweedie: 257.606\n",
      "[116]\tvalid_0's tweedie: 257.605\n",
      "[117]\tvalid_0's tweedie: 257.604\n",
      "[118]\tvalid_0's tweedie: 257.604\n",
      "[119]\tvalid_0's tweedie: 257.604\n",
      "[120]\tvalid_0's tweedie: 257.604\n",
      "[121]\tvalid_0's tweedie: 257.604\n",
      "[122]\tvalid_0's tweedie: 257.604\n",
      "[123]\tvalid_0's tweedie: 257.605\n",
      "[124]\tvalid_0's tweedie: 257.604\n",
      "[125]\tvalid_0's tweedie: 257.604\n",
      "[126]\tvalid_0's tweedie: 257.604\n",
      "[127]\tvalid_0's tweedie: 257.603\n",
      "[128]\tvalid_0's tweedie: 257.604\n",
      "[129]\tvalid_0's tweedie: 257.605\n",
      "[130]\tvalid_0's tweedie: 257.605\n",
      "[131]\tvalid_0's tweedie: 257.605\n",
      "[132]\tvalid_0's tweedie: 257.605\n",
      "[133]\tvalid_0's tweedie: 257.605\n",
      "[134]\tvalid_0's tweedie: 257.605\n",
      "[135]\tvalid_0's tweedie: 257.605\n",
      "[136]\tvalid_0's tweedie: 257.603\n",
      "[137]\tvalid_0's tweedie: 257.603\n",
      "[138]\tvalid_0's tweedie: 257.603\n",
      "[139]\tvalid_0's tweedie: 257.603\n",
      "[140]\tvalid_0's tweedie: 257.602\n",
      "[141]\tvalid_0's tweedie: 257.602\n",
      "[142]\tvalid_0's tweedie: 257.602\n",
      "[143]\tvalid_0's tweedie: 257.602\n",
      "[144]\tvalid_0's tweedie: 257.603\n",
      "[145]\tvalid_0's tweedie: 257.603\n",
      "[146]\tvalid_0's tweedie: 257.604\n",
      "[147]\tvalid_0's tweedie: 257.603\n",
      "[148]\tvalid_0's tweedie: 257.603\n",
      "[149]\tvalid_0's tweedie: 257.602\n",
      "[150]\tvalid_0's tweedie: 257.603\n",
      "[151]\tvalid_0's tweedie: 257.603\n",
      "[152]\tvalid_0's tweedie: 257.603\n",
      "[153]\tvalid_0's tweedie: 257.603\n",
      "[154]\tvalid_0's tweedie: 257.603\n",
      "[155]\tvalid_0's tweedie: 257.603\n",
      "[156]\tvalid_0's tweedie: 257.603\n",
      "[157]\tvalid_0's tweedie: 257.603\n",
      "[158]\tvalid_0's tweedie: 257.603\n",
      "[159]\tvalid_0's tweedie: 257.6\n",
      "[160]\tvalid_0's tweedie: 257.599\n",
      "[161]\tvalid_0's tweedie: 257.599\n",
      "[162]\tvalid_0's tweedie: 257.599\n",
      "[163]\tvalid_0's tweedie: 257.599\n",
      "[164]\tvalid_0's tweedie: 257.6\n",
      "[165]\tvalid_0's tweedie: 257.599\n",
      "[166]\tvalid_0's tweedie: 257.6\n",
      "[167]\tvalid_0's tweedie: 257.6\n",
      "[168]\tvalid_0's tweedie: 257.6\n",
      "[169]\tvalid_0's tweedie: 257.6\n",
      "[170]\tvalid_0's tweedie: 257.6\n",
      "[171]\tvalid_0's tweedie: 257.598\n",
      "[172]\tvalid_0's tweedie: 257.598\n",
      "[173]\tvalid_0's tweedie: 257.598\n",
      "[174]\tvalid_0's tweedie: 257.598\n",
      "[175]\tvalid_0's tweedie: 257.598\n",
      "[176]\tvalid_0's tweedie: 257.597\n",
      "[177]\tvalid_0's tweedie: 257.597\n",
      "[178]\tvalid_0's tweedie: 257.597\n",
      "[179]\tvalid_0's tweedie: 257.597\n",
      "[180]\tvalid_0's tweedie: 257.597\n",
      "[181]\tvalid_0's tweedie: 257.597\n",
      "[182]\tvalid_0's tweedie: 257.597\n",
      "[183]\tvalid_0's tweedie: 257.595\n",
      "[184]\tvalid_0's tweedie: 257.595\n",
      "[185]\tvalid_0's tweedie: 257.595\n",
      "[186]\tvalid_0's tweedie: 257.595\n",
      "[187]\tvalid_0's tweedie: 257.594\n",
      "[188]\tvalid_0's tweedie: 257.595\n",
      "[189]\tvalid_0's tweedie: 257.594\n",
      "[190]\tvalid_0's tweedie: 257.594\n",
      "[191]\tvalid_0's tweedie: 257.593\n",
      "[192]\tvalid_0's tweedie: 257.594\n",
      "[193]\tvalid_0's tweedie: 257.595\n",
      "[194]\tvalid_0's tweedie: 257.594\n",
      "[195]\tvalid_0's tweedie: 257.592\n",
      "[196]\tvalid_0's tweedie: 257.592\n",
      "[197]\tvalid_0's tweedie: 257.59\n",
      "[198]\tvalid_0's tweedie: 257.591\n",
      "[199]\tvalid_0's tweedie: 257.591\n",
      "[200]\tvalid_0's tweedie: 257.591\n",
      "[201]\tvalid_0's tweedie: 257.591\n",
      "[202]\tvalid_0's tweedie: 257.591\n",
      "[203]\tvalid_0's tweedie: 257.591\n",
      "[204]\tvalid_0's tweedie: 257.591\n",
      "[205]\tvalid_0's tweedie: 257.591\n",
      "[206]\tvalid_0's tweedie: 257.591\n",
      "[207]\tvalid_0's tweedie: 257.591\n",
      "[208]\tvalid_0's tweedie: 257.591\n",
      "[209]\tvalid_0's tweedie: 257.591\n",
      "[210]\tvalid_0's tweedie: 257.591\n",
      "[211]\tvalid_0's tweedie: 257.59\n",
      "[212]\tvalid_0's tweedie: 257.59\n",
      "[213]\tvalid_0's tweedie: 257.59\n",
      "[214]\tvalid_0's tweedie: 257.591\n",
      "[215]\tvalid_0's tweedie: 257.591\n",
      "[216]\tvalid_0's tweedie: 257.591\n",
      "[217]\tvalid_0's tweedie: 257.59\n",
      "[218]\tvalid_0's tweedie: 257.59\n",
      "[219]\tvalid_0's tweedie: 257.59\n",
      "[220]\tvalid_0's tweedie: 257.59\n",
      "[221]\tvalid_0's tweedie: 257.59\n",
      "[222]\tvalid_0's tweedie: 257.59\n",
      "[223]\tvalid_0's tweedie: 257.589\n",
      "[224]\tvalid_0's tweedie: 257.589\n",
      "[225]\tvalid_0's tweedie: 257.59\n",
      "[226]\tvalid_0's tweedie: 257.59\n",
      "[227]\tvalid_0's tweedie: 257.59\n",
      "[228]\tvalid_0's tweedie: 257.59\n",
      "[229]\tvalid_0's tweedie: 257.589\n",
      "[230]\tvalid_0's tweedie: 257.588\n",
      "[231]\tvalid_0's tweedie: 257.588\n",
      "[232]\tvalid_0's tweedie: 257.588\n",
      "[233]\tvalid_0's tweedie: 257.588\n",
      "[234]\tvalid_0's tweedie: 257.588\n",
      "[235]\tvalid_0's tweedie: 257.589\n",
      "[236]\tvalid_0's tweedie: 257.589\n",
      "[237]\tvalid_0's tweedie: 257.588\n",
      "[238]\tvalid_0's tweedie: 257.588\n",
      "[239]\tvalid_0's tweedie: 257.588\n",
      "[240]\tvalid_0's tweedie: 257.587\n",
      "[241]\tvalid_0's tweedie: 257.588\n",
      "[242]\tvalid_0's tweedie: 257.59\n",
      "[243]\tvalid_0's tweedie: 257.589\n",
      "[244]\tvalid_0's tweedie: 257.589\n",
      "[245]\tvalid_0's tweedie: 257.589\n",
      "[246]\tvalid_0's tweedie: 257.589\n",
      "[247]\tvalid_0's tweedie: 257.589\n",
      "[248]\tvalid_0's tweedie: 257.589\n",
      "[249]\tvalid_0's tweedie: 257.589\n",
      "[250]\tvalid_0's tweedie: 257.589\n",
      "[251]\tvalid_0's tweedie: 257.589\n",
      "[252]\tvalid_0's tweedie: 257.589\n",
      "[253]\tvalid_0's tweedie: 257.589\n",
      "[254]\tvalid_0's tweedie: 257.59\n",
      "[255]\tvalid_0's tweedie: 257.589\n",
      "[256]\tvalid_0's tweedie: 257.59\n",
      "[257]\tvalid_0's tweedie: 257.59\n",
      "[258]\tvalid_0's tweedie: 257.589\n",
      "[259]\tvalid_0's tweedie: 257.59\n",
      "[260]\tvalid_0's tweedie: 257.59\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's tweedie: 257.587\n",
      "Training model for level 3 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 18580, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141417\n",
      "[1]\tvalid_0's tweedie: 260.842\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.326\n",
      "[3]\tvalid_0's tweedie: 259.894\n",
      "[4]\tvalid_0's tweedie: 259.523\n",
      "[5]\tvalid_0's tweedie: 259.223\n",
      "[6]\tvalid_0's tweedie: 258.972\n",
      "[7]\tvalid_0's tweedie: 258.773\n",
      "[8]\tvalid_0's tweedie: 258.598\n",
      "[9]\tvalid_0's tweedie: 258.457\n",
      "[10]\tvalid_0's tweedie: 258.347\n",
      "[11]\tvalid_0's tweedie: 258.247\n",
      "[12]\tvalid_0's tweedie: 258.153\n",
      "[13]\tvalid_0's tweedie: 258.075\n",
      "[14]\tvalid_0's tweedie: 258.014\n",
      "[15]\tvalid_0's tweedie: 257.963\n",
      "[16]\tvalid_0's tweedie: 257.926\n",
      "[17]\tvalid_0's tweedie: 257.893\n",
      "[18]\tvalid_0's tweedie: 257.859\n",
      "[19]\tvalid_0's tweedie: 257.832\n",
      "[20]\tvalid_0's tweedie: 257.808\n",
      "[21]\tvalid_0's tweedie: 257.786\n",
      "[22]\tvalid_0's tweedie: 257.77\n",
      "[23]\tvalid_0's tweedie: 257.755\n",
      "[24]\tvalid_0's tweedie: 257.747\n",
      "[25]\tvalid_0's tweedie: 257.738\n",
      "[26]\tvalid_0's tweedie: 257.73\n",
      "[27]\tvalid_0's tweedie: 257.722\n",
      "[28]\tvalid_0's tweedie: 257.71\n",
      "[29]\tvalid_0's tweedie: 257.704\n",
      "[30]\tvalid_0's tweedie: 257.697\n",
      "[31]\tvalid_0's tweedie: 257.692\n",
      "[32]\tvalid_0's tweedie: 257.686\n",
      "[33]\tvalid_0's tweedie: 257.685\n",
      "[34]\tvalid_0's tweedie: 257.679\n",
      "[35]\tvalid_0's tweedie: 257.679\n",
      "[36]\tvalid_0's tweedie: 257.679\n",
      "[37]\tvalid_0's tweedie: 257.675\n",
      "[38]\tvalid_0's tweedie: 257.676\n",
      "[39]\tvalid_0's tweedie: 257.678\n",
      "[40]\tvalid_0's tweedie: 257.674\n",
      "[41]\tvalid_0's tweedie: 257.671\n",
      "[42]\tvalid_0's tweedie: 257.673\n",
      "[43]\tvalid_0's tweedie: 257.667\n",
      "[44]\tvalid_0's tweedie: 257.665\n",
      "[45]\tvalid_0's tweedie: 257.664\n",
      "[46]\tvalid_0's tweedie: 257.663\n",
      "[47]\tvalid_0's tweedie: 257.66\n",
      "[48]\tvalid_0's tweedie: 257.664\n",
      "[49]\tvalid_0's tweedie: 257.662\n",
      "[50]\tvalid_0's tweedie: 257.661\n",
      "[51]\tvalid_0's tweedie: 257.658\n",
      "[52]\tvalid_0's tweedie: 257.658\n",
      "[53]\tvalid_0's tweedie: 257.652\n",
      "[54]\tvalid_0's tweedie: 257.65\n",
      "[55]\tvalid_0's tweedie: 257.644\n",
      "[56]\tvalid_0's tweedie: 257.64\n",
      "[57]\tvalid_0's tweedie: 257.636\n",
      "[58]\tvalid_0's tweedie: 257.634\n",
      "[59]\tvalid_0's tweedie: 257.632\n",
      "[60]\tvalid_0's tweedie: 257.631\n",
      "[61]\tvalid_0's tweedie: 257.629\n",
      "[62]\tvalid_0's tweedie: 257.629\n",
      "[63]\tvalid_0's tweedie: 257.632\n",
      "[64]\tvalid_0's tweedie: 257.632\n",
      "[65]\tvalid_0's tweedie: 257.631\n",
      "[66]\tvalid_0's tweedie: 257.635\n",
      "[67]\tvalid_0's tweedie: 257.635\n",
      "[68]\tvalid_0's tweedie: 257.636\n",
      "[69]\tvalid_0's tweedie: 257.636\n",
      "[70]\tvalid_0's tweedie: 257.637\n",
      "[71]\tvalid_0's tweedie: 257.637\n",
      "[72]\tvalid_0's tweedie: 257.633\n",
      "[73]\tvalid_0's tweedie: 257.632\n",
      "[74]\tvalid_0's tweedie: 257.63\n",
      "[75]\tvalid_0's tweedie: 257.63\n",
      "[76]\tvalid_0's tweedie: 257.631\n",
      "[77]\tvalid_0's tweedie: 257.63\n",
      "[78]\tvalid_0's tweedie: 257.629\n",
      "[79]\tvalid_0's tweedie: 257.629\n",
      "[80]\tvalid_0's tweedie: 257.629\n",
      "[81]\tvalid_0's tweedie: 257.629\n",
      "[82]\tvalid_0's tweedie: 257.628\n",
      "[83]\tvalid_0's tweedie: 257.628\n",
      "[84]\tvalid_0's tweedie: 257.628\n",
      "[85]\tvalid_0's tweedie: 257.628\n",
      "[86]\tvalid_0's tweedie: 257.628\n",
      "[87]\tvalid_0's tweedie: 257.626\n",
      "[88]\tvalid_0's tweedie: 257.625\n",
      "[89]\tvalid_0's tweedie: 257.625\n",
      "[90]\tvalid_0's tweedie: 257.624\n",
      "[91]\tvalid_0's tweedie: 257.625\n",
      "[92]\tvalid_0's tweedie: 257.623\n",
      "[93]\tvalid_0's tweedie: 257.623\n",
      "[94]\tvalid_0's tweedie: 257.622\n",
      "[95]\tvalid_0's tweedie: 257.621\n",
      "[96]\tvalid_0's tweedie: 257.621\n",
      "[97]\tvalid_0's tweedie: 257.621\n",
      "[98]\tvalid_0's tweedie: 257.621\n",
      "[99]\tvalid_0's tweedie: 257.619\n",
      "[100]\tvalid_0's tweedie: 257.618\n",
      "[101]\tvalid_0's tweedie: 257.618\n",
      "[102]\tvalid_0's tweedie: 257.618\n",
      "[103]\tvalid_0's tweedie: 257.617\n",
      "[104]\tvalid_0's tweedie: 257.617\n",
      "[105]\tvalid_0's tweedie: 257.616\n",
      "[106]\tvalid_0's tweedie: 257.616\n",
      "[107]\tvalid_0's tweedie: 257.616\n",
      "[108]\tvalid_0's tweedie: 257.616\n",
      "[109]\tvalid_0's tweedie: 257.616\n",
      "[110]\tvalid_0's tweedie: 257.616\n",
      "[111]\tvalid_0's tweedie: 257.616\n",
      "[112]\tvalid_0's tweedie: 257.615\n",
      "[113]\tvalid_0's tweedie: 257.615\n",
      "[114]\tvalid_0's tweedie: 257.615\n",
      "[115]\tvalid_0's tweedie: 257.614\n",
      "[116]\tvalid_0's tweedie: 257.614\n",
      "[117]\tvalid_0's tweedie: 257.614\n",
      "[118]\tvalid_0's tweedie: 257.612\n",
      "[119]\tvalid_0's tweedie: 257.613\n",
      "[120]\tvalid_0's tweedie: 257.611\n",
      "[121]\tvalid_0's tweedie: 257.611\n",
      "[122]\tvalid_0's tweedie: 257.61\n",
      "[123]\tvalid_0's tweedie: 257.609\n",
      "[124]\tvalid_0's tweedie: 257.608\n",
      "[125]\tvalid_0's tweedie: 257.608\n",
      "[126]\tvalid_0's tweedie: 257.608\n",
      "[127]\tvalid_0's tweedie: 257.608\n",
      "[128]\tvalid_0's tweedie: 257.606\n",
      "[129]\tvalid_0's tweedie: 257.605\n",
      "[130]\tvalid_0's tweedie: 257.605\n",
      "[131]\tvalid_0's tweedie: 257.605\n",
      "[132]\tvalid_0's tweedie: 257.605\n",
      "[133]\tvalid_0's tweedie: 257.605\n",
      "[134]\tvalid_0's tweedie: 257.604\n",
      "[135]\tvalid_0's tweedie: 257.605\n",
      "[136]\tvalid_0's tweedie: 257.604\n",
      "[137]\tvalid_0's tweedie: 257.604\n",
      "[138]\tvalid_0's tweedie: 257.604\n",
      "[139]\tvalid_0's tweedie: 257.604\n",
      "[140]\tvalid_0's tweedie: 257.603\n",
      "[141]\tvalid_0's tweedie: 257.603\n",
      "[142]\tvalid_0's tweedie: 257.603\n",
      "[143]\tvalid_0's tweedie: 257.604\n",
      "[144]\tvalid_0's tweedie: 257.604\n",
      "[145]\tvalid_0's tweedie: 257.603\n",
      "[146]\tvalid_0's tweedie: 257.603\n",
      "[147]\tvalid_0's tweedie: 257.603\n",
      "[148]\tvalid_0's tweedie: 257.602\n",
      "[149]\tvalid_0's tweedie: 257.602\n",
      "[150]\tvalid_0's tweedie: 257.602\n",
      "[151]\tvalid_0's tweedie: 257.601\n",
      "[152]\tvalid_0's tweedie: 257.6\n",
      "[153]\tvalid_0's tweedie: 257.6\n",
      "[154]\tvalid_0's tweedie: 257.6\n",
      "[155]\tvalid_0's tweedie: 257.6\n",
      "[156]\tvalid_0's tweedie: 257.6\n",
      "[157]\tvalid_0's tweedie: 257.6\n",
      "[158]\tvalid_0's tweedie: 257.6\n",
      "[159]\tvalid_0's tweedie: 257.6\n",
      "[160]\tvalid_0's tweedie: 257.6\n",
      "[161]\tvalid_0's tweedie: 257.601\n",
      "[162]\tvalid_0's tweedie: 257.602\n",
      "[163]\tvalid_0's tweedie: 257.602\n",
      "[164]\tvalid_0's tweedie: 257.603\n",
      "[165]\tvalid_0's tweedie: 257.603\n",
      "[166]\tvalid_0's tweedie: 257.603\n",
      "[167]\tvalid_0's tweedie: 257.603\n",
      "[168]\tvalid_0's tweedie: 257.603\n",
      "[169]\tvalid_0's tweedie: 257.603\n",
      "[170]\tvalid_0's tweedie: 257.602\n",
      "[171]\tvalid_0's tweedie: 257.602\n",
      "[172]\tvalid_0's tweedie: 257.602\n",
      "[173]\tvalid_0's tweedie: 257.602\n",
      "[174]\tvalid_0's tweedie: 257.604\n",
      "[175]\tvalid_0's tweedie: 257.603\n",
      "[176]\tvalid_0's tweedie: 257.603\n",
      "[177]\tvalid_0's tweedie: 257.603\n",
      "[178]\tvalid_0's tweedie: 257.603\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's tweedie: 257.6\n",
      "Training model for level 3 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 18570, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141602\n",
      "[1]\tvalid_0's tweedie: 260.803\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.242\n",
      "[3]\tvalid_0's tweedie: 259.781\n",
      "[4]\tvalid_0's tweedie: 259.415\n",
      "[5]\tvalid_0's tweedie: 259.093\n",
      "[6]\tvalid_0's tweedie: 258.855\n",
      "[7]\tvalid_0's tweedie: 258.636\n",
      "[8]\tvalid_0's tweedie: 258.47\n",
      "[9]\tvalid_0's tweedie: 258.339\n",
      "[10]\tvalid_0's tweedie: 258.234\n",
      "[11]\tvalid_0's tweedie: 258.147\n",
      "[12]\tvalid_0's tweedie: 258.074\n",
      "[13]\tvalid_0's tweedie: 258.012\n",
      "[14]\tvalid_0's tweedie: 257.952\n",
      "[15]\tvalid_0's tweedie: 257.917\n",
      "[16]\tvalid_0's tweedie: 257.876\n",
      "[17]\tvalid_0's tweedie: 257.842\n",
      "[18]\tvalid_0's tweedie: 257.82\n",
      "[19]\tvalid_0's tweedie: 257.793\n",
      "[20]\tvalid_0's tweedie: 257.772\n",
      "[21]\tvalid_0's tweedie: 257.753\n",
      "[22]\tvalid_0's tweedie: 257.74\n",
      "[23]\tvalid_0's tweedie: 257.733\n",
      "[24]\tvalid_0's tweedie: 257.719\n",
      "[25]\tvalid_0's tweedie: 257.708\n",
      "[26]\tvalid_0's tweedie: 257.698\n",
      "[27]\tvalid_0's tweedie: 257.69\n",
      "[28]\tvalid_0's tweedie: 257.68\n",
      "[29]\tvalid_0's tweedie: 257.675\n",
      "[30]\tvalid_0's tweedie: 257.668\n",
      "[31]\tvalid_0's tweedie: 257.662\n",
      "[32]\tvalid_0's tweedie: 257.658\n",
      "[33]\tvalid_0's tweedie: 257.656\n",
      "[34]\tvalid_0's tweedie: 257.652\n",
      "[35]\tvalid_0's tweedie: 257.65\n",
      "[36]\tvalid_0's tweedie: 257.646\n",
      "[37]\tvalid_0's tweedie: 257.646\n",
      "[38]\tvalid_0's tweedie: 257.644\n",
      "[39]\tvalid_0's tweedie: 257.64\n",
      "[40]\tvalid_0's tweedie: 257.646\n",
      "[41]\tvalid_0's tweedie: 257.644\n",
      "[42]\tvalid_0's tweedie: 257.641\n",
      "[43]\tvalid_0's tweedie: 257.643\n",
      "[44]\tvalid_0's tweedie: 257.641\n",
      "[45]\tvalid_0's tweedie: 257.642\n",
      "[46]\tvalid_0's tweedie: 257.64\n",
      "[47]\tvalid_0's tweedie: 257.638\n",
      "[48]\tvalid_0's tweedie: 257.637\n",
      "[49]\tvalid_0's tweedie: 257.635\n",
      "[50]\tvalid_0's tweedie: 257.635\n",
      "[51]\tvalid_0's tweedie: 257.632\n",
      "[52]\tvalid_0's tweedie: 257.633\n",
      "[53]\tvalid_0's tweedie: 257.631\n",
      "[54]\tvalid_0's tweedie: 257.628\n",
      "[55]\tvalid_0's tweedie: 257.625\n",
      "[56]\tvalid_0's tweedie: 257.623\n",
      "[57]\tvalid_0's tweedie: 257.623\n",
      "[58]\tvalid_0's tweedie: 257.621\n",
      "[59]\tvalid_0's tweedie: 257.623\n",
      "[60]\tvalid_0's tweedie: 257.62\n",
      "[61]\tvalid_0's tweedie: 257.622\n",
      "[62]\tvalid_0's tweedie: 257.622\n",
      "[63]\tvalid_0's tweedie: 257.624\n",
      "[64]\tvalid_0's tweedie: 257.625\n",
      "[65]\tvalid_0's tweedie: 257.623\n",
      "[66]\tvalid_0's tweedie: 257.623\n",
      "[67]\tvalid_0's tweedie: 257.622\n",
      "[68]\tvalid_0's tweedie: 257.62\n",
      "[69]\tvalid_0's tweedie: 257.619\n",
      "[70]\tvalid_0's tweedie: 257.62\n",
      "[71]\tvalid_0's tweedie: 257.619\n",
      "[72]\tvalid_0's tweedie: 257.617\n",
      "[73]\tvalid_0's tweedie: 257.617\n",
      "[74]\tvalid_0's tweedie: 257.617\n",
      "[75]\tvalid_0's tweedie: 257.615\n",
      "[76]\tvalid_0's tweedie: 257.615\n",
      "[77]\tvalid_0's tweedie: 257.615\n",
      "[78]\tvalid_0's tweedie: 257.614\n",
      "[79]\tvalid_0's tweedie: 257.613\n",
      "[80]\tvalid_0's tweedie: 257.611\n",
      "[81]\tvalid_0's tweedie: 257.61\n",
      "[82]\tvalid_0's tweedie: 257.606\n",
      "[83]\tvalid_0's tweedie: 257.606\n",
      "[84]\tvalid_0's tweedie: 257.606\n",
      "[85]\tvalid_0's tweedie: 257.606\n",
      "[86]\tvalid_0's tweedie: 257.605\n",
      "[87]\tvalid_0's tweedie: 257.606\n",
      "[88]\tvalid_0's tweedie: 257.606\n",
      "[89]\tvalid_0's tweedie: 257.606\n",
      "[90]\tvalid_0's tweedie: 257.603\n",
      "[91]\tvalid_0's tweedie: 257.603\n",
      "[92]\tvalid_0's tweedie: 257.603\n",
      "[93]\tvalid_0's tweedie: 257.603\n",
      "[94]\tvalid_0's tweedie: 257.602\n",
      "[95]\tvalid_0's tweedie: 257.602\n",
      "[96]\tvalid_0's tweedie: 257.599\n",
      "[97]\tvalid_0's tweedie: 257.598\n",
      "[98]\tvalid_0's tweedie: 257.598\n",
      "[99]\tvalid_0's tweedie: 257.598\n",
      "[100]\tvalid_0's tweedie: 257.597\n",
      "[101]\tvalid_0's tweedie: 257.597\n",
      "[102]\tvalid_0's tweedie: 257.595\n",
      "[103]\tvalid_0's tweedie: 257.595\n",
      "[104]\tvalid_0's tweedie: 257.595\n",
      "[105]\tvalid_0's tweedie: 257.594\n",
      "[106]\tvalid_0's tweedie: 257.594\n",
      "[107]\tvalid_0's tweedie: 257.594\n",
      "[108]\tvalid_0's tweedie: 257.592\n",
      "[109]\tvalid_0's tweedie: 257.592\n",
      "[110]\tvalid_0's tweedie: 257.592\n",
      "[111]\tvalid_0's tweedie: 257.592\n",
      "[112]\tvalid_0's tweedie: 257.591\n",
      "[113]\tvalid_0's tweedie: 257.591\n",
      "[114]\tvalid_0's tweedie: 257.592\n",
      "[115]\tvalid_0's tweedie: 257.592\n",
      "[116]\tvalid_0's tweedie: 257.592\n",
      "[117]\tvalid_0's tweedie: 257.592\n",
      "[118]\tvalid_0's tweedie: 257.591\n",
      "[119]\tvalid_0's tweedie: 257.591\n",
      "[120]\tvalid_0's tweedie: 257.591\n",
      "[121]\tvalid_0's tweedie: 257.592\n",
      "[122]\tvalid_0's tweedie: 257.591\n",
      "[123]\tvalid_0's tweedie: 257.592\n",
      "[124]\tvalid_0's tweedie: 257.59\n",
      "[125]\tvalid_0's tweedie: 257.587\n",
      "[126]\tvalid_0's tweedie: 257.587\n",
      "[127]\tvalid_0's tweedie: 257.586\n",
      "[128]\tvalid_0's tweedie: 257.586\n",
      "[129]\tvalid_0's tweedie: 257.586\n",
      "[130]\tvalid_0's tweedie: 257.586\n",
      "[131]\tvalid_0's tweedie: 257.587\n",
      "[132]\tvalid_0's tweedie: 257.588\n",
      "[133]\tvalid_0's tweedie: 257.587\n",
      "[134]\tvalid_0's tweedie: 257.588\n",
      "[135]\tvalid_0's tweedie: 257.587\n",
      "[136]\tvalid_0's tweedie: 257.588\n",
      "[137]\tvalid_0's tweedie: 257.587\n",
      "[138]\tvalid_0's tweedie: 257.587\n",
      "[139]\tvalid_0's tweedie: 257.587\n",
      "[140]\tvalid_0's tweedie: 257.587\n",
      "[141]\tvalid_0's tweedie: 257.587\n",
      "[142]\tvalid_0's tweedie: 257.586\n",
      "[143]\tvalid_0's tweedie: 257.586\n",
      "[144]\tvalid_0's tweedie: 257.585\n",
      "[145]\tvalid_0's tweedie: 257.585\n",
      "[146]\tvalid_0's tweedie: 257.584\n",
      "[147]\tvalid_0's tweedie: 257.583\n",
      "[148]\tvalid_0's tweedie: 257.583\n",
      "[149]\tvalid_0's tweedie: 257.583\n",
      "[150]\tvalid_0's tweedie: 257.583\n",
      "[151]\tvalid_0's tweedie: 257.582\n",
      "[152]\tvalid_0's tweedie: 257.582\n",
      "[153]\tvalid_0's tweedie: 257.582\n",
      "[154]\tvalid_0's tweedie: 257.582\n",
      "[155]\tvalid_0's tweedie: 257.58\n",
      "[156]\tvalid_0's tweedie: 257.58\n",
      "[157]\tvalid_0's tweedie: 257.581\n",
      "[158]\tvalid_0's tweedie: 257.581\n",
      "[159]\tvalid_0's tweedie: 257.58\n",
      "[160]\tvalid_0's tweedie: 257.58\n",
      "[161]\tvalid_0's tweedie: 257.581\n",
      "[162]\tvalid_0's tweedie: 257.583\n",
      "[163]\tvalid_0's tweedie: 257.584\n",
      "[164]\tvalid_0's tweedie: 257.584\n",
      "[165]\tvalid_0's tweedie: 257.584\n",
      "[166]\tvalid_0's tweedie: 257.584\n",
      "[167]\tvalid_0's tweedie: 257.584\n",
      "[168]\tvalid_0's tweedie: 257.583\n",
      "[169]\tvalid_0's tweedie: 257.584\n",
      "[170]\tvalid_0's tweedie: 257.584\n",
      "[171]\tvalid_0's tweedie: 257.583\n",
      "[172]\tvalid_0's tweedie: 257.584\n",
      "[173]\tvalid_0's tweedie: 257.583\n",
      "[174]\tvalid_0's tweedie: 257.583\n",
      "[175]\tvalid_0's tweedie: 257.581\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's tweedie: 257.58\n",
      "Training model for level 3 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 18560, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141672\n",
      "[1]\tvalid_0's tweedie: 260.799\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.245\n",
      "[3]\tvalid_0's tweedie: 259.787\n",
      "[4]\tvalid_0's tweedie: 259.406\n",
      "[5]\tvalid_0's tweedie: 259.108\n",
      "[6]\tvalid_0's tweedie: 258.872\n",
      "[7]\tvalid_0's tweedie: 258.66\n",
      "[8]\tvalid_0's tweedie: 258.488\n",
      "[9]\tvalid_0's tweedie: 258.35\n",
      "[10]\tvalid_0's tweedie: 258.231\n",
      "[11]\tvalid_0's tweedie: 258.137\n",
      "[12]\tvalid_0's tweedie: 258.06\n",
      "[13]\tvalid_0's tweedie: 257.997\n",
      "[14]\tvalid_0's tweedie: 257.955\n",
      "[15]\tvalid_0's tweedie: 257.907\n",
      "[16]\tvalid_0's tweedie: 257.86\n",
      "[17]\tvalid_0's tweedie: 257.83\n",
      "[18]\tvalid_0's tweedie: 257.802\n",
      "[19]\tvalid_0's tweedie: 257.777\n",
      "[20]\tvalid_0's tweedie: 257.756\n",
      "[21]\tvalid_0's tweedie: 257.745\n",
      "[22]\tvalid_0's tweedie: 257.729\n",
      "[23]\tvalid_0's tweedie: 257.718\n",
      "[24]\tvalid_0's tweedie: 257.707\n",
      "[25]\tvalid_0's tweedie: 257.699\n",
      "[26]\tvalid_0's tweedie: 257.692\n",
      "[27]\tvalid_0's tweedie: 257.68\n",
      "[28]\tvalid_0's tweedie: 257.671\n",
      "[29]\tvalid_0's tweedie: 257.665\n",
      "[30]\tvalid_0's tweedie: 257.66\n",
      "[31]\tvalid_0's tweedie: 257.656\n",
      "[32]\tvalid_0's tweedie: 257.654\n",
      "[33]\tvalid_0's tweedie: 257.652\n",
      "[34]\tvalid_0's tweedie: 257.647\n",
      "[35]\tvalid_0's tweedie: 257.647\n",
      "[36]\tvalid_0's tweedie: 257.643\n",
      "[37]\tvalid_0's tweedie: 257.643\n",
      "[38]\tvalid_0's tweedie: 257.641\n",
      "[39]\tvalid_0's tweedie: 257.637\n",
      "[40]\tvalid_0's tweedie: 257.637\n",
      "[41]\tvalid_0's tweedie: 257.634\n",
      "[42]\tvalid_0's tweedie: 257.634\n",
      "[43]\tvalid_0's tweedie: 257.634\n",
      "[44]\tvalid_0's tweedie: 257.631\n",
      "[45]\tvalid_0's tweedie: 257.625\n",
      "[46]\tvalid_0's tweedie: 257.628\n",
      "[47]\tvalid_0's tweedie: 257.628\n",
      "[48]\tvalid_0's tweedie: 257.63\n",
      "[49]\tvalid_0's tweedie: 257.63\n",
      "[50]\tvalid_0's tweedie: 257.629\n",
      "[51]\tvalid_0's tweedie: 257.627\n",
      "[52]\tvalid_0's tweedie: 257.625\n",
      "[53]\tvalid_0's tweedie: 257.625\n",
      "[54]\tvalid_0's tweedie: 257.624\n",
      "[55]\tvalid_0's tweedie: 257.624\n",
      "[56]\tvalid_0's tweedie: 257.622\n",
      "[57]\tvalid_0's tweedie: 257.621\n",
      "[58]\tvalid_0's tweedie: 257.62\n",
      "[59]\tvalid_0's tweedie: 257.621\n",
      "[60]\tvalid_0's tweedie: 257.62\n",
      "[61]\tvalid_0's tweedie: 257.618\n",
      "[62]\tvalid_0's tweedie: 257.618\n",
      "[63]\tvalid_0's tweedie: 257.617\n",
      "[64]\tvalid_0's tweedie: 257.613\n",
      "[65]\tvalid_0's tweedie: 257.612\n",
      "[66]\tvalid_0's tweedie: 257.612\n",
      "[67]\tvalid_0's tweedie: 257.612\n",
      "[68]\tvalid_0's tweedie: 257.612\n",
      "[69]\tvalid_0's tweedie: 257.612\n",
      "[70]\tvalid_0's tweedie: 257.61\n",
      "[71]\tvalid_0's tweedie: 257.611\n",
      "[72]\tvalid_0's tweedie: 257.61\n",
      "[73]\tvalid_0's tweedie: 257.609\n",
      "[74]\tvalid_0's tweedie: 257.61\n",
      "[75]\tvalid_0's tweedie: 257.61\n",
      "[76]\tvalid_0's tweedie: 257.608\n",
      "[77]\tvalid_0's tweedie: 257.607\n",
      "[78]\tvalid_0's tweedie: 257.607\n",
      "[79]\tvalid_0's tweedie: 257.605\n",
      "[80]\tvalid_0's tweedie: 257.604\n",
      "[81]\tvalid_0's tweedie: 257.604\n",
      "[82]\tvalid_0's tweedie: 257.603\n",
      "[83]\tvalid_0's tweedie: 257.604\n",
      "[84]\tvalid_0's tweedie: 257.603\n",
      "[85]\tvalid_0's tweedie: 257.601\n",
      "[86]\tvalid_0's tweedie: 257.603\n",
      "[87]\tvalid_0's tweedie: 257.603\n",
      "[88]\tvalid_0's tweedie: 257.603\n",
      "[89]\tvalid_0's tweedie: 257.601\n",
      "[90]\tvalid_0's tweedie: 257.601\n",
      "[91]\tvalid_0's tweedie: 257.6\n",
      "[92]\tvalid_0's tweedie: 257.6\n",
      "[93]\tvalid_0's tweedie: 257.599\n",
      "[94]\tvalid_0's tweedie: 257.598\n",
      "[95]\tvalid_0's tweedie: 257.598\n",
      "[96]\tvalid_0's tweedie: 257.598\n",
      "[97]\tvalid_0's tweedie: 257.598\n",
      "[98]\tvalid_0's tweedie: 257.598\n",
      "[99]\tvalid_0's tweedie: 257.597\n",
      "[100]\tvalid_0's tweedie: 257.597\n",
      "[101]\tvalid_0's tweedie: 257.597\n",
      "[102]\tvalid_0's tweedie: 257.597\n",
      "[103]\tvalid_0's tweedie: 257.597\n",
      "[104]\tvalid_0's tweedie: 257.597\n",
      "[105]\tvalid_0's tweedie: 257.597\n",
      "[106]\tvalid_0's tweedie: 257.597\n",
      "[107]\tvalid_0's tweedie: 257.597\n",
      "[108]\tvalid_0's tweedie: 257.596\n",
      "[109]\tvalid_0's tweedie: 257.597\n",
      "[110]\tvalid_0's tweedie: 257.597\n",
      "[111]\tvalid_0's tweedie: 257.597\n",
      "[112]\tvalid_0's tweedie: 257.597\n",
      "[113]\tvalid_0's tweedie: 257.596\n",
      "[114]\tvalid_0's tweedie: 257.596\n",
      "[115]\tvalid_0's tweedie: 257.596\n",
      "[116]\tvalid_0's tweedie: 257.594\n",
      "[117]\tvalid_0's tweedie: 257.594\n",
      "[118]\tvalid_0's tweedie: 257.593\n",
      "[119]\tvalid_0's tweedie: 257.593\n",
      "[120]\tvalid_0's tweedie: 257.593\n",
      "[121]\tvalid_0's tweedie: 257.593\n",
      "[122]\tvalid_0's tweedie: 257.593\n",
      "[123]\tvalid_0's tweedie: 257.593\n",
      "[124]\tvalid_0's tweedie: 257.593\n",
      "[125]\tvalid_0's tweedie: 257.594\n",
      "[126]\tvalid_0's tweedie: 257.593\n",
      "[127]\tvalid_0's tweedie: 257.593\n",
      "[128]\tvalid_0's tweedie: 257.592\n",
      "[129]\tvalid_0's tweedie: 257.592\n",
      "[130]\tvalid_0's tweedie: 257.592\n",
      "[131]\tvalid_0's tweedie: 257.592\n",
      "[132]\tvalid_0's tweedie: 257.591\n",
      "[133]\tvalid_0's tweedie: 257.591\n",
      "[134]\tvalid_0's tweedie: 257.591\n",
      "[135]\tvalid_0's tweedie: 257.589\n",
      "[136]\tvalid_0's tweedie: 257.588\n",
      "[137]\tvalid_0's tweedie: 257.588\n",
      "[138]\tvalid_0's tweedie: 257.588\n",
      "[139]\tvalid_0's tweedie: 257.586\n",
      "[140]\tvalid_0's tweedie: 257.586\n",
      "[141]\tvalid_0's tweedie: 257.586\n",
      "[142]\tvalid_0's tweedie: 257.586\n",
      "[143]\tvalid_0's tweedie: 257.586\n",
      "[144]\tvalid_0's tweedie: 257.584\n",
      "[145]\tvalid_0's tweedie: 257.584\n",
      "[146]\tvalid_0's tweedie: 257.582\n",
      "[147]\tvalid_0's tweedie: 257.582\n",
      "[148]\tvalid_0's tweedie: 257.582\n",
      "[149]\tvalid_0's tweedie: 257.582\n",
      "[150]\tvalid_0's tweedie: 257.582\n",
      "[151]\tvalid_0's tweedie: 257.584\n",
      "[152]\tvalid_0's tweedie: 257.583\n",
      "[153]\tvalid_0's tweedie: 257.584\n",
      "[154]\tvalid_0's tweedie: 257.584\n",
      "[155]\tvalid_0's tweedie: 257.584\n",
      "[156]\tvalid_0's tweedie: 257.584\n",
      "[157]\tvalid_0's tweedie: 257.584\n",
      "[158]\tvalid_0's tweedie: 257.584\n",
      "[159]\tvalid_0's tweedie: 257.584\n",
      "[160]\tvalid_0's tweedie: 257.584\n",
      "[161]\tvalid_0's tweedie: 257.583\n",
      "[162]\tvalid_0's tweedie: 257.583\n",
      "[163]\tvalid_0's tweedie: 257.583\n",
      "[164]\tvalid_0's tweedie: 257.582\n",
      "[165]\tvalid_0's tweedie: 257.582\n",
      "[166]\tvalid_0's tweedie: 257.582\n",
      "[167]\tvalid_0's tweedie: 257.582\n",
      "[168]\tvalid_0's tweedie: 257.582\n",
      "[169]\tvalid_0's tweedie: 257.581\n",
      "[170]\tvalid_0's tweedie: 257.58\n",
      "[171]\tvalid_0's tweedie: 257.58\n",
      "[172]\tvalid_0's tweedie: 257.581\n",
      "[173]\tvalid_0's tweedie: 257.58\n",
      "[174]\tvalid_0's tweedie: 257.58\n",
      "[175]\tvalid_0's tweedie: 257.58\n",
      "[176]\tvalid_0's tweedie: 257.58\n",
      "[177]\tvalid_0's tweedie: 257.58\n",
      "[178]\tvalid_0's tweedie: 257.579\n",
      "[179]\tvalid_0's tweedie: 257.579\n",
      "[180]\tvalid_0's tweedie: 257.579\n",
      "[181]\tvalid_0's tweedie: 257.579\n",
      "[182]\tvalid_0's tweedie: 257.579\n",
      "[183]\tvalid_0's tweedie: 257.577\n",
      "[184]\tvalid_0's tweedie: 257.576\n",
      "[185]\tvalid_0's tweedie: 257.576\n",
      "[186]\tvalid_0's tweedie: 257.576\n",
      "[187]\tvalid_0's tweedie: 257.577\n",
      "[188]\tvalid_0's tweedie: 257.577\n",
      "[189]\tvalid_0's tweedie: 257.577\n",
      "[190]\tvalid_0's tweedie: 257.577\n",
      "[191]\tvalid_0's tweedie: 257.577\n",
      "[192]\tvalid_0's tweedie: 257.577\n",
      "[193]\tvalid_0's tweedie: 257.577\n",
      "[194]\tvalid_0's tweedie: 257.577\n",
      "[195]\tvalid_0's tweedie: 257.577\n",
      "[196]\tvalid_0's tweedie: 257.576\n",
      "[197]\tvalid_0's tweedie: 257.576\n",
      "[198]\tvalid_0's tweedie: 257.576\n",
      "[199]\tvalid_0's tweedie: 257.576\n",
      "[200]\tvalid_0's tweedie: 257.575\n",
      "[201]\tvalid_0's tweedie: 257.574\n",
      "[202]\tvalid_0's tweedie: 257.574\n",
      "[203]\tvalid_0's tweedie: 257.574\n",
      "[204]\tvalid_0's tweedie: 257.574\n",
      "[205]\tvalid_0's tweedie: 257.574\n",
      "[206]\tvalid_0's tweedie: 257.574\n",
      "[207]\tvalid_0's tweedie: 257.573\n",
      "[208]\tvalid_0's tweedie: 257.573\n",
      "[209]\tvalid_0's tweedie: 257.574\n",
      "[210]\tvalid_0's tweedie: 257.573\n",
      "[211]\tvalid_0's tweedie: 257.573\n",
      "[212]\tvalid_0's tweedie: 257.573\n",
      "[213]\tvalid_0's tweedie: 257.574\n",
      "[214]\tvalid_0's tweedie: 257.574\n",
      "[215]\tvalid_0's tweedie: 257.573\n",
      "[216]\tvalid_0's tweedie: 257.573\n",
      "[217]\tvalid_0's tweedie: 257.574\n",
      "[218]\tvalid_0's tweedie: 257.574\n",
      "[219]\tvalid_0's tweedie: 257.575\n",
      "[220]\tvalid_0's tweedie: 257.575\n",
      "[221]\tvalid_0's tweedie: 257.574\n",
      "[222]\tvalid_0's tweedie: 257.574\n",
      "[223]\tvalid_0's tweedie: 257.574\n",
      "[224]\tvalid_0's tweedie: 257.574\n",
      "[225]\tvalid_0's tweedie: 257.574\n",
      "[226]\tvalid_0's tweedie: 257.574\n",
      "[227]\tvalid_0's tweedie: 257.574\n",
      "[228]\tvalid_0's tweedie: 257.574\n",
      "[229]\tvalid_0's tweedie: 257.574\n",
      "[230]\tvalid_0's tweedie: 257.574\n",
      "[231]\tvalid_0's tweedie: 257.574\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's tweedie: 257.573\n",
      "Training model for level 3 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 18550, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141760\n",
      "[1]\tvalid_0's tweedie: 260.806\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.253\n",
      "[3]\tvalid_0's tweedie: 259.793\n",
      "[4]\tvalid_0's tweedie: 259.418\n",
      "[5]\tvalid_0's tweedie: 259.111\n",
      "[6]\tvalid_0's tweedie: 258.874\n",
      "[7]\tvalid_0's tweedie: 258.655\n",
      "[8]\tvalid_0's tweedie: 258.493\n",
      "[9]\tvalid_0's tweedie: 258.362\n",
      "[10]\tvalid_0's tweedie: 258.248\n",
      "[11]\tvalid_0's tweedie: 258.148\n",
      "[12]\tvalid_0's tweedie: 258.071\n",
      "[13]\tvalid_0's tweedie: 258.004\n",
      "[14]\tvalid_0's tweedie: 257.944\n",
      "[15]\tvalid_0's tweedie: 257.892\n",
      "[16]\tvalid_0's tweedie: 257.856\n",
      "[17]\tvalid_0's tweedie: 257.817\n",
      "[18]\tvalid_0's tweedie: 257.787\n",
      "[19]\tvalid_0's tweedie: 257.766\n",
      "[20]\tvalid_0's tweedie: 257.741\n",
      "[21]\tvalid_0's tweedie: 257.723\n",
      "[22]\tvalid_0's tweedie: 257.714\n",
      "[23]\tvalid_0's tweedie: 257.7\n",
      "[24]\tvalid_0's tweedie: 257.692\n",
      "[25]\tvalid_0's tweedie: 257.684\n",
      "[26]\tvalid_0's tweedie: 257.678\n",
      "[27]\tvalid_0's tweedie: 257.675\n",
      "[28]\tvalid_0's tweedie: 257.665\n",
      "[29]\tvalid_0's tweedie: 257.659\n",
      "[30]\tvalid_0's tweedie: 257.654\n",
      "[31]\tvalid_0's tweedie: 257.651\n",
      "[32]\tvalid_0's tweedie: 257.648\n",
      "[33]\tvalid_0's tweedie: 257.646\n",
      "[34]\tvalid_0's tweedie: 257.645\n",
      "[35]\tvalid_0's tweedie: 257.643\n",
      "[36]\tvalid_0's tweedie: 257.64\n",
      "[37]\tvalid_0's tweedie: 257.64\n",
      "[38]\tvalid_0's tweedie: 257.638\n",
      "[39]\tvalid_0's tweedie: 257.637\n",
      "[40]\tvalid_0's tweedie: 257.637\n",
      "[41]\tvalid_0's tweedie: 257.639\n",
      "[42]\tvalid_0's tweedie: 257.642\n",
      "[43]\tvalid_0's tweedie: 257.641\n",
      "[44]\tvalid_0's tweedie: 257.647\n",
      "[45]\tvalid_0's tweedie: 257.643\n",
      "[46]\tvalid_0's tweedie: 257.645\n",
      "[47]\tvalid_0's tweedie: 257.643\n",
      "[48]\tvalid_0's tweedie: 257.64\n",
      "[49]\tvalid_0's tweedie: 257.638\n",
      "[50]\tvalid_0's tweedie: 257.635\n",
      "[51]\tvalid_0's tweedie: 257.633\n",
      "[52]\tvalid_0's tweedie: 257.631\n",
      "[53]\tvalid_0's tweedie: 257.631\n",
      "[54]\tvalid_0's tweedie: 257.63\n",
      "[55]\tvalid_0's tweedie: 257.631\n",
      "[56]\tvalid_0's tweedie: 257.63\n",
      "[57]\tvalid_0's tweedie: 257.628\n",
      "[58]\tvalid_0's tweedie: 257.629\n",
      "[59]\tvalid_0's tweedie: 257.628\n",
      "[60]\tvalid_0's tweedie: 257.628\n",
      "[61]\tvalid_0's tweedie: 257.626\n",
      "[62]\tvalid_0's tweedie: 257.625\n",
      "[63]\tvalid_0's tweedie: 257.624\n",
      "[64]\tvalid_0's tweedie: 257.624\n",
      "[65]\tvalid_0's tweedie: 257.622\n",
      "[66]\tvalid_0's tweedie: 257.622\n",
      "[67]\tvalid_0's tweedie: 257.621\n",
      "[68]\tvalid_0's tweedie: 257.617\n",
      "[69]\tvalid_0's tweedie: 257.62\n",
      "[70]\tvalid_0's tweedie: 257.62\n",
      "[71]\tvalid_0's tweedie: 257.619\n",
      "[72]\tvalid_0's tweedie: 257.619\n",
      "[73]\tvalid_0's tweedie: 257.619\n",
      "[74]\tvalid_0's tweedie: 257.615\n",
      "[75]\tvalid_0's tweedie: 257.613\n",
      "[76]\tvalid_0's tweedie: 257.61\n",
      "[77]\tvalid_0's tweedie: 257.61\n",
      "[78]\tvalid_0's tweedie: 257.61\n",
      "[79]\tvalid_0's tweedie: 257.609\n",
      "[80]\tvalid_0's tweedie: 257.608\n",
      "[81]\tvalid_0's tweedie: 257.609\n",
      "[82]\tvalid_0's tweedie: 257.608\n",
      "[83]\tvalid_0's tweedie: 257.608\n",
      "[84]\tvalid_0's tweedie: 257.608\n",
      "[85]\tvalid_0's tweedie: 257.608\n",
      "[86]\tvalid_0's tweedie: 257.607\n",
      "[87]\tvalid_0's tweedie: 257.607\n",
      "[88]\tvalid_0's tweedie: 257.606\n",
      "[89]\tvalid_0's tweedie: 257.606\n",
      "[90]\tvalid_0's tweedie: 257.605\n",
      "[91]\tvalid_0's tweedie: 257.602\n",
      "[92]\tvalid_0's tweedie: 257.601\n",
      "[93]\tvalid_0's tweedie: 257.601\n",
      "[94]\tvalid_0's tweedie: 257.601\n",
      "[95]\tvalid_0's tweedie: 257.6\n",
      "[96]\tvalid_0's tweedie: 257.599\n",
      "[97]\tvalid_0's tweedie: 257.599\n",
      "[98]\tvalid_0's tweedie: 257.6\n",
      "[99]\tvalid_0's tweedie: 257.6\n",
      "[100]\tvalid_0's tweedie: 257.599\n",
      "[101]\tvalid_0's tweedie: 257.598\n",
      "[102]\tvalid_0's tweedie: 257.595\n",
      "[103]\tvalid_0's tweedie: 257.595\n",
      "[104]\tvalid_0's tweedie: 257.594\n",
      "[105]\tvalid_0's tweedie: 257.594\n",
      "[106]\tvalid_0's tweedie: 257.592\n",
      "[107]\tvalid_0's tweedie: 257.592\n",
      "[108]\tvalid_0's tweedie: 257.59\n",
      "[109]\tvalid_0's tweedie: 257.59\n",
      "[110]\tvalid_0's tweedie: 257.589\n",
      "[111]\tvalid_0's tweedie: 257.587\n",
      "[112]\tvalid_0's tweedie: 257.586\n",
      "[113]\tvalid_0's tweedie: 257.585\n",
      "[114]\tvalid_0's tweedie: 257.585\n",
      "[115]\tvalid_0's tweedie: 257.585\n",
      "[116]\tvalid_0's tweedie: 257.585\n",
      "[117]\tvalid_0's tweedie: 257.585\n",
      "[118]\tvalid_0's tweedie: 257.585\n",
      "[119]\tvalid_0's tweedie: 257.585\n",
      "[120]\tvalid_0's tweedie: 257.585\n",
      "[121]\tvalid_0's tweedie: 257.584\n",
      "[122]\tvalid_0's tweedie: 257.584\n",
      "[123]\tvalid_0's tweedie: 257.582\n",
      "[124]\tvalid_0's tweedie: 257.581\n",
      "[125]\tvalid_0's tweedie: 257.581\n",
      "[126]\tvalid_0's tweedie: 257.581\n",
      "[127]\tvalid_0's tweedie: 257.581\n",
      "[128]\tvalid_0's tweedie: 257.581\n",
      "[129]\tvalid_0's tweedie: 257.58\n",
      "[130]\tvalid_0's tweedie: 257.581\n",
      "[131]\tvalid_0's tweedie: 257.581\n",
      "[132]\tvalid_0's tweedie: 257.581\n",
      "[133]\tvalid_0's tweedie: 257.58\n",
      "[134]\tvalid_0's tweedie: 257.58\n",
      "[135]\tvalid_0's tweedie: 257.58\n",
      "[136]\tvalid_0's tweedie: 257.58\n",
      "[137]\tvalid_0's tweedie: 257.58\n",
      "[138]\tvalid_0's tweedie: 257.58\n",
      "[139]\tvalid_0's tweedie: 257.58\n",
      "[140]\tvalid_0's tweedie: 257.579\n",
      "[141]\tvalid_0's tweedie: 257.58\n",
      "[142]\tvalid_0's tweedie: 257.58\n",
      "[143]\tvalid_0's tweedie: 257.582\n",
      "[144]\tvalid_0's tweedie: 257.582\n",
      "[145]\tvalid_0's tweedie: 257.582\n",
      "[146]\tvalid_0's tweedie: 257.582\n",
      "[147]\tvalid_0's tweedie: 257.582\n",
      "[148]\tvalid_0's tweedie: 257.582\n",
      "[149]\tvalid_0's tweedie: 257.582\n",
      "[150]\tvalid_0's tweedie: 257.582\n",
      "[151]\tvalid_0's tweedie: 257.582\n",
      "[152]\tvalid_0's tweedie: 257.581\n",
      "[153]\tvalid_0's tweedie: 257.58\n",
      "[154]\tvalid_0's tweedie: 257.58\n",
      "[155]\tvalid_0's tweedie: 257.58\n",
      "[156]\tvalid_0's tweedie: 257.581\n",
      "[157]\tvalid_0's tweedie: 257.581\n",
      "[158]\tvalid_0's tweedie: 257.58\n",
      "[159]\tvalid_0's tweedie: 257.579\n",
      "[160]\tvalid_0's tweedie: 257.579\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's tweedie: 257.579\n",
      "Training model for level 3 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 18540, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.141966\n",
      "[1]\tvalid_0's tweedie: 260.804\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.247\n",
      "[3]\tvalid_0's tweedie: 259.792\n",
      "[4]\tvalid_0's tweedie: 259.411\n",
      "[5]\tvalid_0's tweedie: 259.112\n",
      "[6]\tvalid_0's tweedie: 258.854\n",
      "[7]\tvalid_0's tweedie: 258.656\n",
      "[8]\tvalid_0's tweedie: 258.482\n",
      "[9]\tvalid_0's tweedie: 258.352\n",
      "[10]\tvalid_0's tweedie: 258.242\n",
      "[11]\tvalid_0's tweedie: 258.148\n",
      "[12]\tvalid_0's tweedie: 258.072\n",
      "[13]\tvalid_0's tweedie: 257.999\n",
      "[14]\tvalid_0's tweedie: 257.937\n",
      "[15]\tvalid_0's tweedie: 257.884\n",
      "[16]\tvalid_0's tweedie: 257.842\n",
      "[17]\tvalid_0's tweedie: 257.805\n",
      "[18]\tvalid_0's tweedie: 257.774\n",
      "[19]\tvalid_0's tweedie: 257.749\n",
      "[20]\tvalid_0's tweedie: 257.732\n",
      "[21]\tvalid_0's tweedie: 257.711\n",
      "[22]\tvalid_0's tweedie: 257.696\n",
      "[23]\tvalid_0's tweedie: 257.683\n",
      "[24]\tvalid_0's tweedie: 257.673\n",
      "[25]\tvalid_0's tweedie: 257.666\n",
      "[26]\tvalid_0's tweedie: 257.659\n",
      "[27]\tvalid_0's tweedie: 257.649\n",
      "[28]\tvalid_0's tweedie: 257.642\n",
      "[29]\tvalid_0's tweedie: 257.636\n",
      "[30]\tvalid_0's tweedie: 257.632\n",
      "[31]\tvalid_0's tweedie: 257.631\n",
      "[32]\tvalid_0's tweedie: 257.629\n",
      "[33]\tvalid_0's tweedie: 257.627\n",
      "[34]\tvalid_0's tweedie: 257.627\n",
      "[35]\tvalid_0's tweedie: 257.624\n",
      "[36]\tvalid_0's tweedie: 257.624\n",
      "[37]\tvalid_0's tweedie: 257.623\n",
      "[38]\tvalid_0's tweedie: 257.623\n",
      "[39]\tvalid_0's tweedie: 257.622\n",
      "[40]\tvalid_0's tweedie: 257.624\n",
      "[41]\tvalid_0's tweedie: 257.622\n",
      "[42]\tvalid_0's tweedie: 257.619\n",
      "[43]\tvalid_0's tweedie: 257.618\n",
      "[44]\tvalid_0's tweedie: 257.617\n",
      "[45]\tvalid_0's tweedie: 257.615\n",
      "[46]\tvalid_0's tweedie: 257.612\n",
      "[47]\tvalid_0's tweedie: 257.611\n",
      "[48]\tvalid_0's tweedie: 257.609\n",
      "[49]\tvalid_0's tweedie: 257.608\n",
      "[50]\tvalid_0's tweedie: 257.616\n",
      "[51]\tvalid_0's tweedie: 257.614\n",
      "[52]\tvalid_0's tweedie: 257.614\n",
      "[53]\tvalid_0's tweedie: 257.614\n",
      "[54]\tvalid_0's tweedie: 257.614\n",
      "[55]\tvalid_0's tweedie: 257.618\n",
      "[56]\tvalid_0's tweedie: 257.617\n",
      "[57]\tvalid_0's tweedie: 257.616\n",
      "[58]\tvalid_0's tweedie: 257.616\n",
      "[59]\tvalid_0's tweedie: 257.612\n",
      "[60]\tvalid_0's tweedie: 257.609\n",
      "[61]\tvalid_0's tweedie: 257.609\n",
      "[62]\tvalid_0's tweedie: 257.608\n",
      "[63]\tvalid_0's tweedie: 257.607\n",
      "[64]\tvalid_0's tweedie: 257.608\n",
      "[65]\tvalid_0's tweedie: 257.61\n",
      "[66]\tvalid_0's tweedie: 257.609\n",
      "[67]\tvalid_0's tweedie: 257.609\n",
      "[68]\tvalid_0's tweedie: 257.609\n",
      "[69]\tvalid_0's tweedie: 257.609\n",
      "[70]\tvalid_0's tweedie: 257.609\n",
      "[71]\tvalid_0's tweedie: 257.608\n",
      "[72]\tvalid_0's tweedie: 257.609\n",
      "[73]\tvalid_0's tweedie: 257.608\n",
      "[74]\tvalid_0's tweedie: 257.607\n",
      "[75]\tvalid_0's tweedie: 257.606\n",
      "[76]\tvalid_0's tweedie: 257.606\n",
      "[77]\tvalid_0's tweedie: 257.605\n",
      "[78]\tvalid_0's tweedie: 257.605\n",
      "[79]\tvalid_0's tweedie: 257.605\n",
      "[80]\tvalid_0's tweedie: 257.602\n",
      "[81]\tvalid_0's tweedie: 257.602\n",
      "[82]\tvalid_0's tweedie: 257.601\n",
      "[83]\tvalid_0's tweedie: 257.599\n",
      "[84]\tvalid_0's tweedie: 257.599\n",
      "[85]\tvalid_0's tweedie: 257.599\n",
      "[86]\tvalid_0's tweedie: 257.598\n",
      "[87]\tvalid_0's tweedie: 257.598\n",
      "[88]\tvalid_0's tweedie: 257.598\n",
      "[89]\tvalid_0's tweedie: 257.598\n",
      "[90]\tvalid_0's tweedie: 257.598\n",
      "[91]\tvalid_0's tweedie: 257.598\n",
      "[92]\tvalid_0's tweedie: 257.598\n",
      "[93]\tvalid_0's tweedie: 257.596\n",
      "[94]\tvalid_0's tweedie: 257.595\n",
      "[95]\tvalid_0's tweedie: 257.595\n",
      "[96]\tvalid_0's tweedie: 257.594\n",
      "[97]\tvalid_0's tweedie: 257.591\n",
      "[98]\tvalid_0's tweedie: 257.591\n",
      "[99]\tvalid_0's tweedie: 257.59\n",
      "[100]\tvalid_0's tweedie: 257.589\n",
      "[101]\tvalid_0's tweedie: 257.589\n",
      "[102]\tvalid_0's tweedie: 257.589\n",
      "[103]\tvalid_0's tweedie: 257.589\n",
      "[104]\tvalid_0's tweedie: 257.589\n",
      "[105]\tvalid_0's tweedie: 257.589\n",
      "[106]\tvalid_0's tweedie: 257.589\n",
      "[107]\tvalid_0's tweedie: 257.589\n",
      "[108]\tvalid_0's tweedie: 257.59\n",
      "[109]\tvalid_0's tweedie: 257.588\n",
      "[110]\tvalid_0's tweedie: 257.587\n",
      "[111]\tvalid_0's tweedie: 257.588\n",
      "[112]\tvalid_0's tweedie: 257.588\n",
      "[113]\tvalid_0's tweedie: 257.587\n",
      "[114]\tvalid_0's tweedie: 257.589\n",
      "[115]\tvalid_0's tweedie: 257.587\n",
      "[116]\tvalid_0's tweedie: 257.588\n",
      "[117]\tvalid_0's tweedie: 257.588\n",
      "[118]\tvalid_0's tweedie: 257.587\n",
      "[119]\tvalid_0's tweedie: 257.587\n",
      "[120]\tvalid_0's tweedie: 257.587\n",
      "[121]\tvalid_0's tweedie: 257.587\n",
      "[122]\tvalid_0's tweedie: 257.588\n",
      "[123]\tvalid_0's tweedie: 257.588\n",
      "[124]\tvalid_0's tweedie: 257.588\n",
      "[125]\tvalid_0's tweedie: 257.588\n",
      "[126]\tvalid_0's tweedie: 257.589\n",
      "[127]\tvalid_0's tweedie: 257.588\n",
      "[128]\tvalid_0's tweedie: 257.588\n",
      "[129]\tvalid_0's tweedie: 257.588\n",
      "[130]\tvalid_0's tweedie: 257.587\n",
      "[131]\tvalid_0's tweedie: 257.587\n",
      "[132]\tvalid_0's tweedie: 257.589\n",
      "[133]\tvalid_0's tweedie: 257.588\n",
      "[134]\tvalid_0's tweedie: 257.589\n",
      "[135]\tvalid_0's tweedie: 257.591\n",
      "[136]\tvalid_0's tweedie: 257.591\n",
      "[137]\tvalid_0's tweedie: 257.589\n",
      "[138]\tvalid_0's tweedie: 257.589\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's tweedie: 257.587\n",
      "Training model for level 3 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 18530, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142146\n",
      "[1]\tvalid_0's tweedie: 260.802\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.243\n",
      "[3]\tvalid_0's tweedie: 259.785\n",
      "[4]\tvalid_0's tweedie: 259.412\n",
      "[5]\tvalid_0's tweedie: 259.107\n",
      "[6]\tvalid_0's tweedie: 258.854\n",
      "[7]\tvalid_0's tweedie: 258.658\n",
      "[8]\tvalid_0's tweedie: 258.485\n",
      "[9]\tvalid_0's tweedie: 258.356\n",
      "[10]\tvalid_0's tweedie: 258.232\n",
      "[11]\tvalid_0's tweedie: 258.139\n",
      "[12]\tvalid_0's tweedie: 258.051\n",
      "[13]\tvalid_0's tweedie: 257.986\n",
      "[14]\tvalid_0's tweedie: 257.931\n",
      "[15]\tvalid_0's tweedie: 257.882\n",
      "[16]\tvalid_0's tweedie: 257.845\n",
      "[17]\tvalid_0's tweedie: 257.814\n",
      "[18]\tvalid_0's tweedie: 257.78\n",
      "[19]\tvalid_0's tweedie: 257.758\n",
      "[20]\tvalid_0's tweedie: 257.739\n",
      "[21]\tvalid_0's tweedie: 257.725\n",
      "[22]\tvalid_0's tweedie: 257.715\n",
      "[23]\tvalid_0's tweedie: 257.699\n",
      "[24]\tvalid_0's tweedie: 257.69\n",
      "[25]\tvalid_0's tweedie: 257.677\n",
      "[26]\tvalid_0's tweedie: 257.666\n",
      "[27]\tvalid_0's tweedie: 257.662\n",
      "[28]\tvalid_0's tweedie: 257.652\n",
      "[29]\tvalid_0's tweedie: 257.644\n",
      "[30]\tvalid_0's tweedie: 257.639\n",
      "[31]\tvalid_0's tweedie: 257.634\n",
      "[32]\tvalid_0's tweedie: 257.629\n",
      "[33]\tvalid_0's tweedie: 257.625\n",
      "[34]\tvalid_0's tweedie: 257.624\n",
      "[35]\tvalid_0's tweedie: 257.619\n",
      "[36]\tvalid_0's tweedie: 257.621\n",
      "[37]\tvalid_0's tweedie: 257.62\n",
      "[38]\tvalid_0's tweedie: 257.619\n",
      "[39]\tvalid_0's tweedie: 257.619\n",
      "[40]\tvalid_0's tweedie: 257.616\n",
      "[41]\tvalid_0's tweedie: 257.615\n",
      "[42]\tvalid_0's tweedie: 257.614\n",
      "[43]\tvalid_0's tweedie: 257.62\n",
      "[44]\tvalid_0's tweedie: 257.62\n",
      "[45]\tvalid_0's tweedie: 257.617\n",
      "[46]\tvalid_0's tweedie: 257.617\n",
      "[47]\tvalid_0's tweedie: 257.615\n",
      "[48]\tvalid_0's tweedie: 257.623\n",
      "[49]\tvalid_0's tweedie: 257.622\n",
      "[50]\tvalid_0's tweedie: 257.619\n",
      "[51]\tvalid_0's tweedie: 257.618\n",
      "[52]\tvalid_0's tweedie: 257.616\n",
      "[53]\tvalid_0's tweedie: 257.614\n",
      "[54]\tvalid_0's tweedie: 257.614\n",
      "[55]\tvalid_0's tweedie: 257.613\n",
      "[56]\tvalid_0's tweedie: 257.614\n",
      "[57]\tvalid_0's tweedie: 257.614\n",
      "[58]\tvalid_0's tweedie: 257.614\n",
      "[59]\tvalid_0's tweedie: 257.615\n",
      "[60]\tvalid_0's tweedie: 257.614\n",
      "[61]\tvalid_0's tweedie: 257.614\n",
      "[62]\tvalid_0's tweedie: 257.614\n",
      "[63]\tvalid_0's tweedie: 257.613\n",
      "[64]\tvalid_0's tweedie: 257.614\n",
      "[65]\tvalid_0's tweedie: 257.613\n",
      "[66]\tvalid_0's tweedie: 257.612\n",
      "[67]\tvalid_0's tweedie: 257.611\n",
      "[68]\tvalid_0's tweedie: 257.608\n",
      "[69]\tvalid_0's tweedie: 257.606\n",
      "[70]\tvalid_0's tweedie: 257.606\n",
      "[71]\tvalid_0's tweedie: 257.604\n",
      "[72]\tvalid_0's tweedie: 257.601\n",
      "[73]\tvalid_0's tweedie: 257.601\n",
      "[74]\tvalid_0's tweedie: 257.6\n",
      "[75]\tvalid_0's tweedie: 257.6\n",
      "[76]\tvalid_0's tweedie: 257.599\n",
      "[77]\tvalid_0's tweedie: 257.599\n",
      "[78]\tvalid_0's tweedie: 257.599\n",
      "[79]\tvalid_0's tweedie: 257.598\n",
      "[80]\tvalid_0's tweedie: 257.598\n",
      "[81]\tvalid_0's tweedie: 257.597\n",
      "[82]\tvalid_0's tweedie: 257.596\n",
      "[83]\tvalid_0's tweedie: 257.596\n",
      "[84]\tvalid_0's tweedie: 257.595\n",
      "[85]\tvalid_0's tweedie: 257.595\n",
      "[86]\tvalid_0's tweedie: 257.593\n",
      "[87]\tvalid_0's tweedie: 257.593\n",
      "[88]\tvalid_0's tweedie: 257.593\n",
      "[89]\tvalid_0's tweedie: 257.594\n",
      "[90]\tvalid_0's tweedie: 257.594\n",
      "[91]\tvalid_0's tweedie: 257.594\n",
      "[92]\tvalid_0's tweedie: 257.593\n",
      "[93]\tvalid_0's tweedie: 257.592\n",
      "[94]\tvalid_0's tweedie: 257.592\n",
      "[95]\tvalid_0's tweedie: 257.592\n",
      "[96]\tvalid_0's tweedie: 257.592\n",
      "[97]\tvalid_0's tweedie: 257.592\n",
      "[98]\tvalid_0's tweedie: 257.591\n",
      "[99]\tvalid_0's tweedie: 257.592\n",
      "[100]\tvalid_0's tweedie: 257.593\n",
      "[101]\tvalid_0's tweedie: 257.593\n",
      "[102]\tvalid_0's tweedie: 257.593\n",
      "[103]\tvalid_0's tweedie: 257.592\n",
      "[104]\tvalid_0's tweedie: 257.59\n",
      "[105]\tvalid_0's tweedie: 257.59\n",
      "[106]\tvalid_0's tweedie: 257.59\n",
      "[107]\tvalid_0's tweedie: 257.589\n",
      "[108]\tvalid_0's tweedie: 257.589\n",
      "[109]\tvalid_0's tweedie: 257.588\n",
      "[110]\tvalid_0's tweedie: 257.587\n",
      "[111]\tvalid_0's tweedie: 257.586\n",
      "[112]\tvalid_0's tweedie: 257.587\n",
      "[113]\tvalid_0's tweedie: 257.586\n",
      "[114]\tvalid_0's tweedie: 257.586\n",
      "[115]\tvalid_0's tweedie: 257.586\n",
      "[116]\tvalid_0's tweedie: 257.585\n",
      "[117]\tvalid_0's tweedie: 257.585\n",
      "[118]\tvalid_0's tweedie: 257.585\n",
      "[119]\tvalid_0's tweedie: 257.584\n",
      "[120]\tvalid_0's tweedie: 257.584\n",
      "[121]\tvalid_0's tweedie: 257.584\n",
      "[122]\tvalid_0's tweedie: 257.583\n",
      "[123]\tvalid_0's tweedie: 257.583\n",
      "[124]\tvalid_0's tweedie: 257.584\n",
      "[125]\tvalid_0's tweedie: 257.583\n",
      "[126]\tvalid_0's tweedie: 257.583\n",
      "[127]\tvalid_0's tweedie: 257.583\n",
      "[128]\tvalid_0's tweedie: 257.583\n",
      "[129]\tvalid_0's tweedie: 257.583\n",
      "[130]\tvalid_0's tweedie: 257.582\n",
      "[131]\tvalid_0's tweedie: 257.583\n",
      "[132]\tvalid_0's tweedie: 257.583\n",
      "[133]\tvalid_0's tweedie: 257.584\n",
      "[134]\tvalid_0's tweedie: 257.584\n",
      "[135]\tvalid_0's tweedie: 257.583\n",
      "[136]\tvalid_0's tweedie: 257.583\n",
      "[137]\tvalid_0's tweedie: 257.583\n",
      "[138]\tvalid_0's tweedie: 257.583\n",
      "[139]\tvalid_0's tweedie: 257.583\n",
      "[140]\tvalid_0's tweedie: 257.583\n",
      "[141]\tvalid_0's tweedie: 257.583\n",
      "[142]\tvalid_0's tweedie: 257.582\n",
      "[143]\tvalid_0's tweedie: 257.582\n",
      "[144]\tvalid_0's tweedie: 257.582\n",
      "[145]\tvalid_0's tweedie: 257.584\n",
      "[146]\tvalid_0's tweedie: 257.583\n",
      "[147]\tvalid_0's tweedie: 257.583\n",
      "[148]\tvalid_0's tweedie: 257.584\n",
      "[149]\tvalid_0's tweedie: 257.583\n",
      "[150]\tvalid_0's tweedie: 257.583\n",
      "[151]\tvalid_0's tweedie: 257.583\n",
      "[152]\tvalid_0's tweedie: 257.583\n",
      "[153]\tvalid_0's tweedie: 257.583\n",
      "[154]\tvalid_0's tweedie: 257.583\n",
      "[155]\tvalid_0's tweedie: 257.583\n",
      "[156]\tvalid_0's tweedie: 257.583\n",
      "[157]\tvalid_0's tweedie: 257.583\n",
      "[158]\tvalid_0's tweedie: 257.583\n",
      "[159]\tvalid_0's tweedie: 257.584\n",
      "[160]\tvalid_0's tweedie: 257.584\n",
      "[161]\tvalid_0's tweedie: 257.584\n",
      "[162]\tvalid_0's tweedie: 257.584\n",
      "[163]\tvalid_0's tweedie: 257.584\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's tweedie: 257.582\n",
      "Training model for level 3 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 18520, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142340\n",
      "[1]\tvalid_0's tweedie: 260.795\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.236\n",
      "[3]\tvalid_0's tweedie: 259.78\n",
      "[4]\tvalid_0's tweedie: 259.419\n",
      "[5]\tvalid_0's tweedie: 259.112\n",
      "[6]\tvalid_0's tweedie: 258.858\n",
      "[7]\tvalid_0's tweedie: 258.646\n",
      "[8]\tvalid_0's tweedie: 258.481\n",
      "[9]\tvalid_0's tweedie: 258.34\n",
      "[10]\tvalid_0's tweedie: 258.227\n",
      "[11]\tvalid_0's tweedie: 258.135\n",
      "[12]\tvalid_0's tweedie: 258.06\n",
      "[13]\tvalid_0's tweedie: 257.997\n",
      "[14]\tvalid_0's tweedie: 257.938\n",
      "[15]\tvalid_0's tweedie: 257.884\n",
      "[16]\tvalid_0's tweedie: 257.838\n",
      "[17]\tvalid_0's tweedie: 257.798\n",
      "[18]\tvalid_0's tweedie: 257.767\n",
      "[19]\tvalid_0's tweedie: 257.741\n",
      "[20]\tvalid_0's tweedie: 257.721\n",
      "[21]\tvalid_0's tweedie: 257.705\n",
      "[22]\tvalid_0's tweedie: 257.692\n",
      "[23]\tvalid_0's tweedie: 257.683\n",
      "[24]\tvalid_0's tweedie: 257.672\n",
      "[25]\tvalid_0's tweedie: 257.663\n",
      "[26]\tvalid_0's tweedie: 257.655\n",
      "[27]\tvalid_0's tweedie: 257.645\n",
      "[28]\tvalid_0's tweedie: 257.639\n",
      "[29]\tvalid_0's tweedie: 257.633\n",
      "[30]\tvalid_0's tweedie: 257.626\n",
      "[31]\tvalid_0's tweedie: 257.622\n",
      "[32]\tvalid_0's tweedie: 257.619\n",
      "[33]\tvalid_0's tweedie: 257.615\n",
      "[34]\tvalid_0's tweedie: 257.614\n",
      "[35]\tvalid_0's tweedie: 257.612\n",
      "[36]\tvalid_0's tweedie: 257.611\n",
      "[37]\tvalid_0's tweedie: 257.608\n",
      "[38]\tvalid_0's tweedie: 257.609\n",
      "[39]\tvalid_0's tweedie: 257.605\n",
      "[40]\tvalid_0's tweedie: 257.605\n",
      "[41]\tvalid_0's tweedie: 257.602\n",
      "[42]\tvalid_0's tweedie: 257.601\n",
      "[43]\tvalid_0's tweedie: 257.603\n",
      "[44]\tvalid_0's tweedie: 257.602\n",
      "[45]\tvalid_0's tweedie: 257.606\n",
      "[46]\tvalid_0's tweedie: 257.607\n",
      "[47]\tvalid_0's tweedie: 257.604\n",
      "[48]\tvalid_0's tweedie: 257.604\n",
      "[49]\tvalid_0's tweedie: 257.603\n",
      "[50]\tvalid_0's tweedie: 257.606\n",
      "[51]\tvalid_0's tweedie: 257.605\n",
      "[52]\tvalid_0's tweedie: 257.604\n",
      "[53]\tvalid_0's tweedie: 257.603\n",
      "[54]\tvalid_0's tweedie: 257.603\n",
      "[55]\tvalid_0's tweedie: 257.603\n",
      "[56]\tvalid_0's tweedie: 257.602\n",
      "[57]\tvalid_0's tweedie: 257.6\n",
      "[58]\tvalid_0's tweedie: 257.599\n",
      "[59]\tvalid_0's tweedie: 257.599\n",
      "[60]\tvalid_0's tweedie: 257.599\n",
      "[61]\tvalid_0's tweedie: 257.599\n",
      "[62]\tvalid_0's tweedie: 257.6\n",
      "[63]\tvalid_0's tweedie: 257.599\n",
      "[64]\tvalid_0's tweedie: 257.596\n",
      "[65]\tvalid_0's tweedie: 257.595\n",
      "[66]\tvalid_0's tweedie: 257.594\n",
      "[67]\tvalid_0's tweedie: 257.593\n",
      "[68]\tvalid_0's tweedie: 257.593\n",
      "[69]\tvalid_0's tweedie: 257.593\n",
      "[70]\tvalid_0's tweedie: 257.593\n",
      "[71]\tvalid_0's tweedie: 257.593\n",
      "[72]\tvalid_0's tweedie: 257.593\n",
      "[73]\tvalid_0's tweedie: 257.592\n",
      "[74]\tvalid_0's tweedie: 257.592\n",
      "[75]\tvalid_0's tweedie: 257.595\n",
      "[76]\tvalid_0's tweedie: 257.592\n",
      "[77]\tvalid_0's tweedie: 257.59\n",
      "[78]\tvalid_0's tweedie: 257.59\n",
      "[79]\tvalid_0's tweedie: 257.589\n",
      "[80]\tvalid_0's tweedie: 257.588\n",
      "[81]\tvalid_0's tweedie: 257.589\n",
      "[82]\tvalid_0's tweedie: 257.589\n",
      "[83]\tvalid_0's tweedie: 257.589\n",
      "[84]\tvalid_0's tweedie: 257.589\n",
      "[85]\tvalid_0's tweedie: 257.588\n",
      "[86]\tvalid_0's tweedie: 257.587\n",
      "[87]\tvalid_0's tweedie: 257.585\n",
      "[88]\tvalid_0's tweedie: 257.584\n",
      "[89]\tvalid_0's tweedie: 257.582\n",
      "[90]\tvalid_0's tweedie: 257.582\n",
      "[91]\tvalid_0's tweedie: 257.583\n",
      "[92]\tvalid_0's tweedie: 257.583\n",
      "[93]\tvalid_0's tweedie: 257.584\n",
      "[94]\tvalid_0's tweedie: 257.583\n",
      "[95]\tvalid_0's tweedie: 257.582\n",
      "[96]\tvalid_0's tweedie: 257.582\n",
      "[97]\tvalid_0's tweedie: 257.582\n",
      "[98]\tvalid_0's tweedie: 257.583\n",
      "[99]\tvalid_0's tweedie: 257.585\n",
      "[100]\tvalid_0's tweedie: 257.584\n",
      "[101]\tvalid_0's tweedie: 257.584\n",
      "[102]\tvalid_0's tweedie: 257.585\n",
      "[103]\tvalid_0's tweedie: 257.584\n",
      "[104]\tvalid_0's tweedie: 257.583\n",
      "[105]\tvalid_0's tweedie: 257.583\n",
      "[106]\tvalid_0's tweedie: 257.583\n",
      "[107]\tvalid_0's tweedie: 257.583\n",
      "[108]\tvalid_0's tweedie: 257.583\n",
      "[109]\tvalid_0's tweedie: 257.583\n",
      "[110]\tvalid_0's tweedie: 257.583\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's tweedie: 257.582\n",
      "Training model for level 3 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 18510, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142511\n",
      "[1]\tvalid_0's tweedie: 260.797\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.24\n",
      "[3]\tvalid_0's tweedie: 259.784\n",
      "[4]\tvalid_0's tweedie: 259.408\n",
      "[5]\tvalid_0's tweedie: 259.111\n",
      "[6]\tvalid_0's tweedie: 258.849\n",
      "[7]\tvalid_0's tweedie: 258.644\n",
      "[8]\tvalid_0's tweedie: 258.475\n",
      "[9]\tvalid_0's tweedie: 258.326\n",
      "[10]\tvalid_0's tweedie: 258.207\n",
      "[11]\tvalid_0's tweedie: 258.109\n",
      "[12]\tvalid_0's tweedie: 258.022\n",
      "[13]\tvalid_0's tweedie: 257.947\n",
      "[14]\tvalid_0's tweedie: 257.891\n",
      "[15]\tvalid_0's tweedie: 257.838\n",
      "[16]\tvalid_0's tweedie: 257.8\n",
      "[17]\tvalid_0's tweedie: 257.767\n",
      "[18]\tvalid_0's tweedie: 257.732\n",
      "[19]\tvalid_0's tweedie: 257.709\n",
      "[20]\tvalid_0's tweedie: 257.685\n",
      "[21]\tvalid_0's tweedie: 257.672\n",
      "[22]\tvalid_0's tweedie: 257.662\n",
      "[23]\tvalid_0's tweedie: 257.65\n",
      "[24]\tvalid_0's tweedie: 257.64\n",
      "[25]\tvalid_0's tweedie: 257.628\n",
      "[26]\tvalid_0's tweedie: 257.622\n",
      "[27]\tvalid_0's tweedie: 257.617\n",
      "[28]\tvalid_0's tweedie: 257.611\n",
      "[29]\tvalid_0's tweedie: 257.603\n",
      "[30]\tvalid_0's tweedie: 257.597\n",
      "[31]\tvalid_0's tweedie: 257.595\n",
      "[32]\tvalid_0's tweedie: 257.592\n",
      "[33]\tvalid_0's tweedie: 257.59\n",
      "[34]\tvalid_0's tweedie: 257.587\n",
      "[35]\tvalid_0's tweedie: 257.585\n",
      "[36]\tvalid_0's tweedie: 257.583\n",
      "[37]\tvalid_0's tweedie: 257.581\n",
      "[38]\tvalid_0's tweedie: 257.582\n",
      "[39]\tvalid_0's tweedie: 257.578\n",
      "[40]\tvalid_0's tweedie: 257.576\n",
      "[41]\tvalid_0's tweedie: 257.576\n",
      "[42]\tvalid_0's tweedie: 257.572\n",
      "[43]\tvalid_0's tweedie: 257.571\n",
      "[44]\tvalid_0's tweedie: 257.569\n",
      "[45]\tvalid_0's tweedie: 257.568\n",
      "[46]\tvalid_0's tweedie: 257.575\n",
      "[47]\tvalid_0's tweedie: 257.574\n",
      "[48]\tvalid_0's tweedie: 257.575\n",
      "[49]\tvalid_0's tweedie: 257.574\n",
      "[50]\tvalid_0's tweedie: 257.574\n",
      "[51]\tvalid_0's tweedie: 257.574\n",
      "[52]\tvalid_0's tweedie: 257.573\n",
      "[53]\tvalid_0's tweedie: 257.577\n",
      "[54]\tvalid_0's tweedie: 257.576\n",
      "[55]\tvalid_0's tweedie: 257.576\n",
      "[56]\tvalid_0's tweedie: 257.574\n",
      "[57]\tvalid_0's tweedie: 257.574\n",
      "[58]\tvalid_0's tweedie: 257.572\n",
      "[59]\tvalid_0's tweedie: 257.57\n",
      "[60]\tvalid_0's tweedie: 257.57\n",
      "[61]\tvalid_0's tweedie: 257.568\n",
      "[62]\tvalid_0's tweedie: 257.566\n",
      "[63]\tvalid_0's tweedie: 257.564\n",
      "[64]\tvalid_0's tweedie: 257.563\n",
      "[65]\tvalid_0's tweedie: 257.562\n",
      "[66]\tvalid_0's tweedie: 257.561\n",
      "[67]\tvalid_0's tweedie: 257.56\n",
      "[68]\tvalid_0's tweedie: 257.56\n",
      "[69]\tvalid_0's tweedie: 257.559\n",
      "[70]\tvalid_0's tweedie: 257.558\n",
      "[71]\tvalid_0's tweedie: 257.557\n",
      "[72]\tvalid_0's tweedie: 257.557\n",
      "[73]\tvalid_0's tweedie: 257.557\n",
      "[74]\tvalid_0's tweedie: 257.557\n",
      "[75]\tvalid_0's tweedie: 257.557\n",
      "[76]\tvalid_0's tweedie: 257.557\n",
      "[77]\tvalid_0's tweedie: 257.558\n",
      "[78]\tvalid_0's tweedie: 257.556\n",
      "[79]\tvalid_0's tweedie: 257.555\n",
      "[80]\tvalid_0's tweedie: 257.556\n",
      "[81]\tvalid_0's tweedie: 257.555\n",
      "[82]\tvalid_0's tweedie: 257.555\n",
      "[83]\tvalid_0's tweedie: 257.554\n",
      "[84]\tvalid_0's tweedie: 257.553\n",
      "[85]\tvalid_0's tweedie: 257.553\n",
      "[86]\tvalid_0's tweedie: 257.553\n",
      "[87]\tvalid_0's tweedie: 257.552\n",
      "[88]\tvalid_0's tweedie: 257.552\n",
      "[89]\tvalid_0's tweedie: 257.553\n",
      "[90]\tvalid_0's tweedie: 257.552\n",
      "[91]\tvalid_0's tweedie: 257.552\n",
      "[92]\tvalid_0's tweedie: 257.551\n",
      "[93]\tvalid_0's tweedie: 257.549\n",
      "[94]\tvalid_0's tweedie: 257.548\n",
      "[95]\tvalid_0's tweedie: 257.548\n",
      "[96]\tvalid_0's tweedie: 257.548\n",
      "[97]\tvalid_0's tweedie: 257.548\n",
      "[98]\tvalid_0's tweedie: 257.549\n",
      "[99]\tvalid_0's tweedie: 257.549\n",
      "[100]\tvalid_0's tweedie: 257.549\n",
      "[101]\tvalid_0's tweedie: 257.549\n",
      "[102]\tvalid_0's tweedie: 257.548\n",
      "[103]\tvalid_0's tweedie: 257.548\n",
      "[104]\tvalid_0's tweedie: 257.548\n",
      "[105]\tvalid_0's tweedie: 257.547\n",
      "[106]\tvalid_0's tweedie: 257.548\n",
      "[107]\tvalid_0's tweedie: 257.548\n",
      "[108]\tvalid_0's tweedie: 257.548\n",
      "[109]\tvalid_0's tweedie: 257.547\n",
      "[110]\tvalid_0's tweedie: 257.547\n",
      "[111]\tvalid_0's tweedie: 257.547\n",
      "[112]\tvalid_0's tweedie: 257.546\n",
      "[113]\tvalid_0's tweedie: 257.546\n",
      "[114]\tvalid_0's tweedie: 257.545\n",
      "[115]\tvalid_0's tweedie: 257.545\n",
      "[116]\tvalid_0's tweedie: 257.545\n",
      "[117]\tvalid_0's tweedie: 257.545\n",
      "[118]\tvalid_0's tweedie: 257.545\n",
      "[119]\tvalid_0's tweedie: 257.545\n",
      "[120]\tvalid_0's tweedie: 257.544\n",
      "[121]\tvalid_0's tweedie: 257.545\n",
      "[122]\tvalid_0's tweedie: 257.546\n",
      "[123]\tvalid_0's tweedie: 257.546\n",
      "[124]\tvalid_0's tweedie: 257.546\n",
      "[125]\tvalid_0's tweedie: 257.546\n",
      "[126]\tvalid_0's tweedie: 257.545\n",
      "[127]\tvalid_0's tweedie: 257.545\n",
      "[128]\tvalid_0's tweedie: 257.544\n",
      "[129]\tvalid_0's tweedie: 257.544\n",
      "[130]\tvalid_0's tweedie: 257.544\n",
      "[131]\tvalid_0's tweedie: 257.544\n",
      "[132]\tvalid_0's tweedie: 257.544\n",
      "[133]\tvalid_0's tweedie: 257.546\n",
      "[134]\tvalid_0's tweedie: 257.545\n",
      "[135]\tvalid_0's tweedie: 257.545\n",
      "[136]\tvalid_0's tweedie: 257.545\n",
      "[137]\tvalid_0's tweedie: 257.546\n",
      "[138]\tvalid_0's tweedie: 257.546\n",
      "[139]\tvalid_0's tweedie: 257.546\n",
      "[140]\tvalid_0's tweedie: 257.547\n",
      "[141]\tvalid_0's tweedie: 257.547\n",
      "[142]\tvalid_0's tweedie: 257.547\n",
      "[143]\tvalid_0's tweedie: 257.547\n",
      "[144]\tvalid_0's tweedie: 257.547\n",
      "[145]\tvalid_0's tweedie: 257.547\n",
      "[146]\tvalid_0's tweedie: 257.547\n",
      "[147]\tvalid_0's tweedie: 257.548\n",
      "[148]\tvalid_0's tweedie: 257.546\n",
      "[149]\tvalid_0's tweedie: 257.546\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's tweedie: 257.544\n",
      "Training model for level 3 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 18500, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142681\n",
      "[1]\tvalid_0's tweedie: 260.781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.21\n",
      "[3]\tvalid_0's tweedie: 259.751\n",
      "[4]\tvalid_0's tweedie: 259.378\n",
      "[5]\tvalid_0's tweedie: 259.072\n",
      "[6]\tvalid_0's tweedie: 258.825\n",
      "[7]\tvalid_0's tweedie: 258.62\n",
      "[8]\tvalid_0's tweedie: 258.454\n",
      "[9]\tvalid_0's tweedie: 258.322\n",
      "[10]\tvalid_0's tweedie: 258.207\n",
      "[11]\tvalid_0's tweedie: 258.1\n",
      "[12]\tvalid_0's tweedie: 258.017\n",
      "[13]\tvalid_0's tweedie: 257.946\n",
      "[14]\tvalid_0's tweedie: 257.896\n",
      "[15]\tvalid_0's tweedie: 257.843\n",
      "[16]\tvalid_0's tweedie: 257.802\n",
      "[17]\tvalid_0's tweedie: 257.766\n",
      "[18]\tvalid_0's tweedie: 257.737\n",
      "[19]\tvalid_0's tweedie: 257.708\n",
      "[20]\tvalid_0's tweedie: 257.688\n",
      "[21]\tvalid_0's tweedie: 257.668\n",
      "[22]\tvalid_0's tweedie: 257.654\n",
      "[23]\tvalid_0's tweedie: 257.643\n",
      "[24]\tvalid_0's tweedie: 257.632\n",
      "[25]\tvalid_0's tweedie: 257.623\n",
      "[26]\tvalid_0's tweedie: 257.615\n",
      "[27]\tvalid_0's tweedie: 257.609\n",
      "[28]\tvalid_0's tweedie: 257.604\n",
      "[29]\tvalid_0's tweedie: 257.599\n",
      "[30]\tvalid_0's tweedie: 257.596\n",
      "[31]\tvalid_0's tweedie: 257.593\n",
      "[32]\tvalid_0's tweedie: 257.592\n",
      "[33]\tvalid_0's tweedie: 257.59\n",
      "[34]\tvalid_0's tweedie: 257.59\n",
      "[35]\tvalid_0's tweedie: 257.589\n",
      "[36]\tvalid_0's tweedie: 257.586\n",
      "[37]\tvalid_0's tweedie: 257.584\n",
      "[38]\tvalid_0's tweedie: 257.586\n",
      "[39]\tvalid_0's tweedie: 257.585\n",
      "[40]\tvalid_0's tweedie: 257.585\n",
      "[41]\tvalid_0's tweedie: 257.584\n",
      "[42]\tvalid_0's tweedie: 257.581\n",
      "[43]\tvalid_0's tweedie: 257.584\n",
      "[44]\tvalid_0's tweedie: 257.583\n",
      "[45]\tvalid_0's tweedie: 257.581\n",
      "[46]\tvalid_0's tweedie: 257.581\n",
      "[47]\tvalid_0's tweedie: 257.588\n",
      "[48]\tvalid_0's tweedie: 257.588\n",
      "[49]\tvalid_0's tweedie: 257.586\n",
      "[50]\tvalid_0's tweedie: 257.587\n",
      "[51]\tvalid_0's tweedie: 257.589\n",
      "[52]\tvalid_0's tweedie: 257.588\n",
      "[53]\tvalid_0's tweedie: 257.588\n",
      "[54]\tvalid_0's tweedie: 257.588\n",
      "[55]\tvalid_0's tweedie: 257.587\n",
      "[56]\tvalid_0's tweedie: 257.586\n",
      "[57]\tvalid_0's tweedie: 257.585\n",
      "[58]\tvalid_0's tweedie: 257.585\n",
      "[59]\tvalid_0's tweedie: 257.583\n",
      "[60]\tvalid_0's tweedie: 257.581\n",
      "[61]\tvalid_0's tweedie: 257.581\n",
      "[62]\tvalid_0's tweedie: 257.58\n",
      "[63]\tvalid_0's tweedie: 257.578\n",
      "[64]\tvalid_0's tweedie: 257.577\n",
      "[65]\tvalid_0's tweedie: 257.576\n",
      "[66]\tvalid_0's tweedie: 257.576\n",
      "[67]\tvalid_0's tweedie: 257.575\n",
      "[68]\tvalid_0's tweedie: 257.575\n",
      "[69]\tvalid_0's tweedie: 257.575\n",
      "[70]\tvalid_0's tweedie: 257.573\n",
      "[71]\tvalid_0's tweedie: 257.573\n",
      "[72]\tvalid_0's tweedie: 257.572\n",
      "[73]\tvalid_0's tweedie: 257.572\n",
      "[74]\tvalid_0's tweedie: 257.57\n",
      "[75]\tvalid_0's tweedie: 257.569\n",
      "[76]\tvalid_0's tweedie: 257.57\n",
      "[77]\tvalid_0's tweedie: 257.568\n",
      "[78]\tvalid_0's tweedie: 257.568\n",
      "[79]\tvalid_0's tweedie: 257.568\n",
      "[80]\tvalid_0's tweedie: 257.569\n",
      "[81]\tvalid_0's tweedie: 257.569\n",
      "[82]\tvalid_0's tweedie: 257.569\n",
      "[83]\tvalid_0's tweedie: 257.569\n",
      "[84]\tvalid_0's tweedie: 257.568\n",
      "[85]\tvalid_0's tweedie: 257.567\n",
      "[86]\tvalid_0's tweedie: 257.567\n",
      "[87]\tvalid_0's tweedie: 257.566\n",
      "[88]\tvalid_0's tweedie: 257.565\n",
      "[89]\tvalid_0's tweedie: 257.565\n",
      "[90]\tvalid_0's tweedie: 257.565\n",
      "[91]\tvalid_0's tweedie: 257.564\n",
      "[92]\tvalid_0's tweedie: 257.563\n",
      "[93]\tvalid_0's tweedie: 257.563\n",
      "[94]\tvalid_0's tweedie: 257.562\n",
      "[95]\tvalid_0's tweedie: 257.562\n",
      "[96]\tvalid_0's tweedie: 257.562\n",
      "[97]\tvalid_0's tweedie: 257.562\n",
      "[98]\tvalid_0's tweedie: 257.562\n",
      "[99]\tvalid_0's tweedie: 257.562\n",
      "[100]\tvalid_0's tweedie: 257.562\n",
      "[101]\tvalid_0's tweedie: 257.563\n",
      "[102]\tvalid_0's tweedie: 257.563\n",
      "[103]\tvalid_0's tweedie: 257.563\n",
      "[104]\tvalid_0's tweedie: 257.562\n",
      "[105]\tvalid_0's tweedie: 257.562\n",
      "[106]\tvalid_0's tweedie: 257.562\n",
      "[107]\tvalid_0's tweedie: 257.562\n",
      "[108]\tvalid_0's tweedie: 257.562\n",
      "[109]\tvalid_0's tweedie: 257.561\n",
      "[110]\tvalid_0's tweedie: 257.56\n",
      "[111]\tvalid_0's tweedie: 257.56\n",
      "[112]\tvalid_0's tweedie: 257.558\n",
      "[113]\tvalid_0's tweedie: 257.556\n",
      "[114]\tvalid_0's tweedie: 257.556\n",
      "[115]\tvalid_0's tweedie: 257.556\n",
      "[116]\tvalid_0's tweedie: 257.555\n",
      "[117]\tvalid_0's tweedie: 257.555\n",
      "[118]\tvalid_0's tweedie: 257.554\n",
      "[119]\tvalid_0's tweedie: 257.554\n",
      "[120]\tvalid_0's tweedie: 257.554\n",
      "[121]\tvalid_0's tweedie: 257.554\n",
      "[122]\tvalid_0's tweedie: 257.553\n",
      "[123]\tvalid_0's tweedie: 257.552\n",
      "[124]\tvalid_0's tweedie: 257.552\n",
      "[125]\tvalid_0's tweedie: 257.552\n",
      "[126]\tvalid_0's tweedie: 257.552\n",
      "[127]\tvalid_0's tweedie: 257.552\n",
      "[128]\tvalid_0's tweedie: 257.552\n",
      "[129]\tvalid_0's tweedie: 257.553\n",
      "[130]\tvalid_0's tweedie: 257.553\n",
      "[131]\tvalid_0's tweedie: 257.553\n",
      "[132]\tvalid_0's tweedie: 257.553\n",
      "[133]\tvalid_0's tweedie: 257.553\n",
      "[134]\tvalid_0's tweedie: 257.553\n",
      "[135]\tvalid_0's tweedie: 257.552\n",
      "[136]\tvalid_0's tweedie: 257.552\n",
      "[137]\tvalid_0's tweedie: 257.552\n",
      "[138]\tvalid_0's tweedie: 257.553\n",
      "[139]\tvalid_0's tweedie: 257.552\n",
      "[140]\tvalid_0's tweedie: 257.551\n",
      "[141]\tvalid_0's tweedie: 257.552\n",
      "[142]\tvalid_0's tweedie: 257.552\n",
      "[143]\tvalid_0's tweedie: 257.551\n",
      "[144]\tvalid_0's tweedie: 257.551\n",
      "[145]\tvalid_0's tweedie: 257.551\n",
      "[146]\tvalid_0's tweedie: 257.551\n",
      "[147]\tvalid_0's tweedie: 257.55\n",
      "[148]\tvalid_0's tweedie: 257.55\n",
      "[149]\tvalid_0's tweedie: 257.549\n",
      "[150]\tvalid_0's tweedie: 257.549\n",
      "[151]\tvalid_0's tweedie: 257.548\n",
      "[152]\tvalid_0's tweedie: 257.547\n",
      "[153]\tvalid_0's tweedie: 257.546\n",
      "[154]\tvalid_0's tweedie: 257.546\n",
      "[155]\tvalid_0's tweedie: 257.546\n",
      "[156]\tvalid_0's tweedie: 257.546\n",
      "[157]\tvalid_0's tweedie: 257.546\n",
      "[158]\tvalid_0's tweedie: 257.547\n",
      "[159]\tvalid_0's tweedie: 257.546\n",
      "[160]\tvalid_0's tweedie: 257.545\n",
      "[161]\tvalid_0's tweedie: 257.546\n",
      "[162]\tvalid_0's tweedie: 257.546\n",
      "[163]\tvalid_0's tweedie: 257.545\n",
      "[164]\tvalid_0's tweedie: 257.545\n",
      "[165]\tvalid_0's tweedie: 257.545\n",
      "[166]\tvalid_0's tweedie: 257.545\n",
      "[167]\tvalid_0's tweedie: 257.545\n",
      "[168]\tvalid_0's tweedie: 257.545\n",
      "[169]\tvalid_0's tweedie: 257.545\n",
      "[170]\tvalid_0's tweedie: 257.544\n",
      "[171]\tvalid_0's tweedie: 257.544\n",
      "[172]\tvalid_0's tweedie: 257.546\n",
      "[173]\tvalid_0's tweedie: 257.545\n",
      "[174]\tvalid_0's tweedie: 257.545\n",
      "[175]\tvalid_0's tweedie: 257.545\n",
      "[176]\tvalid_0's tweedie: 257.545\n",
      "[177]\tvalid_0's tweedie: 257.545\n",
      "[178]\tvalid_0's tweedie: 257.545\n",
      "[179]\tvalid_0's tweedie: 257.545\n",
      "[180]\tvalid_0's tweedie: 257.545\n",
      "[181]\tvalid_0's tweedie: 257.545\n",
      "[182]\tvalid_0's tweedie: 257.545\n",
      "[183]\tvalid_0's tweedie: 257.545\n",
      "[184]\tvalid_0's tweedie: 257.544\n",
      "[185]\tvalid_0's tweedie: 257.544\n",
      "[186]\tvalid_0's tweedie: 257.543\n",
      "[187]\tvalid_0's tweedie: 257.544\n",
      "[188]\tvalid_0's tweedie: 257.544\n",
      "[189]\tvalid_0's tweedie: 257.544\n",
      "[190]\tvalid_0's tweedie: 257.544\n",
      "[191]\tvalid_0's tweedie: 257.544\n",
      "[192]\tvalid_0's tweedie: 257.545\n",
      "[193]\tvalid_0's tweedie: 257.545\n",
      "[194]\tvalid_0's tweedie: 257.544\n",
      "[195]\tvalid_0's tweedie: 257.544\n",
      "[196]\tvalid_0's tweedie: 257.544\n",
      "[197]\tvalid_0's tweedie: 257.544\n",
      "[198]\tvalid_0's tweedie: 257.544\n",
      "[199]\tvalid_0's tweedie: 257.544\n",
      "[200]\tvalid_0's tweedie: 257.546\n",
      "[201]\tvalid_0's tweedie: 257.546\n",
      "[202]\tvalid_0's tweedie: 257.545\n",
      "[203]\tvalid_0's tweedie: 257.546\n",
      "[204]\tvalid_0's tweedie: 257.546\n",
      "[205]\tvalid_0's tweedie: 257.546\n",
      "[206]\tvalid_0's tweedie: 257.545\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's tweedie: 257.543\n",
      "Training model for level 3 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 18490, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142731\n",
      "[1]\tvalid_0's tweedie: 260.772\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.203\n",
      "[3]\tvalid_0's tweedie: 259.745\n",
      "[4]\tvalid_0's tweedie: 259.373\n",
      "[5]\tvalid_0's tweedie: 259.068\n",
      "[6]\tvalid_0's tweedie: 258.826\n",
      "[7]\tvalid_0's tweedie: 258.619\n",
      "[8]\tvalid_0's tweedie: 258.454\n",
      "[9]\tvalid_0's tweedie: 258.324\n",
      "[10]\tvalid_0's tweedie: 258.216\n",
      "[11]\tvalid_0's tweedie: 258.114\n",
      "[12]\tvalid_0's tweedie: 258.03\n",
      "[13]\tvalid_0's tweedie: 257.959\n",
      "[14]\tvalid_0's tweedie: 257.906\n",
      "[15]\tvalid_0's tweedie: 257.861\n",
      "[16]\tvalid_0's tweedie: 257.816\n",
      "[17]\tvalid_0's tweedie: 257.775\n",
      "[18]\tvalid_0's tweedie: 257.74\n",
      "[19]\tvalid_0's tweedie: 257.712\n",
      "[20]\tvalid_0's tweedie: 257.695\n",
      "[21]\tvalid_0's tweedie: 257.673\n",
      "[22]\tvalid_0's tweedie: 257.658\n",
      "[23]\tvalid_0's tweedie: 257.647\n",
      "[24]\tvalid_0's tweedie: 257.64\n",
      "[25]\tvalid_0's tweedie: 257.631\n",
      "[26]\tvalid_0's tweedie: 257.62\n",
      "[27]\tvalid_0's tweedie: 257.617\n",
      "[28]\tvalid_0's tweedie: 257.612\n",
      "[29]\tvalid_0's tweedie: 257.606\n",
      "[30]\tvalid_0's tweedie: 257.601\n",
      "[31]\tvalid_0's tweedie: 257.597\n",
      "[32]\tvalid_0's tweedie: 257.594\n",
      "[33]\tvalid_0's tweedie: 257.591\n",
      "[34]\tvalid_0's tweedie: 257.589\n",
      "[35]\tvalid_0's tweedie: 257.589\n",
      "[36]\tvalid_0's tweedie: 257.587\n",
      "[37]\tvalid_0's tweedie: 257.59\n",
      "[38]\tvalid_0's tweedie: 257.589\n",
      "[39]\tvalid_0's tweedie: 257.587\n",
      "[40]\tvalid_0's tweedie: 257.59\n",
      "[41]\tvalid_0's tweedie: 257.588\n",
      "[42]\tvalid_0's tweedie: 257.586\n",
      "[43]\tvalid_0's tweedie: 257.588\n",
      "[44]\tvalid_0's tweedie: 257.586\n",
      "[45]\tvalid_0's tweedie: 257.585\n",
      "[46]\tvalid_0's tweedie: 257.584\n",
      "[47]\tvalid_0's tweedie: 257.589\n",
      "[48]\tvalid_0's tweedie: 257.589\n",
      "[49]\tvalid_0's tweedie: 257.588\n",
      "[50]\tvalid_0's tweedie: 257.588\n",
      "[51]\tvalid_0's tweedie: 257.587\n",
      "[52]\tvalid_0's tweedie: 257.586\n",
      "[53]\tvalid_0's tweedie: 257.584\n",
      "[54]\tvalid_0's tweedie: 257.583\n",
      "[55]\tvalid_0's tweedie: 257.581\n",
      "[56]\tvalid_0's tweedie: 257.581\n",
      "[57]\tvalid_0's tweedie: 257.587\n",
      "[58]\tvalid_0's tweedie: 257.587\n",
      "[59]\tvalid_0's tweedie: 257.589\n",
      "[60]\tvalid_0's tweedie: 257.588\n",
      "[61]\tvalid_0's tweedie: 257.588\n",
      "[62]\tvalid_0's tweedie: 257.588\n",
      "[63]\tvalid_0's tweedie: 257.585\n",
      "[64]\tvalid_0's tweedie: 257.585\n",
      "[65]\tvalid_0's tweedie: 257.586\n",
      "[66]\tvalid_0's tweedie: 257.584\n",
      "[67]\tvalid_0's tweedie: 257.581\n",
      "[68]\tvalid_0's tweedie: 257.581\n",
      "[69]\tvalid_0's tweedie: 257.582\n",
      "[70]\tvalid_0's tweedie: 257.581\n",
      "[71]\tvalid_0's tweedie: 257.581\n",
      "[72]\tvalid_0's tweedie: 257.581\n",
      "[73]\tvalid_0's tweedie: 257.582\n",
      "[74]\tvalid_0's tweedie: 257.581\n",
      "[75]\tvalid_0's tweedie: 257.581\n",
      "[76]\tvalid_0's tweedie: 257.581\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's tweedie: 257.581\n",
      "Training model for level 3 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 18480, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142723\n",
      "[1]\tvalid_0's tweedie: 260.773\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.204\n",
      "[3]\tvalid_0's tweedie: 259.747\n",
      "[4]\tvalid_0's tweedie: 259.375\n",
      "[5]\tvalid_0's tweedie: 259.07\n",
      "[6]\tvalid_0's tweedie: 258.827\n",
      "[7]\tvalid_0's tweedie: 258.622\n",
      "[8]\tvalid_0's tweedie: 258.457\n",
      "[9]\tvalid_0's tweedie: 258.323\n",
      "[10]\tvalid_0's tweedie: 258.214\n",
      "[11]\tvalid_0's tweedie: 258.118\n",
      "[12]\tvalid_0's tweedie: 258.032\n",
      "[13]\tvalid_0's tweedie: 257.961\n",
      "[14]\tvalid_0's tweedie: 257.9\n",
      "[15]\tvalid_0's tweedie: 257.853\n",
      "[16]\tvalid_0's tweedie: 257.813\n",
      "[17]\tvalid_0's tweedie: 257.781\n",
      "[18]\tvalid_0's tweedie: 257.75\n",
      "[19]\tvalid_0's tweedie: 257.726\n",
      "[20]\tvalid_0's tweedie: 257.708\n",
      "[21]\tvalid_0's tweedie: 257.689\n",
      "[22]\tvalid_0's tweedie: 257.673\n",
      "[23]\tvalid_0's tweedie: 257.659\n",
      "[24]\tvalid_0's tweedie: 257.65\n",
      "[25]\tvalid_0's tweedie: 257.641\n",
      "[26]\tvalid_0's tweedie: 257.629\n",
      "[27]\tvalid_0's tweedie: 257.627\n",
      "[28]\tvalid_0's tweedie: 257.623\n",
      "[29]\tvalid_0's tweedie: 257.618\n",
      "[30]\tvalid_0's tweedie: 257.612\n",
      "[31]\tvalid_0's tweedie: 257.609\n",
      "[32]\tvalid_0's tweedie: 257.606\n",
      "[33]\tvalid_0's tweedie: 257.605\n",
      "[34]\tvalid_0's tweedie: 257.602\n",
      "[35]\tvalid_0's tweedie: 257.599\n",
      "[36]\tvalid_0's tweedie: 257.598\n",
      "[37]\tvalid_0's tweedie: 257.597\n",
      "[38]\tvalid_0's tweedie: 257.595\n",
      "[39]\tvalid_0's tweedie: 257.597\n",
      "[40]\tvalid_0's tweedie: 257.595\n",
      "[41]\tvalid_0's tweedie: 257.593\n",
      "[42]\tvalid_0's tweedie: 257.596\n",
      "[43]\tvalid_0's tweedie: 257.594\n",
      "[44]\tvalid_0's tweedie: 257.592\n",
      "[45]\tvalid_0's tweedie: 257.59\n",
      "[46]\tvalid_0's tweedie: 257.59\n",
      "[47]\tvalid_0's tweedie: 257.586\n",
      "[48]\tvalid_0's tweedie: 257.585\n",
      "[49]\tvalid_0's tweedie: 257.584\n",
      "[50]\tvalid_0's tweedie: 257.584\n",
      "[51]\tvalid_0's tweedie: 257.584\n",
      "[52]\tvalid_0's tweedie: 257.583\n",
      "[53]\tvalid_0's tweedie: 257.583\n",
      "[54]\tvalid_0's tweedie: 257.583\n",
      "[55]\tvalid_0's tweedie: 257.582\n",
      "[56]\tvalid_0's tweedie: 257.585\n",
      "[57]\tvalid_0's tweedie: 257.585\n",
      "[58]\tvalid_0's tweedie: 257.584\n",
      "[59]\tvalid_0's tweedie: 257.584\n",
      "[60]\tvalid_0's tweedie: 257.584\n",
      "[61]\tvalid_0's tweedie: 257.583\n",
      "[62]\tvalid_0's tweedie: 257.582\n",
      "[63]\tvalid_0's tweedie: 257.58\n",
      "[64]\tvalid_0's tweedie: 257.577\n",
      "[65]\tvalid_0's tweedie: 257.576\n",
      "[66]\tvalid_0's tweedie: 257.576\n",
      "[67]\tvalid_0's tweedie: 257.576\n",
      "[68]\tvalid_0's tweedie: 257.577\n",
      "[69]\tvalid_0's tweedie: 257.577\n",
      "[70]\tvalid_0's tweedie: 257.582\n",
      "[71]\tvalid_0's tweedie: 257.582\n",
      "[72]\tvalid_0's tweedie: 257.58\n",
      "[73]\tvalid_0's tweedie: 257.579\n",
      "[74]\tvalid_0's tweedie: 257.579\n",
      "[75]\tvalid_0's tweedie: 257.577\n",
      "[76]\tvalid_0's tweedie: 257.577\n",
      "[77]\tvalid_0's tweedie: 257.576\n",
      "[78]\tvalid_0's tweedie: 257.575\n",
      "[79]\tvalid_0's tweedie: 257.574\n",
      "[80]\tvalid_0's tweedie: 257.574\n",
      "[81]\tvalid_0's tweedie: 257.574\n",
      "[82]\tvalid_0's tweedie: 257.573\n",
      "[83]\tvalid_0's tweedie: 257.572\n",
      "[84]\tvalid_0's tweedie: 257.572\n",
      "[85]\tvalid_0's tweedie: 257.572\n",
      "[86]\tvalid_0's tweedie: 257.572\n",
      "[87]\tvalid_0's tweedie: 257.571\n",
      "[88]\tvalid_0's tweedie: 257.571\n",
      "[89]\tvalid_0's tweedie: 257.571\n",
      "[90]\tvalid_0's tweedie: 257.571\n",
      "[91]\tvalid_0's tweedie: 257.569\n",
      "[92]\tvalid_0's tweedie: 257.568\n",
      "[93]\tvalid_0's tweedie: 257.567\n",
      "[94]\tvalid_0's tweedie: 257.567\n",
      "[95]\tvalid_0's tweedie: 257.567\n",
      "[96]\tvalid_0's tweedie: 257.566\n",
      "[97]\tvalid_0's tweedie: 257.566\n",
      "[98]\tvalid_0's tweedie: 257.567\n",
      "[99]\tvalid_0's tweedie: 257.566\n",
      "[100]\tvalid_0's tweedie: 257.566\n",
      "[101]\tvalid_0's tweedie: 257.565\n",
      "[102]\tvalid_0's tweedie: 257.565\n",
      "[103]\tvalid_0's tweedie: 257.566\n",
      "[104]\tvalid_0's tweedie: 257.566\n",
      "[105]\tvalid_0's tweedie: 257.564\n",
      "[106]\tvalid_0's tweedie: 257.563\n",
      "[107]\tvalid_0's tweedie: 257.563\n",
      "[108]\tvalid_0's tweedie: 257.564\n",
      "[109]\tvalid_0's tweedie: 257.564\n",
      "[110]\tvalid_0's tweedie: 257.564\n",
      "[111]\tvalid_0's tweedie: 257.564\n",
      "[112]\tvalid_0's tweedie: 257.563\n",
      "[113]\tvalid_0's tweedie: 257.564\n",
      "[114]\tvalid_0's tweedie: 257.564\n",
      "[115]\tvalid_0's tweedie: 257.564\n",
      "[116]\tvalid_0's tweedie: 257.564\n",
      "[117]\tvalid_0's tweedie: 257.565\n",
      "[118]\tvalid_0's tweedie: 257.564\n",
      "[119]\tvalid_0's tweedie: 257.564\n",
      "[120]\tvalid_0's tweedie: 257.563\n",
      "[121]\tvalid_0's tweedie: 257.562\n",
      "[122]\tvalid_0's tweedie: 257.562\n",
      "[123]\tvalid_0's tweedie: 257.562\n",
      "[124]\tvalid_0's tweedie: 257.562\n",
      "[125]\tvalid_0's tweedie: 257.562\n",
      "[126]\tvalid_0's tweedie: 257.562\n",
      "[127]\tvalid_0's tweedie: 257.562\n",
      "[128]\tvalid_0's tweedie: 257.562\n",
      "[129]\tvalid_0's tweedie: 257.562\n",
      "[130]\tvalid_0's tweedie: 257.562\n",
      "[131]\tvalid_0's tweedie: 257.561\n",
      "[132]\tvalid_0's tweedie: 257.561\n",
      "[133]\tvalid_0's tweedie: 257.561\n",
      "[134]\tvalid_0's tweedie: 257.561\n",
      "[135]\tvalid_0's tweedie: 257.563\n",
      "[136]\tvalid_0's tweedie: 257.563\n",
      "[137]\tvalid_0's tweedie: 257.563\n",
      "[138]\tvalid_0's tweedie: 257.562\n",
      "[139]\tvalid_0's tweedie: 257.562\n",
      "[140]\tvalid_0's tweedie: 257.562\n",
      "[141]\tvalid_0's tweedie: 257.561\n",
      "[142]\tvalid_0's tweedie: 257.561\n",
      "[143]\tvalid_0's tweedie: 257.561\n",
      "[144]\tvalid_0's tweedie: 257.562\n",
      "[145]\tvalid_0's tweedie: 257.561\n",
      "[146]\tvalid_0's tweedie: 257.56\n",
      "[147]\tvalid_0's tweedie: 257.563\n",
      "[148]\tvalid_0's tweedie: 257.562\n",
      "[149]\tvalid_0's tweedie: 257.562\n",
      "[150]\tvalid_0's tweedie: 257.562\n",
      "[151]\tvalid_0's tweedie: 257.562\n",
      "[152]\tvalid_0's tweedie: 257.562\n",
      "[153]\tvalid_0's tweedie: 257.561\n",
      "[154]\tvalid_0's tweedie: 257.56\n",
      "[155]\tvalid_0's tweedie: 257.56\n",
      "[156]\tvalid_0's tweedie: 257.561\n",
      "[157]\tvalid_0's tweedie: 257.561\n",
      "[158]\tvalid_0's tweedie: 257.561\n",
      "[159]\tvalid_0's tweedie: 257.561\n",
      "[160]\tvalid_0's tweedie: 257.561\n",
      "[161]\tvalid_0's tweedie: 257.561\n",
      "[162]\tvalid_0's tweedie: 257.561\n",
      "[163]\tvalid_0's tweedie: 257.56\n",
      "[164]\tvalid_0's tweedie: 257.56\n",
      "[165]\tvalid_0's tweedie: 257.559\n",
      "[166]\tvalid_0's tweedie: 257.559\n",
      "[167]\tvalid_0's tweedie: 257.559\n",
      "[168]\tvalid_0's tweedie: 257.558\n",
      "[169]\tvalid_0's tweedie: 257.558\n",
      "[170]\tvalid_0's tweedie: 257.558\n",
      "[171]\tvalid_0's tweedie: 257.557\n",
      "[172]\tvalid_0's tweedie: 257.557\n",
      "[173]\tvalid_0's tweedie: 257.557\n",
      "[174]\tvalid_0's tweedie: 257.557\n",
      "[175]\tvalid_0's tweedie: 257.557\n",
      "[176]\tvalid_0's tweedie: 257.557\n",
      "[177]\tvalid_0's tweedie: 257.557\n",
      "[178]\tvalid_0's tweedie: 257.556\n",
      "[179]\tvalid_0's tweedie: 257.556\n",
      "[180]\tvalid_0's tweedie: 257.556\n",
      "[181]\tvalid_0's tweedie: 257.555\n",
      "[182]\tvalid_0's tweedie: 257.555\n",
      "[183]\tvalid_0's tweedie: 257.555\n",
      "[184]\tvalid_0's tweedie: 257.555\n",
      "[185]\tvalid_0's tweedie: 257.555\n",
      "[186]\tvalid_0's tweedie: 257.555\n",
      "[187]\tvalid_0's tweedie: 257.555\n",
      "[188]\tvalid_0's tweedie: 257.554\n",
      "[189]\tvalid_0's tweedie: 257.554\n",
      "[190]\tvalid_0's tweedie: 257.554\n",
      "[191]\tvalid_0's tweedie: 257.554\n",
      "[192]\tvalid_0's tweedie: 257.554\n",
      "[193]\tvalid_0's tweedie: 257.554\n",
      "[194]\tvalid_0's tweedie: 257.554\n",
      "[195]\tvalid_0's tweedie: 257.554\n",
      "[196]\tvalid_0's tweedie: 257.554\n",
      "[197]\tvalid_0's tweedie: 257.554\n",
      "[198]\tvalid_0's tweedie: 257.553\n",
      "[199]\tvalid_0's tweedie: 257.553\n",
      "[200]\tvalid_0's tweedie: 257.553\n",
      "[201]\tvalid_0's tweedie: 257.554\n",
      "[202]\tvalid_0's tweedie: 257.553\n",
      "[203]\tvalid_0's tweedie: 257.553\n",
      "[204]\tvalid_0's tweedie: 257.553\n",
      "[205]\tvalid_0's tweedie: 257.553\n",
      "[206]\tvalid_0's tweedie: 257.552\n",
      "[207]\tvalid_0's tweedie: 257.553\n",
      "[208]\tvalid_0's tweedie: 257.553\n",
      "[209]\tvalid_0's tweedie: 257.553\n",
      "[210]\tvalid_0's tweedie: 257.553\n",
      "[211]\tvalid_0's tweedie: 257.552\n",
      "[212]\tvalid_0's tweedie: 257.552\n",
      "[213]\tvalid_0's tweedie: 257.553\n",
      "[214]\tvalid_0's tweedie: 257.553\n",
      "[215]\tvalid_0's tweedie: 257.553\n",
      "[216]\tvalid_0's tweedie: 257.553\n",
      "[217]\tvalid_0's tweedie: 257.552\n",
      "[218]\tvalid_0's tweedie: 257.552\n",
      "[219]\tvalid_0's tweedie: 257.552\n",
      "[220]\tvalid_0's tweedie: 257.551\n",
      "[221]\tvalid_0's tweedie: 257.551\n",
      "[222]\tvalid_0's tweedie: 257.551\n",
      "[223]\tvalid_0's tweedie: 257.551\n",
      "[224]\tvalid_0's tweedie: 257.551\n",
      "[225]\tvalid_0's tweedie: 257.551\n",
      "[226]\tvalid_0's tweedie: 257.551\n",
      "[227]\tvalid_0's tweedie: 257.551\n",
      "[228]\tvalid_0's tweedie: 257.551\n",
      "[229]\tvalid_0's tweedie: 257.551\n",
      "[230]\tvalid_0's tweedie: 257.551\n",
      "[231]\tvalid_0's tweedie: 257.55\n",
      "[232]\tvalid_0's tweedie: 257.553\n",
      "[233]\tvalid_0's tweedie: 257.553\n",
      "[234]\tvalid_0's tweedie: 257.553\n",
      "[235]\tvalid_0's tweedie: 257.553\n",
      "[236]\tvalid_0's tweedie: 257.554\n",
      "[237]\tvalid_0's tweedie: 257.554\n",
      "[238]\tvalid_0's tweedie: 257.553\n",
      "[239]\tvalid_0's tweedie: 257.553\n",
      "[240]\tvalid_0's tweedie: 257.552\n",
      "[241]\tvalid_0's tweedie: 257.552\n",
      "[242]\tvalid_0's tweedie: 257.552\n",
      "[243]\tvalid_0's tweedie: 257.552\n",
      "[244]\tvalid_0's tweedie: 257.552\n",
      "[245]\tvalid_0's tweedie: 257.552\n",
      "[246]\tvalid_0's tweedie: 257.552\n",
      "[247]\tvalid_0's tweedie: 257.554\n",
      "[248]\tvalid_0's tweedie: 257.553\n",
      "[249]\tvalid_0's tweedie: 257.553\n",
      "[250]\tvalid_0's tweedie: 257.553\n",
      "[251]\tvalid_0's tweedie: 257.553\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's tweedie: 257.55\n",
      "Training model for level 3 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 18470, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.142878\n",
      "[1]\tvalid_0's tweedie: 260.771\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.203\n",
      "[3]\tvalid_0's tweedie: 259.746\n",
      "[4]\tvalid_0's tweedie: 259.374\n",
      "[5]\tvalid_0's tweedie: 259.07\n",
      "[6]\tvalid_0's tweedie: 258.827\n",
      "[7]\tvalid_0's tweedie: 258.621\n",
      "[8]\tvalid_0's tweedie: 258.455\n",
      "[9]\tvalid_0's tweedie: 258.317\n",
      "[10]\tvalid_0's tweedie: 258.208\n",
      "[11]\tvalid_0's tweedie: 258.109\n",
      "[12]\tvalid_0's tweedie: 258.025\n",
      "[13]\tvalid_0's tweedie: 257.954\n",
      "[14]\tvalid_0's tweedie: 257.895\n",
      "[15]\tvalid_0's tweedie: 257.844\n",
      "[16]\tvalid_0's tweedie: 257.804\n",
      "[17]\tvalid_0's tweedie: 257.768\n",
      "[18]\tvalid_0's tweedie: 257.736\n",
      "[19]\tvalid_0's tweedie: 257.709\n",
      "[20]\tvalid_0's tweedie: 257.685\n",
      "[21]\tvalid_0's tweedie: 257.665\n",
      "[22]\tvalid_0's tweedie: 257.653\n",
      "[23]\tvalid_0's tweedie: 257.643\n",
      "[24]\tvalid_0's tweedie: 257.633\n",
      "[25]\tvalid_0's tweedie: 257.627\n",
      "[26]\tvalid_0's tweedie: 257.617\n",
      "[27]\tvalid_0's tweedie: 257.61\n",
      "[28]\tvalid_0's tweedie: 257.605\n",
      "[29]\tvalid_0's tweedie: 257.599\n",
      "[30]\tvalid_0's tweedie: 257.598\n",
      "[31]\tvalid_0's tweedie: 257.59\n",
      "[32]\tvalid_0's tweedie: 257.589\n",
      "[33]\tvalid_0's tweedie: 257.585\n",
      "[34]\tvalid_0's tweedie: 257.583\n",
      "[35]\tvalid_0's tweedie: 257.583\n",
      "[36]\tvalid_0's tweedie: 257.582\n",
      "[37]\tvalid_0's tweedie: 257.581\n",
      "[38]\tvalid_0's tweedie: 257.577\n",
      "[39]\tvalid_0's tweedie: 257.58\n",
      "[40]\tvalid_0's tweedie: 257.579\n",
      "[41]\tvalid_0's tweedie: 257.579\n",
      "[42]\tvalid_0's tweedie: 257.577\n",
      "[43]\tvalid_0's tweedie: 257.576\n",
      "[44]\tvalid_0's tweedie: 257.576\n",
      "[45]\tvalid_0's tweedie: 257.575\n",
      "[46]\tvalid_0's tweedie: 257.574\n",
      "[47]\tvalid_0's tweedie: 257.581\n",
      "[48]\tvalid_0's tweedie: 257.58\n",
      "[49]\tvalid_0's tweedie: 257.587\n",
      "[50]\tvalid_0's tweedie: 257.585\n",
      "[51]\tvalid_0's tweedie: 257.585\n",
      "[52]\tvalid_0's tweedie: 257.582\n",
      "[53]\tvalid_0's tweedie: 257.583\n",
      "[54]\tvalid_0's tweedie: 257.583\n",
      "[55]\tvalid_0's tweedie: 257.583\n",
      "[56]\tvalid_0's tweedie: 257.582\n",
      "[57]\tvalid_0's tweedie: 257.588\n",
      "[58]\tvalid_0's tweedie: 257.589\n",
      "[59]\tvalid_0's tweedie: 257.588\n",
      "[60]\tvalid_0's tweedie: 257.587\n",
      "[61]\tvalid_0's tweedie: 257.586\n",
      "[62]\tvalid_0's tweedie: 257.583\n",
      "[63]\tvalid_0's tweedie: 257.579\n",
      "[64]\tvalid_0's tweedie: 257.58\n",
      "[65]\tvalid_0's tweedie: 257.579\n",
      "[66]\tvalid_0's tweedie: 257.578\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's tweedie: 257.574\n",
      "Training model for level 3 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 18460, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.143061\n",
      "[1]\tvalid_0's tweedie: 260.773\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.205\n",
      "[3]\tvalid_0's tweedie: 259.748\n",
      "[4]\tvalid_0's tweedie: 259.375\n",
      "[5]\tvalid_0's tweedie: 259.075\n",
      "[6]\tvalid_0's tweedie: 258.826\n",
      "[7]\tvalid_0's tweedie: 258.62\n",
      "[8]\tvalid_0's tweedie: 258.454\n",
      "[9]\tvalid_0's tweedie: 258.306\n",
      "[10]\tvalid_0's tweedie: 258.193\n",
      "[11]\tvalid_0's tweedie: 258.105\n",
      "[12]\tvalid_0's tweedie: 258.026\n",
      "[13]\tvalid_0's tweedie: 257.956\n",
      "[14]\tvalid_0's tweedie: 257.895\n",
      "[15]\tvalid_0's tweedie: 257.848\n",
      "[16]\tvalid_0's tweedie: 257.812\n",
      "[17]\tvalid_0's tweedie: 257.772\n",
      "[18]\tvalid_0's tweedie: 257.743\n",
      "[19]\tvalid_0's tweedie: 257.72\n",
      "[20]\tvalid_0's tweedie: 257.694\n",
      "[21]\tvalid_0's tweedie: 257.674\n",
      "[22]\tvalid_0's tweedie: 257.657\n",
      "[23]\tvalid_0's tweedie: 257.646\n",
      "[24]\tvalid_0's tweedie: 257.636\n",
      "[25]\tvalid_0's tweedie: 257.629\n",
      "[26]\tvalid_0's tweedie: 257.622\n",
      "[27]\tvalid_0's tweedie: 257.614\n",
      "[28]\tvalid_0's tweedie: 257.609\n",
      "[29]\tvalid_0's tweedie: 257.604\n",
      "[30]\tvalid_0's tweedie: 257.598\n",
      "[31]\tvalid_0's tweedie: 257.595\n",
      "[32]\tvalid_0's tweedie: 257.593\n",
      "[33]\tvalid_0's tweedie: 257.589\n",
      "[34]\tvalid_0's tweedie: 257.587\n",
      "[35]\tvalid_0's tweedie: 257.585\n",
      "[36]\tvalid_0's tweedie: 257.585\n",
      "[37]\tvalid_0's tweedie: 257.583\n",
      "[38]\tvalid_0's tweedie: 257.583\n",
      "[39]\tvalid_0's tweedie: 257.585\n",
      "[40]\tvalid_0's tweedie: 257.583\n",
      "[41]\tvalid_0's tweedie: 257.582\n",
      "[42]\tvalid_0's tweedie: 257.581\n",
      "[43]\tvalid_0's tweedie: 257.581\n",
      "[44]\tvalid_0's tweedie: 257.584\n",
      "[45]\tvalid_0's tweedie: 257.583\n",
      "[46]\tvalid_0's tweedie: 257.584\n",
      "[47]\tvalid_0's tweedie: 257.581\n",
      "[48]\tvalid_0's tweedie: 257.589\n",
      "[49]\tvalid_0's tweedie: 257.588\n",
      "[50]\tvalid_0's tweedie: 257.586\n",
      "[51]\tvalid_0's tweedie: 257.585\n",
      "[52]\tvalid_0's tweedie: 257.59\n",
      "[53]\tvalid_0's tweedie: 257.591\n",
      "[54]\tvalid_0's tweedie: 257.59\n",
      "[55]\tvalid_0's tweedie: 257.59\n",
      "[56]\tvalid_0's tweedie: 257.588\n",
      "[57]\tvalid_0's tweedie: 257.585\n",
      "[58]\tvalid_0's tweedie: 257.587\n",
      "[59]\tvalid_0's tweedie: 257.584\n",
      "[60]\tvalid_0's tweedie: 257.584\n",
      "[61]\tvalid_0's tweedie: 257.585\n",
      "[62]\tvalid_0's tweedie: 257.584\n",
      "[63]\tvalid_0's tweedie: 257.584\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's tweedie: 257.581\n",
      "Training model for level 3 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 18450, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.143248\n",
      "[1]\tvalid_0's tweedie: 260.769\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.198\n",
      "[3]\tvalid_0's tweedie: 259.73\n",
      "[4]\tvalid_0's tweedie: 259.362\n",
      "[5]\tvalid_0's tweedie: 259.065\n",
      "[6]\tvalid_0's tweedie: 258.818\n",
      "[7]\tvalid_0's tweedie: 258.619\n",
      "[8]\tvalid_0's tweedie: 258.445\n",
      "[9]\tvalid_0's tweedie: 258.296\n",
      "[10]\tvalid_0's tweedie: 258.189\n",
      "[11]\tvalid_0's tweedie: 258.098\n",
      "[12]\tvalid_0's tweedie: 258.016\n",
      "[13]\tvalid_0's tweedie: 257.939\n",
      "[14]\tvalid_0's tweedie: 257.894\n",
      "[15]\tvalid_0's tweedie: 257.845\n",
      "[16]\tvalid_0's tweedie: 257.802\n",
      "[17]\tvalid_0's tweedie: 257.767\n",
      "[18]\tvalid_0's tweedie: 257.739\n",
      "[19]\tvalid_0's tweedie: 257.715\n",
      "[20]\tvalid_0's tweedie: 257.695\n",
      "[21]\tvalid_0's tweedie: 257.675\n",
      "[22]\tvalid_0's tweedie: 257.662\n",
      "[23]\tvalid_0's tweedie: 257.65\n",
      "[24]\tvalid_0's tweedie: 257.636\n",
      "[25]\tvalid_0's tweedie: 257.627\n",
      "[26]\tvalid_0's tweedie: 257.619\n",
      "[27]\tvalid_0's tweedie: 257.611\n",
      "[28]\tvalid_0's tweedie: 257.607\n",
      "[29]\tvalid_0's tweedie: 257.601\n",
      "[30]\tvalid_0's tweedie: 257.595\n",
      "[31]\tvalid_0's tweedie: 257.593\n",
      "[32]\tvalid_0's tweedie: 257.589\n",
      "[33]\tvalid_0's tweedie: 257.588\n",
      "[34]\tvalid_0's tweedie: 257.586\n",
      "[35]\tvalid_0's tweedie: 257.584\n",
      "[36]\tvalid_0's tweedie: 257.581\n",
      "[37]\tvalid_0's tweedie: 257.581\n",
      "[38]\tvalid_0's tweedie: 257.576\n",
      "[39]\tvalid_0's tweedie: 257.578\n",
      "[40]\tvalid_0's tweedie: 257.575\n",
      "[41]\tvalid_0's tweedie: 257.573\n",
      "[42]\tvalid_0's tweedie: 257.576\n",
      "[43]\tvalid_0's tweedie: 257.573\n",
      "[44]\tvalid_0's tweedie: 257.572\n",
      "[45]\tvalid_0's tweedie: 257.571\n",
      "[46]\tvalid_0's tweedie: 257.574\n",
      "[47]\tvalid_0's tweedie: 257.573\n",
      "[48]\tvalid_0's tweedie: 257.57\n",
      "[49]\tvalid_0's tweedie: 257.57\n",
      "[50]\tvalid_0's tweedie: 257.572\n",
      "[51]\tvalid_0's tweedie: 257.571\n",
      "[52]\tvalid_0's tweedie: 257.57\n",
      "[53]\tvalid_0's tweedie: 257.576\n",
      "[54]\tvalid_0's tweedie: 257.576\n",
      "[55]\tvalid_0's tweedie: 257.574\n",
      "[56]\tvalid_0's tweedie: 257.576\n",
      "[57]\tvalid_0's tweedie: 257.576\n",
      "[58]\tvalid_0's tweedie: 257.575\n",
      "[59]\tvalid_0's tweedie: 257.572\n",
      "[60]\tvalid_0's tweedie: 257.573\n",
      "[61]\tvalid_0's tweedie: 257.572\n",
      "[62]\tvalid_0's tweedie: 257.573\n",
      "[63]\tvalid_0's tweedie: 257.571\n",
      "[64]\tvalid_0's tweedie: 257.571\n",
      "[65]\tvalid_0's tweedie: 257.571\n",
      "[66]\tvalid_0's tweedie: 257.577\n",
      "[67]\tvalid_0's tweedie: 257.576\n",
      "[68]\tvalid_0's tweedie: 257.575\n",
      "[69]\tvalid_0's tweedie: 257.574\n",
      "[70]\tvalid_0's tweedie: 257.575\n",
      "[71]\tvalid_0's tweedie: 257.573\n",
      "[72]\tvalid_0's tweedie: 257.571\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's tweedie: 257.57\n",
      "Training model for level 3 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/3/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5489\n",
      "[LightGBM] [Info] Number of data points in the train set: 18440, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.143433\n",
      "[1]\tvalid_0's tweedie: 260.767\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 260.196\n",
      "[3]\tvalid_0's tweedie: 259.729\n",
      "[4]\tvalid_0's tweedie: 259.362\n",
      "[5]\tvalid_0's tweedie: 259.065\n",
      "[6]\tvalid_0's tweedie: 258.818\n",
      "[7]\tvalid_0's tweedie: 258.617\n",
      "[8]\tvalid_0's tweedie: 258.446\n",
      "[9]\tvalid_0's tweedie: 258.312\n",
      "[10]\tvalid_0's tweedie: 258.194\n",
      "[11]\tvalid_0's tweedie: 258.1\n",
      "[12]\tvalid_0's tweedie: 258.02\n",
      "[13]\tvalid_0's tweedie: 257.944\n",
      "[14]\tvalid_0's tweedie: 257.879\n",
      "[15]\tvalid_0's tweedie: 257.831\n",
      "[16]\tvalid_0's tweedie: 257.788\n",
      "[17]\tvalid_0's tweedie: 257.762\n",
      "[18]\tvalid_0's tweedie: 257.726\n",
      "[19]\tvalid_0's tweedie: 257.699\n",
      "[20]\tvalid_0's tweedie: 257.677\n",
      "[21]\tvalid_0's tweedie: 257.661\n",
      "[22]\tvalid_0's tweedie: 257.645\n",
      "[23]\tvalid_0's tweedie: 257.635\n",
      "[24]\tvalid_0's tweedie: 257.628\n",
      "[25]\tvalid_0's tweedie: 257.621\n",
      "[26]\tvalid_0's tweedie: 257.613\n",
      "[27]\tvalid_0's tweedie: 257.606\n",
      "[28]\tvalid_0's tweedie: 257.6\n",
      "[29]\tvalid_0's tweedie: 257.594\n",
      "[30]\tvalid_0's tweedie: 257.588\n",
      "[31]\tvalid_0's tweedie: 257.584\n",
      "[32]\tvalid_0's tweedie: 257.582\n",
      "[33]\tvalid_0's tweedie: 257.579\n",
      "[34]\tvalid_0's tweedie: 257.577\n",
      "[35]\tvalid_0's tweedie: 257.575\n",
      "[36]\tvalid_0's tweedie: 257.575\n",
      "[37]\tvalid_0's tweedie: 257.574\n",
      "[38]\tvalid_0's tweedie: 257.57\n",
      "[39]\tvalid_0's tweedie: 257.569\n",
      "[40]\tvalid_0's tweedie: 257.568\n",
      "[41]\tvalid_0's tweedie: 257.571\n",
      "[42]\tvalid_0's tweedie: 257.568\n",
      "[43]\tvalid_0's tweedie: 257.567\n",
      "[44]\tvalid_0's tweedie: 257.567\n",
      "[45]\tvalid_0's tweedie: 257.57\n",
      "[46]\tvalid_0's tweedie: 257.572\n",
      "[47]\tvalid_0's tweedie: 257.57\n",
      "[48]\tvalid_0's tweedie: 257.578\n",
      "[49]\tvalid_0's tweedie: 257.576\n",
      "[50]\tvalid_0's tweedie: 257.575\n",
      "[51]\tvalid_0's tweedie: 257.575\n",
      "[52]\tvalid_0's tweedie: 257.578\n",
      "[53]\tvalid_0's tweedie: 257.576\n",
      "[54]\tvalid_0's tweedie: 257.576\n",
      "[55]\tvalid_0's tweedie: 257.576\n",
      "[56]\tvalid_0's tweedie: 257.576\n",
      "[57]\tvalid_0's tweedie: 257.575\n",
      "[58]\tvalid_0's tweedie: 257.575\n",
      "[59]\tvalid_0's tweedie: 257.571\n",
      "[60]\tvalid_0's tweedie: 257.567\n",
      "[61]\tvalid_0's tweedie: 257.568\n",
      "[62]\tvalid_0's tweedie: 257.567\n",
      "[63]\tvalid_0's tweedie: 257.566\n",
      "[64]\tvalid_0's tweedie: 257.564\n",
      "[65]\tvalid_0's tweedie: 257.564\n",
      "[66]\tvalid_0's tweedie: 257.564\n",
      "[67]\tvalid_0's tweedie: 257.564\n",
      "[68]\tvalid_0's tweedie: 257.562\n",
      "[69]\tvalid_0's tweedie: 257.561\n",
      "[70]\tvalid_0's tweedie: 257.562\n",
      "[71]\tvalid_0's tweedie: 257.563\n",
      "[72]\tvalid_0's tweedie: 257.563\n",
      "[73]\tvalid_0's tweedie: 257.564\n",
      "[74]\tvalid_0's tweedie: 257.566\n",
      "[75]\tvalid_0's tweedie: 257.566\n",
      "[76]\tvalid_0's tweedie: 257.566\n",
      "[77]\tvalid_0's tweedie: 257.566\n",
      "[78]\tvalid_0's tweedie: 257.566\n",
      "[79]\tvalid_0's tweedie: 257.565\n",
      "[80]\tvalid_0's tweedie: 257.564\n",
      "[81]\tvalid_0's tweedie: 257.562\n",
      "[82]\tvalid_0's tweedie: 257.562\n",
      "[83]\tvalid_0's tweedie: 257.562\n",
      "[84]\tvalid_0's tweedie: 257.564\n",
      "[85]\tvalid_0's tweedie: 257.563\n",
      "[86]\tvalid_0's tweedie: 257.562\n",
      "[87]\tvalid_0's tweedie: 257.562\n",
      "[88]\tvalid_0's tweedie: 257.563\n",
      "[89]\tvalid_0's tweedie: 257.563\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's tweedie: 257.561\n",
      "Training model for level 4\n",
      "Training model for level 4 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 5613, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343561\n",
      "[1]\tvalid_0's tweedie: 471.118\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.885\n",
      "[3]\tvalid_0's tweedie: 461.501\n",
      "[4]\tvalid_0's tweedie: 457.788\n",
      "[5]\tvalid_0's tweedie: 454.799\n",
      "[6]\tvalid_0's tweedie: 452.3\n",
      "[7]\tvalid_0's tweedie: 450.259\n",
      "[8]\tvalid_0's tweedie: 448.565\n",
      "[9]\tvalid_0's tweedie: 447.137\n",
      "[10]\tvalid_0's tweedie: 446\n",
      "[11]\tvalid_0's tweedie: 445.038\n",
      "[12]\tvalid_0's tweedie: 444.294\n",
      "[13]\tvalid_0's tweedie: 443.656\n",
      "[14]\tvalid_0's tweedie: 443.127\n",
      "[15]\tvalid_0's tweedie: 442.675\n",
      "[16]\tvalid_0's tweedie: 442.305\n",
      "[17]\tvalid_0's tweedie: 442.021\n",
      "[18]\tvalid_0's tweedie: 441.768\n",
      "[19]\tvalid_0's tweedie: 441.563\n",
      "[20]\tvalid_0's tweedie: 441.383\n",
      "[21]\tvalid_0's tweedie: 441.238\n",
      "[22]\tvalid_0's tweedie: 441.13\n",
      "[23]\tvalid_0's tweedie: 441.044\n",
      "[24]\tvalid_0's tweedie: 440.96\n",
      "[25]\tvalid_0's tweedie: 440.925\n",
      "[26]\tvalid_0's tweedie: 440.879\n",
      "[27]\tvalid_0's tweedie: 440.822\n",
      "[28]\tvalid_0's tweedie: 440.768\n",
      "[29]\tvalid_0's tweedie: 440.73\n",
      "[30]\tvalid_0's tweedie: 440.693\n",
      "[31]\tvalid_0's tweedie: 440.658\n",
      "[32]\tvalid_0's tweedie: 440.635\n",
      "[33]\tvalid_0's tweedie: 440.616\n",
      "[34]\tvalid_0's tweedie: 440.599\n",
      "[35]\tvalid_0's tweedie: 440.581\n",
      "[36]\tvalid_0's tweedie: 440.563\n",
      "[37]\tvalid_0's tweedie: 440.537\n",
      "[38]\tvalid_0's tweedie: 440.516\n",
      "[39]\tvalid_0's tweedie: 440.508\n",
      "[40]\tvalid_0's tweedie: 440.502\n",
      "[41]\tvalid_0's tweedie: 440.488\n",
      "[42]\tvalid_0's tweedie: 440.476\n",
      "[43]\tvalid_0's tweedie: 440.469\n",
      "[44]\tvalid_0's tweedie: 440.458\n",
      "[45]\tvalid_0's tweedie: 440.453\n",
      "[46]\tvalid_0's tweedie: 440.45\n",
      "[47]\tvalid_0's tweedie: 440.445\n",
      "[48]\tvalid_0's tweedie: 440.441\n",
      "[49]\tvalid_0's tweedie: 440.434\n",
      "[50]\tvalid_0's tweedie: 440.432\n",
      "[51]\tvalid_0's tweedie: 440.426\n",
      "[52]\tvalid_0's tweedie: 440.424\n",
      "[53]\tvalid_0's tweedie: 440.423\n",
      "[54]\tvalid_0's tweedie: 440.421\n",
      "[55]\tvalid_0's tweedie: 440.42\n",
      "[56]\tvalid_0's tweedie: 440.418\n",
      "[57]\tvalid_0's tweedie: 440.418\n",
      "[58]\tvalid_0's tweedie: 440.415\n",
      "[59]\tvalid_0's tweedie: 440.414\n",
      "[60]\tvalid_0's tweedie: 440.411\n",
      "[61]\tvalid_0's tweedie: 440.41\n",
      "[62]\tvalid_0's tweedie: 440.407\n",
      "[63]\tvalid_0's tweedie: 440.404\n",
      "[64]\tvalid_0's tweedie: 440.403\n",
      "[65]\tvalid_0's tweedie: 440.4\n",
      "[66]\tvalid_0's tweedie: 440.4\n",
      "[67]\tvalid_0's tweedie: 440.397\n",
      "[68]\tvalid_0's tweedie: 440.396\n",
      "[69]\tvalid_0's tweedie: 440.396\n",
      "[70]\tvalid_0's tweedie: 440.396\n",
      "[71]\tvalid_0's tweedie: 440.396\n",
      "[72]\tvalid_0's tweedie: 440.395\n",
      "[73]\tvalid_0's tweedie: 440.395\n",
      "[74]\tvalid_0's tweedie: 440.396\n",
      "[75]\tvalid_0's tweedie: 440.395\n",
      "[76]\tvalid_0's tweedie: 440.395\n",
      "[77]\tvalid_0's tweedie: 440.395\n",
      "[78]\tvalid_0's tweedie: 440.395\n",
      "[79]\tvalid_0's tweedie: 440.395\n",
      "[80]\tvalid_0's tweedie: 440.395\n",
      "[81]\tvalid_0's tweedie: 440.394\n",
      "[82]\tvalid_0's tweedie: 440.394\n",
      "[83]\tvalid_0's tweedie: 440.394\n",
      "[84]\tvalid_0's tweedie: 440.394\n",
      "[85]\tvalid_0's tweedie: 440.393\n",
      "[86]\tvalid_0's tweedie: 440.392\n",
      "[87]\tvalid_0's tweedie: 440.392\n",
      "[88]\tvalid_0's tweedie: 440.392\n",
      "[89]\tvalid_0's tweedie: 440.392\n",
      "[90]\tvalid_0's tweedie: 440.391\n",
      "[91]\tvalid_0's tweedie: 440.391\n",
      "[92]\tvalid_0's tweedie: 440.391\n",
      "[93]\tvalid_0's tweedie: 440.391\n",
      "[94]\tvalid_0's tweedie: 440.391\n",
      "[95]\tvalid_0's tweedie: 440.391\n",
      "[96]\tvalid_0's tweedie: 440.391\n",
      "[97]\tvalid_0's tweedie: 440.391\n",
      "[98]\tvalid_0's tweedie: 440.391\n",
      "[99]\tvalid_0's tweedie: 440.391\n",
      "[100]\tvalid_0's tweedie: 440.39\n",
      "[101]\tvalid_0's tweedie: 440.39\n",
      "[102]\tvalid_0's tweedie: 440.39\n",
      "[103]\tvalid_0's tweedie: 440.39\n",
      "[104]\tvalid_0's tweedie: 440.39\n",
      "[105]\tvalid_0's tweedie: 440.39\n",
      "[106]\tvalid_0's tweedie: 440.39\n",
      "[107]\tvalid_0's tweedie: 440.39\n",
      "[108]\tvalid_0's tweedie: 440.39\n",
      "[109]\tvalid_0's tweedie: 440.391\n",
      "[110]\tvalid_0's tweedie: 440.39\n",
      "[111]\tvalid_0's tweedie: 440.39\n",
      "[112]\tvalid_0's tweedie: 440.389\n",
      "[113]\tvalid_0's tweedie: 440.39\n",
      "[114]\tvalid_0's tweedie: 440.389\n",
      "[115]\tvalid_0's tweedie: 440.389\n",
      "[116]\tvalid_0's tweedie: 440.39\n",
      "[117]\tvalid_0's tweedie: 440.39\n",
      "[118]\tvalid_0's tweedie: 440.39\n",
      "[119]\tvalid_0's tweedie: 440.39\n",
      "[120]\tvalid_0's tweedie: 440.39\n",
      "[121]\tvalid_0's tweedie: 440.39\n",
      "[122]\tvalid_0's tweedie: 440.39\n",
      "[123]\tvalid_0's tweedie: 440.39\n",
      "[124]\tvalid_0's tweedie: 440.389\n",
      "[125]\tvalid_0's tweedie: 440.389\n",
      "[126]\tvalid_0's tweedie: 440.389\n",
      "[127]\tvalid_0's tweedie: 440.39\n",
      "[128]\tvalid_0's tweedie: 440.39\n",
      "[129]\tvalid_0's tweedie: 440.39\n",
      "[130]\tvalid_0's tweedie: 440.39\n",
      "[131]\tvalid_0's tweedie: 440.389\n",
      "[132]\tvalid_0's tweedie: 440.388\n",
      "[133]\tvalid_0's tweedie: 440.388\n",
      "[134]\tvalid_0's tweedie: 440.388\n",
      "[135]\tvalid_0's tweedie: 440.388\n",
      "[136]\tvalid_0's tweedie: 440.388\n",
      "[137]\tvalid_0's tweedie: 440.388\n",
      "[138]\tvalid_0's tweedie: 440.388\n",
      "[139]\tvalid_0's tweedie: 440.388\n",
      "[140]\tvalid_0's tweedie: 440.388\n",
      "[141]\tvalid_0's tweedie: 440.388\n",
      "[142]\tvalid_0's tweedie: 440.388\n",
      "[143]\tvalid_0's tweedie: 440.388\n",
      "[144]\tvalid_0's tweedie: 440.388\n",
      "[145]\tvalid_0's tweedie: 440.388\n",
      "[146]\tvalid_0's tweedie: 440.388\n",
      "[147]\tvalid_0's tweedie: 440.386\n",
      "[148]\tvalid_0's tweedie: 440.386\n",
      "[149]\tvalid_0's tweedie: 440.386\n",
      "[150]\tvalid_0's tweedie: 440.386\n",
      "[151]\tvalid_0's tweedie: 440.386\n",
      "[152]\tvalid_0's tweedie: 440.386\n",
      "[153]\tvalid_0's tweedie: 440.386\n",
      "[154]\tvalid_0's tweedie: 440.385\n",
      "[155]\tvalid_0's tweedie: 440.385\n",
      "[156]\tvalid_0's tweedie: 440.385\n",
      "[157]\tvalid_0's tweedie: 440.385\n",
      "[158]\tvalid_0's tweedie: 440.386\n",
      "[159]\tvalid_0's tweedie: 440.386\n",
      "[160]\tvalid_0's tweedie: 440.386\n",
      "[161]\tvalid_0's tweedie: 440.385\n",
      "[162]\tvalid_0's tweedie: 440.384\n",
      "[163]\tvalid_0's tweedie: 440.384\n",
      "[164]\tvalid_0's tweedie: 440.384\n",
      "[165]\tvalid_0's tweedie: 440.384\n",
      "[166]\tvalid_0's tweedie: 440.384\n",
      "[167]\tvalid_0's tweedie: 440.384\n",
      "[168]\tvalid_0's tweedie: 440.384\n",
      "[169]\tvalid_0's tweedie: 440.385\n",
      "[170]\tvalid_0's tweedie: 440.385\n",
      "[171]\tvalid_0's tweedie: 440.385\n",
      "[172]\tvalid_0's tweedie: 440.385\n",
      "[173]\tvalid_0's tweedie: 440.385\n",
      "[174]\tvalid_0's tweedie: 440.385\n",
      "[175]\tvalid_0's tweedie: 440.384\n",
      "[176]\tvalid_0's tweedie: 440.384\n",
      "[177]\tvalid_0's tweedie: 440.384\n",
      "[178]\tvalid_0's tweedie: 440.384\n",
      "[179]\tvalid_0's tweedie: 440.384\n",
      "[180]\tvalid_0's tweedie: 440.384\n",
      "[181]\tvalid_0's tweedie: 440.384\n",
      "[182]\tvalid_0's tweedie: 440.384\n",
      "[183]\tvalid_0's tweedie: 440.383\n",
      "[184]\tvalid_0's tweedie: 440.383\n",
      "[185]\tvalid_0's tweedie: 440.384\n",
      "[186]\tvalid_0's tweedie: 440.384\n",
      "[187]\tvalid_0's tweedie: 440.383\n",
      "[188]\tvalid_0's tweedie: 440.383\n",
      "[189]\tvalid_0's tweedie: 440.383\n",
      "[190]\tvalid_0's tweedie: 440.383\n",
      "[191]\tvalid_0's tweedie: 440.384\n",
      "[192]\tvalid_0's tweedie: 440.384\n",
      "[193]\tvalid_0's tweedie: 440.383\n",
      "[194]\tvalid_0's tweedie: 440.383\n",
      "[195]\tvalid_0's tweedie: 440.383\n",
      "[196]\tvalid_0's tweedie: 440.383\n",
      "[197]\tvalid_0's tweedie: 440.383\n",
      "[198]\tvalid_0's tweedie: 440.383\n",
      "[199]\tvalid_0's tweedie: 440.383\n",
      "[200]\tvalid_0's tweedie: 440.383\n",
      "[201]\tvalid_0's tweedie: 440.383\n",
      "[202]\tvalid_0's tweedie: 440.383\n",
      "[203]\tvalid_0's tweedie: 440.383\n",
      "[204]\tvalid_0's tweedie: 440.383\n",
      "[205]\tvalid_0's tweedie: 440.383\n",
      "[206]\tvalid_0's tweedie: 440.383\n",
      "[207]\tvalid_0's tweedie: 440.383\n",
      "[208]\tvalid_0's tweedie: 440.383\n",
      "[209]\tvalid_0's tweedie: 440.383\n",
      "[210]\tvalid_0's tweedie: 440.383\n",
      "[211]\tvalid_0's tweedie: 440.383\n",
      "[212]\tvalid_0's tweedie: 440.383\n",
      "[213]\tvalid_0's tweedie: 440.383\n",
      "[214]\tvalid_0's tweedie: 440.383\n",
      "[215]\tvalid_0's tweedie: 440.384\n",
      "[216]\tvalid_0's tweedie: 440.384\n",
      "[217]\tvalid_0's tweedie: 440.384\n",
      "[218]\tvalid_0's tweedie: 440.384\n",
      "[219]\tvalid_0's tweedie: 440.384\n",
      "[220]\tvalid_0's tweedie: 440.384\n",
      "[221]\tvalid_0's tweedie: 440.384\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's tweedie: 440.383\n",
      "Training model for level 4 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 5610, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343553\n",
      "[1]\tvalid_0's tweedie: 470.894\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.512\n",
      "[3]\tvalid_0's tweedie: 461.156\n",
      "[4]\tvalid_0's tweedie: 457.532\n",
      "[5]\tvalid_0's tweedie: 454.616\n",
      "[6]\tvalid_0's tweedie: 452.138\n",
      "[7]\tvalid_0's tweedie: 450.098\n",
      "[8]\tvalid_0's tweedie: 448.388\n",
      "[9]\tvalid_0's tweedie: 447.014\n",
      "[10]\tvalid_0's tweedie: 445.903\n",
      "[11]\tvalid_0's tweedie: 445.037\n",
      "[12]\tvalid_0's tweedie: 444.278\n",
      "[13]\tvalid_0's tweedie: 443.662\n",
      "[14]\tvalid_0's tweedie: 443.161\n",
      "[15]\tvalid_0's tweedie: 442.725\n",
      "[16]\tvalid_0's tweedie: 442.365\n",
      "[17]\tvalid_0's tweedie: 442.078\n",
      "[18]\tvalid_0's tweedie: 441.837\n",
      "[19]\tvalid_0's tweedie: 441.653\n",
      "[20]\tvalid_0's tweedie: 441.475\n",
      "[21]\tvalid_0's tweedie: 441.335\n",
      "[22]\tvalid_0's tweedie: 441.21\n",
      "[23]\tvalid_0's tweedie: 441.146\n",
      "[24]\tvalid_0's tweedie: 441.064\n",
      "[25]\tvalid_0's tweedie: 440.991\n",
      "[26]\tvalid_0's tweedie: 440.928\n",
      "[27]\tvalid_0's tweedie: 440.848\n",
      "[28]\tvalid_0's tweedie: 440.794\n",
      "[29]\tvalid_0's tweedie: 440.753\n",
      "[30]\tvalid_0's tweedie: 440.7\n",
      "[31]\tvalid_0's tweedie: 440.675\n",
      "[32]\tvalid_0's tweedie: 440.654\n",
      "[33]\tvalid_0's tweedie: 440.622\n",
      "[34]\tvalid_0's tweedie: 440.604\n",
      "[35]\tvalid_0's tweedie: 440.59\n",
      "[36]\tvalid_0's tweedie: 440.581\n",
      "[37]\tvalid_0's tweedie: 440.571\n",
      "[38]\tvalid_0's tweedie: 440.556\n",
      "[39]\tvalid_0's tweedie: 440.533\n",
      "[40]\tvalid_0's tweedie: 440.519\n",
      "[41]\tvalid_0's tweedie: 440.512\n",
      "[42]\tvalid_0's tweedie: 440.497\n",
      "[43]\tvalid_0's tweedie: 440.49\n",
      "[44]\tvalid_0's tweedie: 440.484\n",
      "[45]\tvalid_0's tweedie: 440.475\n",
      "[46]\tvalid_0's tweedie: 440.47\n",
      "[47]\tvalid_0's tweedie: 440.467\n",
      "[48]\tvalid_0's tweedie: 440.462\n",
      "[49]\tvalid_0's tweedie: 440.456\n",
      "[50]\tvalid_0's tweedie: 440.451\n",
      "[51]\tvalid_0's tweedie: 440.452\n",
      "[52]\tvalid_0's tweedie: 440.451\n",
      "[53]\tvalid_0's tweedie: 440.445\n",
      "[54]\tvalid_0's tweedie: 440.443\n",
      "[55]\tvalid_0's tweedie: 440.437\n",
      "[56]\tvalid_0's tweedie: 440.433\n",
      "[57]\tvalid_0's tweedie: 440.432\n",
      "[58]\tvalid_0's tweedie: 440.43\n",
      "[59]\tvalid_0's tweedie: 440.43\n",
      "[60]\tvalid_0's tweedie: 440.426\n",
      "[61]\tvalid_0's tweedie: 440.425\n",
      "[62]\tvalid_0's tweedie: 440.425\n",
      "[63]\tvalid_0's tweedie: 440.424\n",
      "[64]\tvalid_0's tweedie: 440.423\n",
      "[65]\tvalid_0's tweedie: 440.423\n",
      "[66]\tvalid_0's tweedie: 440.423\n",
      "[67]\tvalid_0's tweedie: 440.422\n",
      "[68]\tvalid_0's tweedie: 440.419\n",
      "[69]\tvalid_0's tweedie: 440.418\n",
      "[70]\tvalid_0's tweedie: 440.415\n",
      "[71]\tvalid_0's tweedie: 440.413\n",
      "[72]\tvalid_0's tweedie: 440.413\n",
      "[73]\tvalid_0's tweedie: 440.413\n",
      "[74]\tvalid_0's tweedie: 440.413\n",
      "[75]\tvalid_0's tweedie: 440.413\n",
      "[76]\tvalid_0's tweedie: 440.413\n",
      "[77]\tvalid_0's tweedie: 440.412\n",
      "[78]\tvalid_0's tweedie: 440.413\n",
      "[79]\tvalid_0's tweedie: 440.409\n",
      "[80]\tvalid_0's tweedie: 440.409\n",
      "[81]\tvalid_0's tweedie: 440.409\n",
      "[82]\tvalid_0's tweedie: 440.408\n",
      "[83]\tvalid_0's tweedie: 440.408\n",
      "[84]\tvalid_0's tweedie: 440.407\n",
      "[85]\tvalid_0's tweedie: 440.405\n",
      "[86]\tvalid_0's tweedie: 440.404\n",
      "[87]\tvalid_0's tweedie: 440.404\n",
      "[88]\tvalid_0's tweedie: 440.403\n",
      "[89]\tvalid_0's tweedie: 440.403\n",
      "[90]\tvalid_0's tweedie: 440.403\n",
      "[91]\tvalid_0's tweedie: 440.402\n",
      "[92]\tvalid_0's tweedie: 440.402\n",
      "[93]\tvalid_0's tweedie: 440.403\n",
      "[94]\tvalid_0's tweedie: 440.401\n",
      "[95]\tvalid_0's tweedie: 440.4\n",
      "[96]\tvalid_0's tweedie: 440.4\n",
      "[97]\tvalid_0's tweedie: 440.4\n",
      "[98]\tvalid_0's tweedie: 440.4\n",
      "[99]\tvalid_0's tweedie: 440.4\n",
      "[100]\tvalid_0's tweedie: 440.401\n",
      "[101]\tvalid_0's tweedie: 440.401\n",
      "[102]\tvalid_0's tweedie: 440.401\n",
      "[103]\tvalid_0's tweedie: 440.402\n",
      "[104]\tvalid_0's tweedie: 440.402\n",
      "[105]\tvalid_0's tweedie: 440.402\n",
      "[106]\tvalid_0's tweedie: 440.403\n",
      "[107]\tvalid_0's tweedie: 440.403\n",
      "[108]\tvalid_0's tweedie: 440.403\n",
      "[109]\tvalid_0's tweedie: 440.402\n",
      "[110]\tvalid_0's tweedie: 440.402\n",
      "[111]\tvalid_0's tweedie: 440.403\n",
      "[112]\tvalid_0's tweedie: 440.402\n",
      "[113]\tvalid_0's tweedie: 440.402\n",
      "[114]\tvalid_0's tweedie: 440.402\n",
      "[115]\tvalid_0's tweedie: 440.402\n",
      "[116]\tvalid_0's tweedie: 440.402\n",
      "[117]\tvalid_0's tweedie: 440.403\n",
      "[118]\tvalid_0's tweedie: 440.403\n",
      "[119]\tvalid_0's tweedie: 440.4\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's tweedie: 440.4\n",
      "Training model for level 4 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 5607, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343520\n",
      "[1]\tvalid_0's tweedie: 470.897\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.503\n",
      "[3]\tvalid_0's tweedie: 461.177\n",
      "[4]\tvalid_0's tweedie: 457.637\n",
      "[5]\tvalid_0's tweedie: 454.715\n",
      "[6]\tvalid_0's tweedie: 452.182\n",
      "[7]\tvalid_0's tweedie: 450.161\n",
      "[8]\tvalid_0's tweedie: 448.465\n",
      "[9]\tvalid_0's tweedie: 447.081\n",
      "[10]\tvalid_0's tweedie: 445.954\n",
      "[11]\tvalid_0's tweedie: 445.025\n",
      "[12]\tvalid_0's tweedie: 444.305\n",
      "[13]\tvalid_0's tweedie: 443.705\n",
      "[14]\tvalid_0's tweedie: 443.185\n",
      "[15]\tvalid_0's tweedie: 442.761\n",
      "[16]\tvalid_0's tweedie: 442.394\n",
      "[17]\tvalid_0's tweedie: 442.135\n",
      "[18]\tvalid_0's tweedie: 441.891\n",
      "[19]\tvalid_0's tweedie: 441.717\n",
      "[20]\tvalid_0's tweedie: 441.541\n",
      "[21]\tvalid_0's tweedie: 441.389\n",
      "[22]\tvalid_0's tweedie: 441.259\n",
      "[23]\tvalid_0's tweedie: 441.149\n",
      "[24]\tvalid_0's tweedie: 441.046\n",
      "[25]\tvalid_0's tweedie: 440.981\n",
      "[26]\tvalid_0's tweedie: 440.92\n",
      "[27]\tvalid_0's tweedie: 440.873\n",
      "[28]\tvalid_0's tweedie: 440.83\n",
      "[29]\tvalid_0's tweedie: 440.777\n",
      "[30]\tvalid_0's tweedie: 440.744\n",
      "[31]\tvalid_0's tweedie: 440.703\n",
      "[32]\tvalid_0's tweedie: 440.675\n",
      "[33]\tvalid_0's tweedie: 440.634\n",
      "[34]\tvalid_0's tweedie: 440.6\n",
      "[35]\tvalid_0's tweedie: 440.587\n",
      "[36]\tvalid_0's tweedie: 440.573\n",
      "[37]\tvalid_0's tweedie: 440.548\n",
      "[38]\tvalid_0's tweedie: 440.528\n",
      "[39]\tvalid_0's tweedie: 440.52\n",
      "[40]\tvalid_0's tweedie: 440.504\n",
      "[41]\tvalid_0's tweedie: 440.499\n",
      "[42]\tvalid_0's tweedie: 440.494\n",
      "[43]\tvalid_0's tweedie: 440.484\n",
      "[44]\tvalid_0's tweedie: 440.479\n",
      "[45]\tvalid_0's tweedie: 440.475\n",
      "[46]\tvalid_0's tweedie: 440.471\n",
      "[47]\tvalid_0's tweedie: 440.461\n",
      "[48]\tvalid_0's tweedie: 440.455\n",
      "[49]\tvalid_0's tweedie: 440.454\n",
      "[50]\tvalid_0's tweedie: 440.452\n",
      "[51]\tvalid_0's tweedie: 440.451\n",
      "[52]\tvalid_0's tweedie: 440.449\n",
      "[53]\tvalid_0's tweedie: 440.45\n",
      "[54]\tvalid_0's tweedie: 440.444\n",
      "[55]\tvalid_0's tweedie: 440.444\n",
      "[56]\tvalid_0's tweedie: 440.442\n",
      "[57]\tvalid_0's tweedie: 440.439\n",
      "[58]\tvalid_0's tweedie: 440.437\n",
      "[59]\tvalid_0's tweedie: 440.436\n",
      "[60]\tvalid_0's tweedie: 440.434\n",
      "[61]\tvalid_0's tweedie: 440.432\n",
      "[62]\tvalid_0's tweedie: 440.431\n",
      "[63]\tvalid_0's tweedie: 440.431\n",
      "[64]\tvalid_0's tweedie: 440.427\n",
      "[65]\tvalid_0's tweedie: 440.427\n",
      "[66]\tvalid_0's tweedie: 440.426\n",
      "[67]\tvalid_0's tweedie: 440.426\n",
      "[68]\tvalid_0's tweedie: 440.425\n",
      "[69]\tvalid_0's tweedie: 440.425\n",
      "[70]\tvalid_0's tweedie: 440.423\n",
      "[71]\tvalid_0's tweedie: 440.423\n",
      "[72]\tvalid_0's tweedie: 440.423\n",
      "[73]\tvalid_0's tweedie: 440.421\n",
      "[74]\tvalid_0's tweedie: 440.421\n",
      "[75]\tvalid_0's tweedie: 440.419\n",
      "[76]\tvalid_0's tweedie: 440.417\n",
      "[77]\tvalid_0's tweedie: 440.417\n",
      "[78]\tvalid_0's tweedie: 440.415\n",
      "[79]\tvalid_0's tweedie: 440.415\n",
      "[80]\tvalid_0's tweedie: 440.414\n",
      "[81]\tvalid_0's tweedie: 440.414\n",
      "[82]\tvalid_0's tweedie: 440.414\n",
      "[83]\tvalid_0's tweedie: 440.412\n",
      "[84]\tvalid_0's tweedie: 440.412\n",
      "[85]\tvalid_0's tweedie: 440.411\n",
      "[86]\tvalid_0's tweedie: 440.412\n",
      "[87]\tvalid_0's tweedie: 440.412\n",
      "[88]\tvalid_0's tweedie: 440.411\n",
      "[89]\tvalid_0's tweedie: 440.41\n",
      "[90]\tvalid_0's tweedie: 440.41\n",
      "[91]\tvalid_0's tweedie: 440.409\n",
      "[92]\tvalid_0's tweedie: 440.408\n",
      "[93]\tvalid_0's tweedie: 440.409\n",
      "[94]\tvalid_0's tweedie: 440.407\n",
      "[95]\tvalid_0's tweedie: 440.407\n",
      "[96]\tvalid_0's tweedie: 440.405\n",
      "[97]\tvalid_0's tweedie: 440.405\n",
      "[98]\tvalid_0's tweedie: 440.404\n",
      "[99]\tvalid_0's tweedie: 440.404\n",
      "[100]\tvalid_0's tweedie: 440.403\n",
      "[101]\tvalid_0's tweedie: 440.404\n",
      "[102]\tvalid_0's tweedie: 440.404\n",
      "[103]\tvalid_0's tweedie: 440.405\n",
      "[104]\tvalid_0's tweedie: 440.406\n",
      "[105]\tvalid_0's tweedie: 440.406\n",
      "[106]\tvalid_0's tweedie: 440.405\n",
      "[107]\tvalid_0's tweedie: 440.405\n",
      "[108]\tvalid_0's tweedie: 440.405\n",
      "[109]\tvalid_0's tweedie: 440.404\n",
      "[110]\tvalid_0's tweedie: 440.404\n",
      "[111]\tvalid_0's tweedie: 440.404\n",
      "[112]\tvalid_0's tweedie: 440.402\n",
      "[113]\tvalid_0's tweedie: 440.403\n",
      "[114]\tvalid_0's tweedie: 440.403\n",
      "[115]\tvalid_0's tweedie: 440.403\n",
      "[116]\tvalid_0's tweedie: 440.402\n",
      "[117]\tvalid_0's tweedie: 440.402\n",
      "[118]\tvalid_0's tweedie: 440.402\n",
      "[119]\tvalid_0's tweedie: 440.402\n",
      "[120]\tvalid_0's tweedie: 440.402\n",
      "[121]\tvalid_0's tweedie: 440.401\n",
      "[122]\tvalid_0's tweedie: 440.401\n",
      "[123]\tvalid_0's tweedie: 440.402\n",
      "[124]\tvalid_0's tweedie: 440.401\n",
      "[125]\tvalid_0's tweedie: 440.402\n",
      "[126]\tvalid_0's tweedie: 440.401\n",
      "[127]\tvalid_0's tweedie: 440.401\n",
      "[128]\tvalid_0's tweedie: 440.401\n",
      "[129]\tvalid_0's tweedie: 440.401\n",
      "[130]\tvalid_0's tweedie: 440.4\n",
      "[131]\tvalid_0's tweedie: 440.4\n",
      "[132]\tvalid_0's tweedie: 440.4\n",
      "[133]\tvalid_0's tweedie: 440.4\n",
      "[134]\tvalid_0's tweedie: 440.4\n",
      "[135]\tvalid_0's tweedie: 440.398\n",
      "[136]\tvalid_0's tweedie: 440.398\n",
      "[137]\tvalid_0's tweedie: 440.398\n",
      "[138]\tvalid_0's tweedie: 440.398\n",
      "[139]\tvalid_0's tweedie: 440.398\n",
      "[140]\tvalid_0's tweedie: 440.397\n",
      "[141]\tvalid_0's tweedie: 440.396\n",
      "[142]\tvalid_0's tweedie: 440.396\n",
      "[143]\tvalid_0's tweedie: 440.396\n",
      "[144]\tvalid_0's tweedie: 440.397\n",
      "[145]\tvalid_0's tweedie: 440.397\n",
      "[146]\tvalid_0's tweedie: 440.397\n",
      "[147]\tvalid_0's tweedie: 440.397\n",
      "[148]\tvalid_0's tweedie: 440.397\n",
      "[149]\tvalid_0's tweedie: 440.397\n",
      "[150]\tvalid_0's tweedie: 440.397\n",
      "[151]\tvalid_0's tweedie: 440.397\n",
      "[152]\tvalid_0's tweedie: 440.397\n",
      "[153]\tvalid_0's tweedie: 440.396\n",
      "[154]\tvalid_0's tweedie: 440.397\n",
      "[155]\tvalid_0's tweedie: 440.396\n",
      "[156]\tvalid_0's tweedie: 440.397\n",
      "[157]\tvalid_0's tweedie: 440.397\n",
      "[158]\tvalid_0's tweedie: 440.397\n",
      "[159]\tvalid_0's tweedie: 440.396\n",
      "[160]\tvalid_0's tweedie: 440.396\n",
      "[161]\tvalid_0's tweedie: 440.396\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's tweedie: 440.396\n",
      "Training model for level 4 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 5604, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343715\n",
      "[1]\tvalid_0's tweedie: 470.879\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.455\n",
      "[3]\tvalid_0's tweedie: 461.14\n",
      "[4]\tvalid_0's tweedie: 457.583\n",
      "[5]\tvalid_0's tweedie: 454.551\n",
      "[6]\tvalid_0's tweedie: 452.117\n",
      "[7]\tvalid_0's tweedie: 450.091\n",
      "[8]\tvalid_0's tweedie: 448.49\n",
      "[9]\tvalid_0's tweedie: 447.118\n",
      "[10]\tvalid_0's tweedie: 445.983\n",
      "[11]\tvalid_0's tweedie: 445.1\n",
      "[12]\tvalid_0's tweedie: 444.384\n",
      "[13]\tvalid_0's tweedie: 443.748\n",
      "[14]\tvalid_0's tweedie: 443.22\n",
      "[15]\tvalid_0's tweedie: 442.799\n",
      "[16]\tvalid_0's tweedie: 442.433\n",
      "[17]\tvalid_0's tweedie: 442.142\n",
      "[18]\tvalid_0's tweedie: 441.9\n",
      "[19]\tvalid_0's tweedie: 441.716\n",
      "[20]\tvalid_0's tweedie: 441.545\n",
      "[21]\tvalid_0's tweedie: 441.39\n",
      "[22]\tvalid_0's tweedie: 441.27\n",
      "[23]\tvalid_0's tweedie: 441.177\n",
      "[24]\tvalid_0's tweedie: 441.089\n",
      "[25]\tvalid_0's tweedie: 441.017\n",
      "[26]\tvalid_0's tweedie: 440.952\n",
      "[27]\tvalid_0's tweedie: 440.902\n",
      "[28]\tvalid_0's tweedie: 440.849\n",
      "[29]\tvalid_0's tweedie: 440.808\n",
      "[30]\tvalid_0's tweedie: 440.777\n",
      "[31]\tvalid_0's tweedie: 440.737\n",
      "[32]\tvalid_0's tweedie: 440.688\n",
      "[33]\tvalid_0's tweedie: 440.67\n",
      "[34]\tvalid_0's tweedie: 440.652\n",
      "[35]\tvalid_0's tweedie: 440.618\n",
      "[36]\tvalid_0's tweedie: 440.608\n",
      "[37]\tvalid_0's tweedie: 440.591\n",
      "[38]\tvalid_0's tweedie: 440.566\n",
      "[39]\tvalid_0's tweedie: 440.546\n",
      "[40]\tvalid_0's tweedie: 440.538\n",
      "[41]\tvalid_0's tweedie: 440.53\n",
      "[42]\tvalid_0's tweedie: 440.515\n",
      "[43]\tvalid_0's tweedie: 440.507\n",
      "[44]\tvalid_0's tweedie: 440.499\n",
      "[45]\tvalid_0's tweedie: 440.49\n",
      "[46]\tvalid_0's tweedie: 440.487\n",
      "[47]\tvalid_0's tweedie: 440.484\n",
      "[48]\tvalid_0's tweedie: 440.475\n",
      "[49]\tvalid_0's tweedie: 440.473\n",
      "[50]\tvalid_0's tweedie: 440.464\n",
      "[51]\tvalid_0's tweedie: 440.463\n",
      "[52]\tvalid_0's tweedie: 440.462\n",
      "[53]\tvalid_0's tweedie: 440.46\n",
      "[54]\tvalid_0's tweedie: 440.453\n",
      "[55]\tvalid_0's tweedie: 440.453\n",
      "[56]\tvalid_0's tweedie: 440.447\n",
      "[57]\tvalid_0's tweedie: 440.445\n",
      "[58]\tvalid_0's tweedie: 440.44\n",
      "[59]\tvalid_0's tweedie: 440.438\n",
      "[60]\tvalid_0's tweedie: 440.436\n",
      "[61]\tvalid_0's tweedie: 440.436\n",
      "[62]\tvalid_0's tweedie: 440.436\n",
      "[63]\tvalid_0's tweedie: 440.435\n",
      "[64]\tvalid_0's tweedie: 440.434\n",
      "[65]\tvalid_0's tweedie: 440.433\n",
      "[66]\tvalid_0's tweedie: 440.432\n",
      "[67]\tvalid_0's tweedie: 440.428\n",
      "[68]\tvalid_0's tweedie: 440.428\n",
      "[69]\tvalid_0's tweedie: 440.428\n",
      "[70]\tvalid_0's tweedie: 440.428\n",
      "[71]\tvalid_0's tweedie: 440.428\n",
      "[72]\tvalid_0's tweedie: 440.426\n",
      "[73]\tvalid_0's tweedie: 440.425\n",
      "[74]\tvalid_0's tweedie: 440.425\n",
      "[75]\tvalid_0's tweedie: 440.421\n",
      "[76]\tvalid_0's tweedie: 440.421\n",
      "[77]\tvalid_0's tweedie: 440.42\n",
      "[78]\tvalid_0's tweedie: 440.42\n",
      "[79]\tvalid_0's tweedie: 440.417\n",
      "[80]\tvalid_0's tweedie: 440.418\n",
      "[81]\tvalid_0's tweedie: 440.418\n",
      "[82]\tvalid_0's tweedie: 440.419\n",
      "[83]\tvalid_0's tweedie: 440.417\n",
      "[84]\tvalid_0's tweedie: 440.415\n",
      "[85]\tvalid_0's tweedie: 440.415\n",
      "[86]\tvalid_0's tweedie: 440.415\n",
      "[87]\tvalid_0's tweedie: 440.415\n",
      "[88]\tvalid_0's tweedie: 440.415\n",
      "[89]\tvalid_0's tweedie: 440.415\n",
      "[90]\tvalid_0's tweedie: 440.414\n",
      "[91]\tvalid_0's tweedie: 440.412\n",
      "[92]\tvalid_0's tweedie: 440.412\n",
      "[93]\tvalid_0's tweedie: 440.41\n",
      "[94]\tvalid_0's tweedie: 440.409\n",
      "[95]\tvalid_0's tweedie: 440.409\n",
      "[96]\tvalid_0's tweedie: 440.408\n",
      "[97]\tvalid_0's tweedie: 440.407\n",
      "[98]\tvalid_0's tweedie: 440.409\n",
      "[99]\tvalid_0's tweedie: 440.409\n",
      "[100]\tvalid_0's tweedie: 440.408\n",
      "[101]\tvalid_0's tweedie: 440.407\n",
      "[102]\tvalid_0's tweedie: 440.407\n",
      "[103]\tvalid_0's tweedie: 440.407\n",
      "[104]\tvalid_0's tweedie: 440.406\n",
      "[105]\tvalid_0's tweedie: 440.405\n",
      "[106]\tvalid_0's tweedie: 440.404\n",
      "[107]\tvalid_0's tweedie: 440.403\n",
      "[108]\tvalid_0's tweedie: 440.403\n",
      "[109]\tvalid_0's tweedie: 440.403\n",
      "[110]\tvalid_0's tweedie: 440.403\n",
      "[111]\tvalid_0's tweedie: 440.403\n",
      "[112]\tvalid_0's tweedie: 440.398\n",
      "[113]\tvalid_0's tweedie: 440.398\n",
      "[114]\tvalid_0's tweedie: 440.398\n",
      "[115]\tvalid_0's tweedie: 440.397\n",
      "[116]\tvalid_0's tweedie: 440.397\n",
      "[117]\tvalid_0's tweedie: 440.397\n",
      "[118]\tvalid_0's tweedie: 440.397\n",
      "[119]\tvalid_0's tweedie: 440.397\n",
      "[120]\tvalid_0's tweedie: 440.397\n",
      "[121]\tvalid_0's tweedie: 440.396\n",
      "[122]\tvalid_0's tweedie: 440.394\n",
      "[123]\tvalid_0's tweedie: 440.394\n",
      "[124]\tvalid_0's tweedie: 440.394\n",
      "[125]\tvalid_0's tweedie: 440.394\n",
      "[126]\tvalid_0's tweedie: 440.394\n",
      "[127]\tvalid_0's tweedie: 440.391\n",
      "[128]\tvalid_0's tweedie: 440.39\n",
      "[129]\tvalid_0's tweedie: 440.39\n",
      "[130]\tvalid_0's tweedie: 440.389\n",
      "[131]\tvalid_0's tweedie: 440.39\n",
      "[132]\tvalid_0's tweedie: 440.389\n",
      "[133]\tvalid_0's tweedie: 440.389\n",
      "[134]\tvalid_0's tweedie: 440.389\n",
      "[135]\tvalid_0's tweedie: 440.389\n",
      "[136]\tvalid_0's tweedie: 440.389\n",
      "[137]\tvalid_0's tweedie: 440.389\n",
      "[138]\tvalid_0's tweedie: 440.389\n",
      "[139]\tvalid_0's tweedie: 440.389\n",
      "[140]\tvalid_0's tweedie: 440.388\n",
      "[141]\tvalid_0's tweedie: 440.388\n",
      "[142]\tvalid_0's tweedie: 440.388\n",
      "[143]\tvalid_0's tweedie: 440.388\n",
      "[144]\tvalid_0's tweedie: 440.388\n",
      "[145]\tvalid_0's tweedie: 440.388\n",
      "[146]\tvalid_0's tweedie: 440.388\n",
      "[147]\tvalid_0's tweedie: 440.388\n",
      "[148]\tvalid_0's tweedie: 440.388\n",
      "[149]\tvalid_0's tweedie: 440.388\n",
      "[150]\tvalid_0's tweedie: 440.388\n",
      "[151]\tvalid_0's tweedie: 440.388\n",
      "[152]\tvalid_0's tweedie: 440.388\n",
      "[153]\tvalid_0's tweedie: 440.388\n",
      "[154]\tvalid_0's tweedie: 440.388\n",
      "[155]\tvalid_0's tweedie: 440.388\n",
      "[156]\tvalid_0's tweedie: 440.388\n",
      "[157]\tvalid_0's tweedie: 440.387\n",
      "[158]\tvalid_0's tweedie: 440.385\n",
      "[159]\tvalid_0's tweedie: 440.385\n",
      "[160]\tvalid_0's tweedie: 440.385\n",
      "[161]\tvalid_0's tweedie: 440.385\n",
      "[162]\tvalid_0's tweedie: 440.385\n",
      "[163]\tvalid_0's tweedie: 440.385\n",
      "[164]\tvalid_0's tweedie: 440.385\n",
      "[165]\tvalid_0's tweedie: 440.384\n",
      "[166]\tvalid_0's tweedie: 440.383\n",
      "[167]\tvalid_0's tweedie: 440.383\n",
      "[168]\tvalid_0's tweedie: 440.382\n",
      "[169]\tvalid_0's tweedie: 440.382\n",
      "[170]\tvalid_0's tweedie: 440.381\n",
      "[171]\tvalid_0's tweedie: 440.381\n",
      "[172]\tvalid_0's tweedie: 440.381\n",
      "[173]\tvalid_0's tweedie: 440.381\n",
      "[174]\tvalid_0's tweedie: 440.381\n",
      "[175]\tvalid_0's tweedie: 440.381\n",
      "[176]\tvalid_0's tweedie: 440.381\n",
      "[177]\tvalid_0's tweedie: 440.381\n",
      "[178]\tvalid_0's tweedie: 440.38\n",
      "[179]\tvalid_0's tweedie: 440.379\n",
      "[180]\tvalid_0's tweedie: 440.379\n",
      "[181]\tvalid_0's tweedie: 440.379\n",
      "[182]\tvalid_0's tweedie: 440.379\n",
      "[183]\tvalid_0's tweedie: 440.379\n",
      "[184]\tvalid_0's tweedie: 440.379\n",
      "[185]\tvalid_0's tweedie: 440.379\n",
      "[186]\tvalid_0's tweedie: 440.379\n",
      "[187]\tvalid_0's tweedie: 440.379\n",
      "[188]\tvalid_0's tweedie: 440.379\n",
      "[189]\tvalid_0's tweedie: 440.379\n",
      "[190]\tvalid_0's tweedie: 440.379\n",
      "[191]\tvalid_0's tweedie: 440.379\n",
      "[192]\tvalid_0's tweedie: 440.379\n",
      "[193]\tvalid_0's tweedie: 440.379\n",
      "[194]\tvalid_0's tweedie: 440.379\n",
      "[195]\tvalid_0's tweedie: 440.379\n",
      "[196]\tvalid_0's tweedie: 440.379\n",
      "[197]\tvalid_0's tweedie: 440.38\n",
      "[198]\tvalid_0's tweedie: 440.38\n",
      "[199]\tvalid_0's tweedie: 440.379\n",
      "[200]\tvalid_0's tweedie: 440.378\n",
      "[201]\tvalid_0's tweedie: 440.378\n",
      "[202]\tvalid_0's tweedie: 440.378\n",
      "[203]\tvalid_0's tweedie: 440.378\n",
      "[204]\tvalid_0's tweedie: 440.378\n",
      "[205]\tvalid_0's tweedie: 440.378\n",
      "[206]\tvalid_0's tweedie: 440.379\n",
      "[207]\tvalid_0's tweedie: 440.379\n",
      "[208]\tvalid_0's tweedie: 440.379\n",
      "[209]\tvalid_0's tweedie: 440.379\n",
      "[210]\tvalid_0's tweedie: 440.379\n",
      "[211]\tvalid_0's tweedie: 440.379\n",
      "[212]\tvalid_0's tweedie: 440.378\n",
      "[213]\tvalid_0's tweedie: 440.378\n",
      "[214]\tvalid_0's tweedie: 440.378\n",
      "[215]\tvalid_0's tweedie: 440.379\n",
      "[216]\tvalid_0's tweedie: 440.379\n",
      "[217]\tvalid_0's tweedie: 440.378\n",
      "[218]\tvalid_0's tweedie: 440.379\n",
      "[219]\tvalid_0's tweedie: 440.378\n",
      "[220]\tvalid_0's tweedie: 440.378\n",
      "[221]\tvalid_0's tweedie: 440.379\n",
      "[222]\tvalid_0's tweedie: 440.378\n",
      "[223]\tvalid_0's tweedie: 440.378\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's tweedie: 440.378\n",
      "Training model for level 4 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 5601, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.343874\n",
      "[1]\tvalid_0's tweedie: 470.876\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.59\n",
      "[3]\tvalid_0's tweedie: 461.224\n",
      "[4]\tvalid_0's tweedie: 457.627\n",
      "[5]\tvalid_0's tweedie: 454.547\n",
      "[6]\tvalid_0's tweedie: 452.135\n",
      "[7]\tvalid_0's tweedie: 450.108\n",
      "[8]\tvalid_0's tweedie: 448.43\n",
      "[9]\tvalid_0's tweedie: 447.06\n",
      "[10]\tvalid_0's tweedie: 445.957\n",
      "[11]\tvalid_0's tweedie: 445.032\n",
      "[12]\tvalid_0's tweedie: 444.311\n",
      "[13]\tvalid_0's tweedie: 443.704\n",
      "[14]\tvalid_0's tweedie: 443.195\n",
      "[15]\tvalid_0's tweedie: 442.766\n",
      "[16]\tvalid_0's tweedie: 442.407\n",
      "[17]\tvalid_0's tweedie: 442.104\n",
      "[18]\tvalid_0's tweedie: 441.869\n",
      "[19]\tvalid_0's tweedie: 441.665\n",
      "[20]\tvalid_0's tweedie: 441.5\n",
      "[21]\tvalid_0's tweedie: 441.374\n",
      "[22]\tvalid_0's tweedie: 441.236\n",
      "[23]\tvalid_0's tweedie: 441.148\n",
      "[24]\tvalid_0's tweedie: 441.059\n",
      "[25]\tvalid_0's tweedie: 440.991\n",
      "[26]\tvalid_0's tweedie: 440.924\n",
      "[27]\tvalid_0's tweedie: 440.875\n",
      "[28]\tvalid_0's tweedie: 440.799\n",
      "[29]\tvalid_0's tweedie: 440.767\n",
      "[30]\tvalid_0's tweedie: 440.733\n",
      "[31]\tvalid_0's tweedie: 440.707\n",
      "[32]\tvalid_0's tweedie: 440.679\n",
      "[33]\tvalid_0's tweedie: 440.635\n",
      "[34]\tvalid_0's tweedie: 440.617\n",
      "[35]\tvalid_0's tweedie: 440.587\n",
      "[36]\tvalid_0's tweedie: 440.56\n",
      "[37]\tvalid_0's tweedie: 440.551\n",
      "[38]\tvalid_0's tweedie: 440.54\n",
      "[39]\tvalid_0's tweedie: 440.521\n",
      "[40]\tvalid_0's tweedie: 440.514\n",
      "[41]\tvalid_0's tweedie: 440.51\n",
      "[42]\tvalid_0's tweedie: 440.498\n",
      "[43]\tvalid_0's tweedie: 440.492\n",
      "[44]\tvalid_0's tweedie: 440.488\n",
      "[45]\tvalid_0's tweedie: 440.484\n",
      "[46]\tvalid_0's tweedie: 440.472\n",
      "[47]\tvalid_0's tweedie: 440.469\n",
      "[48]\tvalid_0's tweedie: 440.461\n",
      "[49]\tvalid_0's tweedie: 440.455\n",
      "[50]\tvalid_0's tweedie: 440.455\n",
      "[51]\tvalid_0's tweedie: 440.452\n",
      "[52]\tvalid_0's tweedie: 440.454\n",
      "[53]\tvalid_0's tweedie: 440.453\n",
      "[54]\tvalid_0's tweedie: 440.449\n",
      "[55]\tvalid_0's tweedie: 440.448\n",
      "[56]\tvalid_0's tweedie: 440.446\n",
      "[57]\tvalid_0's tweedie: 440.445\n",
      "[58]\tvalid_0's tweedie: 440.443\n",
      "[59]\tvalid_0's tweedie: 440.443\n",
      "[60]\tvalid_0's tweedie: 440.442\n",
      "[61]\tvalid_0's tweedie: 440.44\n",
      "[62]\tvalid_0's tweedie: 440.44\n",
      "[63]\tvalid_0's tweedie: 440.438\n",
      "[64]\tvalid_0's tweedie: 440.437\n",
      "[65]\tvalid_0's tweedie: 440.437\n",
      "[66]\tvalid_0's tweedie: 440.436\n",
      "[67]\tvalid_0's tweedie: 440.436\n",
      "[68]\tvalid_0's tweedie: 440.436\n",
      "[69]\tvalid_0's tweedie: 440.433\n",
      "[70]\tvalid_0's tweedie: 440.433\n",
      "[71]\tvalid_0's tweedie: 440.429\n",
      "[72]\tvalid_0's tweedie: 440.426\n",
      "[73]\tvalid_0's tweedie: 440.427\n",
      "[74]\tvalid_0's tweedie: 440.426\n",
      "[75]\tvalid_0's tweedie: 440.423\n",
      "[76]\tvalid_0's tweedie: 440.421\n",
      "[77]\tvalid_0's tweedie: 440.419\n",
      "[78]\tvalid_0's tweedie: 440.418\n",
      "[79]\tvalid_0's tweedie: 440.417\n",
      "[80]\tvalid_0's tweedie: 440.416\n",
      "[81]\tvalid_0's tweedie: 440.416\n",
      "[82]\tvalid_0's tweedie: 440.415\n",
      "[83]\tvalid_0's tweedie: 440.415\n",
      "[84]\tvalid_0's tweedie: 440.415\n",
      "[85]\tvalid_0's tweedie: 440.413\n",
      "[86]\tvalid_0's tweedie: 440.413\n",
      "[87]\tvalid_0's tweedie: 440.413\n",
      "[88]\tvalid_0's tweedie: 440.412\n",
      "[89]\tvalid_0's tweedie: 440.412\n",
      "[90]\tvalid_0's tweedie: 440.41\n",
      "[91]\tvalid_0's tweedie: 440.411\n",
      "[92]\tvalid_0's tweedie: 440.411\n",
      "[93]\tvalid_0's tweedie: 440.41\n",
      "[94]\tvalid_0's tweedie: 440.408\n",
      "[95]\tvalid_0's tweedie: 440.408\n",
      "[96]\tvalid_0's tweedie: 440.41\n",
      "[97]\tvalid_0's tweedie: 440.41\n",
      "[98]\tvalid_0's tweedie: 440.41\n",
      "[99]\tvalid_0's tweedie: 440.411\n",
      "[100]\tvalid_0's tweedie: 440.411\n",
      "[101]\tvalid_0's tweedie: 440.41\n",
      "[102]\tvalid_0's tweedie: 440.411\n",
      "[103]\tvalid_0's tweedie: 440.41\n",
      "[104]\tvalid_0's tweedie: 440.41\n",
      "[105]\tvalid_0's tweedie: 440.409\n",
      "[106]\tvalid_0's tweedie: 440.409\n",
      "[107]\tvalid_0's tweedie: 440.408\n",
      "[108]\tvalid_0's tweedie: 440.408\n",
      "[109]\tvalid_0's tweedie: 440.409\n",
      "[110]\tvalid_0's tweedie: 440.411\n",
      "[111]\tvalid_0's tweedie: 440.411\n",
      "[112]\tvalid_0's tweedie: 440.412\n",
      "[113]\tvalid_0's tweedie: 440.413\n",
      "[114]\tvalid_0's tweedie: 440.413\n",
      "[115]\tvalid_0's tweedie: 440.413\n",
      "[116]\tvalid_0's tweedie: 440.412\n",
      "[117]\tvalid_0's tweedie: 440.412\n",
      "[118]\tvalid_0's tweedie: 440.412\n",
      "[119]\tvalid_0's tweedie: 440.411\n",
      "[120]\tvalid_0's tweedie: 440.411\n",
      "[121]\tvalid_0's tweedie: 440.408\n",
      "[122]\tvalid_0's tweedie: 440.408\n",
      "[123]\tvalid_0's tweedie: 440.408\n",
      "[124]\tvalid_0's tweedie: 440.409\n",
      "[125]\tvalid_0's tweedie: 440.41\n",
      "[126]\tvalid_0's tweedie: 440.41\n",
      "[127]\tvalid_0's tweedie: 440.41\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's tweedie: 440.408\n",
      "Training model for level 4 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 5598, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344075\n",
      "[1]\tvalid_0's tweedie: 470.87\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.591\n",
      "[3]\tvalid_0's tweedie: 461.217\n",
      "[4]\tvalid_0's tweedie: 457.624\n",
      "[5]\tvalid_0's tweedie: 454.546\n",
      "[6]\tvalid_0's tweedie: 452.139\n",
      "[7]\tvalid_0's tweedie: 450.132\n",
      "[8]\tvalid_0's tweedie: 448.432\n",
      "[9]\tvalid_0's tweedie: 447.067\n",
      "[10]\tvalid_0's tweedie: 445.921\n",
      "[11]\tvalid_0's tweedie: 445.01\n",
      "[12]\tvalid_0's tweedie: 444.269\n",
      "[13]\tvalid_0's tweedie: 443.687\n",
      "[14]\tvalid_0's tweedie: 443.185\n",
      "[15]\tvalid_0's tweedie: 442.738\n",
      "[16]\tvalid_0's tweedie: 442.391\n",
      "[17]\tvalid_0's tweedie: 442.092\n",
      "[18]\tvalid_0's tweedie: 441.858\n",
      "[19]\tvalid_0's tweedie: 441.661\n",
      "[20]\tvalid_0's tweedie: 441.521\n",
      "[21]\tvalid_0's tweedie: 441.395\n",
      "[22]\tvalid_0's tweedie: 441.285\n",
      "[23]\tvalid_0's tweedie: 441.181\n",
      "[24]\tvalid_0's tweedie: 441.113\n",
      "[25]\tvalid_0's tweedie: 441.03\n",
      "[26]\tvalid_0's tweedie: 440.966\n",
      "[27]\tvalid_0's tweedie: 440.9\n",
      "[28]\tvalid_0's tweedie: 440.846\n",
      "[29]\tvalid_0's tweedie: 440.811\n",
      "[30]\tvalid_0's tweedie: 440.747\n",
      "[31]\tvalid_0's tweedie: 440.717\n",
      "[32]\tvalid_0's tweedie: 440.684\n",
      "[33]\tvalid_0's tweedie: 440.642\n",
      "[34]\tvalid_0's tweedie: 440.622\n",
      "[35]\tvalid_0's tweedie: 440.59\n",
      "[36]\tvalid_0's tweedie: 440.563\n",
      "[37]\tvalid_0's tweedie: 440.542\n",
      "[38]\tvalid_0's tweedie: 440.534\n",
      "[39]\tvalid_0's tweedie: 440.516\n",
      "[40]\tvalid_0's tweedie: 440.505\n",
      "[41]\tvalid_0's tweedie: 440.5\n",
      "[42]\tvalid_0's tweedie: 440.491\n",
      "[43]\tvalid_0's tweedie: 440.484\n",
      "[44]\tvalid_0's tweedie: 440.477\n",
      "[45]\tvalid_0's tweedie: 440.47\n",
      "[46]\tvalid_0's tweedie: 440.463\n",
      "[47]\tvalid_0's tweedie: 440.451\n",
      "[48]\tvalid_0's tweedie: 440.449\n",
      "[49]\tvalid_0's tweedie: 440.443\n",
      "[50]\tvalid_0's tweedie: 440.445\n",
      "[51]\tvalid_0's tweedie: 440.444\n",
      "[52]\tvalid_0's tweedie: 440.444\n",
      "[53]\tvalid_0's tweedie: 440.443\n",
      "[54]\tvalid_0's tweedie: 440.439\n",
      "[55]\tvalid_0's tweedie: 440.438\n",
      "[56]\tvalid_0's tweedie: 440.435\n",
      "[57]\tvalid_0's tweedie: 440.434\n",
      "[58]\tvalid_0's tweedie: 440.434\n",
      "[59]\tvalid_0's tweedie: 440.433\n",
      "[60]\tvalid_0's tweedie: 440.43\n",
      "[61]\tvalid_0's tweedie: 440.429\n",
      "[62]\tvalid_0's tweedie: 440.426\n",
      "[63]\tvalid_0's tweedie: 440.426\n",
      "[64]\tvalid_0's tweedie: 440.425\n",
      "[65]\tvalid_0's tweedie: 440.42\n",
      "[66]\tvalid_0's tweedie: 440.42\n",
      "[67]\tvalid_0's tweedie: 440.418\n",
      "[68]\tvalid_0's tweedie: 440.418\n",
      "[69]\tvalid_0's tweedie: 440.416\n",
      "[70]\tvalid_0's tweedie: 440.416\n",
      "[71]\tvalid_0's tweedie: 440.416\n",
      "[72]\tvalid_0's tweedie: 440.415\n",
      "[73]\tvalid_0's tweedie: 440.415\n",
      "[74]\tvalid_0's tweedie: 440.414\n",
      "[75]\tvalid_0's tweedie: 440.414\n",
      "[76]\tvalid_0's tweedie: 440.414\n",
      "[77]\tvalid_0's tweedie: 440.411\n",
      "[78]\tvalid_0's tweedie: 440.409\n",
      "[79]\tvalid_0's tweedie: 440.409\n",
      "[80]\tvalid_0's tweedie: 440.407\n",
      "[81]\tvalid_0's tweedie: 440.407\n",
      "[82]\tvalid_0's tweedie: 440.407\n",
      "[83]\tvalid_0's tweedie: 440.406\n",
      "[84]\tvalid_0's tweedie: 440.408\n",
      "[85]\tvalid_0's tweedie: 440.407\n",
      "[86]\tvalid_0's tweedie: 440.406\n",
      "[87]\tvalid_0's tweedie: 440.407\n",
      "[88]\tvalid_0's tweedie: 440.407\n",
      "[89]\tvalid_0's tweedie: 440.406\n",
      "[90]\tvalid_0's tweedie: 440.405\n",
      "[91]\tvalid_0's tweedie: 440.404\n",
      "[92]\tvalid_0's tweedie: 440.404\n",
      "[93]\tvalid_0's tweedie: 440.403\n",
      "[94]\tvalid_0's tweedie: 440.403\n",
      "[95]\tvalid_0's tweedie: 440.403\n",
      "[96]\tvalid_0's tweedie: 440.403\n",
      "[97]\tvalid_0's tweedie: 440.403\n",
      "[98]\tvalid_0's tweedie: 440.402\n",
      "[99]\tvalid_0's tweedie: 440.402\n",
      "[100]\tvalid_0's tweedie: 440.401\n",
      "[101]\tvalid_0's tweedie: 440.401\n",
      "[102]\tvalid_0's tweedie: 440.4\n",
      "[103]\tvalid_0's tweedie: 440.4\n",
      "[104]\tvalid_0's tweedie: 440.4\n",
      "[105]\tvalid_0's tweedie: 440.4\n",
      "[106]\tvalid_0's tweedie: 440.4\n",
      "[107]\tvalid_0's tweedie: 440.4\n",
      "[108]\tvalid_0's tweedie: 440.4\n",
      "[109]\tvalid_0's tweedie: 440.4\n",
      "[110]\tvalid_0's tweedie: 440.401\n",
      "[111]\tvalid_0's tweedie: 440.401\n",
      "[112]\tvalid_0's tweedie: 440.4\n",
      "[113]\tvalid_0's tweedie: 440.4\n",
      "[114]\tvalid_0's tweedie: 440.4\n",
      "[115]\tvalid_0's tweedie: 440.4\n",
      "[116]\tvalid_0's tweedie: 440.4\n",
      "[117]\tvalid_0's tweedie: 440.4\n",
      "[118]\tvalid_0's tweedie: 440.399\n",
      "[119]\tvalid_0's tweedie: 440.399\n",
      "[120]\tvalid_0's tweedie: 440.399\n",
      "[121]\tvalid_0's tweedie: 440.399\n",
      "[122]\tvalid_0's tweedie: 440.399\n",
      "[123]\tvalid_0's tweedie: 440.399\n",
      "[124]\tvalid_0's tweedie: 440.399\n",
      "[125]\tvalid_0's tweedie: 440.399\n",
      "[126]\tvalid_0's tweedie: 440.399\n",
      "[127]\tvalid_0's tweedie: 440.399\n",
      "[128]\tvalid_0's tweedie: 440.399\n",
      "[129]\tvalid_0's tweedie: 440.399\n",
      "[130]\tvalid_0's tweedie: 440.399\n",
      "[131]\tvalid_0's tweedie: 440.397\n",
      "[132]\tvalid_0's tweedie: 440.397\n",
      "[133]\tvalid_0's tweedie: 440.397\n",
      "[134]\tvalid_0's tweedie: 440.397\n",
      "[135]\tvalid_0's tweedie: 440.398\n",
      "[136]\tvalid_0's tweedie: 440.398\n",
      "[137]\tvalid_0's tweedie: 440.397\n",
      "[138]\tvalid_0's tweedie: 440.397\n",
      "[139]\tvalid_0's tweedie: 440.396\n",
      "[140]\tvalid_0's tweedie: 440.396\n",
      "[141]\tvalid_0's tweedie: 440.398\n",
      "[142]\tvalid_0's tweedie: 440.398\n",
      "[143]\tvalid_0's tweedie: 440.398\n",
      "[144]\tvalid_0's tweedie: 440.398\n",
      "[145]\tvalid_0's tweedie: 440.397\n",
      "[146]\tvalid_0's tweedie: 440.397\n",
      "[147]\tvalid_0's tweedie: 440.398\n",
      "[148]\tvalid_0's tweedie: 440.397\n",
      "[149]\tvalid_0's tweedie: 440.397\n",
      "[150]\tvalid_0's tweedie: 440.397\n",
      "[151]\tvalid_0's tweedie: 440.396\n",
      "[152]\tvalid_0's tweedie: 440.396\n",
      "[153]\tvalid_0's tweedie: 440.397\n",
      "[154]\tvalid_0's tweedie: 440.398\n",
      "[155]\tvalid_0's tweedie: 440.398\n",
      "[156]\tvalid_0's tweedie: 440.398\n",
      "[157]\tvalid_0's tweedie: 440.397\n",
      "[158]\tvalid_0's tweedie: 440.397\n",
      "[159]\tvalid_0's tweedie: 440.397\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's tweedie: 440.396\n",
      "Training model for level 4 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 5595, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344293\n",
      "[1]\tvalid_0's tweedie: 470.881\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.497\n",
      "[3]\tvalid_0's tweedie: 461.172\n",
      "[4]\tvalid_0's tweedie: 457.574\n",
      "[5]\tvalid_0's tweedie: 454.652\n",
      "[6]\tvalid_0's tweedie: 452.167\n",
      "[7]\tvalid_0's tweedie: 450.147\n",
      "[8]\tvalid_0's tweedie: 448.444\n",
      "[9]\tvalid_0's tweedie: 447.08\n",
      "[10]\tvalid_0's tweedie: 445.983\n",
      "[11]\tvalid_0's tweedie: 445.067\n",
      "[12]\tvalid_0's tweedie: 444.336\n",
      "[13]\tvalid_0's tweedie: 443.732\n",
      "[14]\tvalid_0's tweedie: 443.202\n",
      "[15]\tvalid_0's tweedie: 442.793\n",
      "[16]\tvalid_0's tweedie: 442.416\n",
      "[17]\tvalid_0's tweedie: 442.12\n",
      "[18]\tvalid_0's tweedie: 441.892\n",
      "[19]\tvalid_0's tweedie: 441.68\n",
      "[20]\tvalid_0's tweedie: 441.524\n",
      "[21]\tvalid_0's tweedie: 441.39\n",
      "[22]\tvalid_0's tweedie: 441.265\n",
      "[23]\tvalid_0's tweedie: 441.174\n",
      "[24]\tvalid_0's tweedie: 441.078\n",
      "[25]\tvalid_0's tweedie: 441.004\n",
      "[26]\tvalid_0's tweedie: 440.936\n",
      "[27]\tvalid_0's tweedie: 440.903\n",
      "[28]\tvalid_0's tweedie: 440.855\n",
      "[29]\tvalid_0's tweedie: 440.801\n",
      "[30]\tvalid_0's tweedie: 440.772\n",
      "[31]\tvalid_0's tweedie: 440.743\n",
      "[32]\tvalid_0's tweedie: 440.69\n",
      "[33]\tvalid_0's tweedie: 440.645\n",
      "[34]\tvalid_0's tweedie: 440.626\n",
      "[35]\tvalid_0's tweedie: 440.594\n",
      "[36]\tvalid_0's tweedie: 440.577\n",
      "[37]\tvalid_0's tweedie: 440.562\n",
      "[38]\tvalid_0's tweedie: 440.55\n",
      "[39]\tvalid_0's tweedie: 440.526\n",
      "[40]\tvalid_0's tweedie: 440.519\n",
      "[41]\tvalid_0's tweedie: 440.504\n",
      "[42]\tvalid_0's tweedie: 440.491\n",
      "[43]\tvalid_0's tweedie: 440.486\n",
      "[44]\tvalid_0's tweedie: 440.478\n",
      "[45]\tvalid_0's tweedie: 440.473\n",
      "[46]\tvalid_0's tweedie: 440.459\n",
      "[47]\tvalid_0's tweedie: 440.457\n",
      "[48]\tvalid_0's tweedie: 440.454\n",
      "[49]\tvalid_0's tweedie: 440.452\n",
      "[50]\tvalid_0's tweedie: 440.442\n",
      "[51]\tvalid_0's tweedie: 440.437\n",
      "[52]\tvalid_0's tweedie: 440.433\n",
      "[53]\tvalid_0's tweedie: 440.426\n",
      "[54]\tvalid_0's tweedie: 440.425\n",
      "[55]\tvalid_0's tweedie: 440.419\n",
      "[56]\tvalid_0's tweedie: 440.417\n",
      "[57]\tvalid_0's tweedie: 440.416\n",
      "[58]\tvalid_0's tweedie: 440.412\n",
      "[59]\tvalid_0's tweedie: 440.411\n",
      "[60]\tvalid_0's tweedie: 440.41\n",
      "[61]\tvalid_0's tweedie: 440.408\n",
      "[62]\tvalid_0's tweedie: 440.408\n",
      "[63]\tvalid_0's tweedie: 440.406\n",
      "[64]\tvalid_0's tweedie: 440.406\n",
      "[65]\tvalid_0's tweedie: 440.406\n",
      "[66]\tvalid_0's tweedie: 440.405\n",
      "[67]\tvalid_0's tweedie: 440.404\n",
      "[68]\tvalid_0's tweedie: 440.404\n",
      "[69]\tvalid_0's tweedie: 440.403\n",
      "[70]\tvalid_0's tweedie: 440.4\n",
      "[71]\tvalid_0's tweedie: 440.399\n",
      "[72]\tvalid_0's tweedie: 440.397\n",
      "[73]\tvalid_0's tweedie: 440.397\n",
      "[74]\tvalid_0's tweedie: 440.396\n",
      "[75]\tvalid_0's tweedie: 440.395\n",
      "[76]\tvalid_0's tweedie: 440.395\n",
      "[77]\tvalid_0's tweedie: 440.395\n",
      "[78]\tvalid_0's tweedie: 440.394\n",
      "[79]\tvalid_0's tweedie: 440.392\n",
      "[80]\tvalid_0's tweedie: 440.392\n",
      "[81]\tvalid_0's tweedie: 440.39\n",
      "[82]\tvalid_0's tweedie: 440.388\n",
      "[83]\tvalid_0's tweedie: 440.388\n",
      "[84]\tvalid_0's tweedie: 440.387\n",
      "[85]\tvalid_0's tweedie: 440.387\n",
      "[86]\tvalid_0's tweedie: 440.387\n",
      "[87]\tvalid_0's tweedie: 440.387\n",
      "[88]\tvalid_0's tweedie: 440.386\n",
      "[89]\tvalid_0's tweedie: 440.386\n",
      "[90]\tvalid_0's tweedie: 440.384\n",
      "[91]\tvalid_0's tweedie: 440.384\n",
      "[92]\tvalid_0's tweedie: 440.383\n",
      "[93]\tvalid_0's tweedie: 440.383\n",
      "[94]\tvalid_0's tweedie: 440.383\n",
      "[95]\tvalid_0's tweedie: 440.382\n",
      "[96]\tvalid_0's tweedie: 440.382\n",
      "[97]\tvalid_0's tweedie: 440.381\n",
      "[98]\tvalid_0's tweedie: 440.38\n",
      "[99]\tvalid_0's tweedie: 440.38\n",
      "[100]\tvalid_0's tweedie: 440.381\n",
      "[101]\tvalid_0's tweedie: 440.382\n",
      "[102]\tvalid_0's tweedie: 440.382\n",
      "[103]\tvalid_0's tweedie: 440.382\n",
      "[104]\tvalid_0's tweedie: 440.382\n",
      "[105]\tvalid_0's tweedie: 440.382\n",
      "[106]\tvalid_0's tweedie: 440.382\n",
      "[107]\tvalid_0's tweedie: 440.382\n",
      "[108]\tvalid_0's tweedie: 440.382\n",
      "[109]\tvalid_0's tweedie: 440.382\n",
      "[110]\tvalid_0's tweedie: 440.382\n",
      "[111]\tvalid_0's tweedie: 440.382\n",
      "[112]\tvalid_0's tweedie: 440.382\n",
      "[113]\tvalid_0's tweedie: 440.381\n",
      "[114]\tvalid_0's tweedie: 440.379\n",
      "[115]\tvalid_0's tweedie: 440.379\n",
      "[116]\tvalid_0's tweedie: 440.376\n",
      "[117]\tvalid_0's tweedie: 440.375\n",
      "[118]\tvalid_0's tweedie: 440.375\n",
      "[119]\tvalid_0's tweedie: 440.375\n",
      "[120]\tvalid_0's tweedie: 440.374\n",
      "[121]\tvalid_0's tweedie: 440.374\n",
      "[122]\tvalid_0's tweedie: 440.374\n",
      "[123]\tvalid_0's tweedie: 440.374\n",
      "[124]\tvalid_0's tweedie: 440.375\n",
      "[125]\tvalid_0's tweedie: 440.375\n",
      "[126]\tvalid_0's tweedie: 440.375\n",
      "[127]\tvalid_0's tweedie: 440.375\n",
      "[128]\tvalid_0's tweedie: 440.374\n",
      "[129]\tvalid_0's tweedie: 440.374\n",
      "[130]\tvalid_0's tweedie: 440.374\n",
      "[131]\tvalid_0's tweedie: 440.375\n",
      "[132]\tvalid_0's tweedie: 440.375\n",
      "[133]\tvalid_0's tweedie: 440.375\n",
      "[134]\tvalid_0's tweedie: 440.375\n",
      "[135]\tvalid_0's tweedie: 440.375\n",
      "[136]\tvalid_0's tweedie: 440.374\n",
      "[137]\tvalid_0's tweedie: 440.375\n",
      "[138]\tvalid_0's tweedie: 440.375\n",
      "[139]\tvalid_0's tweedie: 440.375\n",
      "[140]\tvalid_0's tweedie: 440.375\n",
      "[141]\tvalid_0's tweedie: 440.374\n",
      "[142]\tvalid_0's tweedie: 440.375\n",
      "[143]\tvalid_0's tweedie: 440.375\n",
      "[144]\tvalid_0's tweedie: 440.375\n",
      "[145]\tvalid_0's tweedie: 440.375\n",
      "[146]\tvalid_0's tweedie: 440.375\n",
      "[147]\tvalid_0's tweedie: 440.375\n",
      "[148]\tvalid_0's tweedie: 440.374\n",
      "[149]\tvalid_0's tweedie: 440.373\n",
      "[150]\tvalid_0's tweedie: 440.373\n",
      "[151]\tvalid_0's tweedie: 440.372\n",
      "[152]\tvalid_0's tweedie: 440.372\n",
      "[153]\tvalid_0's tweedie: 440.372\n",
      "[154]\tvalid_0's tweedie: 440.373\n",
      "[155]\tvalid_0's tweedie: 440.373\n",
      "[156]\tvalid_0's tweedie: 440.373\n",
      "[157]\tvalid_0's tweedie: 440.373\n",
      "[158]\tvalid_0's tweedie: 440.374\n",
      "[159]\tvalid_0's tweedie: 440.374\n",
      "[160]\tvalid_0's tweedie: 440.372\n",
      "[161]\tvalid_0's tweedie: 440.372\n",
      "[162]\tvalid_0's tweedie: 440.371\n",
      "[163]\tvalid_0's tweedie: 440.371\n",
      "[164]\tvalid_0's tweedie: 440.371\n",
      "[165]\tvalid_0's tweedie: 440.371\n",
      "[166]\tvalid_0's tweedie: 440.37\n",
      "[167]\tvalid_0's tweedie: 440.37\n",
      "[168]\tvalid_0's tweedie: 440.37\n",
      "[169]\tvalid_0's tweedie: 440.37\n",
      "[170]\tvalid_0's tweedie: 440.37\n",
      "[171]\tvalid_0's tweedie: 440.37\n",
      "[172]\tvalid_0's tweedie: 440.369\n",
      "[173]\tvalid_0's tweedie: 440.37\n",
      "[174]\tvalid_0's tweedie: 440.369\n",
      "[175]\tvalid_0's tweedie: 440.369\n",
      "[176]\tvalid_0's tweedie: 440.367\n",
      "[177]\tvalid_0's tweedie: 440.367\n",
      "[178]\tvalid_0's tweedie: 440.367\n",
      "[179]\tvalid_0's tweedie: 440.367\n",
      "[180]\tvalid_0's tweedie: 440.367\n",
      "[181]\tvalid_0's tweedie: 440.367\n",
      "[182]\tvalid_0's tweedie: 440.366\n",
      "[183]\tvalid_0's tweedie: 440.366\n",
      "[184]\tvalid_0's tweedie: 440.365\n",
      "[185]\tvalid_0's tweedie: 440.365\n",
      "[186]\tvalid_0's tweedie: 440.365\n",
      "[187]\tvalid_0's tweedie: 440.365\n",
      "[188]\tvalid_0's tweedie: 440.365\n",
      "[189]\tvalid_0's tweedie: 440.365\n",
      "[190]\tvalid_0's tweedie: 440.365\n",
      "[191]\tvalid_0's tweedie: 440.365\n",
      "[192]\tvalid_0's tweedie: 440.365\n",
      "[193]\tvalid_0's tweedie: 440.364\n",
      "[194]\tvalid_0's tweedie: 440.364\n",
      "[195]\tvalid_0's tweedie: 440.363\n",
      "[196]\tvalid_0's tweedie: 440.365\n",
      "[197]\tvalid_0's tweedie: 440.365\n",
      "[198]\tvalid_0's tweedie: 440.365\n",
      "[199]\tvalid_0's tweedie: 440.365\n",
      "[200]\tvalid_0's tweedie: 440.365\n",
      "[201]\tvalid_0's tweedie: 440.365\n",
      "[202]\tvalid_0's tweedie: 440.365\n",
      "[203]\tvalid_0's tweedie: 440.365\n",
      "[204]\tvalid_0's tweedie: 440.365\n",
      "[205]\tvalid_0's tweedie: 440.365\n",
      "[206]\tvalid_0's tweedie: 440.364\n",
      "[207]\tvalid_0's tweedie: 440.364\n",
      "[208]\tvalid_0's tweedie: 440.365\n",
      "[209]\tvalid_0's tweedie: 440.365\n",
      "[210]\tvalid_0's tweedie: 440.366\n",
      "[211]\tvalid_0's tweedie: 440.366\n",
      "[212]\tvalid_0's tweedie: 440.366\n",
      "[213]\tvalid_0's tweedie: 440.367\n",
      "[214]\tvalid_0's tweedie: 440.366\n",
      "[215]\tvalid_0's tweedie: 440.366\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's tweedie: 440.363\n",
      "Training model for level 4 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 5592, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344459\n",
      "[1]\tvalid_0's tweedie: 471.187\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.972\n",
      "[3]\tvalid_0's tweedie: 461.664\n",
      "[4]\tvalid_0's tweedie: 458.111\n",
      "[5]\tvalid_0's tweedie: 455.198\n",
      "[6]\tvalid_0's tweedie: 452.781\n",
      "[7]\tvalid_0's tweedie: 450.683\n",
      "[8]\tvalid_0's tweedie: 449.029\n",
      "[9]\tvalid_0's tweedie: 447.607\n",
      "[10]\tvalid_0's tweedie: 446.508\n",
      "[11]\tvalid_0's tweedie: 445.563\n",
      "[12]\tvalid_0's tweedie: 444.776\n",
      "[13]\tvalid_0's tweedie: 444.119\n",
      "[14]\tvalid_0's tweedie: 443.559\n",
      "[15]\tvalid_0's tweedie: 443.101\n",
      "[16]\tvalid_0's tweedie: 442.731\n",
      "[17]\tvalid_0's tweedie: 442.431\n",
      "[18]\tvalid_0's tweedie: 442.157\n",
      "[19]\tvalid_0's tweedie: 441.967\n",
      "[20]\tvalid_0's tweedie: 441.764\n",
      "[21]\tvalid_0's tweedie: 441.612\n",
      "[22]\tvalid_0's tweedie: 441.501\n",
      "[23]\tvalid_0's tweedie: 441.398\n",
      "[24]\tvalid_0's tweedie: 441.29\n",
      "[25]\tvalid_0's tweedie: 441.201\n",
      "[26]\tvalid_0's tweedie: 441.128\n",
      "[27]\tvalid_0's tweedie: 441.067\n",
      "[28]\tvalid_0's tweedie: 441.019\n",
      "[29]\tvalid_0's tweedie: 440.968\n",
      "[30]\tvalid_0's tweedie: 440.885\n",
      "[31]\tvalid_0's tweedie: 440.848\n",
      "[32]\tvalid_0's tweedie: 440.785\n",
      "[33]\tvalid_0's tweedie: 440.76\n",
      "[34]\tvalid_0's tweedie: 440.71\n",
      "[35]\tvalid_0's tweedie: 440.671\n",
      "[36]\tvalid_0's tweedie: 440.657\n",
      "[37]\tvalid_0's tweedie: 440.63\n",
      "[38]\tvalid_0's tweedie: 440.602\n",
      "[39]\tvalid_0's tweedie: 440.589\n",
      "[40]\tvalid_0's tweedie: 440.581\n",
      "[41]\tvalid_0's tweedie: 440.573\n",
      "[42]\tvalid_0's tweedie: 440.566\n",
      "[43]\tvalid_0's tweedie: 440.549\n",
      "[44]\tvalid_0's tweedie: 440.532\n",
      "[45]\tvalid_0's tweedie: 440.521\n",
      "[46]\tvalid_0's tweedie: 440.516\n",
      "[47]\tvalid_0's tweedie: 440.505\n",
      "[48]\tvalid_0's tweedie: 440.502\n",
      "[49]\tvalid_0's tweedie: 440.498\n",
      "[50]\tvalid_0's tweedie: 440.496\n",
      "[51]\tvalid_0's tweedie: 440.491\n",
      "[52]\tvalid_0's tweedie: 440.488\n",
      "[53]\tvalid_0's tweedie: 440.484\n",
      "[54]\tvalid_0's tweedie: 440.476\n",
      "[55]\tvalid_0's tweedie: 440.475\n",
      "[56]\tvalid_0's tweedie: 440.473\n",
      "[57]\tvalid_0's tweedie: 440.464\n",
      "[58]\tvalid_0's tweedie: 440.463\n",
      "[59]\tvalid_0's tweedie: 440.462\n",
      "[60]\tvalid_0's tweedie: 440.461\n",
      "[61]\tvalid_0's tweedie: 440.461\n",
      "[62]\tvalid_0's tweedie: 440.459\n",
      "[63]\tvalid_0's tweedie: 440.458\n",
      "[64]\tvalid_0's tweedie: 440.457\n",
      "[65]\tvalid_0's tweedie: 440.455\n",
      "[66]\tvalid_0's tweedie: 440.452\n",
      "[67]\tvalid_0's tweedie: 440.451\n",
      "[68]\tvalid_0's tweedie: 440.448\n",
      "[69]\tvalid_0's tweedie: 440.447\n",
      "[70]\tvalid_0's tweedie: 440.444\n",
      "[71]\tvalid_0's tweedie: 440.444\n",
      "[72]\tvalid_0's tweedie: 440.44\n",
      "[73]\tvalid_0's tweedie: 440.434\n",
      "[74]\tvalid_0's tweedie: 440.43\n",
      "[75]\tvalid_0's tweedie: 440.43\n",
      "[76]\tvalid_0's tweedie: 440.424\n",
      "[77]\tvalid_0's tweedie: 440.424\n",
      "[78]\tvalid_0's tweedie: 440.423\n",
      "[79]\tvalid_0's tweedie: 440.423\n",
      "[80]\tvalid_0's tweedie: 440.42\n",
      "[81]\tvalid_0's tweedie: 440.419\n",
      "[82]\tvalid_0's tweedie: 440.417\n",
      "[83]\tvalid_0's tweedie: 440.414\n",
      "[84]\tvalid_0's tweedie: 440.414\n",
      "[85]\tvalid_0's tweedie: 440.413\n",
      "[86]\tvalid_0's tweedie: 440.413\n",
      "[87]\tvalid_0's tweedie: 440.411\n",
      "[88]\tvalid_0's tweedie: 440.412\n",
      "[89]\tvalid_0's tweedie: 440.411\n",
      "[90]\tvalid_0's tweedie: 440.41\n",
      "[91]\tvalid_0's tweedie: 440.409\n",
      "[92]\tvalid_0's tweedie: 440.408\n",
      "[93]\tvalid_0's tweedie: 440.406\n",
      "[94]\tvalid_0's tweedie: 440.406\n",
      "[95]\tvalid_0's tweedie: 440.405\n",
      "[96]\tvalid_0's tweedie: 440.405\n",
      "[97]\tvalid_0's tweedie: 440.405\n",
      "[98]\tvalid_0's tweedie: 440.405\n",
      "[99]\tvalid_0's tweedie: 440.405\n",
      "[100]\tvalid_0's tweedie: 440.405\n",
      "[101]\tvalid_0's tweedie: 440.404\n",
      "[102]\tvalid_0's tweedie: 440.398\n",
      "[103]\tvalid_0's tweedie: 440.398\n",
      "[104]\tvalid_0's tweedie: 440.397\n",
      "[105]\tvalid_0's tweedie: 440.397\n",
      "[106]\tvalid_0's tweedie: 440.396\n",
      "[107]\tvalid_0's tweedie: 440.396\n",
      "[108]\tvalid_0's tweedie: 440.396\n",
      "[109]\tvalid_0's tweedie: 440.396\n",
      "[110]\tvalid_0's tweedie: 440.396\n",
      "[111]\tvalid_0's tweedie: 440.395\n",
      "[112]\tvalid_0's tweedie: 440.395\n",
      "[113]\tvalid_0's tweedie: 440.393\n",
      "[114]\tvalid_0's tweedie: 440.393\n",
      "[115]\tvalid_0's tweedie: 440.393\n",
      "[116]\tvalid_0's tweedie: 440.393\n",
      "[117]\tvalid_0's tweedie: 440.393\n",
      "[118]\tvalid_0's tweedie: 440.392\n",
      "[119]\tvalid_0's tweedie: 440.39\n",
      "[120]\tvalid_0's tweedie: 440.391\n",
      "[121]\tvalid_0's tweedie: 440.391\n",
      "[122]\tvalid_0's tweedie: 440.391\n",
      "[123]\tvalid_0's tweedie: 440.391\n",
      "[124]\tvalid_0's tweedie: 440.391\n",
      "[125]\tvalid_0's tweedie: 440.391\n",
      "[126]\tvalid_0's tweedie: 440.39\n",
      "[127]\tvalid_0's tweedie: 440.389\n",
      "[128]\tvalid_0's tweedie: 440.39\n",
      "[129]\tvalid_0's tweedie: 440.388\n",
      "[130]\tvalid_0's tweedie: 440.388\n",
      "[131]\tvalid_0's tweedie: 440.387\n",
      "[132]\tvalid_0's tweedie: 440.387\n",
      "[133]\tvalid_0's tweedie: 440.389\n",
      "[134]\tvalid_0's tweedie: 440.387\n",
      "[135]\tvalid_0's tweedie: 440.385\n",
      "[136]\tvalid_0's tweedie: 440.385\n",
      "[137]\tvalid_0's tweedie: 440.385\n",
      "[138]\tvalid_0's tweedie: 440.382\n",
      "[139]\tvalid_0's tweedie: 440.382\n",
      "[140]\tvalid_0's tweedie: 440.382\n",
      "[141]\tvalid_0's tweedie: 440.382\n",
      "[142]\tvalid_0's tweedie: 440.381\n",
      "[143]\tvalid_0's tweedie: 440.38\n",
      "[144]\tvalid_0's tweedie: 440.38\n",
      "[145]\tvalid_0's tweedie: 440.38\n",
      "[146]\tvalid_0's tweedie: 440.385\n",
      "[147]\tvalid_0's tweedie: 440.386\n",
      "[148]\tvalid_0's tweedie: 440.387\n",
      "[149]\tvalid_0's tweedie: 440.386\n",
      "[150]\tvalid_0's tweedie: 440.386\n",
      "[151]\tvalid_0's tweedie: 440.386\n",
      "[152]\tvalid_0's tweedie: 440.384\n",
      "[153]\tvalid_0's tweedie: 440.384\n",
      "[154]\tvalid_0's tweedie: 440.381\n",
      "[155]\tvalid_0's tweedie: 440.38\n",
      "[156]\tvalid_0's tweedie: 440.379\n",
      "[157]\tvalid_0's tweedie: 440.379\n",
      "[158]\tvalid_0's tweedie: 440.379\n",
      "[159]\tvalid_0's tweedie: 440.379\n",
      "[160]\tvalid_0's tweedie: 440.379\n",
      "[161]\tvalid_0's tweedie: 440.378\n",
      "[162]\tvalid_0's tweedie: 440.378\n",
      "[163]\tvalid_0's tweedie: 440.378\n",
      "[164]\tvalid_0's tweedie: 440.378\n",
      "[165]\tvalid_0's tweedie: 440.379\n",
      "[166]\tvalid_0's tweedie: 440.377\n",
      "[167]\tvalid_0's tweedie: 440.377\n",
      "[168]\tvalid_0's tweedie: 440.377\n",
      "[169]\tvalid_0's tweedie: 440.377\n",
      "[170]\tvalid_0's tweedie: 440.376\n",
      "[171]\tvalid_0's tweedie: 440.377\n",
      "[172]\tvalid_0's tweedie: 440.376\n",
      "[173]\tvalid_0's tweedie: 440.376\n",
      "[174]\tvalid_0's tweedie: 440.376\n",
      "[175]\tvalid_0's tweedie: 440.375\n",
      "[176]\tvalid_0's tweedie: 440.373\n",
      "[177]\tvalid_0's tweedie: 440.373\n",
      "[178]\tvalid_0's tweedie: 440.373\n",
      "[179]\tvalid_0's tweedie: 440.373\n",
      "[180]\tvalid_0's tweedie: 440.372\n",
      "[181]\tvalid_0's tweedie: 440.373\n",
      "[182]\tvalid_0's tweedie: 440.372\n",
      "[183]\tvalid_0's tweedie: 440.371\n",
      "[184]\tvalid_0's tweedie: 440.372\n",
      "[185]\tvalid_0's tweedie: 440.372\n",
      "[186]\tvalid_0's tweedie: 440.372\n",
      "[187]\tvalid_0's tweedie: 440.372\n",
      "[188]\tvalid_0's tweedie: 440.372\n",
      "[189]\tvalid_0's tweedie: 440.372\n",
      "[190]\tvalid_0's tweedie: 440.372\n",
      "[191]\tvalid_0's tweedie: 440.369\n",
      "[192]\tvalid_0's tweedie: 440.369\n",
      "[193]\tvalid_0's tweedie: 440.368\n",
      "[194]\tvalid_0's tweedie: 440.368\n",
      "[195]\tvalid_0's tweedie: 440.368\n",
      "[196]\tvalid_0's tweedie: 440.367\n",
      "[197]\tvalid_0's tweedie: 440.367\n",
      "[198]\tvalid_0's tweedie: 440.367\n",
      "[199]\tvalid_0's tweedie: 440.367\n",
      "[200]\tvalid_0's tweedie: 440.367\n",
      "[201]\tvalid_0's tweedie: 440.367\n",
      "[202]\tvalid_0's tweedie: 440.367\n",
      "[203]\tvalid_0's tweedie: 440.367\n",
      "[204]\tvalid_0's tweedie: 440.367\n",
      "[205]\tvalid_0's tweedie: 440.366\n",
      "[206]\tvalid_0's tweedie: 440.366\n",
      "[207]\tvalid_0's tweedie: 440.367\n",
      "[208]\tvalid_0's tweedie: 440.366\n",
      "[209]\tvalid_0's tweedie: 440.366\n",
      "[210]\tvalid_0's tweedie: 440.365\n",
      "[211]\tvalid_0's tweedie: 440.366\n",
      "[212]\tvalid_0's tweedie: 440.365\n",
      "[213]\tvalid_0's tweedie: 440.365\n",
      "[214]\tvalid_0's tweedie: 440.365\n",
      "[215]\tvalid_0's tweedie: 440.366\n",
      "[216]\tvalid_0's tweedie: 440.366\n",
      "[217]\tvalid_0's tweedie: 440.366\n",
      "[218]\tvalid_0's tweedie: 440.366\n",
      "[219]\tvalid_0's tweedie: 440.366\n",
      "[220]\tvalid_0's tweedie: 440.366\n",
      "[221]\tvalid_0's tweedie: 440.366\n",
      "[222]\tvalid_0's tweedie: 440.366\n",
      "[223]\tvalid_0's tweedie: 440.365\n",
      "[224]\tvalid_0's tweedie: 440.366\n",
      "[225]\tvalid_0's tweedie: 440.365\n",
      "[226]\tvalid_0's tweedie: 440.366\n",
      "[227]\tvalid_0's tweedie: 440.366\n",
      "[228]\tvalid_0's tweedie: 440.365\n",
      "[229]\tvalid_0's tweedie: 440.366\n",
      "[230]\tvalid_0's tweedie: 440.366\n",
      "[231]\tvalid_0's tweedie: 440.367\n",
      "[232]\tvalid_0's tweedie: 440.366\n",
      "[233]\tvalid_0's tweedie: 440.366\n",
      "[234]\tvalid_0's tweedie: 440.366\n",
      "[235]\tvalid_0's tweedie: 440.366\n",
      "[236]\tvalid_0's tweedie: 440.366\n",
      "[237]\tvalid_0's tweedie: 440.366\n",
      "[238]\tvalid_0's tweedie: 440.366\n",
      "[239]\tvalid_0's tweedie: 440.365\n",
      "[240]\tvalid_0's tweedie: 440.366\n",
      "[241]\tvalid_0's tweedie: 440.366\n",
      "[242]\tvalid_0's tweedie: 440.366\n",
      "[243]\tvalid_0's tweedie: 440.366\n",
      "[244]\tvalid_0's tweedie: 440.367\n",
      "[245]\tvalid_0's tweedie: 440.366\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's tweedie: 440.365\n",
      "Training model for level 4 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 5589, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344500\n",
      "[1]\tvalid_0's tweedie: 471.234\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 466.013\n",
      "[3]\tvalid_0's tweedie: 461.728\n",
      "[4]\tvalid_0's tweedie: 458.104\n",
      "[5]\tvalid_0's tweedie: 455.212\n",
      "[6]\tvalid_0's tweedie: 452.807\n",
      "[7]\tvalid_0's tweedie: 450.706\n",
      "[8]\tvalid_0's tweedie: 449.037\n",
      "[9]\tvalid_0's tweedie: 447.687\n",
      "[10]\tvalid_0's tweedie: 446.528\n",
      "[11]\tvalid_0's tweedie: 445.545\n",
      "[12]\tvalid_0's tweedie: 444.806\n",
      "[13]\tvalid_0's tweedie: 444.122\n",
      "[14]\tvalid_0's tweedie: 443.572\n",
      "[15]\tvalid_0's tweedie: 443.139\n",
      "[16]\tvalid_0's tweedie: 442.764\n",
      "[17]\tvalid_0's tweedie: 442.47\n",
      "[18]\tvalid_0's tweedie: 442.18\n",
      "[19]\tvalid_0's tweedie: 441.962\n",
      "[20]\tvalid_0's tweedie: 441.786\n",
      "[21]\tvalid_0's tweedie: 441.635\n",
      "[22]\tvalid_0's tweedie: 441.532\n",
      "[23]\tvalid_0's tweedie: 441.357\n",
      "[24]\tvalid_0's tweedie: 441.272\n",
      "[25]\tvalid_0's tweedie: 441.138\n",
      "[26]\tvalid_0's tweedie: 441.067\n",
      "[27]\tvalid_0's tweedie: 441.006\n",
      "[28]\tvalid_0's tweedie: 440.967\n",
      "[29]\tvalid_0's tweedie: 440.915\n",
      "[30]\tvalid_0's tweedie: 440.877\n",
      "[31]\tvalid_0's tweedie: 440.848\n",
      "[32]\tvalid_0's tweedie: 440.786\n",
      "[33]\tvalid_0's tweedie: 440.755\n",
      "[34]\tvalid_0's tweedie: 440.707\n",
      "[35]\tvalid_0's tweedie: 440.667\n",
      "[36]\tvalid_0's tweedie: 440.65\n",
      "[37]\tvalid_0's tweedie: 440.62\n",
      "[38]\tvalid_0's tweedie: 440.604\n",
      "[39]\tvalid_0's tweedie: 440.593\n",
      "[40]\tvalid_0's tweedie: 440.572\n",
      "[41]\tvalid_0's tweedie: 440.561\n",
      "[42]\tvalid_0's tweedie: 440.543\n",
      "[43]\tvalid_0's tweedie: 440.524\n",
      "[44]\tvalid_0's tweedie: 440.521\n",
      "[45]\tvalid_0's tweedie: 440.517\n",
      "[46]\tvalid_0's tweedie: 440.511\n",
      "[47]\tvalid_0's tweedie: 440.516\n",
      "[48]\tvalid_0's tweedie: 440.503\n",
      "[49]\tvalid_0's tweedie: 440.505\n",
      "[50]\tvalid_0's tweedie: 440.501\n",
      "[51]\tvalid_0's tweedie: 440.49\n",
      "[52]\tvalid_0's tweedie: 440.489\n",
      "[53]\tvalid_0's tweedie: 440.482\n",
      "[54]\tvalid_0's tweedie: 440.481\n",
      "[55]\tvalid_0's tweedie: 440.481\n",
      "[56]\tvalid_0's tweedie: 440.476\n",
      "[57]\tvalid_0's tweedie: 440.475\n",
      "[58]\tvalid_0's tweedie: 440.473\n",
      "[59]\tvalid_0's tweedie: 440.466\n",
      "[60]\tvalid_0's tweedie: 440.465\n",
      "[61]\tvalid_0's tweedie: 440.463\n",
      "[62]\tvalid_0's tweedie: 440.461\n",
      "[63]\tvalid_0's tweedie: 440.461\n",
      "[64]\tvalid_0's tweedie: 440.458\n",
      "[65]\tvalid_0's tweedie: 440.455\n",
      "[66]\tvalid_0's tweedie: 440.454\n",
      "[67]\tvalid_0's tweedie: 440.452\n",
      "[68]\tvalid_0's tweedie: 440.448\n",
      "[69]\tvalid_0's tweedie: 440.443\n",
      "[70]\tvalid_0's tweedie: 440.442\n",
      "[71]\tvalid_0's tweedie: 440.441\n",
      "[72]\tvalid_0's tweedie: 440.442\n",
      "[73]\tvalid_0's tweedie: 440.441\n",
      "[74]\tvalid_0's tweedie: 440.439\n",
      "[75]\tvalid_0's tweedie: 440.437\n",
      "[76]\tvalid_0's tweedie: 440.436\n",
      "[77]\tvalid_0's tweedie: 440.433\n",
      "[78]\tvalid_0's tweedie: 440.431\n",
      "[79]\tvalid_0's tweedie: 440.431\n",
      "[80]\tvalid_0's tweedie: 440.431\n",
      "[81]\tvalid_0's tweedie: 440.432\n",
      "[82]\tvalid_0's tweedie: 440.432\n",
      "[83]\tvalid_0's tweedie: 440.431\n",
      "[84]\tvalid_0's tweedie: 440.431\n",
      "[85]\tvalid_0's tweedie: 440.427\n",
      "[86]\tvalid_0's tweedie: 440.427\n",
      "[87]\tvalid_0's tweedie: 440.428\n",
      "[88]\tvalid_0's tweedie: 440.428\n",
      "[89]\tvalid_0's tweedie: 440.428\n",
      "[90]\tvalid_0's tweedie: 440.427\n",
      "[91]\tvalid_0's tweedie: 440.427\n",
      "[92]\tvalid_0's tweedie: 440.427\n",
      "[93]\tvalid_0's tweedie: 440.426\n",
      "[94]\tvalid_0's tweedie: 440.426\n",
      "[95]\tvalid_0's tweedie: 440.425\n",
      "[96]\tvalid_0's tweedie: 440.424\n",
      "[97]\tvalid_0's tweedie: 440.423\n",
      "[98]\tvalid_0's tweedie: 440.423\n",
      "[99]\tvalid_0's tweedie: 440.423\n",
      "[100]\tvalid_0's tweedie: 440.423\n",
      "[101]\tvalid_0's tweedie: 440.421\n",
      "[102]\tvalid_0's tweedie: 440.421\n",
      "[103]\tvalid_0's tweedie: 440.421\n",
      "[104]\tvalid_0's tweedie: 440.421\n",
      "[105]\tvalid_0's tweedie: 440.421\n",
      "[106]\tvalid_0's tweedie: 440.42\n",
      "[107]\tvalid_0's tweedie: 440.416\n",
      "[108]\tvalid_0's tweedie: 440.417\n",
      "[109]\tvalid_0's tweedie: 440.417\n",
      "[110]\tvalid_0's tweedie: 440.416\n",
      "[111]\tvalid_0's tweedie: 440.417\n",
      "[112]\tvalid_0's tweedie: 440.416\n",
      "[113]\tvalid_0's tweedie: 440.416\n",
      "[114]\tvalid_0's tweedie: 440.415\n",
      "[115]\tvalid_0's tweedie: 440.411\n",
      "[116]\tvalid_0's tweedie: 440.411\n",
      "[117]\tvalid_0's tweedie: 440.411\n",
      "[118]\tvalid_0's tweedie: 440.411\n",
      "[119]\tvalid_0's tweedie: 440.411\n",
      "[120]\tvalid_0's tweedie: 440.411\n",
      "[121]\tvalid_0's tweedie: 440.412\n",
      "[122]\tvalid_0's tweedie: 440.411\n",
      "[123]\tvalid_0's tweedie: 440.41\n",
      "[124]\tvalid_0's tweedie: 440.41\n",
      "[125]\tvalid_0's tweedie: 440.408\n",
      "[126]\tvalid_0's tweedie: 440.407\n",
      "[127]\tvalid_0's tweedie: 440.407\n",
      "[128]\tvalid_0's tweedie: 440.407\n",
      "[129]\tvalid_0's tweedie: 440.407\n",
      "[130]\tvalid_0's tweedie: 440.407\n",
      "[131]\tvalid_0's tweedie: 440.407\n",
      "[132]\tvalid_0's tweedie: 440.407\n",
      "[133]\tvalid_0's tweedie: 440.408\n",
      "[134]\tvalid_0's tweedie: 440.408\n",
      "[135]\tvalid_0's tweedie: 440.407\n",
      "[136]\tvalid_0's tweedie: 440.407\n",
      "[137]\tvalid_0's tweedie: 440.405\n",
      "[138]\tvalid_0's tweedie: 440.404\n",
      "[139]\tvalid_0's tweedie: 440.404\n",
      "[140]\tvalid_0's tweedie: 440.404\n",
      "[141]\tvalid_0's tweedie: 440.404\n",
      "[142]\tvalid_0's tweedie: 440.403\n",
      "[143]\tvalid_0's tweedie: 440.403\n",
      "[144]\tvalid_0's tweedie: 440.403\n",
      "[145]\tvalid_0's tweedie: 440.403\n",
      "[146]\tvalid_0's tweedie: 440.402\n",
      "[147]\tvalid_0's tweedie: 440.402\n",
      "[148]\tvalid_0's tweedie: 440.402\n",
      "[149]\tvalid_0's tweedie: 440.402\n",
      "[150]\tvalid_0's tweedie: 440.401\n",
      "[151]\tvalid_0's tweedie: 440.401\n",
      "[152]\tvalid_0's tweedie: 440.401\n",
      "[153]\tvalid_0's tweedie: 440.4\n",
      "[154]\tvalid_0's tweedie: 440.4\n",
      "[155]\tvalid_0's tweedie: 440.403\n",
      "[156]\tvalid_0's tweedie: 440.401\n",
      "[157]\tvalid_0's tweedie: 440.401\n",
      "[158]\tvalid_0's tweedie: 440.399\n",
      "[159]\tvalid_0's tweedie: 440.399\n",
      "[160]\tvalid_0's tweedie: 440.4\n",
      "[161]\tvalid_0's tweedie: 440.4\n",
      "[162]\tvalid_0's tweedie: 440.399\n",
      "[163]\tvalid_0's tweedie: 440.399\n",
      "[164]\tvalid_0's tweedie: 440.399\n",
      "[165]\tvalid_0's tweedie: 440.395\n",
      "[166]\tvalid_0's tweedie: 440.395\n",
      "[167]\tvalid_0's tweedie: 440.394\n",
      "[168]\tvalid_0's tweedie: 440.394\n",
      "[169]\tvalid_0's tweedie: 440.393\n",
      "[170]\tvalid_0's tweedie: 440.393\n",
      "[171]\tvalid_0's tweedie: 440.393\n",
      "[172]\tvalid_0's tweedie: 440.393\n",
      "[173]\tvalid_0's tweedie: 440.393\n",
      "[174]\tvalid_0's tweedie: 440.392\n",
      "[175]\tvalid_0's tweedie: 440.393\n",
      "[176]\tvalid_0's tweedie: 440.392\n",
      "[177]\tvalid_0's tweedie: 440.393\n",
      "[178]\tvalid_0's tweedie: 440.391\n",
      "[179]\tvalid_0's tweedie: 440.389\n",
      "[180]\tvalid_0's tweedie: 440.388\n",
      "[181]\tvalid_0's tweedie: 440.389\n",
      "[182]\tvalid_0's tweedie: 440.388\n",
      "[183]\tvalid_0's tweedie: 440.388\n",
      "[184]\tvalid_0's tweedie: 440.388\n",
      "[185]\tvalid_0's tweedie: 440.388\n",
      "[186]\tvalid_0's tweedie: 440.388\n",
      "[187]\tvalid_0's tweedie: 440.388\n",
      "[188]\tvalid_0's tweedie: 440.388\n",
      "[189]\tvalid_0's tweedie: 440.388\n",
      "[190]\tvalid_0's tweedie: 440.388\n",
      "[191]\tvalid_0's tweedie: 440.388\n",
      "[192]\tvalid_0's tweedie: 440.387\n",
      "[193]\tvalid_0's tweedie: 440.385\n",
      "[194]\tvalid_0's tweedie: 440.385\n",
      "[195]\tvalid_0's tweedie: 440.384\n",
      "[196]\tvalid_0's tweedie: 440.384\n",
      "[197]\tvalid_0's tweedie: 440.384\n",
      "[198]\tvalid_0's tweedie: 440.384\n",
      "[199]\tvalid_0's tweedie: 440.384\n",
      "[200]\tvalid_0's tweedie: 440.383\n",
      "[201]\tvalid_0's tweedie: 440.383\n",
      "[202]\tvalid_0's tweedie: 440.383\n",
      "[203]\tvalid_0's tweedie: 440.383\n",
      "[204]\tvalid_0's tweedie: 440.382\n",
      "[205]\tvalid_0's tweedie: 440.382\n",
      "[206]\tvalid_0's tweedie: 440.381\n",
      "[207]\tvalid_0's tweedie: 440.38\n",
      "[208]\tvalid_0's tweedie: 440.38\n",
      "[209]\tvalid_0's tweedie: 440.379\n",
      "[210]\tvalid_0's tweedie: 440.379\n",
      "[211]\tvalid_0's tweedie: 440.379\n",
      "[212]\tvalid_0's tweedie: 440.379\n",
      "[213]\tvalid_0's tweedie: 440.38\n",
      "[214]\tvalid_0's tweedie: 440.379\n",
      "[215]\tvalid_0's tweedie: 440.379\n",
      "[216]\tvalid_0's tweedie: 440.379\n",
      "[217]\tvalid_0's tweedie: 440.379\n",
      "[218]\tvalid_0's tweedie: 440.379\n",
      "[219]\tvalid_0's tweedie: 440.378\n",
      "[220]\tvalid_0's tweedie: 440.379\n",
      "[221]\tvalid_0's tweedie: 440.38\n",
      "[222]\tvalid_0's tweedie: 440.38\n",
      "[223]\tvalid_0's tweedie: 440.379\n",
      "[224]\tvalid_0's tweedie: 440.379\n",
      "[225]\tvalid_0's tweedie: 440.379\n",
      "[226]\tvalid_0's tweedie: 440.379\n",
      "[227]\tvalid_0's tweedie: 440.38\n",
      "[228]\tvalid_0's tweedie: 440.381\n",
      "[229]\tvalid_0's tweedie: 440.381\n",
      "[230]\tvalid_0's tweedie: 440.381\n",
      "[231]\tvalid_0's tweedie: 440.381\n",
      "[232]\tvalid_0's tweedie: 440.381\n",
      "[233]\tvalid_0's tweedie: 440.381\n",
      "[234]\tvalid_0's tweedie: 440.381\n",
      "[235]\tvalid_0's tweedie: 440.381\n",
      "[236]\tvalid_0's tweedie: 440.381\n",
      "[237]\tvalid_0's tweedie: 440.38\n",
      "[238]\tvalid_0's tweedie: 440.38\n",
      "[239]\tvalid_0's tweedie: 440.38\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's tweedie: 440.378\n",
      "Training model for level 4 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 5586, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344578\n",
      "[1]\tvalid_0's tweedie: 471.223\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.993\n",
      "[3]\tvalid_0's tweedie: 461.722\n",
      "[4]\tvalid_0's tweedie: 458.161\n",
      "[5]\tvalid_0's tweedie: 455.143\n",
      "[6]\tvalid_0's tweedie: 452.647\n",
      "[7]\tvalid_0's tweedie: 450.703\n",
      "[8]\tvalid_0's tweedie: 448.94\n",
      "[9]\tvalid_0's tweedie: 447.602\n",
      "[10]\tvalid_0's tweedie: 446.491\n",
      "[11]\tvalid_0's tweedie: 445.569\n",
      "[12]\tvalid_0's tweedie: 444.799\n",
      "[13]\tvalid_0's tweedie: 444.135\n",
      "[14]\tvalid_0's tweedie: 443.617\n",
      "[15]\tvalid_0's tweedie: 443.165\n",
      "[16]\tvalid_0's tweedie: 442.836\n",
      "[17]\tvalid_0's tweedie: 442.537\n",
      "[18]\tvalid_0's tweedie: 442.266\n",
      "[19]\tvalid_0's tweedie: 442.014\n",
      "[20]\tvalid_0's tweedie: 441.86\n",
      "[21]\tvalid_0's tweedie: 441.692\n",
      "[22]\tvalid_0's tweedie: 441.559\n",
      "[23]\tvalid_0's tweedie: 441.384\n",
      "[24]\tvalid_0's tweedie: 441.286\n",
      "[25]\tvalid_0's tweedie: 441.202\n",
      "[26]\tvalid_0's tweedie: 441.134\n",
      "[27]\tvalid_0's tweedie: 441.072\n",
      "[28]\tvalid_0's tweedie: 441.023\n",
      "[29]\tvalid_0's tweedie: 440.973\n",
      "[30]\tvalid_0's tweedie: 440.922\n",
      "[31]\tvalid_0's tweedie: 440.848\n",
      "[32]\tvalid_0's tweedie: 440.786\n",
      "[33]\tvalid_0's tweedie: 440.732\n",
      "[34]\tvalid_0's tweedie: 440.685\n",
      "[35]\tvalid_0's tweedie: 440.643\n",
      "[36]\tvalid_0's tweedie: 440.615\n",
      "[37]\tvalid_0's tweedie: 440.592\n",
      "[38]\tvalid_0's tweedie: 440.579\n",
      "[39]\tvalid_0's tweedie: 440.571\n",
      "[40]\tvalid_0's tweedie: 440.572\n",
      "[41]\tvalid_0's tweedie: 440.552\n",
      "[42]\tvalid_0's tweedie: 440.544\n",
      "[43]\tvalid_0's tweedie: 440.538\n",
      "[44]\tvalid_0's tweedie: 440.533\n",
      "[45]\tvalid_0's tweedie: 440.521\n",
      "[46]\tvalid_0's tweedie: 440.511\n",
      "[47]\tvalid_0's tweedie: 440.506\n",
      "[48]\tvalid_0's tweedie: 440.505\n",
      "[49]\tvalid_0's tweedie: 440.493\n",
      "[50]\tvalid_0's tweedie: 440.483\n",
      "[51]\tvalid_0's tweedie: 440.482\n",
      "[52]\tvalid_0's tweedie: 440.474\n",
      "[53]\tvalid_0's tweedie: 440.471\n",
      "[54]\tvalid_0's tweedie: 440.469\n",
      "[55]\tvalid_0's tweedie: 440.465\n",
      "[56]\tvalid_0's tweedie: 440.464\n",
      "[57]\tvalid_0's tweedie: 440.463\n",
      "[58]\tvalid_0's tweedie: 440.462\n",
      "[59]\tvalid_0's tweedie: 440.459\n",
      "[60]\tvalid_0's tweedie: 440.462\n",
      "[61]\tvalid_0's tweedie: 440.461\n",
      "[62]\tvalid_0's tweedie: 440.459\n",
      "[63]\tvalid_0's tweedie: 440.456\n",
      "[64]\tvalid_0's tweedie: 440.452\n",
      "[65]\tvalid_0's tweedie: 440.452\n",
      "[66]\tvalid_0's tweedie: 440.451\n",
      "[67]\tvalid_0's tweedie: 440.443\n",
      "[68]\tvalid_0's tweedie: 440.442\n",
      "[69]\tvalid_0's tweedie: 440.442\n",
      "[70]\tvalid_0's tweedie: 440.442\n",
      "[71]\tvalid_0's tweedie: 440.434\n",
      "[72]\tvalid_0's tweedie: 440.435\n",
      "[73]\tvalid_0's tweedie: 440.432\n",
      "[74]\tvalid_0's tweedie: 440.431\n",
      "[75]\tvalid_0's tweedie: 440.431\n",
      "[76]\tvalid_0's tweedie: 440.43\n",
      "[77]\tvalid_0's tweedie: 440.43\n",
      "[78]\tvalid_0's tweedie: 440.424\n",
      "[79]\tvalid_0's tweedie: 440.424\n",
      "[80]\tvalid_0's tweedie: 440.424\n",
      "[81]\tvalid_0's tweedie: 440.422\n",
      "[82]\tvalid_0's tweedie: 440.422\n",
      "[83]\tvalid_0's tweedie: 440.419\n",
      "[84]\tvalid_0's tweedie: 440.419\n",
      "[85]\tvalid_0's tweedie: 440.419\n",
      "[86]\tvalid_0's tweedie: 440.418\n",
      "[87]\tvalid_0's tweedie: 440.418\n",
      "[88]\tvalid_0's tweedie: 440.419\n",
      "[89]\tvalid_0's tweedie: 440.418\n",
      "[90]\tvalid_0's tweedie: 440.418\n",
      "[91]\tvalid_0's tweedie: 440.418\n",
      "[92]\tvalid_0's tweedie: 440.417\n",
      "[93]\tvalid_0's tweedie: 440.415\n",
      "[94]\tvalid_0's tweedie: 440.416\n",
      "[95]\tvalid_0's tweedie: 440.413\n",
      "[96]\tvalid_0's tweedie: 440.413\n",
      "[97]\tvalid_0's tweedie: 440.413\n",
      "[98]\tvalid_0's tweedie: 440.413\n",
      "[99]\tvalid_0's tweedie: 440.412\n",
      "[100]\tvalid_0's tweedie: 440.412\n",
      "[101]\tvalid_0's tweedie: 440.412\n",
      "[102]\tvalid_0's tweedie: 440.412\n",
      "[103]\tvalid_0's tweedie: 440.408\n",
      "[104]\tvalid_0's tweedie: 440.408\n",
      "[105]\tvalid_0's tweedie: 440.404\n",
      "[106]\tvalid_0's tweedie: 440.403\n",
      "[107]\tvalid_0's tweedie: 440.404\n",
      "[108]\tvalid_0's tweedie: 440.404\n",
      "[109]\tvalid_0's tweedie: 440.404\n",
      "[110]\tvalid_0's tweedie: 440.404\n",
      "[111]\tvalid_0's tweedie: 440.403\n",
      "[112]\tvalid_0's tweedie: 440.403\n",
      "[113]\tvalid_0's tweedie: 440.402\n",
      "[114]\tvalid_0's tweedie: 440.402\n",
      "[115]\tvalid_0's tweedie: 440.402\n",
      "[116]\tvalid_0's tweedie: 440.402\n",
      "[117]\tvalid_0's tweedie: 440.402\n",
      "[118]\tvalid_0's tweedie: 440.401\n",
      "[119]\tvalid_0's tweedie: 440.402\n",
      "[120]\tvalid_0's tweedie: 440.401\n",
      "[121]\tvalid_0's tweedie: 440.401\n",
      "[122]\tvalid_0's tweedie: 440.402\n",
      "[123]\tvalid_0's tweedie: 440.401\n",
      "[124]\tvalid_0's tweedie: 440.401\n",
      "[125]\tvalid_0's tweedie: 440.401\n",
      "[126]\tvalid_0's tweedie: 440.402\n",
      "[127]\tvalid_0's tweedie: 440.4\n",
      "[128]\tvalid_0's tweedie: 440.4\n",
      "[129]\tvalid_0's tweedie: 440.401\n",
      "[130]\tvalid_0's tweedie: 440.4\n",
      "[131]\tvalid_0's tweedie: 440.399\n",
      "[132]\tvalid_0's tweedie: 440.399\n",
      "[133]\tvalid_0's tweedie: 440.399\n",
      "[134]\tvalid_0's tweedie: 440.399\n",
      "[135]\tvalid_0's tweedie: 440.399\n",
      "[136]\tvalid_0's tweedie: 440.399\n",
      "[137]\tvalid_0's tweedie: 440.399\n",
      "[138]\tvalid_0's tweedie: 440.398\n",
      "[139]\tvalid_0's tweedie: 440.398\n",
      "[140]\tvalid_0's tweedie: 440.399\n",
      "[141]\tvalid_0's tweedie: 440.398\n",
      "[142]\tvalid_0's tweedie: 440.398\n",
      "[143]\tvalid_0's tweedie: 440.399\n",
      "[144]\tvalid_0's tweedie: 440.398\n",
      "[145]\tvalid_0's tweedie: 440.397\n",
      "[146]\tvalid_0's tweedie: 440.397\n",
      "[147]\tvalid_0's tweedie: 440.396\n",
      "[148]\tvalid_0's tweedie: 440.398\n",
      "[149]\tvalid_0's tweedie: 440.396\n",
      "[150]\tvalid_0's tweedie: 440.396\n",
      "[151]\tvalid_0's tweedie: 440.397\n",
      "[152]\tvalid_0's tweedie: 440.396\n",
      "[153]\tvalid_0's tweedie: 440.396\n",
      "[154]\tvalid_0's tweedie: 440.395\n",
      "[155]\tvalid_0's tweedie: 440.395\n",
      "[156]\tvalid_0's tweedie: 440.395\n",
      "[157]\tvalid_0's tweedie: 440.395\n",
      "[158]\tvalid_0's tweedie: 440.395\n",
      "[159]\tvalid_0's tweedie: 440.395\n",
      "[160]\tvalid_0's tweedie: 440.395\n",
      "[161]\tvalid_0's tweedie: 440.395\n",
      "[162]\tvalid_0's tweedie: 440.395\n",
      "[163]\tvalid_0's tweedie: 440.395\n",
      "[164]\tvalid_0's tweedie: 440.395\n",
      "[165]\tvalid_0's tweedie: 440.39\n",
      "[166]\tvalid_0's tweedie: 440.39\n",
      "[167]\tvalid_0's tweedie: 440.39\n",
      "[168]\tvalid_0's tweedie: 440.389\n",
      "[169]\tvalid_0's tweedie: 440.389\n",
      "[170]\tvalid_0's tweedie: 440.389\n",
      "[171]\tvalid_0's tweedie: 440.389\n",
      "[172]\tvalid_0's tweedie: 440.389\n",
      "[173]\tvalid_0's tweedie: 440.389\n",
      "[174]\tvalid_0's tweedie: 440.389\n",
      "[175]\tvalid_0's tweedie: 440.389\n",
      "[176]\tvalid_0's tweedie: 440.389\n",
      "[177]\tvalid_0's tweedie: 440.389\n",
      "[178]\tvalid_0's tweedie: 440.389\n",
      "[179]\tvalid_0's tweedie: 440.389\n",
      "[180]\tvalid_0's tweedie: 440.389\n",
      "[181]\tvalid_0's tweedie: 440.389\n",
      "[182]\tvalid_0's tweedie: 440.388\n",
      "[183]\tvalid_0's tweedie: 440.388\n",
      "[184]\tvalid_0's tweedie: 440.389\n",
      "[185]\tvalid_0's tweedie: 440.389\n",
      "[186]\tvalid_0's tweedie: 440.388\n",
      "[187]\tvalid_0's tweedie: 440.388\n",
      "[188]\tvalid_0's tweedie: 440.387\n",
      "[189]\tvalid_0's tweedie: 440.387\n",
      "[190]\tvalid_0's tweedie: 440.387\n",
      "[191]\tvalid_0's tweedie: 440.386\n",
      "[192]\tvalid_0's tweedie: 440.385\n",
      "[193]\tvalid_0's tweedie: 440.386\n",
      "[194]\tvalid_0's tweedie: 440.389\n",
      "[195]\tvalid_0's tweedie: 440.388\n",
      "[196]\tvalid_0's tweedie: 440.386\n",
      "[197]\tvalid_0's tweedie: 440.386\n",
      "[198]\tvalid_0's tweedie: 440.386\n",
      "[199]\tvalid_0's tweedie: 440.386\n",
      "[200]\tvalid_0's tweedie: 440.386\n",
      "[201]\tvalid_0's tweedie: 440.385\n",
      "[202]\tvalid_0's tweedie: 440.386\n",
      "[203]\tvalid_0's tweedie: 440.385\n",
      "[204]\tvalid_0's tweedie: 440.385\n",
      "[205]\tvalid_0's tweedie: 440.384\n",
      "[206]\tvalid_0's tweedie: 440.384\n",
      "[207]\tvalid_0's tweedie: 440.383\n",
      "[208]\tvalid_0's tweedie: 440.383\n",
      "[209]\tvalid_0's tweedie: 440.382\n",
      "[210]\tvalid_0's tweedie: 440.382\n",
      "[211]\tvalid_0's tweedie: 440.381\n",
      "[212]\tvalid_0's tweedie: 440.381\n",
      "[213]\tvalid_0's tweedie: 440.381\n",
      "[214]\tvalid_0's tweedie: 440.38\n",
      "[215]\tvalid_0's tweedie: 440.38\n",
      "[216]\tvalid_0's tweedie: 440.38\n",
      "[217]\tvalid_0's tweedie: 440.38\n",
      "[218]\tvalid_0's tweedie: 440.381\n",
      "[219]\tvalid_0's tweedie: 440.38\n",
      "[220]\tvalid_0's tweedie: 440.38\n",
      "[221]\tvalid_0's tweedie: 440.379\n",
      "[222]\tvalid_0's tweedie: 440.378\n",
      "[223]\tvalid_0's tweedie: 440.378\n",
      "[224]\tvalid_0's tweedie: 440.378\n",
      "[225]\tvalid_0's tweedie: 440.378\n",
      "[226]\tvalid_0's tweedie: 440.379\n",
      "[227]\tvalid_0's tweedie: 440.379\n",
      "[228]\tvalid_0's tweedie: 440.383\n",
      "[229]\tvalid_0's tweedie: 440.382\n",
      "[230]\tvalid_0's tweedie: 440.382\n",
      "[231]\tvalid_0's tweedie: 440.382\n",
      "[232]\tvalid_0's tweedie: 440.382\n",
      "[233]\tvalid_0's tweedie: 440.382\n",
      "[234]\tvalid_0's tweedie: 440.382\n",
      "[235]\tvalid_0's tweedie: 440.381\n",
      "[236]\tvalid_0's tweedie: 440.381\n",
      "[237]\tvalid_0's tweedie: 440.381\n",
      "[238]\tvalid_0's tweedie: 440.38\n",
      "[239]\tvalid_0's tweedie: 440.38\n",
      "[240]\tvalid_0's tweedie: 440.38\n",
      "[241]\tvalid_0's tweedie: 440.381\n",
      "[242]\tvalid_0's tweedie: 440.381\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's tweedie: 440.378\n",
      "Training model for level 4 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 5583, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344740\n",
      "[1]\tvalid_0's tweedie: 471.276\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 466.073\n",
      "[3]\tvalid_0's tweedie: 461.866\n",
      "[4]\tvalid_0's tweedie: 458.304\n",
      "[5]\tvalid_0's tweedie: 455.343\n",
      "[6]\tvalid_0's tweedie: 452.799\n",
      "[7]\tvalid_0's tweedie: 450.743\n",
      "[8]\tvalid_0's tweedie: 449.116\n",
      "[9]\tvalid_0's tweedie: 447.785\n",
      "[10]\tvalid_0's tweedie: 446.645\n",
      "[11]\tvalid_0's tweedie: 445.645\n",
      "[12]\tvalid_0's tweedie: 444.876\n",
      "[13]\tvalid_0's tweedie: 444.207\n",
      "[14]\tvalid_0's tweedie: 443.625\n",
      "[15]\tvalid_0's tweedie: 443.188\n",
      "[16]\tvalid_0's tweedie: 442.805\n",
      "[17]\tvalid_0's tweedie: 442.472\n",
      "[18]\tvalid_0's tweedie: 442.223\n",
      "[19]\tvalid_0's tweedie: 441.988\n",
      "[20]\tvalid_0's tweedie: 441.806\n",
      "[21]\tvalid_0's tweedie: 441.667\n",
      "[22]\tvalid_0's tweedie: 441.564\n",
      "[23]\tvalid_0's tweedie: 441.386\n",
      "[24]\tvalid_0's tweedie: 441.245\n",
      "[25]\tvalid_0's tweedie: 441.158\n",
      "[26]\tvalid_0's tweedie: 441.087\n",
      "[27]\tvalid_0's tweedie: 441.033\n",
      "[28]\tvalid_0's tweedie: 440.977\n",
      "[29]\tvalid_0's tweedie: 440.938\n",
      "[30]\tvalid_0's tweedie: 440.896\n",
      "[31]\tvalid_0's tweedie: 440.871\n",
      "[32]\tvalid_0's tweedie: 440.808\n",
      "[33]\tvalid_0's tweedie: 440.757\n",
      "[34]\tvalid_0's tweedie: 440.71\n",
      "[35]\tvalid_0's tweedie: 440.671\n",
      "[36]\tvalid_0's tweedie: 440.66\n",
      "[37]\tvalid_0's tweedie: 440.644\n",
      "[38]\tvalid_0's tweedie: 440.629\n",
      "[39]\tvalid_0's tweedie: 440.618\n",
      "[40]\tvalid_0's tweedie: 440.595\n",
      "[41]\tvalid_0's tweedie: 440.584\n",
      "[42]\tvalid_0's tweedie: 440.577\n",
      "[43]\tvalid_0's tweedie: 440.559\n",
      "[44]\tvalid_0's tweedie: 440.549\n",
      "[45]\tvalid_0's tweedie: 440.545\n",
      "[46]\tvalid_0's tweedie: 440.541\n",
      "[47]\tvalid_0's tweedie: 440.536\n",
      "[48]\tvalid_0's tweedie: 440.529\n",
      "[49]\tvalid_0's tweedie: 440.516\n",
      "[50]\tvalid_0's tweedie: 440.513\n",
      "[51]\tvalid_0's tweedie: 440.522\n",
      "[52]\tvalid_0's tweedie: 440.519\n",
      "[53]\tvalid_0's tweedie: 440.515\n",
      "[54]\tvalid_0's tweedie: 440.505\n",
      "[55]\tvalid_0's tweedie: 440.503\n",
      "[56]\tvalid_0's tweedie: 440.5\n",
      "[57]\tvalid_0's tweedie: 440.496\n",
      "[58]\tvalid_0's tweedie: 440.494\n",
      "[59]\tvalid_0's tweedie: 440.493\n",
      "[60]\tvalid_0's tweedie: 440.493\n",
      "[61]\tvalid_0's tweedie: 440.487\n",
      "[62]\tvalid_0's tweedie: 440.479\n",
      "[63]\tvalid_0's tweedie: 440.474\n",
      "[64]\tvalid_0's tweedie: 440.473\n",
      "[65]\tvalid_0's tweedie: 440.471\n",
      "[66]\tvalid_0's tweedie: 440.471\n",
      "[67]\tvalid_0's tweedie: 440.468\n",
      "[68]\tvalid_0's tweedie: 440.467\n",
      "[69]\tvalid_0's tweedie: 440.464\n",
      "[70]\tvalid_0's tweedie: 440.462\n",
      "[71]\tvalid_0's tweedie: 440.457\n",
      "[72]\tvalid_0's tweedie: 440.456\n",
      "[73]\tvalid_0's tweedie: 440.455\n",
      "[74]\tvalid_0's tweedie: 440.454\n",
      "[75]\tvalid_0's tweedie: 440.449\n",
      "[76]\tvalid_0's tweedie: 440.447\n",
      "[77]\tvalid_0's tweedie: 440.446\n",
      "[78]\tvalid_0's tweedie: 440.446\n",
      "[79]\tvalid_0's tweedie: 440.445\n",
      "[80]\tvalid_0's tweedie: 440.444\n",
      "[81]\tvalid_0's tweedie: 440.443\n",
      "[82]\tvalid_0's tweedie: 440.442\n",
      "[83]\tvalid_0's tweedie: 440.437\n",
      "[84]\tvalid_0's tweedie: 440.436\n",
      "[85]\tvalid_0's tweedie: 440.435\n",
      "[86]\tvalid_0's tweedie: 440.435\n",
      "[87]\tvalid_0's tweedie: 440.433\n",
      "[88]\tvalid_0's tweedie: 440.431\n",
      "[89]\tvalid_0's tweedie: 440.431\n",
      "[90]\tvalid_0's tweedie: 440.431\n",
      "[91]\tvalid_0's tweedie: 440.43\n",
      "[92]\tvalid_0's tweedie: 440.429\n",
      "[93]\tvalid_0's tweedie: 440.427\n",
      "[94]\tvalid_0's tweedie: 440.426\n",
      "[95]\tvalid_0's tweedie: 440.423\n",
      "[96]\tvalid_0's tweedie: 440.423\n",
      "[97]\tvalid_0's tweedie: 440.423\n",
      "[98]\tvalid_0's tweedie: 440.423\n",
      "[99]\tvalid_0's tweedie: 440.422\n",
      "[100]\tvalid_0's tweedie: 440.422\n",
      "[101]\tvalid_0's tweedie: 440.422\n",
      "[102]\tvalid_0's tweedie: 440.421\n",
      "[103]\tvalid_0's tweedie: 440.421\n",
      "[104]\tvalid_0's tweedie: 440.421\n",
      "[105]\tvalid_0's tweedie: 440.421\n",
      "[106]\tvalid_0's tweedie: 440.421\n",
      "[107]\tvalid_0's tweedie: 440.421\n",
      "[108]\tvalid_0's tweedie: 440.421\n",
      "[109]\tvalid_0's tweedie: 440.42\n",
      "[110]\tvalid_0's tweedie: 440.419\n",
      "[111]\tvalid_0's tweedie: 440.419\n",
      "[112]\tvalid_0's tweedie: 440.416\n",
      "[113]\tvalid_0's tweedie: 440.416\n",
      "[114]\tvalid_0's tweedie: 440.416\n",
      "[115]\tvalid_0's tweedie: 440.415\n",
      "[116]\tvalid_0's tweedie: 440.415\n",
      "[117]\tvalid_0's tweedie: 440.415\n",
      "[118]\tvalid_0's tweedie: 440.415\n",
      "[119]\tvalid_0's tweedie: 440.414\n",
      "[120]\tvalid_0's tweedie: 440.413\n",
      "[121]\tvalid_0's tweedie: 440.412\n",
      "[122]\tvalid_0's tweedie: 440.412\n",
      "[123]\tvalid_0's tweedie: 440.412\n",
      "[124]\tvalid_0's tweedie: 440.412\n",
      "[125]\tvalid_0's tweedie: 440.413\n",
      "[126]\tvalid_0's tweedie: 440.413\n",
      "[127]\tvalid_0's tweedie: 440.412\n",
      "[128]\tvalid_0's tweedie: 440.412\n",
      "[129]\tvalid_0's tweedie: 440.413\n",
      "[130]\tvalid_0's tweedie: 440.413\n",
      "[131]\tvalid_0's tweedie: 440.412\n",
      "[132]\tvalid_0's tweedie: 440.412\n",
      "[133]\tvalid_0's tweedie: 440.412\n",
      "[134]\tvalid_0's tweedie: 440.412\n",
      "[135]\tvalid_0's tweedie: 440.412\n",
      "[136]\tvalid_0's tweedie: 440.412\n",
      "[137]\tvalid_0's tweedie: 440.412\n",
      "[138]\tvalid_0's tweedie: 440.412\n",
      "[139]\tvalid_0's tweedie: 440.412\n",
      "[140]\tvalid_0's tweedie: 440.412\n",
      "[141]\tvalid_0's tweedie: 440.409\n",
      "[142]\tvalid_0's tweedie: 440.408\n",
      "[143]\tvalid_0's tweedie: 440.406\n",
      "[144]\tvalid_0's tweedie: 440.405\n",
      "[145]\tvalid_0's tweedie: 440.406\n",
      "[146]\tvalid_0's tweedie: 440.406\n",
      "[147]\tvalid_0's tweedie: 440.406\n",
      "[148]\tvalid_0's tweedie: 440.405\n",
      "[149]\tvalid_0's tweedie: 440.405\n",
      "[150]\tvalid_0's tweedie: 440.405\n",
      "[151]\tvalid_0's tweedie: 440.402\n",
      "[152]\tvalid_0's tweedie: 440.402\n",
      "[153]\tvalid_0's tweedie: 440.401\n",
      "[154]\tvalid_0's tweedie: 440.401\n",
      "[155]\tvalid_0's tweedie: 440.399\n",
      "[156]\tvalid_0's tweedie: 440.399\n",
      "[157]\tvalid_0's tweedie: 440.398\n",
      "[158]\tvalid_0's tweedie: 440.398\n",
      "[159]\tvalid_0's tweedie: 440.398\n",
      "[160]\tvalid_0's tweedie: 440.398\n",
      "[161]\tvalid_0's tweedie: 440.398\n",
      "[162]\tvalid_0's tweedie: 440.397\n",
      "[163]\tvalid_0's tweedie: 440.397\n",
      "[164]\tvalid_0's tweedie: 440.398\n",
      "[165]\tvalid_0's tweedie: 440.396\n",
      "[166]\tvalid_0's tweedie: 440.396\n",
      "[167]\tvalid_0's tweedie: 440.396\n",
      "[168]\tvalid_0's tweedie: 440.397\n",
      "[169]\tvalid_0's tweedie: 440.396\n",
      "[170]\tvalid_0's tweedie: 440.402\n",
      "[171]\tvalid_0's tweedie: 440.403\n",
      "[172]\tvalid_0's tweedie: 440.402\n",
      "[173]\tvalid_0's tweedie: 440.401\n",
      "[174]\tvalid_0's tweedie: 440.4\n",
      "[175]\tvalid_0's tweedie: 440.401\n",
      "[176]\tvalid_0's tweedie: 440.401\n",
      "[177]\tvalid_0's tweedie: 440.401\n",
      "[178]\tvalid_0's tweedie: 440.401\n",
      "[179]\tvalid_0's tweedie: 440.401\n",
      "[180]\tvalid_0's tweedie: 440.401\n",
      "[181]\tvalid_0's tweedie: 440.401\n",
      "[182]\tvalid_0's tweedie: 440.402\n",
      "[183]\tvalid_0's tweedie: 440.402\n",
      "[184]\tvalid_0's tweedie: 440.403\n",
      "[185]\tvalid_0's tweedie: 440.403\n",
      "[186]\tvalid_0's tweedie: 440.402\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's tweedie: 440.396\n",
      "Training model for level 4 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 5580, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.344957\n",
      "[1]\tvalid_0's tweedie: 471.225\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 466.077\n",
      "[3]\tvalid_0's tweedie: 461.839\n",
      "[4]\tvalid_0's tweedie: 458.298\n",
      "[5]\tvalid_0's tweedie: 455.301\n",
      "[6]\tvalid_0's tweedie: 452.812\n",
      "[7]\tvalid_0's tweedie: 450.751\n",
      "[8]\tvalid_0's tweedie: 449.08\n",
      "[9]\tvalid_0's tweedie: 447.78\n",
      "[10]\tvalid_0's tweedie: 446.641\n",
      "[11]\tvalid_0's tweedie: 445.691\n",
      "[12]\tvalid_0's tweedie: 444.889\n",
      "[13]\tvalid_0's tweedie: 444.213\n",
      "[14]\tvalid_0's tweedie: 443.685\n",
      "[15]\tvalid_0's tweedie: 443.2\n",
      "[16]\tvalid_0's tweedie: 442.814\n",
      "[17]\tvalid_0's tweedie: 442.529\n",
      "[18]\tvalid_0's tweedie: 442.253\n",
      "[19]\tvalid_0's tweedie: 442.023\n",
      "[20]\tvalid_0's tweedie: 441.846\n",
      "[21]\tvalid_0's tweedie: 441.673\n",
      "[22]\tvalid_0's tweedie: 441.536\n",
      "[23]\tvalid_0's tweedie: 441.457\n",
      "[24]\tvalid_0's tweedie: 441.301\n",
      "[25]\tvalid_0's tweedie: 441.172\n",
      "[26]\tvalid_0's tweedie: 441.099\n",
      "[27]\tvalid_0's tweedie: 441.046\n",
      "[28]\tvalid_0's tweedie: 440.998\n",
      "[29]\tvalid_0's tweedie: 440.952\n",
      "[30]\tvalid_0's tweedie: 440.921\n",
      "[31]\tvalid_0's tweedie: 440.89\n",
      "[32]\tvalid_0's tweedie: 440.833\n",
      "[33]\tvalid_0's tweedie: 440.778\n",
      "[34]\tvalid_0's tweedie: 440.734\n",
      "[35]\tvalid_0's tweedie: 440.697\n",
      "[36]\tvalid_0's tweedie: 440.668\n",
      "[37]\tvalid_0's tweedie: 440.648\n",
      "[38]\tvalid_0's tweedie: 440.636\n",
      "[39]\tvalid_0's tweedie: 440.624\n",
      "[40]\tvalid_0's tweedie: 440.615\n",
      "[41]\tvalid_0's tweedie: 440.599\n",
      "[42]\tvalid_0's tweedie: 440.581\n",
      "[43]\tvalid_0's tweedie: 440.574\n",
      "[44]\tvalid_0's tweedie: 440.566\n",
      "[45]\tvalid_0's tweedie: 440.566\n",
      "[46]\tvalid_0's tweedie: 440.561\n",
      "[47]\tvalid_0's tweedie: 440.547\n",
      "[48]\tvalid_0's tweedie: 440.546\n",
      "[49]\tvalid_0's tweedie: 440.55\n",
      "[50]\tvalid_0's tweedie: 440.548\n",
      "[51]\tvalid_0's tweedie: 440.539\n",
      "[52]\tvalid_0's tweedie: 440.536\n",
      "[53]\tvalid_0's tweedie: 440.524\n",
      "[54]\tvalid_0's tweedie: 440.523\n",
      "[55]\tvalid_0's tweedie: 440.519\n",
      "[56]\tvalid_0's tweedie: 440.517\n",
      "[57]\tvalid_0's tweedie: 440.516\n",
      "[58]\tvalid_0's tweedie: 440.512\n",
      "[59]\tvalid_0's tweedie: 440.51\n",
      "[60]\tvalid_0's tweedie: 440.507\n",
      "[61]\tvalid_0's tweedie: 440.506\n",
      "[62]\tvalid_0's tweedie: 440.495\n",
      "[63]\tvalid_0's tweedie: 440.494\n",
      "[64]\tvalid_0's tweedie: 440.493\n",
      "[65]\tvalid_0's tweedie: 440.491\n",
      "[66]\tvalid_0's tweedie: 440.49\n",
      "[67]\tvalid_0's tweedie: 440.49\n",
      "[68]\tvalid_0's tweedie: 440.484\n",
      "[69]\tvalid_0's tweedie: 440.483\n",
      "[70]\tvalid_0's tweedie: 440.477\n",
      "[71]\tvalid_0's tweedie: 440.476\n",
      "[72]\tvalid_0's tweedie: 440.476\n",
      "[73]\tvalid_0's tweedie: 440.474\n",
      "[74]\tvalid_0's tweedie: 440.475\n",
      "[75]\tvalid_0's tweedie: 440.474\n",
      "[76]\tvalid_0's tweedie: 440.473\n",
      "[77]\tvalid_0's tweedie: 440.473\n",
      "[78]\tvalid_0's tweedie: 440.473\n",
      "[79]\tvalid_0's tweedie: 440.472\n",
      "[80]\tvalid_0's tweedie: 440.472\n",
      "[81]\tvalid_0's tweedie: 440.469\n",
      "[82]\tvalid_0's tweedie: 440.468\n",
      "[83]\tvalid_0's tweedie: 440.468\n",
      "[84]\tvalid_0's tweedie: 440.469\n",
      "[85]\tvalid_0's tweedie: 440.468\n",
      "[86]\tvalid_0's tweedie: 440.468\n",
      "[87]\tvalid_0's tweedie: 440.464\n",
      "[88]\tvalid_0's tweedie: 440.463\n",
      "[89]\tvalid_0's tweedie: 440.463\n",
      "[90]\tvalid_0's tweedie: 440.458\n",
      "[91]\tvalid_0's tweedie: 440.458\n",
      "[92]\tvalid_0's tweedie: 440.458\n",
      "[93]\tvalid_0's tweedie: 440.458\n",
      "[94]\tvalid_0's tweedie: 440.457\n",
      "[95]\tvalid_0's tweedie: 440.457\n",
      "[96]\tvalid_0's tweedie: 440.452\n",
      "[97]\tvalid_0's tweedie: 440.452\n",
      "[98]\tvalid_0's tweedie: 440.45\n",
      "[99]\tvalid_0's tweedie: 440.45\n",
      "[100]\tvalid_0's tweedie: 440.45\n",
      "[101]\tvalid_0's tweedie: 440.45\n",
      "[102]\tvalid_0's tweedie: 440.451\n",
      "[103]\tvalid_0's tweedie: 440.45\n",
      "[104]\tvalid_0's tweedie: 440.45\n",
      "[105]\tvalid_0's tweedie: 440.45\n",
      "[106]\tvalid_0's tweedie: 440.45\n",
      "[107]\tvalid_0's tweedie: 440.446\n",
      "[108]\tvalid_0's tweedie: 440.446\n",
      "[109]\tvalid_0's tweedie: 440.446\n",
      "[110]\tvalid_0's tweedie: 440.446\n",
      "[111]\tvalid_0's tweedie: 440.446\n",
      "[112]\tvalid_0's tweedie: 440.444\n",
      "[113]\tvalid_0's tweedie: 440.445\n",
      "[114]\tvalid_0's tweedie: 440.441\n",
      "[115]\tvalid_0's tweedie: 440.442\n",
      "[116]\tvalid_0's tweedie: 440.441\n",
      "[117]\tvalid_0's tweedie: 440.441\n",
      "[118]\tvalid_0's tweedie: 440.441\n",
      "[119]\tvalid_0's tweedie: 440.441\n",
      "[120]\tvalid_0's tweedie: 440.441\n",
      "[121]\tvalid_0's tweedie: 440.44\n",
      "[122]\tvalid_0's tweedie: 440.439\n",
      "[123]\tvalid_0's tweedie: 440.439\n",
      "[124]\tvalid_0's tweedie: 440.439\n",
      "[125]\tvalid_0's tweedie: 440.439\n",
      "[126]\tvalid_0's tweedie: 440.44\n",
      "[127]\tvalid_0's tweedie: 440.436\n",
      "[128]\tvalid_0's tweedie: 440.436\n",
      "[129]\tvalid_0's tweedie: 440.439\n",
      "[130]\tvalid_0's tweedie: 440.439\n",
      "[131]\tvalid_0's tweedie: 440.439\n",
      "[132]\tvalid_0's tweedie: 440.437\n",
      "[133]\tvalid_0's tweedie: 440.441\n",
      "[134]\tvalid_0's tweedie: 440.441\n",
      "[135]\tvalid_0's tweedie: 440.441\n",
      "[136]\tvalid_0's tweedie: 440.441\n",
      "[137]\tvalid_0's tweedie: 440.441\n",
      "[138]\tvalid_0's tweedie: 440.441\n",
      "[139]\tvalid_0's tweedie: 440.441\n",
      "[140]\tvalid_0's tweedie: 440.438\n",
      "[141]\tvalid_0's tweedie: 440.438\n",
      "[142]\tvalid_0's tweedie: 440.438\n",
      "[143]\tvalid_0's tweedie: 440.437\n",
      "[144]\tvalid_0's tweedie: 440.437\n",
      "[145]\tvalid_0's tweedie: 440.438\n",
      "[146]\tvalid_0's tweedie: 440.439\n",
      "[147]\tvalid_0's tweedie: 440.439\n",
      "[148]\tvalid_0's tweedie: 440.439\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's tweedie: 440.436\n",
      "Training model for level 4 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 5577, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345169\n",
      "[1]\tvalid_0's tweedie: 471.217\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 466.049\n",
      "[3]\tvalid_0's tweedie: 461.796\n",
      "[4]\tvalid_0's tweedie: 458.325\n",
      "[5]\tvalid_0's tweedie: 455.317\n",
      "[6]\tvalid_0's tweedie: 452.817\n",
      "[7]\tvalid_0's tweedie: 450.822\n",
      "[8]\tvalid_0's tweedie: 449.081\n",
      "[9]\tvalid_0's tweedie: 447.696\n",
      "[10]\tvalid_0's tweedie: 446.585\n",
      "[11]\tvalid_0's tweedie: 445.573\n",
      "[12]\tvalid_0's tweedie: 444.801\n",
      "[13]\tvalid_0's tweedie: 444.142\n",
      "[14]\tvalid_0's tweedie: 443.581\n",
      "[15]\tvalid_0's tweedie: 443.102\n",
      "[16]\tvalid_0's tweedie: 442.772\n",
      "[17]\tvalid_0's tweedie: 442.439\n",
      "[18]\tvalid_0's tweedie: 442.187\n",
      "[19]\tvalid_0's tweedie: 441.996\n",
      "[20]\tvalid_0's tweedie: 441.797\n",
      "[21]\tvalid_0's tweedie: 441.684\n",
      "[22]\tvalid_0's tweedie: 441.564\n",
      "[23]\tvalid_0's tweedie: 441.388\n",
      "[24]\tvalid_0's tweedie: 441.25\n",
      "[25]\tvalid_0's tweedie: 441.175\n",
      "[26]\tvalid_0's tweedie: 441.115\n",
      "[27]\tvalid_0's tweedie: 441.065\n",
      "[28]\tvalid_0's tweedie: 441.017\n",
      "[29]\tvalid_0's tweedie: 440.997\n",
      "[30]\tvalid_0's tweedie: 440.957\n",
      "[31]\tvalid_0's tweedie: 440.883\n",
      "[32]\tvalid_0's tweedie: 440.845\n",
      "[33]\tvalid_0's tweedie: 440.818\n",
      "[34]\tvalid_0's tweedie: 440.77\n",
      "[35]\tvalid_0's tweedie: 440.72\n",
      "[36]\tvalid_0's tweedie: 440.685\n",
      "[37]\tvalid_0's tweedie: 440.661\n",
      "[38]\tvalid_0's tweedie: 440.638\n",
      "[39]\tvalid_0's tweedie: 440.626\n",
      "[40]\tvalid_0's tweedie: 440.608\n",
      "[41]\tvalid_0's tweedie: 440.598\n",
      "[42]\tvalid_0's tweedie: 440.582\n",
      "[43]\tvalid_0's tweedie: 440.576\n",
      "[44]\tvalid_0's tweedie: 440.569\n",
      "[45]\tvalid_0's tweedie: 440.562\n",
      "[46]\tvalid_0's tweedie: 440.557\n",
      "[47]\tvalid_0's tweedie: 440.549\n",
      "[48]\tvalid_0's tweedie: 440.546\n",
      "[49]\tvalid_0's tweedie: 440.533\n",
      "[50]\tvalid_0's tweedie: 440.526\n",
      "[51]\tvalid_0's tweedie: 440.523\n",
      "[52]\tvalid_0's tweedie: 440.52\n",
      "[53]\tvalid_0's tweedie: 440.519\n",
      "[54]\tvalid_0's tweedie: 440.517\n",
      "[55]\tvalid_0's tweedie: 440.513\n",
      "[56]\tvalid_0's tweedie: 440.509\n",
      "[57]\tvalid_0's tweedie: 440.506\n",
      "[58]\tvalid_0's tweedie: 440.506\n",
      "[59]\tvalid_0's tweedie: 440.497\n",
      "[60]\tvalid_0's tweedie: 440.497\n",
      "[61]\tvalid_0's tweedie: 440.493\n",
      "[62]\tvalid_0's tweedie: 440.489\n",
      "[63]\tvalid_0's tweedie: 440.494\n",
      "[64]\tvalid_0's tweedie: 440.493\n",
      "[65]\tvalid_0's tweedie: 440.491\n",
      "[66]\tvalid_0's tweedie: 440.491\n",
      "[67]\tvalid_0's tweedie: 440.488\n",
      "[68]\tvalid_0's tweedie: 440.485\n",
      "[69]\tvalid_0's tweedie: 440.485\n",
      "[70]\tvalid_0's tweedie: 440.479\n",
      "[71]\tvalid_0's tweedie: 440.478\n",
      "[72]\tvalid_0's tweedie: 440.477\n",
      "[73]\tvalid_0's tweedie: 440.477\n",
      "[74]\tvalid_0's tweedie: 440.478\n",
      "[75]\tvalid_0's tweedie: 440.476\n",
      "[76]\tvalid_0's tweedie: 440.472\n",
      "[77]\tvalid_0's tweedie: 440.472\n",
      "[78]\tvalid_0's tweedie: 440.471\n",
      "[79]\tvalid_0's tweedie: 440.468\n",
      "[80]\tvalid_0's tweedie: 440.467\n",
      "[81]\tvalid_0's tweedie: 440.467\n",
      "[82]\tvalid_0's tweedie: 440.465\n",
      "[83]\tvalid_0's tweedie: 440.465\n",
      "[84]\tvalid_0's tweedie: 440.465\n",
      "[85]\tvalid_0's tweedie: 440.465\n",
      "[86]\tvalid_0's tweedie: 440.466\n",
      "[87]\tvalid_0's tweedie: 440.463\n",
      "[88]\tvalid_0's tweedie: 440.463\n",
      "[89]\tvalid_0's tweedie: 440.458\n",
      "[90]\tvalid_0's tweedie: 440.458\n",
      "[91]\tvalid_0's tweedie: 440.458\n",
      "[92]\tvalid_0's tweedie: 440.458\n",
      "[93]\tvalid_0's tweedie: 440.457\n",
      "[94]\tvalid_0's tweedie: 440.457\n",
      "[95]\tvalid_0's tweedie: 440.456\n",
      "[96]\tvalid_0's tweedie: 440.456\n",
      "[97]\tvalid_0's tweedie: 440.455\n",
      "[98]\tvalid_0's tweedie: 440.455\n",
      "[99]\tvalid_0's tweedie: 440.455\n",
      "[100]\tvalid_0's tweedie: 440.452\n",
      "[101]\tvalid_0's tweedie: 440.451\n",
      "[102]\tvalid_0's tweedie: 440.449\n",
      "[103]\tvalid_0's tweedie: 440.449\n",
      "[104]\tvalid_0's tweedie: 440.449\n",
      "[105]\tvalid_0's tweedie: 440.45\n",
      "[106]\tvalid_0's tweedie: 440.45\n",
      "[107]\tvalid_0's tweedie: 440.449\n",
      "[108]\tvalid_0's tweedie: 440.45\n",
      "[109]\tvalid_0's tweedie: 440.45\n",
      "[110]\tvalid_0's tweedie: 440.45\n",
      "[111]\tvalid_0's tweedie: 440.448\n",
      "[112]\tvalid_0's tweedie: 440.448\n",
      "[113]\tvalid_0's tweedie: 440.448\n",
      "[114]\tvalid_0's tweedie: 440.447\n",
      "[115]\tvalid_0's tweedie: 440.447\n",
      "[116]\tvalid_0's tweedie: 440.447\n",
      "[117]\tvalid_0's tweedie: 440.447\n",
      "[118]\tvalid_0's tweedie: 440.446\n",
      "[119]\tvalid_0's tweedie: 440.446\n",
      "[120]\tvalid_0's tweedie: 440.446\n",
      "[121]\tvalid_0's tweedie: 440.446\n",
      "[122]\tvalid_0's tweedie: 440.443\n",
      "[123]\tvalid_0's tweedie: 440.443\n",
      "[124]\tvalid_0's tweedie: 440.442\n",
      "[125]\tvalid_0's tweedie: 440.442\n",
      "[126]\tvalid_0's tweedie: 440.438\n",
      "[127]\tvalid_0's tweedie: 440.438\n",
      "[128]\tvalid_0's tweedie: 440.438\n",
      "[129]\tvalid_0's tweedie: 440.438\n",
      "[130]\tvalid_0's tweedie: 440.438\n",
      "[131]\tvalid_0's tweedie: 440.438\n",
      "[132]\tvalid_0's tweedie: 440.438\n",
      "[133]\tvalid_0's tweedie: 440.434\n",
      "[134]\tvalid_0's tweedie: 440.435\n",
      "[135]\tvalid_0's tweedie: 440.435\n",
      "[136]\tvalid_0's tweedie: 440.435\n",
      "[137]\tvalid_0's tweedie: 440.434\n",
      "[138]\tvalid_0's tweedie: 440.434\n",
      "[139]\tvalid_0's tweedie: 440.435\n",
      "[140]\tvalid_0's tweedie: 440.435\n",
      "[141]\tvalid_0's tweedie: 440.434\n",
      "[142]\tvalid_0's tweedie: 440.434\n",
      "[143]\tvalid_0's tweedie: 440.434\n",
      "[144]\tvalid_0's tweedie: 440.434\n",
      "[145]\tvalid_0's tweedie: 440.434\n",
      "[146]\tvalid_0's tweedie: 440.434\n",
      "[147]\tvalid_0's tweedie: 440.434\n",
      "[148]\tvalid_0's tweedie: 440.434\n",
      "[149]\tvalid_0's tweedie: 440.434\n",
      "[150]\tvalid_0's tweedie: 440.434\n",
      "[151]\tvalid_0's tweedie: 440.434\n",
      "[152]\tvalid_0's tweedie: 440.434\n",
      "[153]\tvalid_0's tweedie: 440.434\n",
      "[154]\tvalid_0's tweedie: 440.433\n",
      "[155]\tvalid_0's tweedie: 440.433\n",
      "[156]\tvalid_0's tweedie: 440.434\n",
      "[157]\tvalid_0's tweedie: 440.435\n",
      "[158]\tvalid_0's tweedie: 440.434\n",
      "[159]\tvalid_0's tweedie: 440.434\n",
      "[160]\tvalid_0's tweedie: 440.434\n",
      "[161]\tvalid_0's tweedie: 440.433\n",
      "[162]\tvalid_0's tweedie: 440.433\n",
      "[163]\tvalid_0's tweedie: 440.433\n",
      "[164]\tvalid_0's tweedie: 440.433\n",
      "[165]\tvalid_0's tweedie: 440.434\n",
      "[166]\tvalid_0's tweedie: 440.435\n",
      "[167]\tvalid_0's tweedie: 440.435\n",
      "[168]\tvalid_0's tweedie: 440.435\n",
      "[169]\tvalid_0's tweedie: 440.435\n",
      "[170]\tvalid_0's tweedie: 440.434\n",
      "[171]\tvalid_0's tweedie: 440.436\n",
      "[172]\tvalid_0's tweedie: 440.436\n",
      "[173]\tvalid_0's tweedie: 440.436\n",
      "[174]\tvalid_0's tweedie: 440.436\n",
      "[175]\tvalid_0's tweedie: 440.435\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's tweedie: 440.433\n",
      "Training model for level 4 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 5574, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345390\n",
      "[1]\tvalid_0's tweedie: 471.236\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 466.08\n",
      "[3]\tvalid_0's tweedie: 461.869\n",
      "[4]\tvalid_0's tweedie: 458.387\n",
      "[5]\tvalid_0's tweedie: 455.44\n",
      "[6]\tvalid_0's tweedie: 452.995\n",
      "[7]\tvalid_0's tweedie: 450.975\n",
      "[8]\tvalid_0's tweedie: 449.315\n",
      "[9]\tvalid_0's tweedie: 447.846\n",
      "[10]\tvalid_0's tweedie: 446.645\n",
      "[11]\tvalid_0's tweedie: 445.665\n",
      "[12]\tvalid_0's tweedie: 444.907\n",
      "[13]\tvalid_0's tweedie: 444.286\n",
      "[14]\tvalid_0's tweedie: 443.712\n",
      "[15]\tvalid_0's tweedie: 443.217\n",
      "[16]\tvalid_0's tweedie: 442.837\n",
      "[17]\tvalid_0's tweedie: 442.54\n",
      "[18]\tvalid_0's tweedie: 442.262\n",
      "[19]\tvalid_0's tweedie: 442.08\n",
      "[20]\tvalid_0's tweedie: 441.883\n",
      "[21]\tvalid_0's tweedie: 441.713\n",
      "[22]\tvalid_0's tweedie: 441.58\n",
      "[23]\tvalid_0's tweedie: 441.396\n",
      "[24]\tvalid_0's tweedie: 441.3\n",
      "[25]\tvalid_0's tweedie: 441.214\n",
      "[26]\tvalid_0's tweedie: 441.145\n",
      "[27]\tvalid_0's tweedie: 441.084\n",
      "[28]\tvalid_0's tweedie: 440.99\n",
      "[29]\tvalid_0's tweedie: 440.908\n",
      "[30]\tvalid_0's tweedie: 440.873\n",
      "[31]\tvalid_0's tweedie: 440.839\n",
      "[32]\tvalid_0's tweedie: 440.813\n",
      "[33]\tvalid_0's tweedie: 440.768\n",
      "[34]\tvalid_0's tweedie: 440.72\n",
      "[35]\tvalid_0's tweedie: 440.679\n",
      "[36]\tvalid_0's tweedie: 440.664\n",
      "[37]\tvalid_0's tweedie: 440.634\n",
      "[38]\tvalid_0's tweedie: 440.61\n",
      "[39]\tvalid_0's tweedie: 440.602\n",
      "[40]\tvalid_0's tweedie: 440.591\n",
      "[41]\tvalid_0's tweedie: 440.578\n",
      "[42]\tvalid_0's tweedie: 440.571\n",
      "[43]\tvalid_0's tweedie: 440.555\n",
      "[44]\tvalid_0's tweedie: 440.543\n",
      "[45]\tvalid_0's tweedie: 440.538\n",
      "[46]\tvalid_0's tweedie: 440.539\n",
      "[47]\tvalid_0's tweedie: 440.534\n",
      "[48]\tvalid_0's tweedie: 440.532\n",
      "[49]\tvalid_0's tweedie: 440.523\n",
      "[50]\tvalid_0's tweedie: 440.52\n",
      "[51]\tvalid_0's tweedie: 440.513\n",
      "[52]\tvalid_0's tweedie: 440.512\n",
      "[53]\tvalid_0's tweedie: 440.508\n",
      "[54]\tvalid_0's tweedie: 440.507\n",
      "[55]\tvalid_0's tweedie: 440.505\n",
      "[56]\tvalid_0's tweedie: 440.502\n",
      "[57]\tvalid_0's tweedie: 440.499\n",
      "[58]\tvalid_0's tweedie: 440.501\n",
      "[59]\tvalid_0's tweedie: 440.499\n",
      "[60]\tvalid_0's tweedie: 440.499\n",
      "[61]\tvalid_0's tweedie: 440.498\n",
      "[62]\tvalid_0's tweedie: 440.495\n",
      "[63]\tvalid_0's tweedie: 440.494\n",
      "[64]\tvalid_0's tweedie: 440.487\n",
      "[65]\tvalid_0's tweedie: 440.488\n",
      "[66]\tvalid_0's tweedie: 440.487\n",
      "[67]\tvalid_0's tweedie: 440.485\n",
      "[68]\tvalid_0's tweedie: 440.485\n",
      "[69]\tvalid_0's tweedie: 440.483\n",
      "[70]\tvalid_0's tweedie: 440.483\n",
      "[71]\tvalid_0's tweedie: 440.481\n",
      "[72]\tvalid_0's tweedie: 440.48\n",
      "[73]\tvalid_0's tweedie: 440.478\n",
      "[74]\tvalid_0's tweedie: 440.477\n",
      "[75]\tvalid_0's tweedie: 440.477\n",
      "[76]\tvalid_0's tweedie: 440.47\n",
      "[77]\tvalid_0's tweedie: 440.47\n",
      "[78]\tvalid_0's tweedie: 440.469\n",
      "[79]\tvalid_0's tweedie: 440.468\n",
      "[80]\tvalid_0's tweedie: 440.468\n",
      "[81]\tvalid_0's tweedie: 440.468\n",
      "[82]\tvalid_0's tweedie: 440.467\n",
      "[83]\tvalid_0's tweedie: 440.466\n",
      "[84]\tvalid_0's tweedie: 440.466\n",
      "[85]\tvalid_0's tweedie: 440.464\n",
      "[86]\tvalid_0's tweedie: 440.464\n",
      "[87]\tvalid_0's tweedie: 440.464\n",
      "[88]\tvalid_0's tweedie: 440.464\n",
      "[89]\tvalid_0's tweedie: 440.466\n",
      "[90]\tvalid_0's tweedie: 440.465\n",
      "[91]\tvalid_0's tweedie: 440.464\n",
      "[92]\tvalid_0's tweedie: 440.462\n",
      "[93]\tvalid_0's tweedie: 440.459\n",
      "[94]\tvalid_0's tweedie: 440.459\n",
      "[95]\tvalid_0's tweedie: 440.458\n",
      "[96]\tvalid_0's tweedie: 440.457\n",
      "[97]\tvalid_0's tweedie: 440.457\n",
      "[98]\tvalid_0's tweedie: 440.455\n",
      "[99]\tvalid_0's tweedie: 440.455\n",
      "[100]\tvalid_0's tweedie: 440.454\n",
      "[101]\tvalid_0's tweedie: 440.453\n",
      "[102]\tvalid_0's tweedie: 440.454\n",
      "[103]\tvalid_0's tweedie: 440.455\n",
      "[104]\tvalid_0's tweedie: 440.455\n",
      "[105]\tvalid_0's tweedie: 440.455\n",
      "[106]\tvalid_0's tweedie: 440.454\n",
      "[107]\tvalid_0's tweedie: 440.454\n",
      "[108]\tvalid_0's tweedie: 440.454\n",
      "[109]\tvalid_0's tweedie: 440.451\n",
      "[110]\tvalid_0's tweedie: 440.451\n",
      "[111]\tvalid_0's tweedie: 440.451\n",
      "[112]\tvalid_0's tweedie: 440.451\n",
      "[113]\tvalid_0's tweedie: 440.452\n",
      "[114]\tvalid_0's tweedie: 440.452\n",
      "[115]\tvalid_0's tweedie: 440.452\n",
      "[116]\tvalid_0's tweedie: 440.452\n",
      "[117]\tvalid_0's tweedie: 440.452\n",
      "[118]\tvalid_0's tweedie: 440.452\n",
      "[119]\tvalid_0's tweedie: 440.452\n",
      "[120]\tvalid_0's tweedie: 440.449\n",
      "[121]\tvalid_0's tweedie: 440.45\n",
      "[122]\tvalid_0's tweedie: 440.45\n",
      "[123]\tvalid_0's tweedie: 440.449\n",
      "[124]\tvalid_0's tweedie: 440.443\n",
      "[125]\tvalid_0's tweedie: 440.442\n",
      "[126]\tvalid_0's tweedie: 440.442\n",
      "[127]\tvalid_0's tweedie: 440.442\n",
      "[128]\tvalid_0's tweedie: 440.44\n",
      "[129]\tvalid_0's tweedie: 440.439\n",
      "[130]\tvalid_0's tweedie: 440.438\n",
      "[131]\tvalid_0's tweedie: 440.435\n",
      "[132]\tvalid_0's tweedie: 440.435\n",
      "[133]\tvalid_0's tweedie: 440.435\n",
      "[134]\tvalid_0's tweedie: 440.435\n",
      "[135]\tvalid_0's tweedie: 440.433\n",
      "[136]\tvalid_0's tweedie: 440.432\n",
      "[137]\tvalid_0's tweedie: 440.432\n",
      "[138]\tvalid_0's tweedie: 440.431\n",
      "[139]\tvalid_0's tweedie: 440.43\n",
      "[140]\tvalid_0's tweedie: 440.43\n",
      "[141]\tvalid_0's tweedie: 440.43\n",
      "[142]\tvalid_0's tweedie: 440.429\n",
      "[143]\tvalid_0's tweedie: 440.428\n",
      "[144]\tvalid_0's tweedie: 440.424\n",
      "[145]\tvalid_0's tweedie: 440.424\n",
      "[146]\tvalid_0's tweedie: 440.424\n",
      "[147]\tvalid_0's tweedie: 440.424\n",
      "[148]\tvalid_0's tweedie: 440.423\n",
      "[149]\tvalid_0's tweedie: 440.424\n",
      "[150]\tvalid_0's tweedie: 440.424\n",
      "[151]\tvalid_0's tweedie: 440.423\n",
      "[152]\tvalid_0's tweedie: 440.423\n",
      "[153]\tvalid_0's tweedie: 440.423\n",
      "[154]\tvalid_0's tweedie: 440.423\n",
      "[155]\tvalid_0's tweedie: 440.423\n",
      "[156]\tvalid_0's tweedie: 440.423\n",
      "[157]\tvalid_0's tweedie: 440.422\n",
      "[158]\tvalid_0's tweedie: 440.422\n",
      "[159]\tvalid_0's tweedie: 440.422\n",
      "[160]\tvalid_0's tweedie: 440.418\n",
      "[161]\tvalid_0's tweedie: 440.417\n",
      "[162]\tvalid_0's tweedie: 440.417\n",
      "[163]\tvalid_0's tweedie: 440.419\n",
      "[164]\tvalid_0's tweedie: 440.419\n",
      "[165]\tvalid_0's tweedie: 440.419\n",
      "[166]\tvalid_0's tweedie: 440.417\n",
      "[167]\tvalid_0's tweedie: 440.417\n",
      "[168]\tvalid_0's tweedie: 440.416\n",
      "[169]\tvalid_0's tweedie: 440.416\n",
      "[170]\tvalid_0's tweedie: 440.416\n",
      "[171]\tvalid_0's tweedie: 440.415\n",
      "[172]\tvalid_0's tweedie: 440.414\n",
      "[173]\tvalid_0's tweedie: 440.414\n",
      "[174]\tvalid_0's tweedie: 440.414\n",
      "[175]\tvalid_0's tweedie: 440.414\n",
      "[176]\tvalid_0's tweedie: 440.414\n",
      "[177]\tvalid_0's tweedie: 440.414\n",
      "[178]\tvalid_0's tweedie: 440.414\n",
      "[179]\tvalid_0's tweedie: 440.414\n",
      "[180]\tvalid_0's tweedie: 440.413\n",
      "[181]\tvalid_0's tweedie: 440.412\n",
      "[182]\tvalid_0's tweedie: 440.413\n",
      "[183]\tvalid_0's tweedie: 440.413\n",
      "[184]\tvalid_0's tweedie: 440.412\n",
      "[185]\tvalid_0's tweedie: 440.412\n",
      "[186]\tvalid_0's tweedie: 440.411\n",
      "[187]\tvalid_0's tweedie: 440.411\n",
      "[188]\tvalid_0's tweedie: 440.411\n",
      "[189]\tvalid_0's tweedie: 440.411\n",
      "[190]\tvalid_0's tweedie: 440.412\n",
      "[191]\tvalid_0's tweedie: 440.412\n",
      "[192]\tvalid_0's tweedie: 440.412\n",
      "[193]\tvalid_0's tweedie: 440.41\n",
      "[194]\tvalid_0's tweedie: 440.41\n",
      "[195]\tvalid_0's tweedie: 440.41\n",
      "[196]\tvalid_0's tweedie: 440.408\n",
      "[197]\tvalid_0's tweedie: 440.408\n",
      "[198]\tvalid_0's tweedie: 440.409\n",
      "[199]\tvalid_0's tweedie: 440.409\n",
      "[200]\tvalid_0's tweedie: 440.408\n",
      "[201]\tvalid_0's tweedie: 440.408\n",
      "[202]\tvalid_0's tweedie: 440.408\n",
      "[203]\tvalid_0's tweedie: 440.408\n",
      "[204]\tvalid_0's tweedie: 440.408\n",
      "[205]\tvalid_0's tweedie: 440.409\n",
      "[206]\tvalid_0's tweedie: 440.409\n",
      "[207]\tvalid_0's tweedie: 440.409\n",
      "[208]\tvalid_0's tweedie: 440.409\n",
      "[209]\tvalid_0's tweedie: 440.409\n",
      "[210]\tvalid_0's tweedie: 440.406\n",
      "[211]\tvalid_0's tweedie: 440.408\n",
      "[212]\tvalid_0's tweedie: 440.408\n",
      "[213]\tvalid_0's tweedie: 440.41\n",
      "[214]\tvalid_0's tweedie: 440.41\n",
      "[215]\tvalid_0's tweedie: 440.409\n",
      "[216]\tvalid_0's tweedie: 440.408\n",
      "[217]\tvalid_0's tweedie: 440.409\n",
      "[218]\tvalid_0's tweedie: 440.409\n",
      "[219]\tvalid_0's tweedie: 440.409\n",
      "[220]\tvalid_0's tweedie: 440.409\n",
      "[221]\tvalid_0's tweedie: 440.411\n",
      "[222]\tvalid_0's tweedie: 440.411\n",
      "[223]\tvalid_0's tweedie: 440.411\n",
      "[224]\tvalid_0's tweedie: 440.412\n",
      "[225]\tvalid_0's tweedie: 440.412\n",
      "[226]\tvalid_0's tweedie: 440.413\n",
      "[227]\tvalid_0's tweedie: 440.41\n",
      "[228]\tvalid_0's tweedie: 440.41\n",
      "[229]\tvalid_0's tweedie: 440.409\n",
      "[230]\tvalid_0's tweedie: 440.409\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's tweedie: 440.406\n",
      "Training model for level 4 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 5571, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345575\n",
      "[1]\tvalid_0's tweedie: 471.013\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.685\n",
      "[3]\tvalid_0's tweedie: 461.34\n",
      "[4]\tvalid_0's tweedie: 457.758\n",
      "[5]\tvalid_0's tweedie: 454.76\n",
      "[6]\tvalid_0's tweedie: 452.288\n",
      "[7]\tvalid_0's tweedie: 450.337\n",
      "[8]\tvalid_0's tweedie: 448.675\n",
      "[9]\tvalid_0's tweedie: 447.287\n",
      "[10]\tvalid_0's tweedie: 446.156\n",
      "[11]\tvalid_0's tweedie: 445.29\n",
      "[12]\tvalid_0's tweedie: 444.564\n",
      "[13]\tvalid_0's tweedie: 443.937\n",
      "[14]\tvalid_0's tweedie: 443.44\n",
      "[15]\tvalid_0's tweedie: 443.005\n",
      "[16]\tvalid_0's tweedie: 442.663\n",
      "[17]\tvalid_0's tweedie: 442.386\n",
      "[18]\tvalid_0's tweedie: 442.136\n",
      "[19]\tvalid_0's tweedie: 441.908\n",
      "[20]\tvalid_0's tweedie: 441.739\n",
      "[21]\tvalid_0's tweedie: 441.613\n",
      "[22]\tvalid_0's tweedie: 441.492\n",
      "[23]\tvalid_0's tweedie: 441.387\n",
      "[24]\tvalid_0's tweedie: 441.296\n",
      "[25]\tvalid_0's tweedie: 441.161\n",
      "[26]\tvalid_0's tweedie: 441.111\n",
      "[27]\tvalid_0's tweedie: 441.064\n",
      "[28]\tvalid_0's tweedie: 441.002\n",
      "[29]\tvalid_0's tweedie: 440.959\n",
      "[30]\tvalid_0's tweedie: 440.928\n",
      "[31]\tvalid_0's tweedie: 440.854\n",
      "[32]\tvalid_0's tweedie: 440.797\n",
      "[33]\tvalid_0's tweedie: 440.771\n",
      "[34]\tvalid_0's tweedie: 440.724\n",
      "[35]\tvalid_0's tweedie: 440.682\n",
      "[36]\tvalid_0's tweedie: 440.652\n",
      "[37]\tvalid_0's tweedie: 440.623\n",
      "[38]\tvalid_0's tweedie: 440.595\n",
      "[39]\tvalid_0's tweedie: 440.576\n",
      "[40]\tvalid_0's tweedie: 440.569\n",
      "[41]\tvalid_0's tweedie: 440.561\n",
      "[42]\tvalid_0's tweedie: 440.552\n",
      "[43]\tvalid_0's tweedie: 440.547\n",
      "[44]\tvalid_0's tweedie: 440.541\n",
      "[45]\tvalid_0's tweedie: 440.534\n",
      "[46]\tvalid_0's tweedie: 440.524\n",
      "[47]\tvalid_0's tweedie: 440.514\n",
      "[48]\tvalid_0's tweedie: 440.513\n",
      "[49]\tvalid_0's tweedie: 440.516\n",
      "[50]\tvalid_0's tweedie: 440.515\n",
      "[51]\tvalid_0's tweedie: 440.514\n",
      "[52]\tvalid_0's tweedie: 440.512\n",
      "[53]\tvalid_0's tweedie: 440.514\n",
      "[54]\tvalid_0's tweedie: 440.513\n",
      "[55]\tvalid_0's tweedie: 440.513\n",
      "[56]\tvalid_0's tweedie: 440.509\n",
      "[57]\tvalid_0's tweedie: 440.507\n",
      "[58]\tvalid_0's tweedie: 440.511\n",
      "[59]\tvalid_0's tweedie: 440.51\n",
      "[60]\tvalid_0's tweedie: 440.508\n",
      "[61]\tvalid_0's tweedie: 440.508\n",
      "[62]\tvalid_0's tweedie: 440.505\n",
      "[63]\tvalid_0's tweedie: 440.503\n",
      "[64]\tvalid_0's tweedie: 440.505\n",
      "[65]\tvalid_0's tweedie: 440.504\n",
      "[66]\tvalid_0's tweedie: 440.504\n",
      "[67]\tvalid_0's tweedie: 440.501\n",
      "[68]\tvalid_0's tweedie: 440.497\n",
      "[69]\tvalid_0's tweedie: 440.496\n",
      "[70]\tvalid_0's tweedie: 440.491\n",
      "[71]\tvalid_0's tweedie: 440.488\n",
      "[72]\tvalid_0's tweedie: 440.488\n",
      "[73]\tvalid_0's tweedie: 440.486\n",
      "[74]\tvalid_0's tweedie: 440.485\n",
      "[75]\tvalid_0's tweedie: 440.485\n",
      "[76]\tvalid_0's tweedie: 440.484\n",
      "[77]\tvalid_0's tweedie: 440.481\n",
      "[78]\tvalid_0's tweedie: 440.477\n",
      "[79]\tvalid_0's tweedie: 440.477\n",
      "[80]\tvalid_0's tweedie: 440.478\n",
      "[81]\tvalid_0's tweedie: 440.478\n",
      "[82]\tvalid_0's tweedie: 440.476\n",
      "[83]\tvalid_0's tweedie: 440.475\n",
      "[84]\tvalid_0's tweedie: 440.468\n",
      "[85]\tvalid_0's tweedie: 440.468\n",
      "[86]\tvalid_0's tweedie: 440.466\n",
      "[87]\tvalid_0's tweedie: 440.464\n",
      "[88]\tvalid_0's tweedie: 440.457\n",
      "[89]\tvalid_0's tweedie: 440.452\n",
      "[90]\tvalid_0's tweedie: 440.451\n",
      "[91]\tvalid_0's tweedie: 440.451\n",
      "[92]\tvalid_0's tweedie: 440.451\n",
      "[93]\tvalid_0's tweedie: 440.45\n",
      "[94]\tvalid_0's tweedie: 440.449\n",
      "[95]\tvalid_0's tweedie: 440.444\n",
      "[96]\tvalid_0's tweedie: 440.443\n",
      "[97]\tvalid_0's tweedie: 440.442\n",
      "[98]\tvalid_0's tweedie: 440.438\n",
      "[99]\tvalid_0's tweedie: 440.438\n",
      "[100]\tvalid_0's tweedie: 440.438\n",
      "[101]\tvalid_0's tweedie: 440.438\n",
      "[102]\tvalid_0's tweedie: 440.438\n",
      "[103]\tvalid_0's tweedie: 440.437\n",
      "[104]\tvalid_0's tweedie: 440.438\n",
      "[105]\tvalid_0's tweedie: 440.437\n",
      "[106]\tvalid_0's tweedie: 440.437\n",
      "[107]\tvalid_0's tweedie: 440.434\n",
      "[108]\tvalid_0's tweedie: 440.432\n",
      "[109]\tvalid_0's tweedie: 440.431\n",
      "[110]\tvalid_0's tweedie: 440.432\n",
      "[111]\tvalid_0's tweedie: 440.432\n",
      "[112]\tvalid_0's tweedie: 440.431\n",
      "[113]\tvalid_0's tweedie: 440.43\n",
      "[114]\tvalid_0's tweedie: 440.43\n",
      "[115]\tvalid_0's tweedie: 440.429\n",
      "[116]\tvalid_0's tweedie: 440.429\n",
      "[117]\tvalid_0's tweedie: 440.427\n",
      "[118]\tvalid_0's tweedie: 440.427\n",
      "[119]\tvalid_0's tweedie: 440.428\n",
      "[120]\tvalid_0's tweedie: 440.427\n",
      "[121]\tvalid_0's tweedie: 440.428\n",
      "[122]\tvalid_0's tweedie: 440.428\n",
      "[123]\tvalid_0's tweedie: 440.428\n",
      "[124]\tvalid_0's tweedie: 440.427\n",
      "[125]\tvalid_0's tweedie: 440.429\n",
      "[126]\tvalid_0's tweedie: 440.429\n",
      "[127]\tvalid_0's tweedie: 440.43\n",
      "[128]\tvalid_0's tweedie: 440.431\n",
      "[129]\tvalid_0's tweedie: 440.43\n",
      "[130]\tvalid_0's tweedie: 440.43\n",
      "[131]\tvalid_0's tweedie: 440.43\n",
      "[132]\tvalid_0's tweedie: 440.43\n",
      "[133]\tvalid_0's tweedie: 440.43\n",
      "[134]\tvalid_0's tweedie: 440.428\n",
      "[135]\tvalid_0's tweedie: 440.428\n",
      "[136]\tvalid_0's tweedie: 440.428\n",
      "[137]\tvalid_0's tweedie: 440.427\n",
      "[138]\tvalid_0's tweedie: 440.427\n",
      "[139]\tvalid_0's tweedie: 440.426\n",
      "[140]\tvalid_0's tweedie: 440.426\n",
      "[141]\tvalid_0's tweedie: 440.427\n",
      "[142]\tvalid_0's tweedie: 440.427\n",
      "[143]\tvalid_0's tweedie: 440.427\n",
      "[144]\tvalid_0's tweedie: 440.425\n",
      "[145]\tvalid_0's tweedie: 440.425\n",
      "[146]\tvalid_0's tweedie: 440.424\n",
      "[147]\tvalid_0's tweedie: 440.423\n",
      "[148]\tvalid_0's tweedie: 440.425\n",
      "[149]\tvalid_0's tweedie: 440.424\n",
      "[150]\tvalid_0's tweedie: 440.424\n",
      "[151]\tvalid_0's tweedie: 440.424\n",
      "[152]\tvalid_0's tweedie: 440.424\n",
      "[153]\tvalid_0's tweedie: 440.424\n",
      "[154]\tvalid_0's tweedie: 440.424\n",
      "[155]\tvalid_0's tweedie: 440.424\n",
      "[156]\tvalid_0's tweedie: 440.421\n",
      "[157]\tvalid_0's tweedie: 440.421\n",
      "[158]\tvalid_0's tweedie: 440.42\n",
      "[159]\tvalid_0's tweedie: 440.42\n",
      "[160]\tvalid_0's tweedie: 440.42\n",
      "[161]\tvalid_0's tweedie: 440.418\n",
      "[162]\tvalid_0's tweedie: 440.418\n",
      "[163]\tvalid_0's tweedie: 440.418\n",
      "[164]\tvalid_0's tweedie: 440.418\n",
      "[165]\tvalid_0's tweedie: 440.418\n",
      "[166]\tvalid_0's tweedie: 440.418\n",
      "[167]\tvalid_0's tweedie: 440.418\n",
      "[168]\tvalid_0's tweedie: 440.418\n",
      "[169]\tvalid_0's tweedie: 440.418\n",
      "[170]\tvalid_0's tweedie: 440.418\n",
      "[171]\tvalid_0's tweedie: 440.418\n",
      "[172]\tvalid_0's tweedie: 440.418\n",
      "[173]\tvalid_0's tweedie: 440.415\n",
      "[174]\tvalid_0's tweedie: 440.416\n",
      "[175]\tvalid_0's tweedie: 440.416\n",
      "[176]\tvalid_0's tweedie: 440.416\n",
      "[177]\tvalid_0's tweedie: 440.417\n",
      "[178]\tvalid_0's tweedie: 440.417\n",
      "[179]\tvalid_0's tweedie: 440.417\n",
      "[180]\tvalid_0's tweedie: 440.417\n",
      "[181]\tvalid_0's tweedie: 440.417\n",
      "[182]\tvalid_0's tweedie: 440.418\n",
      "[183]\tvalid_0's tweedie: 440.418\n",
      "[184]\tvalid_0's tweedie: 440.418\n",
      "[185]\tvalid_0's tweedie: 440.418\n",
      "[186]\tvalid_0's tweedie: 440.418\n",
      "[187]\tvalid_0's tweedie: 440.418\n",
      "[188]\tvalid_0's tweedie: 440.418\n",
      "[189]\tvalid_0's tweedie: 440.417\n",
      "[190]\tvalid_0's tweedie: 440.417\n",
      "[191]\tvalid_0's tweedie: 440.416\n",
      "[192]\tvalid_0's tweedie: 440.416\n",
      "[193]\tvalid_0's tweedie: 440.415\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's tweedie: 440.415\n",
      "Training model for level 4 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 5568, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345644\n",
      "[1]\tvalid_0's tweedie: 471.029\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.699\n",
      "[3]\tvalid_0's tweedie: 461.307\n",
      "[4]\tvalid_0's tweedie: 457.725\n",
      "[5]\tvalid_0's tweedie: 454.758\n",
      "[6]\tvalid_0's tweedie: 452.261\n",
      "[7]\tvalid_0's tweedie: 450.197\n",
      "[8]\tvalid_0's tweedie: 448.548\n",
      "[9]\tvalid_0's tweedie: 447.189\n",
      "[10]\tvalid_0's tweedie: 446.138\n",
      "[11]\tvalid_0's tweedie: 445.18\n",
      "[12]\tvalid_0's tweedie: 444.474\n",
      "[13]\tvalid_0's tweedie: 443.888\n",
      "[14]\tvalid_0's tweedie: 443.389\n",
      "[15]\tvalid_0's tweedie: 442.948\n",
      "[16]\tvalid_0's tweedie: 442.596\n",
      "[17]\tvalid_0's tweedie: 442.312\n",
      "[18]\tvalid_0's tweedie: 442.082\n",
      "[19]\tvalid_0's tweedie: 441.868\n",
      "[20]\tvalid_0's tweedie: 441.694\n",
      "[21]\tvalid_0's tweedie: 441.522\n",
      "[22]\tvalid_0's tweedie: 441.398\n",
      "[23]\tvalid_0's tweedie: 441.298\n",
      "[24]\tvalid_0's tweedie: 441.2\n",
      "[25]\tvalid_0's tweedie: 441.138\n",
      "[26]\tvalid_0's tweedie: 441.087\n",
      "[27]\tvalid_0's tweedie: 440.982\n",
      "[28]\tvalid_0's tweedie: 440.939\n",
      "[29]\tvalid_0's tweedie: 440.908\n",
      "[30]\tvalid_0's tweedie: 440.862\n",
      "[31]\tvalid_0's tweedie: 440.83\n",
      "[32]\tvalid_0's tweedie: 440.771\n",
      "[33]\tvalid_0's tweedie: 440.72\n",
      "[34]\tvalid_0's tweedie: 440.684\n",
      "[35]\tvalid_0's tweedie: 440.67\n",
      "[36]\tvalid_0's tweedie: 440.653\n",
      "[37]\tvalid_0's tweedie: 440.627\n",
      "[38]\tvalid_0's tweedie: 440.617\n",
      "[39]\tvalid_0's tweedie: 440.594\n",
      "[40]\tvalid_0's tweedie: 440.584\n",
      "[41]\tvalid_0's tweedie: 440.566\n",
      "[42]\tvalid_0's tweedie: 440.56\n",
      "[43]\tvalid_0's tweedie: 440.548\n",
      "[44]\tvalid_0's tweedie: 440.541\n",
      "[45]\tvalid_0's tweedie: 440.536\n",
      "[46]\tvalid_0's tweedie: 440.522\n",
      "[47]\tvalid_0's tweedie: 440.52\n",
      "[48]\tvalid_0's tweedie: 440.516\n",
      "[49]\tvalid_0's tweedie: 440.505\n",
      "[50]\tvalid_0's tweedie: 440.498\n",
      "[51]\tvalid_0's tweedie: 440.497\n",
      "[52]\tvalid_0's tweedie: 440.494\n",
      "[53]\tvalid_0's tweedie: 440.49\n",
      "[54]\tvalid_0's tweedie: 440.486\n",
      "[55]\tvalid_0's tweedie: 440.486\n",
      "[56]\tvalid_0's tweedie: 440.485\n",
      "[57]\tvalid_0's tweedie: 440.484\n",
      "[58]\tvalid_0's tweedie: 440.48\n",
      "[59]\tvalid_0's tweedie: 440.48\n",
      "[60]\tvalid_0's tweedie: 440.476\n",
      "[61]\tvalid_0's tweedie: 440.475\n",
      "[62]\tvalid_0's tweedie: 440.471\n",
      "[63]\tvalid_0's tweedie: 440.462\n",
      "[64]\tvalid_0's tweedie: 440.459\n",
      "[65]\tvalid_0's tweedie: 440.454\n",
      "[66]\tvalid_0's tweedie: 440.449\n",
      "[67]\tvalid_0's tweedie: 440.444\n",
      "[68]\tvalid_0's tweedie: 440.444\n",
      "[69]\tvalid_0's tweedie: 440.445\n",
      "[70]\tvalid_0's tweedie: 440.445\n",
      "[71]\tvalid_0's tweedie: 440.441\n",
      "[72]\tvalid_0's tweedie: 440.441\n",
      "[73]\tvalid_0's tweedie: 440.442\n",
      "[74]\tvalid_0's tweedie: 440.44\n",
      "[75]\tvalid_0's tweedie: 440.436\n",
      "[76]\tvalid_0's tweedie: 440.429\n",
      "[77]\tvalid_0's tweedie: 440.427\n",
      "[78]\tvalid_0's tweedie: 440.427\n",
      "[79]\tvalid_0's tweedie: 440.424\n",
      "[80]\tvalid_0's tweedie: 440.424\n",
      "[81]\tvalid_0's tweedie: 440.422\n",
      "[82]\tvalid_0's tweedie: 440.42\n",
      "[83]\tvalid_0's tweedie: 440.419\n",
      "[84]\tvalid_0's tweedie: 440.419\n",
      "[85]\tvalid_0's tweedie: 440.418\n",
      "[86]\tvalid_0's tweedie: 440.414\n",
      "[87]\tvalid_0's tweedie: 440.414\n",
      "[88]\tvalid_0's tweedie: 440.414\n",
      "[89]\tvalid_0's tweedie: 440.413\n",
      "[90]\tvalid_0's tweedie: 440.413\n",
      "[91]\tvalid_0's tweedie: 440.413\n",
      "[92]\tvalid_0's tweedie: 440.413\n",
      "[93]\tvalid_0's tweedie: 440.412\n",
      "[94]\tvalid_0's tweedie: 440.411\n",
      "[95]\tvalid_0's tweedie: 440.41\n",
      "[96]\tvalid_0's tweedie: 440.412\n",
      "[97]\tvalid_0's tweedie: 440.412\n",
      "[98]\tvalid_0's tweedie: 440.412\n",
      "[99]\tvalid_0's tweedie: 440.414\n",
      "[100]\tvalid_0's tweedie: 440.411\n",
      "[101]\tvalid_0's tweedie: 440.411\n",
      "[102]\tvalid_0's tweedie: 440.411\n",
      "[103]\tvalid_0's tweedie: 440.412\n",
      "[104]\tvalid_0's tweedie: 440.411\n",
      "[105]\tvalid_0's tweedie: 440.412\n",
      "[106]\tvalid_0's tweedie: 440.412\n",
      "[107]\tvalid_0's tweedie: 440.412\n",
      "[108]\tvalid_0's tweedie: 440.412\n",
      "[109]\tvalid_0's tweedie: 440.412\n",
      "[110]\tvalid_0's tweedie: 440.412\n",
      "[111]\tvalid_0's tweedie: 440.411\n",
      "[112]\tvalid_0's tweedie: 440.411\n",
      "[113]\tvalid_0's tweedie: 440.41\n",
      "[114]\tvalid_0's tweedie: 440.41\n",
      "[115]\tvalid_0's tweedie: 440.41\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's tweedie: 440.41\n",
      "Training model for level 4 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 5565, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345733\n",
      "[1]\tvalid_0's tweedie: 470.986\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.638\n",
      "[3]\tvalid_0's tweedie: 461.239\n",
      "[4]\tvalid_0's tweedie: 457.533\n",
      "[5]\tvalid_0's tweedie: 454.555\n",
      "[6]\tvalid_0's tweedie: 452.097\n",
      "[7]\tvalid_0's tweedie: 450.122\n",
      "[8]\tvalid_0's tweedie: 448.452\n",
      "[9]\tvalid_0's tweedie: 447.116\n",
      "[10]\tvalid_0's tweedie: 445.98\n",
      "[11]\tvalid_0's tweedie: 445.094\n",
      "[12]\tvalid_0's tweedie: 444.339\n",
      "[13]\tvalid_0's tweedie: 443.701\n",
      "[14]\tvalid_0's tweedie: 443.183\n",
      "[15]\tvalid_0's tweedie: 442.753\n",
      "[16]\tvalid_0's tweedie: 442.428\n",
      "[17]\tvalid_0's tweedie: 442.165\n",
      "[18]\tvalid_0's tweedie: 441.91\n",
      "[19]\tvalid_0's tweedie: 441.7\n",
      "[20]\tvalid_0's tweedie: 441.54\n",
      "[21]\tvalid_0's tweedie: 441.399\n",
      "[22]\tvalid_0's tweedie: 441.279\n",
      "[23]\tvalid_0's tweedie: 441.177\n",
      "[24]\tvalid_0's tweedie: 441.1\n",
      "[25]\tvalid_0's tweedie: 441.02\n",
      "[26]\tvalid_0's tweedie: 440.951\n",
      "[27]\tvalid_0's tweedie: 440.901\n",
      "[28]\tvalid_0's tweedie: 440.858\n",
      "[29]\tvalid_0's tweedie: 440.785\n",
      "[30]\tvalid_0's tweedie: 440.755\n",
      "[31]\tvalid_0's tweedie: 440.746\n",
      "[32]\tvalid_0's tweedie: 440.719\n",
      "[33]\tvalid_0's tweedie: 440.702\n",
      "[34]\tvalid_0's tweedie: 440.684\n",
      "[35]\tvalid_0's tweedie: 440.647\n",
      "[36]\tvalid_0's tweedie: 440.637\n",
      "[37]\tvalid_0's tweedie: 440.608\n",
      "[38]\tvalid_0's tweedie: 440.599\n",
      "[39]\tvalid_0's tweedie: 440.579\n",
      "[40]\tvalid_0's tweedie: 440.572\n",
      "[41]\tvalid_0's tweedie: 440.553\n",
      "[42]\tvalid_0's tweedie: 440.544\n",
      "[43]\tvalid_0's tweedie: 440.53\n",
      "[44]\tvalid_0's tweedie: 440.525\n",
      "[45]\tvalid_0's tweedie: 440.522\n",
      "[46]\tvalid_0's tweedie: 440.519\n",
      "[47]\tvalid_0's tweedie: 440.509\n",
      "[48]\tvalid_0's tweedie: 440.504\n",
      "[49]\tvalid_0's tweedie: 440.498\n",
      "[50]\tvalid_0's tweedie: 440.497\n",
      "[51]\tvalid_0's tweedie: 440.496\n",
      "[52]\tvalid_0's tweedie: 440.492\n",
      "[53]\tvalid_0's tweedie: 440.488\n",
      "[54]\tvalid_0's tweedie: 440.49\n",
      "[55]\tvalid_0's tweedie: 440.489\n",
      "[56]\tvalid_0's tweedie: 440.484\n",
      "[57]\tvalid_0's tweedie: 440.477\n",
      "[58]\tvalid_0's tweedie: 440.472\n",
      "[59]\tvalid_0's tweedie: 440.471\n",
      "[60]\tvalid_0's tweedie: 440.472\n",
      "[61]\tvalid_0's tweedie: 440.468\n",
      "[62]\tvalid_0's tweedie: 440.462\n",
      "[63]\tvalid_0's tweedie: 440.453\n",
      "[64]\tvalid_0's tweedie: 440.453\n",
      "[65]\tvalid_0's tweedie: 440.452\n",
      "[66]\tvalid_0's tweedie: 440.451\n",
      "[67]\tvalid_0's tweedie: 440.45\n",
      "[68]\tvalid_0's tweedie: 440.449\n",
      "[69]\tvalid_0's tweedie: 440.447\n",
      "[70]\tvalid_0's tweedie: 440.447\n",
      "[71]\tvalid_0's tweedie: 440.449\n",
      "[72]\tvalid_0's tweedie: 440.447\n",
      "[73]\tvalid_0's tweedie: 440.449\n",
      "[74]\tvalid_0's tweedie: 440.449\n",
      "[75]\tvalid_0's tweedie: 440.447\n",
      "[76]\tvalid_0's tweedie: 440.448\n",
      "[77]\tvalid_0's tweedie: 440.446\n",
      "[78]\tvalid_0's tweedie: 440.444\n",
      "[79]\tvalid_0's tweedie: 440.443\n",
      "[80]\tvalid_0's tweedie: 440.442\n",
      "[81]\tvalid_0's tweedie: 440.441\n",
      "[82]\tvalid_0's tweedie: 440.444\n",
      "[83]\tvalid_0's tweedie: 440.444\n",
      "[84]\tvalid_0's tweedie: 440.442\n",
      "[85]\tvalid_0's tweedie: 440.442\n",
      "[86]\tvalid_0's tweedie: 440.439\n",
      "[87]\tvalid_0's tweedie: 440.439\n",
      "[88]\tvalid_0's tweedie: 440.439\n",
      "[89]\tvalid_0's tweedie: 440.437\n",
      "[90]\tvalid_0's tweedie: 440.437\n",
      "[91]\tvalid_0's tweedie: 440.44\n",
      "[92]\tvalid_0's tweedie: 440.44\n",
      "[93]\tvalid_0's tweedie: 440.441\n",
      "[94]\tvalid_0's tweedie: 440.441\n",
      "[95]\tvalid_0's tweedie: 440.439\n",
      "[96]\tvalid_0's tweedie: 440.439\n",
      "[97]\tvalid_0's tweedie: 440.439\n",
      "[98]\tvalid_0's tweedie: 440.439\n",
      "[99]\tvalid_0's tweedie: 440.44\n",
      "[100]\tvalid_0's tweedie: 440.439\n",
      "[101]\tvalid_0's tweedie: 440.438\n",
      "[102]\tvalid_0's tweedie: 440.44\n",
      "[103]\tvalid_0's tweedie: 440.439\n",
      "[104]\tvalid_0's tweedie: 440.438\n",
      "[105]\tvalid_0's tweedie: 440.437\n",
      "[106]\tvalid_0's tweedie: 440.437\n",
      "[107]\tvalid_0's tweedie: 440.437\n",
      "[108]\tvalid_0's tweedie: 440.435\n",
      "[109]\tvalid_0's tweedie: 440.434\n",
      "[110]\tvalid_0's tweedie: 440.434\n",
      "[111]\tvalid_0's tweedie: 440.434\n",
      "[112]\tvalid_0's tweedie: 440.435\n",
      "[113]\tvalid_0's tweedie: 440.434\n",
      "[114]\tvalid_0's tweedie: 440.435\n",
      "[115]\tvalid_0's tweedie: 440.434\n",
      "[116]\tvalid_0's tweedie: 440.434\n",
      "[117]\tvalid_0's tweedie: 440.434\n",
      "[118]\tvalid_0's tweedie: 440.431\n",
      "[119]\tvalid_0's tweedie: 440.432\n",
      "[120]\tvalid_0's tweedie: 440.432\n",
      "[121]\tvalid_0's tweedie: 440.432\n",
      "[122]\tvalid_0's tweedie: 440.434\n",
      "[123]\tvalid_0's tweedie: 440.434\n",
      "[124]\tvalid_0's tweedie: 440.433\n",
      "[125]\tvalid_0's tweedie: 440.432\n",
      "[126]\tvalid_0's tweedie: 440.431\n",
      "[127]\tvalid_0's tweedie: 440.431\n",
      "[128]\tvalid_0's tweedie: 440.431\n",
      "[129]\tvalid_0's tweedie: 440.43\n",
      "[130]\tvalid_0's tweedie: 440.431\n",
      "[131]\tvalid_0's tweedie: 440.433\n",
      "[132]\tvalid_0's tweedie: 440.433\n",
      "[133]\tvalid_0's tweedie: 440.43\n",
      "[134]\tvalid_0's tweedie: 440.431\n",
      "[135]\tvalid_0's tweedie: 440.431\n",
      "[136]\tvalid_0's tweedie: 440.43\n",
      "[137]\tvalid_0's tweedie: 440.43\n",
      "[138]\tvalid_0's tweedie: 440.43\n",
      "[139]\tvalid_0's tweedie: 440.43\n",
      "[140]\tvalid_0's tweedie: 440.43\n",
      "[141]\tvalid_0's tweedie: 440.429\n",
      "[142]\tvalid_0's tweedie: 440.429\n",
      "[143]\tvalid_0's tweedie: 440.429\n",
      "[144]\tvalid_0's tweedie: 440.428\n",
      "[145]\tvalid_0's tweedie: 440.427\n",
      "[146]\tvalid_0's tweedie: 440.427\n",
      "[147]\tvalid_0's tweedie: 440.429\n",
      "[148]\tvalid_0's tweedie: 440.429\n",
      "[149]\tvalid_0's tweedie: 440.428\n",
      "[150]\tvalid_0's tweedie: 440.427\n",
      "[151]\tvalid_0's tweedie: 440.427\n",
      "[152]\tvalid_0's tweedie: 440.427\n",
      "[153]\tvalid_0's tweedie: 440.428\n",
      "[154]\tvalid_0's tweedie: 440.428\n",
      "[155]\tvalid_0's tweedie: 440.429\n",
      "[156]\tvalid_0's tweedie: 440.429\n",
      "[157]\tvalid_0's tweedie: 440.429\n",
      "[158]\tvalid_0's tweedie: 440.43\n",
      "[159]\tvalid_0's tweedie: 440.428\n",
      "[160]\tvalid_0's tweedie: 440.428\n",
      "[161]\tvalid_0's tweedie: 440.428\n",
      "[162]\tvalid_0's tweedie: 440.428\n",
      "[163]\tvalid_0's tweedie: 440.427\n",
      "[164]\tvalid_0's tweedie: 440.424\n",
      "[165]\tvalid_0's tweedie: 440.424\n",
      "[166]\tvalid_0's tweedie: 440.424\n",
      "[167]\tvalid_0's tweedie: 440.423\n",
      "[168]\tvalid_0's tweedie: 440.423\n",
      "[169]\tvalid_0's tweedie: 440.423\n",
      "[170]\tvalid_0's tweedie: 440.423\n",
      "[171]\tvalid_0's tweedie: 440.423\n",
      "[172]\tvalid_0's tweedie: 440.423\n",
      "[173]\tvalid_0's tweedie: 440.423\n",
      "[174]\tvalid_0's tweedie: 440.423\n",
      "[175]\tvalid_0's tweedie: 440.423\n",
      "[176]\tvalid_0's tweedie: 440.424\n",
      "[177]\tvalid_0's tweedie: 440.424\n",
      "[178]\tvalid_0's tweedie: 440.424\n",
      "[179]\tvalid_0's tweedie: 440.424\n",
      "[180]\tvalid_0's tweedie: 440.424\n",
      "[181]\tvalid_0's tweedie: 440.424\n",
      "[182]\tvalid_0's tweedie: 440.425\n",
      "[183]\tvalid_0's tweedie: 440.424\n",
      "[184]\tvalid_0's tweedie: 440.426\n",
      "[185]\tvalid_0's tweedie: 440.426\n",
      "[186]\tvalid_0's tweedie: 440.426\n",
      "[187]\tvalid_0's tweedie: 440.426\n",
      "[188]\tvalid_0's tweedie: 440.426\n",
      "[189]\tvalid_0's tweedie: 440.426\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's tweedie: 440.423\n",
      "Training model for level 4 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 5562, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.345939\n",
      "[1]\tvalid_0's tweedie: 470.972\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.626\n",
      "[3]\tvalid_0's tweedie: 461.234\n",
      "[4]\tvalid_0's tweedie: 457.636\n",
      "[5]\tvalid_0's tweedie: 454.597\n",
      "[6]\tvalid_0's tweedie: 452.156\n",
      "[7]\tvalid_0's tweedie: 450.114\n",
      "[8]\tvalid_0's tweedie: 448.445\n",
      "[9]\tvalid_0's tweedie: 447.126\n",
      "[10]\tvalid_0's tweedie: 445.975\n",
      "[11]\tvalid_0's tweedie: 445.077\n",
      "[12]\tvalid_0's tweedie: 444.3\n",
      "[13]\tvalid_0's tweedie: 443.667\n",
      "[14]\tvalid_0's tweedie: 443.172\n",
      "[15]\tvalid_0's tweedie: 442.763\n",
      "[16]\tvalid_0's tweedie: 442.405\n",
      "[17]\tvalid_0's tweedie: 442.114\n",
      "[18]\tvalid_0's tweedie: 441.861\n",
      "[19]\tvalid_0's tweedie: 441.655\n",
      "[20]\tvalid_0's tweedie: 441.476\n",
      "[21]\tvalid_0's tweedie: 441.335\n",
      "[22]\tvalid_0's tweedie: 441.224\n",
      "[23]\tvalid_0's tweedie: 441.128\n",
      "[24]\tvalid_0's tweedie: 441.054\n",
      "[25]\tvalid_0's tweedie: 440.997\n",
      "[26]\tvalid_0's tweedie: 440.898\n",
      "[27]\tvalid_0's tweedie: 440.816\n",
      "[28]\tvalid_0's tweedie: 440.774\n",
      "[29]\tvalid_0's tweedie: 440.732\n",
      "[30]\tvalid_0's tweedie: 440.702\n",
      "[31]\tvalid_0's tweedie: 440.679\n",
      "[32]\tvalid_0's tweedie: 440.664\n",
      "[33]\tvalid_0's tweedie: 440.646\n",
      "[34]\tvalid_0's tweedie: 440.631\n",
      "[35]\tvalid_0's tweedie: 440.631\n",
      "[36]\tvalid_0's tweedie: 440.598\n",
      "[37]\tvalid_0's tweedie: 440.571\n",
      "[38]\tvalid_0's tweedie: 440.547\n",
      "[39]\tvalid_0's tweedie: 440.54\n",
      "[40]\tvalid_0's tweedie: 440.524\n",
      "[41]\tvalid_0's tweedie: 440.52\n",
      "[42]\tvalid_0's tweedie: 440.508\n",
      "[43]\tvalid_0's tweedie: 440.502\n",
      "[44]\tvalid_0's tweedie: 440.49\n",
      "[45]\tvalid_0's tweedie: 440.484\n",
      "[46]\tvalid_0's tweedie: 440.476\n",
      "[47]\tvalid_0's tweedie: 440.473\n",
      "[48]\tvalid_0's tweedie: 440.47\n",
      "[49]\tvalid_0's tweedie: 440.468\n",
      "[50]\tvalid_0's tweedie: 440.464\n",
      "[51]\tvalid_0's tweedie: 440.464\n",
      "[52]\tvalid_0's tweedie: 440.457\n",
      "[53]\tvalid_0's tweedie: 440.455\n",
      "[54]\tvalid_0's tweedie: 440.448\n",
      "[55]\tvalid_0's tweedie: 440.444\n",
      "[56]\tvalid_0's tweedie: 440.443\n",
      "[57]\tvalid_0's tweedie: 440.447\n",
      "[58]\tvalid_0's tweedie: 440.44\n",
      "[59]\tvalid_0's tweedie: 440.436\n",
      "[60]\tvalid_0's tweedie: 440.434\n",
      "[61]\tvalid_0's tweedie: 440.432\n",
      "[62]\tvalid_0's tweedie: 440.431\n",
      "[63]\tvalid_0's tweedie: 440.427\n",
      "[64]\tvalid_0's tweedie: 440.427\n",
      "[65]\tvalid_0's tweedie: 440.423\n",
      "[66]\tvalid_0's tweedie: 440.421\n",
      "[67]\tvalid_0's tweedie: 440.418\n",
      "[68]\tvalid_0's tweedie: 440.417\n",
      "[69]\tvalid_0's tweedie: 440.416\n",
      "[70]\tvalid_0's tweedie: 440.416\n",
      "[71]\tvalid_0's tweedie: 440.416\n",
      "[72]\tvalid_0's tweedie: 440.413\n",
      "[73]\tvalid_0's tweedie: 440.408\n",
      "[74]\tvalid_0's tweedie: 440.407\n",
      "[75]\tvalid_0's tweedie: 440.403\n",
      "[76]\tvalid_0's tweedie: 440.402\n",
      "[77]\tvalid_0's tweedie: 440.402\n",
      "[78]\tvalid_0's tweedie: 440.402\n",
      "[79]\tvalid_0's tweedie: 440.4\n",
      "[80]\tvalid_0's tweedie: 440.402\n",
      "[81]\tvalid_0's tweedie: 440.402\n",
      "[82]\tvalid_0's tweedie: 440.402\n",
      "[83]\tvalid_0's tweedie: 440.402\n",
      "[84]\tvalid_0's tweedie: 440.399\n",
      "[85]\tvalid_0's tweedie: 440.399\n",
      "[86]\tvalid_0's tweedie: 440.396\n",
      "[87]\tvalid_0's tweedie: 440.396\n",
      "[88]\tvalid_0's tweedie: 440.392\n",
      "[89]\tvalid_0's tweedie: 440.393\n",
      "[90]\tvalid_0's tweedie: 440.391\n",
      "[91]\tvalid_0's tweedie: 440.391\n",
      "[92]\tvalid_0's tweedie: 440.39\n",
      "[93]\tvalid_0's tweedie: 440.39\n",
      "[94]\tvalid_0's tweedie: 440.389\n",
      "[95]\tvalid_0's tweedie: 440.389\n",
      "[96]\tvalid_0's tweedie: 440.388\n",
      "[97]\tvalid_0's tweedie: 440.388\n",
      "[98]\tvalid_0's tweedie: 440.389\n",
      "[99]\tvalid_0's tweedie: 440.388\n",
      "[100]\tvalid_0's tweedie: 440.388\n",
      "[101]\tvalid_0's tweedie: 440.388\n",
      "[102]\tvalid_0's tweedie: 440.387\n",
      "[103]\tvalid_0's tweedie: 440.389\n",
      "[104]\tvalid_0's tweedie: 440.388\n",
      "[105]\tvalid_0's tweedie: 440.389\n",
      "[106]\tvalid_0's tweedie: 440.389\n",
      "[107]\tvalid_0's tweedie: 440.388\n",
      "[108]\tvalid_0's tweedie: 440.388\n",
      "[109]\tvalid_0's tweedie: 440.388\n",
      "[110]\tvalid_0's tweedie: 440.388\n",
      "[111]\tvalid_0's tweedie: 440.387\n",
      "[112]\tvalid_0's tweedie: 440.387\n",
      "[113]\tvalid_0's tweedie: 440.387\n",
      "[114]\tvalid_0's tweedie: 440.388\n",
      "[115]\tvalid_0's tweedie: 440.388\n",
      "[116]\tvalid_0's tweedie: 440.388\n",
      "[117]\tvalid_0's tweedie: 440.388\n",
      "[118]\tvalid_0's tweedie: 440.388\n",
      "[119]\tvalid_0's tweedie: 440.388\n",
      "[120]\tvalid_0's tweedie: 440.388\n",
      "[121]\tvalid_0's tweedie: 440.388\n",
      "[122]\tvalid_0's tweedie: 440.387\n",
      "[123]\tvalid_0's tweedie: 440.387\n",
      "[124]\tvalid_0's tweedie: 440.388\n",
      "[125]\tvalid_0's tweedie: 440.389\n",
      "[126]\tvalid_0's tweedie: 440.389\n",
      "[127]\tvalid_0's tweedie: 440.388\n",
      "[128]\tvalid_0's tweedie: 440.389\n",
      "[129]\tvalid_0's tweedie: 440.389\n",
      "[130]\tvalid_0's tweedie: 440.389\n",
      "[131]\tvalid_0's tweedie: 440.39\n",
      "[132]\tvalid_0's tweedie: 440.39\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's tweedie: 440.387\n",
      "Training model for level 4 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 5559, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346119\n",
      "[1]\tvalid_0's tweedie: 470.951\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.594\n",
      "[3]\tvalid_0's tweedie: 461.236\n",
      "[4]\tvalid_0's tweedie: 457.625\n",
      "[5]\tvalid_0's tweedie: 454.606\n",
      "[6]\tvalid_0's tweedie: 452.09\n",
      "[7]\tvalid_0's tweedie: 450.076\n",
      "[8]\tvalid_0's tweedie: 448.507\n",
      "[9]\tvalid_0's tweedie: 447.118\n",
      "[10]\tvalid_0's tweedie: 445.976\n",
      "[11]\tvalid_0's tweedie: 445.045\n",
      "[12]\tvalid_0's tweedie: 444.281\n",
      "[13]\tvalid_0's tweedie: 443.634\n",
      "[14]\tvalid_0's tweedie: 443.13\n",
      "[15]\tvalid_0's tweedie: 442.714\n",
      "[16]\tvalid_0's tweedie: 442.362\n",
      "[17]\tvalid_0's tweedie: 442.074\n",
      "[18]\tvalid_0's tweedie: 441.808\n",
      "[19]\tvalid_0's tweedie: 441.608\n",
      "[20]\tvalid_0's tweedie: 441.438\n",
      "[21]\tvalid_0's tweedie: 441.301\n",
      "[22]\tvalid_0's tweedie: 441.2\n",
      "[23]\tvalid_0's tweedie: 441.11\n",
      "[24]\tvalid_0's tweedie: 441.032\n",
      "[25]\tvalid_0's tweedie: 440.954\n",
      "[26]\tvalid_0's tweedie: 440.853\n",
      "[27]\tvalid_0's tweedie: 440.801\n",
      "[28]\tvalid_0's tweedie: 440.755\n",
      "[29]\tvalid_0's tweedie: 440.724\n",
      "[30]\tvalid_0's tweedie: 440.699\n",
      "[31]\tvalid_0's tweedie: 440.675\n",
      "[32]\tvalid_0's tweedie: 440.654\n",
      "[33]\tvalid_0's tweedie: 440.611\n",
      "[34]\tvalid_0's tweedie: 440.598\n",
      "[35]\tvalid_0's tweedie: 440.565\n",
      "[36]\tvalid_0's tweedie: 440.542\n",
      "[37]\tvalid_0's tweedie: 440.53\n",
      "[38]\tvalid_0's tweedie: 440.51\n",
      "[39]\tvalid_0's tweedie: 440.505\n",
      "[40]\tvalid_0's tweedie: 440.492\n",
      "[41]\tvalid_0's tweedie: 440.486\n",
      "[42]\tvalid_0's tweedie: 440.48\n",
      "[43]\tvalid_0's tweedie: 440.471\n",
      "[44]\tvalid_0's tweedie: 440.463\n",
      "[45]\tvalid_0's tweedie: 440.46\n",
      "[46]\tvalid_0's tweedie: 440.451\n",
      "[47]\tvalid_0's tweedie: 440.444\n",
      "[48]\tvalid_0's tweedie: 440.44\n",
      "[49]\tvalid_0's tweedie: 440.436\n",
      "[50]\tvalid_0's tweedie: 440.432\n",
      "[51]\tvalid_0's tweedie: 440.431\n",
      "[52]\tvalid_0's tweedie: 440.429\n",
      "[53]\tvalid_0's tweedie: 440.428\n",
      "[54]\tvalid_0's tweedie: 440.427\n",
      "[55]\tvalid_0's tweedie: 440.424\n",
      "[56]\tvalid_0's tweedie: 440.419\n",
      "[57]\tvalid_0's tweedie: 440.419\n",
      "[58]\tvalid_0's tweedie: 440.418\n",
      "[59]\tvalid_0's tweedie: 440.417\n",
      "[60]\tvalid_0's tweedie: 440.413\n",
      "[61]\tvalid_0's tweedie: 440.412\n",
      "[62]\tvalid_0's tweedie: 440.411\n",
      "[63]\tvalid_0's tweedie: 440.41\n",
      "[64]\tvalid_0's tweedie: 440.41\n",
      "[65]\tvalid_0's tweedie: 440.409\n",
      "[66]\tvalid_0's tweedie: 440.407\n",
      "[67]\tvalid_0's tweedie: 440.405\n",
      "[68]\tvalid_0's tweedie: 440.404\n",
      "[69]\tvalid_0's tweedie: 440.405\n",
      "[70]\tvalid_0's tweedie: 440.405\n",
      "[71]\tvalid_0's tweedie: 440.405\n",
      "[72]\tvalid_0's tweedie: 440.408\n",
      "[73]\tvalid_0's tweedie: 440.406\n",
      "[74]\tvalid_0's tweedie: 440.404\n",
      "[75]\tvalid_0's tweedie: 440.405\n",
      "[76]\tvalid_0's tweedie: 440.406\n",
      "[77]\tvalid_0's tweedie: 440.406\n",
      "[78]\tvalid_0's tweedie: 440.404\n",
      "[79]\tvalid_0's tweedie: 440.403\n",
      "[80]\tvalid_0's tweedie: 440.402\n",
      "[81]\tvalid_0's tweedie: 440.402\n",
      "[82]\tvalid_0's tweedie: 440.404\n",
      "[83]\tvalid_0's tweedie: 440.401\n",
      "[84]\tvalid_0's tweedie: 440.4\n",
      "[85]\tvalid_0's tweedie: 440.399\n",
      "[86]\tvalid_0's tweedie: 440.399\n",
      "[87]\tvalid_0's tweedie: 440.399\n",
      "[88]\tvalid_0's tweedie: 440.395\n",
      "[89]\tvalid_0's tweedie: 440.395\n",
      "[90]\tvalid_0's tweedie: 440.395\n",
      "[91]\tvalid_0's tweedie: 440.394\n",
      "[92]\tvalid_0's tweedie: 440.394\n",
      "[93]\tvalid_0's tweedie: 440.394\n",
      "[94]\tvalid_0's tweedie: 440.393\n",
      "[95]\tvalid_0's tweedie: 440.392\n",
      "[96]\tvalid_0's tweedie: 440.393\n",
      "[97]\tvalid_0's tweedie: 440.393\n",
      "[98]\tvalid_0's tweedie: 440.392\n",
      "[99]\tvalid_0's tweedie: 440.389\n",
      "[100]\tvalid_0's tweedie: 440.39\n",
      "[101]\tvalid_0's tweedie: 440.389\n",
      "[102]\tvalid_0's tweedie: 440.388\n",
      "[103]\tvalid_0's tweedie: 440.388\n",
      "[104]\tvalid_0's tweedie: 440.389\n",
      "[105]\tvalid_0's tweedie: 440.389\n",
      "[106]\tvalid_0's tweedie: 440.388\n",
      "[107]\tvalid_0's tweedie: 440.388\n",
      "[108]\tvalid_0's tweedie: 440.389\n",
      "[109]\tvalid_0's tweedie: 440.389\n",
      "[110]\tvalid_0's tweedie: 440.389\n",
      "[111]\tvalid_0's tweedie: 440.389\n",
      "[112]\tvalid_0's tweedie: 440.389\n",
      "[113]\tvalid_0's tweedie: 440.388\n",
      "[114]\tvalid_0's tweedie: 440.388\n",
      "[115]\tvalid_0's tweedie: 440.388\n",
      "[116]\tvalid_0's tweedie: 440.388\n",
      "[117]\tvalid_0's tweedie: 440.389\n",
      "[118]\tvalid_0's tweedie: 440.389\n",
      "[119]\tvalid_0's tweedie: 440.389\n",
      "[120]\tvalid_0's tweedie: 440.388\n",
      "[121]\tvalid_0's tweedie: 440.388\n",
      "[122]\tvalid_0's tweedie: 440.388\n",
      "[123]\tvalid_0's tweedie: 440.387\n",
      "[124]\tvalid_0's tweedie: 440.387\n",
      "[125]\tvalid_0's tweedie: 440.387\n",
      "[126]\tvalid_0's tweedie: 440.386\n",
      "[127]\tvalid_0's tweedie: 440.386\n",
      "[128]\tvalid_0's tweedie: 440.384\n",
      "[129]\tvalid_0's tweedie: 440.384\n",
      "[130]\tvalid_0's tweedie: 440.384\n",
      "[131]\tvalid_0's tweedie: 440.384\n",
      "[132]\tvalid_0's tweedie: 440.384\n",
      "[133]\tvalid_0's tweedie: 440.384\n",
      "[134]\tvalid_0's tweedie: 440.387\n",
      "[135]\tvalid_0's tweedie: 440.387\n",
      "[136]\tvalid_0's tweedie: 440.388\n",
      "[137]\tvalid_0's tweedie: 440.388\n",
      "[138]\tvalid_0's tweedie: 440.387\n",
      "[139]\tvalid_0's tweedie: 440.386\n",
      "[140]\tvalid_0's tweedie: 440.386\n",
      "[141]\tvalid_0's tweedie: 440.386\n",
      "[142]\tvalid_0's tweedie: 440.386\n",
      "[143]\tvalid_0's tweedie: 440.387\n",
      "[144]\tvalid_0's tweedie: 440.388\n",
      "[145]\tvalid_0's tweedie: 440.388\n",
      "[146]\tvalid_0's tweedie: 440.387\n",
      "[147]\tvalid_0's tweedie: 440.388\n",
      "[148]\tvalid_0's tweedie: 440.39\n",
      "[149]\tvalid_0's tweedie: 440.389\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's tweedie: 440.384\n",
      "Training model for level 4 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 5556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346313\n",
      "[1]\tvalid_0's tweedie: 470.947\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.59\n",
      "[3]\tvalid_0's tweedie: 461.233\n",
      "[4]\tvalid_0's tweedie: 457.616\n",
      "[5]\tvalid_0's tweedie: 454.601\n",
      "[6]\tvalid_0's tweedie: 452.09\n",
      "[7]\tvalid_0's tweedie: 450.113\n",
      "[8]\tvalid_0's tweedie: 448.437\n",
      "[9]\tvalid_0's tweedie: 447.058\n",
      "[10]\tvalid_0's tweedie: 445.926\n",
      "[11]\tvalid_0's tweedie: 445.048\n",
      "[12]\tvalid_0's tweedie: 444.267\n",
      "[13]\tvalid_0's tweedie: 443.652\n",
      "[14]\tvalid_0's tweedie: 443.147\n",
      "[15]\tvalid_0's tweedie: 442.744\n",
      "[16]\tvalid_0's tweedie: 442.386\n",
      "[17]\tvalid_0's tweedie: 442.082\n",
      "[18]\tvalid_0's tweedie: 441.849\n",
      "[19]\tvalid_0's tweedie: 441.641\n",
      "[20]\tvalid_0's tweedie: 441.471\n",
      "[21]\tvalid_0's tweedie: 441.328\n",
      "[22]\tvalid_0's tweedie: 441.209\n",
      "[23]\tvalid_0's tweedie: 441.107\n",
      "[24]\tvalid_0's tweedie: 441.022\n",
      "[25]\tvalid_0's tweedie: 440.935\n",
      "[26]\tvalid_0's tweedie: 440.874\n",
      "[27]\tvalid_0's tweedie: 440.835\n",
      "[28]\tvalid_0's tweedie: 440.793\n",
      "[29]\tvalid_0's tweedie: 440.759\n",
      "[30]\tvalid_0's tweedie: 440.724\n",
      "[31]\tvalid_0's tweedie: 440.699\n",
      "[32]\tvalid_0's tweedie: 440.644\n",
      "[33]\tvalid_0's tweedie: 440.632\n",
      "[34]\tvalid_0's tweedie: 440.619\n",
      "[35]\tvalid_0's tweedie: 440.616\n",
      "[36]\tvalid_0's tweedie: 440.581\n",
      "[37]\tvalid_0's tweedie: 440.55\n",
      "[38]\tvalid_0's tweedie: 440.531\n",
      "[39]\tvalid_0's tweedie: 440.51\n",
      "[40]\tvalid_0's tweedie: 440.501\n",
      "[41]\tvalid_0's tweedie: 440.493\n",
      "[42]\tvalid_0's tweedie: 440.486\n",
      "[43]\tvalid_0's tweedie: 440.471\n",
      "[44]\tvalid_0's tweedie: 440.461\n",
      "[45]\tvalid_0's tweedie: 440.451\n",
      "[46]\tvalid_0's tweedie: 440.445\n",
      "[47]\tvalid_0's tweedie: 440.44\n",
      "[48]\tvalid_0's tweedie: 440.442\n",
      "[49]\tvalid_0's tweedie: 440.439\n",
      "[50]\tvalid_0's tweedie: 440.435\n",
      "[51]\tvalid_0's tweedie: 440.43\n",
      "[52]\tvalid_0's tweedie: 440.428\n",
      "[53]\tvalid_0's tweedie: 440.426\n",
      "[54]\tvalid_0's tweedie: 440.424\n",
      "[55]\tvalid_0's tweedie: 440.425\n",
      "[56]\tvalid_0's tweedie: 440.425\n",
      "[57]\tvalid_0's tweedie: 440.424\n",
      "[58]\tvalid_0's tweedie: 440.42\n",
      "[59]\tvalid_0's tweedie: 440.419\n",
      "[60]\tvalid_0's tweedie: 440.419\n",
      "[61]\tvalid_0's tweedie: 440.415\n",
      "[62]\tvalid_0's tweedie: 440.414\n",
      "[63]\tvalid_0's tweedie: 440.415\n",
      "[64]\tvalid_0's tweedie: 440.411\n",
      "[65]\tvalid_0's tweedie: 440.409\n",
      "[66]\tvalid_0's tweedie: 440.406\n",
      "[67]\tvalid_0's tweedie: 440.406\n",
      "[68]\tvalid_0's tweedie: 440.41\n",
      "[69]\tvalid_0's tweedie: 440.41\n",
      "[70]\tvalid_0's tweedie: 440.41\n",
      "[71]\tvalid_0's tweedie: 440.411\n",
      "[72]\tvalid_0's tweedie: 440.411\n",
      "[73]\tvalid_0's tweedie: 440.41\n",
      "[74]\tvalid_0's tweedie: 440.41\n",
      "[75]\tvalid_0's tweedie: 440.41\n",
      "[76]\tvalid_0's tweedie: 440.41\n",
      "[77]\tvalid_0's tweedie: 440.41\n",
      "[78]\tvalid_0's tweedie: 440.41\n",
      "[79]\tvalid_0's tweedie: 440.409\n",
      "[80]\tvalid_0's tweedie: 440.408\n",
      "[81]\tvalid_0's tweedie: 440.41\n",
      "[82]\tvalid_0's tweedie: 440.41\n",
      "[83]\tvalid_0's tweedie: 440.41\n",
      "[84]\tvalid_0's tweedie: 440.409\n",
      "[85]\tvalid_0's tweedie: 440.409\n",
      "[86]\tvalid_0's tweedie: 440.406\n",
      "[87]\tvalid_0's tweedie: 440.404\n",
      "[88]\tvalid_0's tweedie: 440.403\n",
      "[89]\tvalid_0's tweedie: 440.402\n",
      "[90]\tvalid_0's tweedie: 440.402\n",
      "[91]\tvalid_0's tweedie: 440.403\n",
      "[92]\tvalid_0's tweedie: 440.403\n",
      "[93]\tvalid_0's tweedie: 440.404\n",
      "[94]\tvalid_0's tweedie: 440.404\n",
      "[95]\tvalid_0's tweedie: 440.403\n",
      "[96]\tvalid_0's tweedie: 440.404\n",
      "[97]\tvalid_0's tweedie: 440.401\n",
      "[98]\tvalid_0's tweedie: 440.401\n",
      "[99]\tvalid_0's tweedie: 440.4\n",
      "[100]\tvalid_0's tweedie: 440.399\n",
      "[101]\tvalid_0's tweedie: 440.402\n",
      "[102]\tvalid_0's tweedie: 440.402\n",
      "[103]\tvalid_0's tweedie: 440.402\n",
      "[104]\tvalid_0's tweedie: 440.402\n",
      "[105]\tvalid_0's tweedie: 440.402\n",
      "[106]\tvalid_0's tweedie: 440.4\n",
      "[107]\tvalid_0's tweedie: 440.4\n",
      "[108]\tvalid_0's tweedie: 440.4\n",
      "[109]\tvalid_0's tweedie: 440.4\n",
      "[110]\tvalid_0's tweedie: 440.4\n",
      "[111]\tvalid_0's tweedie: 440.4\n",
      "[112]\tvalid_0's tweedie: 440.4\n",
      "[113]\tvalid_0's tweedie: 440.402\n",
      "[114]\tvalid_0's tweedie: 440.402\n",
      "[115]\tvalid_0's tweedie: 440.402\n",
      "[116]\tvalid_0's tweedie: 440.402\n",
      "[117]\tvalid_0's tweedie: 440.402\n",
      "[118]\tvalid_0's tweedie: 440.401\n",
      "[119]\tvalid_0's tweedie: 440.401\n",
      "[120]\tvalid_0's tweedie: 440.401\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's tweedie: 440.399\n",
      "Training model for level 4 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5489\n",
      "[LightGBM] [Info] Number of data points in the train set: 5553, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346484\n",
      "[1]\tvalid_0's tweedie: 470.946\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.539\n",
      "[3]\tvalid_0's tweedie: 461.17\n",
      "[4]\tvalid_0's tweedie: 457.482\n",
      "[5]\tvalid_0's tweedie: 454.444\n",
      "[6]\tvalid_0's tweedie: 452.009\n",
      "[7]\tvalid_0's tweedie: 449.986\n",
      "[8]\tvalid_0's tweedie: 448.308\n",
      "[9]\tvalid_0's tweedie: 446.916\n",
      "[10]\tvalid_0's tweedie: 445.834\n",
      "[11]\tvalid_0's tweedie: 444.926\n",
      "[12]\tvalid_0's tweedie: 444.146\n",
      "[13]\tvalid_0's tweedie: 443.55\n",
      "[14]\tvalid_0's tweedie: 443.048\n",
      "[15]\tvalid_0's tweedie: 442.634\n",
      "[16]\tvalid_0's tweedie: 442.291\n",
      "[17]\tvalid_0's tweedie: 441.994\n",
      "[18]\tvalid_0's tweedie: 441.759\n",
      "[19]\tvalid_0's tweedie: 441.556\n",
      "[20]\tvalid_0's tweedie: 441.408\n",
      "[21]\tvalid_0's tweedie: 441.27\n",
      "[22]\tvalid_0's tweedie: 441.144\n",
      "[23]\tvalid_0's tweedie: 441.04\n",
      "[24]\tvalid_0's tweedie: 440.964\n",
      "[25]\tvalid_0's tweedie: 440.907\n",
      "[26]\tvalid_0's tweedie: 440.846\n",
      "[27]\tvalid_0's tweedie: 440.797\n",
      "[28]\tvalid_0's tweedie: 440.762\n",
      "[29]\tvalid_0's tweedie: 440.736\n",
      "[30]\tvalid_0's tweedie: 440.711\n",
      "[31]\tvalid_0's tweedie: 440.694\n",
      "[32]\tvalid_0's tweedie: 440.672\n",
      "[33]\tvalid_0's tweedie: 440.619\n",
      "[34]\tvalid_0's tweedie: 440.605\n",
      "[35]\tvalid_0's tweedie: 440.564\n",
      "[36]\tvalid_0's tweedie: 440.552\n",
      "[37]\tvalid_0's tweedie: 440.526\n",
      "[38]\tvalid_0's tweedie: 440.501\n",
      "[39]\tvalid_0's tweedie: 440.484\n",
      "[40]\tvalid_0's tweedie: 440.469\n",
      "[41]\tvalid_0's tweedie: 440.462\n",
      "[42]\tvalid_0's tweedie: 440.454\n",
      "[43]\tvalid_0's tweedie: 440.45\n",
      "[44]\tvalid_0's tweedie: 440.44\n",
      "[45]\tvalid_0's tweedie: 440.439\n",
      "[46]\tvalid_0's tweedie: 440.433\n",
      "[47]\tvalid_0's tweedie: 440.428\n",
      "[48]\tvalid_0's tweedie: 440.425\n",
      "[49]\tvalid_0's tweedie: 440.42\n",
      "[50]\tvalid_0's tweedie: 440.415\n",
      "[51]\tvalid_0's tweedie: 440.412\n",
      "[52]\tvalid_0's tweedie: 440.411\n",
      "[53]\tvalid_0's tweedie: 440.411\n",
      "[54]\tvalid_0's tweedie: 440.414\n",
      "[55]\tvalid_0's tweedie: 440.414\n",
      "[56]\tvalid_0's tweedie: 440.413\n",
      "[57]\tvalid_0's tweedie: 440.413\n",
      "[58]\tvalid_0's tweedie: 440.41\n",
      "[59]\tvalid_0's tweedie: 440.41\n",
      "[60]\tvalid_0's tweedie: 440.41\n",
      "[61]\tvalid_0's tweedie: 440.409\n",
      "[62]\tvalid_0's tweedie: 440.409\n",
      "[63]\tvalid_0's tweedie: 440.408\n",
      "[64]\tvalid_0's tweedie: 440.407\n",
      "[65]\tvalid_0's tweedie: 440.407\n",
      "[66]\tvalid_0's tweedie: 440.402\n",
      "[67]\tvalid_0's tweedie: 440.401\n",
      "[68]\tvalid_0's tweedie: 440.401\n",
      "[69]\tvalid_0's tweedie: 440.4\n",
      "[70]\tvalid_0's tweedie: 440.397\n",
      "[71]\tvalid_0's tweedie: 440.398\n",
      "[72]\tvalid_0's tweedie: 440.397\n",
      "[73]\tvalid_0's tweedie: 440.397\n",
      "[74]\tvalid_0's tweedie: 440.397\n",
      "[75]\tvalid_0's tweedie: 440.397\n",
      "[76]\tvalid_0's tweedie: 440.397\n",
      "[77]\tvalid_0's tweedie: 440.397\n",
      "[78]\tvalid_0's tweedie: 440.398\n",
      "[79]\tvalid_0's tweedie: 440.397\n",
      "[80]\tvalid_0's tweedie: 440.395\n",
      "[81]\tvalid_0's tweedie: 440.396\n",
      "[82]\tvalid_0's tweedie: 440.395\n",
      "[83]\tvalid_0's tweedie: 440.394\n",
      "[84]\tvalid_0's tweedie: 440.394\n",
      "[85]\tvalid_0's tweedie: 440.394\n",
      "[86]\tvalid_0's tweedie: 440.393\n",
      "[87]\tvalid_0's tweedie: 440.395\n",
      "[88]\tvalid_0's tweedie: 440.395\n",
      "[89]\tvalid_0's tweedie: 440.395\n",
      "[90]\tvalid_0's tweedie: 440.395\n",
      "[91]\tvalid_0's tweedie: 440.392\n",
      "[92]\tvalid_0's tweedie: 440.393\n",
      "[93]\tvalid_0's tweedie: 440.39\n",
      "[94]\tvalid_0's tweedie: 440.391\n",
      "[95]\tvalid_0's tweedie: 440.394\n",
      "[96]\tvalid_0's tweedie: 440.394\n",
      "[97]\tvalid_0's tweedie: 440.394\n",
      "[98]\tvalid_0's tweedie: 440.391\n",
      "[99]\tvalid_0's tweedie: 440.392\n",
      "[100]\tvalid_0's tweedie: 440.391\n",
      "[101]\tvalid_0's tweedie: 440.391\n",
      "[102]\tvalid_0's tweedie: 440.393\n",
      "[103]\tvalid_0's tweedie: 440.393\n",
      "[104]\tvalid_0's tweedie: 440.393\n",
      "[105]\tvalid_0's tweedie: 440.393\n",
      "[106]\tvalid_0's tweedie: 440.393\n",
      "[107]\tvalid_0's tweedie: 440.39\n",
      "[108]\tvalid_0's tweedie: 440.39\n",
      "[109]\tvalid_0's tweedie: 440.39\n",
      "[110]\tvalid_0's tweedie: 440.389\n",
      "[111]\tvalid_0's tweedie: 440.389\n",
      "[112]\tvalid_0's tweedie: 440.389\n",
      "[113]\tvalid_0's tweedie: 440.386\n",
      "[114]\tvalid_0's tweedie: 440.386\n",
      "[115]\tvalid_0's tweedie: 440.386\n",
      "[116]\tvalid_0's tweedie: 440.385\n",
      "[117]\tvalid_0's tweedie: 440.385\n",
      "[118]\tvalid_0's tweedie: 440.385\n",
      "[119]\tvalid_0's tweedie: 440.385\n",
      "[120]\tvalid_0's tweedie: 440.384\n",
      "[121]\tvalid_0's tweedie: 440.387\n",
      "[122]\tvalid_0's tweedie: 440.386\n",
      "[123]\tvalid_0's tweedie: 440.387\n",
      "[124]\tvalid_0's tweedie: 440.387\n",
      "[125]\tvalid_0's tweedie: 440.387\n",
      "[126]\tvalid_0's tweedie: 440.387\n",
      "[127]\tvalid_0's tweedie: 440.387\n",
      "[128]\tvalid_0's tweedie: 440.386\n",
      "[129]\tvalid_0's tweedie: 440.385\n",
      "[130]\tvalid_0's tweedie: 440.386\n",
      "[131]\tvalid_0's tweedie: 440.384\n",
      "[132]\tvalid_0's tweedie: 440.384\n",
      "[133]\tvalid_0's tweedie: 440.384\n",
      "[134]\tvalid_0's tweedie: 440.385\n",
      "[135]\tvalid_0's tweedie: 440.385\n",
      "[136]\tvalid_0's tweedie: 440.383\n",
      "[137]\tvalid_0's tweedie: 440.382\n",
      "[138]\tvalid_0's tweedie: 440.382\n",
      "[139]\tvalid_0's tweedie: 440.383\n",
      "[140]\tvalid_0's tweedie: 440.383\n",
      "[141]\tvalid_0's tweedie: 440.383\n",
      "[142]\tvalid_0's tweedie: 440.381\n",
      "[143]\tvalid_0's tweedie: 440.38\n",
      "[144]\tvalid_0's tweedie: 440.38\n",
      "[145]\tvalid_0's tweedie: 440.38\n",
      "[146]\tvalid_0's tweedie: 440.38\n",
      "[147]\tvalid_0's tweedie: 440.38\n",
      "[148]\tvalid_0's tweedie: 440.38\n",
      "[149]\tvalid_0's tweedie: 440.38\n",
      "[150]\tvalid_0's tweedie: 440.38\n",
      "[151]\tvalid_0's tweedie: 440.379\n",
      "[152]\tvalid_0's tweedie: 440.379\n",
      "[153]\tvalid_0's tweedie: 440.379\n",
      "[154]\tvalid_0's tweedie: 440.379\n",
      "[155]\tvalid_0's tweedie: 440.378\n",
      "[156]\tvalid_0's tweedie: 440.379\n",
      "[157]\tvalid_0's tweedie: 440.378\n",
      "[158]\tvalid_0's tweedie: 440.38\n",
      "[159]\tvalid_0's tweedie: 440.38\n",
      "[160]\tvalid_0's tweedie: 440.38\n",
      "[161]\tvalid_0's tweedie: 440.38\n",
      "[162]\tvalid_0's tweedie: 440.377\n",
      "[163]\tvalid_0's tweedie: 440.376\n",
      "[164]\tvalid_0's tweedie: 440.376\n",
      "[165]\tvalid_0's tweedie: 440.377\n",
      "[166]\tvalid_0's tweedie: 440.377\n",
      "[167]\tvalid_0's tweedie: 440.377\n",
      "[168]\tvalid_0's tweedie: 440.377\n",
      "[169]\tvalid_0's tweedie: 440.379\n",
      "[170]\tvalid_0's tweedie: 440.377\n",
      "[171]\tvalid_0's tweedie: 440.377\n",
      "[172]\tvalid_0's tweedie: 440.378\n",
      "[173]\tvalid_0's tweedie: 440.378\n",
      "[174]\tvalid_0's tweedie: 440.378\n",
      "[175]\tvalid_0's tweedie: 440.377\n",
      "[176]\tvalid_0's tweedie: 440.377\n",
      "[177]\tvalid_0's tweedie: 440.377\n",
      "[178]\tvalid_0's tweedie: 440.378\n",
      "[179]\tvalid_0's tweedie: 440.377\n",
      "[180]\tvalid_0's tweedie: 440.378\n",
      "[181]\tvalid_0's tweedie: 440.378\n",
      "[182]\tvalid_0's tweedie: 440.379\n",
      "[183]\tvalid_0's tweedie: 440.379\n",
      "[184]\tvalid_0's tweedie: 440.378\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's tweedie: 440.376\n",
      "Training model for level 4 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5488\n",
      "[LightGBM] [Info] Number of data points in the train set: 5550, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346654\n",
      "[1]\tvalid_0's tweedie: 470.953\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.586\n",
      "[3]\tvalid_0's tweedie: 461.115\n",
      "[4]\tvalid_0's tweedie: 457.493\n",
      "[5]\tvalid_0's tweedie: 454.525\n",
      "[6]\tvalid_0's tweedie: 451.993\n",
      "[7]\tvalid_0's tweedie: 449.907\n",
      "[8]\tvalid_0's tweedie: 448.239\n",
      "[9]\tvalid_0's tweedie: 446.904\n",
      "[10]\tvalid_0's tweedie: 445.8\n",
      "[11]\tvalid_0's tweedie: 444.877\n",
      "[12]\tvalid_0's tweedie: 444.113\n",
      "[13]\tvalid_0's tweedie: 443.537\n",
      "[14]\tvalid_0's tweedie: 443.044\n",
      "[15]\tvalid_0's tweedie: 442.619\n",
      "[16]\tvalid_0's tweedie: 442.27\n",
      "[17]\tvalid_0's tweedie: 442.005\n",
      "[18]\tvalid_0's tweedie: 441.769\n",
      "[19]\tvalid_0's tweedie: 441.575\n",
      "[20]\tvalid_0's tweedie: 441.41\n",
      "[21]\tvalid_0's tweedie: 441.27\n",
      "[22]\tvalid_0's tweedie: 441.159\n",
      "[23]\tvalid_0's tweedie: 441.066\n",
      "[24]\tvalid_0's tweedie: 440.983\n",
      "[25]\tvalid_0's tweedie: 440.913\n",
      "[26]\tvalid_0's tweedie: 440.867\n",
      "[27]\tvalid_0's tweedie: 440.783\n",
      "[28]\tvalid_0's tweedie: 440.74\n",
      "[29]\tvalid_0's tweedie: 440.709\n",
      "[30]\tvalid_0's tweedie: 440.681\n",
      "[31]\tvalid_0's tweedie: 440.655\n",
      "[32]\tvalid_0's tweedie: 440.636\n",
      "[33]\tvalid_0's tweedie: 440.618\n",
      "[34]\tvalid_0's tweedie: 440.581\n",
      "[35]\tvalid_0's tweedie: 440.57\n",
      "[36]\tvalid_0's tweedie: 440.56\n",
      "[37]\tvalid_0's tweedie: 440.532\n",
      "[38]\tvalid_0's tweedie: 440.513\n",
      "[39]\tvalid_0's tweedie: 440.496\n",
      "[40]\tvalid_0's tweedie: 440.489\n",
      "[41]\tvalid_0's tweedie: 440.474\n",
      "[42]\tvalid_0's tweedie: 440.463\n",
      "[43]\tvalid_0's tweedie: 440.46\n",
      "[44]\tvalid_0's tweedie: 440.451\n",
      "[45]\tvalid_0's tweedie: 440.447\n",
      "[46]\tvalid_0's tweedie: 440.443\n",
      "[47]\tvalid_0's tweedie: 440.436\n",
      "[48]\tvalid_0's tweedie: 440.432\n",
      "[49]\tvalid_0's tweedie: 440.429\n",
      "[50]\tvalid_0's tweedie: 440.425\n",
      "[51]\tvalid_0's tweedie: 440.419\n",
      "[52]\tvalid_0's tweedie: 440.417\n",
      "[53]\tvalid_0's tweedie: 440.418\n",
      "[54]\tvalid_0's tweedie: 440.417\n",
      "[55]\tvalid_0's tweedie: 440.415\n",
      "[56]\tvalid_0's tweedie: 440.414\n",
      "[57]\tvalid_0's tweedie: 440.412\n",
      "[58]\tvalid_0's tweedie: 440.408\n",
      "[59]\tvalid_0's tweedie: 440.408\n",
      "[60]\tvalid_0's tweedie: 440.407\n",
      "[61]\tvalid_0's tweedie: 440.402\n",
      "[62]\tvalid_0's tweedie: 440.4\n",
      "[63]\tvalid_0's tweedie: 440.397\n",
      "[64]\tvalid_0's tweedie: 440.398\n",
      "[65]\tvalid_0's tweedie: 440.398\n",
      "[66]\tvalid_0's tweedie: 440.398\n",
      "[67]\tvalid_0's tweedie: 440.398\n",
      "[68]\tvalid_0's tweedie: 440.399\n",
      "[69]\tvalid_0's tweedie: 440.398\n",
      "[70]\tvalid_0's tweedie: 440.399\n",
      "[71]\tvalid_0's tweedie: 440.395\n",
      "[72]\tvalid_0's tweedie: 440.395\n",
      "[73]\tvalid_0's tweedie: 440.395\n",
      "[74]\tvalid_0's tweedie: 440.395\n",
      "[75]\tvalid_0's tweedie: 440.394\n",
      "[76]\tvalid_0's tweedie: 440.395\n",
      "[77]\tvalid_0's tweedie: 440.394\n",
      "[78]\tvalid_0's tweedie: 440.392\n",
      "[79]\tvalid_0's tweedie: 440.392\n",
      "[80]\tvalid_0's tweedie: 440.387\n",
      "[81]\tvalid_0's tweedie: 440.388\n",
      "[82]\tvalid_0's tweedie: 440.387\n",
      "[83]\tvalid_0's tweedie: 440.388\n",
      "[84]\tvalid_0's tweedie: 440.386\n",
      "[85]\tvalid_0's tweedie: 440.387\n",
      "[86]\tvalid_0's tweedie: 440.387\n",
      "[87]\tvalid_0's tweedie: 440.386\n",
      "[88]\tvalid_0's tweedie: 440.386\n",
      "[89]\tvalid_0's tweedie: 440.386\n",
      "[90]\tvalid_0's tweedie: 440.385\n",
      "[91]\tvalid_0's tweedie: 440.383\n",
      "[92]\tvalid_0's tweedie: 440.385\n",
      "[93]\tvalid_0's tweedie: 440.384\n",
      "[94]\tvalid_0's tweedie: 440.383\n",
      "[95]\tvalid_0's tweedie: 440.383\n",
      "[96]\tvalid_0's tweedie: 440.383\n",
      "[97]\tvalid_0's tweedie: 440.383\n",
      "[98]\tvalid_0's tweedie: 440.383\n",
      "[99]\tvalid_0's tweedie: 440.383\n",
      "[100]\tvalid_0's tweedie: 440.383\n",
      "[101]\tvalid_0's tweedie: 440.382\n",
      "[102]\tvalid_0's tweedie: 440.382\n",
      "[103]\tvalid_0's tweedie: 440.382\n",
      "[104]\tvalid_0's tweedie: 440.382\n",
      "[105]\tvalid_0's tweedie: 440.386\n",
      "[106]\tvalid_0's tweedie: 440.386\n",
      "[107]\tvalid_0's tweedie: 440.386\n",
      "[108]\tvalid_0's tweedie: 440.385\n",
      "[109]\tvalid_0's tweedie: 440.385\n",
      "[110]\tvalid_0's tweedie: 440.385\n",
      "[111]\tvalid_0's tweedie: 440.385\n",
      "[112]\tvalid_0's tweedie: 440.385\n",
      "[113]\tvalid_0's tweedie: 440.384\n",
      "[114]\tvalid_0's tweedie: 440.384\n",
      "[115]\tvalid_0's tweedie: 440.384\n",
      "[116]\tvalid_0's tweedie: 440.385\n",
      "[117]\tvalid_0's tweedie: 440.385\n",
      "[118]\tvalid_0's tweedie: 440.385\n",
      "[119]\tvalid_0's tweedie: 440.384\n",
      "[120]\tvalid_0's tweedie: 440.384\n",
      "[121]\tvalid_0's tweedie: 440.384\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's tweedie: 440.382\n",
      "Training model for level 4 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5487\n",
      "[LightGBM] [Info] Number of data points in the train set: 5547, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346704\n",
      "[1]\tvalid_0's tweedie: 470.941\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.589\n",
      "[3]\tvalid_0's tweedie: 461.083\n",
      "[4]\tvalid_0's tweedie: 457.479\n",
      "[5]\tvalid_0's tweedie: 454.511\n",
      "[6]\tvalid_0's tweedie: 452.018\n",
      "[7]\tvalid_0's tweedie: 449.978\n",
      "[8]\tvalid_0's tweedie: 448.285\n",
      "[9]\tvalid_0's tweedie: 446.917\n",
      "[10]\tvalid_0's tweedie: 445.804\n",
      "[11]\tvalid_0's tweedie: 444.87\n",
      "[12]\tvalid_0's tweedie: 444.154\n",
      "[13]\tvalid_0's tweedie: 443.521\n",
      "[14]\tvalid_0's tweedie: 443.053\n",
      "[15]\tvalid_0's tweedie: 442.64\n",
      "[16]\tvalid_0's tweedie: 442.293\n",
      "[17]\tvalid_0's tweedie: 442.017\n",
      "[18]\tvalid_0's tweedie: 441.777\n",
      "[19]\tvalid_0's tweedie: 441.588\n",
      "[20]\tvalid_0's tweedie: 441.431\n",
      "[21]\tvalid_0's tweedie: 441.333\n",
      "[22]\tvalid_0's tweedie: 441.196\n",
      "[23]\tvalid_0's tweedie: 441.114\n",
      "[24]\tvalid_0's tweedie: 441.032\n",
      "[25]\tvalid_0's tweedie: 440.961\n",
      "[26]\tvalid_0's tweedie: 440.908\n",
      "[27]\tvalid_0's tweedie: 440.854\n",
      "[28]\tvalid_0's tweedie: 440.811\n",
      "[29]\tvalid_0's tweedie: 440.778\n",
      "[30]\tvalid_0's tweedie: 440.753\n",
      "[31]\tvalid_0's tweedie: 440.73\n",
      "[32]\tvalid_0's tweedie: 440.673\n",
      "[33]\tvalid_0's tweedie: 440.655\n",
      "[34]\tvalid_0's tweedie: 440.612\n",
      "[35]\tvalid_0's tweedie: 440.575\n",
      "[36]\tvalid_0's tweedie: 440.55\n",
      "[37]\tvalid_0's tweedie: 440.527\n",
      "[38]\tvalid_0's tweedie: 440.52\n",
      "[39]\tvalid_0's tweedie: 440.503\n",
      "[40]\tvalid_0's tweedie: 440.49\n",
      "[41]\tvalid_0's tweedie: 440.485\n",
      "[42]\tvalid_0's tweedie: 440.479\n",
      "[43]\tvalid_0's tweedie: 440.466\n",
      "[44]\tvalid_0's tweedie: 440.455\n",
      "[45]\tvalid_0's tweedie: 440.448\n",
      "[46]\tvalid_0's tweedie: 440.444\n",
      "[47]\tvalid_0's tweedie: 440.438\n",
      "[48]\tvalid_0's tweedie: 440.436\n",
      "[49]\tvalid_0's tweedie: 440.433\n",
      "[50]\tvalid_0's tweedie: 440.427\n",
      "[51]\tvalid_0's tweedie: 440.425\n",
      "[52]\tvalid_0's tweedie: 440.422\n",
      "[53]\tvalid_0's tweedie: 440.423\n",
      "[54]\tvalid_0's tweedie: 440.422\n",
      "[55]\tvalid_0's tweedie: 440.42\n",
      "[56]\tvalid_0's tweedie: 440.419\n",
      "[57]\tvalid_0's tweedie: 440.417\n",
      "[58]\tvalid_0's tweedie: 440.416\n",
      "[59]\tvalid_0's tweedie: 440.411\n",
      "[60]\tvalid_0's tweedie: 440.407\n",
      "[61]\tvalid_0's tweedie: 440.406\n",
      "[62]\tvalid_0's tweedie: 440.405\n",
      "[63]\tvalid_0's tweedie: 440.404\n",
      "[64]\tvalid_0's tweedie: 440.403\n",
      "[65]\tvalid_0's tweedie: 440.399\n",
      "[66]\tvalid_0's tweedie: 440.399\n",
      "[67]\tvalid_0's tweedie: 440.397\n",
      "[68]\tvalid_0's tweedie: 440.393\n",
      "[69]\tvalid_0's tweedie: 440.393\n",
      "[70]\tvalid_0's tweedie: 440.392\n",
      "[71]\tvalid_0's tweedie: 440.393\n",
      "[72]\tvalid_0's tweedie: 440.391\n",
      "[73]\tvalid_0's tweedie: 440.39\n",
      "[74]\tvalid_0's tweedie: 440.39\n",
      "[75]\tvalid_0's tweedie: 440.39\n",
      "[76]\tvalid_0's tweedie: 440.388\n",
      "[77]\tvalid_0's tweedie: 440.388\n",
      "[78]\tvalid_0's tweedie: 440.388\n",
      "[79]\tvalid_0's tweedie: 440.386\n",
      "[80]\tvalid_0's tweedie: 440.386\n",
      "[81]\tvalid_0's tweedie: 440.386\n",
      "[82]\tvalid_0's tweedie: 440.386\n",
      "[83]\tvalid_0's tweedie: 440.383\n",
      "[84]\tvalid_0's tweedie: 440.383\n",
      "[85]\tvalid_0's tweedie: 440.383\n",
      "[86]\tvalid_0's tweedie: 440.382\n",
      "[87]\tvalid_0's tweedie: 440.382\n",
      "[88]\tvalid_0's tweedie: 440.382\n",
      "[89]\tvalid_0's tweedie: 440.38\n",
      "[90]\tvalid_0's tweedie: 440.38\n",
      "[91]\tvalid_0's tweedie: 440.381\n",
      "[92]\tvalid_0's tweedie: 440.381\n",
      "[93]\tvalid_0's tweedie: 440.381\n",
      "[94]\tvalid_0's tweedie: 440.379\n",
      "[95]\tvalid_0's tweedie: 440.38\n",
      "[96]\tvalid_0's tweedie: 440.378\n",
      "[97]\tvalid_0's tweedie: 440.379\n",
      "[98]\tvalid_0's tweedie: 440.378\n",
      "[99]\tvalid_0's tweedie: 440.379\n",
      "[100]\tvalid_0's tweedie: 440.38\n",
      "[101]\tvalid_0's tweedie: 440.382\n",
      "[102]\tvalid_0's tweedie: 440.381\n",
      "[103]\tvalid_0's tweedie: 440.381\n",
      "[104]\tvalid_0's tweedie: 440.381\n",
      "[105]\tvalid_0's tweedie: 440.381\n",
      "[106]\tvalid_0's tweedie: 440.381\n",
      "[107]\tvalid_0's tweedie: 440.38\n",
      "[108]\tvalid_0's tweedie: 440.38\n",
      "[109]\tvalid_0's tweedie: 440.379\n",
      "[110]\tvalid_0's tweedie: 440.379\n",
      "[111]\tvalid_0's tweedie: 440.378\n",
      "[112]\tvalid_0's tweedie: 440.377\n",
      "[113]\tvalid_0's tweedie: 440.378\n",
      "[114]\tvalid_0's tweedie: 440.377\n",
      "[115]\tvalid_0's tweedie: 440.377\n",
      "[116]\tvalid_0's tweedie: 440.377\n",
      "[117]\tvalid_0's tweedie: 440.377\n",
      "[118]\tvalid_0's tweedie: 440.377\n",
      "[119]\tvalid_0's tweedie: 440.378\n",
      "[120]\tvalid_0's tweedie: 440.378\n",
      "[121]\tvalid_0's tweedie: 440.376\n",
      "[122]\tvalid_0's tweedie: 440.376\n",
      "[123]\tvalid_0's tweedie: 440.376\n",
      "[124]\tvalid_0's tweedie: 440.376\n",
      "[125]\tvalid_0's tweedie: 440.377\n",
      "[126]\tvalid_0's tweedie: 440.376\n",
      "[127]\tvalid_0's tweedie: 440.375\n",
      "[128]\tvalid_0's tweedie: 440.375\n",
      "[129]\tvalid_0's tweedie: 440.375\n",
      "[130]\tvalid_0's tweedie: 440.376\n",
      "[131]\tvalid_0's tweedie: 440.375\n",
      "[132]\tvalid_0's tweedie: 440.375\n",
      "[133]\tvalid_0's tweedie: 440.374\n",
      "[134]\tvalid_0's tweedie: 440.374\n",
      "[135]\tvalid_0's tweedie: 440.373\n",
      "[136]\tvalid_0's tweedie: 440.372\n",
      "[137]\tvalid_0's tweedie: 440.372\n",
      "[138]\tvalid_0's tweedie: 440.372\n",
      "[139]\tvalid_0's tweedie: 440.372\n",
      "[140]\tvalid_0's tweedie: 440.372\n",
      "[141]\tvalid_0's tweedie: 440.372\n",
      "[142]\tvalid_0's tweedie: 440.372\n",
      "[143]\tvalid_0's tweedie: 440.372\n",
      "[144]\tvalid_0's tweedie: 440.373\n",
      "[145]\tvalid_0's tweedie: 440.373\n",
      "[146]\tvalid_0's tweedie: 440.372\n",
      "[147]\tvalid_0's tweedie: 440.372\n",
      "[148]\tvalid_0's tweedie: 440.372\n",
      "[149]\tvalid_0's tweedie: 440.372\n",
      "[150]\tvalid_0's tweedie: 440.372\n",
      "[151]\tvalid_0's tweedie: 440.372\n",
      "[152]\tvalid_0's tweedie: 440.372\n",
      "[153]\tvalid_0's tweedie: 440.372\n",
      "[154]\tvalid_0's tweedie: 440.372\n",
      "[155]\tvalid_0's tweedie: 440.372\n",
      "[156]\tvalid_0's tweedie: 440.371\n",
      "[157]\tvalid_0's tweedie: 440.37\n",
      "[158]\tvalid_0's tweedie: 440.371\n",
      "[159]\tvalid_0's tweedie: 440.37\n",
      "[160]\tvalid_0's tweedie: 440.37\n",
      "[161]\tvalid_0's tweedie: 440.37\n",
      "[162]\tvalid_0's tweedie: 440.37\n",
      "[163]\tvalid_0's tweedie: 440.369\n",
      "[164]\tvalid_0's tweedie: 440.369\n",
      "[165]\tvalid_0's tweedie: 440.369\n",
      "[166]\tvalid_0's tweedie: 440.369\n",
      "[167]\tvalid_0's tweedie: 440.369\n",
      "[168]\tvalid_0's tweedie: 440.37\n",
      "[169]\tvalid_0's tweedie: 440.37\n",
      "[170]\tvalid_0's tweedie: 440.37\n",
      "[171]\tvalid_0's tweedie: 440.37\n",
      "[172]\tvalid_0's tweedie: 440.37\n",
      "[173]\tvalid_0's tweedie: 440.37\n",
      "[174]\tvalid_0's tweedie: 440.37\n",
      "[175]\tvalid_0's tweedie: 440.37\n",
      "[176]\tvalid_0's tweedie: 440.37\n",
      "[177]\tvalid_0's tweedie: 440.37\n",
      "[178]\tvalid_0's tweedie: 440.37\n",
      "[179]\tvalid_0's tweedie: 440.37\n",
      "[180]\tvalid_0's tweedie: 440.37\n",
      "[181]\tvalid_0's tweedie: 440.371\n",
      "[182]\tvalid_0's tweedie: 440.371\n",
      "[183]\tvalid_0's tweedie: 440.371\n",
      "[184]\tvalid_0's tweedie: 440.371\n",
      "[185]\tvalid_0's tweedie: 440.371\n",
      "[186]\tvalid_0's tweedie: 440.371\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's tweedie: 440.369\n",
      "Training model for level 4 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5486\n",
      "[LightGBM] [Info] Number of data points in the train set: 5544, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346696\n",
      "[1]\tvalid_0's tweedie: 470.939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.57\n",
      "[3]\tvalid_0's tweedie: 461.11\n",
      "[4]\tvalid_0's tweedie: 457.379\n",
      "[5]\tvalid_0's tweedie: 454.424\n",
      "[6]\tvalid_0's tweedie: 451.948\n",
      "[7]\tvalid_0's tweedie: 449.966\n",
      "[8]\tvalid_0's tweedie: 448.294\n",
      "[9]\tvalid_0's tweedie: 446.934\n",
      "[10]\tvalid_0's tweedie: 445.818\n",
      "[11]\tvalid_0's tweedie: 444.881\n",
      "[12]\tvalid_0's tweedie: 444.129\n",
      "[13]\tvalid_0's tweedie: 443.536\n",
      "[14]\tvalid_0's tweedie: 443.026\n",
      "[15]\tvalid_0's tweedie: 442.618\n",
      "[16]\tvalid_0's tweedie: 442.269\n",
      "[17]\tvalid_0's tweedie: 441.993\n",
      "[18]\tvalid_0's tweedie: 441.775\n",
      "[19]\tvalid_0's tweedie: 441.583\n",
      "[20]\tvalid_0's tweedie: 441.424\n",
      "[21]\tvalid_0's tweedie: 441.292\n",
      "[22]\tvalid_0's tweedie: 441.177\n",
      "[23]\tvalid_0's tweedie: 441.077\n",
      "[24]\tvalid_0's tweedie: 441.008\n",
      "[25]\tvalid_0's tweedie: 440.952\n",
      "[26]\tvalid_0's tweedie: 440.888\n",
      "[27]\tvalid_0's tweedie: 440.844\n",
      "[28]\tvalid_0's tweedie: 440.799\n",
      "[29]\tvalid_0's tweedie: 440.757\n",
      "[30]\tvalid_0's tweedie: 440.73\n",
      "[31]\tvalid_0's tweedie: 440.668\n",
      "[32]\tvalid_0's tweedie: 440.616\n",
      "[33]\tvalid_0's tweedie: 440.599\n",
      "[34]\tvalid_0's tweedie: 440.561\n",
      "[35]\tvalid_0's tweedie: 440.546\n",
      "[36]\tvalid_0's tweedie: 440.523\n",
      "[37]\tvalid_0's tweedie: 440.497\n",
      "[38]\tvalid_0's tweedie: 440.48\n",
      "[39]\tvalid_0's tweedie: 440.468\n",
      "[40]\tvalid_0's tweedie: 440.462\n",
      "[41]\tvalid_0's tweedie: 440.459\n",
      "[42]\tvalid_0's tweedie: 440.449\n",
      "[43]\tvalid_0's tweedie: 440.443\n",
      "[44]\tvalid_0's tweedie: 440.439\n",
      "[45]\tvalid_0's tweedie: 440.433\n",
      "[46]\tvalid_0's tweedie: 440.426\n",
      "[47]\tvalid_0's tweedie: 440.423\n",
      "[48]\tvalid_0's tweedie: 440.415\n",
      "[49]\tvalid_0's tweedie: 440.413\n",
      "[50]\tvalid_0's tweedie: 440.41\n",
      "[51]\tvalid_0's tweedie: 440.408\n",
      "[52]\tvalid_0's tweedie: 440.406\n",
      "[53]\tvalid_0's tweedie: 440.396\n",
      "[54]\tvalid_0's tweedie: 440.392\n",
      "[55]\tvalid_0's tweedie: 440.391\n",
      "[56]\tvalid_0's tweedie: 440.391\n",
      "[57]\tvalid_0's tweedie: 440.387\n",
      "[58]\tvalid_0's tweedie: 440.388\n",
      "[59]\tvalid_0's tweedie: 440.387\n",
      "[60]\tvalid_0's tweedie: 440.383\n",
      "[61]\tvalid_0's tweedie: 440.382\n",
      "[62]\tvalid_0's tweedie: 440.381\n",
      "[63]\tvalid_0's tweedie: 440.378\n",
      "[64]\tvalid_0's tweedie: 440.375\n",
      "[65]\tvalid_0's tweedie: 440.374\n",
      "[66]\tvalid_0's tweedie: 440.374\n",
      "[67]\tvalid_0's tweedie: 440.374\n",
      "[68]\tvalid_0's tweedie: 440.374\n",
      "[69]\tvalid_0's tweedie: 440.373\n",
      "[70]\tvalid_0's tweedie: 440.371\n",
      "[71]\tvalid_0's tweedie: 440.37\n",
      "[72]\tvalid_0's tweedie: 440.37\n",
      "[73]\tvalid_0's tweedie: 440.369\n",
      "[74]\tvalid_0's tweedie: 440.37\n",
      "[75]\tvalid_0's tweedie: 440.37\n",
      "[76]\tvalid_0's tweedie: 440.37\n",
      "[77]\tvalid_0's tweedie: 440.367\n",
      "[78]\tvalid_0's tweedie: 440.367\n",
      "[79]\tvalid_0's tweedie: 440.366\n",
      "[80]\tvalid_0's tweedie: 440.365\n",
      "[81]\tvalid_0's tweedie: 440.367\n",
      "[82]\tvalid_0's tweedie: 440.366\n",
      "[83]\tvalid_0's tweedie: 440.367\n",
      "[84]\tvalid_0's tweedie: 440.367\n",
      "[85]\tvalid_0's tweedie: 440.367\n",
      "[86]\tvalid_0's tweedie: 440.368\n",
      "[87]\tvalid_0's tweedie: 440.368\n",
      "[88]\tvalid_0's tweedie: 440.368\n",
      "[89]\tvalid_0's tweedie: 440.367\n",
      "[90]\tvalid_0's tweedie: 440.367\n",
      "[91]\tvalid_0's tweedie: 440.367\n",
      "[92]\tvalid_0's tweedie: 440.367\n",
      "[93]\tvalid_0's tweedie: 440.366\n",
      "[94]\tvalid_0's tweedie: 440.365\n",
      "[95]\tvalid_0's tweedie: 440.365\n",
      "[96]\tvalid_0's tweedie: 440.365\n",
      "[97]\tvalid_0's tweedie: 440.365\n",
      "[98]\tvalid_0's tweedie: 440.365\n",
      "[99]\tvalid_0's tweedie: 440.365\n",
      "[100]\tvalid_0's tweedie: 440.365\n",
      "[101]\tvalid_0's tweedie: 440.364\n",
      "[102]\tvalid_0's tweedie: 440.365\n",
      "[103]\tvalid_0's tweedie: 440.364\n",
      "[104]\tvalid_0's tweedie: 440.364\n",
      "[105]\tvalid_0's tweedie: 440.364\n",
      "[106]\tvalid_0's tweedie: 440.364\n",
      "[107]\tvalid_0's tweedie: 440.364\n",
      "[108]\tvalid_0's tweedie: 440.364\n",
      "[109]\tvalid_0's tweedie: 440.363\n",
      "[110]\tvalid_0's tweedie: 440.361\n",
      "[111]\tvalid_0's tweedie: 440.361\n",
      "[112]\tvalid_0's tweedie: 440.361\n",
      "[113]\tvalid_0's tweedie: 440.36\n",
      "[114]\tvalid_0's tweedie: 440.361\n",
      "[115]\tvalid_0's tweedie: 440.36\n",
      "[116]\tvalid_0's tweedie: 440.36\n",
      "[117]\tvalid_0's tweedie: 440.36\n",
      "[118]\tvalid_0's tweedie: 440.36\n",
      "[119]\tvalid_0's tweedie: 440.36\n",
      "[120]\tvalid_0's tweedie: 440.359\n",
      "[121]\tvalid_0's tweedie: 440.359\n",
      "[122]\tvalid_0's tweedie: 440.358\n",
      "[123]\tvalid_0's tweedie: 440.357\n",
      "[124]\tvalid_0's tweedie: 440.357\n",
      "[125]\tvalid_0's tweedie: 440.357\n",
      "[126]\tvalid_0's tweedie: 440.357\n",
      "[127]\tvalid_0's tweedie: 440.357\n",
      "[128]\tvalid_0's tweedie: 440.357\n",
      "[129]\tvalid_0's tweedie: 440.356\n",
      "[130]\tvalid_0's tweedie: 440.357\n",
      "[131]\tvalid_0's tweedie: 440.356\n",
      "[132]\tvalid_0's tweedie: 440.356\n",
      "[133]\tvalid_0's tweedie: 440.355\n",
      "[134]\tvalid_0's tweedie: 440.354\n",
      "[135]\tvalid_0's tweedie: 440.354\n",
      "[136]\tvalid_0's tweedie: 440.354\n",
      "[137]\tvalid_0's tweedie: 440.354\n",
      "[138]\tvalid_0's tweedie: 440.354\n",
      "[139]\tvalid_0's tweedie: 440.354\n",
      "[140]\tvalid_0's tweedie: 440.353\n",
      "[141]\tvalid_0's tweedie: 440.353\n",
      "[142]\tvalid_0's tweedie: 440.353\n",
      "[143]\tvalid_0's tweedie: 440.353\n",
      "[144]\tvalid_0's tweedie: 440.353\n",
      "[145]\tvalid_0's tweedie: 440.353\n",
      "[146]\tvalid_0's tweedie: 440.352\n",
      "[147]\tvalid_0's tweedie: 440.352\n",
      "[148]\tvalid_0's tweedie: 440.351\n",
      "[149]\tvalid_0's tweedie: 440.351\n",
      "[150]\tvalid_0's tweedie: 440.352\n",
      "[151]\tvalid_0's tweedie: 440.351\n",
      "[152]\tvalid_0's tweedie: 440.351\n",
      "[153]\tvalid_0's tweedie: 440.351\n",
      "[154]\tvalid_0's tweedie: 440.35\n",
      "[155]\tvalid_0's tweedie: 440.35\n",
      "[156]\tvalid_0's tweedie: 440.35\n",
      "[157]\tvalid_0's tweedie: 440.351\n",
      "[158]\tvalid_0's tweedie: 440.35\n",
      "[159]\tvalid_0's tweedie: 440.35\n",
      "[160]\tvalid_0's tweedie: 440.352\n",
      "[161]\tvalid_0's tweedie: 440.351\n",
      "[162]\tvalid_0's tweedie: 440.351\n",
      "[163]\tvalid_0's tweedie: 440.351\n",
      "[164]\tvalid_0's tweedie: 440.35\n",
      "[165]\tvalid_0's tweedie: 440.35\n",
      "[166]\tvalid_0's tweedie: 440.351\n",
      "[167]\tvalid_0's tweedie: 440.35\n",
      "[168]\tvalid_0's tweedie: 440.35\n",
      "[169]\tvalid_0's tweedie: 440.35\n",
      "[170]\tvalid_0's tweedie: 440.349\n",
      "[171]\tvalid_0's tweedie: 440.349\n",
      "[172]\tvalid_0's tweedie: 440.349\n",
      "[173]\tvalid_0's tweedie: 440.349\n",
      "[174]\tvalid_0's tweedie: 440.348\n",
      "[175]\tvalid_0's tweedie: 440.348\n",
      "[176]\tvalid_0's tweedie: 440.348\n",
      "[177]\tvalid_0's tweedie: 440.348\n",
      "[178]\tvalid_0's tweedie: 440.348\n",
      "[179]\tvalid_0's tweedie: 440.349\n",
      "[180]\tvalid_0's tweedie: 440.348\n",
      "[181]\tvalid_0's tweedie: 440.347\n",
      "[182]\tvalid_0's tweedie: 440.348\n",
      "[183]\tvalid_0's tweedie: 440.348\n",
      "[184]\tvalid_0's tweedie: 440.348\n",
      "[185]\tvalid_0's tweedie: 440.348\n",
      "[186]\tvalid_0's tweedie: 440.348\n",
      "[187]\tvalid_0's tweedie: 440.348\n",
      "[188]\tvalid_0's tweedie: 440.348\n",
      "[189]\tvalid_0's tweedie: 440.348\n",
      "[190]\tvalid_0's tweedie: 440.347\n",
      "[191]\tvalid_0's tweedie: 440.347\n",
      "[192]\tvalid_0's tweedie: 440.347\n",
      "[193]\tvalid_0's tweedie: 440.348\n",
      "[194]\tvalid_0's tweedie: 440.348\n",
      "[195]\tvalid_0's tweedie: 440.347\n",
      "[196]\tvalid_0's tweedie: 440.347\n",
      "[197]\tvalid_0's tweedie: 440.348\n",
      "[198]\tvalid_0's tweedie: 440.347\n",
      "[199]\tvalid_0's tweedie: 440.347\n",
      "[200]\tvalid_0's tweedie: 440.348\n",
      "[201]\tvalid_0's tweedie: 440.347\n",
      "[202]\tvalid_0's tweedie: 440.347\n",
      "[203]\tvalid_0's tweedie: 440.347\n",
      "[204]\tvalid_0's tweedie: 440.347\n",
      "[205]\tvalid_0's tweedie: 440.347\n",
      "[206]\tvalid_0's tweedie: 440.348\n",
      "[207]\tvalid_0's tweedie: 440.348\n",
      "[208]\tvalid_0's tweedie: 440.347\n",
      "[209]\tvalid_0's tweedie: 440.347\n",
      "[210]\tvalid_0's tweedie: 440.347\n",
      "[211]\tvalid_0's tweedie: 440.346\n",
      "[212]\tvalid_0's tweedie: 440.346\n",
      "[213]\tvalid_0's tweedie: 440.346\n",
      "[214]\tvalid_0's tweedie: 440.346\n",
      "[215]\tvalid_0's tweedie: 440.346\n",
      "[216]\tvalid_0's tweedie: 440.346\n",
      "[217]\tvalid_0's tweedie: 440.346\n",
      "[218]\tvalid_0's tweedie: 440.346\n",
      "[219]\tvalid_0's tweedie: 440.346\n",
      "[220]\tvalid_0's tweedie: 440.345\n",
      "[221]\tvalid_0's tweedie: 440.345\n",
      "[222]\tvalid_0's tweedie: 440.345\n",
      "[223]\tvalid_0's tweedie: 440.345\n",
      "[224]\tvalid_0's tweedie: 440.345\n",
      "[225]\tvalid_0's tweedie: 440.345\n",
      "[226]\tvalid_0's tweedie: 440.345\n",
      "[227]\tvalid_0's tweedie: 440.345\n",
      "[228]\tvalid_0's tweedie: 440.345\n",
      "[229]\tvalid_0's tweedie: 440.345\n",
      "[230]\tvalid_0's tweedie: 440.345\n",
      "[231]\tvalid_0's tweedie: 440.346\n",
      "[232]\tvalid_0's tweedie: 440.346\n",
      "[233]\tvalid_0's tweedie: 440.347\n",
      "[234]\tvalid_0's tweedie: 440.347\n",
      "[235]\tvalid_0's tweedie: 440.347\n",
      "[236]\tvalid_0's tweedie: 440.346\n",
      "[237]\tvalid_0's tweedie: 440.344\n",
      "[238]\tvalid_0's tweedie: 440.344\n",
      "[239]\tvalid_0's tweedie: 440.344\n",
      "[240]\tvalid_0's tweedie: 440.344\n",
      "[241]\tvalid_0's tweedie: 440.344\n",
      "[242]\tvalid_0's tweedie: 440.344\n",
      "[243]\tvalid_0's tweedie: 440.344\n",
      "[244]\tvalid_0's tweedie: 440.344\n",
      "[245]\tvalid_0's tweedie: 440.345\n",
      "[246]\tvalid_0's tweedie: 440.345\n",
      "[247]\tvalid_0's tweedie: 440.344\n",
      "[248]\tvalid_0's tweedie: 440.344\n",
      "[249]\tvalid_0's tweedie: 440.344\n",
      "[250]\tvalid_0's tweedie: 440.343\n",
      "[251]\tvalid_0's tweedie: 440.343\n",
      "[252]\tvalid_0's tweedie: 440.343\n",
      "[253]\tvalid_0's tweedie: 440.343\n",
      "[254]\tvalid_0's tweedie: 440.343\n",
      "[255]\tvalid_0's tweedie: 440.343\n",
      "[256]\tvalid_0's tweedie: 440.342\n",
      "[257]\tvalid_0's tweedie: 440.342\n",
      "[258]\tvalid_0's tweedie: 440.342\n",
      "[259]\tvalid_0's tweedie: 440.342\n",
      "[260]\tvalid_0's tweedie: 440.342\n",
      "[261]\tvalid_0's tweedie: 440.342\n",
      "[262]\tvalid_0's tweedie: 440.342\n",
      "[263]\tvalid_0's tweedie: 440.342\n",
      "[264]\tvalid_0's tweedie: 440.341\n",
      "[265]\tvalid_0's tweedie: 440.341\n",
      "[266]\tvalid_0's tweedie: 440.341\n",
      "[267]\tvalid_0's tweedie: 440.34\n",
      "[268]\tvalid_0's tweedie: 440.34\n",
      "[269]\tvalid_0's tweedie: 440.34\n",
      "[270]\tvalid_0's tweedie: 440.34\n",
      "[271]\tvalid_0's tweedie: 440.34\n",
      "[272]\tvalid_0's tweedie: 440.34\n",
      "[273]\tvalid_0's tweedie: 440.34\n",
      "[274]\tvalid_0's tweedie: 440.34\n",
      "[275]\tvalid_0's tweedie: 440.341\n",
      "[276]\tvalid_0's tweedie: 440.341\n",
      "[277]\tvalid_0's tweedie: 440.341\n",
      "[278]\tvalid_0's tweedie: 440.341\n",
      "[279]\tvalid_0's tweedie: 440.341\n",
      "[280]\tvalid_0's tweedie: 440.341\n",
      "[281]\tvalid_0's tweedie: 440.34\n",
      "[282]\tvalid_0's tweedie: 440.34\n",
      "[283]\tvalid_0's tweedie: 440.34\n",
      "[284]\tvalid_0's tweedie: 440.34\n",
      "[285]\tvalid_0's tweedie: 440.34\n",
      "[286]\tvalid_0's tweedie: 440.34\n",
      "[287]\tvalid_0's tweedie: 440.34\n",
      "[288]\tvalid_0's tweedie: 440.34\n",
      "[289]\tvalid_0's tweedie: 440.34\n",
      "[290]\tvalid_0's tweedie: 440.34\n",
      "[291]\tvalid_0's tweedie: 440.34\n",
      "[292]\tvalid_0's tweedie: 440.34\n",
      "[293]\tvalid_0's tweedie: 440.339\n",
      "[294]\tvalid_0's tweedie: 440.339\n",
      "[295]\tvalid_0's tweedie: 440.338\n",
      "[296]\tvalid_0's tweedie: 440.338\n",
      "[297]\tvalid_0's tweedie: 440.338\n",
      "[298]\tvalid_0's tweedie: 440.338\n",
      "[299]\tvalid_0's tweedie: 440.338\n",
      "[300]\tvalid_0's tweedie: 440.338\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 440.338\n",
      "Training model for level 4 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5485\n",
      "[LightGBM] [Info] Number of data points in the train set: 5541, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.346851\n",
      "[1]\tvalid_0's tweedie: 470.947\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.587\n",
      "[3]\tvalid_0's tweedie: 461.195\n",
      "[4]\tvalid_0's tweedie: 457.476\n",
      "[5]\tvalid_0's tweedie: 454.493\n",
      "[6]\tvalid_0's tweedie: 451.989\n",
      "[7]\tvalid_0's tweedie: 449.953\n",
      "[8]\tvalid_0's tweedie: 448.277\n",
      "[9]\tvalid_0's tweedie: 446.903\n",
      "[10]\tvalid_0's tweedie: 445.733\n",
      "[11]\tvalid_0's tweedie: 444.828\n",
      "[12]\tvalid_0's tweedie: 444.081\n",
      "[13]\tvalid_0's tweedie: 443.515\n",
      "[14]\tvalid_0's tweedie: 443.022\n",
      "[15]\tvalid_0's tweedie: 442.612\n",
      "[16]\tvalid_0's tweedie: 442.287\n",
      "[17]\tvalid_0's tweedie: 442.018\n",
      "[18]\tvalid_0's tweedie: 441.782\n",
      "[19]\tvalid_0's tweedie: 441.58\n",
      "[20]\tvalid_0's tweedie: 441.423\n",
      "[21]\tvalid_0's tweedie: 441.282\n",
      "[22]\tvalid_0's tweedie: 441.176\n",
      "[23]\tvalid_0's tweedie: 441.088\n",
      "[24]\tvalid_0's tweedie: 441.018\n",
      "[25]\tvalid_0's tweedie: 440.964\n",
      "[26]\tvalid_0's tweedie: 440.915\n",
      "[27]\tvalid_0's tweedie: 440.886\n",
      "[28]\tvalid_0's tweedie: 440.837\n",
      "[29]\tvalid_0's tweedie: 440.801\n",
      "[30]\tvalid_0's tweedie: 440.735\n",
      "[31]\tvalid_0's tweedie: 440.713\n",
      "[32]\tvalid_0's tweedie: 440.687\n",
      "[33]\tvalid_0's tweedie: 440.646\n",
      "[34]\tvalid_0's tweedie: 440.617\n",
      "[35]\tvalid_0's tweedie: 440.596\n",
      "[36]\tvalid_0's tweedie: 440.565\n",
      "[37]\tvalid_0's tweedie: 440.551\n",
      "[38]\tvalid_0's tweedie: 440.539\n",
      "[39]\tvalid_0's tweedie: 440.522\n",
      "[40]\tvalid_0's tweedie: 440.509\n",
      "[41]\tvalid_0's tweedie: 440.5\n",
      "[42]\tvalid_0's tweedie: 440.499\n",
      "[43]\tvalid_0's tweedie: 440.494\n",
      "[44]\tvalid_0's tweedie: 440.488\n",
      "[45]\tvalid_0's tweedie: 440.479\n",
      "[46]\tvalid_0's tweedie: 440.477\n",
      "[47]\tvalid_0's tweedie: 440.471\n",
      "[48]\tvalid_0's tweedie: 440.47\n",
      "[49]\tvalid_0's tweedie: 440.468\n",
      "[50]\tvalid_0's tweedie: 440.465\n",
      "[51]\tvalid_0's tweedie: 440.458\n",
      "[52]\tvalid_0's tweedie: 440.457\n",
      "[53]\tvalid_0's tweedie: 440.451\n",
      "[54]\tvalid_0's tweedie: 440.446\n",
      "[55]\tvalid_0's tweedie: 440.444\n",
      "[56]\tvalid_0's tweedie: 440.443\n",
      "[57]\tvalid_0's tweedie: 440.443\n",
      "[58]\tvalid_0's tweedie: 440.438\n",
      "[59]\tvalid_0's tweedie: 440.436\n",
      "[60]\tvalid_0's tweedie: 440.435\n",
      "[61]\tvalid_0's tweedie: 440.434\n",
      "[62]\tvalid_0's tweedie: 440.43\n",
      "[63]\tvalid_0's tweedie: 440.433\n",
      "[64]\tvalid_0's tweedie: 440.432\n",
      "[65]\tvalid_0's tweedie: 440.43\n",
      "[66]\tvalid_0's tweedie: 440.427\n",
      "[67]\tvalid_0's tweedie: 440.424\n",
      "[68]\tvalid_0's tweedie: 440.426\n",
      "[69]\tvalid_0's tweedie: 440.426\n",
      "[70]\tvalid_0's tweedie: 440.424\n",
      "[71]\tvalid_0's tweedie: 440.424\n",
      "[72]\tvalid_0's tweedie: 440.424\n",
      "[73]\tvalid_0's tweedie: 440.423\n",
      "[74]\tvalid_0's tweedie: 440.423\n",
      "[75]\tvalid_0's tweedie: 440.422\n",
      "[76]\tvalid_0's tweedie: 440.422\n",
      "[77]\tvalid_0's tweedie: 440.424\n",
      "[78]\tvalid_0's tweedie: 440.422\n",
      "[79]\tvalid_0's tweedie: 440.42\n",
      "[80]\tvalid_0's tweedie: 440.417\n",
      "[81]\tvalid_0's tweedie: 440.417\n",
      "[82]\tvalid_0's tweedie: 440.418\n",
      "[83]\tvalid_0's tweedie: 440.417\n",
      "[84]\tvalid_0's tweedie: 440.417\n",
      "[85]\tvalid_0's tweedie: 440.415\n",
      "[86]\tvalid_0's tweedie: 440.415\n",
      "[87]\tvalid_0's tweedie: 440.415\n",
      "[88]\tvalid_0's tweedie: 440.415\n",
      "[89]\tvalid_0's tweedie: 440.416\n",
      "[90]\tvalid_0's tweedie: 440.415\n",
      "[91]\tvalid_0's tweedie: 440.413\n",
      "[92]\tvalid_0's tweedie: 440.413\n",
      "[93]\tvalid_0's tweedie: 440.412\n",
      "[94]\tvalid_0's tweedie: 440.408\n",
      "[95]\tvalid_0's tweedie: 440.407\n",
      "[96]\tvalid_0's tweedie: 440.408\n",
      "[97]\tvalid_0's tweedie: 440.407\n",
      "[98]\tvalid_0's tweedie: 440.406\n",
      "[99]\tvalid_0's tweedie: 440.408\n",
      "[100]\tvalid_0's tweedie: 440.407\n",
      "[101]\tvalid_0's tweedie: 440.406\n",
      "[102]\tvalid_0's tweedie: 440.406\n",
      "[103]\tvalid_0's tweedie: 440.406\n",
      "[104]\tvalid_0's tweedie: 440.406\n",
      "[105]\tvalid_0's tweedie: 440.405\n",
      "[106]\tvalid_0's tweedie: 440.404\n",
      "[107]\tvalid_0's tweedie: 440.403\n",
      "[108]\tvalid_0's tweedie: 440.401\n",
      "[109]\tvalid_0's tweedie: 440.401\n",
      "[110]\tvalid_0's tweedie: 440.4\n",
      "[111]\tvalid_0's tweedie: 440.4\n",
      "[112]\tvalid_0's tweedie: 440.4\n",
      "[113]\tvalid_0's tweedie: 440.4\n",
      "[114]\tvalid_0's tweedie: 440.4\n",
      "[115]\tvalid_0's tweedie: 440.4\n",
      "[116]\tvalid_0's tweedie: 440.4\n",
      "[117]\tvalid_0's tweedie: 440.398\n",
      "[118]\tvalid_0's tweedie: 440.398\n",
      "[119]\tvalid_0's tweedie: 440.398\n",
      "[120]\tvalid_0's tweedie: 440.398\n",
      "[121]\tvalid_0's tweedie: 440.398\n",
      "[122]\tvalid_0's tweedie: 440.397\n",
      "[123]\tvalid_0's tweedie: 440.396\n",
      "[124]\tvalid_0's tweedie: 440.396\n",
      "[125]\tvalid_0's tweedie: 440.396\n",
      "[126]\tvalid_0's tweedie: 440.396\n",
      "[127]\tvalid_0's tweedie: 440.394\n",
      "[128]\tvalid_0's tweedie: 440.392\n",
      "[129]\tvalid_0's tweedie: 440.393\n",
      "[130]\tvalid_0's tweedie: 440.393\n",
      "[131]\tvalid_0's tweedie: 440.393\n",
      "[132]\tvalid_0's tweedie: 440.394\n",
      "[133]\tvalid_0's tweedie: 440.394\n",
      "[134]\tvalid_0's tweedie: 440.395\n",
      "[135]\tvalid_0's tweedie: 440.393\n",
      "[136]\tvalid_0's tweedie: 440.393\n",
      "[137]\tvalid_0's tweedie: 440.393\n",
      "[138]\tvalid_0's tweedie: 440.392\n",
      "[139]\tvalid_0's tweedie: 440.391\n",
      "[140]\tvalid_0's tweedie: 440.39\n",
      "[141]\tvalid_0's tweedie: 440.39\n",
      "[142]\tvalid_0's tweedie: 440.39\n",
      "[143]\tvalid_0's tweedie: 440.39\n",
      "[144]\tvalid_0's tweedie: 440.39\n",
      "[145]\tvalid_0's tweedie: 440.39\n",
      "[146]\tvalid_0's tweedie: 440.39\n",
      "[147]\tvalid_0's tweedie: 440.389\n",
      "[148]\tvalid_0's tweedie: 440.389\n",
      "[149]\tvalid_0's tweedie: 440.389\n",
      "[150]\tvalid_0's tweedie: 440.389\n",
      "[151]\tvalid_0's tweedie: 440.389\n",
      "[152]\tvalid_0's tweedie: 440.388\n",
      "[153]\tvalid_0's tweedie: 440.387\n",
      "[154]\tvalid_0's tweedie: 440.387\n",
      "[155]\tvalid_0's tweedie: 440.387\n",
      "[156]\tvalid_0's tweedie: 440.387\n",
      "[157]\tvalid_0's tweedie: 440.387\n",
      "[158]\tvalid_0's tweedie: 440.387\n",
      "[159]\tvalid_0's tweedie: 440.387\n",
      "[160]\tvalid_0's tweedie: 440.388\n",
      "[161]\tvalid_0's tweedie: 440.388\n",
      "[162]\tvalid_0's tweedie: 440.388\n",
      "[163]\tvalid_0's tweedie: 440.388\n",
      "[164]\tvalid_0's tweedie: 440.387\n",
      "[165]\tvalid_0's tweedie: 440.387\n",
      "[166]\tvalid_0's tweedie: 440.387\n",
      "[167]\tvalid_0's tweedie: 440.386\n",
      "[168]\tvalid_0's tweedie: 440.386\n",
      "[169]\tvalid_0's tweedie: 440.387\n",
      "[170]\tvalid_0's tweedie: 440.386\n",
      "[171]\tvalid_0's tweedie: 440.386\n",
      "[172]\tvalid_0's tweedie: 440.386\n",
      "[173]\tvalid_0's tweedie: 440.386\n",
      "[174]\tvalid_0's tweedie: 440.386\n",
      "[175]\tvalid_0's tweedie: 440.385\n",
      "[176]\tvalid_0's tweedie: 440.385\n",
      "[177]\tvalid_0's tweedie: 440.385\n",
      "[178]\tvalid_0's tweedie: 440.385\n",
      "[179]\tvalid_0's tweedie: 440.385\n",
      "[180]\tvalid_0's tweedie: 440.385\n",
      "[181]\tvalid_0's tweedie: 440.385\n",
      "[182]\tvalid_0's tweedie: 440.385\n",
      "[183]\tvalid_0's tweedie: 440.384\n",
      "[184]\tvalid_0's tweedie: 440.384\n",
      "[185]\tvalid_0's tweedie: 440.384\n",
      "[186]\tvalid_0's tweedie: 440.385\n",
      "[187]\tvalid_0's tweedie: 440.385\n",
      "[188]\tvalid_0's tweedie: 440.385\n",
      "[189]\tvalid_0's tweedie: 440.385\n",
      "[190]\tvalid_0's tweedie: 440.384\n",
      "[191]\tvalid_0's tweedie: 440.382\n",
      "[192]\tvalid_0's tweedie: 440.382\n",
      "[193]\tvalid_0's tweedie: 440.382\n",
      "[194]\tvalid_0's tweedie: 440.382\n",
      "[195]\tvalid_0's tweedie: 440.382\n",
      "[196]\tvalid_0's tweedie: 440.381\n",
      "[197]\tvalid_0's tweedie: 440.381\n",
      "[198]\tvalid_0's tweedie: 440.381\n",
      "[199]\tvalid_0's tweedie: 440.382\n",
      "[200]\tvalid_0's tweedie: 440.382\n",
      "[201]\tvalid_0's tweedie: 440.382\n",
      "[202]\tvalid_0's tweedie: 440.382\n",
      "[203]\tvalid_0's tweedie: 440.382\n",
      "[204]\tvalid_0's tweedie: 440.382\n",
      "[205]\tvalid_0's tweedie: 440.381\n",
      "[206]\tvalid_0's tweedie: 440.38\n",
      "[207]\tvalid_0's tweedie: 440.38\n",
      "[208]\tvalid_0's tweedie: 440.38\n",
      "[209]\tvalid_0's tweedie: 440.381\n",
      "[210]\tvalid_0's tweedie: 440.381\n",
      "[211]\tvalid_0's tweedie: 440.381\n",
      "[212]\tvalid_0's tweedie: 440.381\n",
      "[213]\tvalid_0's tweedie: 440.381\n",
      "[214]\tvalid_0's tweedie: 440.38\n",
      "[215]\tvalid_0's tweedie: 440.381\n",
      "[216]\tvalid_0's tweedie: 440.381\n",
      "[217]\tvalid_0's tweedie: 440.381\n",
      "[218]\tvalid_0's tweedie: 440.379\n",
      "[219]\tvalid_0's tweedie: 440.38\n",
      "[220]\tvalid_0's tweedie: 440.38\n",
      "[221]\tvalid_0's tweedie: 440.38\n",
      "[222]\tvalid_0's tweedie: 440.381\n",
      "[223]\tvalid_0's tweedie: 440.381\n",
      "[224]\tvalid_0's tweedie: 440.381\n",
      "[225]\tvalid_0's tweedie: 440.381\n",
      "[226]\tvalid_0's tweedie: 440.38\n",
      "[227]\tvalid_0's tweedie: 440.38\n",
      "[228]\tvalid_0's tweedie: 440.38\n",
      "[229]\tvalid_0's tweedie: 440.38\n",
      "[230]\tvalid_0's tweedie: 440.38\n",
      "[231]\tvalid_0's tweedie: 440.381\n",
      "[232]\tvalid_0's tweedie: 440.38\n",
      "[233]\tvalid_0's tweedie: 440.38\n",
      "[234]\tvalid_0's tweedie: 440.379\n",
      "[235]\tvalid_0's tweedie: 440.379\n",
      "[236]\tvalid_0's tweedie: 440.379\n",
      "[237]\tvalid_0's tweedie: 440.379\n",
      "[238]\tvalid_0's tweedie: 440.379\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's tweedie: 440.379\n",
      "Training model for level 4 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5484\n",
      "[LightGBM] [Info] Number of data points in the train set: 5538, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347034\n",
      "[1]\tvalid_0's tweedie: 470.958\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.59\n",
      "[3]\tvalid_0's tweedie: 461.121\n",
      "[4]\tvalid_0's tweedie: 457.493\n",
      "[5]\tvalid_0's tweedie: 454.501\n",
      "[6]\tvalid_0's tweedie: 452.006\n",
      "[7]\tvalid_0's tweedie: 449.968\n",
      "[8]\tvalid_0's tweedie: 448.293\n",
      "[9]\tvalid_0's tweedie: 446.893\n",
      "[10]\tvalid_0's tweedie: 445.756\n",
      "[11]\tvalid_0's tweedie: 444.898\n",
      "[12]\tvalid_0's tweedie: 444.135\n",
      "[13]\tvalid_0's tweedie: 443.519\n",
      "[14]\tvalid_0's tweedie: 443.019\n",
      "[15]\tvalid_0's tweedie: 442.603\n",
      "[16]\tvalid_0's tweedie: 442.255\n",
      "[17]\tvalid_0's tweedie: 441.99\n",
      "[18]\tvalid_0's tweedie: 441.756\n",
      "[19]\tvalid_0's tweedie: 441.562\n",
      "[20]\tvalid_0's tweedie: 441.416\n",
      "[21]\tvalid_0's tweedie: 441.293\n",
      "[22]\tvalid_0's tweedie: 441.19\n",
      "[23]\tvalid_0's tweedie: 441.107\n",
      "[24]\tvalid_0's tweedie: 441.018\n",
      "[25]\tvalid_0's tweedie: 440.951\n",
      "[26]\tvalid_0's tweedie: 440.902\n",
      "[27]\tvalid_0's tweedie: 440.855\n",
      "[28]\tvalid_0's tweedie: 440.811\n",
      "[29]\tvalid_0's tweedie: 440.778\n",
      "[30]\tvalid_0's tweedie: 440.715\n",
      "[31]\tvalid_0's tweedie: 440.687\n",
      "[32]\tvalid_0's tweedie: 440.67\n",
      "[33]\tvalid_0's tweedie: 440.622\n",
      "[34]\tvalid_0's tweedie: 440.584\n",
      "[35]\tvalid_0's tweedie: 440.553\n",
      "[36]\tvalid_0's tweedie: 440.541\n",
      "[37]\tvalid_0's tweedie: 440.521\n",
      "[38]\tvalid_0's tweedie: 440.512\n",
      "[39]\tvalid_0's tweedie: 440.493\n",
      "[40]\tvalid_0's tweedie: 440.488\n",
      "[41]\tvalid_0's tweedie: 440.48\n",
      "[42]\tvalid_0's tweedie: 440.465\n",
      "[43]\tvalid_0's tweedie: 440.457\n",
      "[44]\tvalid_0's tweedie: 440.451\n",
      "[45]\tvalid_0's tweedie: 440.448\n",
      "[46]\tvalid_0's tweedie: 440.442\n",
      "[47]\tvalid_0's tweedie: 440.436\n",
      "[48]\tvalid_0's tweedie: 440.433\n",
      "[49]\tvalid_0's tweedie: 440.43\n",
      "[50]\tvalid_0's tweedie: 440.426\n",
      "[51]\tvalid_0's tweedie: 440.424\n",
      "[52]\tvalid_0's tweedie: 440.42\n",
      "[53]\tvalid_0's tweedie: 440.421\n",
      "[54]\tvalid_0's tweedie: 440.419\n",
      "[55]\tvalid_0's tweedie: 440.417\n",
      "[56]\tvalid_0's tweedie: 440.416\n",
      "[57]\tvalid_0's tweedie: 440.415\n",
      "[58]\tvalid_0's tweedie: 440.417\n",
      "[59]\tvalid_0's tweedie: 440.413\n",
      "[60]\tvalid_0's tweedie: 440.414\n",
      "[61]\tvalid_0's tweedie: 440.407\n",
      "[62]\tvalid_0's tweedie: 440.404\n",
      "[63]\tvalid_0's tweedie: 440.404\n",
      "[64]\tvalid_0's tweedie: 440.399\n",
      "[65]\tvalid_0's tweedie: 440.396\n",
      "[66]\tvalid_0's tweedie: 440.393\n",
      "[67]\tvalid_0's tweedie: 440.391\n",
      "[68]\tvalid_0's tweedie: 440.391\n",
      "[69]\tvalid_0's tweedie: 440.392\n",
      "[70]\tvalid_0's tweedie: 440.391\n",
      "[71]\tvalid_0's tweedie: 440.388\n",
      "[72]\tvalid_0's tweedie: 440.39\n",
      "[73]\tvalid_0's tweedie: 440.39\n",
      "[74]\tvalid_0's tweedie: 440.389\n",
      "[75]\tvalid_0's tweedie: 440.389\n",
      "[76]\tvalid_0's tweedie: 440.388\n",
      "[77]\tvalid_0's tweedie: 440.389\n",
      "[78]\tvalid_0's tweedie: 440.389\n",
      "[79]\tvalid_0's tweedie: 440.388\n",
      "[80]\tvalid_0's tweedie: 440.39\n",
      "[81]\tvalid_0's tweedie: 440.39\n",
      "[82]\tvalid_0's tweedie: 440.39\n",
      "[83]\tvalid_0's tweedie: 440.389\n",
      "[84]\tvalid_0's tweedie: 440.387\n",
      "[85]\tvalid_0's tweedie: 440.387\n",
      "[86]\tvalid_0's tweedie: 440.387\n",
      "[87]\tvalid_0's tweedie: 440.387\n",
      "[88]\tvalid_0's tweedie: 440.386\n",
      "[89]\tvalid_0's tweedie: 440.386\n",
      "[90]\tvalid_0's tweedie: 440.386\n",
      "[91]\tvalid_0's tweedie: 440.386\n",
      "[92]\tvalid_0's tweedie: 440.387\n",
      "[93]\tvalid_0's tweedie: 440.387\n",
      "[94]\tvalid_0's tweedie: 440.388\n",
      "[95]\tvalid_0's tweedie: 440.388\n",
      "[96]\tvalid_0's tweedie: 440.388\n",
      "[97]\tvalid_0's tweedie: 440.388\n",
      "[98]\tvalid_0's tweedie: 440.388\n",
      "[99]\tvalid_0's tweedie: 440.387\n",
      "[100]\tvalid_0's tweedie: 440.386\n",
      "[101]\tvalid_0's tweedie: 440.387\n",
      "[102]\tvalid_0's tweedie: 440.386\n",
      "[103]\tvalid_0's tweedie: 440.385\n",
      "[104]\tvalid_0's tweedie: 440.385\n",
      "[105]\tvalid_0's tweedie: 440.385\n",
      "[106]\tvalid_0's tweedie: 440.384\n",
      "[107]\tvalid_0's tweedie: 440.383\n",
      "[108]\tvalid_0's tweedie: 440.381\n",
      "[109]\tvalid_0's tweedie: 440.382\n",
      "[110]\tvalid_0's tweedie: 440.381\n",
      "[111]\tvalid_0's tweedie: 440.381\n",
      "[112]\tvalid_0's tweedie: 440.382\n",
      "[113]\tvalid_0's tweedie: 440.381\n",
      "[114]\tvalid_0's tweedie: 440.381\n",
      "[115]\tvalid_0's tweedie: 440.382\n",
      "[116]\tvalid_0's tweedie: 440.383\n",
      "[117]\tvalid_0's tweedie: 440.384\n",
      "[118]\tvalid_0's tweedie: 440.384\n",
      "[119]\tvalid_0's tweedie: 440.383\n",
      "[120]\tvalid_0's tweedie: 440.383\n",
      "[121]\tvalid_0's tweedie: 440.383\n",
      "[122]\tvalid_0's tweedie: 440.382\n",
      "[123]\tvalid_0's tweedie: 440.382\n",
      "[124]\tvalid_0's tweedie: 440.381\n",
      "[125]\tvalid_0's tweedie: 440.381\n",
      "[126]\tvalid_0's tweedie: 440.381\n",
      "[127]\tvalid_0's tweedie: 440.38\n",
      "[128]\tvalid_0's tweedie: 440.38\n",
      "[129]\tvalid_0's tweedie: 440.38\n",
      "[130]\tvalid_0's tweedie: 440.38\n",
      "[131]\tvalid_0's tweedie: 440.38\n",
      "[132]\tvalid_0's tweedie: 440.38\n",
      "[133]\tvalid_0's tweedie: 440.379\n",
      "[134]\tvalid_0's tweedie: 440.379\n",
      "[135]\tvalid_0's tweedie: 440.378\n",
      "[136]\tvalid_0's tweedie: 440.378\n",
      "[137]\tvalid_0's tweedie: 440.377\n",
      "[138]\tvalid_0's tweedie: 440.378\n",
      "[139]\tvalid_0's tweedie: 440.378\n",
      "[140]\tvalid_0's tweedie: 440.377\n",
      "[141]\tvalid_0's tweedie: 440.376\n",
      "[142]\tvalid_0's tweedie: 440.376\n",
      "[143]\tvalid_0's tweedie: 440.376\n",
      "[144]\tvalid_0's tweedie: 440.376\n",
      "[145]\tvalid_0's tweedie: 440.375\n",
      "[146]\tvalid_0's tweedie: 440.375\n",
      "[147]\tvalid_0's tweedie: 440.375\n",
      "[148]\tvalid_0's tweedie: 440.375\n",
      "[149]\tvalid_0's tweedie: 440.374\n",
      "[150]\tvalid_0's tweedie: 440.374\n",
      "[151]\tvalid_0's tweedie: 440.374\n",
      "[152]\tvalid_0's tweedie: 440.374\n",
      "[153]\tvalid_0's tweedie: 440.374\n",
      "[154]\tvalid_0's tweedie: 440.374\n",
      "[155]\tvalid_0's tweedie: 440.374\n",
      "[156]\tvalid_0's tweedie: 440.374\n",
      "[157]\tvalid_0's tweedie: 440.374\n",
      "[158]\tvalid_0's tweedie: 440.372\n",
      "[159]\tvalid_0's tweedie: 440.372\n",
      "[160]\tvalid_0's tweedie: 440.372\n",
      "[161]\tvalid_0's tweedie: 440.372\n",
      "[162]\tvalid_0's tweedie: 440.372\n",
      "[163]\tvalid_0's tweedie: 440.372\n",
      "[164]\tvalid_0's tweedie: 440.372\n",
      "[165]\tvalid_0's tweedie: 440.372\n",
      "[166]\tvalid_0's tweedie: 440.371\n",
      "[167]\tvalid_0's tweedie: 440.371\n",
      "[168]\tvalid_0's tweedie: 440.371\n",
      "[169]\tvalid_0's tweedie: 440.372\n",
      "[170]\tvalid_0's tweedie: 440.371\n",
      "[171]\tvalid_0's tweedie: 440.372\n",
      "[172]\tvalid_0's tweedie: 440.374\n",
      "[173]\tvalid_0's tweedie: 440.375\n",
      "[174]\tvalid_0's tweedie: 440.375\n",
      "[175]\tvalid_0's tweedie: 440.376\n",
      "[176]\tvalid_0's tweedie: 440.376\n",
      "[177]\tvalid_0's tweedie: 440.376\n",
      "[178]\tvalid_0's tweedie: 440.376\n",
      "[179]\tvalid_0's tweedie: 440.375\n",
      "[180]\tvalid_0's tweedie: 440.375\n",
      "[181]\tvalid_0's tweedie: 440.375\n",
      "[182]\tvalid_0's tweedie: 440.375\n",
      "[183]\tvalid_0's tweedie: 440.376\n",
      "[184]\tvalid_0's tweedie: 440.376\n",
      "[185]\tvalid_0's tweedie: 440.376\n",
      "[186]\tvalid_0's tweedie: 440.376\n",
      "[187]\tvalid_0's tweedie: 440.377\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's tweedie: 440.371\n",
      "Training model for level 4 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5483\n",
      "[LightGBM] [Info] Number of data points in the train set: 5535, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347220\n",
      "[1]\tvalid_0's tweedie: 470.963\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.593\n",
      "[3]\tvalid_0's tweedie: 461.128\n",
      "[4]\tvalid_0's tweedie: 457.511\n",
      "[5]\tvalid_0's tweedie: 454.511\n",
      "[6]\tvalid_0's tweedie: 452.016\n",
      "[7]\tvalid_0's tweedie: 450.032\n",
      "[8]\tvalid_0's tweedie: 448.342\n",
      "[9]\tvalid_0's tweedie: 446.939\n",
      "[10]\tvalid_0's tweedie: 445.824\n",
      "[11]\tvalid_0's tweedie: 444.914\n",
      "[12]\tvalid_0's tweedie: 444.143\n",
      "[13]\tvalid_0's tweedie: 443.543\n",
      "[14]\tvalid_0's tweedie: 443.066\n",
      "[15]\tvalid_0's tweedie: 442.667\n",
      "[16]\tvalid_0's tweedie: 442.337\n",
      "[17]\tvalid_0's tweedie: 442.049\n",
      "[18]\tvalid_0's tweedie: 441.827\n",
      "[19]\tvalid_0's tweedie: 441.629\n",
      "[20]\tvalid_0's tweedie: 441.478\n",
      "[21]\tvalid_0's tweedie: 441.336\n",
      "[22]\tvalid_0's tweedie: 441.21\n",
      "[23]\tvalid_0's tweedie: 441.115\n",
      "[24]\tvalid_0's tweedie: 441.038\n",
      "[25]\tvalid_0's tweedie: 440.979\n",
      "[26]\tvalid_0's tweedie: 440.878\n",
      "[27]\tvalid_0's tweedie: 440.829\n",
      "[28]\tvalid_0's tweedie: 440.789\n",
      "[29]\tvalid_0's tweedie: 440.757\n",
      "[30]\tvalid_0's tweedie: 440.695\n",
      "[31]\tvalid_0's tweedie: 440.663\n",
      "[32]\tvalid_0's tweedie: 440.627\n",
      "[33]\tvalid_0's tweedie: 440.608\n",
      "[34]\tvalid_0's tweedie: 440.574\n",
      "[35]\tvalid_0's tweedie: 440.563\n",
      "[36]\tvalid_0's tweedie: 440.537\n",
      "[37]\tvalid_0's tweedie: 440.516\n",
      "[38]\tvalid_0's tweedie: 440.503\n",
      "[39]\tvalid_0's tweedie: 440.495\n",
      "[40]\tvalid_0's tweedie: 440.489\n",
      "[41]\tvalid_0's tweedie: 440.48\n",
      "[42]\tvalid_0's tweedie: 440.468\n",
      "[43]\tvalid_0's tweedie: 440.463\n",
      "[44]\tvalid_0's tweedie: 440.451\n",
      "[45]\tvalid_0's tweedie: 440.444\n",
      "[46]\tvalid_0's tweedie: 440.439\n",
      "[47]\tvalid_0's tweedie: 440.432\n",
      "[48]\tvalid_0's tweedie: 440.428\n",
      "[49]\tvalid_0's tweedie: 440.425\n",
      "[50]\tvalid_0's tweedie: 440.419\n",
      "[51]\tvalid_0's tweedie: 440.417\n",
      "[52]\tvalid_0's tweedie: 440.417\n",
      "[53]\tvalid_0's tweedie: 440.412\n",
      "[54]\tvalid_0's tweedie: 440.411\n",
      "[55]\tvalid_0's tweedie: 440.41\n",
      "[56]\tvalid_0's tweedie: 440.41\n",
      "[57]\tvalid_0's tweedie: 440.405\n",
      "[58]\tvalid_0's tweedie: 440.402\n",
      "[59]\tvalid_0's tweedie: 440.399\n",
      "[60]\tvalid_0's tweedie: 440.395\n",
      "[61]\tvalid_0's tweedie: 440.394\n",
      "[62]\tvalid_0's tweedie: 440.392\n",
      "[63]\tvalid_0's tweedie: 440.392\n",
      "[64]\tvalid_0's tweedie: 440.391\n",
      "[65]\tvalid_0's tweedie: 440.389\n",
      "[66]\tvalid_0's tweedie: 440.387\n",
      "[67]\tvalid_0's tweedie: 440.386\n",
      "[68]\tvalid_0's tweedie: 440.386\n",
      "[69]\tvalid_0's tweedie: 440.384\n",
      "[70]\tvalid_0's tweedie: 440.383\n",
      "[71]\tvalid_0's tweedie: 440.384\n",
      "[72]\tvalid_0's tweedie: 440.379\n",
      "[73]\tvalid_0's tweedie: 440.378\n",
      "[74]\tvalid_0's tweedie: 440.376\n",
      "[75]\tvalid_0's tweedie: 440.374\n",
      "[76]\tvalid_0's tweedie: 440.375\n",
      "[77]\tvalid_0's tweedie: 440.375\n",
      "[78]\tvalid_0's tweedie: 440.374\n",
      "[79]\tvalid_0's tweedie: 440.374\n",
      "[80]\tvalid_0's tweedie: 440.373\n",
      "[81]\tvalid_0's tweedie: 440.376\n",
      "[82]\tvalid_0's tweedie: 440.375\n",
      "[83]\tvalid_0's tweedie: 440.375\n",
      "[84]\tvalid_0's tweedie: 440.375\n",
      "[85]\tvalid_0's tweedie: 440.374\n",
      "[86]\tvalid_0's tweedie: 440.374\n",
      "[87]\tvalid_0's tweedie: 440.374\n",
      "[88]\tvalid_0's tweedie: 440.374\n",
      "[89]\tvalid_0's tweedie: 440.376\n",
      "[90]\tvalid_0's tweedie: 440.376\n",
      "[91]\tvalid_0's tweedie: 440.376\n",
      "[92]\tvalid_0's tweedie: 440.376\n",
      "[93]\tvalid_0's tweedie: 440.374\n",
      "[94]\tvalid_0's tweedie: 440.373\n",
      "[95]\tvalid_0's tweedie: 440.372\n",
      "[96]\tvalid_0's tweedie: 440.372\n",
      "[97]\tvalid_0's tweedie: 440.372\n",
      "[98]\tvalid_0's tweedie: 440.37\n",
      "[99]\tvalid_0's tweedie: 440.37\n",
      "[100]\tvalid_0's tweedie: 440.37\n",
      "[101]\tvalid_0's tweedie: 440.37\n",
      "[102]\tvalid_0's tweedie: 440.369\n",
      "[103]\tvalid_0's tweedie: 440.369\n",
      "[104]\tvalid_0's tweedie: 440.369\n",
      "[105]\tvalid_0's tweedie: 440.37\n",
      "[106]\tvalid_0's tweedie: 440.369\n",
      "[107]\tvalid_0's tweedie: 440.369\n",
      "[108]\tvalid_0's tweedie: 440.369\n",
      "[109]\tvalid_0's tweedie: 440.369\n",
      "[110]\tvalid_0's tweedie: 440.369\n",
      "[111]\tvalid_0's tweedie: 440.369\n",
      "[112]\tvalid_0's tweedie: 440.368\n",
      "[113]\tvalid_0's tweedie: 440.369\n",
      "[114]\tvalid_0's tweedie: 440.369\n",
      "[115]\tvalid_0's tweedie: 440.369\n",
      "[116]\tvalid_0's tweedie: 440.369\n",
      "[117]\tvalid_0's tweedie: 440.368\n",
      "[118]\tvalid_0's tweedie: 440.368\n",
      "[119]\tvalid_0's tweedie: 440.367\n",
      "[120]\tvalid_0's tweedie: 440.366\n",
      "[121]\tvalid_0's tweedie: 440.366\n",
      "[122]\tvalid_0's tweedie: 440.366\n",
      "[123]\tvalid_0's tweedie: 440.366\n",
      "[124]\tvalid_0's tweedie: 440.366\n",
      "[125]\tvalid_0's tweedie: 440.366\n",
      "[126]\tvalid_0's tweedie: 440.365\n",
      "[127]\tvalid_0's tweedie: 440.366\n",
      "[128]\tvalid_0's tweedie: 440.366\n",
      "[129]\tvalid_0's tweedie: 440.365\n",
      "[130]\tvalid_0's tweedie: 440.365\n",
      "[131]\tvalid_0's tweedie: 440.365\n",
      "[132]\tvalid_0's tweedie: 440.365\n",
      "[133]\tvalid_0's tweedie: 440.365\n",
      "[134]\tvalid_0's tweedie: 440.365\n",
      "[135]\tvalid_0's tweedie: 440.365\n",
      "[136]\tvalid_0's tweedie: 440.365\n",
      "[137]\tvalid_0's tweedie: 440.364\n",
      "[138]\tvalid_0's tweedie: 440.364\n",
      "[139]\tvalid_0's tweedie: 440.364\n",
      "[140]\tvalid_0's tweedie: 440.364\n",
      "[141]\tvalid_0's tweedie: 440.362\n",
      "[142]\tvalid_0's tweedie: 440.364\n",
      "[143]\tvalid_0's tweedie: 440.363\n",
      "[144]\tvalid_0's tweedie: 440.363\n",
      "[145]\tvalid_0's tweedie: 440.363\n",
      "[146]\tvalid_0's tweedie: 440.363\n",
      "[147]\tvalid_0's tweedie: 440.363\n",
      "[148]\tvalid_0's tweedie: 440.362\n",
      "[149]\tvalid_0's tweedie: 440.362\n",
      "[150]\tvalid_0's tweedie: 440.363\n",
      "[151]\tvalid_0's tweedie: 440.363\n",
      "[152]\tvalid_0's tweedie: 440.362\n",
      "[153]\tvalid_0's tweedie: 440.363\n",
      "[154]\tvalid_0's tweedie: 440.363\n",
      "[155]\tvalid_0's tweedie: 440.363\n",
      "[156]\tvalid_0's tweedie: 440.362\n",
      "[157]\tvalid_0's tweedie: 440.361\n",
      "[158]\tvalid_0's tweedie: 440.361\n",
      "[159]\tvalid_0's tweedie: 440.36\n",
      "[160]\tvalid_0's tweedie: 440.361\n",
      "[161]\tvalid_0's tweedie: 440.361\n",
      "[162]\tvalid_0's tweedie: 440.36\n",
      "[163]\tvalid_0's tweedie: 440.36\n",
      "[164]\tvalid_0's tweedie: 440.36\n",
      "[165]\tvalid_0's tweedie: 440.359\n",
      "[166]\tvalid_0's tweedie: 440.361\n",
      "[167]\tvalid_0's tweedie: 440.36\n",
      "[168]\tvalid_0's tweedie: 440.361\n",
      "[169]\tvalid_0's tweedie: 440.361\n",
      "[170]\tvalid_0's tweedie: 440.361\n",
      "[171]\tvalid_0's tweedie: 440.361\n",
      "[172]\tvalid_0's tweedie: 440.361\n",
      "[173]\tvalid_0's tweedie: 440.361\n",
      "[174]\tvalid_0's tweedie: 440.361\n",
      "[175]\tvalid_0's tweedie: 440.361\n",
      "[176]\tvalid_0's tweedie: 440.36\n",
      "[177]\tvalid_0's tweedie: 440.36\n",
      "[178]\tvalid_0's tweedie: 440.361\n",
      "[179]\tvalid_0's tweedie: 440.361\n",
      "[180]\tvalid_0's tweedie: 440.36\n",
      "[181]\tvalid_0's tweedie: 440.36\n",
      "[182]\tvalid_0's tweedie: 440.36\n",
      "[183]\tvalid_0's tweedie: 440.36\n",
      "[184]\tvalid_0's tweedie: 440.36\n",
      "[185]\tvalid_0's tweedie: 440.36\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's tweedie: 440.359\n",
      "Training model for level 4 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/4/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5482\n",
      "[LightGBM] [Info] Number of data points in the train set: 5532, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 9.347406\n",
      "[1]\tvalid_0's tweedie: 470.955\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 465.578\n",
      "[3]\tvalid_0's tweedie: 461.114\n",
      "[4]\tvalid_0's tweedie: 457.494\n",
      "[5]\tvalid_0's tweedie: 454.505\n",
      "[6]\tvalid_0's tweedie: 452.035\n",
      "[7]\tvalid_0's tweedie: 449.984\n",
      "[8]\tvalid_0's tweedie: 448.302\n",
      "[9]\tvalid_0's tweedie: 446.9\n",
      "[10]\tvalid_0's tweedie: 445.786\n",
      "[11]\tvalid_0's tweedie: 444.861\n",
      "[12]\tvalid_0's tweedie: 444.145\n",
      "[13]\tvalid_0's tweedie: 443.526\n",
      "[14]\tvalid_0's tweedie: 443.037\n",
      "[15]\tvalid_0's tweedie: 442.615\n",
      "[16]\tvalid_0's tweedie: 442.271\n",
      "[17]\tvalid_0's tweedie: 442.014\n",
      "[18]\tvalid_0's tweedie: 441.772\n",
      "[19]\tvalid_0's tweedie: 441.573\n",
      "[20]\tvalid_0's tweedie: 441.419\n",
      "[21]\tvalid_0's tweedie: 441.278\n",
      "[22]\tvalid_0's tweedie: 441.166\n",
      "[23]\tvalid_0's tweedie: 441.069\n",
      "[24]\tvalid_0's tweedie: 440.996\n",
      "[25]\tvalid_0's tweedie: 440.94\n",
      "[26]\tvalid_0's tweedie: 440.883\n",
      "[27]\tvalid_0's tweedie: 440.836\n",
      "[28]\tvalid_0's tweedie: 440.754\n",
      "[29]\tvalid_0's tweedie: 440.724\n",
      "[30]\tvalid_0's tweedie: 440.696\n",
      "[31]\tvalid_0's tweedie: 440.663\n",
      "[32]\tvalid_0's tweedie: 440.645\n",
      "[33]\tvalid_0's tweedie: 440.627\n",
      "[34]\tvalid_0's tweedie: 440.585\n",
      "[35]\tvalid_0's tweedie: 440.576\n",
      "[36]\tvalid_0's tweedie: 440.567\n",
      "[37]\tvalid_0's tweedie: 440.535\n",
      "[38]\tvalid_0's tweedie: 440.509\n",
      "[39]\tvalid_0's tweedie: 440.49\n",
      "[40]\tvalid_0's tweedie: 440.473\n",
      "[41]\tvalid_0's tweedie: 440.463\n",
      "[42]\tvalid_0's tweedie: 440.453\n",
      "[43]\tvalid_0's tweedie: 440.445\n",
      "[44]\tvalid_0's tweedie: 440.44\n",
      "[45]\tvalid_0's tweedie: 440.436\n",
      "[46]\tvalid_0's tweedie: 440.431\n",
      "[47]\tvalid_0's tweedie: 440.43\n",
      "[48]\tvalid_0's tweedie: 440.428\n",
      "[49]\tvalid_0's tweedie: 440.426\n",
      "[50]\tvalid_0's tweedie: 440.425\n",
      "[51]\tvalid_0's tweedie: 440.418\n",
      "[52]\tvalid_0's tweedie: 440.417\n",
      "[53]\tvalid_0's tweedie: 440.414\n",
      "[54]\tvalid_0's tweedie: 440.41\n",
      "[55]\tvalid_0's tweedie: 440.41\n",
      "[56]\tvalid_0's tweedie: 440.409\n",
      "[57]\tvalid_0's tweedie: 440.405\n",
      "[58]\tvalid_0's tweedie: 440.402\n",
      "[59]\tvalid_0's tweedie: 440.399\n",
      "[60]\tvalid_0's tweedie: 440.397\n",
      "[61]\tvalid_0's tweedie: 440.395\n",
      "[62]\tvalid_0's tweedie: 440.395\n",
      "[63]\tvalid_0's tweedie: 440.394\n",
      "[64]\tvalid_0's tweedie: 440.394\n",
      "[65]\tvalid_0's tweedie: 440.393\n",
      "[66]\tvalid_0's tweedie: 440.391\n",
      "[67]\tvalid_0's tweedie: 440.388\n",
      "[68]\tvalid_0's tweedie: 440.387\n",
      "[69]\tvalid_0's tweedie: 440.385\n",
      "[70]\tvalid_0's tweedie: 440.383\n",
      "[71]\tvalid_0's tweedie: 440.383\n",
      "[72]\tvalid_0's tweedie: 440.382\n",
      "[73]\tvalid_0's tweedie: 440.379\n",
      "[74]\tvalid_0's tweedie: 440.38\n",
      "[75]\tvalid_0's tweedie: 440.378\n",
      "[76]\tvalid_0's tweedie: 440.377\n",
      "[77]\tvalid_0's tweedie: 440.378\n",
      "[78]\tvalid_0's tweedie: 440.378\n",
      "[79]\tvalid_0's tweedie: 440.378\n",
      "[80]\tvalid_0's tweedie: 440.378\n",
      "[81]\tvalid_0's tweedie: 440.378\n",
      "[82]\tvalid_0's tweedie: 440.38\n",
      "[83]\tvalid_0's tweedie: 440.378\n",
      "[84]\tvalid_0's tweedie: 440.377\n",
      "[85]\tvalid_0's tweedie: 440.376\n",
      "[86]\tvalid_0's tweedie: 440.376\n",
      "[87]\tvalid_0's tweedie: 440.376\n",
      "[88]\tvalid_0's tweedie: 440.377\n",
      "[89]\tvalid_0's tweedie: 440.376\n",
      "[90]\tvalid_0's tweedie: 440.375\n",
      "[91]\tvalid_0's tweedie: 440.375\n",
      "[92]\tvalid_0's tweedie: 440.374\n",
      "[93]\tvalid_0's tweedie: 440.373\n",
      "[94]\tvalid_0's tweedie: 440.374\n",
      "[95]\tvalid_0's tweedie: 440.373\n",
      "[96]\tvalid_0's tweedie: 440.373\n",
      "[97]\tvalid_0's tweedie: 440.373\n",
      "[98]\tvalid_0's tweedie: 440.372\n",
      "[99]\tvalid_0's tweedie: 440.372\n",
      "[100]\tvalid_0's tweedie: 440.371\n",
      "[101]\tvalid_0's tweedie: 440.37\n",
      "[102]\tvalid_0's tweedie: 440.37\n",
      "[103]\tvalid_0's tweedie: 440.37\n",
      "[104]\tvalid_0's tweedie: 440.37\n",
      "[105]\tvalid_0's tweedie: 440.369\n",
      "[106]\tvalid_0's tweedie: 440.369\n",
      "[107]\tvalid_0's tweedie: 440.368\n",
      "[108]\tvalid_0's tweedie: 440.368\n",
      "[109]\tvalid_0's tweedie: 440.367\n",
      "[110]\tvalid_0's tweedie: 440.368\n",
      "[111]\tvalid_0's tweedie: 440.367\n",
      "[112]\tvalid_0's tweedie: 440.367\n",
      "[113]\tvalid_0's tweedie: 440.369\n",
      "[114]\tvalid_0's tweedie: 440.369\n",
      "[115]\tvalid_0's tweedie: 440.369\n",
      "[116]\tvalid_0's tweedie: 440.368\n",
      "[117]\tvalid_0's tweedie: 440.368\n",
      "[118]\tvalid_0's tweedie: 440.368\n",
      "[119]\tvalid_0's tweedie: 440.368\n",
      "[120]\tvalid_0's tweedie: 440.368\n",
      "[121]\tvalid_0's tweedie: 440.369\n",
      "[122]\tvalid_0's tweedie: 440.369\n",
      "[123]\tvalid_0's tweedie: 440.368\n",
      "[124]\tvalid_0's tweedie: 440.368\n",
      "[125]\tvalid_0's tweedie: 440.368\n",
      "[126]\tvalid_0's tweedie: 440.367\n",
      "[127]\tvalid_0's tweedie: 440.367\n",
      "[128]\tvalid_0's tweedie: 440.368\n",
      "[129]\tvalid_0's tweedie: 440.365\n",
      "[130]\tvalid_0's tweedie: 440.365\n",
      "[131]\tvalid_0's tweedie: 440.364\n",
      "[132]\tvalid_0's tweedie: 440.364\n",
      "[133]\tvalid_0's tweedie: 440.364\n",
      "[134]\tvalid_0's tweedie: 440.363\n",
      "[135]\tvalid_0's tweedie: 440.363\n",
      "[136]\tvalid_0's tweedie: 440.364\n",
      "[137]\tvalid_0's tweedie: 440.364\n",
      "[138]\tvalid_0's tweedie: 440.366\n",
      "[139]\tvalid_0's tweedie: 440.365\n",
      "[140]\tvalid_0's tweedie: 440.364\n",
      "[141]\tvalid_0's tweedie: 440.364\n",
      "[142]\tvalid_0's tweedie: 440.365\n",
      "[143]\tvalid_0's tweedie: 440.365\n",
      "[144]\tvalid_0's tweedie: 440.364\n",
      "[145]\tvalid_0's tweedie: 440.365\n",
      "[146]\tvalid_0's tweedie: 440.364\n",
      "[147]\tvalid_0's tweedie: 440.365\n",
      "[148]\tvalid_0's tweedie: 440.364\n",
      "[149]\tvalid_0's tweedie: 440.365\n",
      "[150]\tvalid_0's tweedie: 440.365\n",
      "[151]\tvalid_0's tweedie: 440.365\n",
      "[152]\tvalid_0's tweedie: 440.365\n",
      "[153]\tvalid_0's tweedie: 440.364\n",
      "[154]\tvalid_0's tweedie: 440.364\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's tweedie: 440.363\n",
      "Training model for level 5\n",
      "Training model for level 5 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 13097, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496264\n",
      "[1]\tvalid_0's tweedie: 306.674\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.656\n",
      "[3]\tvalid_0's tweedie: 297.416\n",
      "[4]\tvalid_0's tweedie: 293.815\n",
      "[5]\tvalid_0's tweedie: 290.76\n",
      "[6]\tvalid_0's tweedie: 288.229\n",
      "[7]\tvalid_0's tweedie: 286.107\n",
      "[8]\tvalid_0's tweedie: 284.328\n",
      "[9]\tvalid_0's tweedie: 282.848\n",
      "[10]\tvalid_0's tweedie: 281.643\n",
      "[11]\tvalid_0's tweedie: 280.644\n",
      "[12]\tvalid_0's tweedie: 279.83\n",
      "[13]\tvalid_0's tweedie: 279.144\n",
      "[14]\tvalid_0's tweedie: 278.583\n",
      "[15]\tvalid_0's tweedie: 278.126\n",
      "[16]\tvalid_0's tweedie: 277.754\n",
      "[17]\tvalid_0's tweedie: 277.43\n",
      "[18]\tvalid_0's tweedie: 277.175\n",
      "[19]\tvalid_0's tweedie: 276.972\n",
      "[20]\tvalid_0's tweedie: 276.796\n",
      "[21]\tvalid_0's tweedie: 276.646\n",
      "[22]\tvalid_0's tweedie: 276.526\n",
      "[23]\tvalid_0's tweedie: 276.424\n",
      "[24]\tvalid_0's tweedie: 276.345\n",
      "[25]\tvalid_0's tweedie: 276.279\n",
      "[26]\tvalid_0's tweedie: 276.231\n",
      "[27]\tvalid_0's tweedie: 276.181\n",
      "[28]\tvalid_0's tweedie: 276.141\n",
      "[29]\tvalid_0's tweedie: 276.109\n",
      "[30]\tvalid_0's tweedie: 276.081\n",
      "[31]\tvalid_0's tweedie: 276.055\n",
      "[32]\tvalid_0's tweedie: 276.033\n",
      "[33]\tvalid_0's tweedie: 276.013\n",
      "[34]\tvalid_0's tweedie: 275.998\n",
      "[35]\tvalid_0's tweedie: 275.988\n",
      "[36]\tvalid_0's tweedie: 275.976\n",
      "[37]\tvalid_0's tweedie: 275.965\n",
      "[38]\tvalid_0's tweedie: 275.956\n",
      "[39]\tvalid_0's tweedie: 275.949\n",
      "[40]\tvalid_0's tweedie: 275.944\n",
      "[41]\tvalid_0's tweedie: 275.937\n",
      "[42]\tvalid_0's tweedie: 275.928\n",
      "[43]\tvalid_0's tweedie: 275.924\n",
      "[44]\tvalid_0's tweedie: 275.92\n",
      "[45]\tvalid_0's tweedie: 275.916\n",
      "[46]\tvalid_0's tweedie: 275.913\n",
      "[47]\tvalid_0's tweedie: 275.912\n",
      "[48]\tvalid_0's tweedie: 275.91\n",
      "[49]\tvalid_0's tweedie: 275.908\n",
      "[50]\tvalid_0's tweedie: 275.907\n",
      "[51]\tvalid_0's tweedie: 275.903\n",
      "[52]\tvalid_0's tweedie: 275.903\n",
      "[53]\tvalid_0's tweedie: 275.902\n",
      "[54]\tvalid_0's tweedie: 275.9\n",
      "[55]\tvalid_0's tweedie: 275.899\n",
      "[56]\tvalid_0's tweedie: 275.896\n",
      "[57]\tvalid_0's tweedie: 275.895\n",
      "[58]\tvalid_0's tweedie: 275.893\n",
      "[59]\tvalid_0's tweedie: 275.891\n",
      "[60]\tvalid_0's tweedie: 275.89\n",
      "[61]\tvalid_0's tweedie: 275.89\n",
      "[62]\tvalid_0's tweedie: 275.889\n",
      "[63]\tvalid_0's tweedie: 275.888\n",
      "[64]\tvalid_0's tweedie: 275.888\n",
      "[65]\tvalid_0's tweedie: 275.888\n",
      "[66]\tvalid_0's tweedie: 275.888\n",
      "[67]\tvalid_0's tweedie: 275.888\n",
      "[68]\tvalid_0's tweedie: 275.887\n",
      "[69]\tvalid_0's tweedie: 275.887\n",
      "[70]\tvalid_0's tweedie: 275.887\n",
      "[71]\tvalid_0's tweedie: 275.886\n",
      "[72]\tvalid_0's tweedie: 275.885\n",
      "[73]\tvalid_0's tweedie: 275.885\n",
      "[74]\tvalid_0's tweedie: 275.885\n",
      "[75]\tvalid_0's tweedie: 275.885\n",
      "[76]\tvalid_0's tweedie: 275.885\n",
      "[77]\tvalid_0's tweedie: 275.885\n",
      "[78]\tvalid_0's tweedie: 275.884\n",
      "[79]\tvalid_0's tweedie: 275.884\n",
      "[80]\tvalid_0's tweedie: 275.883\n",
      "[81]\tvalid_0's tweedie: 275.883\n",
      "[82]\tvalid_0's tweedie: 275.881\n",
      "[83]\tvalid_0's tweedie: 275.88\n",
      "[84]\tvalid_0's tweedie: 275.88\n",
      "[85]\tvalid_0's tweedie: 275.879\n",
      "[86]\tvalid_0's tweedie: 275.879\n",
      "[87]\tvalid_0's tweedie: 275.879\n",
      "[88]\tvalid_0's tweedie: 275.879\n",
      "[89]\tvalid_0's tweedie: 275.879\n",
      "[90]\tvalid_0's tweedie: 275.879\n",
      "[91]\tvalid_0's tweedie: 275.879\n",
      "[92]\tvalid_0's tweedie: 275.879\n",
      "[93]\tvalid_0's tweedie: 275.879\n",
      "[94]\tvalid_0's tweedie: 275.879\n",
      "[95]\tvalid_0's tweedie: 275.878\n",
      "[96]\tvalid_0's tweedie: 275.877\n",
      "[97]\tvalid_0's tweedie: 275.877\n",
      "[98]\tvalid_0's tweedie: 275.877\n",
      "[99]\tvalid_0's tweedie: 275.877\n",
      "[100]\tvalid_0's tweedie: 275.877\n",
      "[101]\tvalid_0's tweedie: 275.876\n",
      "[102]\tvalid_0's tweedie: 275.876\n",
      "[103]\tvalid_0's tweedie: 275.876\n",
      "[104]\tvalid_0's tweedie: 275.876\n",
      "[105]\tvalid_0's tweedie: 275.876\n",
      "[106]\tvalid_0's tweedie: 275.876\n",
      "[107]\tvalid_0's tweedie: 275.876\n",
      "[108]\tvalid_0's tweedie: 275.874\n",
      "[109]\tvalid_0's tweedie: 275.873\n",
      "[110]\tvalid_0's tweedie: 275.873\n",
      "[111]\tvalid_0's tweedie: 275.873\n",
      "[112]\tvalid_0's tweedie: 275.873\n",
      "[113]\tvalid_0's tweedie: 275.873\n",
      "[114]\tvalid_0's tweedie: 275.873\n",
      "[115]\tvalid_0's tweedie: 275.872\n",
      "[116]\tvalid_0's tweedie: 275.871\n",
      "[117]\tvalid_0's tweedie: 275.871\n",
      "[118]\tvalid_0's tweedie: 275.871\n",
      "[119]\tvalid_0's tweedie: 275.871\n",
      "[120]\tvalid_0's tweedie: 275.872\n",
      "[121]\tvalid_0's tweedie: 275.871\n",
      "[122]\tvalid_0's tweedie: 275.872\n",
      "[123]\tvalid_0's tweedie: 275.871\n",
      "[124]\tvalid_0's tweedie: 275.871\n",
      "[125]\tvalid_0's tweedie: 275.871\n",
      "[126]\tvalid_0's tweedie: 275.87\n",
      "[127]\tvalid_0's tweedie: 275.87\n",
      "[128]\tvalid_0's tweedie: 275.87\n",
      "[129]\tvalid_0's tweedie: 275.87\n",
      "[130]\tvalid_0's tweedie: 275.87\n",
      "[131]\tvalid_0's tweedie: 275.87\n",
      "[132]\tvalid_0's tweedie: 275.87\n",
      "[133]\tvalid_0's tweedie: 275.87\n",
      "[134]\tvalid_0's tweedie: 275.87\n",
      "[135]\tvalid_0's tweedie: 275.869\n",
      "[136]\tvalid_0's tweedie: 275.869\n",
      "[137]\tvalid_0's tweedie: 275.869\n",
      "[138]\tvalid_0's tweedie: 275.869\n",
      "[139]\tvalid_0's tweedie: 275.869\n",
      "[140]\tvalid_0's tweedie: 275.869\n",
      "[141]\tvalid_0's tweedie: 275.869\n",
      "[142]\tvalid_0's tweedie: 275.869\n",
      "[143]\tvalid_0's tweedie: 275.869\n",
      "[144]\tvalid_0's tweedie: 275.869\n",
      "[145]\tvalid_0's tweedie: 275.869\n",
      "[146]\tvalid_0's tweedie: 275.869\n",
      "[147]\tvalid_0's tweedie: 275.87\n",
      "[148]\tvalid_0's tweedie: 275.87\n",
      "[149]\tvalid_0's tweedie: 275.87\n",
      "[150]\tvalid_0's tweedie: 275.87\n",
      "[151]\tvalid_0's tweedie: 275.869\n",
      "[152]\tvalid_0's tweedie: 275.869\n",
      "[153]\tvalid_0's tweedie: 275.869\n",
      "[154]\tvalid_0's tweedie: 275.869\n",
      "[155]\tvalid_0's tweedie: 275.869\n",
      "[156]\tvalid_0's tweedie: 275.869\n",
      "[157]\tvalid_0's tweedie: 275.869\n",
      "[158]\tvalid_0's tweedie: 275.869\n",
      "[159]\tvalid_0's tweedie: 275.869\n",
      "[160]\tvalid_0's tweedie: 275.869\n",
      "[161]\tvalid_0's tweedie: 275.87\n",
      "[162]\tvalid_0's tweedie: 275.87\n",
      "[163]\tvalid_0's tweedie: 275.87\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's tweedie: 275.869\n",
      "Training model for level 5 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5512\n",
      "[LightGBM] [Info] Number of data points in the train set: 13090, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496255\n",
      "[1]\tvalid_0's tweedie: 306.69\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.703\n",
      "[3]\tvalid_0's tweedie: 297.488\n",
      "[4]\tvalid_0's tweedie: 293.88\n",
      "[5]\tvalid_0's tweedie: 290.854\n",
      "[6]\tvalid_0's tweedie: 288.324\n",
      "[7]\tvalid_0's tweedie: 286.198\n",
      "[8]\tvalid_0's tweedie: 284.437\n",
      "[9]\tvalid_0's tweedie: 282.98\n",
      "[10]\tvalid_0's tweedie: 281.767\n",
      "[11]\tvalid_0's tweedie: 280.765\n",
      "[12]\tvalid_0's tweedie: 279.942\n",
      "[13]\tvalid_0's tweedie: 279.255\n",
      "[14]\tvalid_0's tweedie: 278.693\n",
      "[15]\tvalid_0's tweedie: 278.231\n",
      "[16]\tvalid_0's tweedie: 277.847\n",
      "[17]\tvalid_0's tweedie: 277.55\n",
      "[18]\tvalid_0's tweedie: 277.294\n",
      "[19]\tvalid_0's tweedie: 277.078\n",
      "[20]\tvalid_0's tweedie: 276.891\n",
      "[21]\tvalid_0's tweedie: 276.746\n",
      "[22]\tvalid_0's tweedie: 276.62\n",
      "[23]\tvalid_0's tweedie: 276.525\n",
      "[24]\tvalid_0's tweedie: 276.436\n",
      "[25]\tvalid_0's tweedie: 276.361\n",
      "[26]\tvalid_0's tweedie: 276.303\n",
      "[27]\tvalid_0's tweedie: 276.252\n",
      "[28]\tvalid_0's tweedie: 276.208\n",
      "[29]\tvalid_0's tweedie: 276.176\n",
      "[30]\tvalid_0's tweedie: 276.148\n",
      "[31]\tvalid_0's tweedie: 276.125\n",
      "[32]\tvalid_0's tweedie: 276.104\n",
      "[33]\tvalid_0's tweedie: 276.09\n",
      "[34]\tvalid_0's tweedie: 276.076\n",
      "[35]\tvalid_0's tweedie: 276.063\n",
      "[36]\tvalid_0's tweedie: 276.048\n",
      "[37]\tvalid_0's tweedie: 276.037\n",
      "[38]\tvalid_0's tweedie: 276.023\n",
      "[39]\tvalid_0's tweedie: 276.014\n",
      "[40]\tvalid_0's tweedie: 276.007\n",
      "[41]\tvalid_0's tweedie: 275.997\n",
      "[42]\tvalid_0's tweedie: 275.991\n",
      "[43]\tvalid_0's tweedie: 275.984\n",
      "[44]\tvalid_0's tweedie: 275.979\n",
      "[45]\tvalid_0's tweedie: 275.976\n",
      "[46]\tvalid_0's tweedie: 275.974\n",
      "[47]\tvalid_0's tweedie: 275.97\n",
      "[48]\tvalid_0's tweedie: 275.968\n",
      "[49]\tvalid_0's tweedie: 275.966\n",
      "[50]\tvalid_0's tweedie: 275.966\n",
      "[51]\tvalid_0's tweedie: 275.96\n",
      "[52]\tvalid_0's tweedie: 275.959\n",
      "[53]\tvalid_0's tweedie: 275.957\n",
      "[54]\tvalid_0's tweedie: 275.956\n",
      "[55]\tvalid_0's tweedie: 275.953\n",
      "[56]\tvalid_0's tweedie: 275.95\n",
      "[57]\tvalid_0's tweedie: 275.949\n",
      "[58]\tvalid_0's tweedie: 275.944\n",
      "[59]\tvalid_0's tweedie: 275.943\n",
      "[60]\tvalid_0's tweedie: 275.942\n",
      "[61]\tvalid_0's tweedie: 275.942\n",
      "[62]\tvalid_0's tweedie: 275.94\n",
      "[63]\tvalid_0's tweedie: 275.939\n",
      "[64]\tvalid_0's tweedie: 275.936\n",
      "[65]\tvalid_0's tweedie: 275.936\n",
      "[66]\tvalid_0's tweedie: 275.934\n",
      "[67]\tvalid_0's tweedie: 275.934\n",
      "[68]\tvalid_0's tweedie: 275.933\n",
      "[69]\tvalid_0's tweedie: 275.933\n",
      "[70]\tvalid_0's tweedie: 275.933\n",
      "[71]\tvalid_0's tweedie: 275.932\n",
      "[72]\tvalid_0's tweedie: 275.931\n",
      "[73]\tvalid_0's tweedie: 275.931\n",
      "[74]\tvalid_0's tweedie: 275.929\n",
      "[75]\tvalid_0's tweedie: 275.929\n",
      "[76]\tvalid_0's tweedie: 275.929\n",
      "[77]\tvalid_0's tweedie: 275.928\n",
      "[78]\tvalid_0's tweedie: 275.927\n",
      "[79]\tvalid_0's tweedie: 275.926\n",
      "[80]\tvalid_0's tweedie: 275.926\n",
      "[81]\tvalid_0's tweedie: 275.926\n",
      "[82]\tvalid_0's tweedie: 275.924\n",
      "[83]\tvalid_0's tweedie: 275.924\n",
      "[84]\tvalid_0's tweedie: 275.924\n",
      "[85]\tvalid_0's tweedie: 275.923\n",
      "[86]\tvalid_0's tweedie: 275.922\n",
      "[87]\tvalid_0's tweedie: 275.92\n",
      "[88]\tvalid_0's tweedie: 275.92\n",
      "[89]\tvalid_0's tweedie: 275.92\n",
      "[90]\tvalid_0's tweedie: 275.919\n",
      "[91]\tvalid_0's tweedie: 275.92\n",
      "[92]\tvalid_0's tweedie: 275.919\n",
      "[93]\tvalid_0's tweedie: 275.919\n",
      "[94]\tvalid_0's tweedie: 275.919\n",
      "[95]\tvalid_0's tweedie: 275.919\n",
      "[96]\tvalid_0's tweedie: 275.919\n",
      "[97]\tvalid_0's tweedie: 275.918\n",
      "[98]\tvalid_0's tweedie: 275.918\n",
      "[99]\tvalid_0's tweedie: 275.919\n",
      "[100]\tvalid_0's tweedie: 275.916\n",
      "[101]\tvalid_0's tweedie: 275.915\n",
      "[102]\tvalid_0's tweedie: 275.914\n",
      "[103]\tvalid_0's tweedie: 275.914\n",
      "[104]\tvalid_0's tweedie: 275.914\n",
      "[105]\tvalid_0's tweedie: 275.914\n",
      "[106]\tvalid_0's tweedie: 275.913\n",
      "[107]\tvalid_0's tweedie: 275.913\n",
      "[108]\tvalid_0's tweedie: 275.913\n",
      "[109]\tvalid_0's tweedie: 275.913\n",
      "[110]\tvalid_0's tweedie: 275.913\n",
      "[111]\tvalid_0's tweedie: 275.913\n",
      "[112]\tvalid_0's tweedie: 275.913\n",
      "[113]\tvalid_0's tweedie: 275.913\n",
      "[114]\tvalid_0's tweedie: 275.912\n",
      "[115]\tvalid_0's tweedie: 275.912\n",
      "[116]\tvalid_0's tweedie: 275.911\n",
      "[117]\tvalid_0's tweedie: 275.912\n",
      "[118]\tvalid_0's tweedie: 275.911\n",
      "[119]\tvalid_0's tweedie: 275.91\n",
      "[120]\tvalid_0's tweedie: 275.91\n",
      "[121]\tvalid_0's tweedie: 275.91\n",
      "[122]\tvalid_0's tweedie: 275.91\n",
      "[123]\tvalid_0's tweedie: 275.91\n",
      "[124]\tvalid_0's tweedie: 275.909\n",
      "[125]\tvalid_0's tweedie: 275.909\n",
      "[126]\tvalid_0's tweedie: 275.908\n",
      "[127]\tvalid_0's tweedie: 275.908\n",
      "[128]\tvalid_0's tweedie: 275.908\n",
      "[129]\tvalid_0's tweedie: 275.908\n",
      "[130]\tvalid_0's tweedie: 275.908\n",
      "[131]\tvalid_0's tweedie: 275.908\n",
      "[132]\tvalid_0's tweedie: 275.908\n",
      "[133]\tvalid_0's tweedie: 275.907\n",
      "[134]\tvalid_0's tweedie: 275.907\n",
      "[135]\tvalid_0's tweedie: 275.907\n",
      "[136]\tvalid_0's tweedie: 275.907\n",
      "[137]\tvalid_0's tweedie: 275.906\n",
      "[138]\tvalid_0's tweedie: 275.907\n",
      "[139]\tvalid_0's tweedie: 275.906\n",
      "[140]\tvalid_0's tweedie: 275.906\n",
      "[141]\tvalid_0's tweedie: 275.906\n",
      "[142]\tvalid_0's tweedie: 275.906\n",
      "[143]\tvalid_0's tweedie: 275.905\n",
      "[144]\tvalid_0's tweedie: 275.904\n",
      "[145]\tvalid_0's tweedie: 275.905\n",
      "[146]\tvalid_0's tweedie: 275.904\n",
      "[147]\tvalid_0's tweedie: 275.904\n",
      "[148]\tvalid_0's tweedie: 275.903\n",
      "[149]\tvalid_0's tweedie: 275.903\n",
      "[150]\tvalid_0's tweedie: 275.903\n",
      "[151]\tvalid_0's tweedie: 275.904\n",
      "[152]\tvalid_0's tweedie: 275.903\n",
      "[153]\tvalid_0's tweedie: 275.901\n",
      "[154]\tvalid_0's tweedie: 275.901\n",
      "[155]\tvalid_0's tweedie: 275.901\n",
      "[156]\tvalid_0's tweedie: 275.901\n",
      "[157]\tvalid_0's tweedie: 275.901\n",
      "[158]\tvalid_0's tweedie: 275.9\n",
      "[159]\tvalid_0's tweedie: 275.9\n",
      "[160]\tvalid_0's tweedie: 275.9\n",
      "[161]\tvalid_0's tweedie: 275.9\n",
      "[162]\tvalid_0's tweedie: 275.9\n",
      "[163]\tvalid_0's tweedie: 275.9\n",
      "[164]\tvalid_0's tweedie: 275.898\n",
      "[165]\tvalid_0's tweedie: 275.899\n",
      "[166]\tvalid_0's tweedie: 275.898\n",
      "[167]\tvalid_0's tweedie: 275.898\n",
      "[168]\tvalid_0's tweedie: 275.897\n",
      "[169]\tvalid_0's tweedie: 275.898\n",
      "[170]\tvalid_0's tweedie: 275.898\n",
      "[171]\tvalid_0's tweedie: 275.898\n",
      "[172]\tvalid_0's tweedie: 275.898\n",
      "[173]\tvalid_0's tweedie: 275.898\n",
      "[174]\tvalid_0's tweedie: 275.898\n",
      "[175]\tvalid_0's tweedie: 275.898\n",
      "[176]\tvalid_0's tweedie: 275.898\n",
      "[177]\tvalid_0's tweedie: 275.898\n",
      "[178]\tvalid_0's tweedie: 275.899\n",
      "[179]\tvalid_0's tweedie: 275.899\n",
      "[180]\tvalid_0's tweedie: 275.898\n",
      "[181]\tvalid_0's tweedie: 275.898\n",
      "[182]\tvalid_0's tweedie: 275.898\n",
      "[183]\tvalid_0's tweedie: 275.899\n",
      "[184]\tvalid_0's tweedie: 275.899\n",
      "[185]\tvalid_0's tweedie: 275.899\n",
      "[186]\tvalid_0's tweedie: 275.899\n",
      "[187]\tvalid_0's tweedie: 275.899\n",
      "[188]\tvalid_0's tweedie: 275.899\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's tweedie: 275.897\n",
      "Training model for level 5 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5511\n",
      "[LightGBM] [Info] Number of data points in the train set: 13083, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496222\n",
      "[1]\tvalid_0's tweedie: 306.686\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.701\n",
      "[3]\tvalid_0's tweedie: 297.476\n",
      "[4]\tvalid_0's tweedie: 293.896\n",
      "[5]\tvalid_0's tweedie: 290.873\n",
      "[6]\tvalid_0's tweedie: 288.334\n",
      "[7]\tvalid_0's tweedie: 286.216\n",
      "[8]\tvalid_0's tweedie: 284.434\n",
      "[9]\tvalid_0's tweedie: 282.984\n",
      "[10]\tvalid_0's tweedie: 281.772\n",
      "[11]\tvalid_0's tweedie: 280.77\n",
      "[12]\tvalid_0's tweedie: 279.943\n",
      "[13]\tvalid_0's tweedie: 279.26\n",
      "[14]\tvalid_0's tweedie: 278.709\n",
      "[15]\tvalid_0's tweedie: 278.245\n",
      "[16]\tvalid_0's tweedie: 277.87\n",
      "[17]\tvalid_0's tweedie: 277.556\n",
      "[18]\tvalid_0's tweedie: 277.302\n",
      "[19]\tvalid_0's tweedie: 277.082\n",
      "[20]\tvalid_0's tweedie: 276.904\n",
      "[21]\tvalid_0's tweedie: 276.761\n",
      "[22]\tvalid_0's tweedie: 276.644\n",
      "[23]\tvalid_0's tweedie: 276.542\n",
      "[24]\tvalid_0's tweedie: 276.452\n",
      "[25]\tvalid_0's tweedie: 276.384\n",
      "[26]\tvalid_0's tweedie: 276.328\n",
      "[27]\tvalid_0's tweedie: 276.281\n",
      "[28]\tvalid_0's tweedie: 276.24\n",
      "[29]\tvalid_0's tweedie: 276.209\n",
      "[30]\tvalid_0's tweedie: 276.181\n",
      "[31]\tvalid_0's tweedie: 276.149\n",
      "[32]\tvalid_0's tweedie: 276.123\n",
      "[33]\tvalid_0's tweedie: 276.106\n",
      "[34]\tvalid_0's tweedie: 276.094\n",
      "[35]\tvalid_0's tweedie: 276.079\n",
      "[36]\tvalid_0's tweedie: 276.064\n",
      "[37]\tvalid_0's tweedie: 276.053\n",
      "[38]\tvalid_0's tweedie: 276.044\n",
      "[39]\tvalid_0's tweedie: 276.036\n",
      "[40]\tvalid_0's tweedie: 276.029\n",
      "[41]\tvalid_0's tweedie: 276.02\n",
      "[42]\tvalid_0's tweedie: 276.012\n",
      "[43]\tvalid_0's tweedie: 276.004\n",
      "[44]\tvalid_0's tweedie: 275.999\n",
      "[45]\tvalid_0's tweedie: 275.994\n",
      "[46]\tvalid_0's tweedie: 275.991\n",
      "[47]\tvalid_0's tweedie: 275.989\n",
      "[48]\tvalid_0's tweedie: 275.985\n",
      "[49]\tvalid_0's tweedie: 275.982\n",
      "[50]\tvalid_0's tweedie: 275.98\n",
      "[51]\tvalid_0's tweedie: 275.978\n",
      "[52]\tvalid_0's tweedie: 275.975\n",
      "[53]\tvalid_0's tweedie: 275.973\n",
      "[54]\tvalid_0's tweedie: 275.969\n",
      "[55]\tvalid_0's tweedie: 275.967\n",
      "[56]\tvalid_0's tweedie: 275.963\n",
      "[57]\tvalid_0's tweedie: 275.96\n",
      "[58]\tvalid_0's tweedie: 275.959\n",
      "[59]\tvalid_0's tweedie: 275.956\n",
      "[60]\tvalid_0's tweedie: 275.955\n",
      "[61]\tvalid_0's tweedie: 275.954\n",
      "[62]\tvalid_0's tweedie: 275.953\n",
      "[63]\tvalid_0's tweedie: 275.951\n",
      "[64]\tvalid_0's tweedie: 275.95\n",
      "[65]\tvalid_0's tweedie: 275.949\n",
      "[66]\tvalid_0's tweedie: 275.948\n",
      "[67]\tvalid_0's tweedie: 275.947\n",
      "[68]\tvalid_0's tweedie: 275.946\n",
      "[69]\tvalid_0's tweedie: 275.946\n",
      "[70]\tvalid_0's tweedie: 275.944\n",
      "[71]\tvalid_0's tweedie: 275.943\n",
      "[72]\tvalid_0's tweedie: 275.94\n",
      "[73]\tvalid_0's tweedie: 275.939\n",
      "[74]\tvalid_0's tweedie: 275.938\n",
      "[75]\tvalid_0's tweedie: 275.938\n",
      "[76]\tvalid_0's tweedie: 275.938\n",
      "[77]\tvalid_0's tweedie: 275.937\n",
      "[78]\tvalid_0's tweedie: 275.937\n",
      "[79]\tvalid_0's tweedie: 275.936\n",
      "[80]\tvalid_0's tweedie: 275.934\n",
      "[81]\tvalid_0's tweedie: 275.932\n",
      "[82]\tvalid_0's tweedie: 275.93\n",
      "[83]\tvalid_0's tweedie: 275.93\n",
      "[84]\tvalid_0's tweedie: 275.929\n",
      "[85]\tvalid_0's tweedie: 275.928\n",
      "[86]\tvalid_0's tweedie: 275.927\n",
      "[87]\tvalid_0's tweedie: 275.928\n",
      "[88]\tvalid_0's tweedie: 275.926\n",
      "[89]\tvalid_0's tweedie: 275.926\n",
      "[90]\tvalid_0's tweedie: 275.926\n",
      "[91]\tvalid_0's tweedie: 275.926\n",
      "[92]\tvalid_0's tweedie: 275.926\n",
      "[93]\tvalid_0's tweedie: 275.926\n",
      "[94]\tvalid_0's tweedie: 275.923\n",
      "[95]\tvalid_0's tweedie: 275.923\n",
      "[96]\tvalid_0's tweedie: 275.923\n",
      "[97]\tvalid_0's tweedie: 275.923\n",
      "[98]\tvalid_0's tweedie: 275.923\n",
      "[99]\tvalid_0's tweedie: 275.921\n",
      "[100]\tvalid_0's tweedie: 275.921\n",
      "[101]\tvalid_0's tweedie: 275.921\n",
      "[102]\tvalid_0's tweedie: 275.921\n",
      "[103]\tvalid_0's tweedie: 275.922\n",
      "[104]\tvalid_0's tweedie: 275.922\n",
      "[105]\tvalid_0's tweedie: 275.922\n",
      "[106]\tvalid_0's tweedie: 275.922\n",
      "[107]\tvalid_0's tweedie: 275.922\n",
      "[108]\tvalid_0's tweedie: 275.922\n",
      "[109]\tvalid_0's tweedie: 275.921\n",
      "[110]\tvalid_0's tweedie: 275.92\n",
      "[111]\tvalid_0's tweedie: 275.92\n",
      "[112]\tvalid_0's tweedie: 275.918\n",
      "[113]\tvalid_0's tweedie: 275.918\n",
      "[114]\tvalid_0's tweedie: 275.918\n",
      "[115]\tvalid_0's tweedie: 275.918\n",
      "[116]\tvalid_0's tweedie: 275.918\n",
      "[117]\tvalid_0's tweedie: 275.918\n",
      "[118]\tvalid_0's tweedie: 275.918\n",
      "[119]\tvalid_0's tweedie: 275.918\n",
      "[120]\tvalid_0's tweedie: 275.918\n",
      "[121]\tvalid_0's tweedie: 275.918\n",
      "[122]\tvalid_0's tweedie: 275.918\n",
      "[123]\tvalid_0's tweedie: 275.916\n",
      "[124]\tvalid_0's tweedie: 275.916\n",
      "[125]\tvalid_0's tweedie: 275.916\n",
      "[126]\tvalid_0's tweedie: 275.916\n",
      "[127]\tvalid_0's tweedie: 275.916\n",
      "[128]\tvalid_0's tweedie: 275.916\n",
      "[129]\tvalid_0's tweedie: 275.914\n",
      "[130]\tvalid_0's tweedie: 275.914\n",
      "[131]\tvalid_0's tweedie: 275.914\n",
      "[132]\tvalid_0's tweedie: 275.914\n",
      "[133]\tvalid_0's tweedie: 275.914\n",
      "[134]\tvalid_0's tweedie: 275.914\n",
      "[135]\tvalid_0's tweedie: 275.914\n",
      "[136]\tvalid_0's tweedie: 275.914\n",
      "[137]\tvalid_0's tweedie: 275.914\n",
      "[138]\tvalid_0's tweedie: 275.914\n",
      "[139]\tvalid_0's tweedie: 275.913\n",
      "[140]\tvalid_0's tweedie: 275.913\n",
      "[141]\tvalid_0's tweedie: 275.913\n",
      "[142]\tvalid_0's tweedie: 275.913\n",
      "[143]\tvalid_0's tweedie: 275.913\n",
      "[144]\tvalid_0's tweedie: 275.913\n",
      "[145]\tvalid_0's tweedie: 275.913\n",
      "[146]\tvalid_0's tweedie: 275.912\n",
      "[147]\tvalid_0's tweedie: 275.912\n",
      "[148]\tvalid_0's tweedie: 275.911\n",
      "[149]\tvalid_0's tweedie: 275.912\n",
      "[150]\tvalid_0's tweedie: 275.912\n",
      "[151]\tvalid_0's tweedie: 275.911\n",
      "[152]\tvalid_0's tweedie: 275.911\n",
      "[153]\tvalid_0's tweedie: 275.911\n",
      "[154]\tvalid_0's tweedie: 275.91\n",
      "[155]\tvalid_0's tweedie: 275.91\n",
      "[156]\tvalid_0's tweedie: 275.908\n",
      "[157]\tvalid_0's tweedie: 275.908\n",
      "[158]\tvalid_0's tweedie: 275.908\n",
      "[159]\tvalid_0's tweedie: 275.908\n",
      "[160]\tvalid_0's tweedie: 275.907\n",
      "[161]\tvalid_0's tweedie: 275.907\n",
      "[162]\tvalid_0's tweedie: 275.907\n",
      "[163]\tvalid_0's tweedie: 275.907\n",
      "[164]\tvalid_0's tweedie: 275.907\n",
      "[165]\tvalid_0's tweedie: 275.907\n",
      "[166]\tvalid_0's tweedie: 275.907\n",
      "[167]\tvalid_0's tweedie: 275.907\n",
      "[168]\tvalid_0's tweedie: 275.906\n",
      "[169]\tvalid_0's tweedie: 275.906\n",
      "[170]\tvalid_0's tweedie: 275.906\n",
      "[171]\tvalid_0's tweedie: 275.906\n",
      "[172]\tvalid_0's tweedie: 275.906\n",
      "[173]\tvalid_0's tweedie: 275.906\n",
      "[174]\tvalid_0's tweedie: 275.906\n",
      "[175]\tvalid_0's tweedie: 275.905\n",
      "[176]\tvalid_0's tweedie: 275.905\n",
      "[177]\tvalid_0's tweedie: 275.905\n",
      "[178]\tvalid_0's tweedie: 275.905\n",
      "[179]\tvalid_0's tweedie: 275.905\n",
      "[180]\tvalid_0's tweedie: 275.905\n",
      "[181]\tvalid_0's tweedie: 275.905\n",
      "[182]\tvalid_0's tweedie: 275.905\n",
      "[183]\tvalid_0's tweedie: 275.905\n",
      "[184]\tvalid_0's tweedie: 275.905\n",
      "[185]\tvalid_0's tweedie: 275.905\n",
      "[186]\tvalid_0's tweedie: 275.905\n",
      "[187]\tvalid_0's tweedie: 275.905\n",
      "[188]\tvalid_0's tweedie: 275.904\n",
      "[189]\tvalid_0's tweedie: 275.904\n",
      "[190]\tvalid_0's tweedie: 275.903\n",
      "[191]\tvalid_0's tweedie: 275.903\n",
      "[192]\tvalid_0's tweedie: 275.905\n",
      "[193]\tvalid_0's tweedie: 275.905\n",
      "[194]\tvalid_0's tweedie: 275.905\n",
      "[195]\tvalid_0's tweedie: 275.905\n",
      "[196]\tvalid_0's tweedie: 275.905\n",
      "[197]\tvalid_0's tweedie: 275.905\n",
      "[198]\tvalid_0's tweedie: 275.905\n",
      "[199]\tvalid_0's tweedie: 275.905\n",
      "[200]\tvalid_0's tweedie: 275.903\n",
      "[201]\tvalid_0's tweedie: 275.903\n",
      "[202]\tvalid_0's tweedie: 275.903\n",
      "[203]\tvalid_0's tweedie: 275.903\n",
      "[204]\tvalid_0's tweedie: 275.901\n",
      "[205]\tvalid_0's tweedie: 275.901\n",
      "[206]\tvalid_0's tweedie: 275.901\n",
      "[207]\tvalid_0's tweedie: 275.899\n",
      "[208]\tvalid_0's tweedie: 275.899\n",
      "[209]\tvalid_0's tweedie: 275.899\n",
      "[210]\tvalid_0's tweedie: 275.899\n",
      "[211]\tvalid_0's tweedie: 275.899\n",
      "[212]\tvalid_0's tweedie: 275.899\n",
      "[213]\tvalid_0's tweedie: 275.899\n",
      "[214]\tvalid_0's tweedie: 275.898\n",
      "[215]\tvalid_0's tweedie: 275.898\n",
      "[216]\tvalid_0's tweedie: 275.899\n",
      "[217]\tvalid_0's tweedie: 275.898\n",
      "[218]\tvalid_0's tweedie: 275.898\n",
      "[219]\tvalid_0's tweedie: 275.898\n",
      "[220]\tvalid_0's tweedie: 275.898\n",
      "[221]\tvalid_0's tweedie: 275.898\n",
      "[222]\tvalid_0's tweedie: 275.897\n",
      "[223]\tvalid_0's tweedie: 275.896\n",
      "[224]\tvalid_0's tweedie: 275.896\n",
      "[225]\tvalid_0's tweedie: 275.896\n",
      "[226]\tvalid_0's tweedie: 275.896\n",
      "[227]\tvalid_0's tweedie: 275.896\n",
      "[228]\tvalid_0's tweedie: 275.897\n",
      "[229]\tvalid_0's tweedie: 275.898\n",
      "[230]\tvalid_0's tweedie: 275.898\n",
      "[231]\tvalid_0's tweedie: 275.898\n",
      "[232]\tvalid_0's tweedie: 275.899\n",
      "[233]\tvalid_0's tweedie: 275.899\n",
      "[234]\tvalid_0's tweedie: 275.899\n",
      "[235]\tvalid_0's tweedie: 275.899\n",
      "[236]\tvalid_0's tweedie: 275.899\n",
      "[237]\tvalid_0's tweedie: 275.899\n",
      "[238]\tvalid_0's tweedie: 275.898\n",
      "[239]\tvalid_0's tweedie: 275.899\n",
      "[240]\tvalid_0's tweedie: 275.898\n",
      "[241]\tvalid_0's tweedie: 275.898\n",
      "[242]\tvalid_0's tweedie: 275.898\n",
      "[243]\tvalid_0's tweedie: 275.898\n",
      "[244]\tvalid_0's tweedie: 275.898\n",
      "[245]\tvalid_0's tweedie: 275.898\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's tweedie: 275.896\n",
      "Training model for level 5 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13076, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496417\n",
      "[1]\tvalid_0's tweedie: 306.688\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.703\n",
      "[3]\tvalid_0's tweedie: 297.483\n",
      "[4]\tvalid_0's tweedie: 293.895\n",
      "[5]\tvalid_0's tweedie: 290.866\n",
      "[6]\tvalid_0's tweedie: 288.347\n",
      "[7]\tvalid_0's tweedie: 286.197\n",
      "[8]\tvalid_0's tweedie: 284.456\n",
      "[9]\tvalid_0's tweedie: 282.983\n",
      "[10]\tvalid_0's tweedie: 281.77\n",
      "[11]\tvalid_0's tweedie: 280.775\n",
      "[12]\tvalid_0's tweedie: 279.956\n",
      "[13]\tvalid_0's tweedie: 279.282\n",
      "[14]\tvalid_0's tweedie: 278.717\n",
      "[15]\tvalid_0's tweedie: 278.254\n",
      "[16]\tvalid_0's tweedie: 277.863\n",
      "[17]\tvalid_0's tweedie: 277.548\n",
      "[18]\tvalid_0's tweedie: 277.29\n",
      "[19]\tvalid_0's tweedie: 277.077\n",
      "[20]\tvalid_0's tweedie: 276.891\n",
      "[21]\tvalid_0's tweedie: 276.74\n",
      "[22]\tvalid_0's tweedie: 276.62\n",
      "[23]\tvalid_0's tweedie: 276.52\n",
      "[24]\tvalid_0's tweedie: 276.434\n",
      "[25]\tvalid_0's tweedie: 276.358\n",
      "[26]\tvalid_0's tweedie: 276.304\n",
      "[27]\tvalid_0's tweedie: 276.256\n",
      "[28]\tvalid_0's tweedie: 276.215\n",
      "[29]\tvalid_0's tweedie: 276.179\n",
      "[30]\tvalid_0's tweedie: 276.151\n",
      "[31]\tvalid_0's tweedie: 276.128\n",
      "[32]\tvalid_0's tweedie: 276.108\n",
      "[33]\tvalid_0's tweedie: 276.086\n",
      "[34]\tvalid_0's tweedie: 276.066\n",
      "[35]\tvalid_0's tweedie: 276.052\n",
      "[36]\tvalid_0's tweedie: 276.042\n",
      "[37]\tvalid_0's tweedie: 276.03\n",
      "[38]\tvalid_0's tweedie: 276.023\n",
      "[39]\tvalid_0's tweedie: 276.015\n",
      "[40]\tvalid_0's tweedie: 276.005\n",
      "[41]\tvalid_0's tweedie: 275.999\n",
      "[42]\tvalid_0's tweedie: 275.994\n",
      "[43]\tvalid_0's tweedie: 275.99\n",
      "[44]\tvalid_0's tweedie: 275.986\n",
      "[45]\tvalid_0's tweedie: 275.983\n",
      "[46]\tvalid_0's tweedie: 275.976\n",
      "[47]\tvalid_0's tweedie: 275.973\n",
      "[48]\tvalid_0's tweedie: 275.971\n",
      "[49]\tvalid_0's tweedie: 275.965\n",
      "[50]\tvalid_0's tweedie: 275.965\n",
      "[51]\tvalid_0's tweedie: 275.962\n",
      "[52]\tvalid_0's tweedie: 275.96\n",
      "[53]\tvalid_0's tweedie: 275.959\n",
      "[54]\tvalid_0's tweedie: 275.956\n",
      "[55]\tvalid_0's tweedie: 275.954\n",
      "[56]\tvalid_0's tweedie: 275.952\n",
      "[57]\tvalid_0's tweedie: 275.95\n",
      "[58]\tvalid_0's tweedie: 275.948\n",
      "[59]\tvalid_0's tweedie: 275.947\n",
      "[60]\tvalid_0's tweedie: 275.946\n",
      "[61]\tvalid_0's tweedie: 275.945\n",
      "[62]\tvalid_0's tweedie: 275.943\n",
      "[63]\tvalid_0's tweedie: 275.942\n",
      "[64]\tvalid_0's tweedie: 275.941\n",
      "[65]\tvalid_0's tweedie: 275.941\n",
      "[66]\tvalid_0's tweedie: 275.94\n",
      "[67]\tvalid_0's tweedie: 275.94\n",
      "[68]\tvalid_0's tweedie: 275.94\n",
      "[69]\tvalid_0's tweedie: 275.94\n",
      "[70]\tvalid_0's tweedie: 275.939\n",
      "[71]\tvalid_0's tweedie: 275.938\n",
      "[72]\tvalid_0's tweedie: 275.937\n",
      "[73]\tvalid_0's tweedie: 275.937\n",
      "[74]\tvalid_0's tweedie: 275.937\n",
      "[75]\tvalid_0's tweedie: 275.937\n",
      "[76]\tvalid_0's tweedie: 275.937\n",
      "[77]\tvalid_0's tweedie: 275.937\n",
      "[78]\tvalid_0's tweedie: 275.937\n",
      "[79]\tvalid_0's tweedie: 275.936\n",
      "[80]\tvalid_0's tweedie: 275.936\n",
      "[81]\tvalid_0's tweedie: 275.936\n",
      "[82]\tvalid_0's tweedie: 275.938\n",
      "[83]\tvalid_0's tweedie: 275.938\n",
      "[84]\tvalid_0's tweedie: 275.936\n",
      "[85]\tvalid_0's tweedie: 275.935\n",
      "[86]\tvalid_0's tweedie: 275.935\n",
      "[87]\tvalid_0's tweedie: 275.935\n",
      "[88]\tvalid_0's tweedie: 275.933\n",
      "[89]\tvalid_0's tweedie: 275.933\n",
      "[90]\tvalid_0's tweedie: 275.932\n",
      "[91]\tvalid_0's tweedie: 275.932\n",
      "[92]\tvalid_0's tweedie: 275.932\n",
      "[93]\tvalid_0's tweedie: 275.932\n",
      "[94]\tvalid_0's tweedie: 275.932\n",
      "[95]\tvalid_0's tweedie: 275.932\n",
      "[96]\tvalid_0's tweedie: 275.932\n",
      "[97]\tvalid_0's tweedie: 275.932\n",
      "[98]\tvalid_0's tweedie: 275.93\n",
      "[99]\tvalid_0's tweedie: 275.929\n",
      "[100]\tvalid_0's tweedie: 275.929\n",
      "[101]\tvalid_0's tweedie: 275.929\n",
      "[102]\tvalid_0's tweedie: 275.929\n",
      "[103]\tvalid_0's tweedie: 275.928\n",
      "[104]\tvalid_0's tweedie: 275.928\n",
      "[105]\tvalid_0's tweedie: 275.929\n",
      "[106]\tvalid_0's tweedie: 275.928\n",
      "[107]\tvalid_0's tweedie: 275.929\n",
      "[108]\tvalid_0's tweedie: 275.929\n",
      "[109]\tvalid_0's tweedie: 275.929\n",
      "[110]\tvalid_0's tweedie: 275.929\n",
      "[111]\tvalid_0's tweedie: 275.928\n",
      "[112]\tvalid_0's tweedie: 275.928\n",
      "[113]\tvalid_0's tweedie: 275.928\n",
      "[114]\tvalid_0's tweedie: 275.928\n",
      "[115]\tvalid_0's tweedie: 275.927\n",
      "[116]\tvalid_0's tweedie: 275.925\n",
      "[117]\tvalid_0's tweedie: 275.925\n",
      "[118]\tvalid_0's tweedie: 275.924\n",
      "[119]\tvalid_0's tweedie: 275.925\n",
      "[120]\tvalid_0's tweedie: 275.925\n",
      "[121]\tvalid_0's tweedie: 275.925\n",
      "[122]\tvalid_0's tweedie: 275.925\n",
      "[123]\tvalid_0's tweedie: 275.926\n",
      "[124]\tvalid_0's tweedie: 275.926\n",
      "[125]\tvalid_0's tweedie: 275.926\n",
      "[126]\tvalid_0's tweedie: 275.926\n",
      "[127]\tvalid_0's tweedie: 275.924\n",
      "[128]\tvalid_0's tweedie: 275.924\n",
      "[129]\tvalid_0's tweedie: 275.923\n",
      "[130]\tvalid_0's tweedie: 275.923\n",
      "[131]\tvalid_0's tweedie: 275.925\n",
      "[132]\tvalid_0's tweedie: 275.925\n",
      "[133]\tvalid_0's tweedie: 275.924\n",
      "[134]\tvalid_0's tweedie: 275.924\n",
      "[135]\tvalid_0's tweedie: 275.923\n",
      "[136]\tvalid_0's tweedie: 275.923\n",
      "[137]\tvalid_0's tweedie: 275.923\n",
      "[138]\tvalid_0's tweedie: 275.924\n",
      "[139]\tvalid_0's tweedie: 275.924\n",
      "[140]\tvalid_0's tweedie: 275.925\n",
      "[141]\tvalid_0's tweedie: 275.922\n",
      "[142]\tvalid_0's tweedie: 275.922\n",
      "[143]\tvalid_0's tweedie: 275.923\n",
      "[144]\tvalid_0's tweedie: 275.923\n",
      "[145]\tvalid_0's tweedie: 275.923\n",
      "[146]\tvalid_0's tweedie: 275.923\n",
      "[147]\tvalid_0's tweedie: 275.923\n",
      "[148]\tvalid_0's tweedie: 275.922\n",
      "[149]\tvalid_0's tweedie: 275.922\n",
      "[150]\tvalid_0's tweedie: 275.922\n",
      "[151]\tvalid_0's tweedie: 275.922\n",
      "[152]\tvalid_0's tweedie: 275.922\n",
      "[153]\tvalid_0's tweedie: 275.922\n",
      "[154]\tvalid_0's tweedie: 275.922\n",
      "[155]\tvalid_0's tweedie: 275.923\n",
      "[156]\tvalid_0's tweedie: 275.923\n",
      "[157]\tvalid_0's tweedie: 275.923\n",
      "[158]\tvalid_0's tweedie: 275.923\n",
      "[159]\tvalid_0's tweedie: 275.922\n",
      "[160]\tvalid_0's tweedie: 275.923\n",
      "[161]\tvalid_0's tweedie: 275.923\n",
      "[162]\tvalid_0's tweedie: 275.922\n",
      "[163]\tvalid_0's tweedie: 275.922\n",
      "[164]\tvalid_0's tweedie: 275.922\n",
      "[165]\tvalid_0's tweedie: 275.922\n",
      "[166]\tvalid_0's tweedie: 275.922\n",
      "[167]\tvalid_0's tweedie: 275.922\n",
      "[168]\tvalid_0's tweedie: 275.922\n",
      "[169]\tvalid_0's tweedie: 275.923\n",
      "[170]\tvalid_0's tweedie: 275.923\n",
      "[171]\tvalid_0's tweedie: 275.923\n",
      "[172]\tvalid_0's tweedie: 275.923\n",
      "[173]\tvalid_0's tweedie: 275.922\n",
      "[174]\tvalid_0's tweedie: 275.922\n",
      "[175]\tvalid_0's tweedie: 275.922\n",
      "[176]\tvalid_0's tweedie: 275.922\n",
      "[177]\tvalid_0's tweedie: 275.922\n",
      "[178]\tvalid_0's tweedie: 275.922\n",
      "[179]\tvalid_0's tweedie: 275.921\n",
      "[180]\tvalid_0's tweedie: 275.921\n",
      "[181]\tvalid_0's tweedie: 275.921\n",
      "[182]\tvalid_0's tweedie: 275.921\n",
      "[183]\tvalid_0's tweedie: 275.921\n",
      "[184]\tvalid_0's tweedie: 275.921\n",
      "[185]\tvalid_0's tweedie: 275.921\n",
      "[186]\tvalid_0's tweedie: 275.921\n",
      "[187]\tvalid_0's tweedie: 275.921\n",
      "[188]\tvalid_0's tweedie: 275.921\n",
      "[189]\tvalid_0's tweedie: 275.921\n",
      "[190]\tvalid_0's tweedie: 275.921\n",
      "[191]\tvalid_0's tweedie: 275.921\n",
      "[192]\tvalid_0's tweedie: 275.921\n",
      "[193]\tvalid_0's tweedie: 275.921\n",
      "[194]\tvalid_0's tweedie: 275.92\n",
      "[195]\tvalid_0's tweedie: 275.92\n",
      "[196]\tvalid_0's tweedie: 275.921\n",
      "[197]\tvalid_0's tweedie: 275.92\n",
      "[198]\tvalid_0's tweedie: 275.92\n",
      "[199]\tvalid_0's tweedie: 275.92\n",
      "[200]\tvalid_0's tweedie: 275.918\n",
      "[201]\tvalid_0's tweedie: 275.918\n",
      "[202]\tvalid_0's tweedie: 275.918\n",
      "[203]\tvalid_0's tweedie: 275.918\n",
      "[204]\tvalid_0's tweedie: 275.918\n",
      "[205]\tvalid_0's tweedie: 275.918\n",
      "[206]\tvalid_0's tweedie: 275.918\n",
      "[207]\tvalid_0's tweedie: 275.918\n",
      "[208]\tvalid_0's tweedie: 275.918\n",
      "[209]\tvalid_0's tweedie: 275.919\n",
      "[210]\tvalid_0's tweedie: 275.918\n",
      "[211]\tvalid_0's tweedie: 275.918\n",
      "[212]\tvalid_0's tweedie: 275.918\n",
      "[213]\tvalid_0's tweedie: 275.918\n",
      "[214]\tvalid_0's tweedie: 275.918\n",
      "[215]\tvalid_0's tweedie: 275.918\n",
      "[216]\tvalid_0's tweedie: 275.918\n",
      "[217]\tvalid_0's tweedie: 275.918\n",
      "[218]\tvalid_0's tweedie: 275.918\n",
      "[219]\tvalid_0's tweedie: 275.917\n",
      "[220]\tvalid_0's tweedie: 275.917\n",
      "[221]\tvalid_0's tweedie: 275.918\n",
      "[222]\tvalid_0's tweedie: 275.918\n",
      "[223]\tvalid_0's tweedie: 275.918\n",
      "[224]\tvalid_0's tweedie: 275.918\n",
      "[225]\tvalid_0's tweedie: 275.918\n",
      "[226]\tvalid_0's tweedie: 275.918\n",
      "[227]\tvalid_0's tweedie: 275.918\n",
      "[228]\tvalid_0's tweedie: 275.918\n",
      "[229]\tvalid_0's tweedie: 275.918\n",
      "[230]\tvalid_0's tweedie: 275.918\n",
      "[231]\tvalid_0's tweedie: 275.918\n",
      "[232]\tvalid_0's tweedie: 275.918\n",
      "[233]\tvalid_0's tweedie: 275.918\n",
      "[234]\tvalid_0's tweedie: 275.918\n",
      "[235]\tvalid_0's tweedie: 275.918\n",
      "[236]\tvalid_0's tweedie: 275.918\n",
      "[237]\tvalid_0's tweedie: 275.918\n",
      "[238]\tvalid_0's tweedie: 275.918\n",
      "[239]\tvalid_0's tweedie: 275.918\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's tweedie: 275.917\n",
      "Training model for level 5 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 13069, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496576\n",
      "[1]\tvalid_0's tweedie: 306.711\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.734\n",
      "[3]\tvalid_0's tweedie: 297.521\n",
      "[4]\tvalid_0's tweedie: 293.944\n",
      "[5]\tvalid_0's tweedie: 290.904\n",
      "[6]\tvalid_0's tweedie: 288.378\n",
      "[7]\tvalid_0's tweedie: 286.263\n",
      "[8]\tvalid_0's tweedie: 284.508\n",
      "[9]\tvalid_0's tweedie: 283.03\n",
      "[10]\tvalid_0's tweedie: 281.817\n",
      "[11]\tvalid_0's tweedie: 280.822\n",
      "[12]\tvalid_0's tweedie: 280.009\n",
      "[13]\tvalid_0's tweedie: 279.326\n",
      "[14]\tvalid_0's tweedie: 278.757\n",
      "[15]\tvalid_0's tweedie: 278.289\n",
      "[16]\tvalid_0's tweedie: 277.906\n",
      "[17]\tvalid_0's tweedie: 277.588\n",
      "[18]\tvalid_0's tweedie: 277.33\n",
      "[19]\tvalid_0's tweedie: 277.116\n",
      "[20]\tvalid_0's tweedie: 276.935\n",
      "[21]\tvalid_0's tweedie: 276.793\n",
      "[22]\tvalid_0's tweedie: 276.664\n",
      "[23]\tvalid_0's tweedie: 276.56\n",
      "[24]\tvalid_0's tweedie: 276.47\n",
      "[25]\tvalid_0's tweedie: 276.404\n",
      "[26]\tvalid_0's tweedie: 276.343\n",
      "[27]\tvalid_0's tweedie: 276.293\n",
      "[28]\tvalid_0's tweedie: 276.247\n",
      "[29]\tvalid_0's tweedie: 276.207\n",
      "[30]\tvalid_0's tweedie: 276.18\n",
      "[31]\tvalid_0's tweedie: 276.151\n",
      "[32]\tvalid_0's tweedie: 276.128\n",
      "[33]\tvalid_0's tweedie: 276.108\n",
      "[34]\tvalid_0's tweedie: 276.093\n",
      "[35]\tvalid_0's tweedie: 276.077\n",
      "[36]\tvalid_0's tweedie: 276.064\n",
      "[37]\tvalid_0's tweedie: 276.056\n",
      "[38]\tvalid_0's tweedie: 276.049\n",
      "[39]\tvalid_0's tweedie: 276.042\n",
      "[40]\tvalid_0's tweedie: 276.035\n",
      "[41]\tvalid_0's tweedie: 276.027\n",
      "[42]\tvalid_0's tweedie: 276.022\n",
      "[43]\tvalid_0's tweedie: 276.017\n",
      "[44]\tvalid_0's tweedie: 276.014\n",
      "[45]\tvalid_0's tweedie: 276.009\n",
      "[46]\tvalid_0's tweedie: 276.006\n",
      "[47]\tvalid_0's tweedie: 276.002\n",
      "[48]\tvalid_0's tweedie: 275.998\n",
      "[49]\tvalid_0's tweedie: 275.996\n",
      "[50]\tvalid_0's tweedie: 275.994\n",
      "[51]\tvalid_0's tweedie: 275.995\n",
      "[52]\tvalid_0's tweedie: 275.991\n",
      "[53]\tvalid_0's tweedie: 275.989\n",
      "[54]\tvalid_0's tweedie: 275.988\n",
      "[55]\tvalid_0's tweedie: 275.986\n",
      "[56]\tvalid_0's tweedie: 275.982\n",
      "[57]\tvalid_0's tweedie: 275.979\n",
      "[58]\tvalid_0's tweedie: 275.977\n",
      "[59]\tvalid_0's tweedie: 275.973\n",
      "[60]\tvalid_0's tweedie: 275.971\n",
      "[61]\tvalid_0's tweedie: 275.97\n",
      "[62]\tvalid_0's tweedie: 275.968\n",
      "[63]\tvalid_0's tweedie: 275.967\n",
      "[64]\tvalid_0's tweedie: 275.965\n",
      "[65]\tvalid_0's tweedie: 275.964\n",
      "[66]\tvalid_0's tweedie: 275.963\n",
      "[67]\tvalid_0's tweedie: 275.962\n",
      "[68]\tvalid_0's tweedie: 275.962\n",
      "[69]\tvalid_0's tweedie: 275.961\n",
      "[70]\tvalid_0's tweedie: 275.961\n",
      "[71]\tvalid_0's tweedie: 275.96\n",
      "[72]\tvalid_0's tweedie: 275.959\n",
      "[73]\tvalid_0's tweedie: 275.958\n",
      "[74]\tvalid_0's tweedie: 275.956\n",
      "[75]\tvalid_0's tweedie: 275.955\n",
      "[76]\tvalid_0's tweedie: 275.954\n",
      "[77]\tvalid_0's tweedie: 275.954\n",
      "[78]\tvalid_0's tweedie: 275.953\n",
      "[79]\tvalid_0's tweedie: 275.953\n",
      "[80]\tvalid_0's tweedie: 275.951\n",
      "[81]\tvalid_0's tweedie: 275.949\n",
      "[82]\tvalid_0's tweedie: 275.949\n",
      "[83]\tvalid_0's tweedie: 275.947\n",
      "[84]\tvalid_0's tweedie: 275.946\n",
      "[85]\tvalid_0's tweedie: 275.945\n",
      "[86]\tvalid_0's tweedie: 275.945\n",
      "[87]\tvalid_0's tweedie: 275.945\n",
      "[88]\tvalid_0's tweedie: 275.944\n",
      "[89]\tvalid_0's tweedie: 275.944\n",
      "[90]\tvalid_0's tweedie: 275.944\n",
      "[91]\tvalid_0's tweedie: 275.944\n",
      "[92]\tvalid_0's tweedie: 275.943\n",
      "[93]\tvalid_0's tweedie: 275.941\n",
      "[94]\tvalid_0's tweedie: 275.941\n",
      "[95]\tvalid_0's tweedie: 275.942\n",
      "[96]\tvalid_0's tweedie: 275.942\n",
      "[97]\tvalid_0's tweedie: 275.942\n",
      "[98]\tvalid_0's tweedie: 275.941\n",
      "[99]\tvalid_0's tweedie: 275.94\n",
      "[100]\tvalid_0's tweedie: 275.94\n",
      "[101]\tvalid_0's tweedie: 275.94\n",
      "[102]\tvalid_0's tweedie: 275.94\n",
      "[103]\tvalid_0's tweedie: 275.94\n",
      "[104]\tvalid_0's tweedie: 275.939\n",
      "[105]\tvalid_0's tweedie: 275.939\n",
      "[106]\tvalid_0's tweedie: 275.938\n",
      "[107]\tvalid_0's tweedie: 275.938\n",
      "[108]\tvalid_0's tweedie: 275.938\n",
      "[109]\tvalid_0's tweedie: 275.939\n",
      "[110]\tvalid_0's tweedie: 275.938\n",
      "[111]\tvalid_0's tweedie: 275.938\n",
      "[112]\tvalid_0's tweedie: 275.938\n",
      "[113]\tvalid_0's tweedie: 275.938\n",
      "[114]\tvalid_0's tweedie: 275.938\n",
      "[115]\tvalid_0's tweedie: 275.938\n",
      "[116]\tvalid_0's tweedie: 275.938\n",
      "[117]\tvalid_0's tweedie: 275.938\n",
      "[118]\tvalid_0's tweedie: 275.938\n",
      "[119]\tvalid_0's tweedie: 275.937\n",
      "[120]\tvalid_0's tweedie: 275.937\n",
      "[121]\tvalid_0's tweedie: 275.934\n",
      "[122]\tvalid_0's tweedie: 275.934\n",
      "[123]\tvalid_0's tweedie: 275.934\n",
      "[124]\tvalid_0's tweedie: 275.934\n",
      "[125]\tvalid_0's tweedie: 275.934\n",
      "[126]\tvalid_0's tweedie: 275.934\n",
      "[127]\tvalid_0's tweedie: 275.934\n",
      "[128]\tvalid_0's tweedie: 275.933\n",
      "[129]\tvalid_0's tweedie: 275.933\n",
      "[130]\tvalid_0's tweedie: 275.933\n",
      "[131]\tvalid_0's tweedie: 275.932\n",
      "[132]\tvalid_0's tweedie: 275.932\n",
      "[133]\tvalid_0's tweedie: 275.932\n",
      "[134]\tvalid_0's tweedie: 275.932\n",
      "[135]\tvalid_0's tweedie: 275.932\n",
      "[136]\tvalid_0's tweedie: 275.932\n",
      "[137]\tvalid_0's tweedie: 275.932\n",
      "[138]\tvalid_0's tweedie: 275.931\n",
      "[139]\tvalid_0's tweedie: 275.931\n",
      "[140]\tvalid_0's tweedie: 275.932\n",
      "[141]\tvalid_0's tweedie: 275.932\n",
      "[142]\tvalid_0's tweedie: 275.932\n",
      "[143]\tvalid_0's tweedie: 275.932\n",
      "[144]\tvalid_0's tweedie: 275.931\n",
      "[145]\tvalid_0's tweedie: 275.931\n",
      "[146]\tvalid_0's tweedie: 275.931\n",
      "[147]\tvalid_0's tweedie: 275.931\n",
      "[148]\tvalid_0's tweedie: 275.931\n",
      "[149]\tvalid_0's tweedie: 275.931\n",
      "[150]\tvalid_0's tweedie: 275.931\n",
      "[151]\tvalid_0's tweedie: 275.93\n",
      "[152]\tvalid_0's tweedie: 275.929\n",
      "[153]\tvalid_0's tweedie: 275.93\n",
      "[154]\tvalid_0's tweedie: 275.93\n",
      "[155]\tvalid_0's tweedie: 275.93\n",
      "[156]\tvalid_0's tweedie: 275.93\n",
      "[157]\tvalid_0's tweedie: 275.929\n",
      "[158]\tvalid_0's tweedie: 275.93\n",
      "[159]\tvalid_0's tweedie: 275.93\n",
      "[160]\tvalid_0's tweedie: 275.93\n",
      "[161]\tvalid_0's tweedie: 275.93\n",
      "[162]\tvalid_0's tweedie: 275.93\n",
      "[163]\tvalid_0's tweedie: 275.928\n",
      "[164]\tvalid_0's tweedie: 275.928\n",
      "[165]\tvalid_0's tweedie: 275.928\n",
      "[166]\tvalid_0's tweedie: 275.928\n",
      "[167]\tvalid_0's tweedie: 275.928\n",
      "[168]\tvalid_0's tweedie: 275.927\n",
      "[169]\tvalid_0's tweedie: 275.927\n",
      "[170]\tvalid_0's tweedie: 275.927\n",
      "[171]\tvalid_0's tweedie: 275.927\n",
      "[172]\tvalid_0's tweedie: 275.927\n",
      "[173]\tvalid_0's tweedie: 275.927\n",
      "[174]\tvalid_0's tweedie: 275.927\n",
      "[175]\tvalid_0's tweedie: 275.926\n",
      "[176]\tvalid_0's tweedie: 275.926\n",
      "[177]\tvalid_0's tweedie: 275.927\n",
      "[178]\tvalid_0's tweedie: 275.926\n",
      "[179]\tvalid_0's tweedie: 275.926\n",
      "[180]\tvalid_0's tweedie: 275.926\n",
      "[181]\tvalid_0's tweedie: 275.925\n",
      "[182]\tvalid_0's tweedie: 275.925\n",
      "[183]\tvalid_0's tweedie: 275.925\n",
      "[184]\tvalid_0's tweedie: 275.924\n",
      "[185]\tvalid_0's tweedie: 275.924\n",
      "[186]\tvalid_0's tweedie: 275.924\n",
      "[187]\tvalid_0's tweedie: 275.924\n",
      "[188]\tvalid_0's tweedie: 275.922\n",
      "[189]\tvalid_0's tweedie: 275.922\n",
      "[190]\tvalid_0's tweedie: 275.922\n",
      "[191]\tvalid_0's tweedie: 275.922\n",
      "[192]\tvalid_0's tweedie: 275.922\n",
      "[193]\tvalid_0's tweedie: 275.922\n",
      "[194]\tvalid_0's tweedie: 275.922\n",
      "[195]\tvalid_0's tweedie: 275.921\n",
      "[196]\tvalid_0's tweedie: 275.921\n",
      "[197]\tvalid_0's tweedie: 275.921\n",
      "[198]\tvalid_0's tweedie: 275.921\n",
      "[199]\tvalid_0's tweedie: 275.92\n",
      "[200]\tvalid_0's tweedie: 275.921\n",
      "[201]\tvalid_0's tweedie: 275.921\n",
      "[202]\tvalid_0's tweedie: 275.921\n",
      "[203]\tvalid_0's tweedie: 275.921\n",
      "[204]\tvalid_0's tweedie: 275.921\n",
      "[205]\tvalid_0's tweedie: 275.921\n",
      "[206]\tvalid_0's tweedie: 275.921\n",
      "[207]\tvalid_0's tweedie: 275.921\n",
      "[208]\tvalid_0's tweedie: 275.919\n",
      "[209]\tvalid_0's tweedie: 275.918\n",
      "[210]\tvalid_0's tweedie: 275.916\n",
      "[211]\tvalid_0's tweedie: 275.917\n",
      "[212]\tvalid_0's tweedie: 275.917\n",
      "[213]\tvalid_0's tweedie: 275.918\n",
      "[214]\tvalid_0's tweedie: 275.918\n",
      "[215]\tvalid_0's tweedie: 275.918\n",
      "[216]\tvalid_0's tweedie: 275.918\n",
      "[217]\tvalid_0's tweedie: 275.918\n",
      "[218]\tvalid_0's tweedie: 275.918\n",
      "[219]\tvalid_0's tweedie: 275.918\n",
      "[220]\tvalid_0's tweedie: 275.918\n",
      "[221]\tvalid_0's tweedie: 275.918\n",
      "[222]\tvalid_0's tweedie: 275.918\n",
      "[223]\tvalid_0's tweedie: 275.918\n",
      "[224]\tvalid_0's tweedie: 275.918\n",
      "[225]\tvalid_0's tweedie: 275.918\n",
      "[226]\tvalid_0's tweedie: 275.918\n",
      "[227]\tvalid_0's tweedie: 275.918\n",
      "[228]\tvalid_0's tweedie: 275.917\n",
      "[229]\tvalid_0's tweedie: 275.917\n",
      "[230]\tvalid_0's tweedie: 275.917\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's tweedie: 275.916\n",
      "Training model for level 5 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496777\n",
      "[1]\tvalid_0's tweedie: 306.696\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.719\n",
      "[3]\tvalid_0's tweedie: 297.493\n",
      "[4]\tvalid_0's tweedie: 293.921\n",
      "[5]\tvalid_0's tweedie: 290.885\n",
      "[6]\tvalid_0's tweedie: 288.357\n",
      "[7]\tvalid_0's tweedie: 286.231\n",
      "[8]\tvalid_0's tweedie: 284.478\n",
      "[9]\tvalid_0's tweedie: 282.999\n",
      "[10]\tvalid_0's tweedie: 281.793\n",
      "[11]\tvalid_0's tweedie: 280.791\n",
      "[12]\tvalid_0's tweedie: 279.972\n",
      "[13]\tvalid_0's tweedie: 279.282\n",
      "[14]\tvalid_0's tweedie: 278.719\n",
      "[15]\tvalid_0's tweedie: 278.259\n",
      "[16]\tvalid_0's tweedie: 277.879\n",
      "[17]\tvalid_0's tweedie: 277.563\n",
      "[18]\tvalid_0's tweedie: 277.304\n",
      "[19]\tvalid_0's tweedie: 277.082\n",
      "[20]\tvalid_0's tweedie: 276.908\n",
      "[21]\tvalid_0's tweedie: 276.762\n",
      "[22]\tvalid_0's tweedie: 276.643\n",
      "[23]\tvalid_0's tweedie: 276.559\n",
      "[24]\tvalid_0's tweedie: 276.481\n",
      "[25]\tvalid_0's tweedie: 276.412\n",
      "[26]\tvalid_0's tweedie: 276.345\n",
      "[27]\tvalid_0's tweedie: 276.29\n",
      "[28]\tvalid_0's tweedie: 276.246\n",
      "[29]\tvalid_0's tweedie: 276.209\n",
      "[30]\tvalid_0's tweedie: 276.176\n",
      "[31]\tvalid_0's tweedie: 276.15\n",
      "[32]\tvalid_0's tweedie: 276.128\n",
      "[33]\tvalid_0's tweedie: 276.107\n",
      "[34]\tvalid_0's tweedie: 276.094\n",
      "[35]\tvalid_0's tweedie: 276.08\n",
      "[36]\tvalid_0's tweedie: 276.067\n",
      "[37]\tvalid_0's tweedie: 276.054\n",
      "[38]\tvalid_0's tweedie: 276.042\n",
      "[39]\tvalid_0's tweedie: 276.035\n",
      "[40]\tvalid_0's tweedie: 276.028\n",
      "[41]\tvalid_0's tweedie: 276.025\n",
      "[42]\tvalid_0's tweedie: 276.018\n",
      "[43]\tvalid_0's tweedie: 276.013\n",
      "[44]\tvalid_0's tweedie: 276.007\n",
      "[45]\tvalid_0's tweedie: 276.004\n",
      "[46]\tvalid_0's tweedie: 275.995\n",
      "[47]\tvalid_0's tweedie: 275.992\n",
      "[48]\tvalid_0's tweedie: 275.99\n",
      "[49]\tvalid_0's tweedie: 275.987\n",
      "[50]\tvalid_0's tweedie: 275.986\n",
      "[51]\tvalid_0's tweedie: 275.982\n",
      "[52]\tvalid_0's tweedie: 275.982\n",
      "[53]\tvalid_0's tweedie: 275.98\n",
      "[54]\tvalid_0's tweedie: 275.975\n",
      "[55]\tvalid_0's tweedie: 275.972\n",
      "[56]\tvalid_0's tweedie: 275.968\n",
      "[57]\tvalid_0's tweedie: 275.968\n",
      "[58]\tvalid_0's tweedie: 275.965\n",
      "[59]\tvalid_0's tweedie: 275.963\n",
      "[60]\tvalid_0's tweedie: 275.961\n",
      "[61]\tvalid_0's tweedie: 275.96\n",
      "[62]\tvalid_0's tweedie: 275.96\n",
      "[63]\tvalid_0's tweedie: 275.958\n",
      "[64]\tvalid_0's tweedie: 275.958\n",
      "[65]\tvalid_0's tweedie: 275.957\n",
      "[66]\tvalid_0's tweedie: 275.955\n",
      "[67]\tvalid_0's tweedie: 275.955\n",
      "[68]\tvalid_0's tweedie: 275.954\n",
      "[69]\tvalid_0's tweedie: 275.954\n",
      "[70]\tvalid_0's tweedie: 275.954\n",
      "[71]\tvalid_0's tweedie: 275.954\n",
      "[72]\tvalid_0's tweedie: 275.953\n",
      "[73]\tvalid_0's tweedie: 275.952\n",
      "[74]\tvalid_0's tweedie: 275.952\n",
      "[75]\tvalid_0's tweedie: 275.952\n",
      "[76]\tvalid_0's tweedie: 275.952\n",
      "[77]\tvalid_0's tweedie: 275.951\n",
      "[78]\tvalid_0's tweedie: 275.951\n",
      "[79]\tvalid_0's tweedie: 275.951\n",
      "[80]\tvalid_0's tweedie: 275.951\n",
      "[81]\tvalid_0's tweedie: 275.951\n",
      "[82]\tvalid_0's tweedie: 275.95\n",
      "[83]\tvalid_0's tweedie: 275.95\n",
      "[84]\tvalid_0's tweedie: 275.95\n",
      "[85]\tvalid_0's tweedie: 275.949\n",
      "[86]\tvalid_0's tweedie: 275.949\n",
      "[87]\tvalid_0's tweedie: 275.949\n",
      "[88]\tvalid_0's tweedie: 275.949\n",
      "[89]\tvalid_0's tweedie: 275.95\n",
      "[90]\tvalid_0's tweedie: 275.95\n",
      "[91]\tvalid_0's tweedie: 275.947\n",
      "[92]\tvalid_0's tweedie: 275.946\n",
      "[93]\tvalid_0's tweedie: 275.945\n",
      "[94]\tvalid_0's tweedie: 275.945\n",
      "[95]\tvalid_0's tweedie: 275.944\n",
      "[96]\tvalid_0's tweedie: 275.944\n",
      "[97]\tvalid_0's tweedie: 275.944\n",
      "[98]\tvalid_0's tweedie: 275.942\n",
      "[99]\tvalid_0's tweedie: 275.939\n",
      "[100]\tvalid_0's tweedie: 275.937\n",
      "[101]\tvalid_0's tweedie: 275.935\n",
      "[102]\tvalid_0's tweedie: 275.935\n",
      "[103]\tvalid_0's tweedie: 275.933\n",
      "[104]\tvalid_0's tweedie: 275.931\n",
      "[105]\tvalid_0's tweedie: 275.931\n",
      "[106]\tvalid_0's tweedie: 275.93\n",
      "[107]\tvalid_0's tweedie: 275.93\n",
      "[108]\tvalid_0's tweedie: 275.929\n",
      "[109]\tvalid_0's tweedie: 275.929\n",
      "[110]\tvalid_0's tweedie: 275.929\n",
      "[111]\tvalid_0's tweedie: 275.929\n",
      "[112]\tvalid_0's tweedie: 275.929\n",
      "[113]\tvalid_0's tweedie: 275.929\n",
      "[114]\tvalid_0's tweedie: 275.929\n",
      "[115]\tvalid_0's tweedie: 275.929\n",
      "[116]\tvalid_0's tweedie: 275.929\n",
      "[117]\tvalid_0's tweedie: 275.928\n",
      "[118]\tvalid_0's tweedie: 275.928\n",
      "[119]\tvalid_0's tweedie: 275.928\n",
      "[120]\tvalid_0's tweedie: 275.928\n",
      "[121]\tvalid_0's tweedie: 275.927\n",
      "[122]\tvalid_0's tweedie: 275.926\n",
      "[123]\tvalid_0's tweedie: 275.926\n",
      "[124]\tvalid_0's tweedie: 275.926\n",
      "[125]\tvalid_0's tweedie: 275.926\n",
      "[126]\tvalid_0's tweedie: 275.925\n",
      "[127]\tvalid_0's tweedie: 275.925\n",
      "[128]\tvalid_0's tweedie: 275.925\n",
      "[129]\tvalid_0's tweedie: 275.925\n",
      "[130]\tvalid_0's tweedie: 275.924\n",
      "[131]\tvalid_0's tweedie: 275.924\n",
      "[132]\tvalid_0's tweedie: 275.924\n",
      "[133]\tvalid_0's tweedie: 275.924\n",
      "[134]\tvalid_0's tweedie: 275.924\n",
      "[135]\tvalid_0's tweedie: 275.924\n",
      "[136]\tvalid_0's tweedie: 275.924\n",
      "[137]\tvalid_0's tweedie: 275.924\n",
      "[138]\tvalid_0's tweedie: 275.925\n",
      "[139]\tvalid_0's tweedie: 275.925\n",
      "[140]\tvalid_0's tweedie: 275.924\n",
      "[141]\tvalid_0's tweedie: 275.924\n",
      "[142]\tvalid_0's tweedie: 275.923\n",
      "[143]\tvalid_0's tweedie: 275.923\n",
      "[144]\tvalid_0's tweedie: 275.923\n",
      "[145]\tvalid_0's tweedie: 275.923\n",
      "[146]\tvalid_0's tweedie: 275.923\n",
      "[147]\tvalid_0's tweedie: 275.922\n",
      "[148]\tvalid_0's tweedie: 275.922\n",
      "[149]\tvalid_0's tweedie: 275.922\n",
      "[150]\tvalid_0's tweedie: 275.921\n",
      "[151]\tvalid_0's tweedie: 275.921\n",
      "[152]\tvalid_0's tweedie: 275.92\n",
      "[153]\tvalid_0's tweedie: 275.92\n",
      "[154]\tvalid_0's tweedie: 275.92\n",
      "[155]\tvalid_0's tweedie: 275.921\n",
      "[156]\tvalid_0's tweedie: 275.919\n",
      "[157]\tvalid_0's tweedie: 275.917\n",
      "[158]\tvalid_0's tweedie: 275.917\n",
      "[159]\tvalid_0's tweedie: 275.917\n",
      "[160]\tvalid_0's tweedie: 275.916\n",
      "[161]\tvalid_0's tweedie: 275.917\n",
      "[162]\tvalid_0's tweedie: 275.917\n",
      "[163]\tvalid_0's tweedie: 275.917\n",
      "[164]\tvalid_0's tweedie: 275.917\n",
      "[165]\tvalid_0's tweedie: 275.917\n",
      "[166]\tvalid_0's tweedie: 275.916\n",
      "[167]\tvalid_0's tweedie: 275.916\n",
      "[168]\tvalid_0's tweedie: 275.916\n",
      "[169]\tvalid_0's tweedie: 275.915\n",
      "[170]\tvalid_0's tweedie: 275.915\n",
      "[171]\tvalid_0's tweedie: 275.914\n",
      "[172]\tvalid_0's tweedie: 275.915\n",
      "[173]\tvalid_0's tweedie: 275.914\n",
      "[174]\tvalid_0's tweedie: 275.915\n",
      "[175]\tvalid_0's tweedie: 275.915\n",
      "[176]\tvalid_0's tweedie: 275.915\n",
      "[177]\tvalid_0's tweedie: 275.915\n",
      "[178]\tvalid_0's tweedie: 275.915\n",
      "[179]\tvalid_0's tweedie: 275.915\n",
      "[180]\tvalid_0's tweedie: 275.914\n",
      "[181]\tvalid_0's tweedie: 275.913\n",
      "[182]\tvalid_0's tweedie: 275.913\n",
      "[183]\tvalid_0's tweedie: 275.914\n",
      "[184]\tvalid_0's tweedie: 275.914\n",
      "[185]\tvalid_0's tweedie: 275.914\n",
      "[186]\tvalid_0's tweedie: 275.914\n",
      "[187]\tvalid_0's tweedie: 275.914\n",
      "[188]\tvalid_0's tweedie: 275.914\n",
      "[189]\tvalid_0's tweedie: 275.913\n",
      "[190]\tvalid_0's tweedie: 275.913\n",
      "[191]\tvalid_0's tweedie: 275.913\n",
      "[192]\tvalid_0's tweedie: 275.913\n",
      "[193]\tvalid_0's tweedie: 275.913\n",
      "[194]\tvalid_0's tweedie: 275.913\n",
      "[195]\tvalid_0's tweedie: 275.912\n",
      "[196]\tvalid_0's tweedie: 275.913\n",
      "[197]\tvalid_0's tweedie: 275.913\n",
      "[198]\tvalid_0's tweedie: 275.912\n",
      "[199]\tvalid_0's tweedie: 275.912\n",
      "[200]\tvalid_0's tweedie: 275.912\n",
      "[201]\tvalid_0's tweedie: 275.912\n",
      "[202]\tvalid_0's tweedie: 275.912\n",
      "[203]\tvalid_0's tweedie: 275.912\n",
      "[204]\tvalid_0's tweedie: 275.912\n",
      "[205]\tvalid_0's tweedie: 275.912\n",
      "[206]\tvalid_0's tweedie: 275.911\n",
      "[207]\tvalid_0's tweedie: 275.912\n",
      "[208]\tvalid_0's tweedie: 275.912\n",
      "[209]\tvalid_0's tweedie: 275.911\n",
      "[210]\tvalid_0's tweedie: 275.91\n",
      "[211]\tvalid_0's tweedie: 275.911\n",
      "[212]\tvalid_0's tweedie: 275.91\n",
      "[213]\tvalid_0's tweedie: 275.91\n",
      "[214]\tvalid_0's tweedie: 275.91\n",
      "[215]\tvalid_0's tweedie: 275.91\n",
      "[216]\tvalid_0's tweedie: 275.91\n",
      "[217]\tvalid_0's tweedie: 275.91\n",
      "[218]\tvalid_0's tweedie: 275.911\n",
      "[219]\tvalid_0's tweedie: 275.91\n",
      "[220]\tvalid_0's tweedie: 275.909\n",
      "[221]\tvalid_0's tweedie: 275.909\n",
      "[222]\tvalid_0's tweedie: 275.909\n",
      "[223]\tvalid_0's tweedie: 275.909\n",
      "[224]\tvalid_0's tweedie: 275.908\n",
      "[225]\tvalid_0's tweedie: 275.908\n",
      "[226]\tvalid_0's tweedie: 275.909\n",
      "[227]\tvalid_0's tweedie: 275.909\n",
      "[228]\tvalid_0's tweedie: 275.909\n",
      "[229]\tvalid_0's tweedie: 275.909\n",
      "[230]\tvalid_0's tweedie: 275.908\n",
      "[231]\tvalid_0's tweedie: 275.908\n",
      "[232]\tvalid_0's tweedie: 275.908\n",
      "[233]\tvalid_0's tweedie: 275.907\n",
      "[234]\tvalid_0's tweedie: 275.907\n",
      "[235]\tvalid_0's tweedie: 275.908\n",
      "[236]\tvalid_0's tweedie: 275.908\n",
      "[237]\tvalid_0's tweedie: 275.908\n",
      "[238]\tvalid_0's tweedie: 275.908\n",
      "[239]\tvalid_0's tweedie: 275.907\n",
      "[240]\tvalid_0's tweedie: 275.907\n",
      "[241]\tvalid_0's tweedie: 275.907\n",
      "[242]\tvalid_0's tweedie: 275.906\n",
      "[243]\tvalid_0's tweedie: 275.906\n",
      "[244]\tvalid_0's tweedie: 275.906\n",
      "[245]\tvalid_0's tweedie: 275.906\n",
      "[246]\tvalid_0's tweedie: 275.906\n",
      "[247]\tvalid_0's tweedie: 275.906\n",
      "[248]\tvalid_0's tweedie: 275.906\n",
      "[249]\tvalid_0's tweedie: 275.906\n",
      "[250]\tvalid_0's tweedie: 275.906\n",
      "[251]\tvalid_0's tweedie: 275.906\n",
      "[252]\tvalid_0's tweedie: 275.906\n",
      "[253]\tvalid_0's tweedie: 275.906\n",
      "[254]\tvalid_0's tweedie: 275.906\n",
      "[255]\tvalid_0's tweedie: 275.906\n",
      "[256]\tvalid_0's tweedie: 275.906\n",
      "[257]\tvalid_0's tweedie: 275.906\n",
      "[258]\tvalid_0's tweedie: 275.906\n",
      "[259]\tvalid_0's tweedie: 275.906\n",
      "[260]\tvalid_0's tweedie: 275.906\n",
      "[261]\tvalid_0's tweedie: 275.905\n",
      "[262]\tvalid_0's tweedie: 275.905\n",
      "[263]\tvalid_0's tweedie: 275.905\n",
      "[264]\tvalid_0's tweedie: 275.905\n",
      "[265]\tvalid_0's tweedie: 275.905\n",
      "[266]\tvalid_0's tweedie: 275.904\n",
      "[267]\tvalid_0's tweedie: 275.904\n",
      "[268]\tvalid_0's tweedie: 275.905\n",
      "[269]\tvalid_0's tweedie: 275.905\n",
      "[270]\tvalid_0's tweedie: 275.905\n",
      "[271]\tvalid_0's tweedie: 275.905\n",
      "[272]\tvalid_0's tweedie: 275.905\n",
      "[273]\tvalid_0's tweedie: 275.905\n",
      "[274]\tvalid_0's tweedie: 275.905\n",
      "[275]\tvalid_0's tweedie: 275.905\n",
      "[276]\tvalid_0's tweedie: 275.905\n",
      "[277]\tvalid_0's tweedie: 275.905\n",
      "[278]\tvalid_0's tweedie: 275.904\n",
      "[279]\tvalid_0's tweedie: 275.904\n",
      "[280]\tvalid_0's tweedie: 275.903\n",
      "[281]\tvalid_0's tweedie: 275.902\n",
      "[282]\tvalid_0's tweedie: 275.902\n",
      "[283]\tvalid_0's tweedie: 275.901\n",
      "[284]\tvalid_0's tweedie: 275.901\n",
      "[285]\tvalid_0's tweedie: 275.901\n",
      "[286]\tvalid_0's tweedie: 275.901\n",
      "[287]\tvalid_0's tweedie: 275.901\n",
      "[288]\tvalid_0's tweedie: 275.902\n",
      "[289]\tvalid_0's tweedie: 275.902\n",
      "[290]\tvalid_0's tweedie: 275.901\n",
      "[291]\tvalid_0's tweedie: 275.901\n",
      "[292]\tvalid_0's tweedie: 275.901\n",
      "[293]\tvalid_0's tweedie: 275.901\n",
      "[294]\tvalid_0's tweedie: 275.901\n",
      "[295]\tvalid_0's tweedie: 275.901\n",
      "[296]\tvalid_0's tweedie: 275.9\n",
      "[297]\tvalid_0's tweedie: 275.899\n",
      "[298]\tvalid_0's tweedie: 275.899\n",
      "[299]\tvalid_0's tweedie: 275.899\n",
      "[300]\tvalid_0's tweedie: 275.899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 275.899\n",
      "Training model for level 5 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 13055, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.496996\n",
      "[1]\tvalid_0's tweedie: 306.688\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.71\n",
      "[3]\tvalid_0's tweedie: 297.502\n",
      "[4]\tvalid_0's tweedie: 293.935\n",
      "[5]\tvalid_0's tweedie: 290.905\n",
      "[6]\tvalid_0's tweedie: 288.386\n",
      "[7]\tvalid_0's tweedie: 286.246\n",
      "[8]\tvalid_0's tweedie: 284.508\n",
      "[9]\tvalid_0's tweedie: 283.031\n",
      "[10]\tvalid_0's tweedie: 281.805\n",
      "[11]\tvalid_0's tweedie: 280.81\n",
      "[12]\tvalid_0's tweedie: 279.986\n",
      "[13]\tvalid_0's tweedie: 279.301\n",
      "[14]\tvalid_0's tweedie: 278.728\n",
      "[15]\tvalid_0's tweedie: 278.265\n",
      "[16]\tvalid_0's tweedie: 277.878\n",
      "[17]\tvalid_0's tweedie: 277.551\n",
      "[18]\tvalid_0's tweedie: 277.292\n",
      "[19]\tvalid_0's tweedie: 277.086\n",
      "[20]\tvalid_0's tweedie: 276.91\n",
      "[21]\tvalid_0's tweedie: 276.759\n",
      "[22]\tvalid_0's tweedie: 276.644\n",
      "[23]\tvalid_0's tweedie: 276.545\n",
      "[24]\tvalid_0's tweedie: 276.459\n",
      "[25]\tvalid_0's tweedie: 276.391\n",
      "[26]\tvalid_0's tweedie: 276.331\n",
      "[27]\tvalid_0's tweedie: 276.277\n",
      "[28]\tvalid_0's tweedie: 276.231\n",
      "[29]\tvalid_0's tweedie: 276.191\n",
      "[30]\tvalid_0's tweedie: 276.165\n",
      "[31]\tvalid_0's tweedie: 276.136\n",
      "[32]\tvalid_0's tweedie: 276.111\n",
      "[33]\tvalid_0's tweedie: 276.094\n",
      "[34]\tvalid_0's tweedie: 276.076\n",
      "[35]\tvalid_0's tweedie: 276.062\n",
      "[36]\tvalid_0's tweedie: 276.051\n",
      "[37]\tvalid_0's tweedie: 276.042\n",
      "[38]\tvalid_0's tweedie: 276.03\n",
      "[39]\tvalid_0's tweedie: 276.023\n",
      "[40]\tvalid_0's tweedie: 276.015\n",
      "[41]\tvalid_0's tweedie: 276.008\n",
      "[42]\tvalid_0's tweedie: 276.003\n",
      "[43]\tvalid_0's tweedie: 276\n",
      "[44]\tvalid_0's tweedie: 275.995\n",
      "[45]\tvalid_0's tweedie: 275.99\n",
      "[46]\tvalid_0's tweedie: 275.986\n",
      "[47]\tvalid_0's tweedie: 275.983\n",
      "[48]\tvalid_0's tweedie: 275.981\n",
      "[49]\tvalid_0's tweedie: 275.978\n",
      "[50]\tvalid_0's tweedie: 275.976\n",
      "[51]\tvalid_0's tweedie: 275.974\n",
      "[52]\tvalid_0's tweedie: 275.974\n",
      "[53]\tvalid_0's tweedie: 275.97\n",
      "[54]\tvalid_0's tweedie: 275.967\n",
      "[55]\tvalid_0's tweedie: 275.964\n",
      "[56]\tvalid_0's tweedie: 275.962\n",
      "[57]\tvalid_0's tweedie: 275.96\n",
      "[58]\tvalid_0's tweedie: 275.958\n",
      "[59]\tvalid_0's tweedie: 275.956\n",
      "[60]\tvalid_0's tweedie: 275.955\n",
      "[61]\tvalid_0's tweedie: 275.954\n",
      "[62]\tvalid_0's tweedie: 275.952\n",
      "[63]\tvalid_0's tweedie: 275.952\n",
      "[64]\tvalid_0's tweedie: 275.951\n",
      "[65]\tvalid_0's tweedie: 275.949\n",
      "[66]\tvalid_0's tweedie: 275.949\n",
      "[67]\tvalid_0's tweedie: 275.948\n",
      "[68]\tvalid_0's tweedie: 275.947\n",
      "[69]\tvalid_0's tweedie: 275.946\n",
      "[70]\tvalid_0's tweedie: 275.944\n",
      "[71]\tvalid_0's tweedie: 275.943\n",
      "[72]\tvalid_0's tweedie: 275.941\n",
      "[73]\tvalid_0's tweedie: 275.939\n",
      "[74]\tvalid_0's tweedie: 275.938\n",
      "[75]\tvalid_0's tweedie: 275.938\n",
      "[76]\tvalid_0's tweedie: 275.937\n",
      "[77]\tvalid_0's tweedie: 275.937\n",
      "[78]\tvalid_0's tweedie: 275.937\n",
      "[79]\tvalid_0's tweedie: 275.937\n",
      "[80]\tvalid_0's tweedie: 275.937\n",
      "[81]\tvalid_0's tweedie: 275.937\n",
      "[82]\tvalid_0's tweedie: 275.934\n",
      "[83]\tvalid_0's tweedie: 275.932\n",
      "[84]\tvalid_0's tweedie: 275.932\n",
      "[85]\tvalid_0's tweedie: 275.932\n",
      "[86]\tvalid_0's tweedie: 275.931\n",
      "[87]\tvalid_0's tweedie: 275.932\n",
      "[88]\tvalid_0's tweedie: 275.93\n",
      "[89]\tvalid_0's tweedie: 275.93\n",
      "[90]\tvalid_0's tweedie: 275.93\n",
      "[91]\tvalid_0's tweedie: 275.929\n",
      "[92]\tvalid_0's tweedie: 275.929\n",
      "[93]\tvalid_0's tweedie: 275.929\n",
      "[94]\tvalid_0's tweedie: 275.929\n",
      "[95]\tvalid_0's tweedie: 275.929\n",
      "[96]\tvalid_0's tweedie: 275.928\n",
      "[97]\tvalid_0's tweedie: 275.927\n",
      "[98]\tvalid_0's tweedie: 275.927\n",
      "[99]\tvalid_0's tweedie: 275.926\n",
      "[100]\tvalid_0's tweedie: 275.925\n",
      "[101]\tvalid_0's tweedie: 275.925\n",
      "[102]\tvalid_0's tweedie: 275.925\n",
      "[103]\tvalid_0's tweedie: 275.925\n",
      "[104]\tvalid_0's tweedie: 275.924\n",
      "[105]\tvalid_0's tweedie: 275.924\n",
      "[106]\tvalid_0's tweedie: 275.924\n",
      "[107]\tvalid_0's tweedie: 275.925\n",
      "[108]\tvalid_0's tweedie: 275.925\n",
      "[109]\tvalid_0's tweedie: 275.925\n",
      "[110]\tvalid_0's tweedie: 275.925\n",
      "[111]\tvalid_0's tweedie: 275.925\n",
      "[112]\tvalid_0's tweedie: 275.925\n",
      "[113]\tvalid_0's tweedie: 275.925\n",
      "[114]\tvalid_0's tweedie: 275.925\n",
      "[115]\tvalid_0's tweedie: 275.924\n",
      "[116]\tvalid_0's tweedie: 275.923\n",
      "[117]\tvalid_0's tweedie: 275.923\n",
      "[118]\tvalid_0's tweedie: 275.923\n",
      "[119]\tvalid_0's tweedie: 275.923\n",
      "[120]\tvalid_0's tweedie: 275.922\n",
      "[121]\tvalid_0's tweedie: 275.922\n",
      "[122]\tvalid_0's tweedie: 275.922\n",
      "[123]\tvalid_0's tweedie: 275.922\n",
      "[124]\tvalid_0's tweedie: 275.922\n",
      "[125]\tvalid_0's tweedie: 275.923\n",
      "[126]\tvalid_0's tweedie: 275.923\n",
      "[127]\tvalid_0's tweedie: 275.922\n",
      "[128]\tvalid_0's tweedie: 275.922\n",
      "[129]\tvalid_0's tweedie: 275.922\n",
      "[130]\tvalid_0's tweedie: 275.922\n",
      "[131]\tvalid_0's tweedie: 275.922\n",
      "[132]\tvalid_0's tweedie: 275.922\n",
      "[133]\tvalid_0's tweedie: 275.922\n",
      "[134]\tvalid_0's tweedie: 275.921\n",
      "[135]\tvalid_0's tweedie: 275.92\n",
      "[136]\tvalid_0's tweedie: 275.92\n",
      "[137]\tvalid_0's tweedie: 275.919\n",
      "[138]\tvalid_0's tweedie: 275.919\n",
      "[139]\tvalid_0's tweedie: 275.919\n",
      "[140]\tvalid_0's tweedie: 275.919\n",
      "[141]\tvalid_0's tweedie: 275.919\n",
      "[142]\tvalid_0's tweedie: 275.919\n",
      "[143]\tvalid_0's tweedie: 275.919\n",
      "[144]\tvalid_0's tweedie: 275.919\n",
      "[145]\tvalid_0's tweedie: 275.919\n",
      "[146]\tvalid_0's tweedie: 275.919\n",
      "[147]\tvalid_0's tweedie: 275.919\n",
      "[148]\tvalid_0's tweedie: 275.919\n",
      "[149]\tvalid_0's tweedie: 275.919\n",
      "[150]\tvalid_0's tweedie: 275.918\n",
      "[151]\tvalid_0's tweedie: 275.92\n",
      "[152]\tvalid_0's tweedie: 275.92\n",
      "[153]\tvalid_0's tweedie: 275.92\n",
      "[154]\tvalid_0's tweedie: 275.919\n",
      "[155]\tvalid_0's tweedie: 275.918\n",
      "[156]\tvalid_0's tweedie: 275.918\n",
      "[157]\tvalid_0's tweedie: 275.918\n",
      "[158]\tvalid_0's tweedie: 275.918\n",
      "[159]\tvalid_0's tweedie: 275.918\n",
      "[160]\tvalid_0's tweedie: 275.918\n",
      "[161]\tvalid_0's tweedie: 275.918\n",
      "[162]\tvalid_0's tweedie: 275.918\n",
      "[163]\tvalid_0's tweedie: 275.917\n",
      "[164]\tvalid_0's tweedie: 275.918\n",
      "[165]\tvalid_0's tweedie: 275.918\n",
      "[166]\tvalid_0's tweedie: 275.917\n",
      "[167]\tvalid_0's tweedie: 275.918\n",
      "[168]\tvalid_0's tweedie: 275.917\n",
      "[169]\tvalid_0's tweedie: 275.917\n",
      "[170]\tvalid_0's tweedie: 275.917\n",
      "[171]\tvalid_0's tweedie: 275.917\n",
      "[172]\tvalid_0's tweedie: 275.916\n",
      "[173]\tvalid_0's tweedie: 275.915\n",
      "[174]\tvalid_0's tweedie: 275.915\n",
      "[175]\tvalid_0's tweedie: 275.915\n",
      "[176]\tvalid_0's tweedie: 275.915\n",
      "[177]\tvalid_0's tweedie: 275.915\n",
      "[178]\tvalid_0's tweedie: 275.915\n",
      "[179]\tvalid_0's tweedie: 275.915\n",
      "[180]\tvalid_0's tweedie: 275.915\n",
      "[181]\tvalid_0's tweedie: 275.915\n",
      "[182]\tvalid_0's tweedie: 275.914\n",
      "[183]\tvalid_0's tweedie: 275.914\n",
      "[184]\tvalid_0's tweedie: 275.915\n",
      "[185]\tvalid_0's tweedie: 275.915\n",
      "[186]\tvalid_0's tweedie: 275.914\n",
      "[187]\tvalid_0's tweedie: 275.914\n",
      "[188]\tvalid_0's tweedie: 275.914\n",
      "[189]\tvalid_0's tweedie: 275.915\n",
      "[190]\tvalid_0's tweedie: 275.915\n",
      "[191]\tvalid_0's tweedie: 275.915\n",
      "[192]\tvalid_0's tweedie: 275.915\n",
      "[193]\tvalid_0's tweedie: 275.915\n",
      "[194]\tvalid_0's tweedie: 275.915\n",
      "[195]\tvalid_0's tweedie: 275.914\n",
      "[196]\tvalid_0's tweedie: 275.914\n",
      "[197]\tvalid_0's tweedie: 275.914\n",
      "[198]\tvalid_0's tweedie: 275.915\n",
      "[199]\tvalid_0's tweedie: 275.914\n",
      "[200]\tvalid_0's tweedie: 275.915\n",
      "[201]\tvalid_0's tweedie: 275.915\n",
      "[202]\tvalid_0's tweedie: 275.915\n",
      "[203]\tvalid_0's tweedie: 275.915\n",
      "[204]\tvalid_0's tweedie: 275.915\n",
      "[205]\tvalid_0's tweedie: 275.915\n",
      "[206]\tvalid_0's tweedie: 275.915\n",
      "[207]\tvalid_0's tweedie: 275.915\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's tweedie: 275.914\n",
      "Training model for level 5 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 13048, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497161\n",
      "[1]\tvalid_0's tweedie: 306.629\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.701\n",
      "[3]\tvalid_0's tweedie: 297.488\n",
      "[4]\tvalid_0's tweedie: 293.965\n",
      "[5]\tvalid_0's tweedie: 290.998\n",
      "[6]\tvalid_0's tweedie: 288.536\n",
      "[7]\tvalid_0's tweedie: 286.363\n",
      "[8]\tvalid_0's tweedie: 284.621\n",
      "[9]\tvalid_0's tweedie: 283.11\n",
      "[10]\tvalid_0's tweedie: 281.886\n",
      "[11]\tvalid_0's tweedie: 280.872\n",
      "[12]\tvalid_0's tweedie: 280.025\n",
      "[13]\tvalid_0's tweedie: 279.337\n",
      "[14]\tvalid_0's tweedie: 278.763\n",
      "[15]\tvalid_0's tweedie: 278.28\n",
      "[16]\tvalid_0's tweedie: 277.927\n",
      "[17]\tvalid_0's tweedie: 277.606\n",
      "[18]\tvalid_0's tweedie: 277.343\n",
      "[19]\tvalid_0's tweedie: 277.125\n",
      "[20]\tvalid_0's tweedie: 276.94\n",
      "[21]\tvalid_0's tweedie: 276.79\n",
      "[22]\tvalid_0's tweedie: 276.659\n",
      "[23]\tvalid_0's tweedie: 276.562\n",
      "[24]\tvalid_0's tweedie: 276.485\n",
      "[25]\tvalid_0's tweedie: 276.408\n",
      "[26]\tvalid_0's tweedie: 276.341\n",
      "[27]\tvalid_0's tweedie: 276.285\n",
      "[28]\tvalid_0's tweedie: 276.24\n",
      "[29]\tvalid_0's tweedie: 276.205\n",
      "[30]\tvalid_0's tweedie: 276.176\n",
      "[31]\tvalid_0's tweedie: 276.152\n",
      "[32]\tvalid_0's tweedie: 276.128\n",
      "[33]\tvalid_0's tweedie: 276.108\n",
      "[34]\tvalid_0's tweedie: 276.091\n",
      "[35]\tvalid_0's tweedie: 276.073\n",
      "[36]\tvalid_0's tweedie: 276.063\n",
      "[37]\tvalid_0's tweedie: 276.053\n",
      "[38]\tvalid_0's tweedie: 276.043\n",
      "[39]\tvalid_0's tweedie: 276.032\n",
      "[40]\tvalid_0's tweedie: 276.026\n",
      "[41]\tvalid_0's tweedie: 276.016\n",
      "[42]\tvalid_0's tweedie: 276.011\n",
      "[43]\tvalid_0's tweedie: 276.007\n",
      "[44]\tvalid_0's tweedie: 275.998\n",
      "[45]\tvalid_0's tweedie: 275.994\n",
      "[46]\tvalid_0's tweedie: 275.992\n",
      "[47]\tvalid_0's tweedie: 275.989\n",
      "[48]\tvalid_0's tweedie: 275.984\n",
      "[49]\tvalid_0's tweedie: 275.977\n",
      "[50]\tvalid_0's tweedie: 275.976\n",
      "[51]\tvalid_0's tweedie: 275.969\n",
      "[52]\tvalid_0's tweedie: 275.967\n",
      "[53]\tvalid_0's tweedie: 275.964\n",
      "[54]\tvalid_0's tweedie: 275.964\n",
      "[55]\tvalid_0's tweedie: 275.961\n",
      "[56]\tvalid_0's tweedie: 275.956\n",
      "[57]\tvalid_0's tweedie: 275.954\n",
      "[58]\tvalid_0's tweedie: 275.951\n",
      "[59]\tvalid_0's tweedie: 275.947\n",
      "[60]\tvalid_0's tweedie: 275.946\n",
      "[61]\tvalid_0's tweedie: 275.945\n",
      "[62]\tvalid_0's tweedie: 275.943\n",
      "[63]\tvalid_0's tweedie: 275.943\n",
      "[64]\tvalid_0's tweedie: 275.941\n",
      "[65]\tvalid_0's tweedie: 275.94\n",
      "[66]\tvalid_0's tweedie: 275.938\n",
      "[67]\tvalid_0's tweedie: 275.935\n",
      "[68]\tvalid_0's tweedie: 275.933\n",
      "[69]\tvalid_0's tweedie: 275.933\n",
      "[70]\tvalid_0's tweedie: 275.932\n",
      "[71]\tvalid_0's tweedie: 275.932\n",
      "[72]\tvalid_0's tweedie: 275.93\n",
      "[73]\tvalid_0's tweedie: 275.931\n",
      "[74]\tvalid_0's tweedie: 275.93\n",
      "[75]\tvalid_0's tweedie: 275.929\n",
      "[76]\tvalid_0's tweedie: 275.928\n",
      "[77]\tvalid_0's tweedie: 275.927\n",
      "[78]\tvalid_0's tweedie: 275.927\n",
      "[79]\tvalid_0's tweedie: 275.927\n",
      "[80]\tvalid_0's tweedie: 275.925\n",
      "[81]\tvalid_0's tweedie: 275.923\n",
      "[82]\tvalid_0's tweedie: 275.923\n",
      "[83]\tvalid_0's tweedie: 275.923\n",
      "[84]\tvalid_0's tweedie: 275.922\n",
      "[85]\tvalid_0's tweedie: 275.921\n",
      "[86]\tvalid_0's tweedie: 275.92\n",
      "[87]\tvalid_0's tweedie: 275.92\n",
      "[88]\tvalid_0's tweedie: 275.919\n",
      "[89]\tvalid_0's tweedie: 275.918\n",
      "[90]\tvalid_0's tweedie: 275.917\n",
      "[91]\tvalid_0's tweedie: 275.917\n",
      "[92]\tvalid_0's tweedie: 275.916\n",
      "[93]\tvalid_0's tweedie: 275.915\n",
      "[94]\tvalid_0's tweedie: 275.914\n",
      "[95]\tvalid_0's tweedie: 275.914\n",
      "[96]\tvalid_0's tweedie: 275.914\n",
      "[97]\tvalid_0's tweedie: 275.914\n",
      "[98]\tvalid_0's tweedie: 275.913\n",
      "[99]\tvalid_0's tweedie: 275.913\n",
      "[100]\tvalid_0's tweedie: 275.913\n",
      "[101]\tvalid_0's tweedie: 275.912\n",
      "[102]\tvalid_0's tweedie: 275.912\n",
      "[103]\tvalid_0's tweedie: 275.912\n",
      "[104]\tvalid_0's tweedie: 275.912\n",
      "[105]\tvalid_0's tweedie: 275.912\n",
      "[106]\tvalid_0's tweedie: 275.912\n",
      "[107]\tvalid_0's tweedie: 275.911\n",
      "[108]\tvalid_0's tweedie: 275.911\n",
      "[109]\tvalid_0's tweedie: 275.911\n",
      "[110]\tvalid_0's tweedie: 275.91\n",
      "[111]\tvalid_0's tweedie: 275.91\n",
      "[112]\tvalid_0's tweedie: 275.909\n",
      "[113]\tvalid_0's tweedie: 275.909\n",
      "[114]\tvalid_0's tweedie: 275.909\n",
      "[115]\tvalid_0's tweedie: 275.909\n",
      "[116]\tvalid_0's tweedie: 275.909\n",
      "[117]\tvalid_0's tweedie: 275.909\n",
      "[118]\tvalid_0's tweedie: 275.909\n",
      "[119]\tvalid_0's tweedie: 275.909\n",
      "[120]\tvalid_0's tweedie: 275.909\n",
      "[121]\tvalid_0's tweedie: 275.909\n",
      "[122]\tvalid_0's tweedie: 275.909\n",
      "[123]\tvalid_0's tweedie: 275.909\n",
      "[124]\tvalid_0's tweedie: 275.909\n",
      "[125]\tvalid_0's tweedie: 275.908\n",
      "[126]\tvalid_0's tweedie: 275.908\n",
      "[127]\tvalid_0's tweedie: 275.906\n",
      "[128]\tvalid_0's tweedie: 275.906\n",
      "[129]\tvalid_0's tweedie: 275.906\n",
      "[130]\tvalid_0's tweedie: 275.906\n",
      "[131]\tvalid_0's tweedie: 275.906\n",
      "[132]\tvalid_0's tweedie: 275.906\n",
      "[133]\tvalid_0's tweedie: 275.907\n",
      "[134]\tvalid_0's tweedie: 275.905\n",
      "[135]\tvalid_0's tweedie: 275.905\n",
      "[136]\tvalid_0's tweedie: 275.905\n",
      "[137]\tvalid_0's tweedie: 275.905\n",
      "[138]\tvalid_0's tweedie: 275.904\n",
      "[139]\tvalid_0's tweedie: 275.904\n",
      "[140]\tvalid_0's tweedie: 275.904\n",
      "[141]\tvalid_0's tweedie: 275.904\n",
      "[142]\tvalid_0's tweedie: 275.904\n",
      "[143]\tvalid_0's tweedie: 275.903\n",
      "[144]\tvalid_0's tweedie: 275.903\n",
      "[145]\tvalid_0's tweedie: 275.903\n",
      "[146]\tvalid_0's tweedie: 275.903\n",
      "[147]\tvalid_0's tweedie: 275.903\n",
      "[148]\tvalid_0's tweedie: 275.904\n",
      "[149]\tvalid_0's tweedie: 275.904\n",
      "[150]\tvalid_0's tweedie: 275.904\n",
      "[151]\tvalid_0's tweedie: 275.904\n",
      "[152]\tvalid_0's tweedie: 275.906\n",
      "[153]\tvalid_0's tweedie: 275.906\n",
      "[154]\tvalid_0's tweedie: 275.906\n",
      "[155]\tvalid_0's tweedie: 275.906\n",
      "[156]\tvalid_0's tweedie: 275.903\n",
      "[157]\tvalid_0's tweedie: 275.903\n",
      "[158]\tvalid_0's tweedie: 275.903\n",
      "[159]\tvalid_0's tweedie: 275.903\n",
      "[160]\tvalid_0's tweedie: 275.903\n",
      "[161]\tvalid_0's tweedie: 275.903\n",
      "[162]\tvalid_0's tweedie: 275.904\n",
      "[163]\tvalid_0's tweedie: 275.903\n",
      "[164]\tvalid_0's tweedie: 275.903\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's tweedie: 275.903\n",
      "Training model for level 5 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 13041, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497202\n",
      "[1]\tvalid_0's tweedie: 306.648\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.701\n",
      "[3]\tvalid_0's tweedie: 297.526\n",
      "[4]\tvalid_0's tweedie: 293.964\n",
      "[5]\tvalid_0's tweedie: 290.979\n",
      "[6]\tvalid_0's tweedie: 288.442\n",
      "[7]\tvalid_0's tweedie: 286.318\n",
      "[8]\tvalid_0's tweedie: 284.598\n",
      "[9]\tvalid_0's tweedie: 283.122\n",
      "[10]\tvalid_0's tweedie: 281.904\n",
      "[11]\tvalid_0's tweedie: 280.852\n",
      "[12]\tvalid_0's tweedie: 280.058\n",
      "[13]\tvalid_0's tweedie: 279.379\n",
      "[14]\tvalid_0's tweedie: 278.821\n",
      "[15]\tvalid_0's tweedie: 278.344\n",
      "[16]\tvalid_0's tweedie: 277.941\n",
      "[17]\tvalid_0's tweedie: 277.623\n",
      "[18]\tvalid_0's tweedie: 277.358\n",
      "[19]\tvalid_0's tweedie: 277.129\n",
      "[20]\tvalid_0's tweedie: 276.947\n",
      "[21]\tvalid_0's tweedie: 276.799\n",
      "[22]\tvalid_0's tweedie: 276.695\n",
      "[23]\tvalid_0's tweedie: 276.589\n",
      "[24]\tvalid_0's tweedie: 276.497\n",
      "[25]\tvalid_0's tweedie: 276.43\n",
      "[26]\tvalid_0's tweedie: 276.372\n",
      "[27]\tvalid_0's tweedie: 276.321\n",
      "[28]\tvalid_0's tweedie: 276.283\n",
      "[29]\tvalid_0's tweedie: 276.249\n",
      "[30]\tvalid_0's tweedie: 276.214\n",
      "[31]\tvalid_0's tweedie: 276.187\n",
      "[32]\tvalid_0's tweedie: 276.165\n",
      "[33]\tvalid_0's tweedie: 276.143\n",
      "[34]\tvalid_0's tweedie: 276.127\n",
      "[35]\tvalid_0's tweedie: 276.114\n",
      "[36]\tvalid_0's tweedie: 276.1\n",
      "[37]\tvalid_0's tweedie: 276.089\n",
      "[38]\tvalid_0's tweedie: 276.082\n",
      "[39]\tvalid_0's tweedie: 276.071\n",
      "[40]\tvalid_0's tweedie: 276.067\n",
      "[41]\tvalid_0's tweedie: 276.056\n",
      "[42]\tvalid_0's tweedie: 276.044\n",
      "[43]\tvalid_0's tweedie: 276.035\n",
      "[44]\tvalid_0's tweedie: 276.029\n",
      "[45]\tvalid_0's tweedie: 276.026\n",
      "[46]\tvalid_0's tweedie: 276.019\n",
      "[47]\tvalid_0's tweedie: 276.017\n",
      "[48]\tvalid_0's tweedie: 276.013\n",
      "[49]\tvalid_0's tweedie: 276.011\n",
      "[50]\tvalid_0's tweedie: 276.009\n",
      "[51]\tvalid_0's tweedie: 276.005\n",
      "[52]\tvalid_0's tweedie: 276.003\n",
      "[53]\tvalid_0's tweedie: 276.002\n",
      "[54]\tvalid_0's tweedie: 275.997\n",
      "[55]\tvalid_0's tweedie: 275.995\n",
      "[56]\tvalid_0's tweedie: 275.99\n",
      "[57]\tvalid_0's tweedie: 275.988\n",
      "[58]\tvalid_0's tweedie: 275.987\n",
      "[59]\tvalid_0's tweedie: 275.984\n",
      "[60]\tvalid_0's tweedie: 275.983\n",
      "[61]\tvalid_0's tweedie: 275.98\n",
      "[62]\tvalid_0's tweedie: 275.979\n",
      "[63]\tvalid_0's tweedie: 275.977\n",
      "[64]\tvalid_0's tweedie: 275.976\n",
      "[65]\tvalid_0's tweedie: 275.975\n",
      "[66]\tvalid_0's tweedie: 275.974\n",
      "[67]\tvalid_0's tweedie: 275.973\n",
      "[68]\tvalid_0's tweedie: 275.972\n",
      "[69]\tvalid_0's tweedie: 275.971\n",
      "[70]\tvalid_0's tweedie: 275.971\n",
      "[71]\tvalid_0's tweedie: 275.97\n",
      "[72]\tvalid_0's tweedie: 275.968\n",
      "[73]\tvalid_0's tweedie: 275.967\n",
      "[74]\tvalid_0's tweedie: 275.967\n",
      "[75]\tvalid_0's tweedie: 275.966\n",
      "[76]\tvalid_0's tweedie: 275.965\n",
      "[77]\tvalid_0's tweedie: 275.963\n",
      "[78]\tvalid_0's tweedie: 275.962\n",
      "[79]\tvalid_0's tweedie: 275.961\n",
      "[80]\tvalid_0's tweedie: 275.961\n",
      "[81]\tvalid_0's tweedie: 275.961\n",
      "[82]\tvalid_0's tweedie: 275.96\n",
      "[83]\tvalid_0's tweedie: 275.96\n",
      "[84]\tvalid_0's tweedie: 275.958\n",
      "[85]\tvalid_0's tweedie: 275.956\n",
      "[86]\tvalid_0's tweedie: 275.955\n",
      "[87]\tvalid_0's tweedie: 275.955\n",
      "[88]\tvalid_0's tweedie: 275.954\n",
      "[89]\tvalid_0's tweedie: 275.952\n",
      "[90]\tvalid_0's tweedie: 275.952\n",
      "[91]\tvalid_0's tweedie: 275.948\n",
      "[92]\tvalid_0's tweedie: 275.947\n",
      "[93]\tvalid_0's tweedie: 275.947\n",
      "[94]\tvalid_0's tweedie: 275.947\n",
      "[95]\tvalid_0's tweedie: 275.946\n",
      "[96]\tvalid_0's tweedie: 275.945\n",
      "[97]\tvalid_0's tweedie: 275.945\n",
      "[98]\tvalid_0's tweedie: 275.943\n",
      "[99]\tvalid_0's tweedie: 275.943\n",
      "[100]\tvalid_0's tweedie: 275.943\n",
      "[101]\tvalid_0's tweedie: 275.943\n",
      "[102]\tvalid_0's tweedie: 275.942\n",
      "[103]\tvalid_0's tweedie: 275.942\n",
      "[104]\tvalid_0's tweedie: 275.942\n",
      "[105]\tvalid_0's tweedie: 275.942\n",
      "[106]\tvalid_0's tweedie: 275.942\n",
      "[107]\tvalid_0's tweedie: 275.941\n",
      "[108]\tvalid_0's tweedie: 275.941\n",
      "[109]\tvalid_0's tweedie: 275.94\n",
      "[110]\tvalid_0's tweedie: 275.94\n",
      "[111]\tvalid_0's tweedie: 275.941\n",
      "[112]\tvalid_0's tweedie: 275.94\n",
      "[113]\tvalid_0's tweedie: 275.94\n",
      "[114]\tvalid_0's tweedie: 275.94\n",
      "[115]\tvalid_0's tweedie: 275.94\n",
      "[116]\tvalid_0's tweedie: 275.94\n",
      "[117]\tvalid_0's tweedie: 275.939\n",
      "[118]\tvalid_0's tweedie: 275.939\n",
      "[119]\tvalid_0's tweedie: 275.939\n",
      "[120]\tvalid_0's tweedie: 275.938\n",
      "[121]\tvalid_0's tweedie: 275.938\n",
      "[122]\tvalid_0's tweedie: 275.937\n",
      "[123]\tvalid_0's tweedie: 275.935\n",
      "[124]\tvalid_0's tweedie: 275.935\n",
      "[125]\tvalid_0's tweedie: 275.935\n",
      "[126]\tvalid_0's tweedie: 275.935\n",
      "[127]\tvalid_0's tweedie: 275.935\n",
      "[128]\tvalid_0's tweedie: 275.935\n",
      "[129]\tvalid_0's tweedie: 275.935\n",
      "[130]\tvalid_0's tweedie: 275.934\n",
      "[131]\tvalid_0's tweedie: 275.934\n",
      "[132]\tvalid_0's tweedie: 275.934\n",
      "[133]\tvalid_0's tweedie: 275.934\n",
      "[134]\tvalid_0's tweedie: 275.934\n",
      "[135]\tvalid_0's tweedie: 275.934\n",
      "[136]\tvalid_0's tweedie: 275.934\n",
      "[137]\tvalid_0's tweedie: 275.934\n",
      "[138]\tvalid_0's tweedie: 275.933\n",
      "[139]\tvalid_0's tweedie: 275.933\n",
      "[140]\tvalid_0's tweedie: 275.934\n",
      "[141]\tvalid_0's tweedie: 275.934\n",
      "[142]\tvalid_0's tweedie: 275.933\n",
      "[143]\tvalid_0's tweedie: 275.933\n",
      "[144]\tvalid_0's tweedie: 275.933\n",
      "[145]\tvalid_0's tweedie: 275.933\n",
      "[146]\tvalid_0's tweedie: 275.932\n",
      "[147]\tvalid_0's tweedie: 275.931\n",
      "[148]\tvalid_0's tweedie: 275.93\n",
      "[149]\tvalid_0's tweedie: 275.93\n",
      "[150]\tvalid_0's tweedie: 275.93\n",
      "[151]\tvalid_0's tweedie: 275.93\n",
      "[152]\tvalid_0's tweedie: 275.93\n",
      "[153]\tvalid_0's tweedie: 275.931\n",
      "[154]\tvalid_0's tweedie: 275.931\n",
      "[155]\tvalid_0's tweedie: 275.931\n",
      "[156]\tvalid_0's tweedie: 275.931\n",
      "[157]\tvalid_0's tweedie: 275.93\n",
      "[158]\tvalid_0's tweedie: 275.93\n",
      "[159]\tvalid_0's tweedie: 275.93\n",
      "[160]\tvalid_0's tweedie: 275.931\n",
      "[161]\tvalid_0's tweedie: 275.93\n",
      "[162]\tvalid_0's tweedie: 275.93\n",
      "[163]\tvalid_0's tweedie: 275.929\n",
      "[164]\tvalid_0's tweedie: 275.929\n",
      "[165]\tvalid_0's tweedie: 275.929\n",
      "[166]\tvalid_0's tweedie: 275.929\n",
      "[167]\tvalid_0's tweedie: 275.929\n",
      "[168]\tvalid_0's tweedie: 275.929\n",
      "[169]\tvalid_0's tweedie: 275.929\n",
      "[170]\tvalid_0's tweedie: 275.929\n",
      "[171]\tvalid_0's tweedie: 275.929\n",
      "[172]\tvalid_0's tweedie: 275.929\n",
      "[173]\tvalid_0's tweedie: 275.929\n",
      "[174]\tvalid_0's tweedie: 275.928\n",
      "[175]\tvalid_0's tweedie: 275.928\n",
      "[176]\tvalid_0's tweedie: 275.928\n",
      "[177]\tvalid_0's tweedie: 275.928\n",
      "[178]\tvalid_0's tweedie: 275.928\n",
      "[179]\tvalid_0's tweedie: 275.929\n",
      "[180]\tvalid_0's tweedie: 275.929\n",
      "[181]\tvalid_0's tweedie: 275.93\n",
      "[182]\tvalid_0's tweedie: 275.93\n",
      "[183]\tvalid_0's tweedie: 275.93\n",
      "[184]\tvalid_0's tweedie: 275.929\n",
      "[185]\tvalid_0's tweedie: 275.929\n",
      "[186]\tvalid_0's tweedie: 275.929\n",
      "[187]\tvalid_0's tweedie: 275.929\n",
      "[188]\tvalid_0's tweedie: 275.929\n",
      "[189]\tvalid_0's tweedie: 275.929\n",
      "[190]\tvalid_0's tweedie: 275.929\n",
      "[191]\tvalid_0's tweedie: 275.929\n",
      "[192]\tvalid_0's tweedie: 275.928\n",
      "[193]\tvalid_0's tweedie: 275.928\n",
      "[194]\tvalid_0's tweedie: 275.929\n",
      "[195]\tvalid_0's tweedie: 275.928\n",
      "[196]\tvalid_0's tweedie: 275.928\n",
      "[197]\tvalid_0's tweedie: 275.928\n",
      "[198]\tvalid_0's tweedie: 275.928\n",
      "[199]\tvalid_0's tweedie: 275.928\n",
      "[200]\tvalid_0's tweedie: 275.928\n",
      "[201]\tvalid_0's tweedie: 275.928\n",
      "[202]\tvalid_0's tweedie: 275.927\n",
      "[203]\tvalid_0's tweedie: 275.927\n",
      "[204]\tvalid_0's tweedie: 275.928\n",
      "[205]\tvalid_0's tweedie: 275.928\n",
      "[206]\tvalid_0's tweedie: 275.928\n",
      "[207]\tvalid_0's tweedie: 275.928\n",
      "[208]\tvalid_0's tweedie: 275.929\n",
      "[209]\tvalid_0's tweedie: 275.929\n",
      "[210]\tvalid_0's tweedie: 275.929\n",
      "[211]\tvalid_0's tweedie: 275.929\n",
      "[212]\tvalid_0's tweedie: 275.927\n",
      "[213]\tvalid_0's tweedie: 275.927\n",
      "[214]\tvalid_0's tweedie: 275.927\n",
      "[215]\tvalid_0's tweedie: 275.927\n",
      "[216]\tvalid_0's tweedie: 275.927\n",
      "[217]\tvalid_0's tweedie: 275.927\n",
      "[218]\tvalid_0's tweedie: 275.927\n",
      "[219]\tvalid_0's tweedie: 275.927\n",
      "[220]\tvalid_0's tweedie: 275.927\n",
      "[221]\tvalid_0's tweedie: 275.927\n",
      "[222]\tvalid_0's tweedie: 275.927\n",
      "[223]\tvalid_0's tweedie: 275.927\n",
      "[224]\tvalid_0's tweedie: 275.927\n",
      "[225]\tvalid_0's tweedie: 275.927\n",
      "[226]\tvalid_0's tweedie: 275.926\n",
      "[227]\tvalid_0's tweedie: 275.926\n",
      "[228]\tvalid_0's tweedie: 275.927\n",
      "[229]\tvalid_0's tweedie: 275.927\n",
      "[230]\tvalid_0's tweedie: 275.927\n",
      "[231]\tvalid_0's tweedie: 275.927\n",
      "[232]\tvalid_0's tweedie: 275.927\n",
      "[233]\tvalid_0's tweedie: 275.927\n",
      "[234]\tvalid_0's tweedie: 275.927\n",
      "[235]\tvalid_0's tweedie: 275.927\n",
      "[236]\tvalid_0's tweedie: 275.927\n",
      "[237]\tvalid_0's tweedie: 275.926\n",
      "[238]\tvalid_0's tweedie: 275.927\n",
      "[239]\tvalid_0's tweedie: 275.927\n",
      "[240]\tvalid_0's tweedie: 275.927\n",
      "[241]\tvalid_0's tweedie: 275.928\n",
      "[242]\tvalid_0's tweedie: 275.928\n",
      "[243]\tvalid_0's tweedie: 275.928\n",
      "[244]\tvalid_0's tweedie: 275.928\n",
      "[245]\tvalid_0's tweedie: 275.928\n",
      "[246]\tvalid_0's tweedie: 275.928\n",
      "[247]\tvalid_0's tweedie: 275.928\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's tweedie: 275.926\n",
      "Training model for level 5 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 13034, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497281\n",
      "[1]\tvalid_0's tweedie: 306.657\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.709\n",
      "[3]\tvalid_0's tweedie: 297.533\n",
      "[4]\tvalid_0's tweedie: 293.99\n",
      "[5]\tvalid_0's tweedie: 290.978\n",
      "[6]\tvalid_0's tweedie: 288.484\n",
      "[7]\tvalid_0's tweedie: 286.378\n",
      "[8]\tvalid_0's tweedie: 284.612\n",
      "[9]\tvalid_0's tweedie: 283.127\n",
      "[10]\tvalid_0's tweedie: 281.939\n",
      "[11]\tvalid_0's tweedie: 280.893\n",
      "[12]\tvalid_0's tweedie: 280.059\n",
      "[13]\tvalid_0's tweedie: 279.377\n",
      "[14]\tvalid_0's tweedie: 278.824\n",
      "[15]\tvalid_0's tweedie: 278.344\n",
      "[16]\tvalid_0's tweedie: 277.97\n",
      "[17]\tvalid_0's tweedie: 277.652\n",
      "[18]\tvalid_0's tweedie: 277.403\n",
      "[19]\tvalid_0's tweedie: 277.191\n",
      "[20]\tvalid_0's tweedie: 277.026\n",
      "[21]\tvalid_0's tweedie: 276.861\n",
      "[22]\tvalid_0's tweedie: 276.739\n",
      "[23]\tvalid_0's tweedie: 276.629\n",
      "[24]\tvalid_0's tweedie: 276.539\n",
      "[25]\tvalid_0's tweedie: 276.468\n",
      "[26]\tvalid_0's tweedie: 276.418\n",
      "[27]\tvalid_0's tweedie: 276.365\n",
      "[28]\tvalid_0's tweedie: 276.326\n",
      "[29]\tvalid_0's tweedie: 276.29\n",
      "[30]\tvalid_0's tweedie: 276.259\n",
      "[31]\tvalid_0's tweedie: 276.223\n",
      "[32]\tvalid_0's tweedie: 276.198\n",
      "[33]\tvalid_0's tweedie: 276.173\n",
      "[34]\tvalid_0's tweedie: 276.156\n",
      "[35]\tvalid_0's tweedie: 276.142\n",
      "[36]\tvalid_0's tweedie: 276.131\n",
      "[37]\tvalid_0's tweedie: 276.117\n",
      "[38]\tvalid_0's tweedie: 276.109\n",
      "[39]\tvalid_0's tweedie: 276.097\n",
      "[40]\tvalid_0's tweedie: 276.083\n",
      "[41]\tvalid_0's tweedie: 276.074\n",
      "[42]\tvalid_0's tweedie: 276.066\n",
      "[43]\tvalid_0's tweedie: 276.059\n",
      "[44]\tvalid_0's tweedie: 276.055\n",
      "[45]\tvalid_0's tweedie: 276.047\n",
      "[46]\tvalid_0's tweedie: 276.042\n",
      "[47]\tvalid_0's tweedie: 276.036\n",
      "[48]\tvalid_0's tweedie: 276.034\n",
      "[49]\tvalid_0's tweedie: 276.026\n",
      "[50]\tvalid_0's tweedie: 276.023\n",
      "[51]\tvalid_0's tweedie: 276.02\n",
      "[52]\tvalid_0's tweedie: 276.014\n",
      "[53]\tvalid_0's tweedie: 276.01\n",
      "[54]\tvalid_0's tweedie: 276.006\n",
      "[55]\tvalid_0's tweedie: 276.001\n",
      "[56]\tvalid_0's tweedie: 275.999\n",
      "[57]\tvalid_0's tweedie: 275.995\n",
      "[58]\tvalid_0's tweedie: 275.995\n",
      "[59]\tvalid_0's tweedie: 275.994\n",
      "[60]\tvalid_0's tweedie: 275.992\n",
      "[61]\tvalid_0's tweedie: 275.989\n",
      "[62]\tvalid_0's tweedie: 275.986\n",
      "[63]\tvalid_0's tweedie: 275.983\n",
      "[64]\tvalid_0's tweedie: 275.981\n",
      "[65]\tvalid_0's tweedie: 275.979\n",
      "[66]\tvalid_0's tweedie: 275.976\n",
      "[67]\tvalid_0's tweedie: 275.975\n",
      "[68]\tvalid_0's tweedie: 275.975\n",
      "[69]\tvalid_0's tweedie: 275.975\n",
      "[70]\tvalid_0's tweedie: 275.974\n",
      "[71]\tvalid_0's tweedie: 275.973\n",
      "[72]\tvalid_0's tweedie: 275.971\n",
      "[73]\tvalid_0's tweedie: 275.971\n",
      "[74]\tvalid_0's tweedie: 275.971\n",
      "[75]\tvalid_0's tweedie: 275.97\n",
      "[76]\tvalid_0's tweedie: 275.97\n",
      "[77]\tvalid_0's tweedie: 275.969\n",
      "[78]\tvalid_0's tweedie: 275.969\n",
      "[79]\tvalid_0's tweedie: 275.967\n",
      "[80]\tvalid_0's tweedie: 275.967\n",
      "[81]\tvalid_0's tweedie: 275.967\n",
      "[82]\tvalid_0's tweedie: 275.966\n",
      "[83]\tvalid_0's tweedie: 275.965\n",
      "[84]\tvalid_0's tweedie: 275.965\n",
      "[85]\tvalid_0's tweedie: 275.966\n",
      "[86]\tvalid_0's tweedie: 275.966\n",
      "[87]\tvalid_0's tweedie: 275.965\n",
      "[88]\tvalid_0's tweedie: 275.965\n",
      "[89]\tvalid_0's tweedie: 275.965\n",
      "[90]\tvalid_0's tweedie: 275.965\n",
      "[91]\tvalid_0's tweedie: 275.965\n",
      "[92]\tvalid_0's tweedie: 275.963\n",
      "[93]\tvalid_0's tweedie: 275.962\n",
      "[94]\tvalid_0's tweedie: 275.961\n",
      "[95]\tvalid_0's tweedie: 275.962\n",
      "[96]\tvalid_0's tweedie: 275.962\n",
      "[97]\tvalid_0's tweedie: 275.962\n",
      "[98]\tvalid_0's tweedie: 275.963\n",
      "[99]\tvalid_0's tweedie: 275.963\n",
      "[100]\tvalid_0's tweedie: 275.962\n",
      "[101]\tvalid_0's tweedie: 275.962\n",
      "[102]\tvalid_0's tweedie: 275.961\n",
      "[103]\tvalid_0's tweedie: 275.961\n",
      "[104]\tvalid_0's tweedie: 275.961\n",
      "[105]\tvalid_0's tweedie: 275.96\n",
      "[106]\tvalid_0's tweedie: 275.96\n",
      "[107]\tvalid_0's tweedie: 275.96\n",
      "[108]\tvalid_0's tweedie: 275.96\n",
      "[109]\tvalid_0's tweedie: 275.96\n",
      "[110]\tvalid_0's tweedie: 275.96\n",
      "[111]\tvalid_0's tweedie: 275.96\n",
      "[112]\tvalid_0's tweedie: 275.96\n",
      "[113]\tvalid_0's tweedie: 275.96\n",
      "[114]\tvalid_0's tweedie: 275.96\n",
      "[115]\tvalid_0's tweedie: 275.959\n",
      "[116]\tvalid_0's tweedie: 275.959\n",
      "[117]\tvalid_0's tweedie: 275.959\n",
      "[118]\tvalid_0's tweedie: 275.959\n",
      "[119]\tvalid_0's tweedie: 275.959\n",
      "[120]\tvalid_0's tweedie: 275.958\n",
      "[121]\tvalid_0's tweedie: 275.958\n",
      "[122]\tvalid_0's tweedie: 275.958\n",
      "[123]\tvalid_0's tweedie: 275.958\n",
      "[124]\tvalid_0's tweedie: 275.96\n",
      "[125]\tvalid_0's tweedie: 275.96\n",
      "[126]\tvalid_0's tweedie: 275.96\n",
      "[127]\tvalid_0's tweedie: 275.96\n",
      "[128]\tvalid_0's tweedie: 275.96\n",
      "[129]\tvalid_0's tweedie: 275.96\n",
      "[130]\tvalid_0's tweedie: 275.96\n",
      "[131]\tvalid_0's tweedie: 275.959\n",
      "[132]\tvalid_0's tweedie: 275.959\n",
      "[133]\tvalid_0's tweedie: 275.959\n",
      "[134]\tvalid_0's tweedie: 275.959\n",
      "[135]\tvalid_0's tweedie: 275.959\n",
      "[136]\tvalid_0's tweedie: 275.959\n",
      "[137]\tvalid_0's tweedie: 275.96\n",
      "[138]\tvalid_0's tweedie: 275.96\n",
      "[139]\tvalid_0's tweedie: 275.96\n",
      "[140]\tvalid_0's tweedie: 275.96\n",
      "[141]\tvalid_0's tweedie: 275.959\n",
      "[142]\tvalid_0's tweedie: 275.959\n",
      "[143]\tvalid_0's tweedie: 275.958\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's tweedie: 275.958\n",
      "Training model for level 5 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 13027, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497443\n",
      "[1]\tvalid_0's tweedie: 306.655\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.724\n",
      "[3]\tvalid_0's tweedie: 297.54\n",
      "[4]\tvalid_0's tweedie: 294.016\n",
      "[5]\tvalid_0's tweedie: 291.092\n",
      "[6]\tvalid_0's tweedie: 288.543\n",
      "[7]\tvalid_0's tweedie: 286.393\n",
      "[8]\tvalid_0's tweedie: 284.614\n",
      "[9]\tvalid_0's tweedie: 283.137\n",
      "[10]\tvalid_0's tweedie: 281.932\n",
      "[11]\tvalid_0's tweedie: 280.915\n",
      "[12]\tvalid_0's tweedie: 280.058\n",
      "[13]\tvalid_0's tweedie: 279.373\n",
      "[14]\tvalid_0's tweedie: 278.797\n",
      "[15]\tvalid_0's tweedie: 278.32\n",
      "[16]\tvalid_0's tweedie: 277.957\n",
      "[17]\tvalid_0's tweedie: 277.642\n",
      "[18]\tvalid_0's tweedie: 277.391\n",
      "[19]\tvalid_0's tweedie: 277.176\n",
      "[20]\tvalid_0's tweedie: 277.004\n",
      "[21]\tvalid_0's tweedie: 276.854\n",
      "[22]\tvalid_0's tweedie: 276.737\n",
      "[23]\tvalid_0's tweedie: 276.632\n",
      "[24]\tvalid_0's tweedie: 276.546\n",
      "[25]\tvalid_0's tweedie: 276.469\n",
      "[26]\tvalid_0's tweedie: 276.402\n",
      "[27]\tvalid_0's tweedie: 276.348\n",
      "[28]\tvalid_0's tweedie: 276.299\n",
      "[29]\tvalid_0's tweedie: 276.266\n",
      "[30]\tvalid_0's tweedie: 276.232\n",
      "[31]\tvalid_0's tweedie: 276.203\n",
      "[32]\tvalid_0's tweedie: 276.179\n",
      "[33]\tvalid_0's tweedie: 276.158\n",
      "[34]\tvalid_0's tweedie: 276.138\n",
      "[35]\tvalid_0's tweedie: 276.125\n",
      "[36]\tvalid_0's tweedie: 276.11\n",
      "[37]\tvalid_0's tweedie: 276.094\n",
      "[38]\tvalid_0's tweedie: 276.085\n",
      "[39]\tvalid_0's tweedie: 276.077\n",
      "[40]\tvalid_0's tweedie: 276.069\n",
      "[41]\tvalid_0's tweedie: 276.058\n",
      "[42]\tvalid_0's tweedie: 276.05\n",
      "[43]\tvalid_0's tweedie: 276.042\n",
      "[44]\tvalid_0's tweedie: 276.037\n",
      "[45]\tvalid_0's tweedie: 276.031\n",
      "[46]\tvalid_0's tweedie: 276.026\n",
      "[47]\tvalid_0's tweedie: 276.022\n",
      "[48]\tvalid_0's tweedie: 276.016\n",
      "[49]\tvalid_0's tweedie: 276.009\n",
      "[50]\tvalid_0's tweedie: 276.004\n",
      "[51]\tvalid_0's tweedie: 276.002\n",
      "[52]\tvalid_0's tweedie: 276.001\n",
      "[53]\tvalid_0's tweedie: 275.998\n",
      "[54]\tvalid_0's tweedie: 275.997\n",
      "[55]\tvalid_0's tweedie: 275.996\n",
      "[56]\tvalid_0's tweedie: 275.994\n",
      "[57]\tvalid_0's tweedie: 275.994\n",
      "[58]\tvalid_0's tweedie: 275.991\n",
      "[59]\tvalid_0's tweedie: 275.986\n",
      "[60]\tvalid_0's tweedie: 275.984\n",
      "[61]\tvalid_0's tweedie: 275.984\n",
      "[62]\tvalid_0's tweedie: 275.983\n",
      "[63]\tvalid_0's tweedie: 275.983\n",
      "[64]\tvalid_0's tweedie: 275.981\n",
      "[65]\tvalid_0's tweedie: 275.981\n",
      "[66]\tvalid_0's tweedie: 275.978\n",
      "[67]\tvalid_0's tweedie: 275.977\n",
      "[68]\tvalid_0's tweedie: 275.975\n",
      "[69]\tvalid_0's tweedie: 275.975\n",
      "[70]\tvalid_0's tweedie: 275.975\n",
      "[71]\tvalid_0's tweedie: 275.975\n",
      "[72]\tvalid_0's tweedie: 275.974\n",
      "[73]\tvalid_0's tweedie: 275.974\n",
      "[74]\tvalid_0's tweedie: 275.973\n",
      "[75]\tvalid_0's tweedie: 275.972\n",
      "[76]\tvalid_0's tweedie: 275.971\n",
      "[77]\tvalid_0's tweedie: 275.971\n",
      "[78]\tvalid_0's tweedie: 275.97\n",
      "[79]\tvalid_0's tweedie: 275.969\n",
      "[80]\tvalid_0's tweedie: 275.969\n",
      "[81]\tvalid_0's tweedie: 275.969\n",
      "[82]\tvalid_0's tweedie: 275.968\n",
      "[83]\tvalid_0's tweedie: 275.968\n",
      "[84]\tvalid_0's tweedie: 275.967\n",
      "[85]\tvalid_0's tweedie: 275.967\n",
      "[86]\tvalid_0's tweedie: 275.967\n",
      "[87]\tvalid_0's tweedie: 275.966\n",
      "[88]\tvalid_0's tweedie: 275.966\n",
      "[89]\tvalid_0's tweedie: 275.967\n",
      "[90]\tvalid_0's tweedie: 275.967\n",
      "[91]\tvalid_0's tweedie: 275.966\n",
      "[92]\tvalid_0's tweedie: 275.966\n",
      "[93]\tvalid_0's tweedie: 275.965\n",
      "[94]\tvalid_0's tweedie: 275.966\n",
      "[95]\tvalid_0's tweedie: 275.965\n",
      "[96]\tvalid_0's tweedie: 275.965\n",
      "[97]\tvalid_0's tweedie: 275.965\n",
      "[98]\tvalid_0's tweedie: 275.965\n",
      "[99]\tvalid_0's tweedie: 275.964\n",
      "[100]\tvalid_0's tweedie: 275.964\n",
      "[101]\tvalid_0's tweedie: 275.964\n",
      "[102]\tvalid_0's tweedie: 275.965\n",
      "[103]\tvalid_0's tweedie: 275.965\n",
      "[104]\tvalid_0's tweedie: 275.965\n",
      "[105]\tvalid_0's tweedie: 275.965\n",
      "[106]\tvalid_0's tweedie: 275.965\n",
      "[107]\tvalid_0's tweedie: 275.964\n",
      "[108]\tvalid_0's tweedie: 275.964\n",
      "[109]\tvalid_0's tweedie: 275.964\n",
      "[110]\tvalid_0's tweedie: 275.963\n",
      "[111]\tvalid_0's tweedie: 275.963\n",
      "[112]\tvalid_0's tweedie: 275.963\n",
      "[113]\tvalid_0's tweedie: 275.962\n",
      "[114]\tvalid_0's tweedie: 275.962\n",
      "[115]\tvalid_0's tweedie: 275.962\n",
      "[116]\tvalid_0's tweedie: 275.963\n",
      "[117]\tvalid_0's tweedie: 275.963\n",
      "[118]\tvalid_0's tweedie: 275.963\n",
      "[119]\tvalid_0's tweedie: 275.963\n",
      "[120]\tvalid_0's tweedie: 275.963\n",
      "[121]\tvalid_0's tweedie: 275.963\n",
      "[122]\tvalid_0's tweedie: 275.963\n",
      "[123]\tvalid_0's tweedie: 275.963\n",
      "[124]\tvalid_0's tweedie: 275.962\n",
      "[125]\tvalid_0's tweedie: 275.962\n",
      "[126]\tvalid_0's tweedie: 275.961\n",
      "[127]\tvalid_0's tweedie: 275.961\n",
      "[128]\tvalid_0's tweedie: 275.961\n",
      "[129]\tvalid_0's tweedie: 275.957\n",
      "[130]\tvalid_0's tweedie: 275.957\n",
      "[131]\tvalid_0's tweedie: 275.957\n",
      "[132]\tvalid_0's tweedie: 275.957\n",
      "[133]\tvalid_0's tweedie: 275.957\n",
      "[134]\tvalid_0's tweedie: 275.957\n",
      "[135]\tvalid_0's tweedie: 275.957\n",
      "[136]\tvalid_0's tweedie: 275.957\n",
      "[137]\tvalid_0's tweedie: 275.957\n",
      "[138]\tvalid_0's tweedie: 275.957\n",
      "[139]\tvalid_0's tweedie: 275.957\n",
      "[140]\tvalid_0's tweedie: 275.958\n",
      "[141]\tvalid_0's tweedie: 275.958\n",
      "[142]\tvalid_0's tweedie: 275.958\n",
      "[143]\tvalid_0's tweedie: 275.957\n",
      "[144]\tvalid_0's tweedie: 275.957\n",
      "[145]\tvalid_0's tweedie: 275.957\n",
      "[146]\tvalid_0's tweedie: 275.956\n",
      "[147]\tvalid_0's tweedie: 275.956\n",
      "[148]\tvalid_0's tweedie: 275.956\n",
      "[149]\tvalid_0's tweedie: 275.956\n",
      "[150]\tvalid_0's tweedie: 275.956\n",
      "[151]\tvalid_0's tweedie: 275.955\n",
      "[152]\tvalid_0's tweedie: 275.955\n",
      "[153]\tvalid_0's tweedie: 275.955\n",
      "[154]\tvalid_0's tweedie: 275.955\n",
      "[155]\tvalid_0's tweedie: 275.955\n",
      "[156]\tvalid_0's tweedie: 275.954\n",
      "[157]\tvalid_0's tweedie: 275.954\n",
      "[158]\tvalid_0's tweedie: 275.954\n",
      "[159]\tvalid_0's tweedie: 275.954\n",
      "[160]\tvalid_0's tweedie: 275.954\n",
      "[161]\tvalid_0's tweedie: 275.954\n",
      "[162]\tvalid_0's tweedie: 275.954\n",
      "[163]\tvalid_0's tweedie: 275.954\n",
      "[164]\tvalid_0's tweedie: 275.954\n",
      "[165]\tvalid_0's tweedie: 275.954\n",
      "[166]\tvalid_0's tweedie: 275.954\n",
      "[167]\tvalid_0's tweedie: 275.953\n",
      "[168]\tvalid_0's tweedie: 275.953\n",
      "[169]\tvalid_0's tweedie: 275.953\n",
      "[170]\tvalid_0's tweedie: 275.953\n",
      "[171]\tvalid_0's tweedie: 275.953\n",
      "[172]\tvalid_0's tweedie: 275.953\n",
      "[173]\tvalid_0's tweedie: 275.953\n",
      "[174]\tvalid_0's tweedie: 275.953\n",
      "[175]\tvalid_0's tweedie: 275.953\n",
      "[176]\tvalid_0's tweedie: 275.954\n",
      "[177]\tvalid_0's tweedie: 275.954\n",
      "[178]\tvalid_0's tweedie: 275.953\n",
      "[179]\tvalid_0's tweedie: 275.953\n",
      "[180]\tvalid_0's tweedie: 275.953\n",
      "[181]\tvalid_0's tweedie: 275.954\n",
      "[182]\tvalid_0's tweedie: 275.953\n",
      "[183]\tvalid_0's tweedie: 275.953\n",
      "[184]\tvalid_0's tweedie: 275.952\n",
      "[185]\tvalid_0's tweedie: 275.952\n",
      "[186]\tvalid_0's tweedie: 275.952\n",
      "[187]\tvalid_0's tweedie: 275.951\n",
      "[188]\tvalid_0's tweedie: 275.951\n",
      "[189]\tvalid_0's tweedie: 275.951\n",
      "[190]\tvalid_0's tweedie: 275.951\n",
      "[191]\tvalid_0's tweedie: 275.95\n",
      "[192]\tvalid_0's tweedie: 275.95\n",
      "[193]\tvalid_0's tweedie: 275.95\n",
      "[194]\tvalid_0's tweedie: 275.949\n",
      "[195]\tvalid_0's tweedie: 275.949\n",
      "[196]\tvalid_0's tweedie: 275.947\n",
      "[197]\tvalid_0's tweedie: 275.947\n",
      "[198]\tvalid_0's tweedie: 275.948\n",
      "[199]\tvalid_0's tweedie: 275.947\n",
      "[200]\tvalid_0's tweedie: 275.947\n",
      "[201]\tvalid_0's tweedie: 275.947\n",
      "[202]\tvalid_0's tweedie: 275.947\n",
      "[203]\tvalid_0's tweedie: 275.946\n",
      "[204]\tvalid_0's tweedie: 275.946\n",
      "[205]\tvalid_0's tweedie: 275.946\n",
      "[206]\tvalid_0's tweedie: 275.946\n",
      "[207]\tvalid_0's tweedie: 275.946\n",
      "[208]\tvalid_0's tweedie: 275.946\n",
      "[209]\tvalid_0's tweedie: 275.945\n",
      "[210]\tvalid_0's tweedie: 275.941\n",
      "[211]\tvalid_0's tweedie: 275.942\n",
      "[212]\tvalid_0's tweedie: 275.941\n",
      "[213]\tvalid_0's tweedie: 275.941\n",
      "[214]\tvalid_0's tweedie: 275.941\n",
      "[215]\tvalid_0's tweedie: 275.941\n",
      "[216]\tvalid_0's tweedie: 275.941\n",
      "[217]\tvalid_0's tweedie: 275.941\n",
      "[218]\tvalid_0's tweedie: 275.941\n",
      "[219]\tvalid_0's tweedie: 275.941\n",
      "[220]\tvalid_0's tweedie: 275.941\n",
      "[221]\tvalid_0's tweedie: 275.941\n",
      "[222]\tvalid_0's tweedie: 275.94\n",
      "[223]\tvalid_0's tweedie: 275.94\n",
      "[224]\tvalid_0's tweedie: 275.94\n",
      "[225]\tvalid_0's tweedie: 275.94\n",
      "[226]\tvalid_0's tweedie: 275.94\n",
      "[227]\tvalid_0's tweedie: 275.94\n",
      "[228]\tvalid_0's tweedie: 275.94\n",
      "[229]\tvalid_0's tweedie: 275.94\n",
      "[230]\tvalid_0's tweedie: 275.939\n",
      "[231]\tvalid_0's tweedie: 275.939\n",
      "[232]\tvalid_0's tweedie: 275.939\n",
      "[233]\tvalid_0's tweedie: 275.939\n",
      "[234]\tvalid_0's tweedie: 275.939\n",
      "[235]\tvalid_0's tweedie: 275.939\n",
      "[236]\tvalid_0's tweedie: 275.939\n",
      "[237]\tvalid_0's tweedie: 275.938\n",
      "[238]\tvalid_0's tweedie: 275.938\n",
      "[239]\tvalid_0's tweedie: 275.938\n",
      "[240]\tvalid_0's tweedie: 275.938\n",
      "[241]\tvalid_0's tweedie: 275.938\n",
      "[242]\tvalid_0's tweedie: 275.938\n",
      "[243]\tvalid_0's tweedie: 275.937\n",
      "[244]\tvalid_0's tweedie: 275.938\n",
      "[245]\tvalid_0's tweedie: 275.938\n",
      "[246]\tvalid_0's tweedie: 275.938\n",
      "[247]\tvalid_0's tweedie: 275.938\n",
      "[248]\tvalid_0's tweedie: 275.938\n",
      "[249]\tvalid_0's tweedie: 275.938\n",
      "[250]\tvalid_0's tweedie: 275.937\n",
      "[251]\tvalid_0's tweedie: 275.937\n",
      "[252]\tvalid_0's tweedie: 275.936\n",
      "[253]\tvalid_0's tweedie: 275.937\n",
      "[254]\tvalid_0's tweedie: 275.936\n",
      "[255]\tvalid_0's tweedie: 275.936\n",
      "[256]\tvalid_0's tweedie: 275.936\n",
      "[257]\tvalid_0's tweedie: 275.936\n",
      "[258]\tvalid_0's tweedie: 275.936\n",
      "[259]\tvalid_0's tweedie: 275.936\n",
      "[260]\tvalid_0's tweedie: 275.935\n",
      "[261]\tvalid_0's tweedie: 275.935\n",
      "[262]\tvalid_0's tweedie: 275.935\n",
      "[263]\tvalid_0's tweedie: 275.935\n",
      "[264]\tvalid_0's tweedie: 275.935\n",
      "[265]\tvalid_0's tweedie: 275.935\n",
      "[266]\tvalid_0's tweedie: 275.935\n",
      "[267]\tvalid_0's tweedie: 275.935\n",
      "[268]\tvalid_0's tweedie: 275.935\n",
      "[269]\tvalid_0's tweedie: 275.935\n",
      "[270]\tvalid_0's tweedie: 275.935\n",
      "[271]\tvalid_0's tweedie: 275.935\n",
      "[272]\tvalid_0's tweedie: 275.935\n",
      "[273]\tvalid_0's tweedie: 275.935\n",
      "[274]\tvalid_0's tweedie: 275.934\n",
      "[275]\tvalid_0's tweedie: 275.934\n",
      "[276]\tvalid_0's tweedie: 275.934\n",
      "[277]\tvalid_0's tweedie: 275.934\n",
      "[278]\tvalid_0's tweedie: 275.934\n",
      "[279]\tvalid_0's tweedie: 275.935\n",
      "[280]\tvalid_0's tweedie: 275.935\n",
      "[281]\tvalid_0's tweedie: 275.934\n",
      "[282]\tvalid_0's tweedie: 275.934\n",
      "[283]\tvalid_0's tweedie: 275.934\n",
      "[284]\tvalid_0's tweedie: 275.935\n",
      "[285]\tvalid_0's tweedie: 275.935\n",
      "[286]\tvalid_0's tweedie: 275.935\n",
      "[287]\tvalid_0's tweedie: 275.935\n",
      "[288]\tvalid_0's tweedie: 275.935\n",
      "[289]\tvalid_0's tweedie: 275.935\n",
      "[290]\tvalid_0's tweedie: 275.935\n",
      "[291]\tvalid_0's tweedie: 275.935\n",
      "[292]\tvalid_0's tweedie: 275.935\n",
      "[293]\tvalid_0's tweedie: 275.935\n",
      "[294]\tvalid_0's tweedie: 275.935\n",
      "[295]\tvalid_0's tweedie: 275.935\n",
      "[296]\tvalid_0's tweedie: 275.934\n",
      "[297]\tvalid_0's tweedie: 275.934\n",
      "[298]\tvalid_0's tweedie: 275.934\n",
      "[299]\tvalid_0's tweedie: 275.934\n",
      "[300]\tvalid_0's tweedie: 275.932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 275.932\n",
      "Training model for level 5 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 13020, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497659\n",
      "[1]\tvalid_0's tweedie: 306.654\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.722\n",
      "[3]\tvalid_0's tweedie: 297.541\n",
      "[4]\tvalid_0's tweedie: 293.988\n",
      "[5]\tvalid_0's tweedie: 291.012\n",
      "[6]\tvalid_0's tweedie: 288.518\n",
      "[7]\tvalid_0's tweedie: 286.381\n",
      "[8]\tvalid_0's tweedie: 284.577\n",
      "[9]\tvalid_0's tweedie: 283.127\n",
      "[10]\tvalid_0's tweedie: 281.879\n",
      "[11]\tvalid_0's tweedie: 280.908\n",
      "[12]\tvalid_0's tweedie: 280.067\n",
      "[13]\tvalid_0's tweedie: 279.416\n",
      "[14]\tvalid_0's tweedie: 278.843\n",
      "[15]\tvalid_0's tweedie: 278.359\n",
      "[16]\tvalid_0's tweedie: 277.977\n",
      "[17]\tvalid_0's tweedie: 277.648\n",
      "[18]\tvalid_0's tweedie: 277.37\n",
      "[19]\tvalid_0's tweedie: 277.161\n",
      "[20]\tvalid_0's tweedie: 276.993\n",
      "[21]\tvalid_0's tweedie: 276.849\n",
      "[22]\tvalid_0's tweedie: 276.717\n",
      "[23]\tvalid_0's tweedie: 276.612\n",
      "[24]\tvalid_0's tweedie: 276.528\n",
      "[25]\tvalid_0's tweedie: 276.446\n",
      "[26]\tvalid_0's tweedie: 276.384\n",
      "[27]\tvalid_0's tweedie: 276.331\n",
      "[28]\tvalid_0's tweedie: 276.277\n",
      "[29]\tvalid_0's tweedie: 276.241\n",
      "[30]\tvalid_0's tweedie: 276.212\n",
      "[31]\tvalid_0's tweedie: 276.188\n",
      "[32]\tvalid_0's tweedie: 276.17\n",
      "[33]\tvalid_0's tweedie: 276.147\n",
      "[34]\tvalid_0's tweedie: 276.131\n",
      "[35]\tvalid_0's tweedie: 276.118\n",
      "[36]\tvalid_0's tweedie: 276.101\n",
      "[37]\tvalid_0's tweedie: 276.086\n",
      "[38]\tvalid_0's tweedie: 276.079\n",
      "[39]\tvalid_0's tweedie: 276.069\n",
      "[40]\tvalid_0's tweedie: 276.06\n",
      "[41]\tvalid_0's tweedie: 276.053\n",
      "[42]\tvalid_0's tweedie: 276.043\n",
      "[43]\tvalid_0's tweedie: 276.038\n",
      "[44]\tvalid_0's tweedie: 276.03\n",
      "[45]\tvalid_0's tweedie: 276.025\n",
      "[46]\tvalid_0's tweedie: 276.018\n",
      "[47]\tvalid_0's tweedie: 276.014\n",
      "[48]\tvalid_0's tweedie: 276.01\n",
      "[49]\tvalid_0's tweedie: 276.001\n",
      "[50]\tvalid_0's tweedie: 275.999\n",
      "[51]\tvalid_0's tweedie: 275.994\n",
      "[52]\tvalid_0's tweedie: 275.992\n",
      "[53]\tvalid_0's tweedie: 275.988\n",
      "[54]\tvalid_0's tweedie: 275.987\n",
      "[55]\tvalid_0's tweedie: 275.987\n",
      "[56]\tvalid_0's tweedie: 275.985\n",
      "[57]\tvalid_0's tweedie: 275.984\n",
      "[58]\tvalid_0's tweedie: 275.983\n",
      "[59]\tvalid_0's tweedie: 275.98\n",
      "[60]\tvalid_0's tweedie: 275.979\n",
      "[61]\tvalid_0's tweedie: 275.977\n",
      "[62]\tvalid_0's tweedie: 275.976\n",
      "[63]\tvalid_0's tweedie: 275.974\n",
      "[64]\tvalid_0's tweedie: 275.973\n",
      "[65]\tvalid_0's tweedie: 275.97\n",
      "[66]\tvalid_0's tweedie: 275.968\n",
      "[67]\tvalid_0's tweedie: 275.967\n",
      "[68]\tvalid_0's tweedie: 275.967\n",
      "[69]\tvalid_0's tweedie: 275.968\n",
      "[70]\tvalid_0's tweedie: 275.968\n",
      "[71]\tvalid_0's tweedie: 275.967\n",
      "[72]\tvalid_0's tweedie: 275.966\n",
      "[73]\tvalid_0's tweedie: 275.961\n",
      "[74]\tvalid_0's tweedie: 275.96\n",
      "[75]\tvalid_0's tweedie: 275.96\n",
      "[76]\tvalid_0's tweedie: 275.959\n",
      "[77]\tvalid_0's tweedie: 275.959\n",
      "[78]\tvalid_0's tweedie: 275.96\n",
      "[79]\tvalid_0's tweedie: 275.959\n",
      "[80]\tvalid_0's tweedie: 275.96\n",
      "[81]\tvalid_0's tweedie: 275.959\n",
      "[82]\tvalid_0's tweedie: 275.959\n",
      "[83]\tvalid_0's tweedie: 275.959\n",
      "[84]\tvalid_0's tweedie: 275.959\n",
      "[85]\tvalid_0's tweedie: 275.959\n",
      "[86]\tvalid_0's tweedie: 275.96\n",
      "[87]\tvalid_0's tweedie: 275.96\n",
      "[88]\tvalid_0's tweedie: 275.959\n",
      "[89]\tvalid_0's tweedie: 275.959\n",
      "[90]\tvalid_0's tweedie: 275.959\n",
      "[91]\tvalid_0's tweedie: 275.958\n",
      "[92]\tvalid_0's tweedie: 275.959\n",
      "[93]\tvalid_0's tweedie: 275.958\n",
      "[94]\tvalid_0's tweedie: 275.961\n",
      "[95]\tvalid_0's tweedie: 275.961\n",
      "[96]\tvalid_0's tweedie: 275.961\n",
      "[97]\tvalid_0's tweedie: 275.961\n",
      "[98]\tvalid_0's tweedie: 275.961\n",
      "[99]\tvalid_0's tweedie: 275.962\n",
      "[100]\tvalid_0's tweedie: 275.962\n",
      "[101]\tvalid_0's tweedie: 275.962\n",
      "[102]\tvalid_0's tweedie: 275.962\n",
      "[103]\tvalid_0's tweedie: 275.962\n",
      "[104]\tvalid_0's tweedie: 275.962\n",
      "[105]\tvalid_0's tweedie: 275.962\n",
      "[106]\tvalid_0's tweedie: 275.962\n",
      "[107]\tvalid_0's tweedie: 275.96\n",
      "[108]\tvalid_0's tweedie: 275.96\n",
      "[109]\tvalid_0's tweedie: 275.961\n",
      "[110]\tvalid_0's tweedie: 275.961\n",
      "[111]\tvalid_0's tweedie: 275.961\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's tweedie: 275.958\n",
      "Training model for level 5 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 13013, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.497872\n",
      "[1]\tvalid_0's tweedie: 306.651\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.72\n",
      "[3]\tvalid_0's tweedie: 297.529\n",
      "[4]\tvalid_0's tweedie: 293.973\n",
      "[5]\tvalid_0's tweedie: 290.981\n",
      "[6]\tvalid_0's tweedie: 288.524\n",
      "[7]\tvalid_0's tweedie: 286.364\n",
      "[8]\tvalid_0's tweedie: 284.581\n",
      "[9]\tvalid_0's tweedie: 283.105\n",
      "[10]\tvalid_0's tweedie: 281.902\n",
      "[11]\tvalid_0's tweedie: 280.897\n",
      "[12]\tvalid_0's tweedie: 280.062\n",
      "[13]\tvalid_0's tweedie: 279.371\n",
      "[14]\tvalid_0's tweedie: 278.847\n",
      "[15]\tvalid_0's tweedie: 278.372\n",
      "[16]\tvalid_0's tweedie: 277.976\n",
      "[17]\tvalid_0's tweedie: 277.653\n",
      "[18]\tvalid_0's tweedie: 277.376\n",
      "[19]\tvalid_0's tweedie: 277.166\n",
      "[20]\tvalid_0's tweedie: 276.973\n",
      "[21]\tvalid_0's tweedie: 276.827\n",
      "[22]\tvalid_0's tweedie: 276.708\n",
      "[23]\tvalid_0's tweedie: 276.613\n",
      "[24]\tvalid_0's tweedie: 276.525\n",
      "[25]\tvalid_0's tweedie: 276.453\n",
      "[26]\tvalid_0's tweedie: 276.386\n",
      "[27]\tvalid_0's tweedie: 276.331\n",
      "[28]\tvalid_0's tweedie: 276.283\n",
      "[29]\tvalid_0's tweedie: 276.244\n",
      "[30]\tvalid_0's tweedie: 276.212\n",
      "[31]\tvalid_0's tweedie: 276.187\n",
      "[32]\tvalid_0's tweedie: 276.164\n",
      "[33]\tvalid_0's tweedie: 276.145\n",
      "[34]\tvalid_0's tweedie: 276.13\n",
      "[35]\tvalid_0's tweedie: 276.113\n",
      "[36]\tvalid_0's tweedie: 276.102\n",
      "[37]\tvalid_0's tweedie: 276.093\n",
      "[38]\tvalid_0's tweedie: 276.081\n",
      "[39]\tvalid_0's tweedie: 276.072\n",
      "[40]\tvalid_0's tweedie: 276.064\n",
      "[41]\tvalid_0's tweedie: 276.055\n",
      "[42]\tvalid_0's tweedie: 276.049\n",
      "[43]\tvalid_0's tweedie: 276.041\n",
      "[44]\tvalid_0's tweedie: 276.035\n",
      "[45]\tvalid_0's tweedie: 276.028\n",
      "[46]\tvalid_0's tweedie: 276.02\n",
      "[47]\tvalid_0's tweedie: 276.013\n",
      "[48]\tvalid_0's tweedie: 276.01\n",
      "[49]\tvalid_0's tweedie: 276.007\n",
      "[50]\tvalid_0's tweedie: 276.005\n",
      "[51]\tvalid_0's tweedie: 276.003\n",
      "[52]\tvalid_0's tweedie: 275.999\n",
      "[53]\tvalid_0's tweedie: 275.996\n",
      "[54]\tvalid_0's tweedie: 275.994\n",
      "[55]\tvalid_0's tweedie: 275.988\n",
      "[56]\tvalid_0's tweedie: 275.987\n",
      "[57]\tvalid_0's tweedie: 275.985\n",
      "[58]\tvalid_0's tweedie: 275.984\n",
      "[59]\tvalid_0's tweedie: 275.983\n",
      "[60]\tvalid_0's tweedie: 275.979\n",
      "[61]\tvalid_0's tweedie: 275.976\n",
      "[62]\tvalid_0's tweedie: 275.973\n",
      "[63]\tvalid_0's tweedie: 275.973\n",
      "[64]\tvalid_0's tweedie: 275.968\n",
      "[65]\tvalid_0's tweedie: 275.966\n",
      "[66]\tvalid_0's tweedie: 275.966\n",
      "[67]\tvalid_0's tweedie: 275.964\n",
      "[68]\tvalid_0's tweedie: 275.963\n",
      "[69]\tvalid_0's tweedie: 275.963\n",
      "[70]\tvalid_0's tweedie: 275.96\n",
      "[71]\tvalid_0's tweedie: 275.96\n",
      "[72]\tvalid_0's tweedie: 275.959\n",
      "[73]\tvalid_0's tweedie: 275.959\n",
      "[74]\tvalid_0's tweedie: 275.959\n",
      "[75]\tvalid_0's tweedie: 275.959\n",
      "[76]\tvalid_0's tweedie: 275.959\n",
      "[77]\tvalid_0's tweedie: 275.959\n",
      "[78]\tvalid_0's tweedie: 275.958\n",
      "[79]\tvalid_0's tweedie: 275.958\n",
      "[80]\tvalid_0's tweedie: 275.956\n",
      "[81]\tvalid_0's tweedie: 275.956\n",
      "[82]\tvalid_0's tweedie: 275.953\n",
      "[83]\tvalid_0's tweedie: 275.953\n",
      "[84]\tvalid_0's tweedie: 275.953\n",
      "[85]\tvalid_0's tweedie: 275.952\n",
      "[86]\tvalid_0's tweedie: 275.951\n",
      "[87]\tvalid_0's tweedie: 275.951\n",
      "[88]\tvalid_0's tweedie: 275.951\n",
      "[89]\tvalid_0's tweedie: 275.95\n",
      "[90]\tvalid_0's tweedie: 275.949\n",
      "[91]\tvalid_0's tweedie: 275.949\n",
      "[92]\tvalid_0's tweedie: 275.949\n",
      "[93]\tvalid_0's tweedie: 275.949\n",
      "[94]\tvalid_0's tweedie: 275.949\n",
      "[95]\tvalid_0's tweedie: 275.949\n",
      "[96]\tvalid_0's tweedie: 275.949\n",
      "[97]\tvalid_0's tweedie: 275.949\n",
      "[98]\tvalid_0's tweedie: 275.949\n",
      "[99]\tvalid_0's tweedie: 275.947\n",
      "[100]\tvalid_0's tweedie: 275.948\n",
      "[101]\tvalid_0's tweedie: 275.948\n",
      "[102]\tvalid_0's tweedie: 275.948\n",
      "[103]\tvalid_0's tweedie: 275.948\n",
      "[104]\tvalid_0's tweedie: 275.948\n",
      "[105]\tvalid_0's tweedie: 275.948\n",
      "[106]\tvalid_0's tweedie: 275.947\n",
      "[107]\tvalid_0's tweedie: 275.947\n",
      "[108]\tvalid_0's tweedie: 275.946\n",
      "[109]\tvalid_0's tweedie: 275.946\n",
      "[110]\tvalid_0's tweedie: 275.946\n",
      "[111]\tvalid_0's tweedie: 275.945\n",
      "[112]\tvalid_0's tweedie: 275.945\n",
      "[113]\tvalid_0's tweedie: 275.945\n",
      "[114]\tvalid_0's tweedie: 275.943\n",
      "[115]\tvalid_0's tweedie: 275.943\n",
      "[116]\tvalid_0's tweedie: 275.943\n",
      "[117]\tvalid_0's tweedie: 275.942\n",
      "[118]\tvalid_0's tweedie: 275.942\n",
      "[119]\tvalid_0's tweedie: 275.943\n",
      "[120]\tvalid_0's tweedie: 275.942\n",
      "[121]\tvalid_0's tweedie: 275.945\n",
      "[122]\tvalid_0's tweedie: 275.944\n",
      "[123]\tvalid_0's tweedie: 275.943\n",
      "[124]\tvalid_0's tweedie: 275.944\n",
      "[125]\tvalid_0's tweedie: 275.943\n",
      "[126]\tvalid_0's tweedie: 275.942\n",
      "[127]\tvalid_0's tweedie: 275.94\n",
      "[128]\tvalid_0's tweedie: 275.94\n",
      "[129]\tvalid_0's tweedie: 275.94\n",
      "[130]\tvalid_0's tweedie: 275.94\n",
      "[131]\tvalid_0's tweedie: 275.94\n",
      "[132]\tvalid_0's tweedie: 275.94\n",
      "[133]\tvalid_0's tweedie: 275.94\n",
      "[134]\tvalid_0's tweedie: 275.94\n",
      "[135]\tvalid_0's tweedie: 275.94\n",
      "[136]\tvalid_0's tweedie: 275.939\n",
      "[137]\tvalid_0's tweedie: 275.939\n",
      "[138]\tvalid_0's tweedie: 275.939\n",
      "[139]\tvalid_0's tweedie: 275.939\n",
      "[140]\tvalid_0's tweedie: 275.939\n",
      "[141]\tvalid_0's tweedie: 275.939\n",
      "[142]\tvalid_0's tweedie: 275.939\n",
      "[143]\tvalid_0's tweedie: 275.939\n",
      "[144]\tvalid_0's tweedie: 275.94\n",
      "[145]\tvalid_0's tweedie: 275.94\n",
      "[146]\tvalid_0's tweedie: 275.939\n",
      "[147]\tvalid_0's tweedie: 275.938\n",
      "[148]\tvalid_0's tweedie: 275.938\n",
      "[149]\tvalid_0's tweedie: 275.938\n",
      "[150]\tvalid_0's tweedie: 275.938\n",
      "[151]\tvalid_0's tweedie: 275.937\n",
      "[152]\tvalid_0's tweedie: 275.937\n",
      "[153]\tvalid_0's tweedie: 275.937\n",
      "[154]\tvalid_0's tweedie: 275.937\n",
      "[155]\tvalid_0's tweedie: 275.937\n",
      "[156]\tvalid_0's tweedie: 275.936\n",
      "[157]\tvalid_0's tweedie: 275.935\n",
      "[158]\tvalid_0's tweedie: 275.935\n",
      "[159]\tvalid_0's tweedie: 275.936\n",
      "[160]\tvalid_0's tweedie: 275.936\n",
      "[161]\tvalid_0's tweedie: 275.936\n",
      "[162]\tvalid_0's tweedie: 275.935\n",
      "[163]\tvalid_0's tweedie: 275.935\n",
      "[164]\tvalid_0's tweedie: 275.936\n",
      "[165]\tvalid_0's tweedie: 275.936\n",
      "[166]\tvalid_0's tweedie: 275.936\n",
      "[167]\tvalid_0's tweedie: 275.936\n",
      "[168]\tvalid_0's tweedie: 275.937\n",
      "[169]\tvalid_0's tweedie: 275.937\n",
      "[170]\tvalid_0's tweedie: 275.937\n",
      "[171]\tvalid_0's tweedie: 275.937\n",
      "[172]\tvalid_0's tweedie: 275.936\n",
      "[173]\tvalid_0's tweedie: 275.936\n",
      "[174]\tvalid_0's tweedie: 275.936\n",
      "[175]\tvalid_0's tweedie: 275.936\n",
      "[176]\tvalid_0's tweedie: 275.936\n",
      "[177]\tvalid_0's tweedie: 275.936\n",
      "[178]\tvalid_0's tweedie: 275.936\n",
      "[179]\tvalid_0's tweedie: 275.936\n",
      "[180]\tvalid_0's tweedie: 275.936\n",
      "[181]\tvalid_0's tweedie: 275.936\n",
      "[182]\tvalid_0's tweedie: 275.936\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's tweedie: 275.935\n",
      "Training model for level 5 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 13006, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498092\n",
      "[1]\tvalid_0's tweedie: 306.652\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.676\n",
      "[3]\tvalid_0's tweedie: 297.484\n",
      "[4]\tvalid_0's tweedie: 293.945\n",
      "[5]\tvalid_0's tweedie: 290.963\n",
      "[6]\tvalid_0's tweedie: 288.385\n",
      "[7]\tvalid_0's tweedie: 286.26\n",
      "[8]\tvalid_0's tweedie: 284.488\n",
      "[9]\tvalid_0's tweedie: 283.02\n",
      "[10]\tvalid_0's tweedie: 281.774\n",
      "[11]\tvalid_0's tweedie: 280.786\n",
      "[12]\tvalid_0's tweedie: 279.959\n",
      "[13]\tvalid_0's tweedie: 279.274\n",
      "[14]\tvalid_0's tweedie: 278.707\n",
      "[15]\tvalid_0's tweedie: 278.24\n",
      "[16]\tvalid_0's tweedie: 277.855\n",
      "[17]\tvalid_0's tweedie: 277.55\n",
      "[18]\tvalid_0's tweedie: 277.293\n",
      "[19]\tvalid_0's tweedie: 277.077\n",
      "[20]\tvalid_0's tweedie: 276.923\n",
      "[21]\tvalid_0's tweedie: 276.779\n",
      "[22]\tvalid_0's tweedie: 276.654\n",
      "[23]\tvalid_0's tweedie: 276.556\n",
      "[24]\tvalid_0's tweedie: 276.473\n",
      "[25]\tvalid_0's tweedie: 276.404\n",
      "[26]\tvalid_0's tweedie: 276.349\n",
      "[27]\tvalid_0's tweedie: 276.299\n",
      "[28]\tvalid_0's tweedie: 276.253\n",
      "[29]\tvalid_0's tweedie: 276.224\n",
      "[30]\tvalid_0's tweedie: 276.188\n",
      "[31]\tvalid_0's tweedie: 276.161\n",
      "[32]\tvalid_0's tweedie: 276.139\n",
      "[33]\tvalid_0's tweedie: 276.122\n",
      "[34]\tvalid_0's tweedie: 276.107\n",
      "[35]\tvalid_0's tweedie: 276.089\n",
      "[36]\tvalid_0's tweedie: 276.075\n",
      "[37]\tvalid_0's tweedie: 276.065\n",
      "[38]\tvalid_0's tweedie: 276.057\n",
      "[39]\tvalid_0's tweedie: 276.052\n",
      "[40]\tvalid_0's tweedie: 276.04\n",
      "[41]\tvalid_0's tweedie: 276.032\n",
      "[42]\tvalid_0's tweedie: 276.023\n",
      "[43]\tvalid_0's tweedie: 276.016\n",
      "[44]\tvalid_0's tweedie: 276.013\n",
      "[45]\tvalid_0's tweedie: 276.007\n",
      "[46]\tvalid_0's tweedie: 276.001\n",
      "[47]\tvalid_0's tweedie: 275.997\n",
      "[48]\tvalid_0's tweedie: 275.996\n",
      "[49]\tvalid_0's tweedie: 275.994\n",
      "[50]\tvalid_0's tweedie: 275.989\n",
      "[51]\tvalid_0's tweedie: 275.985\n",
      "[52]\tvalid_0's tweedie: 275.982\n",
      "[53]\tvalid_0's tweedie: 275.979\n",
      "[54]\tvalid_0's tweedie: 275.976\n",
      "[55]\tvalid_0's tweedie: 275.974\n",
      "[56]\tvalid_0's tweedie: 275.971\n",
      "[57]\tvalid_0's tweedie: 275.969\n",
      "[58]\tvalid_0's tweedie: 275.966\n",
      "[59]\tvalid_0's tweedie: 275.964\n",
      "[60]\tvalid_0's tweedie: 275.962\n",
      "[61]\tvalid_0's tweedie: 275.959\n",
      "[62]\tvalid_0's tweedie: 275.959\n",
      "[63]\tvalid_0's tweedie: 275.957\n",
      "[64]\tvalid_0's tweedie: 275.955\n",
      "[65]\tvalid_0's tweedie: 275.955\n",
      "[66]\tvalid_0's tweedie: 275.952\n",
      "[67]\tvalid_0's tweedie: 275.953\n",
      "[68]\tvalid_0's tweedie: 275.955\n",
      "[69]\tvalid_0's tweedie: 275.954\n",
      "[70]\tvalid_0's tweedie: 275.953\n",
      "[71]\tvalid_0's tweedie: 275.951\n",
      "[72]\tvalid_0's tweedie: 275.951\n",
      "[73]\tvalid_0's tweedie: 275.951\n",
      "[74]\tvalid_0's tweedie: 275.951\n",
      "[75]\tvalid_0's tweedie: 275.95\n",
      "[76]\tvalid_0's tweedie: 275.949\n",
      "[77]\tvalid_0's tweedie: 275.948\n",
      "[78]\tvalid_0's tweedie: 275.947\n",
      "[79]\tvalid_0's tweedie: 275.947\n",
      "[80]\tvalid_0's tweedie: 275.947\n",
      "[81]\tvalid_0's tweedie: 275.947\n",
      "[82]\tvalid_0's tweedie: 275.947\n",
      "[83]\tvalid_0's tweedie: 275.944\n",
      "[84]\tvalid_0's tweedie: 275.944\n",
      "[85]\tvalid_0's tweedie: 275.944\n",
      "[86]\tvalid_0's tweedie: 275.945\n",
      "[87]\tvalid_0's tweedie: 275.945\n",
      "[88]\tvalid_0's tweedie: 275.944\n",
      "[89]\tvalid_0's tweedie: 275.944\n",
      "[90]\tvalid_0's tweedie: 275.944\n",
      "[91]\tvalid_0's tweedie: 275.944\n",
      "[92]\tvalid_0's tweedie: 275.941\n",
      "[93]\tvalid_0's tweedie: 275.94\n",
      "[94]\tvalid_0's tweedie: 275.939\n",
      "[95]\tvalid_0's tweedie: 275.939\n",
      "[96]\tvalid_0's tweedie: 275.939\n",
      "[97]\tvalid_0's tweedie: 275.938\n",
      "[98]\tvalid_0's tweedie: 275.938\n",
      "[99]\tvalid_0's tweedie: 275.938\n",
      "[100]\tvalid_0's tweedie: 275.937\n",
      "[101]\tvalid_0's tweedie: 275.936\n",
      "[102]\tvalid_0's tweedie: 275.936\n",
      "[103]\tvalid_0's tweedie: 275.939\n",
      "[104]\tvalid_0's tweedie: 275.938\n",
      "[105]\tvalid_0's tweedie: 275.938\n",
      "[106]\tvalid_0's tweedie: 275.937\n",
      "[107]\tvalid_0's tweedie: 275.938\n",
      "[108]\tvalid_0's tweedie: 275.936\n",
      "[109]\tvalid_0's tweedie: 275.936\n",
      "[110]\tvalid_0's tweedie: 275.936\n",
      "[111]\tvalid_0's tweedie: 275.936\n",
      "[112]\tvalid_0's tweedie: 275.935\n",
      "[113]\tvalid_0's tweedie: 275.935\n",
      "[114]\tvalid_0's tweedie: 275.936\n",
      "[115]\tvalid_0's tweedie: 275.931\n",
      "[116]\tvalid_0's tweedie: 275.931\n",
      "[117]\tvalid_0's tweedie: 275.932\n",
      "[118]\tvalid_0's tweedie: 275.932\n",
      "[119]\tvalid_0's tweedie: 275.931\n",
      "[120]\tvalid_0's tweedie: 275.93\n",
      "[121]\tvalid_0's tweedie: 275.931\n",
      "[122]\tvalid_0's tweedie: 275.93\n",
      "[123]\tvalid_0's tweedie: 275.93\n",
      "[124]\tvalid_0's tweedie: 275.93\n",
      "[125]\tvalid_0's tweedie: 275.928\n",
      "[126]\tvalid_0's tweedie: 275.928\n",
      "[127]\tvalid_0's tweedie: 275.928\n",
      "[128]\tvalid_0's tweedie: 275.927\n",
      "[129]\tvalid_0's tweedie: 275.927\n",
      "[130]\tvalid_0's tweedie: 275.927\n",
      "[131]\tvalid_0's tweedie: 275.929\n",
      "[132]\tvalid_0's tweedie: 275.929\n",
      "[133]\tvalid_0's tweedie: 275.925\n",
      "[134]\tvalid_0's tweedie: 275.925\n",
      "[135]\tvalid_0's tweedie: 275.925\n",
      "[136]\tvalid_0's tweedie: 275.926\n",
      "[137]\tvalid_0's tweedie: 275.926\n",
      "[138]\tvalid_0's tweedie: 275.926\n",
      "[139]\tvalid_0's tweedie: 275.926\n",
      "[140]\tvalid_0's tweedie: 275.925\n",
      "[141]\tvalid_0's tweedie: 275.925\n",
      "[142]\tvalid_0's tweedie: 275.926\n",
      "[143]\tvalid_0's tweedie: 275.926\n",
      "[144]\tvalid_0's tweedie: 275.926\n",
      "[145]\tvalid_0's tweedie: 275.926\n",
      "[146]\tvalid_0's tweedie: 275.925\n",
      "[147]\tvalid_0's tweedie: 275.925\n",
      "[148]\tvalid_0's tweedie: 275.924\n",
      "[149]\tvalid_0's tweedie: 275.924\n",
      "[150]\tvalid_0's tweedie: 275.924\n",
      "[151]\tvalid_0's tweedie: 275.924\n",
      "[152]\tvalid_0's tweedie: 275.924\n",
      "[153]\tvalid_0's tweedie: 275.923\n",
      "[154]\tvalid_0's tweedie: 275.923\n",
      "[155]\tvalid_0's tweedie: 275.923\n",
      "[156]\tvalid_0's tweedie: 275.922\n",
      "[157]\tvalid_0's tweedie: 275.922\n",
      "[158]\tvalid_0's tweedie: 275.923\n",
      "[159]\tvalid_0's tweedie: 275.923\n",
      "[160]\tvalid_0's tweedie: 275.922\n",
      "[161]\tvalid_0's tweedie: 275.922\n",
      "[162]\tvalid_0's tweedie: 275.922\n",
      "[163]\tvalid_0's tweedie: 275.922\n",
      "[164]\tvalid_0's tweedie: 275.922\n",
      "[165]\tvalid_0's tweedie: 275.922\n",
      "[166]\tvalid_0's tweedie: 275.922\n",
      "[167]\tvalid_0's tweedie: 275.922\n",
      "[168]\tvalid_0's tweedie: 275.92\n",
      "[169]\tvalid_0's tweedie: 275.92\n",
      "[170]\tvalid_0's tweedie: 275.92\n",
      "[171]\tvalid_0's tweedie: 275.92\n",
      "[172]\tvalid_0's tweedie: 275.919\n",
      "[173]\tvalid_0's tweedie: 275.918\n",
      "[174]\tvalid_0's tweedie: 275.918\n",
      "[175]\tvalid_0's tweedie: 275.918\n",
      "[176]\tvalid_0's tweedie: 275.918\n",
      "[177]\tvalid_0's tweedie: 275.918\n",
      "[178]\tvalid_0's tweedie: 275.919\n",
      "[179]\tvalid_0's tweedie: 275.917\n",
      "[180]\tvalid_0's tweedie: 275.916\n",
      "[181]\tvalid_0's tweedie: 275.917\n",
      "[182]\tvalid_0's tweedie: 275.916\n",
      "[183]\tvalid_0's tweedie: 275.916\n",
      "[184]\tvalid_0's tweedie: 275.916\n",
      "[185]\tvalid_0's tweedie: 275.915\n",
      "[186]\tvalid_0's tweedie: 275.915\n",
      "[187]\tvalid_0's tweedie: 275.915\n",
      "[188]\tvalid_0's tweedie: 275.917\n",
      "[189]\tvalid_0's tweedie: 275.918\n",
      "[190]\tvalid_0's tweedie: 275.918\n",
      "[191]\tvalid_0's tweedie: 275.917\n",
      "[192]\tvalid_0's tweedie: 275.917\n",
      "[193]\tvalid_0's tweedie: 275.917\n",
      "[194]\tvalid_0's tweedie: 275.918\n",
      "[195]\tvalid_0's tweedie: 275.92\n",
      "[196]\tvalid_0's tweedie: 275.92\n",
      "[197]\tvalid_0's tweedie: 275.92\n",
      "[198]\tvalid_0's tweedie: 275.92\n",
      "[199]\tvalid_0's tweedie: 275.92\n",
      "[200]\tvalid_0's tweedie: 275.92\n",
      "[201]\tvalid_0's tweedie: 275.92\n",
      "[202]\tvalid_0's tweedie: 275.92\n",
      "[203]\tvalid_0's tweedie: 275.92\n",
      "[204]\tvalid_0's tweedie: 275.92\n",
      "[205]\tvalid_0's tweedie: 275.92\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's tweedie: 275.915\n",
      "Training model for level 5 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 12999, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498277\n",
      "[1]\tvalid_0's tweedie: 306.598\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.614\n",
      "[3]\tvalid_0's tweedie: 297.332\n",
      "[4]\tvalid_0's tweedie: 293.739\n",
      "[5]\tvalid_0's tweedie: 290.721\n",
      "[6]\tvalid_0's tweedie: 288.178\n",
      "[7]\tvalid_0's tweedie: 286.038\n",
      "[8]\tvalid_0's tweedie: 284.297\n",
      "[9]\tvalid_0's tweedie: 282.861\n",
      "[10]\tvalid_0's tweedie: 281.65\n",
      "[11]\tvalid_0's tweedie: 280.628\n",
      "[12]\tvalid_0's tweedie: 279.793\n",
      "[13]\tvalid_0's tweedie: 279.161\n",
      "[14]\tvalid_0's tweedie: 278.603\n",
      "[15]\tvalid_0's tweedie: 278.145\n",
      "[16]\tvalid_0's tweedie: 277.76\n",
      "[17]\tvalid_0's tweedie: 277.449\n",
      "[18]\tvalid_0's tweedie: 277.204\n",
      "[19]\tvalid_0's tweedie: 277.009\n",
      "[20]\tvalid_0's tweedie: 276.832\n",
      "[21]\tvalid_0's tweedie: 276.697\n",
      "[22]\tvalid_0's tweedie: 276.583\n",
      "[23]\tvalid_0's tweedie: 276.483\n",
      "[24]\tvalid_0's tweedie: 276.407\n",
      "[25]\tvalid_0's tweedie: 276.348\n",
      "[26]\tvalid_0's tweedie: 276.284\n",
      "[27]\tvalid_0's tweedie: 276.235\n",
      "[28]\tvalid_0's tweedie: 276.198\n",
      "[29]\tvalid_0's tweedie: 276.171\n",
      "[30]\tvalid_0's tweedie: 276.139\n",
      "[31]\tvalid_0's tweedie: 276.116\n",
      "[32]\tvalid_0's tweedie: 276.093\n",
      "[33]\tvalid_0's tweedie: 276.079\n",
      "[34]\tvalid_0's tweedie: 276.065\n",
      "[35]\tvalid_0's tweedie: 276.051\n",
      "[36]\tvalid_0's tweedie: 276.038\n",
      "[37]\tvalid_0's tweedie: 276.027\n",
      "[38]\tvalid_0's tweedie: 276.019\n",
      "[39]\tvalid_0's tweedie: 276.015\n",
      "[40]\tvalid_0's tweedie: 276.006\n",
      "[41]\tvalid_0's tweedie: 275.998\n",
      "[42]\tvalid_0's tweedie: 275.988\n",
      "[43]\tvalid_0's tweedie: 275.985\n",
      "[44]\tvalid_0's tweedie: 275.982\n",
      "[45]\tvalid_0's tweedie: 275.978\n",
      "[46]\tvalid_0's tweedie: 275.973\n",
      "[47]\tvalid_0's tweedie: 275.97\n",
      "[48]\tvalid_0's tweedie: 275.969\n",
      "[49]\tvalid_0's tweedie: 275.966\n",
      "[50]\tvalid_0's tweedie: 275.962\n",
      "[51]\tvalid_0's tweedie: 275.958\n",
      "[52]\tvalid_0's tweedie: 275.954\n",
      "[53]\tvalid_0's tweedie: 275.951\n",
      "[54]\tvalid_0's tweedie: 275.949\n",
      "[55]\tvalid_0's tweedie: 275.945\n",
      "[56]\tvalid_0's tweedie: 275.942\n",
      "[57]\tvalid_0's tweedie: 275.941\n",
      "[58]\tvalid_0's tweedie: 275.939\n",
      "[59]\tvalid_0's tweedie: 275.94\n",
      "[60]\tvalid_0's tweedie: 275.939\n",
      "[61]\tvalid_0's tweedie: 275.936\n",
      "[62]\tvalid_0's tweedie: 275.933\n",
      "[63]\tvalid_0's tweedie: 275.931\n",
      "[64]\tvalid_0's tweedie: 275.93\n",
      "[65]\tvalid_0's tweedie: 275.929\n",
      "[66]\tvalid_0's tweedie: 275.927\n",
      "[67]\tvalid_0's tweedie: 275.927\n",
      "[68]\tvalid_0's tweedie: 275.927\n",
      "[69]\tvalid_0's tweedie: 275.926\n",
      "[70]\tvalid_0's tweedie: 275.925\n",
      "[71]\tvalid_0's tweedie: 275.925\n",
      "[72]\tvalid_0's tweedie: 275.924\n",
      "[73]\tvalid_0's tweedie: 275.924\n",
      "[74]\tvalid_0's tweedie: 275.924\n",
      "[75]\tvalid_0's tweedie: 275.923\n",
      "[76]\tvalid_0's tweedie: 275.923\n",
      "[77]\tvalid_0's tweedie: 275.923\n",
      "[78]\tvalid_0's tweedie: 275.923\n",
      "[79]\tvalid_0's tweedie: 275.923\n",
      "[80]\tvalid_0's tweedie: 275.923\n",
      "[81]\tvalid_0's tweedie: 275.922\n",
      "[82]\tvalid_0's tweedie: 275.92\n",
      "[83]\tvalid_0's tweedie: 275.92\n",
      "[84]\tvalid_0's tweedie: 275.92\n",
      "[85]\tvalid_0's tweedie: 275.919\n",
      "[86]\tvalid_0's tweedie: 275.918\n",
      "[87]\tvalid_0's tweedie: 275.917\n",
      "[88]\tvalid_0's tweedie: 275.916\n",
      "[89]\tvalid_0's tweedie: 275.916\n",
      "[90]\tvalid_0's tweedie: 275.915\n",
      "[91]\tvalid_0's tweedie: 275.915\n",
      "[92]\tvalid_0's tweedie: 275.915\n",
      "[93]\tvalid_0's tweedie: 275.916\n",
      "[94]\tvalid_0's tweedie: 275.915\n",
      "[95]\tvalid_0's tweedie: 275.915\n",
      "[96]\tvalid_0's tweedie: 275.914\n",
      "[97]\tvalid_0's tweedie: 275.913\n",
      "[98]\tvalid_0's tweedie: 275.912\n",
      "[99]\tvalid_0's tweedie: 275.911\n",
      "[100]\tvalid_0's tweedie: 275.91\n",
      "[101]\tvalid_0's tweedie: 275.909\n",
      "[102]\tvalid_0's tweedie: 275.909\n",
      "[103]\tvalid_0's tweedie: 275.908\n",
      "[104]\tvalid_0's tweedie: 275.907\n",
      "[105]\tvalid_0's tweedie: 275.904\n",
      "[106]\tvalid_0's tweedie: 275.906\n",
      "[107]\tvalid_0's tweedie: 275.906\n",
      "[108]\tvalid_0's tweedie: 275.905\n",
      "[109]\tvalid_0's tweedie: 275.905\n",
      "[110]\tvalid_0's tweedie: 275.904\n",
      "[111]\tvalid_0's tweedie: 275.903\n",
      "[112]\tvalid_0's tweedie: 275.902\n",
      "[113]\tvalid_0's tweedie: 275.902\n",
      "[114]\tvalid_0's tweedie: 275.902\n",
      "[115]\tvalid_0's tweedie: 275.902\n",
      "[116]\tvalid_0's tweedie: 275.902\n",
      "[117]\tvalid_0's tweedie: 275.902\n",
      "[118]\tvalid_0's tweedie: 275.902\n",
      "[119]\tvalid_0's tweedie: 275.902\n",
      "[120]\tvalid_0's tweedie: 275.902\n",
      "[121]\tvalid_0's tweedie: 275.901\n",
      "[122]\tvalid_0's tweedie: 275.901\n",
      "[123]\tvalid_0's tweedie: 275.901\n",
      "[124]\tvalid_0's tweedie: 275.901\n",
      "[125]\tvalid_0's tweedie: 275.901\n",
      "[126]\tvalid_0's tweedie: 275.901\n",
      "[127]\tvalid_0's tweedie: 275.899\n",
      "[128]\tvalid_0's tweedie: 275.899\n",
      "[129]\tvalid_0's tweedie: 275.899\n",
      "[130]\tvalid_0's tweedie: 275.899\n",
      "[131]\tvalid_0's tweedie: 275.899\n",
      "[132]\tvalid_0's tweedie: 275.898\n",
      "[133]\tvalid_0's tweedie: 275.898\n",
      "[134]\tvalid_0's tweedie: 275.898\n",
      "[135]\tvalid_0's tweedie: 275.898\n",
      "[136]\tvalid_0's tweedie: 275.898\n",
      "[137]\tvalid_0's tweedie: 275.897\n",
      "[138]\tvalid_0's tweedie: 275.897\n",
      "[139]\tvalid_0's tweedie: 275.897\n",
      "[140]\tvalid_0's tweedie: 275.897\n",
      "[141]\tvalid_0's tweedie: 275.898\n",
      "[142]\tvalid_0's tweedie: 275.898\n",
      "[143]\tvalid_0's tweedie: 275.898\n",
      "[144]\tvalid_0's tweedie: 275.898\n",
      "[145]\tvalid_0's tweedie: 275.898\n",
      "[146]\tvalid_0's tweedie: 275.897\n",
      "[147]\tvalid_0's tweedie: 275.897\n",
      "[148]\tvalid_0's tweedie: 275.897\n",
      "[149]\tvalid_0's tweedie: 275.897\n",
      "[150]\tvalid_0's tweedie: 275.897\n",
      "[151]\tvalid_0's tweedie: 275.896\n",
      "[152]\tvalid_0's tweedie: 275.895\n",
      "[153]\tvalid_0's tweedie: 275.895\n",
      "[154]\tvalid_0's tweedie: 275.895\n",
      "[155]\tvalid_0's tweedie: 275.894\n",
      "[156]\tvalid_0's tweedie: 275.894\n",
      "[157]\tvalid_0's tweedie: 275.894\n",
      "[158]\tvalid_0's tweedie: 275.893\n",
      "[159]\tvalid_0's tweedie: 275.894\n",
      "[160]\tvalid_0's tweedie: 275.894\n",
      "[161]\tvalid_0's tweedie: 275.894\n",
      "[162]\tvalid_0's tweedie: 275.894\n",
      "[163]\tvalid_0's tweedie: 275.894\n",
      "[164]\tvalid_0's tweedie: 275.894\n",
      "[165]\tvalid_0's tweedie: 275.893\n",
      "[166]\tvalid_0's tweedie: 275.893\n",
      "[167]\tvalid_0's tweedie: 275.893\n",
      "[168]\tvalid_0's tweedie: 275.893\n",
      "[169]\tvalid_0's tweedie: 275.893\n",
      "[170]\tvalid_0's tweedie: 275.893\n",
      "[171]\tvalid_0's tweedie: 275.892\n",
      "[172]\tvalid_0's tweedie: 275.893\n",
      "[173]\tvalid_0's tweedie: 275.894\n",
      "[174]\tvalid_0's tweedie: 275.894\n",
      "[175]\tvalid_0's tweedie: 275.894\n",
      "[176]\tvalid_0's tweedie: 275.892\n",
      "[177]\tvalid_0's tweedie: 275.892\n",
      "[178]\tvalid_0's tweedie: 275.891\n",
      "[179]\tvalid_0's tweedie: 275.891\n",
      "[180]\tvalid_0's tweedie: 275.89\n",
      "[181]\tvalid_0's tweedie: 275.89\n",
      "[182]\tvalid_0's tweedie: 275.89\n",
      "[183]\tvalid_0's tweedie: 275.89\n",
      "[184]\tvalid_0's tweedie: 275.89\n",
      "[185]\tvalid_0's tweedie: 275.888\n",
      "[186]\tvalid_0's tweedie: 275.888\n",
      "[187]\tvalid_0's tweedie: 275.889\n",
      "[188]\tvalid_0's tweedie: 275.888\n",
      "[189]\tvalid_0's tweedie: 275.888\n",
      "[190]\tvalid_0's tweedie: 275.888\n",
      "[191]\tvalid_0's tweedie: 275.888\n",
      "[192]\tvalid_0's tweedie: 275.888\n",
      "[193]\tvalid_0's tweedie: 275.888\n",
      "[194]\tvalid_0's tweedie: 275.887\n",
      "[195]\tvalid_0's tweedie: 275.887\n",
      "[196]\tvalid_0's tweedie: 275.887\n",
      "[197]\tvalid_0's tweedie: 275.888\n",
      "[198]\tvalid_0's tweedie: 275.887\n",
      "[199]\tvalid_0's tweedie: 275.887\n",
      "[200]\tvalid_0's tweedie: 275.887\n",
      "[201]\tvalid_0's tweedie: 275.887\n",
      "[202]\tvalid_0's tweedie: 275.887\n",
      "[203]\tvalid_0's tweedie: 275.888\n",
      "[204]\tvalid_0's tweedie: 275.885\n",
      "[205]\tvalid_0's tweedie: 275.885\n",
      "[206]\tvalid_0's tweedie: 275.885\n",
      "[207]\tvalid_0's tweedie: 275.885\n",
      "[208]\tvalid_0's tweedie: 275.885\n",
      "[209]\tvalid_0's tweedie: 275.885\n",
      "[210]\tvalid_0's tweedie: 275.886\n",
      "[211]\tvalid_0's tweedie: 275.886\n",
      "[212]\tvalid_0's tweedie: 275.886\n",
      "[213]\tvalid_0's tweedie: 275.886\n",
      "[214]\tvalid_0's tweedie: 275.886\n",
      "[215]\tvalid_0's tweedie: 275.886\n",
      "[216]\tvalid_0's tweedie: 275.886\n",
      "[217]\tvalid_0's tweedie: 275.886\n",
      "[218]\tvalid_0's tweedie: 275.886\n",
      "[219]\tvalid_0's tweedie: 275.886\n",
      "[220]\tvalid_0's tweedie: 275.886\n",
      "[221]\tvalid_0's tweedie: 275.886\n",
      "[222]\tvalid_0's tweedie: 275.886\n",
      "[223]\tvalid_0's tweedie: 275.886\n",
      "[224]\tvalid_0's tweedie: 275.886\n",
      "[225]\tvalid_0's tweedie: 275.885\n",
      "[226]\tvalid_0's tweedie: 275.885\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's tweedie: 275.885\n",
      "Training model for level 5 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 12992, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498347\n",
      "[1]\tvalid_0's tweedie: 306.632\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.607\n",
      "[3]\tvalid_0's tweedie: 297.32\n",
      "[4]\tvalid_0's tweedie: 293.717\n",
      "[5]\tvalid_0's tweedie: 290.682\n",
      "[6]\tvalid_0's tweedie: 288.134\n",
      "[7]\tvalid_0's tweedie: 286.003\n",
      "[8]\tvalid_0's tweedie: 284.262\n",
      "[9]\tvalid_0's tweedie: 282.813\n",
      "[10]\tvalid_0's tweedie: 281.616\n",
      "[11]\tvalid_0's tweedie: 280.622\n",
      "[12]\tvalid_0's tweedie: 279.788\n",
      "[13]\tvalid_0's tweedie: 279.117\n",
      "[14]\tvalid_0's tweedie: 278.558\n",
      "[15]\tvalid_0's tweedie: 278.1\n",
      "[16]\tvalid_0's tweedie: 277.747\n",
      "[17]\tvalid_0's tweedie: 277.443\n",
      "[18]\tvalid_0's tweedie: 277.217\n",
      "[19]\tvalid_0's tweedie: 277.007\n",
      "[20]\tvalid_0's tweedie: 276.832\n",
      "[21]\tvalid_0's tweedie: 276.694\n",
      "[22]\tvalid_0's tweedie: 276.573\n",
      "[23]\tvalid_0's tweedie: 276.482\n",
      "[24]\tvalid_0's tweedie: 276.399\n",
      "[25]\tvalid_0's tweedie: 276.334\n",
      "[26]\tvalid_0's tweedie: 276.279\n",
      "[27]\tvalid_0's tweedie: 276.234\n",
      "[28]\tvalid_0's tweedie: 276.194\n",
      "[29]\tvalid_0's tweedie: 276.156\n",
      "[30]\tvalid_0's tweedie: 276.128\n",
      "[31]\tvalid_0's tweedie: 276.109\n",
      "[32]\tvalid_0's tweedie: 276.089\n",
      "[33]\tvalid_0's tweedie: 276.073\n",
      "[34]\tvalid_0's tweedie: 276.061\n",
      "[35]\tvalid_0's tweedie: 276.046\n",
      "[36]\tvalid_0's tweedie: 276.04\n",
      "[37]\tvalid_0's tweedie: 276.03\n",
      "[38]\tvalid_0's tweedie: 276.021\n",
      "[39]\tvalid_0's tweedie: 276.01\n",
      "[40]\tvalid_0's tweedie: 276.003\n",
      "[41]\tvalid_0's tweedie: 275.995\n",
      "[42]\tvalid_0's tweedie: 275.99\n",
      "[43]\tvalid_0's tweedie: 275.983\n",
      "[44]\tvalid_0's tweedie: 275.978\n",
      "[45]\tvalid_0's tweedie: 275.975\n",
      "[46]\tvalid_0's tweedie: 275.968\n",
      "[47]\tvalid_0's tweedie: 275.96\n",
      "[48]\tvalid_0's tweedie: 275.958\n",
      "[49]\tvalid_0's tweedie: 275.949\n",
      "[50]\tvalid_0's tweedie: 275.945\n",
      "[51]\tvalid_0's tweedie: 275.943\n",
      "[52]\tvalid_0's tweedie: 275.941\n",
      "[53]\tvalid_0's tweedie: 275.935\n",
      "[54]\tvalid_0's tweedie: 275.933\n",
      "[55]\tvalid_0's tweedie: 275.931\n",
      "[56]\tvalid_0's tweedie: 275.929\n",
      "[57]\tvalid_0's tweedie: 275.925\n",
      "[58]\tvalid_0's tweedie: 275.923\n",
      "[59]\tvalid_0's tweedie: 275.92\n",
      "[60]\tvalid_0's tweedie: 275.92\n",
      "[61]\tvalid_0's tweedie: 275.917\n",
      "[62]\tvalid_0's tweedie: 275.915\n",
      "[63]\tvalid_0's tweedie: 275.916\n",
      "[64]\tvalid_0's tweedie: 275.914\n",
      "[65]\tvalid_0's tweedie: 275.912\n",
      "[66]\tvalid_0's tweedie: 275.911\n",
      "[67]\tvalid_0's tweedie: 275.91\n",
      "[68]\tvalid_0's tweedie: 275.908\n",
      "[69]\tvalid_0's tweedie: 275.91\n",
      "[70]\tvalid_0's tweedie: 275.908\n",
      "[71]\tvalid_0's tweedie: 275.908\n",
      "[72]\tvalid_0's tweedie: 275.906\n",
      "[73]\tvalid_0's tweedie: 275.906\n",
      "[74]\tvalid_0's tweedie: 275.905\n",
      "[75]\tvalid_0's tweedie: 275.904\n",
      "[76]\tvalid_0's tweedie: 275.904\n",
      "[77]\tvalid_0's tweedie: 275.905\n",
      "[78]\tvalid_0's tweedie: 275.903\n",
      "[79]\tvalid_0's tweedie: 275.903\n",
      "[80]\tvalid_0's tweedie: 275.902\n",
      "[81]\tvalid_0's tweedie: 275.901\n",
      "[82]\tvalid_0's tweedie: 275.901\n",
      "[83]\tvalid_0's tweedie: 275.9\n",
      "[84]\tvalid_0's tweedie: 275.898\n",
      "[85]\tvalid_0's tweedie: 275.899\n",
      "[86]\tvalid_0's tweedie: 275.899\n",
      "[87]\tvalid_0's tweedie: 275.899\n",
      "[88]\tvalid_0's tweedie: 275.898\n",
      "[89]\tvalid_0's tweedie: 275.898\n",
      "[90]\tvalid_0's tweedie: 275.897\n",
      "[91]\tvalid_0's tweedie: 275.896\n",
      "[92]\tvalid_0's tweedie: 275.895\n",
      "[93]\tvalid_0's tweedie: 275.893\n",
      "[94]\tvalid_0's tweedie: 275.893\n",
      "[95]\tvalid_0's tweedie: 275.892\n",
      "[96]\tvalid_0's tweedie: 275.89\n",
      "[97]\tvalid_0's tweedie: 275.888\n",
      "[98]\tvalid_0's tweedie: 275.887\n",
      "[99]\tvalid_0's tweedie: 275.886\n",
      "[100]\tvalid_0's tweedie: 275.889\n",
      "[101]\tvalid_0's tweedie: 275.889\n",
      "[102]\tvalid_0's tweedie: 275.888\n",
      "[103]\tvalid_0's tweedie: 275.888\n",
      "[104]\tvalid_0's tweedie: 275.888\n",
      "[105]\tvalid_0's tweedie: 275.888\n",
      "[106]\tvalid_0's tweedie: 275.888\n",
      "[107]\tvalid_0's tweedie: 275.887\n",
      "[108]\tvalid_0's tweedie: 275.887\n",
      "[109]\tvalid_0's tweedie: 275.887\n",
      "[110]\tvalid_0's tweedie: 275.887\n",
      "[111]\tvalid_0's tweedie: 275.886\n",
      "[112]\tvalid_0's tweedie: 275.887\n",
      "[113]\tvalid_0's tweedie: 275.885\n",
      "[114]\tvalid_0's tweedie: 275.885\n",
      "[115]\tvalid_0's tweedie: 275.885\n",
      "[116]\tvalid_0's tweedie: 275.885\n",
      "[117]\tvalid_0's tweedie: 275.885\n",
      "[118]\tvalid_0's tweedie: 275.884\n",
      "[119]\tvalid_0's tweedie: 275.883\n",
      "[120]\tvalid_0's tweedie: 275.883\n",
      "[121]\tvalid_0's tweedie: 275.881\n",
      "[122]\tvalid_0's tweedie: 275.882\n",
      "[123]\tvalid_0's tweedie: 275.881\n",
      "[124]\tvalid_0's tweedie: 275.88\n",
      "[125]\tvalid_0's tweedie: 275.881\n",
      "[126]\tvalid_0's tweedie: 275.88\n",
      "[127]\tvalid_0's tweedie: 275.879\n",
      "[128]\tvalid_0's tweedie: 275.879\n",
      "[129]\tvalid_0's tweedie: 275.879\n",
      "[130]\tvalid_0's tweedie: 275.879\n",
      "[131]\tvalid_0's tweedie: 275.879\n",
      "[132]\tvalid_0's tweedie: 275.879\n",
      "[133]\tvalid_0's tweedie: 275.879\n",
      "[134]\tvalid_0's tweedie: 275.878\n",
      "[135]\tvalid_0's tweedie: 275.877\n",
      "[136]\tvalid_0's tweedie: 275.877\n",
      "[137]\tvalid_0's tweedie: 275.877\n",
      "[138]\tvalid_0's tweedie: 275.876\n",
      "[139]\tvalid_0's tweedie: 275.877\n",
      "[140]\tvalid_0's tweedie: 275.877\n",
      "[141]\tvalid_0's tweedie: 275.876\n",
      "[142]\tvalid_0's tweedie: 275.876\n",
      "[143]\tvalid_0's tweedie: 275.876\n",
      "[144]\tvalid_0's tweedie: 275.876\n",
      "[145]\tvalid_0's tweedie: 275.876\n",
      "[146]\tvalid_0's tweedie: 275.876\n",
      "[147]\tvalid_0's tweedie: 275.876\n",
      "[148]\tvalid_0's tweedie: 275.876\n",
      "[149]\tvalid_0's tweedie: 275.879\n",
      "[150]\tvalid_0's tweedie: 275.878\n",
      "[151]\tvalid_0's tweedie: 275.882\n",
      "[152]\tvalid_0's tweedie: 275.882\n",
      "[153]\tvalid_0's tweedie: 275.882\n",
      "[154]\tvalid_0's tweedie: 275.882\n",
      "[155]\tvalid_0's tweedie: 275.882\n",
      "[156]\tvalid_0's tweedie: 275.882\n",
      "[157]\tvalid_0's tweedie: 275.882\n",
      "[158]\tvalid_0's tweedie: 275.882\n",
      "[159]\tvalid_0's tweedie: 275.882\n",
      "[160]\tvalid_0's tweedie: 275.882\n",
      "[161]\tvalid_0's tweedie: 275.882\n",
      "[162]\tvalid_0's tweedie: 275.881\n",
      "[163]\tvalid_0's tweedie: 275.881\n",
      "[164]\tvalid_0's tweedie: 275.881\n",
      "[165]\tvalid_0's tweedie: 275.881\n",
      "[166]\tvalid_0's tweedie: 275.881\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's tweedie: 275.876\n",
      "Training model for level 5 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 12985, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498435\n",
      "[1]\tvalid_0's tweedie: 306.608\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.586\n",
      "[3]\tvalid_0's tweedie: 297.329\n",
      "[4]\tvalid_0's tweedie: 293.7\n",
      "[5]\tvalid_0's tweedie: 290.684\n",
      "[6]\tvalid_0's tweedie: 288.138\n",
      "[7]\tvalid_0's tweedie: 286.007\n",
      "[8]\tvalid_0's tweedie: 284.24\n",
      "[9]\tvalid_0's tweedie: 282.787\n",
      "[10]\tvalid_0's tweedie: 281.575\n",
      "[11]\tvalid_0's tweedie: 280.584\n",
      "[12]\tvalid_0's tweedie: 279.759\n",
      "[13]\tvalid_0's tweedie: 279.095\n",
      "[14]\tvalid_0's tweedie: 278.544\n",
      "[15]\tvalid_0's tweedie: 278.112\n",
      "[16]\tvalid_0's tweedie: 277.741\n",
      "[17]\tvalid_0's tweedie: 277.439\n",
      "[18]\tvalid_0's tweedie: 277.185\n",
      "[19]\tvalid_0's tweedie: 276.981\n",
      "[20]\tvalid_0's tweedie: 276.821\n",
      "[21]\tvalid_0's tweedie: 276.694\n",
      "[22]\tvalid_0's tweedie: 276.571\n",
      "[23]\tvalid_0's tweedie: 276.477\n",
      "[24]\tvalid_0's tweedie: 276.396\n",
      "[25]\tvalid_0's tweedie: 276.327\n",
      "[26]\tvalid_0's tweedie: 276.264\n",
      "[27]\tvalid_0's tweedie: 276.22\n",
      "[28]\tvalid_0's tweedie: 276.181\n",
      "[29]\tvalid_0's tweedie: 276.15\n",
      "[30]\tvalid_0's tweedie: 276.127\n",
      "[31]\tvalid_0's tweedie: 276.105\n",
      "[32]\tvalid_0's tweedie: 276.082\n",
      "[33]\tvalid_0's tweedie: 276.068\n",
      "[34]\tvalid_0's tweedie: 276.053\n",
      "[35]\tvalid_0's tweedie: 276.04\n",
      "[36]\tvalid_0's tweedie: 276.029\n",
      "[37]\tvalid_0's tweedie: 276.017\n",
      "[38]\tvalid_0's tweedie: 276.008\n",
      "[39]\tvalid_0's tweedie: 276\n",
      "[40]\tvalid_0's tweedie: 275.995\n",
      "[41]\tvalid_0's tweedie: 275.983\n",
      "[42]\tvalid_0's tweedie: 275.974\n",
      "[43]\tvalid_0's tweedie: 275.969\n",
      "[44]\tvalid_0's tweedie: 275.965\n",
      "[45]\tvalid_0's tweedie: 275.959\n",
      "[46]\tvalid_0's tweedie: 275.952\n",
      "[47]\tvalid_0's tweedie: 275.948\n",
      "[48]\tvalid_0's tweedie: 275.946\n",
      "[49]\tvalid_0's tweedie: 275.939\n",
      "[50]\tvalid_0's tweedie: 275.935\n",
      "[51]\tvalid_0's tweedie: 275.93\n",
      "[52]\tvalid_0's tweedie: 275.929\n",
      "[53]\tvalid_0's tweedie: 275.926\n",
      "[54]\tvalid_0's tweedie: 275.923\n",
      "[55]\tvalid_0's tweedie: 275.922\n",
      "[56]\tvalid_0's tweedie: 275.92\n",
      "[57]\tvalid_0's tweedie: 275.919\n",
      "[58]\tvalid_0's tweedie: 275.917\n",
      "[59]\tvalid_0's tweedie: 275.913\n",
      "[60]\tvalid_0's tweedie: 275.912\n",
      "[61]\tvalid_0's tweedie: 275.911\n",
      "[62]\tvalid_0's tweedie: 275.912\n",
      "[63]\tvalid_0's tweedie: 275.91\n",
      "[64]\tvalid_0's tweedie: 275.91\n",
      "[65]\tvalid_0's tweedie: 275.909\n",
      "[66]\tvalid_0's tweedie: 275.909\n",
      "[67]\tvalid_0's tweedie: 275.907\n",
      "[68]\tvalid_0's tweedie: 275.905\n",
      "[69]\tvalid_0's tweedie: 275.903\n",
      "[70]\tvalid_0's tweedie: 275.903\n",
      "[71]\tvalid_0's tweedie: 275.902\n",
      "[72]\tvalid_0's tweedie: 275.901\n",
      "[73]\tvalid_0's tweedie: 275.901\n",
      "[74]\tvalid_0's tweedie: 275.9\n",
      "[75]\tvalid_0's tweedie: 275.902\n",
      "[76]\tvalid_0's tweedie: 275.901\n",
      "[77]\tvalid_0's tweedie: 275.904\n",
      "[78]\tvalid_0's tweedie: 275.904\n",
      "[79]\tvalid_0's tweedie: 275.906\n",
      "[80]\tvalid_0's tweedie: 275.904\n",
      "[81]\tvalid_0's tweedie: 275.903\n",
      "[82]\tvalid_0's tweedie: 275.903\n",
      "[83]\tvalid_0's tweedie: 275.902\n",
      "[84]\tvalid_0's tweedie: 275.902\n",
      "[85]\tvalid_0's tweedie: 275.901\n",
      "[86]\tvalid_0's tweedie: 275.901\n",
      "[87]\tvalid_0's tweedie: 275.901\n",
      "[88]\tvalid_0's tweedie: 275.9\n",
      "[89]\tvalid_0's tweedie: 275.9\n",
      "[90]\tvalid_0's tweedie: 275.899\n",
      "[91]\tvalid_0's tweedie: 275.901\n",
      "[92]\tvalid_0's tweedie: 275.901\n",
      "[93]\tvalid_0's tweedie: 275.9\n",
      "[94]\tvalid_0's tweedie: 275.899\n",
      "[95]\tvalid_0's tweedie: 275.897\n",
      "[96]\tvalid_0's tweedie: 275.897\n",
      "[97]\tvalid_0's tweedie: 275.896\n",
      "[98]\tvalid_0's tweedie: 275.895\n",
      "[99]\tvalid_0's tweedie: 275.895\n",
      "[100]\tvalid_0's tweedie: 275.894\n",
      "[101]\tvalid_0's tweedie: 275.893\n",
      "[102]\tvalid_0's tweedie: 275.893\n",
      "[103]\tvalid_0's tweedie: 275.892\n",
      "[104]\tvalid_0's tweedie: 275.893\n",
      "[105]\tvalid_0's tweedie: 275.893\n",
      "[106]\tvalid_0's tweedie: 275.892\n",
      "[107]\tvalid_0's tweedie: 275.892\n",
      "[108]\tvalid_0's tweedie: 275.892\n",
      "[109]\tvalid_0's tweedie: 275.892\n",
      "[110]\tvalid_0's tweedie: 275.891\n",
      "[111]\tvalid_0's tweedie: 275.891\n",
      "[112]\tvalid_0's tweedie: 275.891\n",
      "[113]\tvalid_0's tweedie: 275.888\n",
      "[114]\tvalid_0's tweedie: 275.887\n",
      "[115]\tvalid_0's tweedie: 275.888\n",
      "[116]\tvalid_0's tweedie: 275.887\n",
      "[117]\tvalid_0's tweedie: 275.887\n",
      "[118]\tvalid_0's tweedie: 275.886\n",
      "[119]\tvalid_0's tweedie: 275.886\n",
      "[120]\tvalid_0's tweedie: 275.886\n",
      "[121]\tvalid_0's tweedie: 275.886\n",
      "[122]\tvalid_0's tweedie: 275.886\n",
      "[123]\tvalid_0's tweedie: 275.884\n",
      "[124]\tvalid_0's tweedie: 275.884\n",
      "[125]\tvalid_0's tweedie: 275.884\n",
      "[126]\tvalid_0's tweedie: 275.883\n",
      "[127]\tvalid_0's tweedie: 275.883\n",
      "[128]\tvalid_0's tweedie: 275.885\n",
      "[129]\tvalid_0's tweedie: 275.885\n",
      "[130]\tvalid_0's tweedie: 275.885\n",
      "[131]\tvalid_0's tweedie: 275.885\n",
      "[132]\tvalid_0's tweedie: 275.884\n",
      "[133]\tvalid_0's tweedie: 275.884\n",
      "[134]\tvalid_0's tweedie: 275.884\n",
      "[135]\tvalid_0's tweedie: 275.884\n",
      "[136]\tvalid_0's tweedie: 275.884\n",
      "[137]\tvalid_0's tweedie: 275.884\n",
      "[138]\tvalid_0's tweedie: 275.883\n",
      "[139]\tvalid_0's tweedie: 275.883\n",
      "[140]\tvalid_0's tweedie: 275.883\n",
      "[141]\tvalid_0's tweedie: 275.883\n",
      "[142]\tvalid_0's tweedie: 275.883\n",
      "[143]\tvalid_0's tweedie: 275.885\n",
      "[144]\tvalid_0's tweedie: 275.886\n",
      "[145]\tvalid_0's tweedie: 275.886\n",
      "[146]\tvalid_0's tweedie: 275.886\n",
      "[147]\tvalid_0's tweedie: 275.886\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's tweedie: 275.883\n",
      "Training model for level 5 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 12978, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498641\n",
      "[1]\tvalid_0's tweedie: 306.589\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.557\n",
      "[3]\tvalid_0's tweedie: 297.285\n",
      "[4]\tvalid_0's tweedie: 293.685\n",
      "[5]\tvalid_0's tweedie: 290.662\n",
      "[6]\tvalid_0's tweedie: 288.105\n",
      "[7]\tvalid_0's tweedie: 285.967\n",
      "[8]\tvalid_0's tweedie: 284.186\n",
      "[9]\tvalid_0's tweedie: 282.759\n",
      "[10]\tvalid_0's tweedie: 281.559\n",
      "[11]\tvalid_0's tweedie: 280.567\n",
      "[12]\tvalid_0's tweedie: 279.745\n",
      "[13]\tvalid_0's tweedie: 279.074\n",
      "[14]\tvalid_0's tweedie: 278.528\n",
      "[15]\tvalid_0's tweedie: 278.07\n",
      "[16]\tvalid_0's tweedie: 277.7\n",
      "[17]\tvalid_0's tweedie: 277.399\n",
      "[18]\tvalid_0's tweedie: 277.173\n",
      "[19]\tvalid_0's tweedie: 276.964\n",
      "[20]\tvalid_0's tweedie: 276.797\n",
      "[21]\tvalid_0's tweedie: 276.656\n",
      "[22]\tvalid_0's tweedie: 276.538\n",
      "[23]\tvalid_0's tweedie: 276.457\n",
      "[24]\tvalid_0's tweedie: 276.379\n",
      "[25]\tvalid_0's tweedie: 276.311\n",
      "[26]\tvalid_0's tweedie: 276.257\n",
      "[27]\tvalid_0's tweedie: 276.212\n",
      "[28]\tvalid_0's tweedie: 276.17\n",
      "[29]\tvalid_0's tweedie: 276.142\n",
      "[30]\tvalid_0's tweedie: 276.111\n",
      "[31]\tvalid_0's tweedie: 276.089\n",
      "[32]\tvalid_0's tweedie: 276.07\n",
      "[33]\tvalid_0's tweedie: 276.052\n",
      "[34]\tvalid_0's tweedie: 276.037\n",
      "[35]\tvalid_0's tweedie: 276.026\n",
      "[36]\tvalid_0's tweedie: 276.02\n",
      "[37]\tvalid_0's tweedie: 276.01\n",
      "[38]\tvalid_0's tweedie: 276.003\n",
      "[39]\tvalid_0's tweedie: 275.998\n",
      "[40]\tvalid_0's tweedie: 275.995\n",
      "[41]\tvalid_0's tweedie: 275.987\n",
      "[42]\tvalid_0's tweedie: 275.984\n",
      "[43]\tvalid_0's tweedie: 275.977\n",
      "[44]\tvalid_0's tweedie: 275.97\n",
      "[45]\tvalid_0's tweedie: 275.968\n",
      "[46]\tvalid_0's tweedie: 275.962\n",
      "[47]\tvalid_0's tweedie: 275.959\n",
      "[48]\tvalid_0's tweedie: 275.955\n",
      "[49]\tvalid_0's tweedie: 275.955\n",
      "[50]\tvalid_0's tweedie: 275.951\n",
      "[51]\tvalid_0's tweedie: 275.945\n",
      "[52]\tvalid_0's tweedie: 275.941\n",
      "[53]\tvalid_0's tweedie: 275.939\n",
      "[54]\tvalid_0's tweedie: 275.938\n",
      "[55]\tvalid_0's tweedie: 275.934\n",
      "[56]\tvalid_0's tweedie: 275.93\n",
      "[57]\tvalid_0's tweedie: 275.927\n",
      "[58]\tvalid_0's tweedie: 275.926\n",
      "[59]\tvalid_0's tweedie: 275.924\n",
      "[60]\tvalid_0's tweedie: 275.922\n",
      "[61]\tvalid_0's tweedie: 275.922\n",
      "[62]\tvalid_0's tweedie: 275.922\n",
      "[63]\tvalid_0's tweedie: 275.921\n",
      "[64]\tvalid_0's tweedie: 275.917\n",
      "[65]\tvalid_0's tweedie: 275.916\n",
      "[66]\tvalid_0's tweedie: 275.915\n",
      "[67]\tvalid_0's tweedie: 275.913\n",
      "[68]\tvalid_0's tweedie: 275.913\n",
      "[69]\tvalid_0's tweedie: 275.912\n",
      "[70]\tvalid_0's tweedie: 275.91\n",
      "[71]\tvalid_0's tweedie: 275.908\n",
      "[72]\tvalid_0's tweedie: 275.907\n",
      "[73]\tvalid_0's tweedie: 275.906\n",
      "[74]\tvalid_0's tweedie: 275.904\n",
      "[75]\tvalid_0's tweedie: 275.903\n",
      "[76]\tvalid_0's tweedie: 275.904\n",
      "[77]\tvalid_0's tweedie: 275.904\n",
      "[78]\tvalid_0's tweedie: 275.905\n",
      "[79]\tvalid_0's tweedie: 275.904\n",
      "[80]\tvalid_0's tweedie: 275.904\n",
      "[81]\tvalid_0's tweedie: 275.906\n",
      "[82]\tvalid_0's tweedie: 275.904\n",
      "[83]\tvalid_0's tweedie: 275.904\n",
      "[84]\tvalid_0's tweedie: 275.903\n",
      "[85]\tvalid_0's tweedie: 275.903\n",
      "[86]\tvalid_0's tweedie: 275.902\n",
      "[87]\tvalid_0's tweedie: 275.902\n",
      "[88]\tvalid_0's tweedie: 275.902\n",
      "[89]\tvalid_0's tweedie: 275.902\n",
      "[90]\tvalid_0's tweedie: 275.902\n",
      "[91]\tvalid_0's tweedie: 275.902\n",
      "[92]\tvalid_0's tweedie: 275.902\n",
      "[93]\tvalid_0's tweedie: 275.902\n",
      "[94]\tvalid_0's tweedie: 275.902\n",
      "[95]\tvalid_0's tweedie: 275.901\n",
      "[96]\tvalid_0's tweedie: 275.901\n",
      "[97]\tvalid_0's tweedie: 275.901\n",
      "[98]\tvalid_0's tweedie: 275.9\n",
      "[99]\tvalid_0's tweedie: 275.9\n",
      "[100]\tvalid_0's tweedie: 275.9\n",
      "[101]\tvalid_0's tweedie: 275.899\n",
      "[102]\tvalid_0's tweedie: 275.899\n",
      "[103]\tvalid_0's tweedie: 275.899\n",
      "[104]\tvalid_0's tweedie: 275.9\n",
      "[105]\tvalid_0's tweedie: 275.899\n",
      "[106]\tvalid_0's tweedie: 275.9\n",
      "[107]\tvalid_0's tweedie: 275.9\n",
      "[108]\tvalid_0's tweedie: 275.9\n",
      "[109]\tvalid_0's tweedie: 275.901\n",
      "[110]\tvalid_0's tweedie: 275.9\n",
      "[111]\tvalid_0's tweedie: 275.9\n",
      "[112]\tvalid_0's tweedie: 275.9\n",
      "[113]\tvalid_0's tweedie: 275.9\n",
      "[114]\tvalid_0's tweedie: 275.9\n",
      "[115]\tvalid_0's tweedie: 275.9\n",
      "[116]\tvalid_0's tweedie: 275.899\n",
      "[117]\tvalid_0's tweedie: 275.898\n",
      "[118]\tvalid_0's tweedie: 275.898\n",
      "[119]\tvalid_0's tweedie: 275.898\n",
      "[120]\tvalid_0's tweedie: 275.898\n",
      "[121]\tvalid_0's tweedie: 275.898\n",
      "[122]\tvalid_0's tweedie: 275.898\n",
      "[123]\tvalid_0's tweedie: 275.897\n",
      "[124]\tvalid_0's tweedie: 275.897\n",
      "[125]\tvalid_0's tweedie: 275.898\n",
      "[126]\tvalid_0's tweedie: 275.897\n",
      "[127]\tvalid_0's tweedie: 275.897\n",
      "[128]\tvalid_0's tweedie: 275.897\n",
      "[129]\tvalid_0's tweedie: 275.897\n",
      "[130]\tvalid_0's tweedie: 275.897\n",
      "[131]\tvalid_0's tweedie: 275.895\n",
      "[132]\tvalid_0's tweedie: 275.895\n",
      "[133]\tvalid_0's tweedie: 275.894\n",
      "[134]\tvalid_0's tweedie: 275.894\n",
      "[135]\tvalid_0's tweedie: 275.894\n",
      "[136]\tvalid_0's tweedie: 275.894\n",
      "[137]\tvalid_0's tweedie: 275.895\n",
      "[138]\tvalid_0's tweedie: 275.895\n",
      "[139]\tvalid_0's tweedie: 275.897\n",
      "[140]\tvalid_0's tweedie: 275.897\n",
      "[141]\tvalid_0's tweedie: 275.895\n",
      "[142]\tvalid_0's tweedie: 275.895\n",
      "[143]\tvalid_0's tweedie: 275.894\n",
      "[144]\tvalid_0's tweedie: 275.893\n",
      "[145]\tvalid_0's tweedie: 275.893\n",
      "[146]\tvalid_0's tweedie: 275.893\n",
      "[147]\tvalid_0's tweedie: 275.893\n",
      "[148]\tvalid_0's tweedie: 275.893\n",
      "[149]\tvalid_0's tweedie: 275.892\n",
      "[150]\tvalid_0's tweedie: 275.892\n",
      "[151]\tvalid_0's tweedie: 275.892\n",
      "[152]\tvalid_0's tweedie: 275.889\n",
      "[153]\tvalid_0's tweedie: 275.889\n",
      "[154]\tvalid_0's tweedie: 275.889\n",
      "[155]\tvalid_0's tweedie: 275.889\n",
      "[156]\tvalid_0's tweedie: 275.889\n",
      "[157]\tvalid_0's tweedie: 275.889\n",
      "[158]\tvalid_0's tweedie: 275.889\n",
      "[159]\tvalid_0's tweedie: 275.888\n",
      "[160]\tvalid_0's tweedie: 275.888\n",
      "[161]\tvalid_0's tweedie: 275.888\n",
      "[162]\tvalid_0's tweedie: 275.888\n",
      "[163]\tvalid_0's tweedie: 275.888\n",
      "[164]\tvalid_0's tweedie: 275.888\n",
      "[165]\tvalid_0's tweedie: 275.888\n",
      "[166]\tvalid_0's tweedie: 275.888\n",
      "[167]\tvalid_0's tweedie: 275.888\n",
      "[168]\tvalid_0's tweedie: 275.888\n",
      "[169]\tvalid_0's tweedie: 275.888\n",
      "[170]\tvalid_0's tweedie: 275.888\n",
      "[171]\tvalid_0's tweedie: 275.888\n",
      "[172]\tvalid_0's tweedie: 275.888\n",
      "[173]\tvalid_0's tweedie: 275.888\n",
      "[174]\tvalid_0's tweedie: 275.888\n",
      "[175]\tvalid_0's tweedie: 275.888\n",
      "[176]\tvalid_0's tweedie: 275.888\n",
      "[177]\tvalid_0's tweedie: 275.888\n",
      "[178]\tvalid_0's tweedie: 275.888\n",
      "[179]\tvalid_0's tweedie: 275.888\n",
      "[180]\tvalid_0's tweedie: 275.888\n",
      "[181]\tvalid_0's tweedie: 275.888\n",
      "[182]\tvalid_0's tweedie: 275.888\n",
      "[183]\tvalid_0's tweedie: 275.889\n",
      "[184]\tvalid_0's tweedie: 275.888\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's tweedie: 275.888\n",
      "Training model for level 5 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 12971, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.498821\n",
      "[1]\tvalid_0's tweedie: 306.586\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.553\n",
      "[3]\tvalid_0's tweedie: 297.274\n",
      "[4]\tvalid_0's tweedie: 293.674\n",
      "[5]\tvalid_0's tweedie: 290.678\n",
      "[6]\tvalid_0's tweedie: 288.125\n",
      "[7]\tvalid_0's tweedie: 285.969\n",
      "[8]\tvalid_0's tweedie: 284.202\n",
      "[9]\tvalid_0's tweedie: 282.72\n",
      "[10]\tvalid_0's tweedie: 281.522\n",
      "[11]\tvalid_0's tweedie: 280.53\n",
      "[12]\tvalid_0's tweedie: 279.713\n",
      "[13]\tvalid_0's tweedie: 279.041\n",
      "[14]\tvalid_0's tweedie: 278.504\n",
      "[15]\tvalid_0's tweedie: 278.064\n",
      "[16]\tvalid_0's tweedie: 277.69\n",
      "[17]\tvalid_0's tweedie: 277.395\n",
      "[18]\tvalid_0's tweedie: 277.144\n",
      "[19]\tvalid_0's tweedie: 276.939\n",
      "[20]\tvalid_0's tweedie: 276.771\n",
      "[21]\tvalid_0's tweedie: 276.647\n",
      "[22]\tvalid_0's tweedie: 276.529\n",
      "[23]\tvalid_0's tweedie: 276.443\n",
      "[24]\tvalid_0's tweedie: 276.369\n",
      "[25]\tvalid_0's tweedie: 276.297\n",
      "[26]\tvalid_0's tweedie: 276.25\n",
      "[27]\tvalid_0's tweedie: 276.208\n",
      "[28]\tvalid_0's tweedie: 276.164\n",
      "[29]\tvalid_0's tweedie: 276.136\n",
      "[30]\tvalid_0's tweedie: 276.108\n",
      "[31]\tvalid_0's tweedie: 276.085\n",
      "[32]\tvalid_0's tweedie: 276.067\n",
      "[33]\tvalid_0's tweedie: 276.051\n",
      "[34]\tvalid_0's tweedie: 276.041\n",
      "[35]\tvalid_0's tweedie: 276.027\n",
      "[36]\tvalid_0's tweedie: 276.017\n",
      "[37]\tvalid_0's tweedie: 276.011\n",
      "[38]\tvalid_0's tweedie: 276\n",
      "[39]\tvalid_0's tweedie: 275.994\n",
      "[40]\tvalid_0's tweedie: 275.99\n",
      "[41]\tvalid_0's tweedie: 275.986\n",
      "[42]\tvalid_0's tweedie: 275.976\n",
      "[43]\tvalid_0's tweedie: 275.972\n",
      "[44]\tvalid_0's tweedie: 275.963\n",
      "[45]\tvalid_0's tweedie: 275.959\n",
      "[46]\tvalid_0's tweedie: 275.953\n",
      "[47]\tvalid_0's tweedie: 275.951\n",
      "[48]\tvalid_0's tweedie: 275.946\n",
      "[49]\tvalid_0's tweedie: 275.944\n",
      "[50]\tvalid_0's tweedie: 275.943\n",
      "[51]\tvalid_0's tweedie: 275.938\n",
      "[52]\tvalid_0's tweedie: 275.936\n",
      "[53]\tvalid_0's tweedie: 275.934\n",
      "[54]\tvalid_0's tweedie: 275.932\n",
      "[55]\tvalid_0's tweedie: 275.93\n",
      "[56]\tvalid_0's tweedie: 275.928\n",
      "[57]\tvalid_0's tweedie: 275.923\n",
      "[58]\tvalid_0's tweedie: 275.921\n",
      "[59]\tvalid_0's tweedie: 275.919\n",
      "[60]\tvalid_0's tweedie: 275.917\n",
      "[61]\tvalid_0's tweedie: 275.915\n",
      "[62]\tvalid_0's tweedie: 275.915\n",
      "[63]\tvalid_0's tweedie: 275.915\n",
      "[64]\tvalid_0's tweedie: 275.913\n",
      "[65]\tvalid_0's tweedie: 275.911\n",
      "[66]\tvalid_0's tweedie: 275.91\n",
      "[67]\tvalid_0's tweedie: 275.91\n",
      "[68]\tvalid_0's tweedie: 275.908\n",
      "[69]\tvalid_0's tweedie: 275.908\n",
      "[70]\tvalid_0's tweedie: 275.907\n",
      "[71]\tvalid_0's tweedie: 275.905\n",
      "[72]\tvalid_0's tweedie: 275.906\n",
      "[73]\tvalid_0's tweedie: 275.905\n",
      "[74]\tvalid_0's tweedie: 275.904\n",
      "[75]\tvalid_0's tweedie: 275.902\n",
      "[76]\tvalid_0's tweedie: 275.902\n",
      "[77]\tvalid_0's tweedie: 275.902\n",
      "[78]\tvalid_0's tweedie: 275.902\n",
      "[79]\tvalid_0's tweedie: 275.9\n",
      "[80]\tvalid_0's tweedie: 275.9\n",
      "[81]\tvalid_0's tweedie: 275.898\n",
      "[82]\tvalid_0's tweedie: 275.898\n",
      "[83]\tvalid_0's tweedie: 275.898\n",
      "[84]\tvalid_0's tweedie: 275.897\n",
      "[85]\tvalid_0's tweedie: 275.896\n",
      "[86]\tvalid_0's tweedie: 275.896\n",
      "[87]\tvalid_0's tweedie: 275.896\n",
      "[88]\tvalid_0's tweedie: 275.896\n",
      "[89]\tvalid_0's tweedie: 275.896\n",
      "[90]\tvalid_0's tweedie: 275.896\n",
      "[91]\tvalid_0's tweedie: 275.895\n",
      "[92]\tvalid_0's tweedie: 275.894\n",
      "[93]\tvalid_0's tweedie: 275.894\n",
      "[94]\tvalid_0's tweedie: 275.894\n",
      "[95]\tvalid_0's tweedie: 275.894\n",
      "[96]\tvalid_0's tweedie: 275.894\n",
      "[97]\tvalid_0's tweedie: 275.894\n",
      "[98]\tvalid_0's tweedie: 275.894\n",
      "[99]\tvalid_0's tweedie: 275.893\n",
      "[100]\tvalid_0's tweedie: 275.893\n",
      "[101]\tvalid_0's tweedie: 275.891\n",
      "[102]\tvalid_0's tweedie: 275.891\n",
      "[103]\tvalid_0's tweedie: 275.891\n",
      "[104]\tvalid_0's tweedie: 275.889\n",
      "[105]\tvalid_0's tweedie: 275.889\n",
      "[106]\tvalid_0's tweedie: 275.889\n",
      "[107]\tvalid_0's tweedie: 275.889\n",
      "[108]\tvalid_0's tweedie: 275.89\n",
      "[109]\tvalid_0's tweedie: 275.889\n",
      "[110]\tvalid_0's tweedie: 275.889\n",
      "[111]\tvalid_0's tweedie: 275.889\n",
      "[112]\tvalid_0's tweedie: 275.889\n",
      "[113]\tvalid_0's tweedie: 275.889\n",
      "[114]\tvalid_0's tweedie: 275.888\n",
      "[115]\tvalid_0's tweedie: 275.888\n",
      "[116]\tvalid_0's tweedie: 275.891\n",
      "[117]\tvalid_0's tweedie: 275.891\n",
      "[118]\tvalid_0's tweedie: 275.89\n",
      "[119]\tvalid_0's tweedie: 275.89\n",
      "[120]\tvalid_0's tweedie: 275.892\n",
      "[121]\tvalid_0's tweedie: 275.894\n",
      "[122]\tvalid_0's tweedie: 275.894\n",
      "[123]\tvalid_0's tweedie: 275.893\n",
      "[124]\tvalid_0's tweedie: 275.893\n",
      "[125]\tvalid_0's tweedie: 275.892\n",
      "[126]\tvalid_0's tweedie: 275.895\n",
      "[127]\tvalid_0's tweedie: 275.894\n",
      "[128]\tvalid_0's tweedie: 275.894\n",
      "[129]\tvalid_0's tweedie: 275.894\n",
      "[130]\tvalid_0's tweedie: 275.894\n",
      "[131]\tvalid_0's tweedie: 275.893\n",
      "[132]\tvalid_0's tweedie: 275.893\n",
      "[133]\tvalid_0's tweedie: 275.892\n",
      "[134]\tvalid_0's tweedie: 275.892\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's tweedie: 275.888\n",
      "Training model for level 5 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 12964, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499015\n",
      "[1]\tvalid_0's tweedie: 306.592\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.573\n",
      "[3]\tvalid_0's tweedie: 297.303\n",
      "[4]\tvalid_0's tweedie: 293.682\n",
      "[5]\tvalid_0's tweedie: 290.685\n",
      "[6]\tvalid_0's tweedie: 288.12\n",
      "[7]\tvalid_0's tweedie: 285.995\n",
      "[8]\tvalid_0's tweedie: 284.221\n",
      "[9]\tvalid_0's tweedie: 282.755\n",
      "[10]\tvalid_0's tweedie: 281.552\n",
      "[11]\tvalid_0's tweedie: 280.554\n",
      "[12]\tvalid_0's tweedie: 279.737\n",
      "[13]\tvalid_0's tweedie: 279.055\n",
      "[14]\tvalid_0's tweedie: 278.5\n",
      "[15]\tvalid_0's tweedie: 278.051\n",
      "[16]\tvalid_0's tweedie: 277.696\n",
      "[17]\tvalid_0's tweedie: 277.405\n",
      "[18]\tvalid_0's tweedie: 277.147\n",
      "[19]\tvalid_0's tweedie: 276.945\n",
      "[20]\tvalid_0's tweedie: 276.779\n",
      "[21]\tvalid_0's tweedie: 276.632\n",
      "[22]\tvalid_0's tweedie: 276.531\n",
      "[23]\tvalid_0's tweedie: 276.438\n",
      "[24]\tvalid_0's tweedie: 276.353\n",
      "[25]\tvalid_0's tweedie: 276.295\n",
      "[26]\tvalid_0's tweedie: 276.243\n",
      "[27]\tvalid_0's tweedie: 276.191\n",
      "[28]\tvalid_0's tweedie: 276.16\n",
      "[29]\tvalid_0's tweedie: 276.126\n",
      "[30]\tvalid_0's tweedie: 276.105\n",
      "[31]\tvalid_0's tweedie: 276.086\n",
      "[32]\tvalid_0's tweedie: 276.062\n",
      "[33]\tvalid_0's tweedie: 276.042\n",
      "[34]\tvalid_0's tweedie: 276.028\n",
      "[35]\tvalid_0's tweedie: 276.016\n",
      "[36]\tvalid_0's tweedie: 276.008\n",
      "[37]\tvalid_0's tweedie: 276\n",
      "[38]\tvalid_0's tweedie: 275.991\n",
      "[39]\tvalid_0's tweedie: 275.986\n",
      "[40]\tvalid_0's tweedie: 275.982\n",
      "[41]\tvalid_0's tweedie: 275.978\n",
      "[42]\tvalid_0's tweedie: 275.968\n",
      "[43]\tvalid_0's tweedie: 275.964\n",
      "[44]\tvalid_0's tweedie: 275.955\n",
      "[45]\tvalid_0's tweedie: 275.949\n",
      "[46]\tvalid_0's tweedie: 275.945\n",
      "[47]\tvalid_0's tweedie: 275.939\n",
      "[48]\tvalid_0's tweedie: 275.937\n",
      "[49]\tvalid_0's tweedie: 275.934\n",
      "[50]\tvalid_0's tweedie: 275.934\n",
      "[51]\tvalid_0's tweedie: 275.928\n",
      "[52]\tvalid_0's tweedie: 275.926\n",
      "[53]\tvalid_0's tweedie: 275.925\n",
      "[54]\tvalid_0's tweedie: 275.921\n",
      "[55]\tvalid_0's tweedie: 275.921\n",
      "[56]\tvalid_0's tweedie: 275.919\n",
      "[57]\tvalid_0's tweedie: 275.917\n",
      "[58]\tvalid_0's tweedie: 275.917\n",
      "[59]\tvalid_0's tweedie: 275.915\n",
      "[60]\tvalid_0's tweedie: 275.914\n",
      "[61]\tvalid_0's tweedie: 275.911\n",
      "[62]\tvalid_0's tweedie: 275.91\n",
      "[63]\tvalid_0's tweedie: 275.907\n",
      "[64]\tvalid_0's tweedie: 275.905\n",
      "[65]\tvalid_0's tweedie: 275.903\n",
      "[66]\tvalid_0's tweedie: 275.901\n",
      "[67]\tvalid_0's tweedie: 275.9\n",
      "[68]\tvalid_0's tweedie: 275.898\n",
      "[69]\tvalid_0's tweedie: 275.896\n",
      "[70]\tvalid_0's tweedie: 275.895\n",
      "[71]\tvalid_0's tweedie: 275.893\n",
      "[72]\tvalid_0's tweedie: 275.89\n",
      "[73]\tvalid_0's tweedie: 275.89\n",
      "[74]\tvalid_0's tweedie: 275.89\n",
      "[75]\tvalid_0's tweedie: 275.889\n",
      "[76]\tvalid_0's tweedie: 275.889\n",
      "[77]\tvalid_0's tweedie: 275.887\n",
      "[78]\tvalid_0's tweedie: 275.887\n",
      "[79]\tvalid_0's tweedie: 275.887\n",
      "[80]\tvalid_0's tweedie: 275.886\n",
      "[81]\tvalid_0's tweedie: 275.886\n",
      "[82]\tvalid_0's tweedie: 275.887\n",
      "[83]\tvalid_0's tweedie: 275.886\n",
      "[84]\tvalid_0's tweedie: 275.886\n",
      "[85]\tvalid_0's tweedie: 275.886\n",
      "[86]\tvalid_0's tweedie: 275.886\n",
      "[87]\tvalid_0's tweedie: 275.885\n",
      "[88]\tvalid_0's tweedie: 275.885\n",
      "[89]\tvalid_0's tweedie: 275.885\n",
      "[90]\tvalid_0's tweedie: 275.886\n",
      "[91]\tvalid_0's tweedie: 275.885\n",
      "[92]\tvalid_0's tweedie: 275.884\n",
      "[93]\tvalid_0's tweedie: 275.885\n",
      "[94]\tvalid_0's tweedie: 275.885\n",
      "[95]\tvalid_0's tweedie: 275.884\n",
      "[96]\tvalid_0's tweedie: 275.883\n",
      "[97]\tvalid_0's tweedie: 275.883\n",
      "[98]\tvalid_0's tweedie: 275.883\n",
      "[99]\tvalid_0's tweedie: 275.882\n",
      "[100]\tvalid_0's tweedie: 275.882\n",
      "[101]\tvalid_0's tweedie: 275.882\n",
      "[102]\tvalid_0's tweedie: 275.882\n",
      "[103]\tvalid_0's tweedie: 275.882\n",
      "[104]\tvalid_0's tweedie: 275.883\n",
      "[105]\tvalid_0's tweedie: 275.883\n",
      "[106]\tvalid_0's tweedie: 275.883\n",
      "[107]\tvalid_0's tweedie: 275.881\n",
      "[108]\tvalid_0's tweedie: 275.881\n",
      "[109]\tvalid_0's tweedie: 275.88\n",
      "[110]\tvalid_0's tweedie: 275.88\n",
      "[111]\tvalid_0's tweedie: 275.88\n",
      "[112]\tvalid_0's tweedie: 275.879\n",
      "[113]\tvalid_0's tweedie: 275.879\n",
      "[114]\tvalid_0's tweedie: 275.881\n",
      "[115]\tvalid_0's tweedie: 275.88\n",
      "[116]\tvalid_0's tweedie: 275.882\n",
      "[117]\tvalid_0's tweedie: 275.882\n",
      "[118]\tvalid_0's tweedie: 275.882\n",
      "[119]\tvalid_0's tweedie: 275.882\n",
      "[120]\tvalid_0's tweedie: 275.882\n",
      "[121]\tvalid_0's tweedie: 275.881\n",
      "[122]\tvalid_0's tweedie: 275.881\n",
      "[123]\tvalid_0's tweedie: 275.881\n",
      "[124]\tvalid_0's tweedie: 275.88\n",
      "[125]\tvalid_0's tweedie: 275.88\n",
      "[126]\tvalid_0's tweedie: 275.879\n",
      "[127]\tvalid_0's tweedie: 275.879\n",
      "[128]\tvalid_0's tweedie: 275.879\n",
      "[129]\tvalid_0's tweedie: 275.879\n",
      "[130]\tvalid_0's tweedie: 275.878\n",
      "[131]\tvalid_0's tweedie: 275.877\n",
      "[132]\tvalid_0's tweedie: 275.876\n",
      "[133]\tvalid_0's tweedie: 275.876\n",
      "[134]\tvalid_0's tweedie: 275.876\n",
      "[135]\tvalid_0's tweedie: 275.876\n",
      "[136]\tvalid_0's tweedie: 275.875\n",
      "[137]\tvalid_0's tweedie: 275.875\n",
      "[138]\tvalid_0's tweedie: 275.875\n",
      "[139]\tvalid_0's tweedie: 275.875\n",
      "[140]\tvalid_0's tweedie: 275.875\n",
      "[141]\tvalid_0's tweedie: 275.875\n",
      "[142]\tvalid_0's tweedie: 275.875\n",
      "[143]\tvalid_0's tweedie: 275.875\n",
      "[144]\tvalid_0's tweedie: 275.875\n",
      "[145]\tvalid_0's tweedie: 275.875\n",
      "[146]\tvalid_0's tweedie: 275.875\n",
      "[147]\tvalid_0's tweedie: 275.875\n",
      "[148]\tvalid_0's tweedie: 275.875\n",
      "[149]\tvalid_0's tweedie: 275.875\n",
      "[150]\tvalid_0's tweedie: 275.874\n",
      "[151]\tvalid_0's tweedie: 275.874\n",
      "[152]\tvalid_0's tweedie: 275.874\n",
      "[153]\tvalid_0's tweedie: 275.874\n",
      "[154]\tvalid_0's tweedie: 275.875\n",
      "[155]\tvalid_0's tweedie: 275.874\n",
      "[156]\tvalid_0's tweedie: 275.874\n",
      "[157]\tvalid_0's tweedie: 275.874\n",
      "[158]\tvalid_0's tweedie: 275.874\n",
      "[159]\tvalid_0's tweedie: 275.874\n",
      "[160]\tvalid_0's tweedie: 275.874\n",
      "[161]\tvalid_0's tweedie: 275.874\n",
      "[162]\tvalid_0's tweedie: 275.875\n",
      "[163]\tvalid_0's tweedie: 275.875\n",
      "[164]\tvalid_0's tweedie: 275.875\n",
      "[165]\tvalid_0's tweedie: 275.875\n",
      "[166]\tvalid_0's tweedie: 275.875\n",
      "[167]\tvalid_0's tweedie: 275.874\n",
      "[168]\tvalid_0's tweedie: 275.875\n",
      "[169]\tvalid_0's tweedie: 275.875\n",
      "[170]\tvalid_0's tweedie: 275.875\n",
      "[171]\tvalid_0's tweedie: 275.875\n",
      "[172]\tvalid_0's tweedie: 275.875\n",
      "[173]\tvalid_0's tweedie: 275.875\n",
      "[174]\tvalid_0's tweedie: 275.875\n",
      "[175]\tvalid_0's tweedie: 275.875\n",
      "[176]\tvalid_0's tweedie: 275.875\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's tweedie: 275.874\n",
      "Training model for level 5 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 12957, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499186\n",
      "[1]\tvalid_0's tweedie: 306.589\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.568\n",
      "[3]\tvalid_0's tweedie: 297.294\n",
      "[4]\tvalid_0's tweedie: 293.689\n",
      "[5]\tvalid_0's tweedie: 290.688\n",
      "[6]\tvalid_0's tweedie: 288.118\n",
      "[7]\tvalid_0's tweedie: 285.973\n",
      "[8]\tvalid_0's tweedie: 284.244\n",
      "[9]\tvalid_0's tweedie: 282.778\n",
      "[10]\tvalid_0's tweedie: 281.573\n",
      "[11]\tvalid_0's tweedie: 280.557\n",
      "[12]\tvalid_0's tweedie: 279.733\n",
      "[13]\tvalid_0's tweedie: 279.044\n",
      "[14]\tvalid_0's tweedie: 278.49\n",
      "[15]\tvalid_0's tweedie: 278.021\n",
      "[16]\tvalid_0's tweedie: 277.64\n",
      "[17]\tvalid_0's tweedie: 277.337\n",
      "[18]\tvalid_0's tweedie: 277.09\n",
      "[19]\tvalid_0's tweedie: 276.894\n",
      "[20]\tvalid_0's tweedie: 276.729\n",
      "[21]\tvalid_0's tweedie: 276.605\n",
      "[22]\tvalid_0's tweedie: 276.492\n",
      "[23]\tvalid_0's tweedie: 276.397\n",
      "[24]\tvalid_0's tweedie: 276.318\n",
      "[25]\tvalid_0's tweedie: 276.263\n",
      "[26]\tvalid_0's tweedie: 276.213\n",
      "[27]\tvalid_0's tweedie: 276.172\n",
      "[28]\tvalid_0's tweedie: 276.142\n",
      "[29]\tvalid_0's tweedie: 276.109\n",
      "[30]\tvalid_0's tweedie: 276.085\n",
      "[31]\tvalid_0's tweedie: 276.063\n",
      "[32]\tvalid_0's tweedie: 276.045\n",
      "[33]\tvalid_0's tweedie: 276.031\n",
      "[34]\tvalid_0's tweedie: 276.018\n",
      "[35]\tvalid_0's tweedie: 276.004\n",
      "[36]\tvalid_0's tweedie: 275.995\n",
      "[37]\tvalid_0's tweedie: 275.986\n",
      "[38]\tvalid_0's tweedie: 275.978\n",
      "[39]\tvalid_0's tweedie: 275.969\n",
      "[40]\tvalid_0's tweedie: 275.962\n",
      "[41]\tvalid_0's tweedie: 275.958\n",
      "[42]\tvalid_0's tweedie: 275.955\n",
      "[43]\tvalid_0's tweedie: 275.951\n",
      "[44]\tvalid_0's tweedie: 275.941\n",
      "[45]\tvalid_0's tweedie: 275.938\n",
      "[46]\tvalid_0's tweedie: 275.931\n",
      "[47]\tvalid_0's tweedie: 275.928\n",
      "[48]\tvalid_0's tweedie: 275.925\n",
      "[49]\tvalid_0's tweedie: 275.923\n",
      "[50]\tvalid_0's tweedie: 275.921\n",
      "[51]\tvalid_0's tweedie: 275.919\n",
      "[52]\tvalid_0's tweedie: 275.916\n",
      "[53]\tvalid_0's tweedie: 275.915\n",
      "[54]\tvalid_0's tweedie: 275.912\n",
      "[55]\tvalid_0's tweedie: 275.908\n",
      "[56]\tvalid_0's tweedie: 275.907\n",
      "[57]\tvalid_0's tweedie: 275.905\n",
      "[58]\tvalid_0's tweedie: 275.901\n",
      "[59]\tvalid_0's tweedie: 275.898\n",
      "[60]\tvalid_0's tweedie: 275.897\n",
      "[61]\tvalid_0's tweedie: 275.897\n",
      "[62]\tvalid_0's tweedie: 275.896\n",
      "[63]\tvalid_0's tweedie: 275.895\n",
      "[64]\tvalid_0's tweedie: 275.894\n",
      "[65]\tvalid_0's tweedie: 275.892\n",
      "[66]\tvalid_0's tweedie: 275.892\n",
      "[67]\tvalid_0's tweedie: 275.892\n",
      "[68]\tvalid_0's tweedie: 275.891\n",
      "[69]\tvalid_0's tweedie: 275.89\n",
      "[70]\tvalid_0's tweedie: 275.89\n",
      "[71]\tvalid_0's tweedie: 275.889\n",
      "[72]\tvalid_0's tweedie: 275.888\n",
      "[73]\tvalid_0's tweedie: 275.888\n",
      "[74]\tvalid_0's tweedie: 275.888\n",
      "[75]\tvalid_0's tweedie: 275.887\n",
      "[76]\tvalid_0's tweedie: 275.886\n",
      "[77]\tvalid_0's tweedie: 275.885\n",
      "[78]\tvalid_0's tweedie: 275.884\n",
      "[79]\tvalid_0's tweedie: 275.883\n",
      "[80]\tvalid_0's tweedie: 275.883\n",
      "[81]\tvalid_0's tweedie: 275.883\n",
      "[82]\tvalid_0's tweedie: 275.884\n",
      "[83]\tvalid_0's tweedie: 275.883\n",
      "[84]\tvalid_0's tweedie: 275.883\n",
      "[85]\tvalid_0's tweedie: 275.883\n",
      "[86]\tvalid_0's tweedie: 275.883\n",
      "[87]\tvalid_0's tweedie: 275.882\n",
      "[88]\tvalid_0's tweedie: 275.882\n",
      "[89]\tvalid_0's tweedie: 275.885\n",
      "[90]\tvalid_0's tweedie: 275.885\n",
      "[91]\tvalid_0's tweedie: 275.884\n",
      "[92]\tvalid_0's tweedie: 275.885\n",
      "[93]\tvalid_0's tweedie: 275.884\n",
      "[94]\tvalid_0's tweedie: 275.885\n",
      "[95]\tvalid_0's tweedie: 275.884\n",
      "[96]\tvalid_0's tweedie: 275.884\n",
      "[97]\tvalid_0's tweedie: 275.884\n",
      "[98]\tvalid_0's tweedie: 275.884\n",
      "[99]\tvalid_0's tweedie: 275.884\n",
      "[100]\tvalid_0's tweedie: 275.884\n",
      "[101]\tvalid_0's tweedie: 275.883\n",
      "[102]\tvalid_0's tweedie: 275.883\n",
      "[103]\tvalid_0's tweedie: 275.883\n",
      "[104]\tvalid_0's tweedie: 275.883\n",
      "[105]\tvalid_0's tweedie: 275.883\n",
      "[106]\tvalid_0's tweedie: 275.882\n",
      "[107]\tvalid_0's tweedie: 275.882\n",
      "[108]\tvalid_0's tweedie: 275.882\n",
      "[109]\tvalid_0's tweedie: 275.882\n",
      "[110]\tvalid_0's tweedie: 275.883\n",
      "[111]\tvalid_0's tweedie: 275.883\n",
      "[112]\tvalid_0's tweedie: 275.883\n",
      "[113]\tvalid_0's tweedie: 275.882\n",
      "[114]\tvalid_0's tweedie: 275.882\n",
      "[115]\tvalid_0's tweedie: 275.882\n",
      "[116]\tvalid_0's tweedie: 275.882\n",
      "[117]\tvalid_0's tweedie: 275.882\n",
      "[118]\tvalid_0's tweedie: 275.884\n",
      "[119]\tvalid_0's tweedie: 275.884\n",
      "[120]\tvalid_0's tweedie: 275.886\n",
      "[121]\tvalid_0's tweedie: 275.886\n",
      "[122]\tvalid_0's tweedie: 275.886\n",
      "[123]\tvalid_0's tweedie: 275.885\n",
      "[124]\tvalid_0's tweedie: 275.885\n",
      "[125]\tvalid_0's tweedie: 275.885\n",
      "[126]\tvalid_0's tweedie: 275.885\n",
      "[127]\tvalid_0's tweedie: 275.885\n",
      "[128]\tvalid_0's tweedie: 275.885\n",
      "[129]\tvalid_0's tweedie: 275.884\n",
      "[130]\tvalid_0's tweedie: 275.884\n",
      "[131]\tvalid_0's tweedie: 275.883\n",
      "[132]\tvalid_0's tweedie: 275.883\n",
      "[133]\tvalid_0's tweedie: 275.883\n",
      "[134]\tvalid_0's tweedie: 275.883\n",
      "[135]\tvalid_0's tweedie: 275.883\n",
      "[136]\tvalid_0's tweedie: 275.881\n",
      "[137]\tvalid_0's tweedie: 275.881\n",
      "[138]\tvalid_0's tweedie: 275.881\n",
      "[139]\tvalid_0's tweedie: 275.885\n",
      "[140]\tvalid_0's tweedie: 275.888\n",
      "[141]\tvalid_0's tweedie: 275.888\n",
      "[142]\tvalid_0's tweedie: 275.889\n",
      "[143]\tvalid_0's tweedie: 275.889\n",
      "[144]\tvalid_0's tweedie: 275.888\n",
      "[145]\tvalid_0's tweedie: 275.889\n",
      "[146]\tvalid_0's tweedie: 275.889\n",
      "[147]\tvalid_0's tweedie: 275.889\n",
      "[148]\tvalid_0's tweedie: 275.888\n",
      "[149]\tvalid_0's tweedie: 275.888\n",
      "[150]\tvalid_0's tweedie: 275.887\n",
      "[151]\tvalid_0's tweedie: 275.887\n",
      "[152]\tvalid_0's tweedie: 275.887\n",
      "[153]\tvalid_0's tweedie: 275.887\n",
      "[154]\tvalid_0's tweedie: 275.887\n",
      "[155]\tvalid_0's tweedie: 275.886\n",
      "[156]\tvalid_0's tweedie: 275.887\n",
      "[157]\tvalid_0's tweedie: 275.887\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's tweedie: 275.881\n",
      "Training model for level 5 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 12950, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499356\n",
      "[1]\tvalid_0's tweedie: 306.554\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.511\n",
      "[3]\tvalid_0's tweedie: 297.23\n",
      "[4]\tvalid_0's tweedie: 293.632\n",
      "[5]\tvalid_0's tweedie: 290.588\n",
      "[6]\tvalid_0's tweedie: 288.047\n",
      "[7]\tvalid_0's tweedie: 285.905\n",
      "[8]\tvalid_0's tweedie: 284.152\n",
      "[9]\tvalid_0's tweedie: 282.692\n",
      "[10]\tvalid_0's tweedie: 281.497\n",
      "[11]\tvalid_0's tweedie: 280.515\n",
      "[12]\tvalid_0's tweedie: 279.686\n",
      "[13]\tvalid_0's tweedie: 279.005\n",
      "[14]\tvalid_0's tweedie: 278.457\n",
      "[15]\tvalid_0's tweedie: 277.999\n",
      "[16]\tvalid_0's tweedie: 277.619\n",
      "[17]\tvalid_0's tweedie: 277.324\n",
      "[18]\tvalid_0's tweedie: 277.065\n",
      "[19]\tvalid_0's tweedie: 276.881\n",
      "[20]\tvalid_0's tweedie: 276.704\n",
      "[21]\tvalid_0's tweedie: 276.561\n",
      "[22]\tvalid_0's tweedie: 276.45\n",
      "[23]\tvalid_0's tweedie: 276.359\n",
      "[24]\tvalid_0's tweedie: 276.285\n",
      "[25]\tvalid_0's tweedie: 276.225\n",
      "[26]\tvalid_0's tweedie: 276.172\n",
      "[27]\tvalid_0's tweedie: 276.13\n",
      "[28]\tvalid_0's tweedie: 276.099\n",
      "[29]\tvalid_0's tweedie: 276.068\n",
      "[30]\tvalid_0's tweedie: 276.042\n",
      "[31]\tvalid_0's tweedie: 276.023\n",
      "[32]\tvalid_0's tweedie: 276.008\n",
      "[33]\tvalid_0's tweedie: 275.994\n",
      "[34]\tvalid_0's tweedie: 275.986\n",
      "[35]\tvalid_0's tweedie: 275.975\n",
      "[36]\tvalid_0's tweedie: 275.966\n",
      "[37]\tvalid_0's tweedie: 275.96\n",
      "[38]\tvalid_0's tweedie: 275.947\n",
      "[39]\tvalid_0's tweedie: 275.941\n",
      "[40]\tvalid_0's tweedie: 275.935\n",
      "[41]\tvalid_0's tweedie: 275.928\n",
      "[42]\tvalid_0's tweedie: 275.924\n",
      "[43]\tvalid_0's tweedie: 275.915\n",
      "[44]\tvalid_0's tweedie: 275.909\n",
      "[45]\tvalid_0's tweedie: 275.904\n",
      "[46]\tvalid_0's tweedie: 275.9\n",
      "[47]\tvalid_0's tweedie: 275.896\n",
      "[48]\tvalid_0's tweedie: 275.894\n",
      "[49]\tvalid_0's tweedie: 275.893\n",
      "[50]\tvalid_0's tweedie: 275.891\n",
      "[51]\tvalid_0's tweedie: 275.887\n",
      "[52]\tvalid_0's tweedie: 275.883\n",
      "[53]\tvalid_0's tweedie: 275.881\n",
      "[54]\tvalid_0's tweedie: 275.879\n",
      "[55]\tvalid_0's tweedie: 275.876\n",
      "[56]\tvalid_0's tweedie: 275.875\n",
      "[57]\tvalid_0's tweedie: 275.874\n",
      "[58]\tvalid_0's tweedie: 275.87\n",
      "[59]\tvalid_0's tweedie: 275.869\n",
      "[60]\tvalid_0's tweedie: 275.866\n",
      "[61]\tvalid_0's tweedie: 275.865\n",
      "[62]\tvalid_0's tweedie: 275.865\n",
      "[63]\tvalid_0's tweedie: 275.862\n",
      "[64]\tvalid_0's tweedie: 275.862\n",
      "[65]\tvalid_0's tweedie: 275.861\n",
      "[66]\tvalid_0's tweedie: 275.861\n",
      "[67]\tvalid_0's tweedie: 275.86\n",
      "[68]\tvalid_0's tweedie: 275.859\n",
      "[69]\tvalid_0's tweedie: 275.858\n",
      "[70]\tvalid_0's tweedie: 275.858\n",
      "[71]\tvalid_0's tweedie: 275.859\n",
      "[72]\tvalid_0's tweedie: 275.857\n",
      "[73]\tvalid_0's tweedie: 275.856\n",
      "[74]\tvalid_0's tweedie: 275.854\n",
      "[75]\tvalid_0's tweedie: 275.853\n",
      "[76]\tvalid_0's tweedie: 275.854\n",
      "[77]\tvalid_0's tweedie: 275.854\n",
      "[78]\tvalid_0's tweedie: 275.855\n",
      "[79]\tvalid_0's tweedie: 275.855\n",
      "[80]\tvalid_0's tweedie: 275.855\n",
      "[81]\tvalid_0's tweedie: 275.857\n",
      "[82]\tvalid_0's tweedie: 275.857\n",
      "[83]\tvalid_0's tweedie: 275.858\n",
      "[84]\tvalid_0's tweedie: 275.857\n",
      "[85]\tvalid_0's tweedie: 275.857\n",
      "[86]\tvalid_0's tweedie: 275.857\n",
      "[87]\tvalid_0's tweedie: 275.857\n",
      "[88]\tvalid_0's tweedie: 275.857\n",
      "[89]\tvalid_0's tweedie: 275.857\n",
      "[90]\tvalid_0's tweedie: 275.856\n",
      "[91]\tvalid_0's tweedie: 275.856\n",
      "[92]\tvalid_0's tweedie: 275.856\n",
      "[93]\tvalid_0's tweedie: 275.858\n",
      "[94]\tvalid_0's tweedie: 275.858\n",
      "[95]\tvalid_0's tweedie: 275.858\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's tweedie: 275.853\n",
      "Training model for level 5 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 12943, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499406\n",
      "[1]\tvalid_0's tweedie: 306.555\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.537\n",
      "[3]\tvalid_0's tweedie: 297.249\n",
      "[4]\tvalid_0's tweedie: 293.643\n",
      "[5]\tvalid_0's tweedie: 290.629\n",
      "[6]\tvalid_0's tweedie: 288.051\n",
      "[7]\tvalid_0's tweedie: 285.92\n",
      "[8]\tvalid_0's tweedie: 284.134\n",
      "[9]\tvalid_0's tweedie: 282.681\n",
      "[10]\tvalid_0's tweedie: 281.475\n",
      "[11]\tvalid_0's tweedie: 280.471\n",
      "[12]\tvalid_0's tweedie: 279.67\n",
      "[13]\tvalid_0's tweedie: 278.977\n",
      "[14]\tvalid_0's tweedie: 278.427\n",
      "[15]\tvalid_0's tweedie: 277.968\n",
      "[16]\tvalid_0's tweedie: 277.608\n",
      "[17]\tvalid_0's tweedie: 277.308\n",
      "[18]\tvalid_0's tweedie: 277.063\n",
      "[19]\tvalid_0's tweedie: 276.864\n",
      "[20]\tvalid_0's tweedie: 276.693\n",
      "[21]\tvalid_0's tweedie: 276.555\n",
      "[22]\tvalid_0's tweedie: 276.448\n",
      "[23]\tvalid_0's tweedie: 276.348\n",
      "[24]\tvalid_0's tweedie: 276.278\n",
      "[25]\tvalid_0's tweedie: 276.212\n",
      "[26]\tvalid_0's tweedie: 276.163\n",
      "[27]\tvalid_0's tweedie: 276.126\n",
      "[28]\tvalid_0's tweedie: 276.088\n",
      "[29]\tvalid_0's tweedie: 276.059\n",
      "[30]\tvalid_0's tweedie: 276.036\n",
      "[31]\tvalid_0's tweedie: 276.019\n",
      "[32]\tvalid_0's tweedie: 276.006\n",
      "[33]\tvalid_0's tweedie: 275.99\n",
      "[34]\tvalid_0's tweedie: 275.979\n",
      "[35]\tvalid_0's tweedie: 275.972\n",
      "[36]\tvalid_0's tweedie: 275.96\n",
      "[37]\tvalid_0's tweedie: 275.958\n",
      "[38]\tvalid_0's tweedie: 275.951\n",
      "[39]\tvalid_0's tweedie: 275.946\n",
      "[40]\tvalid_0's tweedie: 275.942\n",
      "[41]\tvalid_0's tweedie: 275.937\n",
      "[42]\tvalid_0's tweedie: 275.927\n",
      "[43]\tvalid_0's tweedie: 275.917\n",
      "[44]\tvalid_0's tweedie: 275.913\n",
      "[45]\tvalid_0's tweedie: 275.912\n",
      "[46]\tvalid_0's tweedie: 275.906\n",
      "[47]\tvalid_0's tweedie: 275.901\n",
      "[48]\tvalid_0's tweedie: 275.898\n",
      "[49]\tvalid_0's tweedie: 275.893\n",
      "[50]\tvalid_0's tweedie: 275.892\n",
      "[51]\tvalid_0's tweedie: 275.891\n",
      "[52]\tvalid_0's tweedie: 275.889\n",
      "[53]\tvalid_0's tweedie: 275.886\n",
      "[54]\tvalid_0's tweedie: 275.884\n",
      "[55]\tvalid_0's tweedie: 275.883\n",
      "[56]\tvalid_0's tweedie: 275.881\n",
      "[57]\tvalid_0's tweedie: 275.879\n",
      "[58]\tvalid_0's tweedie: 275.875\n",
      "[59]\tvalid_0's tweedie: 275.873\n",
      "[60]\tvalid_0's tweedie: 275.873\n",
      "[61]\tvalid_0's tweedie: 275.873\n",
      "[62]\tvalid_0's tweedie: 275.872\n",
      "[63]\tvalid_0's tweedie: 275.871\n",
      "[64]\tvalid_0's tweedie: 275.87\n",
      "[65]\tvalid_0's tweedie: 275.868\n",
      "[66]\tvalid_0's tweedie: 275.867\n",
      "[67]\tvalid_0's tweedie: 275.865\n",
      "[68]\tvalid_0's tweedie: 275.864\n",
      "[69]\tvalid_0's tweedie: 275.863\n",
      "[70]\tvalid_0's tweedie: 275.863\n",
      "[71]\tvalid_0's tweedie: 275.863\n",
      "[72]\tvalid_0's tweedie: 275.862\n",
      "[73]\tvalid_0's tweedie: 275.86\n",
      "[74]\tvalid_0's tweedie: 275.861\n",
      "[75]\tvalid_0's tweedie: 275.86\n",
      "[76]\tvalid_0's tweedie: 275.86\n",
      "[77]\tvalid_0's tweedie: 275.86\n",
      "[78]\tvalid_0's tweedie: 275.859\n",
      "[79]\tvalid_0's tweedie: 275.859\n",
      "[80]\tvalid_0's tweedie: 275.858\n",
      "[81]\tvalid_0's tweedie: 275.858\n",
      "[82]\tvalid_0's tweedie: 275.858\n",
      "[83]\tvalid_0's tweedie: 275.857\n",
      "[84]\tvalid_0's tweedie: 275.857\n",
      "[85]\tvalid_0's tweedie: 275.856\n",
      "[86]\tvalid_0's tweedie: 275.857\n",
      "[87]\tvalid_0's tweedie: 275.856\n",
      "[88]\tvalid_0's tweedie: 275.858\n",
      "[89]\tvalid_0's tweedie: 275.858\n",
      "[90]\tvalid_0's tweedie: 275.857\n",
      "[91]\tvalid_0's tweedie: 275.857\n",
      "[92]\tvalid_0's tweedie: 275.857\n",
      "[93]\tvalid_0's tweedie: 275.857\n",
      "[94]\tvalid_0's tweedie: 275.857\n",
      "[95]\tvalid_0's tweedie: 275.858\n",
      "[96]\tvalid_0's tweedie: 275.859\n",
      "[97]\tvalid_0's tweedie: 275.859\n",
      "[98]\tvalid_0's tweedie: 275.859\n",
      "[99]\tvalid_0's tweedie: 275.859\n",
      "[100]\tvalid_0's tweedie: 275.859\n",
      "[101]\tvalid_0's tweedie: 275.857\n",
      "[102]\tvalid_0's tweedie: 275.858\n",
      "[103]\tvalid_0's tweedie: 275.857\n",
      "[104]\tvalid_0's tweedie: 275.856\n",
      "[105]\tvalid_0's tweedie: 275.856\n",
      "[106]\tvalid_0's tweedie: 275.857\n",
      "[107]\tvalid_0's tweedie: 275.857\n",
      "[108]\tvalid_0's tweedie: 275.857\n",
      "[109]\tvalid_0's tweedie: 275.857\n",
      "[110]\tvalid_0's tweedie: 275.857\n",
      "[111]\tvalid_0's tweedie: 275.857\n",
      "[112]\tvalid_0's tweedie: 275.857\n",
      "[113]\tvalid_0's tweedie: 275.856\n",
      "[114]\tvalid_0's tweedie: 275.856\n",
      "[115]\tvalid_0's tweedie: 275.855\n",
      "[116]\tvalid_0's tweedie: 275.855\n",
      "[117]\tvalid_0's tweedie: 275.855\n",
      "[118]\tvalid_0's tweedie: 275.855\n",
      "[119]\tvalid_0's tweedie: 275.855\n",
      "[120]\tvalid_0's tweedie: 275.855\n",
      "[121]\tvalid_0's tweedie: 275.856\n",
      "[122]\tvalid_0's tweedie: 275.856\n",
      "[123]\tvalid_0's tweedie: 275.856\n",
      "[124]\tvalid_0's tweedie: 275.857\n",
      "[125]\tvalid_0's tweedie: 275.857\n",
      "[126]\tvalid_0's tweedie: 275.857\n",
      "[127]\tvalid_0's tweedie: 275.857\n",
      "[128]\tvalid_0's tweedie: 275.857\n",
      "[129]\tvalid_0's tweedie: 275.857\n",
      "[130]\tvalid_0's tweedie: 275.857\n",
      "[131]\tvalid_0's tweedie: 275.857\n",
      "[132]\tvalid_0's tweedie: 275.857\n",
      "[133]\tvalid_0's tweedie: 275.856\n",
      "[134]\tvalid_0's tweedie: 275.856\n",
      "[135]\tvalid_0's tweedie: 275.855\n",
      "[136]\tvalid_0's tweedie: 275.855\n",
      "[137]\tvalid_0's tweedie: 275.858\n",
      "[138]\tvalid_0's tweedie: 275.86\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's tweedie: 275.855\n",
      "Training model for level 5 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 12936, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499398\n",
      "[1]\tvalid_0's tweedie: 306.55\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.512\n",
      "[3]\tvalid_0's tweedie: 297.235\n",
      "[4]\tvalid_0's tweedie: 293.602\n",
      "[5]\tvalid_0's tweedie: 290.579\n",
      "[6]\tvalid_0's tweedie: 288.005\n",
      "[7]\tvalid_0's tweedie: 285.896\n",
      "[8]\tvalid_0's tweedie: 284.127\n",
      "[9]\tvalid_0's tweedie: 282.667\n",
      "[10]\tvalid_0's tweedie: 281.46\n",
      "[11]\tvalid_0's tweedie: 280.463\n",
      "[12]\tvalid_0's tweedie: 279.662\n",
      "[13]\tvalid_0's tweedie: 278.989\n",
      "[14]\tvalid_0's tweedie: 278.439\n",
      "[15]\tvalid_0's tweedie: 277.983\n",
      "[16]\tvalid_0's tweedie: 277.61\n",
      "[17]\tvalid_0's tweedie: 277.308\n",
      "[18]\tvalid_0's tweedie: 277.057\n",
      "[19]\tvalid_0's tweedie: 276.855\n",
      "[20]\tvalid_0's tweedie: 276.684\n",
      "[21]\tvalid_0's tweedie: 276.553\n",
      "[22]\tvalid_0's tweedie: 276.444\n",
      "[23]\tvalid_0's tweedie: 276.352\n",
      "[24]\tvalid_0's tweedie: 276.274\n",
      "[25]\tvalid_0's tweedie: 276.218\n",
      "[26]\tvalid_0's tweedie: 276.167\n",
      "[27]\tvalid_0's tweedie: 276.127\n",
      "[28]\tvalid_0's tweedie: 276.093\n",
      "[29]\tvalid_0's tweedie: 276.065\n",
      "[30]\tvalid_0's tweedie: 276.045\n",
      "[31]\tvalid_0's tweedie: 276.023\n",
      "[32]\tvalid_0's tweedie: 276.008\n",
      "[33]\tvalid_0's tweedie: 275.993\n",
      "[34]\tvalid_0's tweedie: 275.99\n",
      "[35]\tvalid_0's tweedie: 275.981\n",
      "[36]\tvalid_0's tweedie: 275.978\n",
      "[37]\tvalid_0's tweedie: 275.971\n",
      "[38]\tvalid_0's tweedie: 275.965\n",
      "[39]\tvalid_0's tweedie: 275.957\n",
      "[40]\tvalid_0's tweedie: 275.947\n",
      "[41]\tvalid_0's tweedie: 275.941\n",
      "[42]\tvalid_0's tweedie: 275.937\n",
      "[43]\tvalid_0's tweedie: 275.927\n",
      "[44]\tvalid_0's tweedie: 275.923\n",
      "[45]\tvalid_0's tweedie: 275.921\n",
      "[46]\tvalid_0's tweedie: 275.914\n",
      "[47]\tvalid_0's tweedie: 275.908\n",
      "[48]\tvalid_0's tweedie: 275.906\n",
      "[49]\tvalid_0's tweedie: 275.9\n",
      "[50]\tvalid_0's tweedie: 275.897\n",
      "[51]\tvalid_0's tweedie: 275.895\n",
      "[52]\tvalid_0's tweedie: 275.892\n",
      "[53]\tvalid_0's tweedie: 275.89\n",
      "[54]\tvalid_0's tweedie: 275.886\n",
      "[55]\tvalid_0's tweedie: 275.885\n",
      "[56]\tvalid_0's tweedie: 275.884\n",
      "[57]\tvalid_0's tweedie: 275.882\n",
      "[58]\tvalid_0's tweedie: 275.879\n",
      "[59]\tvalid_0's tweedie: 275.876\n",
      "[60]\tvalid_0's tweedie: 275.874\n",
      "[61]\tvalid_0's tweedie: 275.872\n",
      "[62]\tvalid_0's tweedie: 275.871\n",
      "[63]\tvalid_0's tweedie: 275.87\n",
      "[64]\tvalid_0's tweedie: 275.869\n",
      "[65]\tvalid_0's tweedie: 275.869\n",
      "[66]\tvalid_0's tweedie: 275.868\n",
      "[67]\tvalid_0's tweedie: 275.867\n",
      "[68]\tvalid_0's tweedie: 275.866\n",
      "[69]\tvalid_0's tweedie: 275.865\n",
      "[70]\tvalid_0's tweedie: 275.864\n",
      "[71]\tvalid_0's tweedie: 275.864\n",
      "[72]\tvalid_0's tweedie: 275.863\n",
      "[73]\tvalid_0's tweedie: 275.863\n",
      "[74]\tvalid_0's tweedie: 275.862\n",
      "[75]\tvalid_0's tweedie: 275.864\n",
      "[76]\tvalid_0's tweedie: 275.862\n",
      "[77]\tvalid_0's tweedie: 275.861\n",
      "[78]\tvalid_0's tweedie: 275.86\n",
      "[79]\tvalid_0's tweedie: 275.86\n",
      "[80]\tvalid_0's tweedie: 275.86\n",
      "[81]\tvalid_0's tweedie: 275.86\n",
      "[82]\tvalid_0's tweedie: 275.859\n",
      "[83]\tvalid_0's tweedie: 275.857\n",
      "[84]\tvalid_0's tweedie: 275.857\n",
      "[85]\tvalid_0's tweedie: 275.858\n",
      "[86]\tvalid_0's tweedie: 275.857\n",
      "[87]\tvalid_0's tweedie: 275.857\n",
      "[88]\tvalid_0's tweedie: 275.857\n",
      "[89]\tvalid_0's tweedie: 275.857\n",
      "[90]\tvalid_0's tweedie: 275.857\n",
      "[91]\tvalid_0's tweedie: 275.857\n",
      "[92]\tvalid_0's tweedie: 275.856\n",
      "[93]\tvalid_0's tweedie: 275.856\n",
      "[94]\tvalid_0's tweedie: 275.855\n",
      "[95]\tvalid_0's tweedie: 275.854\n",
      "[96]\tvalid_0's tweedie: 275.855\n",
      "[97]\tvalid_0's tweedie: 275.855\n",
      "[98]\tvalid_0's tweedie: 275.854\n",
      "[99]\tvalid_0's tweedie: 275.854\n",
      "[100]\tvalid_0's tweedie: 275.853\n",
      "[101]\tvalid_0's tweedie: 275.853\n",
      "[102]\tvalid_0's tweedie: 275.853\n",
      "[103]\tvalid_0's tweedie: 275.854\n",
      "[104]\tvalid_0's tweedie: 275.854\n",
      "[105]\tvalid_0's tweedie: 275.855\n",
      "[106]\tvalid_0's tweedie: 275.855\n",
      "[107]\tvalid_0's tweedie: 275.855\n",
      "[108]\tvalid_0's tweedie: 275.855\n",
      "[109]\tvalid_0's tweedie: 275.854\n",
      "[110]\tvalid_0's tweedie: 275.854\n",
      "[111]\tvalid_0's tweedie: 275.852\n",
      "[112]\tvalid_0's tweedie: 275.852\n",
      "[113]\tvalid_0's tweedie: 275.852\n",
      "[114]\tvalid_0's tweedie: 275.852\n",
      "[115]\tvalid_0's tweedie: 275.851\n",
      "[116]\tvalid_0's tweedie: 275.851\n",
      "[117]\tvalid_0's tweedie: 275.851\n",
      "[118]\tvalid_0's tweedie: 275.851\n",
      "[119]\tvalid_0's tweedie: 275.851\n",
      "[120]\tvalid_0's tweedie: 275.851\n",
      "[121]\tvalid_0's tweedie: 275.851\n",
      "[122]\tvalid_0's tweedie: 275.85\n",
      "[123]\tvalid_0's tweedie: 275.85\n",
      "[124]\tvalid_0's tweedie: 275.85\n",
      "[125]\tvalid_0's tweedie: 275.85\n",
      "[126]\tvalid_0's tweedie: 275.849\n",
      "[127]\tvalid_0's tweedie: 275.85\n",
      "[128]\tvalid_0's tweedie: 275.85\n",
      "[129]\tvalid_0's tweedie: 275.85\n",
      "[130]\tvalid_0's tweedie: 275.849\n",
      "[131]\tvalid_0's tweedie: 275.849\n",
      "[132]\tvalid_0's tweedie: 275.849\n",
      "[133]\tvalid_0's tweedie: 275.848\n",
      "[134]\tvalid_0's tweedie: 275.848\n",
      "[135]\tvalid_0's tweedie: 275.848\n",
      "[136]\tvalid_0's tweedie: 275.848\n",
      "[137]\tvalid_0's tweedie: 275.848\n",
      "[138]\tvalid_0's tweedie: 275.848\n",
      "[139]\tvalid_0's tweedie: 275.848\n",
      "[140]\tvalid_0's tweedie: 275.847\n",
      "[141]\tvalid_0's tweedie: 275.846\n",
      "[142]\tvalid_0's tweedie: 275.846\n",
      "[143]\tvalid_0's tweedie: 275.846\n",
      "[144]\tvalid_0's tweedie: 275.849\n",
      "[145]\tvalid_0's tweedie: 275.849\n",
      "[146]\tvalid_0's tweedie: 275.848\n",
      "[147]\tvalid_0's tweedie: 275.847\n",
      "[148]\tvalid_0's tweedie: 275.847\n",
      "[149]\tvalid_0's tweedie: 275.847\n",
      "[150]\tvalid_0's tweedie: 275.848\n",
      "[151]\tvalid_0's tweedie: 275.847\n",
      "[152]\tvalid_0's tweedie: 275.847\n",
      "[153]\tvalid_0's tweedie: 275.847\n",
      "[154]\tvalid_0's tweedie: 275.847\n",
      "[155]\tvalid_0's tweedie: 275.847\n",
      "[156]\tvalid_0's tweedie: 275.848\n",
      "[157]\tvalid_0's tweedie: 275.848\n",
      "[158]\tvalid_0's tweedie: 275.848\n",
      "[159]\tvalid_0's tweedie: 275.848\n",
      "[160]\tvalid_0's tweedie: 275.848\n",
      "[161]\tvalid_0's tweedie: 275.848\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's tweedie: 275.846\n",
      "Training model for level 5 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5489\n",
      "[LightGBM] [Info] Number of data points in the train set: 12929, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499553\n",
      "[1]\tvalid_0's tweedie: 306.546\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.509\n",
      "[3]\tvalid_0's tweedie: 297.231\n",
      "[4]\tvalid_0's tweedie: 293.592\n",
      "[5]\tvalid_0's tweedie: 290.549\n",
      "[6]\tvalid_0's tweedie: 287.999\n",
      "[7]\tvalid_0's tweedie: 285.864\n",
      "[8]\tvalid_0's tweedie: 284.11\n",
      "[9]\tvalid_0's tweedie: 282.661\n",
      "[10]\tvalid_0's tweedie: 281.468\n",
      "[11]\tvalid_0's tweedie: 280.485\n",
      "[12]\tvalid_0's tweedie: 279.662\n",
      "[13]\tvalid_0's tweedie: 278.993\n",
      "[14]\tvalid_0's tweedie: 278.443\n",
      "[15]\tvalid_0's tweedie: 277.981\n",
      "[16]\tvalid_0's tweedie: 277.606\n",
      "[17]\tvalid_0's tweedie: 277.31\n",
      "[18]\tvalid_0's tweedie: 277.064\n",
      "[19]\tvalid_0's tweedie: 276.853\n",
      "[20]\tvalid_0's tweedie: 276.681\n",
      "[21]\tvalid_0's tweedie: 276.556\n",
      "[22]\tvalid_0's tweedie: 276.454\n",
      "[23]\tvalid_0's tweedie: 276.363\n",
      "[24]\tvalid_0's tweedie: 276.284\n",
      "[25]\tvalid_0's tweedie: 276.221\n",
      "[26]\tvalid_0's tweedie: 276.171\n",
      "[27]\tvalid_0's tweedie: 276.129\n",
      "[28]\tvalid_0's tweedie: 276.09\n",
      "[29]\tvalid_0's tweedie: 276.06\n",
      "[30]\tvalid_0's tweedie: 276.035\n",
      "[31]\tvalid_0's tweedie: 276.014\n",
      "[32]\tvalid_0's tweedie: 275.999\n",
      "[33]\tvalid_0's tweedie: 275.987\n",
      "[34]\tvalid_0's tweedie: 275.977\n",
      "[35]\tvalid_0's tweedie: 275.966\n",
      "[36]\tvalid_0's tweedie: 275.959\n",
      "[37]\tvalid_0's tweedie: 275.95\n",
      "[38]\tvalid_0's tweedie: 275.942\n",
      "[39]\tvalid_0's tweedie: 275.936\n",
      "[40]\tvalid_0's tweedie: 275.927\n",
      "[41]\tvalid_0's tweedie: 275.924\n",
      "[42]\tvalid_0's tweedie: 275.92\n",
      "[43]\tvalid_0's tweedie: 275.911\n",
      "[44]\tvalid_0's tweedie: 275.909\n",
      "[45]\tvalid_0's tweedie: 275.903\n",
      "[46]\tvalid_0's tweedie: 275.9\n",
      "[47]\tvalid_0's tweedie: 275.898\n",
      "[48]\tvalid_0's tweedie: 275.896\n",
      "[49]\tvalid_0's tweedie: 275.895\n",
      "[50]\tvalid_0's tweedie: 275.889\n",
      "[51]\tvalid_0's tweedie: 275.885\n",
      "[52]\tvalid_0's tweedie: 275.883\n",
      "[53]\tvalid_0's tweedie: 275.881\n",
      "[54]\tvalid_0's tweedie: 275.88\n",
      "[55]\tvalid_0's tweedie: 275.88\n",
      "[56]\tvalid_0's tweedie: 275.878\n",
      "[57]\tvalid_0's tweedie: 275.874\n",
      "[58]\tvalid_0's tweedie: 275.869\n",
      "[59]\tvalid_0's tweedie: 275.868\n",
      "[60]\tvalid_0's tweedie: 275.867\n",
      "[61]\tvalid_0's tweedie: 275.866\n",
      "[62]\tvalid_0's tweedie: 275.865\n",
      "[63]\tvalid_0's tweedie: 275.865\n",
      "[64]\tvalid_0's tweedie: 275.864\n",
      "[65]\tvalid_0's tweedie: 275.861\n",
      "[66]\tvalid_0's tweedie: 275.861\n",
      "[67]\tvalid_0's tweedie: 275.858\n",
      "[68]\tvalid_0's tweedie: 275.857\n",
      "[69]\tvalid_0's tweedie: 275.856\n",
      "[70]\tvalid_0's tweedie: 275.854\n",
      "[71]\tvalid_0's tweedie: 275.854\n",
      "[72]\tvalid_0's tweedie: 275.853\n",
      "[73]\tvalid_0's tweedie: 275.853\n",
      "[74]\tvalid_0's tweedie: 275.853\n",
      "[75]\tvalid_0's tweedie: 275.852\n",
      "[76]\tvalid_0's tweedie: 275.852\n",
      "[77]\tvalid_0's tweedie: 275.851\n",
      "[78]\tvalid_0's tweedie: 275.85\n",
      "[79]\tvalid_0's tweedie: 275.85\n",
      "[80]\tvalid_0's tweedie: 275.85\n",
      "[81]\tvalid_0's tweedie: 275.85\n",
      "[82]\tvalid_0's tweedie: 275.849\n",
      "[83]\tvalid_0's tweedie: 275.849\n",
      "[84]\tvalid_0's tweedie: 275.849\n",
      "[85]\tvalid_0's tweedie: 275.847\n",
      "[86]\tvalid_0's tweedie: 275.847\n",
      "[87]\tvalid_0's tweedie: 275.846\n",
      "[88]\tvalid_0's tweedie: 275.846\n",
      "[89]\tvalid_0's tweedie: 275.846\n",
      "[90]\tvalid_0's tweedie: 275.845\n",
      "[91]\tvalid_0's tweedie: 275.844\n",
      "[92]\tvalid_0's tweedie: 275.844\n",
      "[93]\tvalid_0's tweedie: 275.845\n",
      "[94]\tvalid_0's tweedie: 275.844\n",
      "[95]\tvalid_0's tweedie: 275.845\n",
      "[96]\tvalid_0's tweedie: 275.845\n",
      "[97]\tvalid_0's tweedie: 275.844\n",
      "[98]\tvalid_0's tweedie: 275.844\n",
      "[99]\tvalid_0's tweedie: 275.844\n",
      "[100]\tvalid_0's tweedie: 275.844\n",
      "[101]\tvalid_0's tweedie: 275.844\n",
      "[102]\tvalid_0's tweedie: 275.843\n",
      "[103]\tvalid_0's tweedie: 275.844\n",
      "[104]\tvalid_0's tweedie: 275.844\n",
      "[105]\tvalid_0's tweedie: 275.844\n",
      "[106]\tvalid_0's tweedie: 275.844\n",
      "[107]\tvalid_0's tweedie: 275.844\n",
      "[108]\tvalid_0's tweedie: 275.843\n",
      "[109]\tvalid_0's tweedie: 275.843\n",
      "[110]\tvalid_0's tweedie: 275.842\n",
      "[111]\tvalid_0's tweedie: 275.843\n",
      "[112]\tvalid_0's tweedie: 275.844\n",
      "[113]\tvalid_0's tweedie: 275.844\n",
      "[114]\tvalid_0's tweedie: 275.843\n",
      "[115]\tvalid_0's tweedie: 275.843\n",
      "[116]\tvalid_0's tweedie: 275.844\n",
      "[117]\tvalid_0's tweedie: 275.843\n",
      "[118]\tvalid_0's tweedie: 275.843\n",
      "[119]\tvalid_0's tweedie: 275.843\n",
      "[120]\tvalid_0's tweedie: 275.843\n",
      "[121]\tvalid_0's tweedie: 275.843\n",
      "[122]\tvalid_0's tweedie: 275.843\n",
      "[123]\tvalid_0's tweedie: 275.842\n",
      "[124]\tvalid_0's tweedie: 275.842\n",
      "[125]\tvalid_0's tweedie: 275.841\n",
      "[126]\tvalid_0's tweedie: 275.841\n",
      "[127]\tvalid_0's tweedie: 275.841\n",
      "[128]\tvalid_0's tweedie: 275.842\n",
      "[129]\tvalid_0's tweedie: 275.842\n",
      "[130]\tvalid_0's tweedie: 275.841\n",
      "[131]\tvalid_0's tweedie: 275.841\n",
      "[132]\tvalid_0's tweedie: 275.841\n",
      "[133]\tvalid_0's tweedie: 275.841\n",
      "[134]\tvalid_0's tweedie: 275.841\n",
      "[135]\tvalid_0's tweedie: 275.841\n",
      "[136]\tvalid_0's tweedie: 275.841\n",
      "[137]\tvalid_0's tweedie: 275.841\n",
      "[138]\tvalid_0's tweedie: 275.841\n",
      "[139]\tvalid_0's tweedie: 275.842\n",
      "[140]\tvalid_0's tweedie: 275.842\n",
      "[141]\tvalid_0's tweedie: 275.842\n",
      "[142]\tvalid_0's tweedie: 275.841\n",
      "[143]\tvalid_0's tweedie: 275.842\n",
      "[144]\tvalid_0's tweedie: 275.843\n",
      "[145]\tvalid_0's tweedie: 275.842\n",
      "[146]\tvalid_0's tweedie: 275.842\n",
      "[147]\tvalid_0's tweedie: 275.842\n",
      "[148]\tvalid_0's tweedie: 275.842\n",
      "[149]\tvalid_0's tweedie: 275.842\n",
      "[150]\tvalid_0's tweedie: 275.842\n",
      "[151]\tvalid_0's tweedie: 275.842\n",
      "[152]\tvalid_0's tweedie: 275.842\n",
      "[153]\tvalid_0's tweedie: 275.842\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's tweedie: 275.841\n",
      "Training model for level 5 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5488\n",
      "[LightGBM] [Info] Number of data points in the train set: 12922, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499736\n",
      "[1]\tvalid_0's tweedie: 306.548\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.511\n",
      "[3]\tvalid_0's tweedie: 297.239\n",
      "[4]\tvalid_0's tweedie: 293.605\n",
      "[5]\tvalid_0's tweedie: 290.552\n",
      "[6]\tvalid_0's tweedie: 287.984\n",
      "[7]\tvalid_0's tweedie: 285.855\n",
      "[8]\tvalid_0's tweedie: 284.123\n",
      "[9]\tvalid_0's tweedie: 282.683\n",
      "[10]\tvalid_0's tweedie: 281.487\n",
      "[11]\tvalid_0's tweedie: 280.501\n",
      "[12]\tvalid_0's tweedie: 279.661\n",
      "[13]\tvalid_0's tweedie: 278.998\n",
      "[14]\tvalid_0's tweedie: 278.438\n",
      "[15]\tvalid_0's tweedie: 277.972\n",
      "[16]\tvalid_0's tweedie: 277.608\n",
      "[17]\tvalid_0's tweedie: 277.302\n",
      "[18]\tvalid_0's tweedie: 277.049\n",
      "[19]\tvalid_0's tweedie: 276.855\n",
      "[20]\tvalid_0's tweedie: 276.685\n",
      "[21]\tvalid_0's tweedie: 276.541\n",
      "[22]\tvalid_0's tweedie: 276.439\n",
      "[23]\tvalid_0's tweedie: 276.352\n",
      "[24]\tvalid_0's tweedie: 276.288\n",
      "[25]\tvalid_0's tweedie: 276.229\n",
      "[26]\tvalid_0's tweedie: 276.176\n",
      "[27]\tvalid_0's tweedie: 276.127\n",
      "[28]\tvalid_0's tweedie: 276.093\n",
      "[29]\tvalid_0's tweedie: 276.069\n",
      "[30]\tvalid_0's tweedie: 276.044\n",
      "[31]\tvalid_0's tweedie: 276.023\n",
      "[32]\tvalid_0's tweedie: 276.005\n",
      "[33]\tvalid_0's tweedie: 275.99\n",
      "[34]\tvalid_0's tweedie: 275.979\n",
      "[35]\tvalid_0's tweedie: 275.968\n",
      "[36]\tvalid_0's tweedie: 275.957\n",
      "[37]\tvalid_0's tweedie: 275.948\n",
      "[38]\tvalid_0's tweedie: 275.943\n",
      "[39]\tvalid_0's tweedie: 275.938\n",
      "[40]\tvalid_0's tweedie: 275.932\n",
      "[41]\tvalid_0's tweedie: 275.922\n",
      "[42]\tvalid_0's tweedie: 275.92\n",
      "[43]\tvalid_0's tweedie: 275.917\n",
      "[44]\tvalid_0's tweedie: 275.914\n",
      "[45]\tvalid_0's tweedie: 275.908\n",
      "[46]\tvalid_0's tweedie: 275.905\n",
      "[47]\tvalid_0's tweedie: 275.902\n",
      "[48]\tvalid_0's tweedie: 275.898\n",
      "[49]\tvalid_0's tweedie: 275.894\n",
      "[50]\tvalid_0's tweedie: 275.893\n",
      "[51]\tvalid_0's tweedie: 275.891\n",
      "[52]\tvalid_0's tweedie: 275.886\n",
      "[53]\tvalid_0's tweedie: 275.885\n",
      "[54]\tvalid_0's tweedie: 275.881\n",
      "[55]\tvalid_0's tweedie: 275.877\n",
      "[56]\tvalid_0's tweedie: 275.876\n",
      "[57]\tvalid_0's tweedie: 275.876\n",
      "[58]\tvalid_0's tweedie: 275.876\n",
      "[59]\tvalid_0's tweedie: 275.875\n",
      "[60]\tvalid_0's tweedie: 275.873\n",
      "[61]\tvalid_0's tweedie: 275.871\n",
      "[62]\tvalid_0's tweedie: 275.87\n",
      "[63]\tvalid_0's tweedie: 275.867\n",
      "[64]\tvalid_0's tweedie: 275.867\n",
      "[65]\tvalid_0's tweedie: 275.866\n",
      "[66]\tvalid_0's tweedie: 275.865\n",
      "[67]\tvalid_0's tweedie: 275.863\n",
      "[68]\tvalid_0's tweedie: 275.862\n",
      "[69]\tvalid_0's tweedie: 275.861\n",
      "[70]\tvalid_0's tweedie: 275.86\n",
      "[71]\tvalid_0's tweedie: 275.86\n",
      "[72]\tvalid_0's tweedie: 275.86\n",
      "[73]\tvalid_0's tweedie: 275.859\n",
      "[74]\tvalid_0's tweedie: 275.859\n",
      "[75]\tvalid_0's tweedie: 275.858\n",
      "[76]\tvalid_0's tweedie: 275.858\n",
      "[77]\tvalid_0's tweedie: 275.857\n",
      "[78]\tvalid_0's tweedie: 275.856\n",
      "[79]\tvalid_0's tweedie: 275.856\n",
      "[80]\tvalid_0's tweedie: 275.856\n",
      "[81]\tvalid_0's tweedie: 275.855\n",
      "[82]\tvalid_0's tweedie: 275.854\n",
      "[83]\tvalid_0's tweedie: 275.854\n",
      "[84]\tvalid_0's tweedie: 275.854\n",
      "[85]\tvalid_0's tweedie: 275.853\n",
      "[86]\tvalid_0's tweedie: 275.854\n",
      "[87]\tvalid_0's tweedie: 275.853\n",
      "[88]\tvalid_0's tweedie: 275.853\n",
      "[89]\tvalid_0's tweedie: 275.853\n",
      "[90]\tvalid_0's tweedie: 275.852\n",
      "[91]\tvalid_0's tweedie: 275.852\n",
      "[92]\tvalid_0's tweedie: 275.852\n",
      "[93]\tvalid_0's tweedie: 275.851\n",
      "[94]\tvalid_0's tweedie: 275.851\n",
      "[95]\tvalid_0's tweedie: 275.851\n",
      "[96]\tvalid_0's tweedie: 275.851\n",
      "[97]\tvalid_0's tweedie: 275.851\n",
      "[98]\tvalid_0's tweedie: 275.851\n",
      "[99]\tvalid_0's tweedie: 275.851\n",
      "[100]\tvalid_0's tweedie: 275.852\n",
      "[101]\tvalid_0's tweedie: 275.852\n",
      "[102]\tvalid_0's tweedie: 275.851\n",
      "[103]\tvalid_0's tweedie: 275.852\n",
      "[104]\tvalid_0's tweedie: 275.852\n",
      "[105]\tvalid_0's tweedie: 275.852\n",
      "[106]\tvalid_0's tweedie: 275.851\n",
      "[107]\tvalid_0's tweedie: 275.851\n",
      "[108]\tvalid_0's tweedie: 275.851\n",
      "[109]\tvalid_0's tweedie: 275.851\n",
      "[110]\tvalid_0's tweedie: 275.85\n",
      "[111]\tvalid_0's tweedie: 275.85\n",
      "[112]\tvalid_0's tweedie: 275.848\n",
      "[113]\tvalid_0's tweedie: 275.847\n",
      "[114]\tvalid_0's tweedie: 275.847\n",
      "[115]\tvalid_0's tweedie: 275.847\n",
      "[116]\tvalid_0's tweedie: 275.847\n",
      "[117]\tvalid_0's tweedie: 275.846\n",
      "[118]\tvalid_0's tweedie: 275.846\n",
      "[119]\tvalid_0's tweedie: 275.846\n",
      "[120]\tvalid_0's tweedie: 275.846\n",
      "[121]\tvalid_0's tweedie: 275.846\n",
      "[122]\tvalid_0's tweedie: 275.845\n",
      "[123]\tvalid_0's tweedie: 275.845\n",
      "[124]\tvalid_0's tweedie: 275.845\n",
      "[125]\tvalid_0's tweedie: 275.845\n",
      "[126]\tvalid_0's tweedie: 275.845\n",
      "[127]\tvalid_0's tweedie: 275.845\n",
      "[128]\tvalid_0's tweedie: 275.844\n",
      "[129]\tvalid_0's tweedie: 275.845\n",
      "[130]\tvalid_0's tweedie: 275.845\n",
      "[131]\tvalid_0's tweedie: 275.845\n",
      "[132]\tvalid_0's tweedie: 275.845\n",
      "[133]\tvalid_0's tweedie: 275.845\n",
      "[134]\tvalid_0's tweedie: 275.844\n",
      "[135]\tvalid_0's tweedie: 275.844\n",
      "[136]\tvalid_0's tweedie: 275.843\n",
      "[137]\tvalid_0's tweedie: 275.843\n",
      "[138]\tvalid_0's tweedie: 275.843\n",
      "[139]\tvalid_0's tweedie: 275.845\n",
      "[140]\tvalid_0's tweedie: 275.845\n",
      "[141]\tvalid_0's tweedie: 275.845\n",
      "[142]\tvalid_0's tweedie: 275.845\n",
      "[143]\tvalid_0's tweedie: 275.845\n",
      "[144]\tvalid_0's tweedie: 275.844\n",
      "[145]\tvalid_0's tweedie: 275.844\n",
      "[146]\tvalid_0's tweedie: 275.844\n",
      "[147]\tvalid_0's tweedie: 275.844\n",
      "[148]\tvalid_0's tweedie: 275.844\n",
      "[149]\tvalid_0's tweedie: 275.844\n",
      "[150]\tvalid_0's tweedie: 275.844\n",
      "[151]\tvalid_0's tweedie: 275.843\n",
      "[152]\tvalid_0's tweedie: 275.844\n",
      "[153]\tvalid_0's tweedie: 275.843\n",
      "[154]\tvalid_0's tweedie: 275.843\n",
      "[155]\tvalid_0's tweedie: 275.843\n",
      "[156]\tvalid_0's tweedie: 275.842\n",
      "[157]\tvalid_0's tweedie: 275.842\n",
      "[158]\tvalid_0's tweedie: 275.842\n",
      "[159]\tvalid_0's tweedie: 275.842\n",
      "[160]\tvalid_0's tweedie: 275.842\n",
      "[161]\tvalid_0's tweedie: 275.841\n",
      "[162]\tvalid_0's tweedie: 275.841\n",
      "[163]\tvalid_0's tweedie: 275.841\n",
      "[164]\tvalid_0's tweedie: 275.841\n",
      "[165]\tvalid_0's tweedie: 275.841\n",
      "[166]\tvalid_0's tweedie: 275.841\n",
      "[167]\tvalid_0's tweedie: 275.841\n",
      "[168]\tvalid_0's tweedie: 275.841\n",
      "[169]\tvalid_0's tweedie: 275.842\n",
      "[170]\tvalid_0's tweedie: 275.842\n",
      "[171]\tvalid_0's tweedie: 275.842\n",
      "[172]\tvalid_0's tweedie: 275.842\n",
      "[173]\tvalid_0's tweedie: 275.842\n",
      "[174]\tvalid_0's tweedie: 275.842\n",
      "[175]\tvalid_0's tweedie: 275.842\n",
      "[176]\tvalid_0's tweedie: 275.842\n",
      "[177]\tvalid_0's tweedie: 275.841\n",
      "[178]\tvalid_0's tweedie: 275.841\n",
      "[179]\tvalid_0's tweedie: 275.841\n",
      "[180]\tvalid_0's tweedie: 275.841\n",
      "[181]\tvalid_0's tweedie: 275.841\n",
      "[182]\tvalid_0's tweedie: 275.841\n",
      "[183]\tvalid_0's tweedie: 275.841\n",
      "[184]\tvalid_0's tweedie: 275.841\n",
      "[185]\tvalid_0's tweedie: 275.841\n",
      "[186]\tvalid_0's tweedie: 275.841\n",
      "[187]\tvalid_0's tweedie: 275.842\n",
      "[188]\tvalid_0's tweedie: 275.841\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's tweedie: 275.841\n",
      "Training model for level 5 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5487\n",
      "[LightGBM] [Info] Number of data points in the train set: 12915, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.499923\n",
      "[1]\tvalid_0's tweedie: 306.559\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.513\n",
      "[3]\tvalid_0's tweedie: 297.253\n",
      "[4]\tvalid_0's tweedie: 293.624\n",
      "[5]\tvalid_0's tweedie: 290.554\n",
      "[6]\tvalid_0's tweedie: 287.989\n",
      "[7]\tvalid_0's tweedie: 285.861\n",
      "[8]\tvalid_0's tweedie: 284.121\n",
      "[9]\tvalid_0's tweedie: 282.673\n",
      "[10]\tvalid_0's tweedie: 281.494\n",
      "[11]\tvalid_0's tweedie: 280.495\n",
      "[12]\tvalid_0's tweedie: 279.684\n",
      "[13]\tvalid_0's tweedie: 278.999\n",
      "[14]\tvalid_0's tweedie: 278.444\n",
      "[15]\tvalid_0's tweedie: 277.992\n",
      "[16]\tvalid_0's tweedie: 277.617\n",
      "[17]\tvalid_0's tweedie: 277.314\n",
      "[18]\tvalid_0's tweedie: 277.061\n",
      "[19]\tvalid_0's tweedie: 276.869\n",
      "[20]\tvalid_0's tweedie: 276.713\n",
      "[21]\tvalid_0's tweedie: 276.577\n",
      "[22]\tvalid_0's tweedie: 276.462\n",
      "[23]\tvalid_0's tweedie: 276.362\n",
      "[24]\tvalid_0's tweedie: 276.293\n",
      "[25]\tvalid_0's tweedie: 276.23\n",
      "[26]\tvalid_0's tweedie: 276.177\n",
      "[27]\tvalid_0's tweedie: 276.132\n",
      "[28]\tvalid_0's tweedie: 276.104\n",
      "[29]\tvalid_0's tweedie: 276.071\n",
      "[30]\tvalid_0's tweedie: 276.048\n",
      "[31]\tvalid_0's tweedie: 276.026\n",
      "[32]\tvalid_0's tweedie: 276.01\n",
      "[33]\tvalid_0's tweedie: 275.995\n",
      "[34]\tvalid_0's tweedie: 275.983\n",
      "[35]\tvalid_0's tweedie: 275.968\n",
      "[36]\tvalid_0's tweedie: 275.959\n",
      "[37]\tvalid_0's tweedie: 275.951\n",
      "[38]\tvalid_0's tweedie: 275.944\n",
      "[39]\tvalid_0's tweedie: 275.938\n",
      "[40]\tvalid_0's tweedie: 275.927\n",
      "[41]\tvalid_0's tweedie: 275.92\n",
      "[42]\tvalid_0's tweedie: 275.916\n",
      "[43]\tvalid_0's tweedie: 275.908\n",
      "[44]\tvalid_0's tweedie: 275.906\n",
      "[45]\tvalid_0's tweedie: 275.9\n",
      "[46]\tvalid_0's tweedie: 275.899\n",
      "[47]\tvalid_0's tweedie: 275.894\n",
      "[48]\tvalid_0's tweedie: 275.891\n",
      "[49]\tvalid_0's tweedie: 275.89\n",
      "[50]\tvalid_0's tweedie: 275.887\n",
      "[51]\tvalid_0's tweedie: 275.884\n",
      "[52]\tvalid_0's tweedie: 275.881\n",
      "[53]\tvalid_0's tweedie: 275.879\n",
      "[54]\tvalid_0's tweedie: 275.877\n",
      "[55]\tvalid_0's tweedie: 275.877\n",
      "[56]\tvalid_0's tweedie: 275.876\n",
      "[57]\tvalid_0's tweedie: 275.874\n",
      "[58]\tvalid_0's tweedie: 275.873\n",
      "[59]\tvalid_0's tweedie: 275.872\n",
      "[60]\tvalid_0's tweedie: 275.872\n",
      "[61]\tvalid_0's tweedie: 275.871\n",
      "[62]\tvalid_0's tweedie: 275.87\n",
      "[63]\tvalid_0's tweedie: 275.867\n",
      "[64]\tvalid_0's tweedie: 275.867\n",
      "[65]\tvalid_0's tweedie: 275.866\n",
      "[66]\tvalid_0's tweedie: 275.865\n",
      "[67]\tvalid_0's tweedie: 275.865\n",
      "[68]\tvalid_0's tweedie: 275.865\n",
      "[69]\tvalid_0's tweedie: 275.865\n",
      "[70]\tvalid_0's tweedie: 275.866\n",
      "[71]\tvalid_0's tweedie: 275.865\n",
      "[72]\tvalid_0's tweedie: 275.863\n",
      "[73]\tvalid_0's tweedie: 275.863\n",
      "[74]\tvalid_0's tweedie: 275.862\n",
      "[75]\tvalid_0's tweedie: 275.861\n",
      "[76]\tvalid_0's tweedie: 275.861\n",
      "[77]\tvalid_0's tweedie: 275.86\n",
      "[78]\tvalid_0's tweedie: 275.86\n",
      "[79]\tvalid_0's tweedie: 275.859\n",
      "[80]\tvalid_0's tweedie: 275.86\n",
      "[81]\tvalid_0's tweedie: 275.859\n",
      "[82]\tvalid_0's tweedie: 275.859\n",
      "[83]\tvalid_0's tweedie: 275.859\n",
      "[84]\tvalid_0's tweedie: 275.859\n",
      "[85]\tvalid_0's tweedie: 275.859\n",
      "[86]\tvalid_0's tweedie: 275.858\n",
      "[87]\tvalid_0's tweedie: 275.858\n",
      "[88]\tvalid_0's tweedie: 275.857\n",
      "[89]\tvalid_0's tweedie: 275.857\n",
      "[90]\tvalid_0's tweedie: 275.856\n",
      "[91]\tvalid_0's tweedie: 275.856\n",
      "[92]\tvalid_0's tweedie: 275.857\n",
      "[93]\tvalid_0's tweedie: 275.857\n",
      "[94]\tvalid_0's tweedie: 275.857\n",
      "[95]\tvalid_0's tweedie: 275.857\n",
      "[96]\tvalid_0's tweedie: 275.857\n",
      "[97]\tvalid_0's tweedie: 275.857\n",
      "[98]\tvalid_0's tweedie: 275.856\n",
      "[99]\tvalid_0's tweedie: 275.856\n",
      "[100]\tvalid_0's tweedie: 275.856\n",
      "[101]\tvalid_0's tweedie: 275.856\n",
      "[102]\tvalid_0's tweedie: 275.855\n",
      "[103]\tvalid_0's tweedie: 275.854\n",
      "[104]\tvalid_0's tweedie: 275.854\n",
      "[105]\tvalid_0's tweedie: 275.853\n",
      "[106]\tvalid_0's tweedie: 275.853\n",
      "[107]\tvalid_0's tweedie: 275.857\n",
      "[108]\tvalid_0's tweedie: 275.859\n",
      "[109]\tvalid_0's tweedie: 275.859\n",
      "[110]\tvalid_0's tweedie: 275.858\n",
      "[111]\tvalid_0's tweedie: 275.858\n",
      "[112]\tvalid_0's tweedie: 275.857\n",
      "[113]\tvalid_0's tweedie: 275.858\n",
      "[114]\tvalid_0's tweedie: 275.858\n",
      "[115]\tvalid_0's tweedie: 275.857\n",
      "[116]\tvalid_0's tweedie: 275.857\n",
      "[117]\tvalid_0's tweedie: 275.857\n",
      "[118]\tvalid_0's tweedie: 275.857\n",
      "[119]\tvalid_0's tweedie: 275.856\n",
      "[120]\tvalid_0's tweedie: 275.856\n",
      "[121]\tvalid_0's tweedie: 275.856\n",
      "[122]\tvalid_0's tweedie: 275.856\n",
      "[123]\tvalid_0's tweedie: 275.856\n",
      "[124]\tvalid_0's tweedie: 275.856\n",
      "[125]\tvalid_0's tweedie: 275.857\n",
      "[126]\tvalid_0's tweedie: 275.857\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's tweedie: 275.853\n",
      "Training model for level 5 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/5/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5486\n",
      "[LightGBM] [Info] Number of data points in the train set: 12908, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 8.500108\n",
      "[1]\tvalid_0's tweedie: 306.542\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 301.498\n",
      "[3]\tvalid_0's tweedie: 297.227\n",
      "[4]\tvalid_0's tweedie: 293.591\n",
      "[5]\tvalid_0's tweedie: 290.542\n",
      "[6]\tvalid_0's tweedie: 288.002\n",
      "[7]\tvalid_0's tweedie: 285.864\n",
      "[8]\tvalid_0's tweedie: 284.096\n",
      "[9]\tvalid_0's tweedie: 282.626\n",
      "[10]\tvalid_0's tweedie: 281.434\n",
      "[11]\tvalid_0's tweedie: 280.454\n",
      "[12]\tvalid_0's tweedie: 279.606\n",
      "[13]\tvalid_0's tweedie: 278.938\n",
      "[14]\tvalid_0's tweedie: 278.408\n",
      "[15]\tvalid_0's tweedie: 277.969\n",
      "[16]\tvalid_0's tweedie: 277.608\n",
      "[17]\tvalid_0's tweedie: 277.303\n",
      "[18]\tvalid_0's tweedie: 277.045\n",
      "[19]\tvalid_0's tweedie: 276.841\n",
      "[20]\tvalid_0's tweedie: 276.677\n",
      "[21]\tvalid_0's tweedie: 276.548\n",
      "[22]\tvalid_0's tweedie: 276.446\n",
      "[23]\tvalid_0's tweedie: 276.353\n",
      "[24]\tvalid_0's tweedie: 276.279\n",
      "[25]\tvalid_0's tweedie: 276.219\n",
      "[26]\tvalid_0's tweedie: 276.17\n",
      "[27]\tvalid_0's tweedie: 276.133\n",
      "[28]\tvalid_0's tweedie: 276.097\n",
      "[29]\tvalid_0's tweedie: 276.074\n",
      "[30]\tvalid_0's tweedie: 276.05\n",
      "[31]\tvalid_0's tweedie: 276.034\n",
      "[32]\tvalid_0's tweedie: 276.015\n",
      "[33]\tvalid_0's tweedie: 275.997\n",
      "[34]\tvalid_0's tweedie: 275.983\n",
      "[35]\tvalid_0's tweedie: 275.977\n",
      "[36]\tvalid_0's tweedie: 275.967\n",
      "[37]\tvalid_0's tweedie: 275.956\n",
      "[38]\tvalid_0's tweedie: 275.95\n",
      "[39]\tvalid_0's tweedie: 275.945\n",
      "[40]\tvalid_0's tweedie: 275.938\n",
      "[41]\tvalid_0's tweedie: 275.931\n",
      "[42]\tvalid_0's tweedie: 275.928\n",
      "[43]\tvalid_0's tweedie: 275.918\n",
      "[44]\tvalid_0's tweedie: 275.914\n",
      "[45]\tvalid_0's tweedie: 275.91\n",
      "[46]\tvalid_0's tweedie: 275.907\n",
      "[47]\tvalid_0's tweedie: 275.899\n",
      "[48]\tvalid_0's tweedie: 275.894\n",
      "[49]\tvalid_0's tweedie: 275.894\n",
      "[50]\tvalid_0's tweedie: 275.891\n",
      "[51]\tvalid_0's tweedie: 275.886\n",
      "[52]\tvalid_0's tweedie: 275.884\n",
      "[53]\tvalid_0's tweedie: 275.88\n",
      "[54]\tvalid_0's tweedie: 275.879\n",
      "[55]\tvalid_0's tweedie: 275.877\n",
      "[56]\tvalid_0's tweedie: 275.876\n",
      "[57]\tvalid_0's tweedie: 275.874\n",
      "[58]\tvalid_0's tweedie: 275.871\n",
      "[59]\tvalid_0's tweedie: 275.869\n",
      "[60]\tvalid_0's tweedie: 275.868\n",
      "[61]\tvalid_0's tweedie: 275.866\n",
      "[62]\tvalid_0's tweedie: 275.864\n",
      "[63]\tvalid_0's tweedie: 275.864\n",
      "[64]\tvalid_0's tweedie: 275.862\n",
      "[65]\tvalid_0's tweedie: 275.861\n",
      "[66]\tvalid_0's tweedie: 275.86\n",
      "[67]\tvalid_0's tweedie: 275.859\n",
      "[68]\tvalid_0's tweedie: 275.856\n",
      "[69]\tvalid_0's tweedie: 275.855\n",
      "[70]\tvalid_0's tweedie: 275.853\n",
      "[71]\tvalid_0's tweedie: 275.853\n",
      "[72]\tvalid_0's tweedie: 275.852\n",
      "[73]\tvalid_0's tweedie: 275.851\n",
      "[74]\tvalid_0's tweedie: 275.852\n",
      "[75]\tvalid_0's tweedie: 275.852\n",
      "[76]\tvalid_0's tweedie: 275.853\n",
      "[77]\tvalid_0's tweedie: 275.852\n",
      "[78]\tvalid_0's tweedie: 275.851\n",
      "[79]\tvalid_0's tweedie: 275.851\n",
      "[80]\tvalid_0's tweedie: 275.851\n",
      "[81]\tvalid_0's tweedie: 275.85\n",
      "[82]\tvalid_0's tweedie: 275.85\n",
      "[83]\tvalid_0's tweedie: 275.849\n",
      "[84]\tvalid_0's tweedie: 275.85\n",
      "[85]\tvalid_0's tweedie: 275.85\n",
      "[86]\tvalid_0's tweedie: 275.85\n",
      "[87]\tvalid_0's tweedie: 275.85\n",
      "[88]\tvalid_0's tweedie: 275.85\n",
      "[89]\tvalid_0's tweedie: 275.85\n",
      "[90]\tvalid_0's tweedie: 275.85\n",
      "[91]\tvalid_0's tweedie: 275.85\n",
      "[92]\tvalid_0's tweedie: 275.85\n",
      "[93]\tvalid_0's tweedie: 275.849\n",
      "[94]\tvalid_0's tweedie: 275.85\n",
      "[95]\tvalid_0's tweedie: 275.849\n",
      "[96]\tvalid_0's tweedie: 275.849\n",
      "[97]\tvalid_0's tweedie: 275.848\n",
      "[98]\tvalid_0's tweedie: 275.848\n",
      "[99]\tvalid_0's tweedie: 275.848\n",
      "[100]\tvalid_0's tweedie: 275.847\n",
      "[101]\tvalid_0's tweedie: 275.847\n",
      "[102]\tvalid_0's tweedie: 275.847\n",
      "[103]\tvalid_0's tweedie: 275.848\n",
      "[104]\tvalid_0's tweedie: 275.848\n",
      "[105]\tvalid_0's tweedie: 275.847\n",
      "[106]\tvalid_0's tweedie: 275.847\n",
      "[107]\tvalid_0's tweedie: 275.847\n",
      "[108]\tvalid_0's tweedie: 275.847\n",
      "[109]\tvalid_0's tweedie: 275.847\n",
      "[110]\tvalid_0's tweedie: 275.848\n",
      "[111]\tvalid_0's tweedie: 275.848\n",
      "[112]\tvalid_0's tweedie: 275.848\n",
      "[113]\tvalid_0's tweedie: 275.848\n",
      "[114]\tvalid_0's tweedie: 275.847\n",
      "[115]\tvalid_0's tweedie: 275.847\n",
      "[116]\tvalid_0's tweedie: 275.848\n",
      "[117]\tvalid_0's tweedie: 275.847\n",
      "[118]\tvalid_0's tweedie: 275.847\n",
      "[119]\tvalid_0's tweedie: 275.846\n",
      "[120]\tvalid_0's tweedie: 275.846\n",
      "[121]\tvalid_0's tweedie: 275.847\n",
      "[122]\tvalid_0's tweedie: 275.847\n",
      "[123]\tvalid_0's tweedie: 275.847\n",
      "[124]\tvalid_0's tweedie: 275.847\n",
      "[125]\tvalid_0's tweedie: 275.847\n",
      "[126]\tvalid_0's tweedie: 275.847\n",
      "[127]\tvalid_0's tweedie: 275.846\n",
      "[128]\tvalid_0's tweedie: 275.846\n",
      "[129]\tvalid_0's tweedie: 275.846\n",
      "[130]\tvalid_0's tweedie: 275.846\n",
      "[131]\tvalid_0's tweedie: 275.846\n",
      "[132]\tvalid_0's tweedie: 275.846\n",
      "[133]\tvalid_0's tweedie: 275.846\n",
      "[134]\tvalid_0's tweedie: 275.846\n",
      "[135]\tvalid_0's tweedie: 275.847\n",
      "[136]\tvalid_0's tweedie: 275.848\n",
      "[137]\tvalid_0's tweedie: 275.848\n",
      "[138]\tvalid_0's tweedie: 275.848\n",
      "[139]\tvalid_0's tweedie: 275.847\n",
      "[140]\tvalid_0's tweedie: 275.847\n",
      "[141]\tvalid_0's tweedie: 275.847\n",
      "[142]\tvalid_0's tweedie: 275.847\n",
      "[143]\tvalid_0's tweedie: 275.847\n",
      "[144]\tvalid_0's tweedie: 275.846\n",
      "[145]\tvalid_0's tweedie: 275.846\n",
      "[146]\tvalid_0's tweedie: 275.846\n",
      "[147]\tvalid_0's tweedie: 275.846\n",
      "[148]\tvalid_0's tweedie: 275.846\n",
      "[149]\tvalid_0's tweedie: 275.845\n",
      "[150]\tvalid_0's tweedie: 275.845\n",
      "[151]\tvalid_0's tweedie: 275.845\n",
      "[152]\tvalid_0's tweedie: 275.847\n",
      "[153]\tvalid_0's tweedie: 275.847\n",
      "[154]\tvalid_0's tweedie: 275.847\n",
      "[155]\tvalid_0's tweedie: 275.847\n",
      "[156]\tvalid_0's tweedie: 275.847\n",
      "[157]\tvalid_0's tweedie: 275.847\n",
      "[158]\tvalid_0's tweedie: 275.846\n",
      "[159]\tvalid_0's tweedie: 275.846\n",
      "[160]\tvalid_0's tweedie: 275.846\n",
      "[161]\tvalid_0's tweedie: 275.847\n",
      "[162]\tvalid_0's tweedie: 275.847\n",
      "[163]\tvalid_0's tweedie: 275.848\n",
      "[164]\tvalid_0's tweedie: 275.848\n",
      "[165]\tvalid_0's tweedie: 275.848\n",
      "[166]\tvalid_0's tweedie: 275.847\n",
      "[167]\tvalid_0's tweedie: 275.847\n",
      "[168]\tvalid_0's tweedie: 275.848\n",
      "[169]\tvalid_0's tweedie: 275.848\n",
      "[170]\tvalid_0's tweedie: 275.849\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's tweedie: 275.845\n",
      "Training model for level 6\n",
      "Training model for level 6 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 16839, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.244949\n",
      "[1]\tvalid_0's tweedie: 271.611\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.264\n",
      "[3]\tvalid_0's tweedie: 265.494\n",
      "[4]\tvalid_0's tweedie: 263.179\n",
      "[5]\tvalid_0's tweedie: 261.285\n",
      "[6]\tvalid_0's tweedie: 259.725\n",
      "[7]\tvalid_0's tweedie: 258.443\n",
      "[8]\tvalid_0's tweedie: 257.398\n",
      "[9]\tvalid_0's tweedie: 256.544\n",
      "[10]\tvalid_0's tweedie: 255.824\n",
      "[11]\tvalid_0's tweedie: 255.247\n",
      "[12]\tvalid_0's tweedie: 254.783\n",
      "[13]\tvalid_0's tweedie: 254.398\n",
      "[14]\tvalid_0's tweedie: 254.072\n",
      "[15]\tvalid_0's tweedie: 253.813\n",
      "[16]\tvalid_0's tweedie: 253.6\n",
      "[17]\tvalid_0's tweedie: 253.43\n",
      "[18]\tvalid_0's tweedie: 253.285\n",
      "[19]\tvalid_0's tweedie: 253.167\n",
      "[20]\tvalid_0's tweedie: 253.07\n",
      "[21]\tvalid_0's tweedie: 252.991\n",
      "[22]\tvalid_0's tweedie: 252.919\n",
      "[23]\tvalid_0's tweedie: 252.865\n",
      "[24]\tvalid_0's tweedie: 252.817\n",
      "[25]\tvalid_0's tweedie: 252.778\n",
      "[26]\tvalid_0's tweedie: 252.748\n",
      "[27]\tvalid_0's tweedie: 252.722\n",
      "[28]\tvalid_0's tweedie: 252.699\n",
      "[29]\tvalid_0's tweedie: 252.679\n",
      "[30]\tvalid_0's tweedie: 252.662\n",
      "[31]\tvalid_0's tweedie: 252.648\n",
      "[32]\tvalid_0's tweedie: 252.637\n",
      "[33]\tvalid_0's tweedie: 252.628\n",
      "[34]\tvalid_0's tweedie: 252.62\n",
      "[35]\tvalid_0's tweedie: 252.613\n",
      "[36]\tvalid_0's tweedie: 252.606\n",
      "[37]\tvalid_0's tweedie: 252.602\n",
      "[38]\tvalid_0's tweedie: 252.597\n",
      "[39]\tvalid_0's tweedie: 252.594\n",
      "[40]\tvalid_0's tweedie: 252.591\n",
      "[41]\tvalid_0's tweedie: 252.586\n",
      "[42]\tvalid_0's tweedie: 252.583\n",
      "[43]\tvalid_0's tweedie: 252.581\n",
      "[44]\tvalid_0's tweedie: 252.579\n",
      "[45]\tvalid_0's tweedie: 252.578\n",
      "[46]\tvalid_0's tweedie: 252.578\n",
      "[47]\tvalid_0's tweedie: 252.578\n",
      "[48]\tvalid_0's tweedie: 252.579\n",
      "[49]\tvalid_0's tweedie: 252.577\n",
      "[50]\tvalid_0's tweedie: 252.578\n",
      "[51]\tvalid_0's tweedie: 252.578\n",
      "[52]\tvalid_0's tweedie: 252.576\n",
      "[53]\tvalid_0's tweedie: 252.578\n",
      "[54]\tvalid_0's tweedie: 252.577\n",
      "[55]\tvalid_0's tweedie: 252.577\n",
      "[56]\tvalid_0's tweedie: 252.577\n",
      "[57]\tvalid_0's tweedie: 252.577\n",
      "[58]\tvalid_0's tweedie: 252.577\n",
      "[59]\tvalid_0's tweedie: 252.576\n",
      "[60]\tvalid_0's tweedie: 252.575\n",
      "[61]\tvalid_0's tweedie: 252.575\n",
      "[62]\tvalid_0's tweedie: 252.574\n",
      "[63]\tvalid_0's tweedie: 252.574\n",
      "[64]\tvalid_0's tweedie: 252.573\n",
      "[65]\tvalid_0's tweedie: 252.573\n",
      "[66]\tvalid_0's tweedie: 252.572\n",
      "[67]\tvalid_0's tweedie: 252.573\n",
      "[68]\tvalid_0's tweedie: 252.573\n",
      "[69]\tvalid_0's tweedie: 252.572\n",
      "[70]\tvalid_0's tweedie: 252.573\n",
      "[71]\tvalid_0's tweedie: 252.573\n",
      "[72]\tvalid_0's tweedie: 252.572\n",
      "[73]\tvalid_0's tweedie: 252.572\n",
      "[74]\tvalid_0's tweedie: 252.572\n",
      "[75]\tvalid_0's tweedie: 252.572\n",
      "[76]\tvalid_0's tweedie: 252.572\n",
      "[77]\tvalid_0's tweedie: 252.571\n",
      "[78]\tvalid_0's tweedie: 252.571\n",
      "[79]\tvalid_0's tweedie: 252.569\n",
      "[80]\tvalid_0's tweedie: 252.569\n",
      "[81]\tvalid_0's tweedie: 252.57\n",
      "[82]\tvalid_0's tweedie: 252.57\n",
      "[83]\tvalid_0's tweedie: 252.57\n",
      "[84]\tvalid_0's tweedie: 252.569\n",
      "[85]\tvalid_0's tweedie: 252.569\n",
      "[86]\tvalid_0's tweedie: 252.569\n",
      "[87]\tvalid_0's tweedie: 252.569\n",
      "[88]\tvalid_0's tweedie: 252.569\n",
      "[89]\tvalid_0's tweedie: 252.568\n",
      "[90]\tvalid_0's tweedie: 252.568\n",
      "[91]\tvalid_0's tweedie: 252.568\n",
      "[92]\tvalid_0's tweedie: 252.569\n",
      "[93]\tvalid_0's tweedie: 252.569\n",
      "[94]\tvalid_0's tweedie: 252.569\n",
      "[95]\tvalid_0's tweedie: 252.568\n",
      "[96]\tvalid_0's tweedie: 252.568\n",
      "[97]\tvalid_0's tweedie: 252.567\n",
      "[98]\tvalid_0's tweedie: 252.567\n",
      "[99]\tvalid_0's tweedie: 252.566\n",
      "[100]\tvalid_0's tweedie: 252.566\n",
      "[101]\tvalid_0's tweedie: 252.566\n",
      "[102]\tvalid_0's tweedie: 252.566\n",
      "[103]\tvalid_0's tweedie: 252.566\n",
      "[104]\tvalid_0's tweedie: 252.566\n",
      "[105]\tvalid_0's tweedie: 252.566\n",
      "[106]\tvalid_0's tweedie: 252.566\n",
      "[107]\tvalid_0's tweedie: 252.566\n",
      "[108]\tvalid_0's tweedie: 252.565\n",
      "[109]\tvalid_0's tweedie: 252.565\n",
      "[110]\tvalid_0's tweedie: 252.565\n",
      "[111]\tvalid_0's tweedie: 252.565\n",
      "[112]\tvalid_0's tweedie: 252.563\n",
      "[113]\tvalid_0's tweedie: 252.563\n",
      "[114]\tvalid_0's tweedie: 252.563\n",
      "[115]\tvalid_0's tweedie: 252.563\n",
      "[116]\tvalid_0's tweedie: 252.563\n",
      "[117]\tvalid_0's tweedie: 252.563\n",
      "[118]\tvalid_0's tweedie: 252.562\n",
      "[119]\tvalid_0's tweedie: 252.562\n",
      "[120]\tvalid_0's tweedie: 252.561\n",
      "[121]\tvalid_0's tweedie: 252.561\n",
      "[122]\tvalid_0's tweedie: 252.561\n",
      "[123]\tvalid_0's tweedie: 252.561\n",
      "[124]\tvalid_0's tweedie: 252.56\n",
      "[125]\tvalid_0's tweedie: 252.56\n",
      "[126]\tvalid_0's tweedie: 252.56\n",
      "[127]\tvalid_0's tweedie: 252.56\n",
      "[128]\tvalid_0's tweedie: 252.559\n",
      "[129]\tvalid_0's tweedie: 252.559\n",
      "[130]\tvalid_0's tweedie: 252.559\n",
      "[131]\tvalid_0's tweedie: 252.559\n",
      "[132]\tvalid_0's tweedie: 252.559\n",
      "[133]\tvalid_0's tweedie: 252.557\n",
      "[134]\tvalid_0's tweedie: 252.557\n",
      "[135]\tvalid_0's tweedie: 252.557\n",
      "[136]\tvalid_0's tweedie: 252.557\n",
      "[137]\tvalid_0's tweedie: 252.557\n",
      "[138]\tvalid_0's tweedie: 252.557\n",
      "[139]\tvalid_0's tweedie: 252.557\n",
      "[140]\tvalid_0's tweedie: 252.557\n",
      "[141]\tvalid_0's tweedie: 252.557\n",
      "[142]\tvalid_0's tweedie: 252.557\n",
      "[143]\tvalid_0's tweedie: 252.556\n",
      "[144]\tvalid_0's tweedie: 252.556\n",
      "[145]\tvalid_0's tweedie: 252.556\n",
      "[146]\tvalid_0's tweedie: 252.556\n",
      "[147]\tvalid_0's tweedie: 252.555\n",
      "[148]\tvalid_0's tweedie: 252.556\n",
      "[149]\tvalid_0's tweedie: 252.555\n",
      "[150]\tvalid_0's tweedie: 252.556\n",
      "[151]\tvalid_0's tweedie: 252.555\n",
      "[152]\tvalid_0's tweedie: 252.556\n",
      "[153]\tvalid_0's tweedie: 252.555\n",
      "[154]\tvalid_0's tweedie: 252.555\n",
      "[155]\tvalid_0's tweedie: 252.554\n",
      "[156]\tvalid_0's tweedie: 252.554\n",
      "[157]\tvalid_0's tweedie: 252.554\n",
      "[158]\tvalid_0's tweedie: 252.553\n",
      "[159]\tvalid_0's tweedie: 252.553\n",
      "[160]\tvalid_0's tweedie: 252.553\n",
      "[161]\tvalid_0's tweedie: 252.553\n",
      "[162]\tvalid_0's tweedie: 252.553\n",
      "[163]\tvalid_0's tweedie: 252.553\n",
      "[164]\tvalid_0's tweedie: 252.553\n",
      "[165]\tvalid_0's tweedie: 252.553\n",
      "[166]\tvalid_0's tweedie: 252.554\n",
      "[167]\tvalid_0's tweedie: 252.554\n",
      "[168]\tvalid_0's tweedie: 252.554\n",
      "[169]\tvalid_0's tweedie: 252.553\n",
      "[170]\tvalid_0's tweedie: 252.553\n",
      "[171]\tvalid_0's tweedie: 252.553\n",
      "[172]\tvalid_0's tweedie: 252.553\n",
      "[173]\tvalid_0's tweedie: 252.553\n",
      "[174]\tvalid_0's tweedie: 252.553\n",
      "[175]\tvalid_0's tweedie: 252.552\n",
      "[176]\tvalid_0's tweedie: 252.552\n",
      "[177]\tvalid_0's tweedie: 252.552\n",
      "[178]\tvalid_0's tweedie: 252.552\n",
      "[179]\tvalid_0's tweedie: 252.552\n",
      "[180]\tvalid_0's tweedie: 252.552\n",
      "[181]\tvalid_0's tweedie: 252.551\n",
      "[182]\tvalid_0's tweedie: 252.551\n",
      "[183]\tvalid_0's tweedie: 252.551\n",
      "[184]\tvalid_0's tweedie: 252.552\n",
      "[185]\tvalid_0's tweedie: 252.552\n",
      "[186]\tvalid_0's tweedie: 252.552\n",
      "[187]\tvalid_0's tweedie: 252.552\n",
      "[188]\tvalid_0's tweedie: 252.552\n",
      "[189]\tvalid_0's tweedie: 252.551\n",
      "[190]\tvalid_0's tweedie: 252.551\n",
      "[191]\tvalid_0's tweedie: 252.551\n",
      "[192]\tvalid_0's tweedie: 252.551\n",
      "[193]\tvalid_0's tweedie: 252.551\n",
      "[194]\tvalid_0's tweedie: 252.551\n",
      "[195]\tvalid_0's tweedie: 252.551\n",
      "[196]\tvalid_0's tweedie: 252.551\n",
      "[197]\tvalid_0's tweedie: 252.551\n",
      "[198]\tvalid_0's tweedie: 252.551\n",
      "[199]\tvalid_0's tweedie: 252.551\n",
      "[200]\tvalid_0's tweedie: 252.551\n",
      "[201]\tvalid_0's tweedie: 252.551\n",
      "[202]\tvalid_0's tweedie: 252.551\n",
      "[203]\tvalid_0's tweedie: 252.551\n",
      "[204]\tvalid_0's tweedie: 252.551\n",
      "[205]\tvalid_0's tweedie: 252.551\n",
      "[206]\tvalid_0's tweedie: 252.551\n",
      "[207]\tvalid_0's tweedie: 252.551\n",
      "[208]\tvalid_0's tweedie: 252.551\n",
      "[209]\tvalid_0's tweedie: 252.551\n",
      "[210]\tvalid_0's tweedie: 252.551\n",
      "[211]\tvalid_0's tweedie: 252.551\n",
      "[212]\tvalid_0's tweedie: 252.551\n",
      "[213]\tvalid_0's tweedie: 252.551\n",
      "[214]\tvalid_0's tweedie: 252.551\n",
      "[215]\tvalid_0's tweedie: 252.55\n",
      "[216]\tvalid_0's tweedie: 252.551\n",
      "[217]\tvalid_0's tweedie: 252.551\n",
      "[218]\tvalid_0's tweedie: 252.55\n",
      "[219]\tvalid_0's tweedie: 252.55\n",
      "[220]\tvalid_0's tweedie: 252.55\n",
      "[221]\tvalid_0's tweedie: 252.551\n",
      "[222]\tvalid_0's tweedie: 252.551\n",
      "[223]\tvalid_0's tweedie: 252.551\n",
      "[224]\tvalid_0's tweedie: 252.551\n",
      "[225]\tvalid_0's tweedie: 252.551\n",
      "[226]\tvalid_0's tweedie: 252.551\n",
      "[227]\tvalid_0's tweedie: 252.55\n",
      "[228]\tvalid_0's tweedie: 252.55\n",
      "[229]\tvalid_0's tweedie: 252.55\n",
      "[230]\tvalid_0's tweedie: 252.55\n",
      "[231]\tvalid_0's tweedie: 252.55\n",
      "[232]\tvalid_0's tweedie: 252.55\n",
      "[233]\tvalid_0's tweedie: 252.55\n",
      "[234]\tvalid_0's tweedie: 252.55\n",
      "[235]\tvalid_0's tweedie: 252.55\n",
      "[236]\tvalid_0's tweedie: 252.55\n",
      "[237]\tvalid_0's tweedie: 252.55\n",
      "[238]\tvalid_0's tweedie: 252.55\n",
      "[239]\tvalid_0's tweedie: 252.55\n",
      "[240]\tvalid_0's tweedie: 252.55\n",
      "[241]\tvalid_0's tweedie: 252.55\n",
      "[242]\tvalid_0's tweedie: 252.55\n",
      "[243]\tvalid_0's tweedie: 252.55\n",
      "[244]\tvalid_0's tweedie: 252.55\n",
      "[245]\tvalid_0's tweedie: 252.55\n",
      "[246]\tvalid_0's tweedie: 252.55\n",
      "[247]\tvalid_0's tweedie: 252.55\n",
      "[248]\tvalid_0's tweedie: 252.55\n",
      "[249]\tvalid_0's tweedie: 252.55\n",
      "[250]\tvalid_0's tweedie: 252.55\n",
      "[251]\tvalid_0's tweedie: 252.55\n",
      "[252]\tvalid_0's tweedie: 252.55\n",
      "[253]\tvalid_0's tweedie: 252.55\n",
      "[254]\tvalid_0's tweedie: 252.55\n",
      "[255]\tvalid_0's tweedie: 252.55\n",
      "[256]\tvalid_0's tweedie: 252.55\n",
      "[257]\tvalid_0's tweedie: 252.55\n",
      "[258]\tvalid_0's tweedie: 252.55\n",
      "[259]\tvalid_0's tweedie: 252.55\n",
      "[260]\tvalid_0's tweedie: 252.55\n",
      "[261]\tvalid_0's tweedie: 252.55\n",
      "[262]\tvalid_0's tweedie: 252.55\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's tweedie: 252.55\n",
      "Training model for level 6 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5512\n",
      "[LightGBM] [Info] Number of data points in the train set: 16830, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.244940\n",
      "[1]\tvalid_0's tweedie: 271.674\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.356\n",
      "[3]\tvalid_0's tweedie: 265.595\n",
      "[4]\tvalid_0's tweedie: 263.282\n",
      "[5]\tvalid_0's tweedie: 261.369\n",
      "[6]\tvalid_0's tweedie: 259.818\n",
      "[7]\tvalid_0's tweedie: 258.513\n",
      "[8]\tvalid_0's tweedie: 257.462\n",
      "[9]\tvalid_0's tweedie: 256.591\n",
      "[10]\tvalid_0's tweedie: 255.872\n",
      "[11]\tvalid_0's tweedie: 255.297\n",
      "[12]\tvalid_0's tweedie: 254.815\n",
      "[13]\tvalid_0's tweedie: 254.416\n",
      "[14]\tvalid_0's tweedie: 254.089\n",
      "[15]\tvalid_0's tweedie: 253.832\n",
      "[16]\tvalid_0's tweedie: 253.62\n",
      "[17]\tvalid_0's tweedie: 253.449\n",
      "[18]\tvalid_0's tweedie: 253.304\n",
      "[19]\tvalid_0's tweedie: 253.181\n",
      "[20]\tvalid_0's tweedie: 253.084\n",
      "[21]\tvalid_0's tweedie: 253.004\n",
      "[22]\tvalid_0's tweedie: 252.941\n",
      "[23]\tvalid_0's tweedie: 252.885\n",
      "[24]\tvalid_0's tweedie: 252.836\n",
      "[25]\tvalid_0's tweedie: 252.8\n",
      "[26]\tvalid_0's tweedie: 252.769\n",
      "[27]\tvalid_0's tweedie: 252.742\n",
      "[28]\tvalid_0's tweedie: 252.721\n",
      "[29]\tvalid_0's tweedie: 252.704\n",
      "[30]\tvalid_0's tweedie: 252.69\n",
      "[31]\tvalid_0's tweedie: 252.674\n",
      "[32]\tvalid_0's tweedie: 252.666\n",
      "[33]\tvalid_0's tweedie: 252.657\n",
      "[34]\tvalid_0's tweedie: 252.651\n",
      "[35]\tvalid_0's tweedie: 252.647\n",
      "[36]\tvalid_0's tweedie: 252.643\n",
      "[37]\tvalid_0's tweedie: 252.639\n",
      "[38]\tvalid_0's tweedie: 252.637\n",
      "[39]\tvalid_0's tweedie: 252.631\n",
      "[40]\tvalid_0's tweedie: 252.626\n",
      "[41]\tvalid_0's tweedie: 252.623\n",
      "[42]\tvalid_0's tweedie: 252.621\n",
      "[43]\tvalid_0's tweedie: 252.619\n",
      "[44]\tvalid_0's tweedie: 252.617\n",
      "[45]\tvalid_0's tweedie: 252.618\n",
      "[46]\tvalid_0's tweedie: 252.617\n",
      "[47]\tvalid_0's tweedie: 252.618\n",
      "[48]\tvalid_0's tweedie: 252.617\n",
      "[49]\tvalid_0's tweedie: 252.615\n",
      "[50]\tvalid_0's tweedie: 252.614\n",
      "[51]\tvalid_0's tweedie: 252.614\n",
      "[52]\tvalid_0's tweedie: 252.612\n",
      "[53]\tvalid_0's tweedie: 252.61\n",
      "[54]\tvalid_0's tweedie: 252.609\n",
      "[55]\tvalid_0's tweedie: 252.609\n",
      "[56]\tvalid_0's tweedie: 252.608\n",
      "[57]\tvalid_0's tweedie: 252.608\n",
      "[58]\tvalid_0's tweedie: 252.61\n",
      "[59]\tvalid_0's tweedie: 252.61\n",
      "[60]\tvalid_0's tweedie: 252.61\n",
      "[61]\tvalid_0's tweedie: 252.608\n",
      "[62]\tvalid_0's tweedie: 252.607\n",
      "[63]\tvalid_0's tweedie: 252.608\n",
      "[64]\tvalid_0's tweedie: 252.608\n",
      "[65]\tvalid_0's tweedie: 252.609\n",
      "[66]\tvalid_0's tweedie: 252.607\n",
      "[67]\tvalid_0's tweedie: 252.606\n",
      "[68]\tvalid_0's tweedie: 252.607\n",
      "[69]\tvalid_0's tweedie: 252.606\n",
      "[70]\tvalid_0's tweedie: 252.606\n",
      "[71]\tvalid_0's tweedie: 252.606\n",
      "[72]\tvalid_0's tweedie: 252.605\n",
      "[73]\tvalid_0's tweedie: 252.605\n",
      "[74]\tvalid_0's tweedie: 252.605\n",
      "[75]\tvalid_0's tweedie: 252.604\n",
      "[76]\tvalid_0's tweedie: 252.604\n",
      "[77]\tvalid_0's tweedie: 252.604\n",
      "[78]\tvalid_0's tweedie: 252.603\n",
      "[79]\tvalid_0's tweedie: 252.603\n",
      "[80]\tvalid_0's tweedie: 252.602\n",
      "[81]\tvalid_0's tweedie: 252.602\n",
      "[82]\tvalid_0's tweedie: 252.602\n",
      "[83]\tvalid_0's tweedie: 252.602\n",
      "[84]\tvalid_0's tweedie: 252.602\n",
      "[85]\tvalid_0's tweedie: 252.601\n",
      "[86]\tvalid_0's tweedie: 252.601\n",
      "[87]\tvalid_0's tweedie: 252.601\n",
      "[88]\tvalid_0's tweedie: 252.601\n",
      "[89]\tvalid_0's tweedie: 252.602\n",
      "[90]\tvalid_0's tweedie: 252.602\n",
      "[91]\tvalid_0's tweedie: 252.602\n",
      "[92]\tvalid_0's tweedie: 252.603\n",
      "[93]\tvalid_0's tweedie: 252.604\n",
      "[94]\tvalid_0's tweedie: 252.604\n",
      "[95]\tvalid_0's tweedie: 252.604\n",
      "[96]\tvalid_0's tweedie: 252.603\n",
      "[97]\tvalid_0's tweedie: 252.602\n",
      "[98]\tvalid_0's tweedie: 252.603\n",
      "[99]\tvalid_0's tweedie: 252.603\n",
      "[100]\tvalid_0's tweedie: 252.602\n",
      "[101]\tvalid_0's tweedie: 252.602\n",
      "[102]\tvalid_0's tweedie: 252.602\n",
      "[103]\tvalid_0's tweedie: 252.602\n",
      "[104]\tvalid_0's tweedie: 252.602\n",
      "[105]\tvalid_0's tweedie: 252.602\n",
      "[106]\tvalid_0's tweedie: 252.602\n",
      "[107]\tvalid_0's tweedie: 252.602\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's tweedie: 252.601\n",
      "Training model for level 6 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5511\n",
      "[LightGBM] [Info] Number of data points in the train set: 16821, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.244908\n",
      "[1]\tvalid_0's tweedie: 271.666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.361\n",
      "[3]\tvalid_0's tweedie: 265.607\n",
      "[4]\tvalid_0's tweedie: 263.298\n",
      "[5]\tvalid_0's tweedie: 261.371\n",
      "[6]\tvalid_0's tweedie: 259.824\n",
      "[7]\tvalid_0's tweedie: 258.535\n",
      "[8]\tvalid_0's tweedie: 257.475\n",
      "[9]\tvalid_0's tweedie: 256.601\n",
      "[10]\tvalid_0's tweedie: 255.879\n",
      "[11]\tvalid_0's tweedie: 255.287\n",
      "[12]\tvalid_0's tweedie: 254.813\n",
      "[13]\tvalid_0's tweedie: 254.425\n",
      "[14]\tvalid_0's tweedie: 254.107\n",
      "[15]\tvalid_0's tweedie: 253.844\n",
      "[16]\tvalid_0's tweedie: 253.622\n",
      "[17]\tvalid_0's tweedie: 253.455\n",
      "[18]\tvalid_0's tweedie: 253.31\n",
      "[19]\tvalid_0's tweedie: 253.191\n",
      "[20]\tvalid_0's tweedie: 253.093\n",
      "[21]\tvalid_0's tweedie: 253.012\n",
      "[22]\tvalid_0's tweedie: 252.952\n",
      "[23]\tvalid_0's tweedie: 252.9\n",
      "[24]\tvalid_0's tweedie: 252.854\n",
      "[25]\tvalid_0's tweedie: 252.817\n",
      "[26]\tvalid_0's tweedie: 252.787\n",
      "[27]\tvalid_0's tweedie: 252.765\n",
      "[28]\tvalid_0's tweedie: 252.741\n",
      "[29]\tvalid_0's tweedie: 252.726\n",
      "[30]\tvalid_0's tweedie: 252.706\n",
      "[31]\tvalid_0's tweedie: 252.691\n",
      "[32]\tvalid_0's tweedie: 252.679\n",
      "[33]\tvalid_0's tweedie: 252.671\n",
      "[34]\tvalid_0's tweedie: 252.661\n",
      "[35]\tvalid_0's tweedie: 252.654\n",
      "[36]\tvalid_0's tweedie: 252.649\n",
      "[37]\tvalid_0's tweedie: 252.645\n",
      "[38]\tvalid_0's tweedie: 252.639\n",
      "[39]\tvalid_0's tweedie: 252.634\n",
      "[40]\tvalid_0's tweedie: 252.633\n",
      "[41]\tvalid_0's tweedie: 252.63\n",
      "[42]\tvalid_0's tweedie: 252.627\n",
      "[43]\tvalid_0's tweedie: 252.626\n",
      "[44]\tvalid_0's tweedie: 252.626\n",
      "[45]\tvalid_0's tweedie: 252.625\n",
      "[46]\tvalid_0's tweedie: 252.623\n",
      "[47]\tvalid_0's tweedie: 252.623\n",
      "[48]\tvalid_0's tweedie: 252.622\n",
      "[49]\tvalid_0's tweedie: 252.621\n",
      "[50]\tvalid_0's tweedie: 252.619\n",
      "[51]\tvalid_0's tweedie: 252.62\n",
      "[52]\tvalid_0's tweedie: 252.622\n",
      "[53]\tvalid_0's tweedie: 252.622\n",
      "[54]\tvalid_0's tweedie: 252.621\n",
      "[55]\tvalid_0's tweedie: 252.622\n",
      "[56]\tvalid_0's tweedie: 252.621\n",
      "[57]\tvalid_0's tweedie: 252.622\n",
      "[58]\tvalid_0's tweedie: 252.621\n",
      "[59]\tvalid_0's tweedie: 252.621\n",
      "[60]\tvalid_0's tweedie: 252.62\n",
      "[61]\tvalid_0's tweedie: 252.618\n",
      "[62]\tvalid_0's tweedie: 252.618\n",
      "[63]\tvalid_0's tweedie: 252.618\n",
      "[64]\tvalid_0's tweedie: 252.618\n",
      "[65]\tvalid_0's tweedie: 252.619\n",
      "[66]\tvalid_0's tweedie: 252.62\n",
      "[67]\tvalid_0's tweedie: 252.62\n",
      "[68]\tvalid_0's tweedie: 252.62\n",
      "[69]\tvalid_0's tweedie: 252.618\n",
      "[70]\tvalid_0's tweedie: 252.619\n",
      "[71]\tvalid_0's tweedie: 252.618\n",
      "[72]\tvalid_0's tweedie: 252.619\n",
      "[73]\tvalid_0's tweedie: 252.619\n",
      "[74]\tvalid_0's tweedie: 252.619\n",
      "[75]\tvalid_0's tweedie: 252.619\n",
      "[76]\tvalid_0's tweedie: 252.619\n",
      "[77]\tvalid_0's tweedie: 252.619\n",
      "[78]\tvalid_0's tweedie: 252.618\n",
      "[79]\tvalid_0's tweedie: 252.617\n",
      "[80]\tvalid_0's tweedie: 252.617\n",
      "[81]\tvalid_0's tweedie: 252.617\n",
      "[82]\tvalid_0's tweedie: 252.617\n",
      "[83]\tvalid_0's tweedie: 252.618\n",
      "[84]\tvalid_0's tweedie: 252.619\n",
      "[85]\tvalid_0's tweedie: 252.619\n",
      "[86]\tvalid_0's tweedie: 252.619\n",
      "[87]\tvalid_0's tweedie: 252.619\n",
      "[88]\tvalid_0's tweedie: 252.618\n",
      "[89]\tvalid_0's tweedie: 252.618\n",
      "[90]\tvalid_0's tweedie: 252.618\n",
      "[91]\tvalid_0's tweedie: 252.618\n",
      "[92]\tvalid_0's tweedie: 252.618\n",
      "[93]\tvalid_0's tweedie: 252.618\n",
      "[94]\tvalid_0's tweedie: 252.618\n",
      "[95]\tvalid_0's tweedie: 252.618\n",
      "[96]\tvalid_0's tweedie: 252.617\n",
      "[97]\tvalid_0's tweedie: 252.617\n",
      "[98]\tvalid_0's tweedie: 252.617\n",
      "[99]\tvalid_0's tweedie: 252.617\n",
      "[100]\tvalid_0's tweedie: 252.617\n",
      "[101]\tvalid_0's tweedie: 252.618\n",
      "[102]\tvalid_0's tweedie: 252.618\n",
      "[103]\tvalid_0's tweedie: 252.618\n",
      "[104]\tvalid_0's tweedie: 252.617\n",
      "[105]\tvalid_0's tweedie: 252.617\n",
      "[106]\tvalid_0's tweedie: 252.617\n",
      "[107]\tvalid_0's tweedie: 252.617\n",
      "[108]\tvalid_0's tweedie: 252.617\n",
      "[109]\tvalid_0's tweedie: 252.616\n",
      "[110]\tvalid_0's tweedie: 252.615\n",
      "[111]\tvalid_0's tweedie: 252.615\n",
      "[112]\tvalid_0's tweedie: 252.615\n",
      "[113]\tvalid_0's tweedie: 252.615\n",
      "[114]\tvalid_0's tweedie: 252.615\n",
      "[115]\tvalid_0's tweedie: 252.614\n",
      "[116]\tvalid_0's tweedie: 252.614\n",
      "[117]\tvalid_0's tweedie: 252.614\n",
      "[118]\tvalid_0's tweedie: 252.613\n",
      "[119]\tvalid_0's tweedie: 252.613\n",
      "[120]\tvalid_0's tweedie: 252.613\n",
      "[121]\tvalid_0's tweedie: 252.613\n",
      "[122]\tvalid_0's tweedie: 252.612\n",
      "[123]\tvalid_0's tweedie: 252.612\n",
      "[124]\tvalid_0's tweedie: 252.612\n",
      "[125]\tvalid_0's tweedie: 252.611\n",
      "[126]\tvalid_0's tweedie: 252.611\n",
      "[127]\tvalid_0's tweedie: 252.609\n",
      "[128]\tvalid_0's tweedie: 252.609\n",
      "[129]\tvalid_0's tweedie: 252.608\n",
      "[130]\tvalid_0's tweedie: 252.607\n",
      "[131]\tvalid_0's tweedie: 252.608\n",
      "[132]\tvalid_0's tweedie: 252.608\n",
      "[133]\tvalid_0's tweedie: 252.609\n",
      "[134]\tvalid_0's tweedie: 252.608\n",
      "[135]\tvalid_0's tweedie: 252.608\n",
      "[136]\tvalid_0's tweedie: 252.608\n",
      "[137]\tvalid_0's tweedie: 252.607\n",
      "[138]\tvalid_0's tweedie: 252.607\n",
      "[139]\tvalid_0's tweedie: 252.608\n",
      "[140]\tvalid_0's tweedie: 252.608\n",
      "[141]\tvalid_0's tweedie: 252.608\n",
      "[142]\tvalid_0's tweedie: 252.608\n",
      "[143]\tvalid_0's tweedie: 252.606\n",
      "[144]\tvalid_0's tweedie: 252.606\n",
      "[145]\tvalid_0's tweedie: 252.605\n",
      "[146]\tvalid_0's tweedie: 252.605\n",
      "[147]\tvalid_0's tweedie: 252.605\n",
      "[148]\tvalid_0's tweedie: 252.605\n",
      "[149]\tvalid_0's tweedie: 252.605\n",
      "[150]\tvalid_0's tweedie: 252.604\n",
      "[151]\tvalid_0's tweedie: 252.604\n",
      "[152]\tvalid_0's tweedie: 252.604\n",
      "[153]\tvalid_0's tweedie: 252.604\n",
      "[154]\tvalid_0's tweedie: 252.604\n",
      "[155]\tvalid_0's tweedie: 252.604\n",
      "[156]\tvalid_0's tweedie: 252.604\n",
      "[157]\tvalid_0's tweedie: 252.604\n",
      "[158]\tvalid_0's tweedie: 252.604\n",
      "[159]\tvalid_0's tweedie: 252.604\n",
      "[160]\tvalid_0's tweedie: 252.605\n",
      "[161]\tvalid_0's tweedie: 252.606\n",
      "[162]\tvalid_0's tweedie: 252.606\n",
      "[163]\tvalid_0's tweedie: 252.606\n",
      "[164]\tvalid_0's tweedie: 252.605\n",
      "[165]\tvalid_0's tweedie: 252.605\n",
      "[166]\tvalid_0's tweedie: 252.605\n",
      "[167]\tvalid_0's tweedie: 252.605\n",
      "[168]\tvalid_0's tweedie: 252.605\n",
      "[169]\tvalid_0's tweedie: 252.605\n",
      "[170]\tvalid_0's tweedie: 252.606\n",
      "[171]\tvalid_0's tweedie: 252.605\n",
      "[172]\tvalid_0's tweedie: 252.605\n",
      "[173]\tvalid_0's tweedie: 252.605\n",
      "[174]\tvalid_0's tweedie: 252.605\n",
      "[175]\tvalid_0's tweedie: 252.605\n",
      "[176]\tvalid_0's tweedie: 252.603\n",
      "[177]\tvalid_0's tweedie: 252.603\n",
      "[178]\tvalid_0's tweedie: 252.603\n",
      "[179]\tvalid_0's tweedie: 252.603\n",
      "[180]\tvalid_0's tweedie: 252.603\n",
      "[181]\tvalid_0's tweedie: 252.603\n",
      "[182]\tvalid_0's tweedie: 252.603\n",
      "[183]\tvalid_0's tweedie: 252.603\n",
      "[184]\tvalid_0's tweedie: 252.603\n",
      "[185]\tvalid_0's tweedie: 252.602\n",
      "[186]\tvalid_0's tweedie: 252.602\n",
      "[187]\tvalid_0's tweedie: 252.601\n",
      "[188]\tvalid_0's tweedie: 252.601\n",
      "[189]\tvalid_0's tweedie: 252.601\n",
      "[190]\tvalid_0's tweedie: 252.601\n",
      "[191]\tvalid_0's tweedie: 252.601\n",
      "[192]\tvalid_0's tweedie: 252.601\n",
      "[193]\tvalid_0's tweedie: 252.602\n",
      "[194]\tvalid_0's tweedie: 252.602\n",
      "[195]\tvalid_0's tweedie: 252.601\n",
      "[196]\tvalid_0's tweedie: 252.601\n",
      "[197]\tvalid_0's tweedie: 252.601\n",
      "[198]\tvalid_0's tweedie: 252.601\n",
      "[199]\tvalid_0's tweedie: 252.602\n",
      "[200]\tvalid_0's tweedie: 252.602\n",
      "[201]\tvalid_0's tweedie: 252.602\n",
      "[202]\tvalid_0's tweedie: 252.602\n",
      "[203]\tvalid_0's tweedie: 252.602\n",
      "[204]\tvalid_0's tweedie: 252.601\n",
      "[205]\tvalid_0's tweedie: 252.602\n",
      "[206]\tvalid_0's tweedie: 252.601\n",
      "[207]\tvalid_0's tweedie: 252.601\n",
      "[208]\tvalid_0's tweedie: 252.601\n",
      "[209]\tvalid_0's tweedie: 252.601\n",
      "[210]\tvalid_0's tweedie: 252.601\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's tweedie: 252.601\n",
      "Training model for level 6 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5510\n",
      "[LightGBM] [Info] Number of data points in the train set: 16812, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245102\n",
      "[1]\tvalid_0's tweedie: 271.67\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.359\n",
      "[3]\tvalid_0's tweedie: 265.61\n",
      "[4]\tvalid_0's tweedie: 263.309\n",
      "[5]\tvalid_0's tweedie: 261.405\n",
      "[6]\tvalid_0's tweedie: 259.839\n",
      "[7]\tvalid_0's tweedie: 258.564\n",
      "[8]\tvalid_0's tweedie: 257.509\n",
      "[9]\tvalid_0's tweedie: 256.632\n",
      "[10]\tvalid_0's tweedie: 255.911\n",
      "[11]\tvalid_0's tweedie: 255.312\n",
      "[12]\tvalid_0's tweedie: 254.831\n",
      "[13]\tvalid_0's tweedie: 254.438\n",
      "[14]\tvalid_0's tweedie: 254.114\n",
      "[15]\tvalid_0's tweedie: 253.847\n",
      "[16]\tvalid_0's tweedie: 253.628\n",
      "[17]\tvalid_0's tweedie: 253.454\n",
      "[18]\tvalid_0's tweedie: 253.319\n",
      "[19]\tvalid_0's tweedie: 253.204\n",
      "[20]\tvalid_0's tweedie: 253.11\n",
      "[21]\tvalid_0's tweedie: 253.026\n",
      "[22]\tvalid_0's tweedie: 252.96\n",
      "[23]\tvalid_0's tweedie: 252.904\n",
      "[24]\tvalid_0's tweedie: 252.858\n",
      "[25]\tvalid_0's tweedie: 252.822\n",
      "[26]\tvalid_0's tweedie: 252.788\n",
      "[27]\tvalid_0's tweedie: 252.763\n",
      "[28]\tvalid_0's tweedie: 252.74\n",
      "[29]\tvalid_0's tweedie: 252.723\n",
      "[30]\tvalid_0's tweedie: 252.705\n",
      "[31]\tvalid_0's tweedie: 252.693\n",
      "[32]\tvalid_0's tweedie: 252.679\n",
      "[33]\tvalid_0's tweedie: 252.664\n",
      "[34]\tvalid_0's tweedie: 252.656\n",
      "[35]\tvalid_0's tweedie: 252.65\n",
      "[36]\tvalid_0's tweedie: 252.644\n",
      "[37]\tvalid_0's tweedie: 252.639\n",
      "[38]\tvalid_0's tweedie: 252.633\n",
      "[39]\tvalid_0's tweedie: 252.626\n",
      "[40]\tvalid_0's tweedie: 252.621\n",
      "[41]\tvalid_0's tweedie: 252.617\n",
      "[42]\tvalid_0's tweedie: 252.613\n",
      "[43]\tvalid_0's tweedie: 252.61\n",
      "[44]\tvalid_0's tweedie: 252.611\n",
      "[45]\tvalid_0's tweedie: 252.611\n",
      "[46]\tvalid_0's tweedie: 252.611\n",
      "[47]\tvalid_0's tweedie: 252.61\n",
      "[48]\tvalid_0's tweedie: 252.61\n",
      "[49]\tvalid_0's tweedie: 252.608\n",
      "[50]\tvalid_0's tweedie: 252.606\n",
      "[51]\tvalid_0's tweedie: 252.606\n",
      "[52]\tvalid_0's tweedie: 252.607\n",
      "[53]\tvalid_0's tweedie: 252.606\n",
      "[54]\tvalid_0's tweedie: 252.604\n",
      "[55]\tvalid_0's tweedie: 252.604\n",
      "[56]\tvalid_0's tweedie: 252.606\n",
      "[57]\tvalid_0's tweedie: 252.605\n",
      "[58]\tvalid_0's tweedie: 252.606\n",
      "[59]\tvalid_0's tweedie: 252.606\n",
      "[60]\tvalid_0's tweedie: 252.606\n",
      "[61]\tvalid_0's tweedie: 252.606\n",
      "[62]\tvalid_0's tweedie: 252.605\n",
      "[63]\tvalid_0's tweedie: 252.606\n",
      "[64]\tvalid_0's tweedie: 252.606\n",
      "[65]\tvalid_0's tweedie: 252.606\n",
      "[66]\tvalid_0's tweedie: 252.606\n",
      "[67]\tvalid_0's tweedie: 252.604\n",
      "[68]\tvalid_0's tweedie: 252.604\n",
      "[69]\tvalid_0's tweedie: 252.604\n",
      "[70]\tvalid_0's tweedie: 252.604\n",
      "[71]\tvalid_0's tweedie: 252.605\n",
      "[72]\tvalid_0's tweedie: 252.605\n",
      "[73]\tvalid_0's tweedie: 252.605\n",
      "[74]\tvalid_0's tweedie: 252.606\n",
      "[75]\tvalid_0's tweedie: 252.606\n",
      "[76]\tvalid_0's tweedie: 252.607\n",
      "[77]\tvalid_0's tweedie: 252.607\n",
      "[78]\tvalid_0's tweedie: 252.607\n",
      "[79]\tvalid_0's tweedie: 252.607\n",
      "[80]\tvalid_0's tweedie: 252.608\n",
      "[81]\tvalid_0's tweedie: 252.608\n",
      "[82]\tvalid_0's tweedie: 252.608\n",
      "[83]\tvalid_0's tweedie: 252.608\n",
      "[84]\tvalid_0's tweedie: 252.608\n",
      "[85]\tvalid_0's tweedie: 252.608\n",
      "[86]\tvalid_0's tweedie: 252.608\n",
      "[87]\tvalid_0's tweedie: 252.608\n",
      "[88]\tvalid_0's tweedie: 252.608\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's tweedie: 252.604\n",
      "Training model for level 6 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 16803, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245262\n",
      "[1]\tvalid_0's tweedie: 271.664\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.355\n",
      "[3]\tvalid_0's tweedie: 265.609\n",
      "[4]\tvalid_0's tweedie: 263.308\n",
      "[5]\tvalid_0's tweedie: 261.405\n",
      "[6]\tvalid_0's tweedie: 259.84\n",
      "[7]\tvalid_0's tweedie: 258.547\n",
      "[8]\tvalid_0's tweedie: 257.486\n",
      "[9]\tvalid_0's tweedie: 256.605\n",
      "[10]\tvalid_0's tweedie: 255.892\n",
      "[11]\tvalid_0's tweedie: 255.318\n",
      "[12]\tvalid_0's tweedie: 254.838\n",
      "[13]\tvalid_0's tweedie: 254.435\n",
      "[14]\tvalid_0's tweedie: 254.118\n",
      "[15]\tvalid_0's tweedie: 253.852\n",
      "[16]\tvalid_0's tweedie: 253.629\n",
      "[17]\tvalid_0's tweedie: 253.456\n",
      "[18]\tvalid_0's tweedie: 253.315\n",
      "[19]\tvalid_0's tweedie: 253.199\n",
      "[20]\tvalid_0's tweedie: 253.105\n",
      "[21]\tvalid_0's tweedie: 253.026\n",
      "[22]\tvalid_0's tweedie: 252.958\n",
      "[23]\tvalid_0's tweedie: 252.903\n",
      "[24]\tvalid_0's tweedie: 252.858\n",
      "[25]\tvalid_0's tweedie: 252.822\n",
      "[26]\tvalid_0's tweedie: 252.789\n",
      "[27]\tvalid_0's tweedie: 252.763\n",
      "[28]\tvalid_0's tweedie: 252.741\n",
      "[29]\tvalid_0's tweedie: 252.727\n",
      "[30]\tvalid_0's tweedie: 252.711\n",
      "[31]\tvalid_0's tweedie: 252.697\n",
      "[32]\tvalid_0's tweedie: 252.684\n",
      "[33]\tvalid_0's tweedie: 252.673\n",
      "[34]\tvalid_0's tweedie: 252.666\n",
      "[35]\tvalid_0's tweedie: 252.656\n",
      "[36]\tvalid_0's tweedie: 252.647\n",
      "[37]\tvalid_0's tweedie: 252.642\n",
      "[38]\tvalid_0's tweedie: 252.635\n",
      "[39]\tvalid_0's tweedie: 252.631\n",
      "[40]\tvalid_0's tweedie: 252.626\n",
      "[41]\tvalid_0's tweedie: 252.623\n",
      "[42]\tvalid_0's tweedie: 252.622\n",
      "[43]\tvalid_0's tweedie: 252.62\n",
      "[44]\tvalid_0's tweedie: 252.621\n",
      "[45]\tvalid_0's tweedie: 252.622\n",
      "[46]\tvalid_0's tweedie: 252.623\n",
      "[47]\tvalid_0's tweedie: 252.622\n",
      "[48]\tvalid_0's tweedie: 252.622\n",
      "[49]\tvalid_0's tweedie: 252.622\n",
      "[50]\tvalid_0's tweedie: 252.625\n",
      "[51]\tvalid_0's tweedie: 252.626\n",
      "[52]\tvalid_0's tweedie: 252.625\n",
      "[53]\tvalid_0's tweedie: 252.625\n",
      "[54]\tvalid_0's tweedie: 252.624\n",
      "[55]\tvalid_0's tweedie: 252.622\n",
      "[56]\tvalid_0's tweedie: 252.623\n",
      "[57]\tvalid_0's tweedie: 252.624\n",
      "[58]\tvalid_0's tweedie: 252.623\n",
      "[59]\tvalid_0's tweedie: 252.623\n",
      "[60]\tvalid_0's tweedie: 252.623\n",
      "[61]\tvalid_0's tweedie: 252.623\n",
      "[62]\tvalid_0's tweedie: 252.624\n",
      "[63]\tvalid_0's tweedie: 252.624\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's tweedie: 252.62\n",
      "Training model for level 6 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 16794, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245463\n",
      "[1]\tvalid_0's tweedie: 271.662\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.354\n",
      "[3]\tvalid_0's tweedie: 265.601\n",
      "[4]\tvalid_0's tweedie: 263.303\n",
      "[5]\tvalid_0's tweedie: 261.399\n",
      "[6]\tvalid_0's tweedie: 259.875\n",
      "[7]\tvalid_0's tweedie: 258.595\n",
      "[8]\tvalid_0's tweedie: 257.528\n",
      "[9]\tvalid_0's tweedie: 256.648\n",
      "[10]\tvalid_0's tweedie: 255.923\n",
      "[11]\tvalid_0's tweedie: 255.327\n",
      "[12]\tvalid_0's tweedie: 254.845\n",
      "[13]\tvalid_0's tweedie: 254.446\n",
      "[14]\tvalid_0's tweedie: 254.124\n",
      "[15]\tvalid_0's tweedie: 253.867\n",
      "[16]\tvalid_0's tweedie: 253.648\n",
      "[17]\tvalid_0's tweedie: 253.467\n",
      "[18]\tvalid_0's tweedie: 253.324\n",
      "[19]\tvalid_0's tweedie: 253.209\n",
      "[20]\tvalid_0's tweedie: 253.107\n",
      "[21]\tvalid_0's tweedie: 253.028\n",
      "[22]\tvalid_0's tweedie: 252.965\n",
      "[23]\tvalid_0's tweedie: 252.91\n",
      "[24]\tvalid_0's tweedie: 252.865\n",
      "[25]\tvalid_0's tweedie: 252.828\n",
      "[26]\tvalid_0's tweedie: 252.795\n",
      "[27]\tvalid_0's tweedie: 252.769\n",
      "[28]\tvalid_0's tweedie: 252.742\n",
      "[29]\tvalid_0's tweedie: 252.725\n",
      "[30]\tvalid_0's tweedie: 252.709\n",
      "[31]\tvalid_0's tweedie: 252.694\n",
      "[32]\tvalid_0's tweedie: 252.681\n",
      "[33]\tvalid_0's tweedie: 252.672\n",
      "[34]\tvalid_0's tweedie: 252.665\n",
      "[35]\tvalid_0's tweedie: 252.66\n",
      "[36]\tvalid_0's tweedie: 252.654\n",
      "[37]\tvalid_0's tweedie: 252.65\n",
      "[38]\tvalid_0's tweedie: 252.64\n",
      "[39]\tvalid_0's tweedie: 252.636\n",
      "[40]\tvalid_0's tweedie: 252.63\n",
      "[41]\tvalid_0's tweedie: 252.626\n",
      "[42]\tvalid_0's tweedie: 252.625\n",
      "[43]\tvalid_0's tweedie: 252.623\n",
      "[44]\tvalid_0's tweedie: 252.623\n",
      "[45]\tvalid_0's tweedie: 252.625\n",
      "[46]\tvalid_0's tweedie: 252.625\n",
      "[47]\tvalid_0's tweedie: 252.624\n",
      "[48]\tvalid_0's tweedie: 252.622\n",
      "[49]\tvalid_0's tweedie: 252.622\n",
      "[50]\tvalid_0's tweedie: 252.622\n",
      "[51]\tvalid_0's tweedie: 252.619\n",
      "[52]\tvalid_0's tweedie: 252.618\n",
      "[53]\tvalid_0's tweedie: 252.62\n",
      "[54]\tvalid_0's tweedie: 252.62\n",
      "[55]\tvalid_0's tweedie: 252.621\n",
      "[56]\tvalid_0's tweedie: 252.619\n",
      "[57]\tvalid_0's tweedie: 252.62\n",
      "[58]\tvalid_0's tweedie: 252.62\n",
      "[59]\tvalid_0's tweedie: 252.621\n",
      "[60]\tvalid_0's tweedie: 252.62\n",
      "[61]\tvalid_0's tweedie: 252.621\n",
      "[62]\tvalid_0's tweedie: 252.621\n",
      "[63]\tvalid_0's tweedie: 252.621\n",
      "[64]\tvalid_0's tweedie: 252.622\n",
      "[65]\tvalid_0's tweedie: 252.621\n",
      "[66]\tvalid_0's tweedie: 252.621\n",
      "[67]\tvalid_0's tweedie: 252.62\n",
      "[68]\tvalid_0's tweedie: 252.621\n",
      "[69]\tvalid_0's tweedie: 252.62\n",
      "[70]\tvalid_0's tweedie: 252.619\n",
      "[71]\tvalid_0's tweedie: 252.617\n",
      "[72]\tvalid_0's tweedie: 252.617\n",
      "[73]\tvalid_0's tweedie: 252.617\n",
      "[74]\tvalid_0's tweedie: 252.617\n",
      "[75]\tvalid_0's tweedie: 252.614\n",
      "[76]\tvalid_0's tweedie: 252.614\n",
      "[77]\tvalid_0's tweedie: 252.614\n",
      "[78]\tvalid_0's tweedie: 252.615\n",
      "[79]\tvalid_0's tweedie: 252.614\n",
      "[80]\tvalid_0's tweedie: 252.615\n",
      "[81]\tvalid_0's tweedie: 252.614\n",
      "[82]\tvalid_0's tweedie: 252.615\n",
      "[83]\tvalid_0's tweedie: 252.612\n",
      "[84]\tvalid_0's tweedie: 252.612\n",
      "[85]\tvalid_0's tweedie: 252.612\n",
      "[86]\tvalid_0's tweedie: 252.612\n",
      "[87]\tvalid_0's tweedie: 252.612\n",
      "[88]\tvalid_0's tweedie: 252.612\n",
      "[89]\tvalid_0's tweedie: 252.612\n",
      "[90]\tvalid_0's tweedie: 252.611\n",
      "[91]\tvalid_0's tweedie: 252.611\n",
      "[92]\tvalid_0's tweedie: 252.611\n",
      "[93]\tvalid_0's tweedie: 252.611\n",
      "[94]\tvalid_0's tweedie: 252.611\n",
      "[95]\tvalid_0's tweedie: 252.611\n",
      "[96]\tvalid_0's tweedie: 252.61\n",
      "[97]\tvalid_0's tweedie: 252.611\n",
      "[98]\tvalid_0's tweedie: 252.611\n",
      "[99]\tvalid_0's tweedie: 252.611\n",
      "[100]\tvalid_0's tweedie: 252.611\n",
      "[101]\tvalid_0's tweedie: 252.611\n",
      "[102]\tvalid_0's tweedie: 252.612\n",
      "[103]\tvalid_0's tweedie: 252.612\n",
      "[104]\tvalid_0's tweedie: 252.611\n",
      "[105]\tvalid_0's tweedie: 252.612\n",
      "[106]\tvalid_0's tweedie: 252.612\n",
      "[107]\tvalid_0's tweedie: 252.612\n",
      "[108]\tvalid_0's tweedie: 252.612\n",
      "[109]\tvalid_0's tweedie: 252.612\n",
      "[110]\tvalid_0's tweedie: 252.613\n",
      "[111]\tvalid_0's tweedie: 252.612\n",
      "[112]\tvalid_0's tweedie: 252.609\n",
      "[113]\tvalid_0's tweedie: 252.608\n",
      "[114]\tvalid_0's tweedie: 252.608\n",
      "[115]\tvalid_0's tweedie: 252.608\n",
      "[116]\tvalid_0's tweedie: 252.608\n",
      "[117]\tvalid_0's tweedie: 252.605\n",
      "[118]\tvalid_0's tweedie: 252.605\n",
      "[119]\tvalid_0's tweedie: 252.606\n",
      "[120]\tvalid_0's tweedie: 252.606\n",
      "[121]\tvalid_0's tweedie: 252.605\n",
      "[122]\tvalid_0's tweedie: 252.605\n",
      "[123]\tvalid_0's tweedie: 252.605\n",
      "[124]\tvalid_0's tweedie: 252.605\n",
      "[125]\tvalid_0's tweedie: 252.605\n",
      "[126]\tvalid_0's tweedie: 252.605\n",
      "[127]\tvalid_0's tweedie: 252.605\n",
      "[128]\tvalid_0's tweedie: 252.603\n",
      "[129]\tvalid_0's tweedie: 252.602\n",
      "[130]\tvalid_0's tweedie: 252.602\n",
      "[131]\tvalid_0's tweedie: 252.602\n",
      "[132]\tvalid_0's tweedie: 252.602\n",
      "[133]\tvalid_0's tweedie: 252.602\n",
      "[134]\tvalid_0's tweedie: 252.602\n",
      "[135]\tvalid_0's tweedie: 252.601\n",
      "[136]\tvalid_0's tweedie: 252.602\n",
      "[137]\tvalid_0's tweedie: 252.601\n",
      "[138]\tvalid_0's tweedie: 252.601\n",
      "[139]\tvalid_0's tweedie: 252.599\n",
      "[140]\tvalid_0's tweedie: 252.6\n",
      "[141]\tvalid_0's tweedie: 252.598\n",
      "[142]\tvalid_0's tweedie: 252.598\n",
      "[143]\tvalid_0's tweedie: 252.598\n",
      "[144]\tvalid_0's tweedie: 252.598\n",
      "[145]\tvalid_0's tweedie: 252.598\n",
      "[146]\tvalid_0's tweedie: 252.598\n",
      "[147]\tvalid_0's tweedie: 252.598\n",
      "[148]\tvalid_0's tweedie: 252.598\n",
      "[149]\tvalid_0's tweedie: 252.597\n",
      "[150]\tvalid_0's tweedie: 252.597\n",
      "[151]\tvalid_0's tweedie: 252.597\n",
      "[152]\tvalid_0's tweedie: 252.597\n",
      "[153]\tvalid_0's tweedie: 252.597\n",
      "[154]\tvalid_0's tweedie: 252.597\n",
      "[155]\tvalid_0's tweedie: 252.597\n",
      "[156]\tvalid_0's tweedie: 252.597\n",
      "[157]\tvalid_0's tweedie: 252.597\n",
      "[158]\tvalid_0's tweedie: 252.597\n",
      "[159]\tvalid_0's tweedie: 252.597\n",
      "[160]\tvalid_0's tweedie: 252.598\n",
      "[161]\tvalid_0's tweedie: 252.598\n",
      "[162]\tvalid_0's tweedie: 252.598\n",
      "[163]\tvalid_0's tweedie: 252.598\n",
      "[164]\tvalid_0's tweedie: 252.598\n",
      "[165]\tvalid_0's tweedie: 252.598\n",
      "[166]\tvalid_0's tweedie: 252.597\n",
      "[167]\tvalid_0's tweedie: 252.597\n",
      "[168]\tvalid_0's tweedie: 252.598\n",
      "[169]\tvalid_0's tweedie: 252.598\n",
      "[170]\tvalid_0's tweedie: 252.598\n",
      "[171]\tvalid_0's tweedie: 252.598\n",
      "[172]\tvalid_0's tweedie: 252.599\n",
      "[173]\tvalid_0's tweedie: 252.599\n",
      "[174]\tvalid_0's tweedie: 252.599\n",
      "[175]\tvalid_0's tweedie: 252.599\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's tweedie: 252.597\n",
      "Training model for level 6 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 16785, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245681\n",
      "[1]\tvalid_0's tweedie: 271.66\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.354\n",
      "[3]\tvalid_0's tweedie: 265.572\n",
      "[4]\tvalid_0's tweedie: 263.272\n",
      "[5]\tvalid_0's tweedie: 261.369\n",
      "[6]\tvalid_0's tweedie: 259.842\n",
      "[7]\tvalid_0's tweedie: 258.552\n",
      "[8]\tvalid_0's tweedie: 257.489\n",
      "[9]\tvalid_0's tweedie: 256.632\n",
      "[10]\tvalid_0's tweedie: 255.904\n",
      "[11]\tvalid_0's tweedie: 255.306\n",
      "[12]\tvalid_0's tweedie: 254.822\n",
      "[13]\tvalid_0's tweedie: 254.423\n",
      "[14]\tvalid_0's tweedie: 254.107\n",
      "[15]\tvalid_0's tweedie: 253.844\n",
      "[16]\tvalid_0's tweedie: 253.644\n",
      "[17]\tvalid_0's tweedie: 253.467\n",
      "[18]\tvalid_0's tweedie: 253.32\n",
      "[19]\tvalid_0's tweedie: 253.201\n",
      "[20]\tvalid_0's tweedie: 253.109\n",
      "[21]\tvalid_0's tweedie: 253.025\n",
      "[22]\tvalid_0's tweedie: 252.957\n",
      "[23]\tvalid_0's tweedie: 252.902\n",
      "[24]\tvalid_0's tweedie: 252.855\n",
      "[25]\tvalid_0's tweedie: 252.816\n",
      "[26]\tvalid_0's tweedie: 252.781\n",
      "[27]\tvalid_0's tweedie: 252.755\n",
      "[28]\tvalid_0's tweedie: 252.729\n",
      "[29]\tvalid_0's tweedie: 252.706\n",
      "[30]\tvalid_0's tweedie: 252.691\n",
      "[31]\tvalid_0's tweedie: 252.678\n",
      "[32]\tvalid_0's tweedie: 252.665\n",
      "[33]\tvalid_0's tweedie: 252.656\n",
      "[34]\tvalid_0's tweedie: 252.65\n",
      "[35]\tvalid_0's tweedie: 252.643\n",
      "[36]\tvalid_0's tweedie: 252.634\n",
      "[37]\tvalid_0's tweedie: 252.629\n",
      "[38]\tvalid_0's tweedie: 252.622\n",
      "[39]\tvalid_0's tweedie: 252.617\n",
      "[40]\tvalid_0's tweedie: 252.616\n",
      "[41]\tvalid_0's tweedie: 252.615\n",
      "[42]\tvalid_0's tweedie: 252.609\n",
      "[43]\tvalid_0's tweedie: 252.61\n",
      "[44]\tvalid_0's tweedie: 252.61\n",
      "[45]\tvalid_0's tweedie: 252.609\n",
      "[46]\tvalid_0's tweedie: 252.609\n",
      "[47]\tvalid_0's tweedie: 252.607\n",
      "[48]\tvalid_0's tweedie: 252.609\n",
      "[49]\tvalid_0's tweedie: 252.608\n",
      "[50]\tvalid_0's tweedie: 252.605\n",
      "[51]\tvalid_0's tweedie: 252.605\n",
      "[52]\tvalid_0's tweedie: 252.605\n",
      "[53]\tvalid_0's tweedie: 252.604\n",
      "[54]\tvalid_0's tweedie: 252.605\n",
      "[55]\tvalid_0's tweedie: 252.606\n",
      "[56]\tvalid_0's tweedie: 252.606\n",
      "[57]\tvalid_0's tweedie: 252.606\n",
      "[58]\tvalid_0's tweedie: 252.607\n",
      "[59]\tvalid_0's tweedie: 252.607\n",
      "[60]\tvalid_0's tweedie: 252.607\n",
      "[61]\tvalid_0's tweedie: 252.607\n",
      "[62]\tvalid_0's tweedie: 252.607\n",
      "[63]\tvalid_0's tweedie: 252.608\n",
      "[64]\tvalid_0's tweedie: 252.608\n",
      "[65]\tvalid_0's tweedie: 252.608\n",
      "[66]\tvalid_0's tweedie: 252.608\n",
      "[67]\tvalid_0's tweedie: 252.609\n",
      "[68]\tvalid_0's tweedie: 252.609\n",
      "[69]\tvalid_0's tweedie: 252.608\n",
      "[70]\tvalid_0's tweedie: 252.607\n",
      "[71]\tvalid_0's tweedie: 252.607\n",
      "[72]\tvalid_0's tweedie: 252.608\n",
      "[73]\tvalid_0's tweedie: 252.608\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's tweedie: 252.604\n",
      "Training model for level 6 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 16776, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245847\n",
      "[1]\tvalid_0's tweedie: 271.688\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.441\n",
      "[3]\tvalid_0's tweedie: 265.679\n",
      "[4]\tvalid_0's tweedie: 263.462\n",
      "[5]\tvalid_0's tweedie: 261.568\n",
      "[6]\tvalid_0's tweedie: 260.02\n",
      "[7]\tvalid_0's tweedie: 258.73\n",
      "[8]\tvalid_0's tweedie: 257.667\n",
      "[9]\tvalid_0's tweedie: 256.812\n",
      "[10]\tvalid_0's tweedie: 256.084\n",
      "[11]\tvalid_0's tweedie: 255.494\n",
      "[12]\tvalid_0's tweedie: 255.008\n",
      "[13]\tvalid_0's tweedie: 254.596\n",
      "[14]\tvalid_0's tweedie: 254.274\n",
      "[15]\tvalid_0's tweedie: 254.028\n",
      "[16]\tvalid_0's tweedie: 253.799\n",
      "[17]\tvalid_0's tweedie: 253.614\n",
      "[18]\tvalid_0's tweedie: 253.461\n",
      "[19]\tvalid_0's tweedie: 253.329\n",
      "[20]\tvalid_0's tweedie: 253.218\n",
      "[21]\tvalid_0's tweedie: 253.134\n",
      "[22]\tvalid_0's tweedie: 253.065\n",
      "[23]\tvalid_0's tweedie: 253.006\n",
      "[24]\tvalid_0's tweedie: 252.952\n",
      "[25]\tvalid_0's tweedie: 252.917\n",
      "[26]\tvalid_0's tweedie: 252.88\n",
      "[27]\tvalid_0's tweedie: 252.85\n",
      "[28]\tvalid_0's tweedie: 252.824\n",
      "[29]\tvalid_0's tweedie: 252.798\n",
      "[30]\tvalid_0's tweedie: 252.769\n",
      "[31]\tvalid_0's tweedie: 252.749\n",
      "[32]\tvalid_0's tweedie: 252.731\n",
      "[33]\tvalid_0's tweedie: 252.715\n",
      "[34]\tvalid_0's tweedie: 252.706\n",
      "[35]\tvalid_0's tweedie: 252.697\n",
      "[36]\tvalid_0's tweedie: 252.692\n",
      "[37]\tvalid_0's tweedie: 252.682\n",
      "[38]\tvalid_0's tweedie: 252.676\n",
      "[39]\tvalid_0's tweedie: 252.672\n",
      "[40]\tvalid_0's tweedie: 252.669\n",
      "[41]\tvalid_0's tweedie: 252.665\n",
      "[42]\tvalid_0's tweedie: 252.666\n",
      "[43]\tvalid_0's tweedie: 252.664\n",
      "[44]\tvalid_0's tweedie: 252.662\n",
      "[45]\tvalid_0's tweedie: 252.659\n",
      "[46]\tvalid_0's tweedie: 252.658\n",
      "[47]\tvalid_0's tweedie: 252.658\n",
      "[48]\tvalid_0's tweedie: 252.655\n",
      "[49]\tvalid_0's tweedie: 252.656\n",
      "[50]\tvalid_0's tweedie: 252.657\n",
      "[51]\tvalid_0's tweedie: 252.652\n",
      "[52]\tvalid_0's tweedie: 252.653\n",
      "[53]\tvalid_0's tweedie: 252.652\n",
      "[54]\tvalid_0's tweedie: 252.652\n",
      "[55]\tvalid_0's tweedie: 252.651\n",
      "[56]\tvalid_0's tweedie: 252.651\n",
      "[57]\tvalid_0's tweedie: 252.653\n",
      "[58]\tvalid_0's tweedie: 252.653\n",
      "[59]\tvalid_0's tweedie: 252.654\n",
      "[60]\tvalid_0's tweedie: 252.654\n",
      "[61]\tvalid_0's tweedie: 252.655\n",
      "[62]\tvalid_0's tweedie: 252.655\n",
      "[63]\tvalid_0's tweedie: 252.652\n",
      "[64]\tvalid_0's tweedie: 252.652\n",
      "[65]\tvalid_0's tweedie: 252.652\n",
      "[66]\tvalid_0's tweedie: 252.653\n",
      "[67]\tvalid_0's tweedie: 252.652\n",
      "[68]\tvalid_0's tweedie: 252.652\n",
      "[69]\tvalid_0's tweedie: 252.65\n",
      "[70]\tvalid_0's tweedie: 252.65\n",
      "[71]\tvalid_0's tweedie: 252.65\n",
      "[72]\tvalid_0's tweedie: 252.649\n",
      "[73]\tvalid_0's tweedie: 252.648\n",
      "[74]\tvalid_0's tweedie: 252.647\n",
      "[75]\tvalid_0's tweedie: 252.647\n",
      "[76]\tvalid_0's tweedie: 252.645\n",
      "[77]\tvalid_0's tweedie: 252.645\n",
      "[78]\tvalid_0's tweedie: 252.645\n",
      "[79]\tvalid_0's tweedie: 252.644\n",
      "[80]\tvalid_0's tweedie: 252.642\n",
      "[81]\tvalid_0's tweedie: 252.642\n",
      "[82]\tvalid_0's tweedie: 252.64\n",
      "[83]\tvalid_0's tweedie: 252.64\n",
      "[84]\tvalid_0's tweedie: 252.64\n",
      "[85]\tvalid_0's tweedie: 252.638\n",
      "[86]\tvalid_0's tweedie: 252.638\n",
      "[87]\tvalid_0's tweedie: 252.636\n",
      "[88]\tvalid_0's tweedie: 252.637\n",
      "[89]\tvalid_0's tweedie: 252.637\n",
      "[90]\tvalid_0's tweedie: 252.636\n",
      "[91]\tvalid_0's tweedie: 252.635\n",
      "[92]\tvalid_0's tweedie: 252.636\n",
      "[93]\tvalid_0's tweedie: 252.636\n",
      "[94]\tvalid_0's tweedie: 252.637\n",
      "[95]\tvalid_0's tweedie: 252.637\n",
      "[96]\tvalid_0's tweedie: 252.636\n",
      "[97]\tvalid_0's tweedie: 252.636\n",
      "[98]\tvalid_0's tweedie: 252.637\n",
      "[99]\tvalid_0's tweedie: 252.637\n",
      "[100]\tvalid_0's tweedie: 252.637\n",
      "[101]\tvalid_0's tweedie: 252.637\n",
      "[102]\tvalid_0's tweedie: 252.636\n",
      "[103]\tvalid_0's tweedie: 252.636\n",
      "[104]\tvalid_0's tweedie: 252.635\n",
      "[105]\tvalid_0's tweedie: 252.635\n",
      "[106]\tvalid_0's tweedie: 252.635\n",
      "[107]\tvalid_0's tweedie: 252.635\n",
      "[108]\tvalid_0's tweedie: 252.635\n",
      "[109]\tvalid_0's tweedie: 252.635\n",
      "[110]\tvalid_0's tweedie: 252.635\n",
      "[111]\tvalid_0's tweedie: 252.634\n",
      "[112]\tvalid_0's tweedie: 252.632\n",
      "[113]\tvalid_0's tweedie: 252.631\n",
      "[114]\tvalid_0's tweedie: 252.631\n",
      "[115]\tvalid_0's tweedie: 252.631\n",
      "[116]\tvalid_0's tweedie: 252.628\n",
      "[117]\tvalid_0's tweedie: 252.628\n",
      "[118]\tvalid_0's tweedie: 252.627\n",
      "[119]\tvalid_0's tweedie: 252.628\n",
      "[120]\tvalid_0's tweedie: 252.627\n",
      "[121]\tvalid_0's tweedie: 252.627\n",
      "[122]\tvalid_0's tweedie: 252.626\n",
      "[123]\tvalid_0's tweedie: 252.626\n",
      "[124]\tvalid_0's tweedie: 252.626\n",
      "[125]\tvalid_0's tweedie: 252.627\n",
      "[126]\tvalid_0's tweedie: 252.627\n",
      "[127]\tvalid_0's tweedie: 252.627\n",
      "[128]\tvalid_0's tweedie: 252.625\n",
      "[129]\tvalid_0's tweedie: 252.625\n",
      "[130]\tvalid_0's tweedie: 252.625\n",
      "[131]\tvalid_0's tweedie: 252.625\n",
      "[132]\tvalid_0's tweedie: 252.625\n",
      "[133]\tvalid_0's tweedie: 252.624\n",
      "[134]\tvalid_0's tweedie: 252.624\n",
      "[135]\tvalid_0's tweedie: 252.623\n",
      "[136]\tvalid_0's tweedie: 252.623\n",
      "[137]\tvalid_0's tweedie: 252.623\n",
      "[138]\tvalid_0's tweedie: 252.624\n",
      "[139]\tvalid_0's tweedie: 252.624\n",
      "[140]\tvalid_0's tweedie: 252.625\n",
      "[141]\tvalid_0's tweedie: 252.625\n",
      "[142]\tvalid_0's tweedie: 252.626\n",
      "[143]\tvalid_0's tweedie: 252.626\n",
      "[144]\tvalid_0's tweedie: 252.625\n",
      "[145]\tvalid_0's tweedie: 252.625\n",
      "[146]\tvalid_0's tweedie: 252.625\n",
      "[147]\tvalid_0's tweedie: 252.625\n",
      "[148]\tvalid_0's tweedie: 252.625\n",
      "[149]\tvalid_0's tweedie: 252.624\n",
      "[150]\tvalid_0's tweedie: 252.625\n",
      "[151]\tvalid_0's tweedie: 252.621\n",
      "[152]\tvalid_0's tweedie: 252.622\n",
      "[153]\tvalid_0's tweedie: 252.621\n",
      "[154]\tvalid_0's tweedie: 252.621\n",
      "[155]\tvalid_0's tweedie: 252.621\n",
      "[156]\tvalid_0's tweedie: 252.621\n",
      "[157]\tvalid_0's tweedie: 252.621\n",
      "[158]\tvalid_0's tweedie: 252.62\n",
      "[159]\tvalid_0's tweedie: 252.62\n",
      "[160]\tvalid_0's tweedie: 252.62\n",
      "[161]\tvalid_0's tweedie: 252.62\n",
      "[162]\tvalid_0's tweedie: 252.62\n",
      "[163]\tvalid_0's tweedie: 252.619\n",
      "[164]\tvalid_0's tweedie: 252.619\n",
      "[165]\tvalid_0's tweedie: 252.62\n",
      "[166]\tvalid_0's tweedie: 252.62\n",
      "[167]\tvalid_0's tweedie: 252.62\n",
      "[168]\tvalid_0's tweedie: 252.619\n",
      "[169]\tvalid_0's tweedie: 252.619\n",
      "[170]\tvalid_0's tweedie: 252.62\n",
      "[171]\tvalid_0's tweedie: 252.619\n",
      "[172]\tvalid_0's tweedie: 252.619\n",
      "[173]\tvalid_0's tweedie: 252.619\n",
      "[174]\tvalid_0's tweedie: 252.618\n",
      "[175]\tvalid_0's tweedie: 252.618\n",
      "[176]\tvalid_0's tweedie: 252.618\n",
      "[177]\tvalid_0's tweedie: 252.618\n",
      "[178]\tvalid_0's tweedie: 252.618\n",
      "[179]\tvalid_0's tweedie: 252.618\n",
      "[180]\tvalid_0's tweedie: 252.618\n",
      "[181]\tvalid_0's tweedie: 252.618\n",
      "[182]\tvalid_0's tweedie: 252.618\n",
      "[183]\tvalid_0's tweedie: 252.617\n",
      "[184]\tvalid_0's tweedie: 252.617\n",
      "[185]\tvalid_0's tweedie: 252.618\n",
      "[186]\tvalid_0's tweedie: 252.618\n",
      "[187]\tvalid_0's tweedie: 252.618\n",
      "[188]\tvalid_0's tweedie: 252.618\n",
      "[189]\tvalid_0's tweedie: 252.618\n",
      "[190]\tvalid_0's tweedie: 252.616\n",
      "[191]\tvalid_0's tweedie: 252.616\n",
      "[192]\tvalid_0's tweedie: 252.617\n",
      "[193]\tvalid_0's tweedie: 252.616\n",
      "[194]\tvalid_0's tweedie: 252.618\n",
      "[195]\tvalid_0's tweedie: 252.618\n",
      "[196]\tvalid_0's tweedie: 252.618\n",
      "[197]\tvalid_0's tweedie: 252.618\n",
      "[198]\tvalid_0's tweedie: 252.618\n",
      "[199]\tvalid_0's tweedie: 252.618\n",
      "[200]\tvalid_0's tweedie: 252.619\n",
      "[201]\tvalid_0's tweedie: 252.619\n",
      "[202]\tvalid_0's tweedie: 252.619\n",
      "[203]\tvalid_0's tweedie: 252.619\n",
      "[204]\tvalid_0's tweedie: 252.619\n",
      "[205]\tvalid_0's tweedie: 252.619\n",
      "[206]\tvalid_0's tweedie: 252.619\n",
      "[207]\tvalid_0's tweedie: 252.619\n",
      "[208]\tvalid_0's tweedie: 252.619\n",
      "[209]\tvalid_0's tweedie: 252.619\n",
      "[210]\tvalid_0's tweedie: 252.619\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's tweedie: 252.616\n",
      "Training model for level 6 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 16767, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245888\n",
      "[1]\tvalid_0's tweedie: 271.709\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.451\n",
      "[3]\tvalid_0's tweedie: 265.762\n",
      "[4]\tvalid_0's tweedie: 263.556\n",
      "[5]\tvalid_0's tweedie: 261.623\n",
      "[6]\tvalid_0's tweedie: 260.064\n",
      "[7]\tvalid_0's tweedie: 258.783\n",
      "[8]\tvalid_0's tweedie: 257.713\n",
      "[9]\tvalid_0's tweedie: 256.841\n",
      "[10]\tvalid_0's tweedie: 256.125\n",
      "[11]\tvalid_0's tweedie: 255.535\n",
      "[12]\tvalid_0's tweedie: 255.035\n",
      "[13]\tvalid_0's tweedie: 254.633\n",
      "[14]\tvalid_0's tweedie: 254.31\n",
      "[15]\tvalid_0's tweedie: 254.03\n",
      "[16]\tvalid_0's tweedie: 253.807\n",
      "[17]\tvalid_0's tweedie: 253.62\n",
      "[18]\tvalid_0's tweedie: 253.462\n",
      "[19]\tvalid_0's tweedie: 253.332\n",
      "[20]\tvalid_0's tweedie: 253.226\n",
      "[21]\tvalid_0's tweedie: 253.137\n",
      "[22]\tvalid_0's tweedie: 253.064\n",
      "[23]\tvalid_0's tweedie: 253.005\n",
      "[24]\tvalid_0's tweedie: 252.96\n",
      "[25]\tvalid_0's tweedie: 252.916\n",
      "[26]\tvalid_0's tweedie: 252.888\n",
      "[27]\tvalid_0's tweedie: 252.861\n",
      "[28]\tvalid_0's tweedie: 252.836\n",
      "[29]\tvalid_0's tweedie: 252.805\n",
      "[30]\tvalid_0's tweedie: 252.78\n",
      "[31]\tvalid_0's tweedie: 252.754\n",
      "[32]\tvalid_0's tweedie: 252.743\n",
      "[33]\tvalid_0's tweedie: 252.73\n",
      "[34]\tvalid_0's tweedie: 252.716\n",
      "[35]\tvalid_0's tweedie: 252.706\n",
      "[36]\tvalid_0's tweedie: 252.7\n",
      "[37]\tvalid_0's tweedie: 252.694\n",
      "[38]\tvalid_0's tweedie: 252.69\n",
      "[39]\tvalid_0's tweedie: 252.684\n",
      "[40]\tvalid_0's tweedie: 252.68\n",
      "[41]\tvalid_0's tweedie: 252.676\n",
      "[42]\tvalid_0's tweedie: 252.672\n",
      "[43]\tvalid_0's tweedie: 252.67\n",
      "[44]\tvalid_0's tweedie: 252.668\n",
      "[45]\tvalid_0's tweedie: 252.668\n",
      "[46]\tvalid_0's tweedie: 252.665\n",
      "[47]\tvalid_0's tweedie: 252.661\n",
      "[48]\tvalid_0's tweedie: 252.661\n",
      "[49]\tvalid_0's tweedie: 252.662\n",
      "[50]\tvalid_0's tweedie: 252.662\n",
      "[51]\tvalid_0's tweedie: 252.661\n",
      "[52]\tvalid_0's tweedie: 252.661\n",
      "[53]\tvalid_0's tweedie: 252.657\n",
      "[54]\tvalid_0's tweedie: 252.657\n",
      "[55]\tvalid_0's tweedie: 252.658\n",
      "[56]\tvalid_0's tweedie: 252.658\n",
      "[57]\tvalid_0's tweedie: 252.659\n",
      "[58]\tvalid_0's tweedie: 252.658\n",
      "[59]\tvalid_0's tweedie: 252.657\n",
      "[60]\tvalid_0's tweedie: 252.658\n",
      "[61]\tvalid_0's tweedie: 252.654\n",
      "[62]\tvalid_0's tweedie: 252.655\n",
      "[63]\tvalid_0's tweedie: 252.654\n",
      "[64]\tvalid_0's tweedie: 252.653\n",
      "[65]\tvalid_0's tweedie: 252.651\n",
      "[66]\tvalid_0's tweedie: 252.651\n",
      "[67]\tvalid_0's tweedie: 252.651\n",
      "[68]\tvalid_0's tweedie: 252.651\n",
      "[69]\tvalid_0's tweedie: 252.65\n",
      "[70]\tvalid_0's tweedie: 252.65\n",
      "[71]\tvalid_0's tweedie: 252.65\n",
      "[72]\tvalid_0's tweedie: 252.65\n",
      "[73]\tvalid_0's tweedie: 252.65\n",
      "[74]\tvalid_0's tweedie: 252.651\n",
      "[75]\tvalid_0's tweedie: 252.651\n",
      "[76]\tvalid_0's tweedie: 252.651\n",
      "[77]\tvalid_0's tweedie: 252.65\n",
      "[78]\tvalid_0's tweedie: 252.647\n",
      "[79]\tvalid_0's tweedie: 252.648\n",
      "[80]\tvalid_0's tweedie: 252.648\n",
      "[81]\tvalid_0's tweedie: 252.645\n",
      "[82]\tvalid_0's tweedie: 252.645\n",
      "[83]\tvalid_0's tweedie: 252.645\n",
      "[84]\tvalid_0's tweedie: 252.645\n",
      "[85]\tvalid_0's tweedie: 252.646\n",
      "[86]\tvalid_0's tweedie: 252.646\n",
      "[87]\tvalid_0's tweedie: 252.645\n",
      "[88]\tvalid_0's tweedie: 252.645\n",
      "[89]\tvalid_0's tweedie: 252.645\n",
      "[90]\tvalid_0's tweedie: 252.645\n",
      "[91]\tvalid_0's tweedie: 252.644\n",
      "[92]\tvalid_0's tweedie: 252.643\n",
      "[93]\tvalid_0's tweedie: 252.643\n",
      "[94]\tvalid_0's tweedie: 252.642\n",
      "[95]\tvalid_0's tweedie: 252.642\n",
      "[96]\tvalid_0's tweedie: 252.642\n",
      "[97]\tvalid_0's tweedie: 252.642\n",
      "[98]\tvalid_0's tweedie: 252.642\n",
      "[99]\tvalid_0's tweedie: 252.642\n",
      "[100]\tvalid_0's tweedie: 252.638\n",
      "[101]\tvalid_0's tweedie: 252.637\n",
      "[102]\tvalid_0's tweedie: 252.638\n",
      "[103]\tvalid_0's tweedie: 252.639\n",
      "[104]\tvalid_0's tweedie: 252.638\n",
      "[105]\tvalid_0's tweedie: 252.638\n",
      "[106]\tvalid_0's tweedie: 252.639\n",
      "[107]\tvalid_0's tweedie: 252.639\n",
      "[108]\tvalid_0's tweedie: 252.635\n",
      "[109]\tvalid_0's tweedie: 252.635\n",
      "[110]\tvalid_0's tweedie: 252.635\n",
      "[111]\tvalid_0's tweedie: 252.636\n",
      "[112]\tvalid_0's tweedie: 252.636\n",
      "[113]\tvalid_0's tweedie: 252.636\n",
      "[114]\tvalid_0's tweedie: 252.636\n",
      "[115]\tvalid_0's tweedie: 252.636\n",
      "[116]\tvalid_0's tweedie: 252.636\n",
      "[117]\tvalid_0's tweedie: 252.635\n",
      "[118]\tvalid_0's tweedie: 252.636\n",
      "[119]\tvalid_0's tweedie: 252.635\n",
      "[120]\tvalid_0's tweedie: 252.635\n",
      "[121]\tvalid_0's tweedie: 252.634\n",
      "[122]\tvalid_0's tweedie: 252.634\n",
      "[123]\tvalid_0's tweedie: 252.634\n",
      "[124]\tvalid_0's tweedie: 252.63\n",
      "[125]\tvalid_0's tweedie: 252.63\n",
      "[126]\tvalid_0's tweedie: 252.63\n",
      "[127]\tvalid_0's tweedie: 252.631\n",
      "[128]\tvalid_0's tweedie: 252.63\n",
      "[129]\tvalid_0's tweedie: 252.628\n",
      "[130]\tvalid_0's tweedie: 252.628\n",
      "[131]\tvalid_0's tweedie: 252.629\n",
      "[132]\tvalid_0's tweedie: 252.629\n",
      "[133]\tvalid_0's tweedie: 252.629\n",
      "[134]\tvalid_0's tweedie: 252.629\n",
      "[135]\tvalid_0's tweedie: 252.629\n",
      "[136]\tvalid_0's tweedie: 252.628\n",
      "[137]\tvalid_0's tweedie: 252.628\n",
      "[138]\tvalid_0's tweedie: 252.628\n",
      "[139]\tvalid_0's tweedie: 252.628\n",
      "[140]\tvalid_0's tweedie: 252.628\n",
      "[141]\tvalid_0's tweedie: 252.628\n",
      "[142]\tvalid_0's tweedie: 252.628\n",
      "[143]\tvalid_0's tweedie: 252.628\n",
      "[144]\tvalid_0's tweedie: 252.628\n",
      "[145]\tvalid_0's tweedie: 252.628\n",
      "[146]\tvalid_0's tweedie: 252.628\n",
      "[147]\tvalid_0's tweedie: 252.628\n",
      "[148]\tvalid_0's tweedie: 252.628\n",
      "[149]\tvalid_0's tweedie: 252.628\n",
      "[150]\tvalid_0's tweedie: 252.627\n",
      "[151]\tvalid_0's tweedie: 252.627\n",
      "[152]\tvalid_0's tweedie: 252.626\n",
      "[153]\tvalid_0's tweedie: 252.626\n",
      "[154]\tvalid_0's tweedie: 252.626\n",
      "[155]\tvalid_0's tweedie: 252.626\n",
      "[156]\tvalid_0's tweedie: 252.626\n",
      "[157]\tvalid_0's tweedie: 252.626\n",
      "[158]\tvalid_0's tweedie: 252.627\n",
      "[159]\tvalid_0's tweedie: 252.626\n",
      "[160]\tvalid_0's tweedie: 252.626\n",
      "[161]\tvalid_0's tweedie: 252.626\n",
      "[162]\tvalid_0's tweedie: 252.626\n",
      "[163]\tvalid_0's tweedie: 252.625\n",
      "[164]\tvalid_0's tweedie: 252.626\n",
      "[165]\tvalid_0's tweedie: 252.626\n",
      "[166]\tvalid_0's tweedie: 252.625\n",
      "[167]\tvalid_0's tweedie: 252.625\n",
      "[168]\tvalid_0's tweedie: 252.625\n",
      "[169]\tvalid_0's tweedie: 252.625\n",
      "[170]\tvalid_0's tweedie: 252.624\n",
      "[171]\tvalid_0's tweedie: 252.624\n",
      "[172]\tvalid_0's tweedie: 252.624\n",
      "[173]\tvalid_0's tweedie: 252.623\n",
      "[174]\tvalid_0's tweedie: 252.623\n",
      "[175]\tvalid_0's tweedie: 252.623\n",
      "[176]\tvalid_0's tweedie: 252.623\n",
      "[177]\tvalid_0's tweedie: 252.623\n",
      "[178]\tvalid_0's tweedie: 252.622\n",
      "[179]\tvalid_0's tweedie: 252.622\n",
      "[180]\tvalid_0's tweedie: 252.621\n",
      "[181]\tvalid_0's tweedie: 252.62\n",
      "[182]\tvalid_0's tweedie: 252.62\n",
      "[183]\tvalid_0's tweedie: 252.62\n",
      "[184]\tvalid_0's tweedie: 252.619\n",
      "[185]\tvalid_0's tweedie: 252.618\n",
      "[186]\tvalid_0's tweedie: 252.618\n",
      "[187]\tvalid_0's tweedie: 252.618\n",
      "[188]\tvalid_0's tweedie: 252.618\n",
      "[189]\tvalid_0's tweedie: 252.618\n",
      "[190]\tvalid_0's tweedie: 252.618\n",
      "[191]\tvalid_0's tweedie: 252.619\n",
      "[192]\tvalid_0's tweedie: 252.619\n",
      "[193]\tvalid_0's tweedie: 252.619\n",
      "[194]\tvalid_0's tweedie: 252.618\n",
      "[195]\tvalid_0's tweedie: 252.619\n",
      "[196]\tvalid_0's tweedie: 252.619\n",
      "[197]\tvalid_0's tweedie: 252.619\n",
      "[198]\tvalid_0's tweedie: 252.619\n",
      "[199]\tvalid_0's tweedie: 252.619\n",
      "[200]\tvalid_0's tweedie: 252.618\n",
      "[201]\tvalid_0's tweedie: 252.618\n",
      "[202]\tvalid_0's tweedie: 252.618\n",
      "[203]\tvalid_0's tweedie: 252.618\n",
      "[204]\tvalid_0's tweedie: 252.618\n",
      "[205]\tvalid_0's tweedie: 252.618\n",
      "[206]\tvalid_0's tweedie: 252.618\n",
      "[207]\tvalid_0's tweedie: 252.619\n",
      "[208]\tvalid_0's tweedie: 252.619\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's tweedie: 252.618\n",
      "Training model for level 6 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 16758, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.245966\n",
      "[1]\tvalid_0's tweedie: 271.702\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.447\n",
      "[3]\tvalid_0's tweedie: 265.799\n",
      "[4]\tvalid_0's tweedie: 263.501\n",
      "[5]\tvalid_0's tweedie: 261.617\n",
      "[6]\tvalid_0's tweedie: 260.054\n",
      "[7]\tvalid_0's tweedie: 258.76\n",
      "[8]\tvalid_0's tweedie: 257.681\n",
      "[9]\tvalid_0's tweedie: 256.793\n",
      "[10]\tvalid_0's tweedie: 256.084\n",
      "[11]\tvalid_0's tweedie: 255.485\n",
      "[12]\tvalid_0's tweedie: 254.996\n",
      "[13]\tvalid_0's tweedie: 254.59\n",
      "[14]\tvalid_0's tweedie: 254.27\n",
      "[15]\tvalid_0's tweedie: 254.03\n",
      "[16]\tvalid_0's tweedie: 253.8\n",
      "[17]\tvalid_0's tweedie: 253.61\n",
      "[18]\tvalid_0's tweedie: 253.462\n",
      "[19]\tvalid_0's tweedie: 253.338\n",
      "[20]\tvalid_0's tweedie: 253.237\n",
      "[21]\tvalid_0's tweedie: 253.148\n",
      "[22]\tvalid_0's tweedie: 253.075\n",
      "[23]\tvalid_0's tweedie: 253.017\n",
      "[24]\tvalid_0's tweedie: 252.967\n",
      "[25]\tvalid_0's tweedie: 252.924\n",
      "[26]\tvalid_0's tweedie: 252.878\n",
      "[27]\tvalid_0's tweedie: 252.846\n",
      "[28]\tvalid_0's tweedie: 252.825\n",
      "[29]\tvalid_0's tweedie: 252.804\n",
      "[30]\tvalid_0's tweedie: 252.788\n",
      "[31]\tvalid_0's tweedie: 252.774\n",
      "[32]\tvalid_0's tweedie: 252.748\n",
      "[33]\tvalid_0's tweedie: 252.725\n",
      "[34]\tvalid_0's tweedie: 252.711\n",
      "[35]\tvalid_0's tweedie: 252.704\n",
      "[36]\tvalid_0's tweedie: 252.694\n",
      "[37]\tvalid_0's tweedie: 252.687\n",
      "[38]\tvalid_0's tweedie: 252.683\n",
      "[39]\tvalid_0's tweedie: 252.68\n",
      "[40]\tvalid_0's tweedie: 252.676\n",
      "[41]\tvalid_0's tweedie: 252.673\n",
      "[42]\tvalid_0's tweedie: 252.674\n",
      "[43]\tvalid_0's tweedie: 252.673\n",
      "[44]\tvalid_0's tweedie: 252.673\n",
      "[45]\tvalid_0's tweedie: 252.67\n",
      "[46]\tvalid_0's tweedie: 252.666\n",
      "[47]\tvalid_0's tweedie: 252.665\n",
      "[48]\tvalid_0's tweedie: 252.665\n",
      "[49]\tvalid_0's tweedie: 252.661\n",
      "[50]\tvalid_0's tweedie: 252.657\n",
      "[51]\tvalid_0's tweedie: 252.66\n",
      "[52]\tvalid_0's tweedie: 252.662\n",
      "[53]\tvalid_0's tweedie: 252.661\n",
      "[54]\tvalid_0's tweedie: 252.661\n",
      "[55]\tvalid_0's tweedie: 252.658\n",
      "[56]\tvalid_0's tweedie: 252.655\n",
      "[57]\tvalid_0's tweedie: 252.655\n",
      "[58]\tvalid_0's tweedie: 252.656\n",
      "[59]\tvalid_0's tweedie: 252.654\n",
      "[60]\tvalid_0's tweedie: 252.655\n",
      "[61]\tvalid_0's tweedie: 252.652\n",
      "[62]\tvalid_0's tweedie: 252.651\n",
      "[63]\tvalid_0's tweedie: 252.652\n",
      "[64]\tvalid_0's tweedie: 252.652\n",
      "[65]\tvalid_0's tweedie: 252.652\n",
      "[66]\tvalid_0's tweedie: 252.653\n",
      "[67]\tvalid_0's tweedie: 252.651\n",
      "[68]\tvalid_0's tweedie: 252.651\n",
      "[69]\tvalid_0's tweedie: 252.651\n",
      "[70]\tvalid_0's tweedie: 252.652\n",
      "[71]\tvalid_0's tweedie: 252.652\n",
      "[72]\tvalid_0's tweedie: 252.652\n",
      "[73]\tvalid_0's tweedie: 252.652\n",
      "[74]\tvalid_0's tweedie: 252.651\n",
      "[75]\tvalid_0's tweedie: 252.651\n",
      "[76]\tvalid_0's tweedie: 252.652\n",
      "[77]\tvalid_0's tweedie: 252.651\n",
      "[78]\tvalid_0's tweedie: 252.649\n",
      "[79]\tvalid_0's tweedie: 252.649\n",
      "[80]\tvalid_0's tweedie: 252.65\n",
      "[81]\tvalid_0's tweedie: 252.65\n",
      "[82]\tvalid_0's tweedie: 252.651\n",
      "[83]\tvalid_0's tweedie: 252.651\n",
      "[84]\tvalid_0's tweedie: 252.651\n",
      "[85]\tvalid_0's tweedie: 252.651\n",
      "[86]\tvalid_0's tweedie: 252.651\n",
      "[87]\tvalid_0's tweedie: 252.65\n",
      "[88]\tvalid_0's tweedie: 252.647\n",
      "[89]\tvalid_0's tweedie: 252.647\n",
      "[90]\tvalid_0's tweedie: 252.647\n",
      "[91]\tvalid_0's tweedie: 252.647\n",
      "[92]\tvalid_0's tweedie: 252.647\n",
      "[93]\tvalid_0's tweedie: 252.647\n",
      "[94]\tvalid_0's tweedie: 252.647\n",
      "[95]\tvalid_0's tweedie: 252.647\n",
      "[96]\tvalid_0's tweedie: 252.648\n",
      "[97]\tvalid_0's tweedie: 252.647\n",
      "[98]\tvalid_0's tweedie: 252.648\n",
      "[99]\tvalid_0's tweedie: 252.646\n",
      "[100]\tvalid_0's tweedie: 252.647\n",
      "[101]\tvalid_0's tweedie: 252.646\n",
      "[102]\tvalid_0's tweedie: 252.646\n",
      "[103]\tvalid_0's tweedie: 252.645\n",
      "[104]\tvalid_0's tweedie: 252.643\n",
      "[105]\tvalid_0's tweedie: 252.643\n",
      "[106]\tvalid_0's tweedie: 252.643\n",
      "[107]\tvalid_0's tweedie: 252.644\n",
      "[108]\tvalid_0's tweedie: 252.645\n",
      "[109]\tvalid_0's tweedie: 252.645\n",
      "[110]\tvalid_0's tweedie: 252.645\n",
      "[111]\tvalid_0's tweedie: 252.645\n",
      "[112]\tvalid_0's tweedie: 252.644\n",
      "[113]\tvalid_0's tweedie: 252.643\n",
      "[114]\tvalid_0's tweedie: 252.643\n",
      "[115]\tvalid_0's tweedie: 252.643\n",
      "[116]\tvalid_0's tweedie: 252.643\n",
      "[117]\tvalid_0's tweedie: 252.643\n",
      "[118]\tvalid_0's tweedie: 252.643\n",
      "[119]\tvalid_0's tweedie: 252.643\n",
      "[120]\tvalid_0's tweedie: 252.643\n",
      "[121]\tvalid_0's tweedie: 252.643\n",
      "[122]\tvalid_0's tweedie: 252.643\n",
      "[123]\tvalid_0's tweedie: 252.643\n",
      "[124]\tvalid_0's tweedie: 252.643\n",
      "[125]\tvalid_0's tweedie: 252.643\n",
      "[126]\tvalid_0's tweedie: 252.643\n",
      "[127]\tvalid_0's tweedie: 252.644\n",
      "[128]\tvalid_0's tweedie: 252.644\n",
      "[129]\tvalid_0's tweedie: 252.644\n",
      "[130]\tvalid_0's tweedie: 252.645\n",
      "[131]\tvalid_0's tweedie: 252.642\n",
      "[132]\tvalid_0's tweedie: 252.642\n",
      "[133]\tvalid_0's tweedie: 252.642\n",
      "[134]\tvalid_0's tweedie: 252.642\n",
      "[135]\tvalid_0's tweedie: 252.641\n",
      "[136]\tvalid_0's tweedie: 252.641\n",
      "[137]\tvalid_0's tweedie: 252.641\n",
      "[138]\tvalid_0's tweedie: 252.642\n",
      "[139]\tvalid_0's tweedie: 252.642\n",
      "[140]\tvalid_0's tweedie: 252.642\n",
      "[141]\tvalid_0's tweedie: 252.642\n",
      "[142]\tvalid_0's tweedie: 252.642\n",
      "[143]\tvalid_0's tweedie: 252.642\n",
      "[144]\tvalid_0's tweedie: 252.642\n",
      "[145]\tvalid_0's tweedie: 252.642\n",
      "[146]\tvalid_0's tweedie: 252.642\n",
      "[147]\tvalid_0's tweedie: 252.642\n",
      "[148]\tvalid_0's tweedie: 252.642\n",
      "[149]\tvalid_0's tweedie: 252.642\n",
      "[150]\tvalid_0's tweedie: 252.642\n",
      "[151]\tvalid_0's tweedie: 252.642\n",
      "[152]\tvalid_0's tweedie: 252.639\n",
      "[153]\tvalid_0's tweedie: 252.638\n",
      "[154]\tvalid_0's tweedie: 252.639\n",
      "[155]\tvalid_0's tweedie: 252.639\n",
      "[156]\tvalid_0's tweedie: 252.639\n",
      "[157]\tvalid_0's tweedie: 252.638\n",
      "[158]\tvalid_0's tweedie: 252.638\n",
      "[159]\tvalid_0's tweedie: 252.638\n",
      "[160]\tvalid_0's tweedie: 252.638\n",
      "[161]\tvalid_0's tweedie: 252.635\n",
      "[162]\tvalid_0's tweedie: 252.635\n",
      "[163]\tvalid_0's tweedie: 252.635\n",
      "[164]\tvalid_0's tweedie: 252.635\n",
      "[165]\tvalid_0's tweedie: 252.632\n",
      "[166]\tvalid_0's tweedie: 252.633\n",
      "[167]\tvalid_0's tweedie: 252.633\n",
      "[168]\tvalid_0's tweedie: 252.633\n",
      "[169]\tvalid_0's tweedie: 252.634\n",
      "[170]\tvalid_0's tweedie: 252.634\n",
      "[171]\tvalid_0's tweedie: 252.633\n",
      "[172]\tvalid_0's tweedie: 252.631\n",
      "[173]\tvalid_0's tweedie: 252.631\n",
      "[174]\tvalid_0's tweedie: 252.631\n",
      "[175]\tvalid_0's tweedie: 252.631\n",
      "[176]\tvalid_0's tweedie: 252.631\n",
      "[177]\tvalid_0's tweedie: 252.631\n",
      "[178]\tvalid_0's tweedie: 252.63\n",
      "[179]\tvalid_0's tweedie: 252.631\n",
      "[180]\tvalid_0's tweedie: 252.631\n",
      "[181]\tvalid_0's tweedie: 252.631\n",
      "[182]\tvalid_0's tweedie: 252.631\n",
      "[183]\tvalid_0's tweedie: 252.631\n",
      "[184]\tvalid_0's tweedie: 252.63\n",
      "[185]\tvalid_0's tweedie: 252.63\n",
      "[186]\tvalid_0's tweedie: 252.63\n",
      "[187]\tvalid_0's tweedie: 252.63\n",
      "[188]\tvalid_0's tweedie: 252.63\n",
      "[189]\tvalid_0's tweedie: 252.63\n",
      "[190]\tvalid_0's tweedie: 252.631\n",
      "[191]\tvalid_0's tweedie: 252.631\n",
      "[192]\tvalid_0's tweedie: 252.631\n",
      "[193]\tvalid_0's tweedie: 252.63\n",
      "[194]\tvalid_0's tweedie: 252.631\n",
      "[195]\tvalid_0's tweedie: 252.631\n",
      "[196]\tvalid_0's tweedie: 252.631\n",
      "[197]\tvalid_0's tweedie: 252.631\n",
      "[198]\tvalid_0's tweedie: 252.631\n",
      "[199]\tvalid_0's tweedie: 252.631\n",
      "[200]\tvalid_0's tweedie: 252.631\n",
      "[201]\tvalid_0's tweedie: 252.631\n",
      "[202]\tvalid_0's tweedie: 252.631\n",
      "[203]\tvalid_0's tweedie: 252.631\n",
      "[204]\tvalid_0's tweedie: 252.631\n",
      "[205]\tvalid_0's tweedie: 252.631\n",
      "[206]\tvalid_0's tweedie: 252.631\n",
      "[207]\tvalid_0's tweedie: 252.631\n",
      "[208]\tvalid_0's tweedie: 252.63\n",
      "[209]\tvalid_0's tweedie: 252.63\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's tweedie: 252.63\n",
      "Training model for level 6 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 16749, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.246128\n",
      "[1]\tvalid_0's tweedie: 271.708\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.477\n",
      "[3]\tvalid_0's tweedie: 265.782\n",
      "[4]\tvalid_0's tweedie: 263.587\n",
      "[5]\tvalid_0's tweedie: 261.712\n",
      "[6]\tvalid_0's tweedie: 260.147\n",
      "[7]\tvalid_0's tweedie: 258.834\n",
      "[8]\tvalid_0's tweedie: 257.771\n",
      "[9]\tvalid_0's tweedie: 256.879\n",
      "[10]\tvalid_0's tweedie: 256.139\n",
      "[11]\tvalid_0's tweedie: 255.539\n",
      "[12]\tvalid_0's tweedie: 255.05\n",
      "[13]\tvalid_0's tweedie: 254.645\n",
      "[14]\tvalid_0's tweedie: 254.312\n",
      "[15]\tvalid_0's tweedie: 254.063\n",
      "[16]\tvalid_0's tweedie: 253.832\n",
      "[17]\tvalid_0's tweedie: 253.635\n",
      "[18]\tvalid_0's tweedie: 253.481\n",
      "[19]\tvalid_0's tweedie: 253.355\n",
      "[20]\tvalid_0's tweedie: 253.243\n",
      "[21]\tvalid_0's tweedie: 253.157\n",
      "[22]\tvalid_0's tweedie: 253.086\n",
      "[23]\tvalid_0's tweedie: 253.034\n",
      "[24]\tvalid_0's tweedie: 252.973\n",
      "[25]\tvalid_0's tweedie: 252.929\n",
      "[26]\tvalid_0's tweedie: 252.898\n",
      "[27]\tvalid_0's tweedie: 252.871\n",
      "[28]\tvalid_0's tweedie: 252.838\n",
      "[29]\tvalid_0's tweedie: 252.817\n",
      "[30]\tvalid_0's tweedie: 252.791\n",
      "[31]\tvalid_0's tweedie: 252.777\n",
      "[32]\tvalid_0's tweedie: 252.768\n",
      "[33]\tvalid_0's tweedie: 252.758\n",
      "[34]\tvalid_0's tweedie: 252.742\n",
      "[35]\tvalid_0's tweedie: 252.731\n",
      "[36]\tvalid_0's tweedie: 252.725\n",
      "[37]\tvalid_0's tweedie: 252.721\n",
      "[38]\tvalid_0's tweedie: 252.716\n",
      "[39]\tvalid_0's tweedie: 252.709\n",
      "[40]\tvalid_0's tweedie: 252.706\n",
      "[41]\tvalid_0's tweedie: 252.702\n",
      "[42]\tvalid_0's tweedie: 252.7\n",
      "[43]\tvalid_0's tweedie: 252.696\n",
      "[44]\tvalid_0's tweedie: 252.689\n",
      "[45]\tvalid_0's tweedie: 252.685\n",
      "[46]\tvalid_0's tweedie: 252.681\n",
      "[47]\tvalid_0's tweedie: 252.68\n",
      "[48]\tvalid_0's tweedie: 252.68\n",
      "[49]\tvalid_0's tweedie: 252.68\n",
      "[50]\tvalid_0's tweedie: 252.677\n",
      "[51]\tvalid_0's tweedie: 252.676\n",
      "[52]\tvalid_0's tweedie: 252.674\n",
      "[53]\tvalid_0's tweedie: 252.675\n",
      "[54]\tvalid_0's tweedie: 252.672\n",
      "[55]\tvalid_0's tweedie: 252.674\n",
      "[56]\tvalid_0's tweedie: 252.675\n",
      "[57]\tvalid_0's tweedie: 252.675\n",
      "[58]\tvalid_0's tweedie: 252.674\n",
      "[59]\tvalid_0's tweedie: 252.675\n",
      "[60]\tvalid_0's tweedie: 252.677\n",
      "[61]\tvalid_0's tweedie: 252.675\n",
      "[62]\tvalid_0's tweedie: 252.672\n",
      "[63]\tvalid_0's tweedie: 252.672\n",
      "[64]\tvalid_0's tweedie: 252.673\n",
      "[65]\tvalid_0's tweedie: 252.671\n",
      "[66]\tvalid_0's tweedie: 252.668\n",
      "[67]\tvalid_0's tweedie: 252.667\n",
      "[68]\tvalid_0's tweedie: 252.669\n",
      "[69]\tvalid_0's tweedie: 252.668\n",
      "[70]\tvalid_0's tweedie: 252.668\n",
      "[71]\tvalid_0's tweedie: 252.668\n",
      "[72]\tvalid_0's tweedie: 252.668\n",
      "[73]\tvalid_0's tweedie: 252.668\n",
      "[74]\tvalid_0's tweedie: 252.667\n",
      "[75]\tvalid_0's tweedie: 252.667\n",
      "[76]\tvalid_0's tweedie: 252.666\n",
      "[77]\tvalid_0's tweedie: 252.665\n",
      "[78]\tvalid_0's tweedie: 252.666\n",
      "[79]\tvalid_0's tweedie: 252.666\n",
      "[80]\tvalid_0's tweedie: 252.663\n",
      "[81]\tvalid_0's tweedie: 252.663\n",
      "[82]\tvalid_0's tweedie: 252.664\n",
      "[83]\tvalid_0's tweedie: 252.664\n",
      "[84]\tvalid_0's tweedie: 252.662\n",
      "[85]\tvalid_0's tweedie: 252.662\n",
      "[86]\tvalid_0's tweedie: 252.662\n",
      "[87]\tvalid_0's tweedie: 252.662\n",
      "[88]\tvalid_0's tweedie: 252.662\n",
      "[89]\tvalid_0's tweedie: 252.662\n",
      "[90]\tvalid_0's tweedie: 252.663\n",
      "[91]\tvalid_0's tweedie: 252.661\n",
      "[92]\tvalid_0's tweedie: 252.661\n",
      "[93]\tvalid_0's tweedie: 252.661\n",
      "[94]\tvalid_0's tweedie: 252.661\n",
      "[95]\tvalid_0's tweedie: 252.66\n",
      "[96]\tvalid_0's tweedie: 252.66\n",
      "[97]\tvalid_0's tweedie: 252.66\n",
      "[98]\tvalid_0's tweedie: 252.66\n",
      "[99]\tvalid_0's tweedie: 252.66\n",
      "[100]\tvalid_0's tweedie: 252.66\n",
      "[101]\tvalid_0's tweedie: 252.66\n",
      "[102]\tvalid_0's tweedie: 252.659\n",
      "[103]\tvalid_0's tweedie: 252.659\n",
      "[104]\tvalid_0's tweedie: 252.659\n",
      "[105]\tvalid_0's tweedie: 252.659\n",
      "[106]\tvalid_0's tweedie: 252.656\n",
      "[107]\tvalid_0's tweedie: 252.657\n",
      "[108]\tvalid_0's tweedie: 252.657\n",
      "[109]\tvalid_0's tweedie: 252.657\n",
      "[110]\tvalid_0's tweedie: 252.658\n",
      "[111]\tvalid_0's tweedie: 252.657\n",
      "[112]\tvalid_0's tweedie: 252.657\n",
      "[113]\tvalid_0's tweedie: 252.658\n",
      "[114]\tvalid_0's tweedie: 252.657\n",
      "[115]\tvalid_0's tweedie: 252.657\n",
      "[116]\tvalid_0's tweedie: 252.658\n",
      "[117]\tvalid_0's tweedie: 252.657\n",
      "[118]\tvalid_0's tweedie: 252.654\n",
      "[119]\tvalid_0's tweedie: 252.654\n",
      "[120]\tvalid_0's tweedie: 252.655\n",
      "[121]\tvalid_0's tweedie: 252.655\n",
      "[122]\tvalid_0's tweedie: 252.655\n",
      "[123]\tvalid_0's tweedie: 252.654\n",
      "[124]\tvalid_0's tweedie: 252.651\n",
      "[125]\tvalid_0's tweedie: 252.651\n",
      "[126]\tvalid_0's tweedie: 252.651\n",
      "[127]\tvalid_0's tweedie: 252.651\n",
      "[128]\tvalid_0's tweedie: 252.651\n",
      "[129]\tvalid_0's tweedie: 252.651\n",
      "[130]\tvalid_0's tweedie: 252.651\n",
      "[131]\tvalid_0's tweedie: 252.651\n",
      "[132]\tvalid_0's tweedie: 252.65\n",
      "[133]\tvalid_0's tweedie: 252.65\n",
      "[134]\tvalid_0's tweedie: 252.65\n",
      "[135]\tvalid_0's tweedie: 252.65\n",
      "[136]\tvalid_0's tweedie: 252.65\n",
      "[137]\tvalid_0's tweedie: 252.65\n",
      "[138]\tvalid_0's tweedie: 252.65\n",
      "[139]\tvalid_0's tweedie: 252.65\n",
      "[140]\tvalid_0's tweedie: 252.65\n",
      "[141]\tvalid_0's tweedie: 252.649\n",
      "[142]\tvalid_0's tweedie: 252.648\n",
      "[143]\tvalid_0's tweedie: 252.648\n",
      "[144]\tvalid_0's tweedie: 252.648\n",
      "[145]\tvalid_0's tweedie: 252.648\n",
      "[146]\tvalid_0's tweedie: 252.648\n",
      "[147]\tvalid_0's tweedie: 252.648\n",
      "[148]\tvalid_0's tweedie: 252.648\n",
      "[149]\tvalid_0's tweedie: 252.648\n",
      "[150]\tvalid_0's tweedie: 252.649\n",
      "[151]\tvalid_0's tweedie: 252.649\n",
      "[152]\tvalid_0's tweedie: 252.65\n",
      "[153]\tvalid_0's tweedie: 252.65\n",
      "[154]\tvalid_0's tweedie: 252.646\n",
      "[155]\tvalid_0's tweedie: 252.646\n",
      "[156]\tvalid_0's tweedie: 252.644\n",
      "[157]\tvalid_0's tweedie: 252.644\n",
      "[158]\tvalid_0's tweedie: 252.644\n",
      "[159]\tvalid_0's tweedie: 252.644\n",
      "[160]\tvalid_0's tweedie: 252.644\n",
      "[161]\tvalid_0's tweedie: 252.644\n",
      "[162]\tvalid_0's tweedie: 252.644\n",
      "[163]\tvalid_0's tweedie: 252.644\n",
      "[164]\tvalid_0's tweedie: 252.644\n",
      "[165]\tvalid_0's tweedie: 252.64\n",
      "[166]\tvalid_0's tweedie: 252.64\n",
      "[167]\tvalid_0's tweedie: 252.641\n",
      "[168]\tvalid_0's tweedie: 252.64\n",
      "[169]\tvalid_0's tweedie: 252.64\n",
      "[170]\tvalid_0's tweedie: 252.64\n",
      "[171]\tvalid_0's tweedie: 252.639\n",
      "[172]\tvalid_0's tweedie: 252.639\n",
      "[173]\tvalid_0's tweedie: 252.639\n",
      "[174]\tvalid_0's tweedie: 252.639\n",
      "[175]\tvalid_0's tweedie: 252.638\n",
      "[176]\tvalid_0's tweedie: 252.639\n",
      "[177]\tvalid_0's tweedie: 252.639\n",
      "[178]\tvalid_0's tweedie: 252.639\n",
      "[179]\tvalid_0's tweedie: 252.639\n",
      "[180]\tvalid_0's tweedie: 252.639\n",
      "[181]\tvalid_0's tweedie: 252.639\n",
      "[182]\tvalid_0's tweedie: 252.639\n",
      "[183]\tvalid_0's tweedie: 252.639\n",
      "[184]\tvalid_0's tweedie: 252.639\n",
      "[185]\tvalid_0's tweedie: 252.638\n",
      "[186]\tvalid_0's tweedie: 252.638\n",
      "[187]\tvalid_0's tweedie: 252.638\n",
      "[188]\tvalid_0's tweedie: 252.638\n",
      "[189]\tvalid_0's tweedie: 252.639\n",
      "[190]\tvalid_0's tweedie: 252.637\n",
      "[191]\tvalid_0's tweedie: 252.637\n",
      "[192]\tvalid_0's tweedie: 252.637\n",
      "[193]\tvalid_0's tweedie: 252.637\n",
      "[194]\tvalid_0's tweedie: 252.637\n",
      "[195]\tvalid_0's tweedie: 252.637\n",
      "[196]\tvalid_0's tweedie: 252.637\n",
      "[197]\tvalid_0's tweedie: 252.637\n",
      "[198]\tvalid_0's tweedie: 252.636\n",
      "[199]\tvalid_0's tweedie: 252.636\n",
      "[200]\tvalid_0's tweedie: 252.636\n",
      "[201]\tvalid_0's tweedie: 252.636\n",
      "[202]\tvalid_0's tweedie: 252.636\n",
      "[203]\tvalid_0's tweedie: 252.636\n",
      "[204]\tvalid_0's tweedie: 252.636\n",
      "[205]\tvalid_0's tweedie: 252.636\n",
      "[206]\tvalid_0's tweedie: 252.636\n",
      "[207]\tvalid_0's tweedie: 252.636\n",
      "[208]\tvalid_0's tweedie: 252.636\n",
      "[209]\tvalid_0's tweedie: 252.637\n",
      "[210]\tvalid_0's tweedie: 252.636\n",
      "[211]\tvalid_0's tweedie: 252.636\n",
      "[212]\tvalid_0's tweedie: 252.634\n",
      "[213]\tvalid_0's tweedie: 252.634\n",
      "[214]\tvalid_0's tweedie: 252.634\n",
      "[215]\tvalid_0's tweedie: 252.634\n",
      "[216]\tvalid_0's tweedie: 252.634\n",
      "[217]\tvalid_0's tweedie: 252.635\n",
      "[218]\tvalid_0's tweedie: 252.635\n",
      "[219]\tvalid_0's tweedie: 252.634\n",
      "[220]\tvalid_0's tweedie: 252.635\n",
      "[221]\tvalid_0's tweedie: 252.633\n",
      "[222]\tvalid_0's tweedie: 252.633\n",
      "[223]\tvalid_0's tweedie: 252.633\n",
      "[224]\tvalid_0's tweedie: 252.633\n",
      "[225]\tvalid_0's tweedie: 252.633\n",
      "[226]\tvalid_0's tweedie: 252.634\n",
      "[227]\tvalid_0's tweedie: 252.633\n",
      "[228]\tvalid_0's tweedie: 252.633\n",
      "[229]\tvalid_0's tweedie: 252.634\n",
      "[230]\tvalid_0's tweedie: 252.633\n",
      "[231]\tvalid_0's tweedie: 252.634\n",
      "[232]\tvalid_0's tweedie: 252.634\n",
      "[233]\tvalid_0's tweedie: 252.633\n",
      "[234]\tvalid_0's tweedie: 252.633\n",
      "[235]\tvalid_0's tweedie: 252.633\n",
      "[236]\tvalid_0's tweedie: 252.633\n",
      "[237]\tvalid_0's tweedie: 252.633\n",
      "[238]\tvalid_0's tweedie: 252.633\n",
      "[239]\tvalid_0's tweedie: 252.633\n",
      "[240]\tvalid_0's tweedie: 252.633\n",
      "[241]\tvalid_0's tweedie: 252.633\n",
      "[242]\tvalid_0's tweedie: 252.633\n",
      "[243]\tvalid_0's tweedie: 252.633\n",
      "[244]\tvalid_0's tweedie: 252.633\n",
      "[245]\tvalid_0's tweedie: 252.631\n",
      "[246]\tvalid_0's tweedie: 252.631\n",
      "[247]\tvalid_0's tweedie: 252.631\n",
      "[248]\tvalid_0's tweedie: 252.631\n",
      "[249]\tvalid_0's tweedie: 252.631\n",
      "[250]\tvalid_0's tweedie: 252.631\n",
      "[251]\tvalid_0's tweedie: 252.631\n",
      "[252]\tvalid_0's tweedie: 252.631\n",
      "[253]\tvalid_0's tweedie: 252.631\n",
      "[254]\tvalid_0's tweedie: 252.631\n",
      "[255]\tvalid_0's tweedie: 252.631\n",
      "[256]\tvalid_0's tweedie: 252.631\n",
      "[257]\tvalid_0's tweedie: 252.631\n",
      "[258]\tvalid_0's tweedie: 252.631\n",
      "[259]\tvalid_0's tweedie: 252.631\n",
      "[260]\tvalid_0's tweedie: 252.631\n",
      "[261]\tvalid_0's tweedie: 252.631\n",
      "[262]\tvalid_0's tweedie: 252.631\n",
      "[263]\tvalid_0's tweedie: 252.631\n",
      "[264]\tvalid_0's tweedie: 252.63\n",
      "[265]\tvalid_0's tweedie: 252.63\n",
      "[266]\tvalid_0's tweedie: 252.63\n",
      "[267]\tvalid_0's tweedie: 252.63\n",
      "[268]\tvalid_0's tweedie: 252.63\n",
      "[269]\tvalid_0's tweedie: 252.63\n",
      "[270]\tvalid_0's tweedie: 252.63\n",
      "[271]\tvalid_0's tweedie: 252.629\n",
      "[272]\tvalid_0's tweedie: 252.629\n",
      "[273]\tvalid_0's tweedie: 252.628\n",
      "[274]\tvalid_0's tweedie: 252.628\n",
      "[275]\tvalid_0's tweedie: 252.628\n",
      "[276]\tvalid_0's tweedie: 252.628\n",
      "[277]\tvalid_0's tweedie: 252.628\n",
      "[278]\tvalid_0's tweedie: 252.628\n",
      "[279]\tvalid_0's tweedie: 252.629\n",
      "[280]\tvalid_0's tweedie: 252.629\n",
      "[281]\tvalid_0's tweedie: 252.629\n",
      "[282]\tvalid_0's tweedie: 252.629\n",
      "[283]\tvalid_0's tweedie: 252.629\n",
      "[284]\tvalid_0's tweedie: 252.629\n",
      "[285]\tvalid_0's tweedie: 252.629\n",
      "[286]\tvalid_0's tweedie: 252.629\n",
      "[287]\tvalid_0's tweedie: 252.629\n",
      "[288]\tvalid_0's tweedie: 252.629\n",
      "[289]\tvalid_0's tweedie: 252.628\n",
      "[290]\tvalid_0's tweedie: 252.628\n",
      "[291]\tvalid_0's tweedie: 252.628\n",
      "[292]\tvalid_0's tweedie: 252.628\n",
      "[293]\tvalid_0's tweedie: 252.628\n",
      "[294]\tvalid_0's tweedie: 252.628\n",
      "[295]\tvalid_0's tweedie: 252.627\n",
      "[296]\tvalid_0's tweedie: 252.627\n",
      "[297]\tvalid_0's tweedie: 252.627\n",
      "[298]\tvalid_0's tweedie: 252.627\n",
      "[299]\tvalid_0's tweedie: 252.627\n",
      "[300]\tvalid_0's tweedie: 252.627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[297]\tvalid_0's tweedie: 252.627\n",
      "Training model for level 6 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 16740, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.246345\n",
      "[1]\tvalid_0's tweedie: 271.709\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.458\n",
      "[3]\tvalid_0's tweedie: 265.767\n",
      "[4]\tvalid_0's tweedie: 263.521\n",
      "[5]\tvalid_0's tweedie: 261.637\n",
      "[6]\tvalid_0's tweedie: 260.074\n",
      "[7]\tvalid_0's tweedie: 258.774\n",
      "[8]\tvalid_0's tweedie: 257.682\n",
      "[9]\tvalid_0's tweedie: 256.842\n",
      "[10]\tvalid_0's tweedie: 256.108\n",
      "[11]\tvalid_0's tweedie: 255.518\n",
      "[12]\tvalid_0's tweedie: 255.023\n",
      "[13]\tvalid_0's tweedie: 254.62\n",
      "[14]\tvalid_0's tweedie: 254.287\n",
      "[15]\tvalid_0's tweedie: 254.018\n",
      "[16]\tvalid_0's tweedie: 253.793\n",
      "[17]\tvalid_0's tweedie: 253.602\n",
      "[18]\tvalid_0's tweedie: 253.468\n",
      "[19]\tvalid_0's tweedie: 253.341\n",
      "[20]\tvalid_0's tweedie: 253.238\n",
      "[21]\tvalid_0's tweedie: 253.162\n",
      "[22]\tvalid_0's tweedie: 253.09\n",
      "[23]\tvalid_0's tweedie: 253.034\n",
      "[24]\tvalid_0's tweedie: 252.986\n",
      "[25]\tvalid_0's tweedie: 252.934\n",
      "[26]\tvalid_0's tweedie: 252.899\n",
      "[27]\tvalid_0's tweedie: 252.871\n",
      "[28]\tvalid_0's tweedie: 252.842\n",
      "[29]\tvalid_0's tweedie: 252.823\n",
      "[30]\tvalid_0's tweedie: 252.797\n",
      "[31]\tvalid_0's tweedie: 252.781\n",
      "[32]\tvalid_0's tweedie: 252.764\n",
      "[33]\tvalid_0's tweedie: 252.748\n",
      "[34]\tvalid_0's tweedie: 252.737\n",
      "[35]\tvalid_0's tweedie: 252.729\n",
      "[36]\tvalid_0's tweedie: 252.721\n",
      "[37]\tvalid_0's tweedie: 252.715\n",
      "[38]\tvalid_0's tweedie: 252.709\n",
      "[39]\tvalid_0's tweedie: 252.703\n",
      "[40]\tvalid_0's tweedie: 252.7\n",
      "[41]\tvalid_0's tweedie: 252.696\n",
      "[42]\tvalid_0's tweedie: 252.694\n",
      "[43]\tvalid_0's tweedie: 252.693\n",
      "[44]\tvalid_0's tweedie: 252.689\n",
      "[45]\tvalid_0's tweedie: 252.683\n",
      "[46]\tvalid_0's tweedie: 252.681\n",
      "[47]\tvalid_0's tweedie: 252.682\n",
      "[48]\tvalid_0's tweedie: 252.677\n",
      "[49]\tvalid_0's tweedie: 252.678\n",
      "[50]\tvalid_0's tweedie: 252.676\n",
      "[51]\tvalid_0's tweedie: 252.672\n",
      "[52]\tvalid_0's tweedie: 252.669\n",
      "[53]\tvalid_0's tweedie: 252.67\n",
      "[54]\tvalid_0's tweedie: 252.668\n",
      "[55]\tvalid_0's tweedie: 252.662\n",
      "[56]\tvalid_0's tweedie: 252.664\n",
      "[57]\tvalid_0's tweedie: 252.664\n",
      "[58]\tvalid_0's tweedie: 252.664\n",
      "[59]\tvalid_0's tweedie: 252.662\n",
      "[60]\tvalid_0's tweedie: 252.663\n",
      "[61]\tvalid_0's tweedie: 252.663\n",
      "[62]\tvalid_0's tweedie: 252.662\n",
      "[63]\tvalid_0's tweedie: 252.66\n",
      "[64]\tvalid_0's tweedie: 252.66\n",
      "[65]\tvalid_0's tweedie: 252.66\n",
      "[66]\tvalid_0's tweedie: 252.66\n",
      "[67]\tvalid_0's tweedie: 252.66\n",
      "[68]\tvalid_0's tweedie: 252.658\n",
      "[69]\tvalid_0's tweedie: 252.658\n",
      "[70]\tvalid_0's tweedie: 252.658\n",
      "[71]\tvalid_0's tweedie: 252.658\n",
      "[72]\tvalid_0's tweedie: 252.658\n",
      "[73]\tvalid_0's tweedie: 252.658\n",
      "[74]\tvalid_0's tweedie: 252.659\n",
      "[75]\tvalid_0's tweedie: 252.658\n",
      "[76]\tvalid_0's tweedie: 252.658\n",
      "[77]\tvalid_0's tweedie: 252.658\n",
      "[78]\tvalid_0's tweedie: 252.657\n",
      "[79]\tvalid_0's tweedie: 252.657\n",
      "[80]\tvalid_0's tweedie: 252.657\n",
      "[81]\tvalid_0's tweedie: 252.657\n",
      "[82]\tvalid_0's tweedie: 252.657\n",
      "[83]\tvalid_0's tweedie: 252.657\n",
      "[84]\tvalid_0's tweedie: 252.657\n",
      "[85]\tvalid_0's tweedie: 252.656\n",
      "[86]\tvalid_0's tweedie: 252.657\n",
      "[87]\tvalid_0's tweedie: 252.657\n",
      "[88]\tvalid_0's tweedie: 252.657\n",
      "[89]\tvalid_0's tweedie: 252.658\n",
      "[90]\tvalid_0's tweedie: 252.658\n",
      "[91]\tvalid_0's tweedie: 252.658\n",
      "[92]\tvalid_0's tweedie: 252.659\n",
      "[93]\tvalid_0's tweedie: 252.659\n",
      "[94]\tvalid_0's tweedie: 252.658\n",
      "[95]\tvalid_0's tweedie: 252.656\n",
      "[96]\tvalid_0's tweedie: 252.655\n",
      "[97]\tvalid_0's tweedie: 252.655\n",
      "[98]\tvalid_0's tweedie: 252.656\n",
      "[99]\tvalid_0's tweedie: 252.656\n",
      "[100]\tvalid_0's tweedie: 252.655\n",
      "[101]\tvalid_0's tweedie: 252.655\n",
      "[102]\tvalid_0's tweedie: 252.655\n",
      "[103]\tvalid_0's tweedie: 252.655\n",
      "[104]\tvalid_0's tweedie: 252.654\n",
      "[105]\tvalid_0's tweedie: 252.654\n",
      "[106]\tvalid_0's tweedie: 252.654\n",
      "[107]\tvalid_0's tweedie: 252.653\n",
      "[108]\tvalid_0's tweedie: 252.653\n",
      "[109]\tvalid_0's tweedie: 252.653\n",
      "[110]\tvalid_0's tweedie: 252.653\n",
      "[111]\tvalid_0's tweedie: 252.653\n",
      "[112]\tvalid_0's tweedie: 252.653\n",
      "[113]\tvalid_0's tweedie: 252.652\n",
      "[114]\tvalid_0's tweedie: 252.653\n",
      "[115]\tvalid_0's tweedie: 252.653\n",
      "[116]\tvalid_0's tweedie: 252.653\n",
      "[117]\tvalid_0's tweedie: 252.653\n",
      "[118]\tvalid_0's tweedie: 252.652\n",
      "[119]\tvalid_0's tweedie: 252.652\n",
      "[120]\tvalid_0's tweedie: 252.653\n",
      "[121]\tvalid_0's tweedie: 252.653\n",
      "[122]\tvalid_0's tweedie: 252.651\n",
      "[123]\tvalid_0's tweedie: 252.652\n",
      "[124]\tvalid_0's tweedie: 252.652\n",
      "[125]\tvalid_0's tweedie: 252.652\n",
      "[126]\tvalid_0's tweedie: 252.652\n",
      "[127]\tvalid_0's tweedie: 252.652\n",
      "[128]\tvalid_0's tweedie: 252.65\n",
      "[129]\tvalid_0's tweedie: 252.65\n",
      "[130]\tvalid_0's tweedie: 252.65\n",
      "[131]\tvalid_0's tweedie: 252.65\n",
      "[132]\tvalid_0's tweedie: 252.65\n",
      "[133]\tvalid_0's tweedie: 252.649\n",
      "[134]\tvalid_0's tweedie: 252.65\n",
      "[135]\tvalid_0's tweedie: 252.649\n",
      "[136]\tvalid_0's tweedie: 252.649\n",
      "[137]\tvalid_0's tweedie: 252.649\n",
      "[138]\tvalid_0's tweedie: 252.649\n",
      "[139]\tvalid_0's tweedie: 252.649\n",
      "[140]\tvalid_0's tweedie: 252.649\n",
      "[141]\tvalid_0's tweedie: 252.649\n",
      "[142]\tvalid_0's tweedie: 252.648\n",
      "[143]\tvalid_0's tweedie: 252.649\n",
      "[144]\tvalid_0's tweedie: 252.649\n",
      "[145]\tvalid_0's tweedie: 252.648\n",
      "[146]\tvalid_0's tweedie: 252.648\n",
      "[147]\tvalid_0's tweedie: 252.649\n",
      "[148]\tvalid_0's tweedie: 252.649\n",
      "[149]\tvalid_0's tweedie: 252.649\n",
      "[150]\tvalid_0's tweedie: 252.649\n",
      "[151]\tvalid_0's tweedie: 252.649\n",
      "[152]\tvalid_0's tweedie: 252.649\n",
      "[153]\tvalid_0's tweedie: 252.649\n",
      "[154]\tvalid_0's tweedie: 252.648\n",
      "[155]\tvalid_0's tweedie: 252.649\n",
      "[156]\tvalid_0's tweedie: 252.648\n",
      "[157]\tvalid_0's tweedie: 252.649\n",
      "[158]\tvalid_0's tweedie: 252.649\n",
      "[159]\tvalid_0's tweedie: 252.649\n",
      "[160]\tvalid_0's tweedie: 252.649\n",
      "[161]\tvalid_0's tweedie: 252.649\n",
      "[162]\tvalid_0's tweedie: 252.649\n",
      "[163]\tvalid_0's tweedie: 252.649\n",
      "[164]\tvalid_0's tweedie: 252.65\n",
      "[165]\tvalid_0's tweedie: 252.65\n",
      "[166]\tvalid_0's tweedie: 252.649\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's tweedie: 252.648\n",
      "Training model for level 6 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 16731, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.246557\n",
      "[1]\tvalid_0's tweedie: 271.695\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.482\n",
      "[3]\tvalid_0's tweedie: 265.788\n",
      "[4]\tvalid_0's tweedie: 263.543\n",
      "[5]\tvalid_0's tweedie: 261.692\n",
      "[6]\tvalid_0's tweedie: 260.102\n",
      "[7]\tvalid_0's tweedie: 258.815\n",
      "[8]\tvalid_0's tweedie: 257.737\n",
      "[9]\tvalid_0's tweedie: 256.855\n",
      "[10]\tvalid_0's tweedie: 256.131\n",
      "[11]\tvalid_0's tweedie: 255.532\n",
      "[12]\tvalid_0's tweedie: 255.031\n",
      "[13]\tvalid_0's tweedie: 254.621\n",
      "[14]\tvalid_0's tweedie: 254.289\n",
      "[15]\tvalid_0's tweedie: 254.013\n",
      "[16]\tvalid_0's tweedie: 253.787\n",
      "[17]\tvalid_0's tweedie: 253.607\n",
      "[18]\tvalid_0's tweedie: 253.465\n",
      "[19]\tvalid_0's tweedie: 253.337\n",
      "[20]\tvalid_0's tweedie: 253.23\n",
      "[21]\tvalid_0's tweedie: 253.149\n",
      "[22]\tvalid_0's tweedie: 253.076\n",
      "[23]\tvalid_0's tweedie: 253.015\n",
      "[24]\tvalid_0's tweedie: 252.964\n",
      "[25]\tvalid_0's tweedie: 252.923\n",
      "[26]\tvalid_0's tweedie: 252.889\n",
      "[27]\tvalid_0's tweedie: 252.851\n",
      "[28]\tvalid_0's tweedie: 252.826\n",
      "[29]\tvalid_0's tweedie: 252.797\n",
      "[30]\tvalid_0's tweedie: 252.772\n",
      "[31]\tvalid_0's tweedie: 252.756\n",
      "[32]\tvalid_0's tweedie: 252.74\n",
      "[33]\tvalid_0's tweedie: 252.719\n",
      "[34]\tvalid_0's tweedie: 252.709\n",
      "[35]\tvalid_0's tweedie: 252.702\n",
      "[36]\tvalid_0's tweedie: 252.691\n",
      "[37]\tvalid_0's tweedie: 252.685\n",
      "[38]\tvalid_0's tweedie: 252.681\n",
      "[39]\tvalid_0's tweedie: 252.678\n",
      "[40]\tvalid_0's tweedie: 252.674\n",
      "[41]\tvalid_0's tweedie: 252.671\n",
      "[42]\tvalid_0's tweedie: 252.664\n",
      "[43]\tvalid_0's tweedie: 252.663\n",
      "[44]\tvalid_0's tweedie: 252.662\n",
      "[45]\tvalid_0's tweedie: 252.66\n",
      "[46]\tvalid_0's tweedie: 252.66\n",
      "[47]\tvalid_0's tweedie: 252.657\n",
      "[48]\tvalid_0's tweedie: 252.657\n",
      "[49]\tvalid_0's tweedie: 252.656\n",
      "[50]\tvalid_0's tweedie: 252.655\n",
      "[51]\tvalid_0's tweedie: 252.651\n",
      "[52]\tvalid_0's tweedie: 252.654\n",
      "[53]\tvalid_0's tweedie: 252.652\n",
      "[54]\tvalid_0's tweedie: 252.652\n",
      "[55]\tvalid_0's tweedie: 252.653\n",
      "[56]\tvalid_0's tweedie: 252.654\n",
      "[57]\tvalid_0's tweedie: 252.652\n",
      "[58]\tvalid_0's tweedie: 252.65\n",
      "[59]\tvalid_0's tweedie: 252.65\n",
      "[60]\tvalid_0's tweedie: 252.652\n",
      "[61]\tvalid_0's tweedie: 252.653\n",
      "[62]\tvalid_0's tweedie: 252.653\n",
      "[63]\tvalid_0's tweedie: 252.654\n",
      "[64]\tvalid_0's tweedie: 252.653\n",
      "[65]\tvalid_0's tweedie: 252.653\n",
      "[66]\tvalid_0's tweedie: 252.651\n",
      "[67]\tvalid_0's tweedie: 252.651\n",
      "[68]\tvalid_0's tweedie: 252.65\n",
      "[69]\tvalid_0's tweedie: 252.65\n",
      "[70]\tvalid_0's tweedie: 252.65\n",
      "[71]\tvalid_0's tweedie: 252.651\n",
      "[72]\tvalid_0's tweedie: 252.651\n",
      "[73]\tvalid_0's tweedie: 252.651\n",
      "[74]\tvalid_0's tweedie: 252.649\n",
      "[75]\tvalid_0's tweedie: 252.649\n",
      "[76]\tvalid_0's tweedie: 252.649\n",
      "[77]\tvalid_0's tweedie: 252.649\n",
      "[78]\tvalid_0's tweedie: 252.65\n",
      "[79]\tvalid_0's tweedie: 252.65\n",
      "[80]\tvalid_0's tweedie: 252.65\n",
      "[81]\tvalid_0's tweedie: 252.65\n",
      "[82]\tvalid_0's tweedie: 252.65\n",
      "[83]\tvalid_0's tweedie: 252.65\n",
      "[84]\tvalid_0's tweedie: 252.65\n",
      "[85]\tvalid_0's tweedie: 252.65\n",
      "[86]\tvalid_0's tweedie: 252.65\n",
      "[87]\tvalid_0's tweedie: 252.651\n",
      "[88]\tvalid_0's tweedie: 252.651\n",
      "[89]\tvalid_0's tweedie: 252.65\n",
      "[90]\tvalid_0's tweedie: 252.651\n",
      "[91]\tvalid_0's tweedie: 252.649\n",
      "[92]\tvalid_0's tweedie: 252.649\n",
      "[93]\tvalid_0's tweedie: 252.65\n",
      "[94]\tvalid_0's tweedie: 252.65\n",
      "[95]\tvalid_0's tweedie: 252.65\n",
      "[96]\tvalid_0's tweedie: 252.651\n",
      "[97]\tvalid_0's tweedie: 252.65\n",
      "[98]\tvalid_0's tweedie: 252.651\n",
      "[99]\tvalid_0's tweedie: 252.651\n",
      "[100]\tvalid_0's tweedie: 252.651\n",
      "[101]\tvalid_0's tweedie: 252.651\n",
      "[102]\tvalid_0's tweedie: 252.65\n",
      "[103]\tvalid_0's tweedie: 252.651\n",
      "[104]\tvalid_0's tweedie: 252.651\n",
      "[105]\tvalid_0's tweedie: 252.651\n",
      "[106]\tvalid_0's tweedie: 252.652\n",
      "[107]\tvalid_0's tweedie: 252.647\n",
      "[108]\tvalid_0's tweedie: 252.645\n",
      "[109]\tvalid_0's tweedie: 252.645\n",
      "[110]\tvalid_0's tweedie: 252.64\n",
      "[111]\tvalid_0's tweedie: 252.641\n",
      "[112]\tvalid_0's tweedie: 252.641\n",
      "[113]\tvalid_0's tweedie: 252.641\n",
      "[114]\tvalid_0's tweedie: 252.641\n",
      "[115]\tvalid_0's tweedie: 252.642\n",
      "[116]\tvalid_0's tweedie: 252.642\n",
      "[117]\tvalid_0's tweedie: 252.643\n",
      "[118]\tvalid_0's tweedie: 252.643\n",
      "[119]\tvalid_0's tweedie: 252.642\n",
      "[120]\tvalid_0's tweedie: 252.642\n",
      "[121]\tvalid_0's tweedie: 252.638\n",
      "[122]\tvalid_0's tweedie: 252.639\n",
      "[123]\tvalid_0's tweedie: 252.638\n",
      "[124]\tvalid_0's tweedie: 252.638\n",
      "[125]\tvalid_0's tweedie: 252.638\n",
      "[126]\tvalid_0's tweedie: 252.638\n",
      "[127]\tvalid_0's tweedie: 252.638\n",
      "[128]\tvalid_0's tweedie: 252.638\n",
      "[129]\tvalid_0's tweedie: 252.637\n",
      "[130]\tvalid_0's tweedie: 252.637\n",
      "[131]\tvalid_0's tweedie: 252.638\n",
      "[132]\tvalid_0's tweedie: 252.637\n",
      "[133]\tvalid_0's tweedie: 252.637\n",
      "[134]\tvalid_0's tweedie: 252.637\n",
      "[135]\tvalid_0's tweedie: 252.637\n",
      "[136]\tvalid_0's tweedie: 252.636\n",
      "[137]\tvalid_0's tweedie: 252.636\n",
      "[138]\tvalid_0's tweedie: 252.636\n",
      "[139]\tvalid_0's tweedie: 252.633\n",
      "[140]\tvalid_0's tweedie: 252.633\n",
      "[141]\tvalid_0's tweedie: 252.633\n",
      "[142]\tvalid_0's tweedie: 252.633\n",
      "[143]\tvalid_0's tweedie: 252.635\n",
      "[144]\tvalid_0's tweedie: 252.634\n",
      "[145]\tvalid_0's tweedie: 252.636\n",
      "[146]\tvalid_0's tweedie: 252.636\n",
      "[147]\tvalid_0's tweedie: 252.636\n",
      "[148]\tvalid_0's tweedie: 252.635\n",
      "[149]\tvalid_0's tweedie: 252.635\n",
      "[150]\tvalid_0's tweedie: 252.635\n",
      "[151]\tvalid_0's tweedie: 252.632\n",
      "[152]\tvalid_0's tweedie: 252.632\n",
      "[153]\tvalid_0's tweedie: 252.633\n",
      "[154]\tvalid_0's tweedie: 252.633\n",
      "[155]\tvalid_0's tweedie: 252.633\n",
      "[156]\tvalid_0's tweedie: 252.633\n",
      "[157]\tvalid_0's tweedie: 252.633\n",
      "[158]\tvalid_0's tweedie: 252.633\n",
      "[159]\tvalid_0's tweedie: 252.633\n",
      "[160]\tvalid_0's tweedie: 252.633\n",
      "[161]\tvalid_0's tweedie: 252.633\n",
      "[162]\tvalid_0's tweedie: 252.633\n",
      "[163]\tvalid_0's tweedie: 252.633\n",
      "[164]\tvalid_0's tweedie: 252.632\n",
      "[165]\tvalid_0's tweedie: 252.632\n",
      "[166]\tvalid_0's tweedie: 252.632\n",
      "[167]\tvalid_0's tweedie: 252.632\n",
      "[168]\tvalid_0's tweedie: 252.632\n",
      "[169]\tvalid_0's tweedie: 252.631\n",
      "[170]\tvalid_0's tweedie: 252.631\n",
      "[171]\tvalid_0's tweedie: 252.631\n",
      "[172]\tvalid_0's tweedie: 252.631\n",
      "[173]\tvalid_0's tweedie: 252.632\n",
      "[174]\tvalid_0's tweedie: 252.632\n",
      "[175]\tvalid_0's tweedie: 252.63\n",
      "[176]\tvalid_0's tweedie: 252.628\n",
      "[177]\tvalid_0's tweedie: 252.628\n",
      "[178]\tvalid_0's tweedie: 252.628\n",
      "[179]\tvalid_0's tweedie: 252.628\n",
      "[180]\tvalid_0's tweedie: 252.628\n",
      "[181]\tvalid_0's tweedie: 252.627\n",
      "[182]\tvalid_0's tweedie: 252.627\n",
      "[183]\tvalid_0's tweedie: 252.627\n",
      "[184]\tvalid_0's tweedie: 252.627\n",
      "[185]\tvalid_0's tweedie: 252.628\n",
      "[186]\tvalid_0's tweedie: 252.63\n",
      "[187]\tvalid_0's tweedie: 252.63\n",
      "[188]\tvalid_0's tweedie: 252.63\n",
      "[189]\tvalid_0's tweedie: 252.63\n",
      "[190]\tvalid_0's tweedie: 252.63\n",
      "[191]\tvalid_0's tweedie: 252.63\n",
      "[192]\tvalid_0's tweedie: 252.631\n",
      "[193]\tvalid_0's tweedie: 252.63\n",
      "[194]\tvalid_0's tweedie: 252.63\n",
      "[195]\tvalid_0's tweedie: 252.629\n",
      "[196]\tvalid_0's tweedie: 252.63\n",
      "[197]\tvalid_0's tweedie: 252.63\n",
      "[198]\tvalid_0's tweedie: 252.63\n",
      "[199]\tvalid_0's tweedie: 252.63\n",
      "[200]\tvalid_0's tweedie: 252.63\n",
      "[201]\tvalid_0's tweedie: 252.63\n",
      "[202]\tvalid_0's tweedie: 252.629\n",
      "[203]\tvalid_0's tweedie: 252.629\n",
      "[204]\tvalid_0's tweedie: 252.628\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's tweedie: 252.627\n",
      "Training model for level 6 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 16722, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.246777\n",
      "[1]\tvalid_0's tweedie: 271.717\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.451\n",
      "[3]\tvalid_0's tweedie: 265.72\n",
      "[4]\tvalid_0's tweedie: 263.452\n",
      "[5]\tvalid_0's tweedie: 261.541\n",
      "[6]\tvalid_0's tweedie: 259.992\n",
      "[7]\tvalid_0's tweedie: 258.692\n",
      "[8]\tvalid_0's tweedie: 257.636\n",
      "[9]\tvalid_0's tweedie: 256.739\n",
      "[10]\tvalid_0's tweedie: 256.016\n",
      "[11]\tvalid_0's tweedie: 255.431\n",
      "[12]\tvalid_0's tweedie: 254.944\n",
      "[13]\tvalid_0's tweedie: 254.536\n",
      "[14]\tvalid_0's tweedie: 254.22\n",
      "[15]\tvalid_0's tweedie: 253.953\n",
      "[16]\tvalid_0's tweedie: 253.73\n",
      "[17]\tvalid_0's tweedie: 253.559\n",
      "[18]\tvalid_0's tweedie: 253.402\n",
      "[19]\tvalid_0's tweedie: 253.279\n",
      "[20]\tvalid_0's tweedie: 253.18\n",
      "[21]\tvalid_0's tweedie: 253.1\n",
      "[22]\tvalid_0's tweedie: 253.032\n",
      "[23]\tvalid_0's tweedie: 252.97\n",
      "[24]\tvalid_0's tweedie: 252.923\n",
      "[25]\tvalid_0's tweedie: 252.873\n",
      "[26]\tvalid_0's tweedie: 252.834\n",
      "[27]\tvalid_0's tweedie: 252.804\n",
      "[28]\tvalid_0's tweedie: 252.779\n",
      "[29]\tvalid_0's tweedie: 252.756\n",
      "[30]\tvalid_0's tweedie: 252.74\n",
      "[31]\tvalid_0's tweedie: 252.724\n",
      "[32]\tvalid_0's tweedie: 252.703\n",
      "[33]\tvalid_0's tweedie: 252.687\n",
      "[34]\tvalid_0's tweedie: 252.679\n",
      "[35]\tvalid_0's tweedie: 252.672\n",
      "[36]\tvalid_0's tweedie: 252.666\n",
      "[37]\tvalid_0's tweedie: 252.662\n",
      "[38]\tvalid_0's tweedie: 252.654\n",
      "[39]\tvalid_0's tweedie: 252.647\n",
      "[40]\tvalid_0's tweedie: 252.641\n",
      "[41]\tvalid_0's tweedie: 252.638\n",
      "[42]\tvalid_0's tweedie: 252.636\n",
      "[43]\tvalid_0's tweedie: 252.634\n",
      "[44]\tvalid_0's tweedie: 252.633\n",
      "[45]\tvalid_0's tweedie: 252.633\n",
      "[46]\tvalid_0's tweedie: 252.632\n",
      "[47]\tvalid_0's tweedie: 252.629\n",
      "[48]\tvalid_0's tweedie: 252.628\n",
      "[49]\tvalid_0's tweedie: 252.628\n",
      "[50]\tvalid_0's tweedie: 252.626\n",
      "[51]\tvalid_0's tweedie: 252.626\n",
      "[52]\tvalid_0's tweedie: 252.624\n",
      "[53]\tvalid_0's tweedie: 252.624\n",
      "[54]\tvalid_0's tweedie: 252.623\n",
      "[55]\tvalid_0's tweedie: 252.624\n",
      "[56]\tvalid_0's tweedie: 252.625\n",
      "[57]\tvalid_0's tweedie: 252.625\n",
      "[58]\tvalid_0's tweedie: 252.623\n",
      "[59]\tvalid_0's tweedie: 252.62\n",
      "[60]\tvalid_0's tweedie: 252.62\n",
      "[61]\tvalid_0's tweedie: 252.62\n",
      "[62]\tvalid_0's tweedie: 252.621\n",
      "[63]\tvalid_0's tweedie: 252.62\n",
      "[64]\tvalid_0's tweedie: 252.619\n",
      "[65]\tvalid_0's tweedie: 252.62\n",
      "[66]\tvalid_0's tweedie: 252.622\n",
      "[67]\tvalid_0's tweedie: 252.622\n",
      "[68]\tvalid_0's tweedie: 252.622\n",
      "[69]\tvalid_0's tweedie: 252.622\n",
      "[70]\tvalid_0's tweedie: 252.622\n",
      "[71]\tvalid_0's tweedie: 252.624\n",
      "[72]\tvalid_0's tweedie: 252.624\n",
      "[73]\tvalid_0's tweedie: 252.624\n",
      "[74]\tvalid_0's tweedie: 252.624\n",
      "[75]\tvalid_0's tweedie: 252.624\n",
      "[76]\tvalid_0's tweedie: 252.624\n",
      "[77]\tvalid_0's tweedie: 252.624\n",
      "[78]\tvalid_0's tweedie: 252.621\n",
      "[79]\tvalid_0's tweedie: 252.621\n",
      "[80]\tvalid_0's tweedie: 252.62\n",
      "[81]\tvalid_0's tweedie: 252.62\n",
      "[82]\tvalid_0's tweedie: 252.621\n",
      "[83]\tvalid_0's tweedie: 252.622\n",
      "[84]\tvalid_0's tweedie: 252.624\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's tweedie: 252.619\n",
      "Training model for level 6 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 16713, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.246963\n",
      "[1]\tvalid_0's tweedie: 271.563\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.226\n",
      "[3]\tvalid_0's tweedie: 265.461\n",
      "[4]\tvalid_0's tweedie: 263.152\n",
      "[5]\tvalid_0's tweedie: 261.253\n",
      "[6]\tvalid_0's tweedie: 259.696\n",
      "[7]\tvalid_0's tweedie: 258.44\n",
      "[8]\tvalid_0's tweedie: 257.41\n",
      "[9]\tvalid_0's tweedie: 256.587\n",
      "[10]\tvalid_0's tweedie: 255.89\n",
      "[11]\tvalid_0's tweedie: 255.31\n",
      "[12]\tvalid_0's tweedie: 254.852\n",
      "[13]\tvalid_0's tweedie: 254.462\n",
      "[14]\tvalid_0's tweedie: 254.136\n",
      "[15]\tvalid_0's tweedie: 253.887\n",
      "[16]\tvalid_0's tweedie: 253.678\n",
      "[17]\tvalid_0's tweedie: 253.512\n",
      "[18]\tvalid_0's tweedie: 253.369\n",
      "[19]\tvalid_0's tweedie: 253.255\n",
      "[20]\tvalid_0's tweedie: 253.152\n",
      "[21]\tvalid_0's tweedie: 253.071\n",
      "[22]\tvalid_0's tweedie: 253.002\n",
      "[23]\tvalid_0's tweedie: 252.947\n",
      "[24]\tvalid_0's tweedie: 252.903\n",
      "[25]\tvalid_0's tweedie: 252.863\n",
      "[26]\tvalid_0's tweedie: 252.835\n",
      "[27]\tvalid_0's tweedie: 252.797\n",
      "[28]\tvalid_0's tweedie: 252.766\n",
      "[29]\tvalid_0's tweedie: 252.744\n",
      "[30]\tvalid_0's tweedie: 252.722\n",
      "[31]\tvalid_0's tweedie: 252.712\n",
      "[32]\tvalid_0's tweedie: 252.701\n",
      "[33]\tvalid_0's tweedie: 252.684\n",
      "[34]\tvalid_0's tweedie: 252.671\n",
      "[35]\tvalid_0's tweedie: 252.665\n",
      "[36]\tvalid_0's tweedie: 252.659\n",
      "[37]\tvalid_0's tweedie: 252.653\n",
      "[38]\tvalid_0's tweedie: 252.649\n",
      "[39]\tvalid_0's tweedie: 252.643\n",
      "[40]\tvalid_0's tweedie: 252.639\n",
      "[41]\tvalid_0's tweedie: 252.636\n",
      "[42]\tvalid_0's tweedie: 252.638\n",
      "[43]\tvalid_0's tweedie: 252.636\n",
      "[44]\tvalid_0's tweedie: 252.635\n",
      "[45]\tvalid_0's tweedie: 252.635\n",
      "[46]\tvalid_0's tweedie: 252.632\n",
      "[47]\tvalid_0's tweedie: 252.628\n",
      "[48]\tvalid_0's tweedie: 252.632\n",
      "[49]\tvalid_0's tweedie: 252.636\n",
      "[50]\tvalid_0's tweedie: 252.636\n",
      "[51]\tvalid_0's tweedie: 252.634\n",
      "[52]\tvalid_0's tweedie: 252.633\n",
      "[53]\tvalid_0's tweedie: 252.632\n",
      "[54]\tvalid_0's tweedie: 252.635\n",
      "[55]\tvalid_0's tweedie: 252.634\n",
      "[56]\tvalid_0's tweedie: 252.636\n",
      "[57]\tvalid_0's tweedie: 252.638\n",
      "[58]\tvalid_0's tweedie: 252.635\n",
      "[59]\tvalid_0's tweedie: 252.633\n",
      "[60]\tvalid_0's tweedie: 252.632\n",
      "[61]\tvalid_0's tweedie: 252.633\n",
      "[62]\tvalid_0's tweedie: 252.636\n",
      "[63]\tvalid_0's tweedie: 252.634\n",
      "[64]\tvalid_0's tweedie: 252.635\n",
      "[65]\tvalid_0's tweedie: 252.635\n",
      "[66]\tvalid_0's tweedie: 252.635\n",
      "[67]\tvalid_0's tweedie: 252.637\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's tweedie: 252.628\n",
      "Training model for level 6 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 16704, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247032\n",
      "[1]\tvalid_0's tweedie: 271.561\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.225\n",
      "[3]\tvalid_0's tweedie: 265.437\n",
      "[4]\tvalid_0's tweedie: 263.145\n",
      "[5]\tvalid_0's tweedie: 261.267\n",
      "[6]\tvalid_0's tweedie: 259.739\n",
      "[7]\tvalid_0's tweedie: 258.471\n",
      "[8]\tvalid_0's tweedie: 257.414\n",
      "[9]\tvalid_0's tweedie: 256.558\n",
      "[10]\tvalid_0's tweedie: 255.845\n",
      "[11]\tvalid_0's tweedie: 255.276\n",
      "[12]\tvalid_0's tweedie: 254.808\n",
      "[13]\tvalid_0's tweedie: 254.435\n",
      "[14]\tvalid_0's tweedie: 254.104\n",
      "[15]\tvalid_0's tweedie: 253.847\n",
      "[16]\tvalid_0's tweedie: 253.629\n",
      "[17]\tvalid_0's tweedie: 253.458\n",
      "[18]\tvalid_0's tweedie: 253.314\n",
      "[19]\tvalid_0's tweedie: 253.199\n",
      "[20]\tvalid_0's tweedie: 253.106\n",
      "[21]\tvalid_0's tweedie: 253.029\n",
      "[22]\tvalid_0's tweedie: 252.962\n",
      "[23]\tvalid_0's tweedie: 252.911\n",
      "[24]\tvalid_0's tweedie: 252.862\n",
      "[25]\tvalid_0's tweedie: 252.826\n",
      "[26]\tvalid_0's tweedie: 252.793\n",
      "[27]\tvalid_0's tweedie: 252.767\n",
      "[28]\tvalid_0's tweedie: 252.747\n",
      "[29]\tvalid_0's tweedie: 252.73\n",
      "[30]\tvalid_0's tweedie: 252.715\n",
      "[31]\tvalid_0's tweedie: 252.696\n",
      "[32]\tvalid_0's tweedie: 252.684\n",
      "[33]\tvalid_0's tweedie: 252.671\n",
      "[34]\tvalid_0's tweedie: 252.663\n",
      "[35]\tvalid_0's tweedie: 252.657\n",
      "[36]\tvalid_0's tweedie: 252.651\n",
      "[37]\tvalid_0's tweedie: 252.641\n",
      "[38]\tvalid_0's tweedie: 252.637\n",
      "[39]\tvalid_0's tweedie: 252.633\n",
      "[40]\tvalid_0's tweedie: 252.632\n",
      "[41]\tvalid_0's tweedie: 252.628\n",
      "[42]\tvalid_0's tweedie: 252.628\n",
      "[43]\tvalid_0's tweedie: 252.627\n",
      "[44]\tvalid_0's tweedie: 252.626\n",
      "[45]\tvalid_0's tweedie: 252.623\n",
      "[46]\tvalid_0's tweedie: 252.624\n",
      "[47]\tvalid_0's tweedie: 252.624\n",
      "[48]\tvalid_0's tweedie: 252.625\n",
      "[49]\tvalid_0's tweedie: 252.621\n",
      "[50]\tvalid_0's tweedie: 252.624\n",
      "[51]\tvalid_0's tweedie: 252.622\n",
      "[52]\tvalid_0's tweedie: 252.62\n",
      "[53]\tvalid_0's tweedie: 252.623\n",
      "[54]\tvalid_0's tweedie: 252.625\n",
      "[55]\tvalid_0's tweedie: 252.626\n",
      "[56]\tvalid_0's tweedie: 252.621\n",
      "[57]\tvalid_0's tweedie: 252.623\n",
      "[58]\tvalid_0's tweedie: 252.621\n",
      "[59]\tvalid_0's tweedie: 252.624\n",
      "[60]\tvalid_0's tweedie: 252.623\n",
      "[61]\tvalid_0's tweedie: 252.623\n",
      "[62]\tvalid_0's tweedie: 252.622\n",
      "[63]\tvalid_0's tweedie: 252.623\n",
      "[64]\tvalid_0's tweedie: 252.623\n",
      "[65]\tvalid_0's tweedie: 252.625\n",
      "[66]\tvalid_0's tweedie: 252.623\n",
      "[67]\tvalid_0's tweedie: 252.625\n",
      "[68]\tvalid_0's tweedie: 252.623\n",
      "[69]\tvalid_0's tweedie: 252.624\n",
      "[70]\tvalid_0's tweedie: 252.624\n",
      "[71]\tvalid_0's tweedie: 252.625\n",
      "[72]\tvalid_0's tweedie: 252.625\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's tweedie: 252.62\n",
      "Training model for level 6 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 16695, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247121\n",
      "[1]\tvalid_0's tweedie: 271.556\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.218\n",
      "[3]\tvalid_0's tweedie: 265.423\n",
      "[4]\tvalid_0's tweedie: 263.131\n",
      "[5]\tvalid_0's tweedie: 261.231\n",
      "[6]\tvalid_0's tweedie: 259.701\n",
      "[7]\tvalid_0's tweedie: 258.41\n",
      "[8]\tvalid_0's tweedie: 257.378\n",
      "[9]\tvalid_0's tweedie: 256.53\n",
      "[10]\tvalid_0's tweedie: 255.849\n",
      "[11]\tvalid_0's tweedie: 255.266\n",
      "[12]\tvalid_0's tweedie: 254.808\n",
      "[13]\tvalid_0's tweedie: 254.429\n",
      "[14]\tvalid_0's tweedie: 254.114\n",
      "[15]\tvalid_0's tweedie: 253.856\n",
      "[16]\tvalid_0's tweedie: 253.64\n",
      "[17]\tvalid_0's tweedie: 253.461\n",
      "[18]\tvalid_0's tweedie: 253.316\n",
      "[19]\tvalid_0's tweedie: 253.194\n",
      "[20]\tvalid_0's tweedie: 253.105\n",
      "[21]\tvalid_0's tweedie: 253.019\n",
      "[22]\tvalid_0's tweedie: 252.949\n",
      "[23]\tvalid_0's tweedie: 252.902\n",
      "[24]\tvalid_0's tweedie: 252.858\n",
      "[25]\tvalid_0's tweedie: 252.823\n",
      "[26]\tvalid_0's tweedie: 252.794\n",
      "[27]\tvalid_0's tweedie: 252.765\n",
      "[28]\tvalid_0's tweedie: 252.745\n",
      "[29]\tvalid_0's tweedie: 252.719\n",
      "[30]\tvalid_0's tweedie: 252.702\n",
      "[31]\tvalid_0's tweedie: 252.68\n",
      "[32]\tvalid_0's tweedie: 252.671\n",
      "[33]\tvalid_0's tweedie: 252.66\n",
      "[34]\tvalid_0's tweedie: 252.652\n",
      "[35]\tvalid_0's tweedie: 252.645\n",
      "[36]\tvalid_0's tweedie: 252.637\n",
      "[37]\tvalid_0's tweedie: 252.633\n",
      "[38]\tvalid_0's tweedie: 252.629\n",
      "[39]\tvalid_0's tweedie: 252.621\n",
      "[40]\tvalid_0's tweedie: 252.618\n",
      "[41]\tvalid_0's tweedie: 252.613\n",
      "[42]\tvalid_0's tweedie: 252.612\n",
      "[43]\tvalid_0's tweedie: 252.609\n",
      "[44]\tvalid_0's tweedie: 252.605\n",
      "[45]\tvalid_0's tweedie: 252.602\n",
      "[46]\tvalid_0's tweedie: 252.602\n",
      "[47]\tvalid_0's tweedie: 252.602\n",
      "[48]\tvalid_0's tweedie: 252.603\n",
      "[49]\tvalid_0's tweedie: 252.6\n",
      "[50]\tvalid_0's tweedie: 252.602\n",
      "[51]\tvalid_0's tweedie: 252.6\n",
      "[52]\tvalid_0's tweedie: 252.597\n",
      "[53]\tvalid_0's tweedie: 252.6\n",
      "[54]\tvalid_0's tweedie: 252.602\n",
      "[55]\tvalid_0's tweedie: 252.602\n",
      "[56]\tvalid_0's tweedie: 252.601\n",
      "[57]\tvalid_0's tweedie: 252.599\n",
      "[58]\tvalid_0's tweedie: 252.599\n",
      "[59]\tvalid_0's tweedie: 252.599\n",
      "[60]\tvalid_0's tweedie: 252.6\n",
      "[61]\tvalid_0's tweedie: 252.6\n",
      "[62]\tvalid_0's tweedie: 252.6\n",
      "[63]\tvalid_0's tweedie: 252.601\n",
      "[64]\tvalid_0's tweedie: 252.599\n",
      "[65]\tvalid_0's tweedie: 252.599\n",
      "[66]\tvalid_0's tweedie: 252.597\n",
      "[67]\tvalid_0's tweedie: 252.599\n",
      "[68]\tvalid_0's tweedie: 252.599\n",
      "[69]\tvalid_0's tweedie: 252.598\n",
      "[70]\tvalid_0's tweedie: 252.598\n",
      "[71]\tvalid_0's tweedie: 252.598\n",
      "[72]\tvalid_0's tweedie: 252.598\n",
      "[73]\tvalid_0's tweedie: 252.599\n",
      "[74]\tvalid_0's tweedie: 252.599\n",
      "[75]\tvalid_0's tweedie: 252.601\n",
      "[76]\tvalid_0's tweedie: 252.601\n",
      "[77]\tvalid_0's tweedie: 252.601\n",
      "[78]\tvalid_0's tweedie: 252.602\n",
      "[79]\tvalid_0's tweedie: 252.604\n",
      "[80]\tvalid_0's tweedie: 252.603\n",
      "[81]\tvalid_0's tweedie: 252.601\n",
      "[82]\tvalid_0's tweedie: 252.602\n",
      "[83]\tvalid_0's tweedie: 252.603\n",
      "[84]\tvalid_0's tweedie: 252.604\n",
      "[85]\tvalid_0's tweedie: 252.604\n",
      "[86]\tvalid_0's tweedie: 252.606\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's tweedie: 252.597\n",
      "Training model for level 6 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 16686, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247327\n",
      "[1]\tvalid_0's tweedie: 271.556\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.21\n",
      "[3]\tvalid_0's tweedie: 265.424\n",
      "[4]\tvalid_0's tweedie: 263.116\n",
      "[5]\tvalid_0's tweedie: 261.223\n",
      "[6]\tvalid_0's tweedie: 259.686\n",
      "[7]\tvalid_0's tweedie: 258.417\n",
      "[8]\tvalid_0's tweedie: 257.373\n",
      "[9]\tvalid_0's tweedie: 256.516\n",
      "[10]\tvalid_0's tweedie: 255.838\n",
      "[11]\tvalid_0's tweedie: 255.253\n",
      "[12]\tvalid_0's tweedie: 254.79\n",
      "[13]\tvalid_0's tweedie: 254.4\n",
      "[14]\tvalid_0's tweedie: 254.085\n",
      "[15]\tvalid_0's tweedie: 253.821\n",
      "[16]\tvalid_0's tweedie: 253.62\n",
      "[17]\tvalid_0's tweedie: 253.437\n",
      "[18]\tvalid_0's tweedie: 253.289\n",
      "[19]\tvalid_0's tweedie: 253.169\n",
      "[20]\tvalid_0's tweedie: 253.069\n",
      "[21]\tvalid_0's tweedie: 252.996\n",
      "[22]\tvalid_0's tweedie: 252.937\n",
      "[23]\tvalid_0's tweedie: 252.882\n",
      "[24]\tvalid_0's tweedie: 252.837\n",
      "[25]\tvalid_0's tweedie: 252.804\n",
      "[26]\tvalid_0's tweedie: 252.775\n",
      "[27]\tvalid_0's tweedie: 252.751\n",
      "[28]\tvalid_0's tweedie: 252.719\n",
      "[29]\tvalid_0's tweedie: 252.694\n",
      "[30]\tvalid_0's tweedie: 252.68\n",
      "[31]\tvalid_0's tweedie: 252.667\n",
      "[32]\tvalid_0's tweedie: 252.65\n",
      "[33]\tvalid_0's tweedie: 252.64\n",
      "[34]\tvalid_0's tweedie: 252.625\n",
      "[35]\tvalid_0's tweedie: 252.619\n",
      "[36]\tvalid_0's tweedie: 252.614\n",
      "[37]\tvalid_0's tweedie: 252.61\n",
      "[38]\tvalid_0's tweedie: 252.606\n",
      "[39]\tvalid_0's tweedie: 252.601\n",
      "[40]\tvalid_0's tweedie: 252.598\n",
      "[41]\tvalid_0's tweedie: 252.594\n",
      "[42]\tvalid_0's tweedie: 252.594\n",
      "[43]\tvalid_0's tweedie: 252.593\n",
      "[44]\tvalid_0's tweedie: 252.591\n",
      "[45]\tvalid_0's tweedie: 252.59\n",
      "[46]\tvalid_0's tweedie: 252.587\n",
      "[47]\tvalid_0's tweedie: 252.585\n",
      "[48]\tvalid_0's tweedie: 252.586\n",
      "[49]\tvalid_0's tweedie: 252.585\n",
      "[50]\tvalid_0's tweedie: 252.589\n",
      "[51]\tvalid_0's tweedie: 252.59\n",
      "[52]\tvalid_0's tweedie: 252.589\n",
      "[53]\tvalid_0's tweedie: 252.59\n",
      "[54]\tvalid_0's tweedie: 252.589\n",
      "[55]\tvalid_0's tweedie: 252.592\n",
      "[56]\tvalid_0's tweedie: 252.59\n",
      "[57]\tvalid_0's tweedie: 252.592\n",
      "[58]\tvalid_0's tweedie: 252.592\n",
      "[59]\tvalid_0's tweedie: 252.591\n",
      "[60]\tvalid_0's tweedie: 252.591\n",
      "[61]\tvalid_0's tweedie: 252.593\n",
      "[62]\tvalid_0's tweedie: 252.594\n",
      "[63]\tvalid_0's tweedie: 252.594\n",
      "[64]\tvalid_0's tweedie: 252.595\n",
      "[65]\tvalid_0's tweedie: 252.595\n",
      "[66]\tvalid_0's tweedie: 252.595\n",
      "[67]\tvalid_0's tweedie: 252.595\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's tweedie: 252.585\n",
      "Training model for level 6 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 16677, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247507\n",
      "[1]\tvalid_0's tweedie: 271.555\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.197\n",
      "[3]\tvalid_0's tweedie: 265.439\n",
      "[4]\tvalid_0's tweedie: 263.14\n",
      "[5]\tvalid_0's tweedie: 261.224\n",
      "[6]\tvalid_0's tweedie: 259.682\n",
      "[7]\tvalid_0's tweedie: 258.41\n",
      "[8]\tvalid_0's tweedie: 257.382\n",
      "[9]\tvalid_0's tweedie: 256.524\n",
      "[10]\tvalid_0's tweedie: 255.824\n",
      "[11]\tvalid_0's tweedie: 255.24\n",
      "[12]\tvalid_0's tweedie: 254.767\n",
      "[13]\tvalid_0's tweedie: 254.387\n",
      "[14]\tvalid_0's tweedie: 254.073\n",
      "[15]\tvalid_0's tweedie: 253.814\n",
      "[16]\tvalid_0's tweedie: 253.602\n",
      "[17]\tvalid_0's tweedie: 253.424\n",
      "[18]\tvalid_0's tweedie: 253.282\n",
      "[19]\tvalid_0's tweedie: 253.161\n",
      "[20]\tvalid_0's tweedie: 253.067\n",
      "[21]\tvalid_0's tweedie: 252.984\n",
      "[22]\tvalid_0's tweedie: 252.926\n",
      "[23]\tvalid_0's tweedie: 252.873\n",
      "[24]\tvalid_0's tweedie: 252.828\n",
      "[25]\tvalid_0's tweedie: 252.794\n",
      "[26]\tvalid_0's tweedie: 252.768\n",
      "[27]\tvalid_0's tweedie: 252.736\n",
      "[28]\tvalid_0's tweedie: 252.716\n",
      "[29]\tvalid_0's tweedie: 252.691\n",
      "[30]\tvalid_0's tweedie: 252.677\n",
      "[31]\tvalid_0's tweedie: 252.661\n",
      "[32]\tvalid_0's tweedie: 252.65\n",
      "[33]\tvalid_0's tweedie: 252.642\n",
      "[34]\tvalid_0's tweedie: 252.632\n",
      "[35]\tvalid_0's tweedie: 252.622\n",
      "[36]\tvalid_0's tweedie: 252.619\n",
      "[37]\tvalid_0's tweedie: 252.613\n",
      "[38]\tvalid_0's tweedie: 252.612\n",
      "[39]\tvalid_0's tweedie: 252.609\n",
      "[40]\tvalid_0's tweedie: 252.608\n",
      "[41]\tvalid_0's tweedie: 252.604\n",
      "[42]\tvalid_0's tweedie: 252.603\n",
      "[43]\tvalid_0's tweedie: 252.602\n",
      "[44]\tvalid_0's tweedie: 252.601\n",
      "[45]\tvalid_0's tweedie: 252.598\n",
      "[46]\tvalid_0's tweedie: 252.599\n",
      "[47]\tvalid_0's tweedie: 252.596\n",
      "[48]\tvalid_0's tweedie: 252.598\n",
      "[49]\tvalid_0's tweedie: 252.599\n",
      "[50]\tvalid_0's tweedie: 252.597\n",
      "[51]\tvalid_0's tweedie: 252.598\n",
      "[52]\tvalid_0's tweedie: 252.597\n",
      "[53]\tvalid_0's tweedie: 252.597\n",
      "[54]\tvalid_0's tweedie: 252.596\n",
      "[55]\tvalid_0's tweedie: 252.598\n",
      "[56]\tvalid_0's tweedie: 252.601\n",
      "[57]\tvalid_0's tweedie: 252.601\n",
      "[58]\tvalid_0's tweedie: 252.6\n",
      "[59]\tvalid_0's tweedie: 252.601\n",
      "[60]\tvalid_0's tweedie: 252.601\n",
      "[61]\tvalid_0's tweedie: 252.602\n",
      "[62]\tvalid_0's tweedie: 252.601\n",
      "[63]\tvalid_0's tweedie: 252.601\n",
      "[64]\tvalid_0's tweedie: 252.601\n",
      "[65]\tvalid_0's tweedie: 252.602\n",
      "[66]\tvalid_0's tweedie: 252.602\n",
      "[67]\tvalid_0's tweedie: 252.603\n",
      "[68]\tvalid_0's tweedie: 252.603\n",
      "[69]\tvalid_0's tweedie: 252.604\n",
      "[70]\tvalid_0's tweedie: 252.604\n",
      "[71]\tvalid_0's tweedie: 252.604\n",
      "[72]\tvalid_0's tweedie: 252.604\n",
      "[73]\tvalid_0's tweedie: 252.604\n",
      "[74]\tvalid_0's tweedie: 252.604\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's tweedie: 252.596\n",
      "Training model for level 6 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 16668, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247700\n",
      "[1]\tvalid_0's tweedie: 271.55\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.21\n",
      "[3]\tvalid_0's tweedie: 265.419\n",
      "[4]\tvalid_0's tweedie: 263.106\n",
      "[5]\tvalid_0's tweedie: 261.204\n",
      "[6]\tvalid_0's tweedie: 259.668\n",
      "[7]\tvalid_0's tweedie: 258.391\n",
      "[8]\tvalid_0's tweedie: 257.342\n",
      "[9]\tvalid_0's tweedie: 256.503\n",
      "[10]\tvalid_0's tweedie: 255.797\n",
      "[11]\tvalid_0's tweedie: 255.225\n",
      "[12]\tvalid_0's tweedie: 254.774\n",
      "[13]\tvalid_0's tweedie: 254.39\n",
      "[14]\tvalid_0's tweedie: 254.066\n",
      "[15]\tvalid_0's tweedie: 253.808\n",
      "[16]\tvalid_0's tweedie: 253.598\n",
      "[17]\tvalid_0's tweedie: 253.415\n",
      "[18]\tvalid_0's tweedie: 253.276\n",
      "[19]\tvalid_0's tweedie: 253.16\n",
      "[20]\tvalid_0's tweedie: 253.064\n",
      "[21]\tvalid_0's tweedie: 252.977\n",
      "[22]\tvalid_0's tweedie: 252.912\n",
      "[23]\tvalid_0's tweedie: 252.864\n",
      "[24]\tvalid_0's tweedie: 252.82\n",
      "[25]\tvalid_0's tweedie: 252.785\n",
      "[26]\tvalid_0's tweedie: 252.753\n",
      "[27]\tvalid_0's tweedie: 252.732\n",
      "[28]\tvalid_0's tweedie: 252.712\n",
      "[29]\tvalid_0's tweedie: 252.689\n",
      "[30]\tvalid_0's tweedie: 252.678\n",
      "[31]\tvalid_0's tweedie: 252.666\n",
      "[32]\tvalid_0's tweedie: 252.653\n",
      "[33]\tvalid_0's tweedie: 252.643\n",
      "[34]\tvalid_0's tweedie: 252.633\n",
      "[35]\tvalid_0's tweedie: 252.622\n",
      "[36]\tvalid_0's tweedie: 252.617\n",
      "[37]\tvalid_0's tweedie: 252.611\n",
      "[38]\tvalid_0's tweedie: 252.607\n",
      "[39]\tvalid_0's tweedie: 252.602\n",
      "[40]\tvalid_0's tweedie: 252.599\n",
      "[41]\tvalid_0's tweedie: 252.597\n",
      "[42]\tvalid_0's tweedie: 252.595\n",
      "[43]\tvalid_0's tweedie: 252.595\n",
      "[44]\tvalid_0's tweedie: 252.594\n",
      "[45]\tvalid_0's tweedie: 252.592\n",
      "[46]\tvalid_0's tweedie: 252.591\n",
      "[47]\tvalid_0's tweedie: 252.592\n",
      "[48]\tvalid_0's tweedie: 252.591\n",
      "[49]\tvalid_0's tweedie: 252.593\n",
      "[50]\tvalid_0's tweedie: 252.593\n",
      "[51]\tvalid_0's tweedie: 252.596\n",
      "[52]\tvalid_0's tweedie: 252.596\n",
      "[53]\tvalid_0's tweedie: 252.598\n",
      "[54]\tvalid_0's tweedie: 252.596\n",
      "[55]\tvalid_0's tweedie: 252.598\n",
      "[56]\tvalid_0's tweedie: 252.597\n",
      "[57]\tvalid_0's tweedie: 252.597\n",
      "[58]\tvalid_0's tweedie: 252.599\n",
      "[59]\tvalid_0's tweedie: 252.597\n",
      "[60]\tvalid_0's tweedie: 252.596\n",
      "[61]\tvalid_0's tweedie: 252.598\n",
      "[62]\tvalid_0's tweedie: 252.599\n",
      "[63]\tvalid_0's tweedie: 252.601\n",
      "[64]\tvalid_0's tweedie: 252.602\n",
      "[65]\tvalid_0's tweedie: 252.602\n",
      "[66]\tvalid_0's tweedie: 252.601\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's tweedie: 252.591\n",
      "Training model for level 6 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 16659, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.247872\n",
      "[1]\tvalid_0's tweedie: 271.541\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.196\n",
      "[3]\tvalid_0's tweedie: 265.392\n",
      "[4]\tvalid_0's tweedie: 263.078\n",
      "[5]\tvalid_0's tweedie: 261.189\n",
      "[6]\tvalid_0's tweedie: 259.63\n",
      "[7]\tvalid_0's tweedie: 258.387\n",
      "[8]\tvalid_0's tweedie: 257.334\n",
      "[9]\tvalid_0's tweedie: 256.485\n",
      "[10]\tvalid_0's tweedie: 255.771\n",
      "[11]\tvalid_0's tweedie: 255.193\n",
      "[12]\tvalid_0's tweedie: 254.719\n",
      "[13]\tvalid_0's tweedie: 254.337\n",
      "[14]\tvalid_0's tweedie: 254.023\n",
      "[15]\tvalid_0's tweedie: 253.755\n",
      "[16]\tvalid_0's tweedie: 253.539\n",
      "[17]\tvalid_0's tweedie: 253.371\n",
      "[18]\tvalid_0's tweedie: 253.235\n",
      "[19]\tvalid_0's tweedie: 253.121\n",
      "[20]\tvalid_0's tweedie: 253.029\n",
      "[21]\tvalid_0's tweedie: 252.955\n",
      "[22]\tvalid_0's tweedie: 252.895\n",
      "[23]\tvalid_0's tweedie: 252.849\n",
      "[24]\tvalid_0's tweedie: 252.804\n",
      "[25]\tvalid_0's tweedie: 252.773\n",
      "[26]\tvalid_0's tweedie: 252.746\n",
      "[27]\tvalid_0's tweedie: 252.712\n",
      "[28]\tvalid_0's tweedie: 252.694\n",
      "[29]\tvalid_0's tweedie: 252.676\n",
      "[30]\tvalid_0's tweedie: 252.662\n",
      "[31]\tvalid_0's tweedie: 252.645\n",
      "[32]\tvalid_0's tweedie: 252.636\n",
      "[33]\tvalid_0's tweedie: 252.624\n",
      "[34]\tvalid_0's tweedie: 252.616\n",
      "[35]\tvalid_0's tweedie: 252.611\n",
      "[36]\tvalid_0's tweedie: 252.607\n",
      "[37]\tvalid_0's tweedie: 252.603\n",
      "[38]\tvalid_0's tweedie: 252.6\n",
      "[39]\tvalid_0's tweedie: 252.597\n",
      "[40]\tvalid_0's tweedie: 252.595\n",
      "[41]\tvalid_0's tweedie: 252.591\n",
      "[42]\tvalid_0's tweedie: 252.592\n",
      "[43]\tvalid_0's tweedie: 252.592\n",
      "[44]\tvalid_0's tweedie: 252.589\n",
      "[45]\tvalid_0's tweedie: 252.588\n",
      "[46]\tvalid_0's tweedie: 252.588\n",
      "[47]\tvalid_0's tweedie: 252.588\n",
      "[48]\tvalid_0's tweedie: 252.59\n",
      "[49]\tvalid_0's tweedie: 252.589\n",
      "[50]\tvalid_0's tweedie: 252.592\n",
      "[51]\tvalid_0's tweedie: 252.589\n",
      "[52]\tvalid_0's tweedie: 252.593\n",
      "[53]\tvalid_0's tweedie: 252.596\n",
      "[54]\tvalid_0's tweedie: 252.594\n",
      "[55]\tvalid_0's tweedie: 252.593\n",
      "[56]\tvalid_0's tweedie: 252.594\n",
      "[57]\tvalid_0's tweedie: 252.594\n",
      "[58]\tvalid_0's tweedie: 252.593\n",
      "[59]\tvalid_0's tweedie: 252.593\n",
      "[60]\tvalid_0's tweedie: 252.594\n",
      "[61]\tvalid_0's tweedie: 252.593\n",
      "[62]\tvalid_0's tweedie: 252.593\n",
      "[63]\tvalid_0's tweedie: 252.594\n",
      "[64]\tvalid_0's tweedie: 252.595\n",
      "[65]\tvalid_0's tweedie: 252.596\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's tweedie: 252.588\n",
      "Training model for level 6 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 16650, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248042\n",
      "[1]\tvalid_0's tweedie: 271.597\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.258\n",
      "[3]\tvalid_0's tweedie: 265.491\n",
      "[4]\tvalid_0's tweedie: 263.169\n",
      "[5]\tvalid_0's tweedie: 261.25\n",
      "[6]\tvalid_0's tweedie: 259.695\n",
      "[7]\tvalid_0's tweedie: 258.412\n",
      "[8]\tvalid_0's tweedie: 257.38\n",
      "[9]\tvalid_0's tweedie: 256.517\n",
      "[10]\tvalid_0's tweedie: 255.816\n",
      "[11]\tvalid_0's tweedie: 255.249\n",
      "[12]\tvalid_0's tweedie: 254.77\n",
      "[13]\tvalid_0's tweedie: 254.387\n",
      "[14]\tvalid_0's tweedie: 254.059\n",
      "[15]\tvalid_0's tweedie: 253.793\n",
      "[16]\tvalid_0's tweedie: 253.576\n",
      "[17]\tvalid_0's tweedie: 253.4\n",
      "[18]\tvalid_0's tweedie: 253.257\n",
      "[19]\tvalid_0's tweedie: 253.145\n",
      "[20]\tvalid_0's tweedie: 253.048\n",
      "[21]\tvalid_0's tweedie: 252.979\n",
      "[22]\tvalid_0's tweedie: 252.911\n",
      "[23]\tvalid_0's tweedie: 252.859\n",
      "[24]\tvalid_0's tweedie: 252.81\n",
      "[25]\tvalid_0's tweedie: 252.774\n",
      "[26]\tvalid_0's tweedie: 252.744\n",
      "[27]\tvalid_0's tweedie: 252.719\n",
      "[28]\tvalid_0's tweedie: 252.689\n",
      "[29]\tvalid_0's tweedie: 252.671\n",
      "[30]\tvalid_0's tweedie: 252.659\n",
      "[31]\tvalid_0's tweedie: 252.648\n",
      "[32]\tvalid_0's tweedie: 252.632\n",
      "[33]\tvalid_0's tweedie: 252.621\n",
      "[34]\tvalid_0's tweedie: 252.613\n",
      "[35]\tvalid_0's tweedie: 252.604\n",
      "[36]\tvalid_0's tweedie: 252.598\n",
      "[37]\tvalid_0's tweedie: 252.594\n",
      "[38]\tvalid_0's tweedie: 252.591\n",
      "[39]\tvalid_0's tweedie: 252.589\n",
      "[40]\tvalid_0's tweedie: 252.587\n",
      "[41]\tvalid_0's tweedie: 252.587\n",
      "[42]\tvalid_0's tweedie: 252.587\n",
      "[43]\tvalid_0's tweedie: 252.587\n",
      "[44]\tvalid_0's tweedie: 252.586\n",
      "[45]\tvalid_0's tweedie: 252.583\n",
      "[46]\tvalid_0's tweedie: 252.584\n",
      "[47]\tvalid_0's tweedie: 252.583\n",
      "[48]\tvalid_0's tweedie: 252.585\n",
      "[49]\tvalid_0's tweedie: 252.584\n",
      "[50]\tvalid_0's tweedie: 252.587\n",
      "[51]\tvalid_0's tweedie: 252.586\n",
      "[52]\tvalid_0's tweedie: 252.588\n",
      "[53]\tvalid_0's tweedie: 252.589\n",
      "[54]\tvalid_0's tweedie: 252.589\n",
      "[55]\tvalid_0's tweedie: 252.588\n",
      "[56]\tvalid_0's tweedie: 252.586\n",
      "[57]\tvalid_0's tweedie: 252.584\n",
      "[58]\tvalid_0's tweedie: 252.586\n",
      "[59]\tvalid_0's tweedie: 252.585\n",
      "[60]\tvalid_0's tweedie: 252.585\n",
      "[61]\tvalid_0's tweedie: 252.585\n",
      "[62]\tvalid_0's tweedie: 252.585\n",
      "[63]\tvalid_0's tweedie: 252.588\n",
      "[64]\tvalid_0's tweedie: 252.588\n",
      "[65]\tvalid_0's tweedie: 252.587\n",
      "[66]\tvalid_0's tweedie: 252.587\n",
      "[67]\tvalid_0's tweedie: 252.587\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's tweedie: 252.583\n",
      "Training model for level 6 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 16641, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248092\n",
      "[1]\tvalid_0's tweedie: 271.586\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.254\n",
      "[3]\tvalid_0's tweedie: 265.484\n",
      "[4]\tvalid_0's tweedie: 263.18\n",
      "[5]\tvalid_0's tweedie: 261.256\n",
      "[6]\tvalid_0's tweedie: 259.694\n",
      "[7]\tvalid_0's tweedie: 258.419\n",
      "[8]\tvalid_0's tweedie: 257.383\n",
      "[9]\tvalid_0's tweedie: 256.519\n",
      "[10]\tvalid_0's tweedie: 255.82\n",
      "[11]\tvalid_0's tweedie: 255.24\n",
      "[12]\tvalid_0's tweedie: 254.771\n",
      "[13]\tvalid_0's tweedie: 254.379\n",
      "[14]\tvalid_0's tweedie: 254.054\n",
      "[15]\tvalid_0's tweedie: 253.792\n",
      "[16]\tvalid_0's tweedie: 253.581\n",
      "[17]\tvalid_0's tweedie: 253.407\n",
      "[18]\tvalid_0's tweedie: 253.262\n",
      "[19]\tvalid_0's tweedie: 253.146\n",
      "[20]\tvalid_0's tweedie: 253.053\n",
      "[21]\tvalid_0's tweedie: 252.967\n",
      "[22]\tvalid_0's tweedie: 252.907\n",
      "[23]\tvalid_0's tweedie: 252.86\n",
      "[24]\tvalid_0's tweedie: 252.816\n",
      "[25]\tvalid_0's tweedie: 252.781\n",
      "[26]\tvalid_0's tweedie: 252.754\n",
      "[27]\tvalid_0's tweedie: 252.728\n",
      "[28]\tvalid_0's tweedie: 252.709\n",
      "[29]\tvalid_0's tweedie: 252.694\n",
      "[30]\tvalid_0's tweedie: 252.68\n",
      "[31]\tvalid_0's tweedie: 252.659\n",
      "[32]\tvalid_0's tweedie: 252.648\n",
      "[33]\tvalid_0's tweedie: 252.644\n",
      "[34]\tvalid_0's tweedie: 252.634\n",
      "[35]\tvalid_0's tweedie: 252.624\n",
      "[36]\tvalid_0's tweedie: 252.614\n",
      "[37]\tvalid_0's tweedie: 252.609\n",
      "[38]\tvalid_0's tweedie: 252.602\n",
      "[39]\tvalid_0's tweedie: 252.599\n",
      "[40]\tvalid_0's tweedie: 252.598\n",
      "[41]\tvalid_0's tweedie: 252.598\n",
      "[42]\tvalid_0's tweedie: 252.597\n",
      "[43]\tvalid_0's tweedie: 252.598\n",
      "[44]\tvalid_0's tweedie: 252.597\n",
      "[45]\tvalid_0's tweedie: 252.599\n",
      "[46]\tvalid_0's tweedie: 252.597\n",
      "[47]\tvalid_0's tweedie: 252.597\n",
      "[48]\tvalid_0's tweedie: 252.6\n",
      "[49]\tvalid_0's tweedie: 252.598\n",
      "[50]\tvalid_0's tweedie: 252.596\n",
      "[51]\tvalid_0's tweedie: 252.594\n",
      "[52]\tvalid_0's tweedie: 252.596\n",
      "[53]\tvalid_0's tweedie: 252.598\n",
      "[54]\tvalid_0's tweedie: 252.595\n",
      "[55]\tvalid_0's tweedie: 252.594\n",
      "[56]\tvalid_0's tweedie: 252.596\n",
      "[57]\tvalid_0's tweedie: 252.598\n",
      "[58]\tvalid_0's tweedie: 252.598\n",
      "[59]\tvalid_0's tweedie: 252.598\n",
      "[60]\tvalid_0's tweedie: 252.596\n",
      "[61]\tvalid_0's tweedie: 252.596\n",
      "[62]\tvalid_0's tweedie: 252.596\n",
      "[63]\tvalid_0's tweedie: 252.596\n",
      "[64]\tvalid_0's tweedie: 252.596\n",
      "[65]\tvalid_0's tweedie: 252.596\n",
      "[66]\tvalid_0's tweedie: 252.596\n",
      "[67]\tvalid_0's tweedie: 252.597\n",
      "[68]\tvalid_0's tweedie: 252.596\n",
      "[69]\tvalid_0's tweedie: 252.597\n",
      "[70]\tvalid_0's tweedie: 252.597\n",
      "[71]\tvalid_0's tweedie: 252.596\n",
      "[72]\tvalid_0's tweedie: 252.597\n",
      "[73]\tvalid_0's tweedie: 252.597\n",
      "[74]\tvalid_0's tweedie: 252.597\n",
      "[75]\tvalid_0's tweedie: 252.597\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's tweedie: 252.594\n",
      "Training model for level 6 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 16632, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248084\n",
      "[1]\tvalid_0's tweedie: 271.584\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.253\n",
      "[3]\tvalid_0's tweedie: 265.465\n",
      "[4]\tvalid_0's tweedie: 263.172\n",
      "[5]\tvalid_0's tweedie: 261.276\n",
      "[6]\tvalid_0's tweedie: 259.727\n",
      "[7]\tvalid_0's tweedie: 258.461\n",
      "[8]\tvalid_0's tweedie: 257.396\n",
      "[9]\tvalid_0's tweedie: 256.526\n",
      "[10]\tvalid_0's tweedie: 255.812\n",
      "[11]\tvalid_0's tweedie: 255.216\n",
      "[12]\tvalid_0's tweedie: 254.746\n",
      "[13]\tvalid_0's tweedie: 254.356\n",
      "[14]\tvalid_0's tweedie: 254.034\n",
      "[15]\tvalid_0's tweedie: 253.781\n",
      "[16]\tvalid_0's tweedie: 253.566\n",
      "[17]\tvalid_0's tweedie: 253.39\n",
      "[18]\tvalid_0's tweedie: 253.248\n",
      "[19]\tvalid_0's tweedie: 253.131\n",
      "[20]\tvalid_0's tweedie: 253.046\n",
      "[21]\tvalid_0's tweedie: 252.969\n",
      "[22]\tvalid_0's tweedie: 252.904\n",
      "[23]\tvalid_0's tweedie: 252.855\n",
      "[24]\tvalid_0's tweedie: 252.813\n",
      "[25]\tvalid_0's tweedie: 252.782\n",
      "[26]\tvalid_0's tweedie: 252.755\n",
      "[27]\tvalid_0's tweedie: 252.732\n",
      "[28]\tvalid_0's tweedie: 252.71\n",
      "[29]\tvalid_0's tweedie: 252.688\n",
      "[30]\tvalid_0's tweedie: 252.665\n",
      "[31]\tvalid_0's tweedie: 252.652\n",
      "[32]\tvalid_0's tweedie: 252.642\n",
      "[33]\tvalid_0's tweedie: 252.631\n",
      "[34]\tvalid_0's tweedie: 252.624\n",
      "[35]\tvalid_0's tweedie: 252.619\n",
      "[36]\tvalid_0's tweedie: 252.613\n",
      "[37]\tvalid_0's tweedie: 252.606\n",
      "[38]\tvalid_0's tweedie: 252.601\n",
      "[39]\tvalid_0's tweedie: 252.595\n",
      "[40]\tvalid_0's tweedie: 252.592\n",
      "[41]\tvalid_0's tweedie: 252.591\n",
      "[42]\tvalid_0's tweedie: 252.591\n",
      "[43]\tvalid_0's tweedie: 252.589\n",
      "[44]\tvalid_0's tweedie: 252.588\n",
      "[45]\tvalid_0's tweedie: 252.589\n",
      "[46]\tvalid_0's tweedie: 252.589\n",
      "[47]\tvalid_0's tweedie: 252.591\n",
      "[48]\tvalid_0's tweedie: 252.594\n",
      "[49]\tvalid_0's tweedie: 252.592\n",
      "[50]\tvalid_0's tweedie: 252.594\n",
      "[51]\tvalid_0's tweedie: 252.591\n",
      "[52]\tvalid_0's tweedie: 252.593\n",
      "[53]\tvalid_0's tweedie: 252.591\n",
      "[54]\tvalid_0's tweedie: 252.591\n",
      "[55]\tvalid_0's tweedie: 252.593\n",
      "[56]\tvalid_0's tweedie: 252.593\n",
      "[57]\tvalid_0's tweedie: 252.596\n",
      "[58]\tvalid_0's tweedie: 252.595\n",
      "[59]\tvalid_0's tweedie: 252.595\n",
      "[60]\tvalid_0's tweedie: 252.594\n",
      "[61]\tvalid_0's tweedie: 252.593\n",
      "[62]\tvalid_0's tweedie: 252.595\n",
      "[63]\tvalid_0's tweedie: 252.594\n",
      "[64]\tvalid_0's tweedie: 252.596\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's tweedie: 252.588\n",
      "Training model for level 6 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5489\n",
      "[LightGBM] [Info] Number of data points in the train set: 16623, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248238\n",
      "[1]\tvalid_0's tweedie: 271.585\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.255\n",
      "[3]\tvalid_0's tweedie: 265.492\n",
      "[4]\tvalid_0's tweedie: 263.174\n",
      "[5]\tvalid_0's tweedie: 261.257\n",
      "[6]\tvalid_0's tweedie: 259.676\n",
      "[7]\tvalid_0's tweedie: 258.392\n",
      "[8]\tvalid_0's tweedie: 257.353\n",
      "[9]\tvalid_0's tweedie: 256.506\n",
      "[10]\tvalid_0's tweedie: 255.8\n",
      "[11]\tvalid_0's tweedie: 255.219\n",
      "[12]\tvalid_0's tweedie: 254.742\n",
      "[13]\tvalid_0's tweedie: 254.348\n",
      "[14]\tvalid_0's tweedie: 254.024\n",
      "[15]\tvalid_0's tweedie: 253.762\n",
      "[16]\tvalid_0's tweedie: 253.554\n",
      "[17]\tvalid_0's tweedie: 253.383\n",
      "[18]\tvalid_0's tweedie: 253.237\n",
      "[19]\tvalid_0's tweedie: 253.12\n",
      "[20]\tvalid_0's tweedie: 253.027\n",
      "[21]\tvalid_0's tweedie: 252.953\n",
      "[22]\tvalid_0's tweedie: 252.894\n",
      "[23]\tvalid_0's tweedie: 252.843\n",
      "[24]\tvalid_0's tweedie: 252.802\n",
      "[25]\tvalid_0's tweedie: 252.769\n",
      "[26]\tvalid_0's tweedie: 252.74\n",
      "[27]\tvalid_0's tweedie: 252.713\n",
      "[28]\tvalid_0's tweedie: 252.693\n",
      "[29]\tvalid_0's tweedie: 252.675\n",
      "[30]\tvalid_0's tweedie: 252.656\n",
      "[31]\tvalid_0's tweedie: 252.64\n",
      "[32]\tvalid_0's tweedie: 252.632\n",
      "[33]\tvalid_0's tweedie: 252.622\n",
      "[34]\tvalid_0's tweedie: 252.614\n",
      "[35]\tvalid_0's tweedie: 252.605\n",
      "[36]\tvalid_0's tweedie: 252.6\n",
      "[37]\tvalid_0's tweedie: 252.596\n",
      "[38]\tvalid_0's tweedie: 252.592\n",
      "[39]\tvalid_0's tweedie: 252.591\n",
      "[40]\tvalid_0's tweedie: 252.589\n",
      "[41]\tvalid_0's tweedie: 252.585\n",
      "[42]\tvalid_0's tweedie: 252.584\n",
      "[43]\tvalid_0's tweedie: 252.585\n",
      "[44]\tvalid_0's tweedie: 252.582\n",
      "[45]\tvalid_0's tweedie: 252.582\n",
      "[46]\tvalid_0's tweedie: 252.581\n",
      "[47]\tvalid_0's tweedie: 252.582\n",
      "[48]\tvalid_0's tweedie: 252.581\n",
      "[49]\tvalid_0's tweedie: 252.582\n",
      "[50]\tvalid_0's tweedie: 252.584\n",
      "[51]\tvalid_0's tweedie: 252.583\n",
      "[52]\tvalid_0's tweedie: 252.585\n",
      "[53]\tvalid_0's tweedie: 252.584\n",
      "[54]\tvalid_0's tweedie: 252.585\n",
      "[55]\tvalid_0's tweedie: 252.582\n",
      "[56]\tvalid_0's tweedie: 252.583\n",
      "[57]\tvalid_0's tweedie: 252.582\n",
      "[58]\tvalid_0's tweedie: 252.583\n",
      "[59]\tvalid_0's tweedie: 252.582\n",
      "[60]\tvalid_0's tweedie: 252.584\n",
      "[61]\tvalid_0's tweedie: 252.584\n",
      "[62]\tvalid_0's tweedie: 252.584\n",
      "[63]\tvalid_0's tweedie: 252.58\n",
      "[64]\tvalid_0's tweedie: 252.581\n",
      "[65]\tvalid_0's tweedie: 252.583\n",
      "[66]\tvalid_0's tweedie: 252.583\n",
      "[67]\tvalid_0's tweedie: 252.583\n",
      "[68]\tvalid_0's tweedie: 252.583\n",
      "[69]\tvalid_0's tweedie: 252.582\n",
      "[70]\tvalid_0's tweedie: 252.582\n",
      "[71]\tvalid_0's tweedie: 252.582\n",
      "[72]\tvalid_0's tweedie: 252.582\n",
      "[73]\tvalid_0's tweedie: 252.582\n",
      "[74]\tvalid_0's tweedie: 252.581\n",
      "[75]\tvalid_0's tweedie: 252.581\n",
      "[76]\tvalid_0's tweedie: 252.581\n",
      "[77]\tvalid_0's tweedie: 252.58\n",
      "[78]\tvalid_0's tweedie: 252.58\n",
      "[79]\tvalid_0's tweedie: 252.579\n",
      "[80]\tvalid_0's tweedie: 252.58\n",
      "[81]\tvalid_0's tweedie: 252.579\n",
      "[82]\tvalid_0's tweedie: 252.58\n",
      "[83]\tvalid_0's tweedie: 252.579\n",
      "[84]\tvalid_0's tweedie: 252.579\n",
      "[85]\tvalid_0's tweedie: 252.58\n",
      "[86]\tvalid_0's tweedie: 252.58\n",
      "[87]\tvalid_0's tweedie: 252.579\n",
      "[88]\tvalid_0's tweedie: 252.579\n",
      "[89]\tvalid_0's tweedie: 252.578\n",
      "[90]\tvalid_0's tweedie: 252.578\n",
      "[91]\tvalid_0's tweedie: 252.578\n",
      "[92]\tvalid_0's tweedie: 252.578\n",
      "[93]\tvalid_0's tweedie: 252.578\n",
      "[94]\tvalid_0's tweedie: 252.578\n",
      "[95]\tvalid_0's tweedie: 252.579\n",
      "[96]\tvalid_0's tweedie: 252.579\n",
      "[97]\tvalid_0's tweedie: 252.579\n",
      "[98]\tvalid_0's tweedie: 252.578\n",
      "[99]\tvalid_0's tweedie: 252.579\n",
      "[100]\tvalid_0's tweedie: 252.579\n",
      "[101]\tvalid_0's tweedie: 252.579\n",
      "[102]\tvalid_0's tweedie: 252.579\n",
      "[103]\tvalid_0's tweedie: 252.579\n",
      "[104]\tvalid_0's tweedie: 252.578\n",
      "[105]\tvalid_0's tweedie: 252.58\n",
      "[106]\tvalid_0's tweedie: 252.58\n",
      "[107]\tvalid_0's tweedie: 252.58\n",
      "[108]\tvalid_0's tweedie: 252.58\n",
      "[109]\tvalid_0's tweedie: 252.58\n",
      "[110]\tvalid_0's tweedie: 252.58\n",
      "[111]\tvalid_0's tweedie: 252.58\n",
      "[112]\tvalid_0's tweedie: 252.58\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's tweedie: 252.578\n",
      "Training model for level 6 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5488\n",
      "[LightGBM] [Info] Number of data points in the train set: 16614, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248422\n",
      "[1]\tvalid_0's tweedie: 271.581\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.252\n",
      "[3]\tvalid_0's tweedie: 265.46\n",
      "[4]\tvalid_0's tweedie: 263.166\n",
      "[5]\tvalid_0's tweedie: 261.267\n",
      "[6]\tvalid_0's tweedie: 259.708\n",
      "[7]\tvalid_0's tweedie: 258.457\n",
      "[8]\tvalid_0's tweedie: 257.394\n",
      "[9]\tvalid_0's tweedie: 256.553\n",
      "[10]\tvalid_0's tweedie: 255.849\n",
      "[11]\tvalid_0's tweedie: 255.259\n",
      "[12]\tvalid_0's tweedie: 254.782\n",
      "[13]\tvalid_0's tweedie: 254.397\n",
      "[14]\tvalid_0's tweedie: 254.075\n",
      "[15]\tvalid_0's tweedie: 253.808\n",
      "[16]\tvalid_0's tweedie: 253.59\n",
      "[17]\tvalid_0's tweedie: 253.414\n",
      "[18]\tvalid_0's tweedie: 253.269\n",
      "[19]\tvalid_0's tweedie: 253.152\n",
      "[20]\tvalid_0's tweedie: 253.061\n",
      "[21]\tvalid_0's tweedie: 252.981\n",
      "[22]\tvalid_0's tweedie: 252.913\n",
      "[23]\tvalid_0's tweedie: 252.862\n",
      "[24]\tvalid_0's tweedie: 252.817\n",
      "[25]\tvalid_0's tweedie: 252.781\n",
      "[26]\tvalid_0's tweedie: 252.753\n",
      "[27]\tvalid_0's tweedie: 252.726\n",
      "[28]\tvalid_0's tweedie: 252.699\n",
      "[29]\tvalid_0's tweedie: 252.686\n",
      "[30]\tvalid_0's tweedie: 252.674\n",
      "[31]\tvalid_0's tweedie: 252.661\n",
      "[32]\tvalid_0's tweedie: 252.648\n",
      "[33]\tvalid_0's tweedie: 252.638\n",
      "[34]\tvalid_0's tweedie: 252.624\n",
      "[35]\tvalid_0's tweedie: 252.614\n",
      "[36]\tvalid_0's tweedie: 252.608\n",
      "[37]\tvalid_0's tweedie: 252.604\n",
      "[38]\tvalid_0's tweedie: 252.601\n",
      "[39]\tvalid_0's tweedie: 252.593\n",
      "[40]\tvalid_0's tweedie: 252.59\n",
      "[41]\tvalid_0's tweedie: 252.59\n",
      "[42]\tvalid_0's tweedie: 252.588\n",
      "[43]\tvalid_0's tweedie: 252.589\n",
      "[44]\tvalid_0's tweedie: 252.59\n",
      "[45]\tvalid_0's tweedie: 252.588\n",
      "[46]\tvalid_0's tweedie: 252.586\n",
      "[47]\tvalid_0's tweedie: 252.586\n",
      "[48]\tvalid_0's tweedie: 252.587\n",
      "[49]\tvalid_0's tweedie: 252.584\n",
      "[50]\tvalid_0's tweedie: 252.582\n",
      "[51]\tvalid_0's tweedie: 252.584\n",
      "[52]\tvalid_0's tweedie: 252.588\n",
      "[53]\tvalid_0's tweedie: 252.59\n",
      "[54]\tvalid_0's tweedie: 252.588\n",
      "[55]\tvalid_0's tweedie: 252.589\n",
      "[56]\tvalid_0's tweedie: 252.589\n",
      "[57]\tvalid_0's tweedie: 252.587\n",
      "[58]\tvalid_0's tweedie: 252.587\n",
      "[59]\tvalid_0's tweedie: 252.585\n",
      "[60]\tvalid_0's tweedie: 252.585\n",
      "[61]\tvalid_0's tweedie: 252.587\n",
      "[62]\tvalid_0's tweedie: 252.588\n",
      "[63]\tvalid_0's tweedie: 252.587\n",
      "[64]\tvalid_0's tweedie: 252.587\n",
      "[65]\tvalid_0's tweedie: 252.587\n",
      "[66]\tvalid_0's tweedie: 252.586\n",
      "[67]\tvalid_0's tweedie: 252.586\n",
      "[68]\tvalid_0's tweedie: 252.587\n",
      "[69]\tvalid_0's tweedie: 252.586\n",
      "[70]\tvalid_0's tweedie: 252.586\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's tweedie: 252.582\n",
      "Training model for level 6 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5487\n",
      "[LightGBM] [Info] Number of data points in the train set: 16605, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248608\n",
      "[1]\tvalid_0's tweedie: 271.575\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.238\n",
      "[3]\tvalid_0's tweedie: 265.445\n",
      "[4]\tvalid_0's tweedie: 263.167\n",
      "[5]\tvalid_0's tweedie: 261.275\n",
      "[6]\tvalid_0's tweedie: 259.725\n",
      "[7]\tvalid_0's tweedie: 258.443\n",
      "[8]\tvalid_0's tweedie: 257.382\n",
      "[9]\tvalid_0's tweedie: 256.521\n",
      "[10]\tvalid_0's tweedie: 255.808\n",
      "[11]\tvalid_0's tweedie: 255.23\n",
      "[12]\tvalid_0's tweedie: 254.753\n",
      "[13]\tvalid_0's tweedie: 254.368\n",
      "[14]\tvalid_0's tweedie: 254.041\n",
      "[15]\tvalid_0's tweedie: 253.777\n",
      "[16]\tvalid_0's tweedie: 253.568\n",
      "[17]\tvalid_0's tweedie: 253.4\n",
      "[18]\tvalid_0's tweedie: 253.253\n",
      "[19]\tvalid_0's tweedie: 253.139\n",
      "[20]\tvalid_0's tweedie: 253.046\n",
      "[21]\tvalid_0's tweedie: 252.967\n",
      "[22]\tvalid_0's tweedie: 252.905\n",
      "[23]\tvalid_0's tweedie: 252.85\n",
      "[24]\tvalid_0's tweedie: 252.806\n",
      "[25]\tvalid_0's tweedie: 252.769\n",
      "[26]\tvalid_0's tweedie: 252.732\n",
      "[27]\tvalid_0's tweedie: 252.71\n",
      "[28]\tvalid_0's tweedie: 252.689\n",
      "[29]\tvalid_0's tweedie: 252.675\n",
      "[30]\tvalid_0's tweedie: 252.664\n",
      "[31]\tvalid_0's tweedie: 252.652\n",
      "[32]\tvalid_0's tweedie: 252.639\n",
      "[33]\tvalid_0's tweedie: 252.632\n",
      "[34]\tvalid_0's tweedie: 252.621\n",
      "[35]\tvalid_0's tweedie: 252.612\n",
      "[36]\tvalid_0's tweedie: 252.607\n",
      "[37]\tvalid_0's tweedie: 252.603\n",
      "[38]\tvalid_0's tweedie: 252.6\n",
      "[39]\tvalid_0's tweedie: 252.595\n",
      "[40]\tvalid_0's tweedie: 252.594\n",
      "[41]\tvalid_0's tweedie: 252.592\n",
      "[42]\tvalid_0's tweedie: 252.592\n",
      "[43]\tvalid_0's tweedie: 252.592\n",
      "[44]\tvalid_0's tweedie: 252.591\n",
      "[45]\tvalid_0's tweedie: 252.589\n",
      "[46]\tvalid_0's tweedie: 252.59\n",
      "[47]\tvalid_0's tweedie: 252.591\n",
      "[48]\tvalid_0's tweedie: 252.589\n",
      "[49]\tvalid_0's tweedie: 252.59\n",
      "[50]\tvalid_0's tweedie: 252.588\n",
      "[51]\tvalid_0's tweedie: 252.589\n",
      "[52]\tvalid_0's tweedie: 252.591\n",
      "[53]\tvalid_0's tweedie: 252.593\n",
      "[54]\tvalid_0's tweedie: 252.592\n",
      "[55]\tvalid_0's tweedie: 252.593\n",
      "[56]\tvalid_0's tweedie: 252.591\n",
      "[57]\tvalid_0's tweedie: 252.592\n",
      "[58]\tvalid_0's tweedie: 252.59\n",
      "[59]\tvalid_0's tweedie: 252.59\n",
      "[60]\tvalid_0's tweedie: 252.59\n",
      "[61]\tvalid_0's tweedie: 252.59\n",
      "[62]\tvalid_0's tweedie: 252.59\n",
      "[63]\tvalid_0's tweedie: 252.59\n",
      "[64]\tvalid_0's tweedie: 252.59\n",
      "[65]\tvalid_0's tweedie: 252.589\n",
      "[66]\tvalid_0's tweedie: 252.588\n",
      "[67]\tvalid_0's tweedie: 252.589\n",
      "[68]\tvalid_0's tweedie: 252.588\n",
      "[69]\tvalid_0's tweedie: 252.588\n",
      "[70]\tvalid_0's tweedie: 252.588\n",
      "[71]\tvalid_0's tweedie: 252.588\n",
      "[72]\tvalid_0's tweedie: 252.585\n",
      "[73]\tvalid_0's tweedie: 252.585\n",
      "[74]\tvalid_0's tweedie: 252.586\n",
      "[75]\tvalid_0's tweedie: 252.587\n",
      "[76]\tvalid_0's tweedie: 252.586\n",
      "[77]\tvalid_0's tweedie: 252.586\n",
      "[78]\tvalid_0's tweedie: 252.586\n",
      "[79]\tvalid_0's tweedie: 252.586\n",
      "[80]\tvalid_0's tweedie: 252.589\n",
      "[81]\tvalid_0's tweedie: 252.59\n",
      "[82]\tvalid_0's tweedie: 252.589\n",
      "[83]\tvalid_0's tweedie: 252.589\n",
      "[84]\tvalid_0's tweedie: 252.589\n",
      "[85]\tvalid_0's tweedie: 252.589\n",
      "[86]\tvalid_0's tweedie: 252.589\n",
      "[87]\tvalid_0's tweedie: 252.589\n",
      "[88]\tvalid_0's tweedie: 252.589\n",
      "[89]\tvalid_0's tweedie: 252.59\n",
      "[90]\tvalid_0's tweedie: 252.59\n",
      "[91]\tvalid_0's tweedie: 252.591\n",
      "[92]\tvalid_0's tweedie: 252.591\n",
      "[93]\tvalid_0's tweedie: 252.591\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's tweedie: 252.585\n",
      "Training model for level 6 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/6/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5486\n",
      "[LightGBM] [Info] Number of data points in the train set: 16596, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 8.248794\n",
      "[1]\tvalid_0's tweedie: 271.58\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 268.252\n",
      "[3]\tvalid_0's tweedie: 265.47\n",
      "[4]\tvalid_0's tweedie: 263.189\n",
      "[5]\tvalid_0's tweedie: 261.266\n",
      "[6]\tvalid_0's tweedie: 259.715\n",
      "[7]\tvalid_0's tweedie: 258.433\n",
      "[8]\tvalid_0's tweedie: 257.394\n",
      "[9]\tvalid_0's tweedie: 256.52\n",
      "[10]\tvalid_0's tweedie: 255.826\n",
      "[11]\tvalid_0's tweedie: 255.258\n",
      "[12]\tvalid_0's tweedie: 254.784\n",
      "[13]\tvalid_0's tweedie: 254.394\n",
      "[14]\tvalid_0's tweedie: 254.072\n",
      "[15]\tvalid_0's tweedie: 253.808\n",
      "[16]\tvalid_0's tweedie: 253.589\n",
      "[17]\tvalid_0's tweedie: 253.412\n",
      "[18]\tvalid_0's tweedie: 253.265\n",
      "[19]\tvalid_0's tweedie: 253.152\n",
      "[20]\tvalid_0's tweedie: 253.054\n",
      "[21]\tvalid_0's tweedie: 252.976\n",
      "[22]\tvalid_0's tweedie: 252.91\n",
      "[23]\tvalid_0's tweedie: 252.86\n",
      "[24]\tvalid_0's tweedie: 252.817\n",
      "[25]\tvalid_0's tweedie: 252.783\n",
      "[26]\tvalid_0's tweedie: 252.753\n",
      "[27]\tvalid_0's tweedie: 252.719\n",
      "[28]\tvalid_0's tweedie: 252.699\n",
      "[29]\tvalid_0's tweedie: 252.682\n",
      "[30]\tvalid_0's tweedie: 252.672\n",
      "[31]\tvalid_0's tweedie: 252.663\n",
      "[32]\tvalid_0's tweedie: 252.648\n",
      "[33]\tvalid_0's tweedie: 252.641\n",
      "[34]\tvalid_0's tweedie: 252.633\n",
      "[35]\tvalid_0's tweedie: 252.624\n",
      "[36]\tvalid_0's tweedie: 252.616\n",
      "[37]\tvalid_0's tweedie: 252.608\n",
      "[38]\tvalid_0's tweedie: 252.601\n",
      "[39]\tvalid_0's tweedie: 252.599\n",
      "[40]\tvalid_0's tweedie: 252.596\n",
      "[41]\tvalid_0's tweedie: 252.595\n",
      "[42]\tvalid_0's tweedie: 252.595\n",
      "[43]\tvalid_0's tweedie: 252.594\n",
      "[44]\tvalid_0's tweedie: 252.592\n",
      "[45]\tvalid_0's tweedie: 252.593\n",
      "[46]\tvalid_0's tweedie: 252.592\n",
      "[47]\tvalid_0's tweedie: 252.592\n",
      "[48]\tvalid_0's tweedie: 252.591\n",
      "[49]\tvalid_0's tweedie: 252.594\n",
      "[50]\tvalid_0's tweedie: 252.593\n",
      "[51]\tvalid_0's tweedie: 252.593\n",
      "[52]\tvalid_0's tweedie: 252.595\n",
      "[53]\tvalid_0's tweedie: 252.593\n",
      "[54]\tvalid_0's tweedie: 252.593\n",
      "[55]\tvalid_0's tweedie: 252.594\n",
      "[56]\tvalid_0's tweedie: 252.593\n",
      "[57]\tvalid_0's tweedie: 252.591\n",
      "[58]\tvalid_0's tweedie: 252.59\n",
      "[59]\tvalid_0's tweedie: 252.588\n",
      "[60]\tvalid_0's tweedie: 252.589\n",
      "[61]\tvalid_0's tweedie: 252.589\n",
      "[62]\tvalid_0's tweedie: 252.587\n",
      "[63]\tvalid_0's tweedie: 252.587\n",
      "[64]\tvalid_0's tweedie: 252.586\n",
      "[65]\tvalid_0's tweedie: 252.585\n",
      "[66]\tvalid_0's tweedie: 252.585\n",
      "[67]\tvalid_0's tweedie: 252.585\n",
      "[68]\tvalid_0's tweedie: 252.585\n",
      "[69]\tvalid_0's tweedie: 252.585\n",
      "[70]\tvalid_0's tweedie: 252.585\n",
      "[71]\tvalid_0's tweedie: 252.586\n",
      "[72]\tvalid_0's tweedie: 252.586\n",
      "[73]\tvalid_0's tweedie: 252.586\n",
      "[74]\tvalid_0's tweedie: 252.586\n",
      "[75]\tvalid_0's tweedie: 252.586\n",
      "[76]\tvalid_0's tweedie: 252.587\n",
      "[77]\tvalid_0's tweedie: 252.587\n",
      "[78]\tvalid_0's tweedie: 252.587\n",
      "[79]\tvalid_0's tweedie: 252.587\n",
      "[80]\tvalid_0's tweedie: 252.587\n",
      "[81]\tvalid_0's tweedie: 252.587\n",
      "[82]\tvalid_0's tweedie: 252.587\n",
      "[83]\tvalid_0's tweedie: 252.587\n",
      "[84]\tvalid_0's tweedie: 252.587\n",
      "[85]\tvalid_0's tweedie: 252.587\n",
      "[86]\tvalid_0's tweedie: 252.587\n",
      "[87]\tvalid_0's tweedie: 252.587\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's tweedie: 252.585\n",
      "Training model for level 7\n",
      "Training model for level 7 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5517\n",
      "[LightGBM] [Info] Number of data points in the train set: 39291, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.397651\n",
      "[1]\tvalid_0's tweedie: 176.821\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.748\n",
      "[3]\tvalid_0's tweedie: 171.143\n",
      "[4]\tvalid_0's tweedie: 168.936\n",
      "[5]\tvalid_0's tweedie: 167.08\n",
      "[6]\tvalid_0's tweedie: 165.523\n",
      "[7]\tvalid_0's tweedie: 164.227\n",
      "[8]\tvalid_0's tweedie: 163.157\n",
      "[9]\tvalid_0's tweedie: 162.266\n",
      "[10]\tvalid_0's tweedie: 161.533\n",
      "[11]\tvalid_0's tweedie: 160.921\n",
      "[12]\tvalid_0's tweedie: 160.427\n",
      "[13]\tvalid_0's tweedie: 160.02\n",
      "[14]\tvalid_0's tweedie: 159.678\n",
      "[15]\tvalid_0's tweedie: 159.403\n",
      "[16]\tvalid_0's tweedie: 159.173\n",
      "[17]\tvalid_0's tweedie: 158.987\n",
      "[18]\tvalid_0's tweedie: 158.827\n",
      "[19]\tvalid_0's tweedie: 158.699\n",
      "[20]\tvalid_0's tweedie: 158.594\n",
      "[21]\tvalid_0's tweedie: 158.509\n",
      "[22]\tvalid_0's tweedie: 158.437\n",
      "[23]\tvalid_0's tweedie: 158.38\n",
      "[24]\tvalid_0's tweedie: 158.331\n",
      "[25]\tvalid_0's tweedie: 158.289\n",
      "[26]\tvalid_0's tweedie: 158.255\n",
      "[27]\tvalid_0's tweedie: 158.227\n",
      "[28]\tvalid_0's tweedie: 158.205\n",
      "[29]\tvalid_0's tweedie: 158.184\n",
      "[30]\tvalid_0's tweedie: 158.168\n",
      "[31]\tvalid_0's tweedie: 158.154\n",
      "[32]\tvalid_0's tweedie: 158.143\n",
      "[33]\tvalid_0's tweedie: 158.135\n",
      "[34]\tvalid_0's tweedie: 158.127\n",
      "[35]\tvalid_0's tweedie: 158.118\n",
      "[36]\tvalid_0's tweedie: 158.112\n",
      "[37]\tvalid_0's tweedie: 158.108\n",
      "[38]\tvalid_0's tweedie: 158.105\n",
      "[39]\tvalid_0's tweedie: 158.102\n",
      "[40]\tvalid_0's tweedie: 158.1\n",
      "[41]\tvalid_0's tweedie: 158.097\n",
      "[42]\tvalid_0's tweedie: 158.096\n",
      "[43]\tvalid_0's tweedie: 158.095\n",
      "[44]\tvalid_0's tweedie: 158.092\n",
      "[45]\tvalid_0's tweedie: 158.092\n",
      "[46]\tvalid_0's tweedie: 158.091\n",
      "[47]\tvalid_0's tweedie: 158.09\n",
      "[48]\tvalid_0's tweedie: 158.09\n",
      "[49]\tvalid_0's tweedie: 158.087\n",
      "[50]\tvalid_0's tweedie: 158.087\n",
      "[51]\tvalid_0's tweedie: 158.086\n",
      "[52]\tvalid_0's tweedie: 158.084\n",
      "[53]\tvalid_0's tweedie: 158.084\n",
      "[54]\tvalid_0's tweedie: 158.083\n",
      "[55]\tvalid_0's tweedie: 158.082\n",
      "[56]\tvalid_0's tweedie: 158.082\n",
      "[57]\tvalid_0's tweedie: 158.08\n",
      "[58]\tvalid_0's tweedie: 158.08\n",
      "[59]\tvalid_0's tweedie: 158.079\n",
      "[60]\tvalid_0's tweedie: 158.079\n",
      "[61]\tvalid_0's tweedie: 158.08\n",
      "[62]\tvalid_0's tweedie: 158.079\n",
      "[63]\tvalid_0's tweedie: 158.079\n",
      "[64]\tvalid_0's tweedie: 158.079\n",
      "[65]\tvalid_0's tweedie: 158.079\n",
      "[66]\tvalid_0's tweedie: 158.079\n",
      "[67]\tvalid_0's tweedie: 158.079\n",
      "[68]\tvalid_0's tweedie: 158.078\n",
      "[69]\tvalid_0's tweedie: 158.078\n",
      "[70]\tvalid_0's tweedie: 158.078\n",
      "[71]\tvalid_0's tweedie: 158.078\n",
      "[72]\tvalid_0's tweedie: 158.078\n",
      "[73]\tvalid_0's tweedie: 158.078\n",
      "[74]\tvalid_0's tweedie: 158.078\n",
      "[75]\tvalid_0's tweedie: 158.078\n",
      "[76]\tvalid_0's tweedie: 158.078\n",
      "[77]\tvalid_0's tweedie: 158.078\n",
      "[78]\tvalid_0's tweedie: 158.077\n",
      "[79]\tvalid_0's tweedie: 158.077\n",
      "[80]\tvalid_0's tweedie: 158.076\n",
      "[81]\tvalid_0's tweedie: 158.075\n",
      "[82]\tvalid_0's tweedie: 158.075\n",
      "[83]\tvalid_0's tweedie: 158.075\n",
      "[84]\tvalid_0's tweedie: 158.075\n",
      "[85]\tvalid_0's tweedie: 158.075\n",
      "[86]\tvalid_0's tweedie: 158.075\n",
      "[87]\tvalid_0's tweedie: 158.075\n",
      "[88]\tvalid_0's tweedie: 158.075\n",
      "[89]\tvalid_0's tweedie: 158.075\n",
      "[90]\tvalid_0's tweedie: 158.075\n",
      "[91]\tvalid_0's tweedie: 158.075\n",
      "[92]\tvalid_0's tweedie: 158.075\n",
      "[93]\tvalid_0's tweedie: 158.075\n",
      "[94]\tvalid_0's tweedie: 158.074\n",
      "[95]\tvalid_0's tweedie: 158.072\n",
      "[96]\tvalid_0's tweedie: 158.072\n",
      "[97]\tvalid_0's tweedie: 158.072\n",
      "[98]\tvalid_0's tweedie: 158.072\n",
      "[99]\tvalid_0's tweedie: 158.072\n",
      "[100]\tvalid_0's tweedie: 158.072\n",
      "[101]\tvalid_0's tweedie: 158.072\n",
      "[102]\tvalid_0's tweedie: 158.072\n",
      "[103]\tvalid_0's tweedie: 158.072\n",
      "[104]\tvalid_0's tweedie: 158.072\n",
      "[105]\tvalid_0's tweedie: 158.072\n",
      "[106]\tvalid_0's tweedie: 158.071\n",
      "[107]\tvalid_0's tweedie: 158.071\n",
      "[108]\tvalid_0's tweedie: 158.071\n",
      "[109]\tvalid_0's tweedie: 158.071\n",
      "[110]\tvalid_0's tweedie: 158.071\n",
      "[111]\tvalid_0's tweedie: 158.069\n",
      "[112]\tvalid_0's tweedie: 158.069\n",
      "[113]\tvalid_0's tweedie: 158.069\n",
      "[114]\tvalid_0's tweedie: 158.069\n",
      "[115]\tvalid_0's tweedie: 158.069\n",
      "[116]\tvalid_0's tweedie: 158.068\n",
      "[117]\tvalid_0's tweedie: 158.068\n",
      "[118]\tvalid_0's tweedie: 158.068\n",
      "[119]\tvalid_0's tweedie: 158.068\n",
      "[120]\tvalid_0's tweedie: 158.068\n",
      "[121]\tvalid_0's tweedie: 158.067\n",
      "[122]\tvalid_0's tweedie: 158.067\n",
      "[123]\tvalid_0's tweedie: 158.067\n",
      "[124]\tvalid_0's tweedie: 158.067\n",
      "[125]\tvalid_0's tweedie: 158.067\n",
      "[126]\tvalid_0's tweedie: 158.067\n",
      "[127]\tvalid_0's tweedie: 158.067\n",
      "[128]\tvalid_0's tweedie: 158.067\n",
      "[129]\tvalid_0's tweedie: 158.067\n",
      "[130]\tvalid_0's tweedie: 158.067\n",
      "[131]\tvalid_0's tweedie: 158.066\n",
      "[132]\tvalid_0's tweedie: 158.066\n",
      "[133]\tvalid_0's tweedie: 158.065\n",
      "[134]\tvalid_0's tweedie: 158.065\n",
      "[135]\tvalid_0's tweedie: 158.065\n",
      "[136]\tvalid_0's tweedie: 158.065\n",
      "[137]\tvalid_0's tweedie: 158.065\n",
      "[138]\tvalid_0's tweedie: 158.064\n",
      "[139]\tvalid_0's tweedie: 158.064\n",
      "[140]\tvalid_0's tweedie: 158.064\n",
      "[141]\tvalid_0's tweedie: 158.064\n",
      "[142]\tvalid_0's tweedie: 158.064\n",
      "[143]\tvalid_0's tweedie: 158.064\n",
      "[144]\tvalid_0's tweedie: 158.064\n",
      "[145]\tvalid_0's tweedie: 158.064\n",
      "[146]\tvalid_0's tweedie: 158.064\n",
      "[147]\tvalid_0's tweedie: 158.064\n",
      "[148]\tvalid_0's tweedie: 158.063\n",
      "[149]\tvalid_0's tweedie: 158.063\n",
      "[150]\tvalid_0's tweedie: 158.063\n",
      "[151]\tvalid_0's tweedie: 158.063\n",
      "[152]\tvalid_0's tweedie: 158.063\n",
      "[153]\tvalid_0's tweedie: 158.063\n",
      "[154]\tvalid_0's tweedie: 158.063\n",
      "[155]\tvalid_0's tweedie: 158.063\n",
      "[156]\tvalid_0's tweedie: 158.063\n",
      "[157]\tvalid_0's tweedie: 158.063\n",
      "[158]\tvalid_0's tweedie: 158.062\n",
      "[159]\tvalid_0's tweedie: 158.062\n",
      "[160]\tvalid_0's tweedie: 158.062\n",
      "[161]\tvalid_0's tweedie: 158.062\n",
      "[162]\tvalid_0's tweedie: 158.062\n",
      "[163]\tvalid_0's tweedie: 158.062\n",
      "[164]\tvalid_0's tweedie: 158.062\n",
      "[165]\tvalid_0's tweedie: 158.062\n",
      "[166]\tvalid_0's tweedie: 158.062\n",
      "[167]\tvalid_0's tweedie: 158.062\n",
      "[168]\tvalid_0's tweedie: 158.061\n",
      "[169]\tvalid_0's tweedie: 158.061\n",
      "[170]\tvalid_0's tweedie: 158.061\n",
      "[171]\tvalid_0's tweedie: 158.061\n",
      "[172]\tvalid_0's tweedie: 158.061\n",
      "[173]\tvalid_0's tweedie: 158.061\n",
      "[174]\tvalid_0's tweedie: 158.061\n",
      "[175]\tvalid_0's tweedie: 158.061\n",
      "[176]\tvalid_0's tweedie: 158.061\n",
      "[177]\tvalid_0's tweedie: 158.061\n",
      "[178]\tvalid_0's tweedie: 158.061\n",
      "[179]\tvalid_0's tweedie: 158.061\n",
      "[180]\tvalid_0's tweedie: 158.061\n",
      "[181]\tvalid_0's tweedie: 158.061\n",
      "[182]\tvalid_0's tweedie: 158.061\n",
      "[183]\tvalid_0's tweedie: 158.061\n",
      "[184]\tvalid_0's tweedie: 158.061\n",
      "[185]\tvalid_0's tweedie: 158.06\n",
      "[186]\tvalid_0's tweedie: 158.06\n",
      "[187]\tvalid_0's tweedie: 158.06\n",
      "[188]\tvalid_0's tweedie: 158.06\n",
      "[189]\tvalid_0's tweedie: 158.06\n",
      "[190]\tvalid_0's tweedie: 158.06\n",
      "[191]\tvalid_0's tweedie: 158.06\n",
      "[192]\tvalid_0's tweedie: 158.06\n",
      "[193]\tvalid_0's tweedie: 158.06\n",
      "[194]\tvalid_0's tweedie: 158.06\n",
      "[195]\tvalid_0's tweedie: 158.06\n",
      "[196]\tvalid_0's tweedie: 158.06\n",
      "[197]\tvalid_0's tweedie: 158.06\n",
      "[198]\tvalid_0's tweedie: 158.06\n",
      "[199]\tvalid_0's tweedie: 158.06\n",
      "[200]\tvalid_0's tweedie: 158.06\n",
      "[201]\tvalid_0's tweedie: 158.06\n",
      "[202]\tvalid_0's tweedie: 158.06\n",
      "[203]\tvalid_0's tweedie: 158.06\n",
      "[204]\tvalid_0's tweedie: 158.06\n",
      "[205]\tvalid_0's tweedie: 158.06\n",
      "[206]\tvalid_0's tweedie: 158.06\n",
      "[207]\tvalid_0's tweedie: 158.06\n",
      "[208]\tvalid_0's tweedie: 158.059\n",
      "[209]\tvalid_0's tweedie: 158.059\n",
      "[210]\tvalid_0's tweedie: 158.059\n",
      "[211]\tvalid_0's tweedie: 158.059\n",
      "[212]\tvalid_0's tweedie: 158.059\n",
      "[213]\tvalid_0's tweedie: 158.059\n",
      "[214]\tvalid_0's tweedie: 158.059\n",
      "[215]\tvalid_0's tweedie: 158.059\n",
      "[216]\tvalid_0's tweedie: 158.059\n",
      "[217]\tvalid_0's tweedie: 158.059\n",
      "[218]\tvalid_0's tweedie: 158.059\n",
      "[219]\tvalid_0's tweedie: 158.059\n",
      "[220]\tvalid_0's tweedie: 158.059\n",
      "[221]\tvalid_0's tweedie: 158.059\n",
      "[222]\tvalid_0's tweedie: 158.059\n",
      "[223]\tvalid_0's tweedie: 158.059\n",
      "[224]\tvalid_0's tweedie: 158.059\n",
      "[225]\tvalid_0's tweedie: 158.059\n",
      "[226]\tvalid_0's tweedie: 158.059\n",
      "[227]\tvalid_0's tweedie: 158.059\n",
      "[228]\tvalid_0's tweedie: 158.059\n",
      "[229]\tvalid_0's tweedie: 158.058\n",
      "[230]\tvalid_0's tweedie: 158.059\n",
      "[231]\tvalid_0's tweedie: 158.058\n",
      "[232]\tvalid_0's tweedie: 158.058\n",
      "[233]\tvalid_0's tweedie: 158.058\n",
      "[234]\tvalid_0's tweedie: 158.058\n",
      "[235]\tvalid_0's tweedie: 158.058\n",
      "[236]\tvalid_0's tweedie: 158.058\n",
      "[237]\tvalid_0's tweedie: 158.058\n",
      "[238]\tvalid_0's tweedie: 158.058\n",
      "[239]\tvalid_0's tweedie: 158.057\n",
      "[240]\tvalid_0's tweedie: 158.057\n",
      "[241]\tvalid_0's tweedie: 158.057\n",
      "[242]\tvalid_0's tweedie: 158.057\n",
      "[243]\tvalid_0's tweedie: 158.057\n",
      "[244]\tvalid_0's tweedie: 158.057\n",
      "[245]\tvalid_0's tweedie: 158.057\n",
      "[246]\tvalid_0's tweedie: 158.057\n",
      "[247]\tvalid_0's tweedie: 158.057\n",
      "[248]\tvalid_0's tweedie: 158.057\n",
      "[249]\tvalid_0's tweedie: 158.057\n",
      "[250]\tvalid_0's tweedie: 158.057\n",
      "[251]\tvalid_0's tweedie: 158.057\n",
      "[252]\tvalid_0's tweedie: 158.057\n",
      "[253]\tvalid_0's tweedie: 158.057\n",
      "[254]\tvalid_0's tweedie: 158.057\n",
      "[255]\tvalid_0's tweedie: 158.057\n",
      "[256]\tvalid_0's tweedie: 158.057\n",
      "[257]\tvalid_0's tweedie: 158.057\n",
      "[258]\tvalid_0's tweedie: 158.056\n",
      "[259]\tvalid_0's tweedie: 158.056\n",
      "[260]\tvalid_0's tweedie: 158.056\n",
      "[261]\tvalid_0's tweedie: 158.056\n",
      "[262]\tvalid_0's tweedie: 158.056\n",
      "[263]\tvalid_0's tweedie: 158.056\n",
      "[264]\tvalid_0's tweedie: 158.056\n",
      "[265]\tvalid_0's tweedie: 158.056\n",
      "[266]\tvalid_0's tweedie: 158.056\n",
      "[267]\tvalid_0's tweedie: 158.056\n",
      "[268]\tvalid_0's tweedie: 158.056\n",
      "[269]\tvalid_0's tweedie: 158.055\n",
      "[270]\tvalid_0's tweedie: 158.056\n",
      "[271]\tvalid_0's tweedie: 158.055\n",
      "[272]\tvalid_0's tweedie: 158.055\n",
      "[273]\tvalid_0's tweedie: 158.055\n",
      "[274]\tvalid_0's tweedie: 158.055\n",
      "[275]\tvalid_0's tweedie: 158.055\n",
      "[276]\tvalid_0's tweedie: 158.055\n",
      "[277]\tvalid_0's tweedie: 158.055\n",
      "[278]\tvalid_0's tweedie: 158.055\n",
      "[279]\tvalid_0's tweedie: 158.055\n",
      "[280]\tvalid_0's tweedie: 158.054\n",
      "[281]\tvalid_0's tweedie: 158.054\n",
      "[282]\tvalid_0's tweedie: 158.054\n",
      "[283]\tvalid_0's tweedie: 158.054\n",
      "[284]\tvalid_0's tweedie: 158.054\n",
      "[285]\tvalid_0's tweedie: 158.054\n",
      "[286]\tvalid_0's tweedie: 158.054\n",
      "[287]\tvalid_0's tweedie: 158.055\n",
      "[288]\tvalid_0's tweedie: 158.055\n",
      "[289]\tvalid_0's tweedie: 158.055\n",
      "[290]\tvalid_0's tweedie: 158.055\n",
      "[291]\tvalid_0's tweedie: 158.055\n",
      "[292]\tvalid_0's tweedie: 158.054\n",
      "[293]\tvalid_0's tweedie: 158.054\n",
      "[294]\tvalid_0's tweedie: 158.054\n",
      "[295]\tvalid_0's tweedie: 158.054\n",
      "[296]\tvalid_0's tweedie: 158.054\n",
      "[297]\tvalid_0's tweedie: 158.054\n",
      "[298]\tvalid_0's tweedie: 158.054\n",
      "[299]\tvalid_0's tweedie: 158.054\n",
      "[300]\tvalid_0's tweedie: 158.054\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[281]\tvalid_0's tweedie: 158.054\n",
      "Training model for level 7 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5516\n",
      "[LightGBM] [Info] Number of data points in the train set: 39270, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.397643\n",
      "[1]\tvalid_0's tweedie: 176.85\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.772\n",
      "[3]\tvalid_0's tweedie: 171.171\n",
      "[4]\tvalid_0's tweedie: 168.964\n",
      "[5]\tvalid_0's tweedie: 167.124\n",
      "[6]\tvalid_0's tweedie: 165.593\n",
      "[7]\tvalid_0's tweedie: 164.297\n",
      "[8]\tvalid_0's tweedie: 163.227\n",
      "[9]\tvalid_0's tweedie: 162.32\n",
      "[10]\tvalid_0's tweedie: 161.587\n",
      "[11]\tvalid_0's tweedie: 160.969\n",
      "[12]\tvalid_0's tweedie: 160.494\n",
      "[13]\tvalid_0's tweedie: 160.083\n",
      "[14]\tvalid_0's tweedie: 159.741\n",
      "[15]\tvalid_0's tweedie: 159.454\n",
      "[16]\tvalid_0's tweedie: 159.226\n",
      "[17]\tvalid_0's tweedie: 159.035\n",
      "[18]\tvalid_0's tweedie: 158.876\n",
      "[19]\tvalid_0's tweedie: 158.745\n",
      "[20]\tvalid_0's tweedie: 158.638\n",
      "[21]\tvalid_0's tweedie: 158.549\n",
      "[22]\tvalid_0's tweedie: 158.478\n",
      "[23]\tvalid_0's tweedie: 158.42\n",
      "[24]\tvalid_0's tweedie: 158.371\n",
      "[25]\tvalid_0's tweedie: 158.334\n",
      "[26]\tvalid_0's tweedie: 158.297\n",
      "[27]\tvalid_0's tweedie: 158.268\n",
      "[28]\tvalid_0's tweedie: 158.243\n",
      "[29]\tvalid_0's tweedie: 158.222\n",
      "[30]\tvalid_0's tweedie: 158.207\n",
      "[31]\tvalid_0's tweedie: 158.193\n",
      "[32]\tvalid_0's tweedie: 158.181\n",
      "[33]\tvalid_0's tweedie: 158.169\n",
      "[34]\tvalid_0's tweedie: 158.162\n",
      "[35]\tvalid_0's tweedie: 158.15\n",
      "[36]\tvalid_0's tweedie: 158.142\n",
      "[37]\tvalid_0's tweedie: 158.139\n",
      "[38]\tvalid_0's tweedie: 158.132\n",
      "[39]\tvalid_0's tweedie: 158.128\n",
      "[40]\tvalid_0's tweedie: 158.123\n",
      "[41]\tvalid_0's tweedie: 158.122\n",
      "[42]\tvalid_0's tweedie: 158.12\n",
      "[43]\tvalid_0's tweedie: 158.119\n",
      "[44]\tvalid_0's tweedie: 158.116\n",
      "[45]\tvalid_0's tweedie: 158.115\n",
      "[46]\tvalid_0's tweedie: 158.114\n",
      "[47]\tvalid_0's tweedie: 158.113\n",
      "[48]\tvalid_0's tweedie: 158.113\n",
      "[49]\tvalid_0's tweedie: 158.112\n",
      "[50]\tvalid_0's tweedie: 158.109\n",
      "[51]\tvalid_0's tweedie: 158.108\n",
      "[52]\tvalid_0's tweedie: 158.107\n",
      "[53]\tvalid_0's tweedie: 158.107\n",
      "[54]\tvalid_0's tweedie: 158.106\n",
      "[55]\tvalid_0's tweedie: 158.106\n",
      "[56]\tvalid_0's tweedie: 158.106\n",
      "[57]\tvalid_0's tweedie: 158.105\n",
      "[58]\tvalid_0's tweedie: 158.105\n",
      "[59]\tvalid_0's tweedie: 158.105\n",
      "[60]\tvalid_0's tweedie: 158.105\n",
      "[61]\tvalid_0's tweedie: 158.104\n",
      "[62]\tvalid_0's tweedie: 158.104\n",
      "[63]\tvalid_0's tweedie: 158.103\n",
      "[64]\tvalid_0's tweedie: 158.101\n",
      "[65]\tvalid_0's tweedie: 158.099\n",
      "[66]\tvalid_0's tweedie: 158.098\n",
      "[67]\tvalid_0's tweedie: 158.098\n",
      "[68]\tvalid_0's tweedie: 158.097\n",
      "[69]\tvalid_0's tweedie: 158.097\n",
      "[70]\tvalid_0's tweedie: 158.098\n",
      "[71]\tvalid_0's tweedie: 158.097\n",
      "[72]\tvalid_0's tweedie: 158.097\n",
      "[73]\tvalid_0's tweedie: 158.097\n",
      "[74]\tvalid_0's tweedie: 158.096\n",
      "[75]\tvalid_0's tweedie: 158.096\n",
      "[76]\tvalid_0's tweedie: 158.096\n",
      "[77]\tvalid_0's tweedie: 158.097\n",
      "[78]\tvalid_0's tweedie: 158.095\n",
      "[79]\tvalid_0's tweedie: 158.095\n",
      "[80]\tvalid_0's tweedie: 158.094\n",
      "[81]\tvalid_0's tweedie: 158.094\n",
      "[82]\tvalid_0's tweedie: 158.094\n",
      "[83]\tvalid_0's tweedie: 158.094\n",
      "[84]\tvalid_0's tweedie: 158.094\n",
      "[85]\tvalid_0's tweedie: 158.094\n",
      "[86]\tvalid_0's tweedie: 158.094\n",
      "[87]\tvalid_0's tweedie: 158.092\n",
      "[88]\tvalid_0's tweedie: 158.092\n",
      "[89]\tvalid_0's tweedie: 158.092\n",
      "[90]\tvalid_0's tweedie: 158.091\n",
      "[91]\tvalid_0's tweedie: 158.09\n",
      "[92]\tvalid_0's tweedie: 158.09\n",
      "[93]\tvalid_0's tweedie: 158.09\n",
      "[94]\tvalid_0's tweedie: 158.089\n",
      "[95]\tvalid_0's tweedie: 158.089\n",
      "[96]\tvalid_0's tweedie: 158.089\n",
      "[97]\tvalid_0's tweedie: 158.089\n",
      "[98]\tvalid_0's tweedie: 158.089\n",
      "[99]\tvalid_0's tweedie: 158.089\n",
      "[100]\tvalid_0's tweedie: 158.089\n",
      "[101]\tvalid_0's tweedie: 158.089\n",
      "[102]\tvalid_0's tweedie: 158.088\n",
      "[103]\tvalid_0's tweedie: 158.088\n",
      "[104]\tvalid_0's tweedie: 158.088\n",
      "[105]\tvalid_0's tweedie: 158.088\n",
      "[106]\tvalid_0's tweedie: 158.087\n",
      "[107]\tvalid_0's tweedie: 158.087\n",
      "[108]\tvalid_0's tweedie: 158.087\n",
      "[109]\tvalid_0's tweedie: 158.087\n",
      "[110]\tvalid_0's tweedie: 158.087\n",
      "[111]\tvalid_0's tweedie: 158.087\n",
      "[112]\tvalid_0's tweedie: 158.087\n",
      "[113]\tvalid_0's tweedie: 158.086\n",
      "[114]\tvalid_0's tweedie: 158.086\n",
      "[115]\tvalid_0's tweedie: 158.086\n",
      "[116]\tvalid_0's tweedie: 158.086\n",
      "[117]\tvalid_0's tweedie: 158.086\n",
      "[118]\tvalid_0's tweedie: 158.086\n",
      "[119]\tvalid_0's tweedie: 158.085\n",
      "[120]\tvalid_0's tweedie: 158.085\n",
      "[121]\tvalid_0's tweedie: 158.085\n",
      "[122]\tvalid_0's tweedie: 158.085\n",
      "[123]\tvalid_0's tweedie: 158.085\n",
      "[124]\tvalid_0's tweedie: 158.085\n",
      "[125]\tvalid_0's tweedie: 158.085\n",
      "[126]\tvalid_0's tweedie: 158.085\n",
      "[127]\tvalid_0's tweedie: 158.085\n",
      "[128]\tvalid_0's tweedie: 158.085\n",
      "[129]\tvalid_0's tweedie: 158.085\n",
      "[130]\tvalid_0's tweedie: 158.085\n",
      "[131]\tvalid_0's tweedie: 158.085\n",
      "[132]\tvalid_0's tweedie: 158.085\n",
      "[133]\tvalid_0's tweedie: 158.085\n",
      "[134]\tvalid_0's tweedie: 158.084\n",
      "[135]\tvalid_0's tweedie: 158.084\n",
      "[136]\tvalid_0's tweedie: 158.084\n",
      "[137]\tvalid_0's tweedie: 158.084\n",
      "[138]\tvalid_0's tweedie: 158.084\n",
      "[139]\tvalid_0's tweedie: 158.084\n",
      "[140]\tvalid_0's tweedie: 158.084\n",
      "[141]\tvalid_0's tweedie: 158.084\n",
      "[142]\tvalid_0's tweedie: 158.084\n",
      "[143]\tvalid_0's tweedie: 158.084\n",
      "[144]\tvalid_0's tweedie: 158.083\n",
      "[145]\tvalid_0's tweedie: 158.083\n",
      "[146]\tvalid_0's tweedie: 158.083\n",
      "[147]\tvalid_0's tweedie: 158.083\n",
      "[148]\tvalid_0's tweedie: 158.082\n",
      "[149]\tvalid_0's tweedie: 158.082\n",
      "[150]\tvalid_0's tweedie: 158.082\n",
      "[151]\tvalid_0's tweedie: 158.082\n",
      "[152]\tvalid_0's tweedie: 158.081\n",
      "[153]\tvalid_0's tweedie: 158.081\n",
      "[154]\tvalid_0's tweedie: 158.081\n",
      "[155]\tvalid_0's tweedie: 158.081\n",
      "[156]\tvalid_0's tweedie: 158.081\n",
      "[157]\tvalid_0's tweedie: 158.081\n",
      "[158]\tvalid_0's tweedie: 158.08\n",
      "[159]\tvalid_0's tweedie: 158.08\n",
      "[160]\tvalid_0's tweedie: 158.08\n",
      "[161]\tvalid_0's tweedie: 158.08\n",
      "[162]\tvalid_0's tweedie: 158.08\n",
      "[163]\tvalid_0's tweedie: 158.08\n",
      "[164]\tvalid_0's tweedie: 158.079\n",
      "[165]\tvalid_0's tweedie: 158.079\n",
      "[166]\tvalid_0's tweedie: 158.079\n",
      "[167]\tvalid_0's tweedie: 158.079\n",
      "[168]\tvalid_0's tweedie: 158.078\n",
      "[169]\tvalid_0's tweedie: 158.078\n",
      "[170]\tvalid_0's tweedie: 158.078\n",
      "[171]\tvalid_0's tweedie: 158.078\n",
      "[172]\tvalid_0's tweedie: 158.078\n",
      "[173]\tvalid_0's tweedie: 158.077\n",
      "[174]\tvalid_0's tweedie: 158.077\n",
      "[175]\tvalid_0's tweedie: 158.078\n",
      "[176]\tvalid_0's tweedie: 158.078\n",
      "[177]\tvalid_0's tweedie: 158.077\n",
      "[178]\tvalid_0's tweedie: 158.077\n",
      "[179]\tvalid_0's tweedie: 158.077\n",
      "[180]\tvalid_0's tweedie: 158.077\n",
      "[181]\tvalid_0's tweedie: 158.077\n",
      "[182]\tvalid_0's tweedie: 158.077\n",
      "[183]\tvalid_0's tweedie: 158.077\n",
      "[184]\tvalid_0's tweedie: 158.076\n",
      "[185]\tvalid_0's tweedie: 158.076\n",
      "[186]\tvalid_0's tweedie: 158.077\n",
      "[187]\tvalid_0's tweedie: 158.077\n",
      "[188]\tvalid_0's tweedie: 158.076\n",
      "[189]\tvalid_0's tweedie: 158.076\n",
      "[190]\tvalid_0's tweedie: 158.076\n",
      "[191]\tvalid_0's tweedie: 158.076\n",
      "[192]\tvalid_0's tweedie: 158.076\n",
      "[193]\tvalid_0's tweedie: 158.076\n",
      "[194]\tvalid_0's tweedie: 158.076\n",
      "[195]\tvalid_0's tweedie: 158.076\n",
      "[196]\tvalid_0's tweedie: 158.076\n",
      "[197]\tvalid_0's tweedie: 158.076\n",
      "[198]\tvalid_0's tweedie: 158.076\n",
      "[199]\tvalid_0's tweedie: 158.076\n",
      "[200]\tvalid_0's tweedie: 158.076\n",
      "[201]\tvalid_0's tweedie: 158.076\n",
      "[202]\tvalid_0's tweedie: 158.076\n",
      "[203]\tvalid_0's tweedie: 158.076\n",
      "[204]\tvalid_0's tweedie: 158.076\n",
      "[205]\tvalid_0's tweedie: 158.076\n",
      "[206]\tvalid_0's tweedie: 158.076\n",
      "[207]\tvalid_0's tweedie: 158.076\n",
      "[208]\tvalid_0's tweedie: 158.076\n",
      "[209]\tvalid_0's tweedie: 158.076\n",
      "[210]\tvalid_0's tweedie: 158.076\n",
      "[211]\tvalid_0's tweedie: 158.076\n",
      "[212]\tvalid_0's tweedie: 158.076\n",
      "[213]\tvalid_0's tweedie: 158.076\n",
      "[214]\tvalid_0's tweedie: 158.076\n",
      "[215]\tvalid_0's tweedie: 158.075\n",
      "[216]\tvalid_0's tweedie: 158.075\n",
      "[217]\tvalid_0's tweedie: 158.075\n",
      "[218]\tvalid_0's tweedie: 158.075\n",
      "[219]\tvalid_0's tweedie: 158.074\n",
      "[220]\tvalid_0's tweedie: 158.074\n",
      "[221]\tvalid_0's tweedie: 158.074\n",
      "[222]\tvalid_0's tweedie: 158.074\n",
      "[223]\tvalid_0's tweedie: 158.074\n",
      "[224]\tvalid_0's tweedie: 158.074\n",
      "[225]\tvalid_0's tweedie: 158.074\n",
      "[226]\tvalid_0's tweedie: 158.074\n",
      "[227]\tvalid_0's tweedie: 158.074\n",
      "[228]\tvalid_0's tweedie: 158.074\n",
      "[229]\tvalid_0's tweedie: 158.074\n",
      "[230]\tvalid_0's tweedie: 158.074\n",
      "[231]\tvalid_0's tweedie: 158.074\n",
      "[232]\tvalid_0's tweedie: 158.074\n",
      "[233]\tvalid_0's tweedie: 158.074\n",
      "[234]\tvalid_0's tweedie: 158.074\n",
      "[235]\tvalid_0's tweedie: 158.074\n",
      "[236]\tvalid_0's tweedie: 158.074\n",
      "[237]\tvalid_0's tweedie: 158.073\n",
      "[238]\tvalid_0's tweedie: 158.073\n",
      "[239]\tvalid_0's tweedie: 158.073\n",
      "[240]\tvalid_0's tweedie: 158.073\n",
      "[241]\tvalid_0's tweedie: 158.073\n",
      "[242]\tvalid_0's tweedie: 158.073\n",
      "[243]\tvalid_0's tweedie: 158.073\n",
      "[244]\tvalid_0's tweedie: 158.072\n",
      "[245]\tvalid_0's tweedie: 158.072\n",
      "[246]\tvalid_0's tweedie: 158.072\n",
      "[247]\tvalid_0's tweedie: 158.072\n",
      "[248]\tvalid_0's tweedie: 158.072\n",
      "[249]\tvalid_0's tweedie: 158.072\n",
      "[250]\tvalid_0's tweedie: 158.072\n",
      "[251]\tvalid_0's tweedie: 158.072\n",
      "[252]\tvalid_0's tweedie: 158.072\n",
      "[253]\tvalid_0's tweedie: 158.072\n",
      "[254]\tvalid_0's tweedie: 158.072\n",
      "[255]\tvalid_0's tweedie: 158.072\n",
      "[256]\tvalid_0's tweedie: 158.072\n",
      "[257]\tvalid_0's tweedie: 158.072\n",
      "[258]\tvalid_0's tweedie: 158.072\n",
      "[259]\tvalid_0's tweedie: 158.072\n",
      "[260]\tvalid_0's tweedie: 158.072\n",
      "[261]\tvalid_0's tweedie: 158.072\n",
      "[262]\tvalid_0's tweedie: 158.072\n",
      "[263]\tvalid_0's tweedie: 158.072\n",
      "[264]\tvalid_0's tweedie: 158.072\n",
      "[265]\tvalid_0's tweedie: 158.072\n",
      "[266]\tvalid_0's tweedie: 158.072\n",
      "[267]\tvalid_0's tweedie: 158.072\n",
      "[268]\tvalid_0's tweedie: 158.072\n",
      "[269]\tvalid_0's tweedie: 158.072\n",
      "[270]\tvalid_0's tweedie: 158.072\n",
      "[271]\tvalid_0's tweedie: 158.072\n",
      "[272]\tvalid_0's tweedie: 158.072\n",
      "[273]\tvalid_0's tweedie: 158.072\n",
      "[274]\tvalid_0's tweedie: 158.072\n",
      "[275]\tvalid_0's tweedie: 158.071\n",
      "[276]\tvalid_0's tweedie: 158.071\n",
      "[277]\tvalid_0's tweedie: 158.071\n",
      "[278]\tvalid_0's tweedie: 158.071\n",
      "[279]\tvalid_0's tweedie: 158.071\n",
      "[280]\tvalid_0's tweedie: 158.071\n",
      "[281]\tvalid_0's tweedie: 158.07\n",
      "[282]\tvalid_0's tweedie: 158.07\n",
      "[283]\tvalid_0's tweedie: 158.07\n",
      "[284]\tvalid_0's tweedie: 158.07\n",
      "[285]\tvalid_0's tweedie: 158.07\n",
      "[286]\tvalid_0's tweedie: 158.07\n",
      "[287]\tvalid_0's tweedie: 158.07\n",
      "[288]\tvalid_0's tweedie: 158.07\n",
      "[289]\tvalid_0's tweedie: 158.07\n",
      "[290]\tvalid_0's tweedie: 158.07\n",
      "[291]\tvalid_0's tweedie: 158.07\n",
      "[292]\tvalid_0's tweedie: 158.07\n",
      "[293]\tvalid_0's tweedie: 158.07\n",
      "[294]\tvalid_0's tweedie: 158.07\n",
      "[295]\tvalid_0's tweedie: 158.07\n",
      "[296]\tvalid_0's tweedie: 158.07\n",
      "[297]\tvalid_0's tweedie: 158.07\n",
      "[298]\tvalid_0's tweedie: 158.07\n",
      "[299]\tvalid_0's tweedie: 158.07\n",
      "[300]\tvalid_0's tweedie: 158.07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 158.07\n",
      "Training model for level 7 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5515\n",
      "[LightGBM] [Info] Number of data points in the train set: 39249, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.397610\n",
      "[1]\tvalid_0's tweedie: 176.851\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.773\n",
      "[3]\tvalid_0's tweedie: 171.186\n",
      "[4]\tvalid_0's tweedie: 168.986\n",
      "[5]\tvalid_0's tweedie: 167.149\n",
      "[6]\tvalid_0's tweedie: 165.602\n",
      "[7]\tvalid_0's tweedie: 164.295\n",
      "[8]\tvalid_0's tweedie: 163.233\n",
      "[9]\tvalid_0's tweedie: 162.339\n",
      "[10]\tvalid_0's tweedie: 161.604\n",
      "[11]\tvalid_0's tweedie: 161.025\n",
      "[12]\tvalid_0's tweedie: 160.515\n",
      "[13]\tvalid_0's tweedie: 160.107\n",
      "[14]\tvalid_0's tweedie: 159.766\n",
      "[15]\tvalid_0's tweedie: 159.487\n",
      "[16]\tvalid_0's tweedie: 159.261\n",
      "[17]\tvalid_0's tweedie: 159.067\n",
      "[18]\tvalid_0's tweedie: 158.904\n",
      "[19]\tvalid_0's tweedie: 158.783\n",
      "[20]\tvalid_0's tweedie: 158.672\n",
      "[21]\tvalid_0's tweedie: 158.583\n",
      "[22]\tvalid_0's tweedie: 158.512\n",
      "[23]\tvalid_0's tweedie: 158.455\n",
      "[24]\tvalid_0's tweedie: 158.403\n",
      "[25]\tvalid_0's tweedie: 158.361\n",
      "[26]\tvalid_0's tweedie: 158.326\n",
      "[27]\tvalid_0's tweedie: 158.289\n",
      "[28]\tvalid_0's tweedie: 158.264\n",
      "[29]\tvalid_0's tweedie: 158.246\n",
      "[30]\tvalid_0's tweedie: 158.228\n",
      "[31]\tvalid_0's tweedie: 158.213\n",
      "[32]\tvalid_0's tweedie: 158.196\n",
      "[33]\tvalid_0's tweedie: 158.183\n",
      "[34]\tvalid_0's tweedie: 158.174\n",
      "[35]\tvalid_0's tweedie: 158.165\n",
      "[36]\tvalid_0's tweedie: 158.161\n",
      "[37]\tvalid_0's tweedie: 158.157\n",
      "[38]\tvalid_0's tweedie: 158.154\n",
      "[39]\tvalid_0's tweedie: 158.149\n",
      "[40]\tvalid_0's tweedie: 158.147\n",
      "[41]\tvalid_0's tweedie: 158.145\n",
      "[42]\tvalid_0's tweedie: 158.144\n",
      "[43]\tvalid_0's tweedie: 158.143\n",
      "[44]\tvalid_0's tweedie: 158.143\n",
      "[45]\tvalid_0's tweedie: 158.141\n",
      "[46]\tvalid_0's tweedie: 158.139\n",
      "[47]\tvalid_0's tweedie: 158.139\n",
      "[48]\tvalid_0's tweedie: 158.138\n",
      "[49]\tvalid_0's tweedie: 158.137\n",
      "[50]\tvalid_0's tweedie: 158.137\n",
      "[51]\tvalid_0's tweedie: 158.136\n",
      "[52]\tvalid_0's tweedie: 158.136\n",
      "[53]\tvalid_0's tweedie: 158.135\n",
      "[54]\tvalid_0's tweedie: 158.132\n",
      "[55]\tvalid_0's tweedie: 158.132\n",
      "[56]\tvalid_0's tweedie: 158.132\n",
      "[57]\tvalid_0's tweedie: 158.129\n",
      "[58]\tvalid_0's tweedie: 158.128\n",
      "[59]\tvalid_0's tweedie: 158.128\n",
      "[60]\tvalid_0's tweedie: 158.127\n",
      "[61]\tvalid_0's tweedie: 158.126\n",
      "[62]\tvalid_0's tweedie: 158.126\n",
      "[63]\tvalid_0's tweedie: 158.126\n",
      "[64]\tvalid_0's tweedie: 158.126\n",
      "[65]\tvalid_0's tweedie: 158.126\n",
      "[66]\tvalid_0's tweedie: 158.122\n",
      "[67]\tvalid_0's tweedie: 158.122\n",
      "[68]\tvalid_0's tweedie: 158.122\n",
      "[69]\tvalid_0's tweedie: 158.122\n",
      "[70]\tvalid_0's tweedie: 158.122\n",
      "[71]\tvalid_0's tweedie: 158.121\n",
      "[72]\tvalid_0's tweedie: 158.121\n",
      "[73]\tvalid_0's tweedie: 158.12\n",
      "[74]\tvalid_0's tweedie: 158.119\n",
      "[75]\tvalid_0's tweedie: 158.118\n",
      "[76]\tvalid_0's tweedie: 158.118\n",
      "[77]\tvalid_0's tweedie: 158.118\n",
      "[78]\tvalid_0's tweedie: 158.117\n",
      "[79]\tvalid_0's tweedie: 158.117\n",
      "[80]\tvalid_0's tweedie: 158.116\n",
      "[81]\tvalid_0's tweedie: 158.116\n",
      "[82]\tvalid_0's tweedie: 158.116\n",
      "[83]\tvalid_0's tweedie: 158.116\n",
      "[84]\tvalid_0's tweedie: 158.115\n",
      "[85]\tvalid_0's tweedie: 158.115\n",
      "[86]\tvalid_0's tweedie: 158.112\n",
      "[87]\tvalid_0's tweedie: 158.111\n",
      "[88]\tvalid_0's tweedie: 158.11\n",
      "[89]\tvalid_0's tweedie: 158.109\n",
      "[90]\tvalid_0's tweedie: 158.109\n",
      "[91]\tvalid_0's tweedie: 158.109\n",
      "[92]\tvalid_0's tweedie: 158.109\n",
      "[93]\tvalid_0's tweedie: 158.109\n",
      "[94]\tvalid_0's tweedie: 158.109\n",
      "[95]\tvalid_0's tweedie: 158.109\n",
      "[96]\tvalid_0's tweedie: 158.109\n",
      "[97]\tvalid_0's tweedie: 158.109\n",
      "[98]\tvalid_0's tweedie: 158.109\n",
      "[99]\tvalid_0's tweedie: 158.108\n",
      "[100]\tvalid_0's tweedie: 158.108\n",
      "[101]\tvalid_0's tweedie: 158.108\n",
      "[102]\tvalid_0's tweedie: 158.108\n",
      "[103]\tvalid_0's tweedie: 158.107\n",
      "[104]\tvalid_0's tweedie: 158.107\n",
      "[105]\tvalid_0's tweedie: 158.107\n",
      "[106]\tvalid_0's tweedie: 158.105\n",
      "[107]\tvalid_0's tweedie: 158.105\n",
      "[108]\tvalid_0's tweedie: 158.106\n",
      "[109]\tvalid_0's tweedie: 158.106\n",
      "[110]\tvalid_0's tweedie: 158.105\n",
      "[111]\tvalid_0's tweedie: 158.105\n",
      "[112]\tvalid_0's tweedie: 158.104\n",
      "[113]\tvalid_0's tweedie: 158.103\n",
      "[114]\tvalid_0's tweedie: 158.103\n",
      "[115]\tvalid_0's tweedie: 158.102\n",
      "[116]\tvalid_0's tweedie: 158.102\n",
      "[117]\tvalid_0's tweedie: 158.102\n",
      "[118]\tvalid_0's tweedie: 158.102\n",
      "[119]\tvalid_0's tweedie: 158.102\n",
      "[120]\tvalid_0's tweedie: 158.102\n",
      "[121]\tvalid_0's tweedie: 158.101\n",
      "[122]\tvalid_0's tweedie: 158.101\n",
      "[123]\tvalid_0's tweedie: 158.101\n",
      "[124]\tvalid_0's tweedie: 158.099\n",
      "[125]\tvalid_0's tweedie: 158.1\n",
      "[126]\tvalid_0's tweedie: 158.1\n",
      "[127]\tvalid_0's tweedie: 158.1\n",
      "[128]\tvalid_0's tweedie: 158.099\n",
      "[129]\tvalid_0's tweedie: 158.098\n",
      "[130]\tvalid_0's tweedie: 158.098\n",
      "[131]\tvalid_0's tweedie: 158.097\n",
      "[132]\tvalid_0's tweedie: 158.097\n",
      "[133]\tvalid_0's tweedie: 158.097\n",
      "[134]\tvalid_0's tweedie: 158.097\n",
      "[135]\tvalid_0's tweedie: 158.096\n",
      "[136]\tvalid_0's tweedie: 158.096\n",
      "[137]\tvalid_0's tweedie: 158.095\n",
      "[138]\tvalid_0's tweedie: 158.095\n",
      "[139]\tvalid_0's tweedie: 158.095\n",
      "[140]\tvalid_0's tweedie: 158.094\n",
      "[141]\tvalid_0's tweedie: 158.094\n",
      "[142]\tvalid_0's tweedie: 158.094\n",
      "[143]\tvalid_0's tweedie: 158.094\n",
      "[144]\tvalid_0's tweedie: 158.092\n",
      "[145]\tvalid_0's tweedie: 158.092\n",
      "[146]\tvalid_0's tweedie: 158.092\n",
      "[147]\tvalid_0's tweedie: 158.091\n",
      "[148]\tvalid_0's tweedie: 158.091\n",
      "[149]\tvalid_0's tweedie: 158.091\n",
      "[150]\tvalid_0's tweedie: 158.091\n",
      "[151]\tvalid_0's tweedie: 158.091\n",
      "[152]\tvalid_0's tweedie: 158.091\n",
      "[153]\tvalid_0's tweedie: 158.091\n",
      "[154]\tvalid_0's tweedie: 158.091\n",
      "[155]\tvalid_0's tweedie: 158.091\n",
      "[156]\tvalid_0's tweedie: 158.091\n",
      "[157]\tvalid_0's tweedie: 158.089\n",
      "[158]\tvalid_0's tweedie: 158.089\n",
      "[159]\tvalid_0's tweedie: 158.088\n",
      "[160]\tvalid_0's tweedie: 158.088\n",
      "[161]\tvalid_0's tweedie: 158.088\n",
      "[162]\tvalid_0's tweedie: 158.088\n",
      "[163]\tvalid_0's tweedie: 158.088\n",
      "[164]\tvalid_0's tweedie: 158.088\n",
      "[165]\tvalid_0's tweedie: 158.088\n",
      "[166]\tvalid_0's tweedie: 158.088\n",
      "[167]\tvalid_0's tweedie: 158.088\n",
      "[168]\tvalid_0's tweedie: 158.088\n",
      "[169]\tvalid_0's tweedie: 158.087\n",
      "[170]\tvalid_0's tweedie: 158.087\n",
      "[171]\tvalid_0's tweedie: 158.087\n",
      "[172]\tvalid_0's tweedie: 158.087\n",
      "[173]\tvalid_0's tweedie: 158.087\n",
      "[174]\tvalid_0's tweedie: 158.087\n",
      "[175]\tvalid_0's tweedie: 158.087\n",
      "[176]\tvalid_0's tweedie: 158.087\n",
      "[177]\tvalid_0's tweedie: 158.087\n",
      "[178]\tvalid_0's tweedie: 158.087\n",
      "[179]\tvalid_0's tweedie: 158.086\n",
      "[180]\tvalid_0's tweedie: 158.087\n",
      "[181]\tvalid_0's tweedie: 158.087\n",
      "[182]\tvalid_0's tweedie: 158.087\n",
      "[183]\tvalid_0's tweedie: 158.087\n",
      "[184]\tvalid_0's tweedie: 158.086\n",
      "[185]\tvalid_0's tweedie: 158.086\n",
      "[186]\tvalid_0's tweedie: 158.086\n",
      "[187]\tvalid_0's tweedie: 158.086\n",
      "[188]\tvalid_0's tweedie: 158.086\n",
      "[189]\tvalid_0's tweedie: 158.085\n",
      "[190]\tvalid_0's tweedie: 158.086\n",
      "[191]\tvalid_0's tweedie: 158.085\n",
      "[192]\tvalid_0's tweedie: 158.085\n",
      "[193]\tvalid_0's tweedie: 158.085\n",
      "[194]\tvalid_0's tweedie: 158.085\n",
      "[195]\tvalid_0's tweedie: 158.085\n",
      "[196]\tvalid_0's tweedie: 158.085\n",
      "[197]\tvalid_0's tweedie: 158.085\n",
      "[198]\tvalid_0's tweedie: 158.085\n",
      "[199]\tvalid_0's tweedie: 158.085\n",
      "[200]\tvalid_0's tweedie: 158.085\n",
      "[201]\tvalid_0's tweedie: 158.085\n",
      "[202]\tvalid_0's tweedie: 158.085\n",
      "[203]\tvalid_0's tweedie: 158.085\n",
      "[204]\tvalid_0's tweedie: 158.085\n",
      "[205]\tvalid_0's tweedie: 158.085\n",
      "[206]\tvalid_0's tweedie: 158.085\n",
      "[207]\tvalid_0's tweedie: 158.085\n",
      "[208]\tvalid_0's tweedie: 158.085\n",
      "[209]\tvalid_0's tweedie: 158.085\n",
      "[210]\tvalid_0's tweedie: 158.085\n",
      "[211]\tvalid_0's tweedie: 158.085\n",
      "[212]\tvalid_0's tweedie: 158.085\n",
      "[213]\tvalid_0's tweedie: 158.085\n",
      "[214]\tvalid_0's tweedie: 158.086\n",
      "[215]\tvalid_0's tweedie: 158.086\n",
      "[216]\tvalid_0's tweedie: 158.086\n",
      "[217]\tvalid_0's tweedie: 158.086\n",
      "[218]\tvalid_0's tweedie: 158.085\n",
      "[219]\tvalid_0's tweedie: 158.085\n",
      "[220]\tvalid_0's tweedie: 158.085\n",
      "[221]\tvalid_0's tweedie: 158.085\n",
      "[222]\tvalid_0's tweedie: 158.085\n",
      "[223]\tvalid_0's tweedie: 158.085\n",
      "[224]\tvalid_0's tweedie: 158.085\n",
      "[225]\tvalid_0's tweedie: 158.085\n",
      "[226]\tvalid_0's tweedie: 158.085\n",
      "[227]\tvalid_0's tweedie: 158.085\n",
      "[228]\tvalid_0's tweedie: 158.085\n",
      "[229]\tvalid_0's tweedie: 158.085\n",
      "[230]\tvalid_0's tweedie: 158.085\n",
      "[231]\tvalid_0's tweedie: 158.085\n",
      "[232]\tvalid_0's tweedie: 158.085\n",
      "[233]\tvalid_0's tweedie: 158.084\n",
      "[234]\tvalid_0's tweedie: 158.085\n",
      "[235]\tvalid_0's tweedie: 158.085\n",
      "[236]\tvalid_0's tweedie: 158.085\n",
      "[237]\tvalid_0's tweedie: 158.085\n",
      "[238]\tvalid_0's tweedie: 158.085\n",
      "[239]\tvalid_0's tweedie: 158.085\n",
      "[240]\tvalid_0's tweedie: 158.085\n",
      "[241]\tvalid_0's tweedie: 158.085\n",
      "[242]\tvalid_0's tweedie: 158.084\n",
      "[243]\tvalid_0's tweedie: 158.085\n",
      "[244]\tvalid_0's tweedie: 158.084\n",
      "[245]\tvalid_0's tweedie: 158.084\n",
      "[246]\tvalid_0's tweedie: 158.084\n",
      "[247]\tvalid_0's tweedie: 158.084\n",
      "[248]\tvalid_0's tweedie: 158.084\n",
      "[249]\tvalid_0's tweedie: 158.084\n",
      "[250]\tvalid_0's tweedie: 158.084\n",
      "[251]\tvalid_0's tweedie: 158.084\n",
      "[252]\tvalid_0's tweedie: 158.084\n",
      "[253]\tvalid_0's tweedie: 158.084\n",
      "[254]\tvalid_0's tweedie: 158.084\n",
      "[255]\tvalid_0's tweedie: 158.084\n",
      "[256]\tvalid_0's tweedie: 158.084\n",
      "[257]\tvalid_0's tweedie: 158.084\n",
      "[258]\tvalid_0's tweedie: 158.084\n",
      "[259]\tvalid_0's tweedie: 158.084\n",
      "[260]\tvalid_0's tweedie: 158.084\n",
      "[261]\tvalid_0's tweedie: 158.084\n",
      "[262]\tvalid_0's tweedie: 158.084\n",
      "[263]\tvalid_0's tweedie: 158.084\n",
      "[264]\tvalid_0's tweedie: 158.083\n",
      "[265]\tvalid_0's tweedie: 158.083\n",
      "[266]\tvalid_0's tweedie: 158.083\n",
      "[267]\tvalid_0's tweedie: 158.083\n",
      "[268]\tvalid_0's tweedie: 158.083\n",
      "[269]\tvalid_0's tweedie: 158.083\n",
      "[270]\tvalid_0's tweedie: 158.083\n",
      "[271]\tvalid_0's tweedie: 158.083\n",
      "[272]\tvalid_0's tweedie: 158.083\n",
      "[273]\tvalid_0's tweedie: 158.083\n",
      "[274]\tvalid_0's tweedie: 158.083\n",
      "[275]\tvalid_0's tweedie: 158.083\n",
      "[276]\tvalid_0's tweedie: 158.083\n",
      "[277]\tvalid_0's tweedie: 158.083\n",
      "[278]\tvalid_0's tweedie: 158.083\n",
      "[279]\tvalid_0's tweedie: 158.083\n",
      "[280]\tvalid_0's tweedie: 158.083\n",
      "[281]\tvalid_0's tweedie: 158.083\n",
      "[282]\tvalid_0's tweedie: 158.083\n",
      "[283]\tvalid_0's tweedie: 158.083\n",
      "[284]\tvalid_0's tweedie: 158.083\n",
      "[285]\tvalid_0's tweedie: 158.083\n",
      "[286]\tvalid_0's tweedie: 158.083\n",
      "[287]\tvalid_0's tweedie: 158.083\n",
      "[288]\tvalid_0's tweedie: 158.083\n",
      "[289]\tvalid_0's tweedie: 158.083\n",
      "[290]\tvalid_0's tweedie: 158.083\n",
      "[291]\tvalid_0's tweedie: 158.083\n",
      "[292]\tvalid_0's tweedie: 158.083\n",
      "[293]\tvalid_0's tweedie: 158.083\n",
      "[294]\tvalid_0's tweedie: 158.083\n",
      "[295]\tvalid_0's tweedie: 158.083\n",
      "[296]\tvalid_0's tweedie: 158.083\n",
      "[297]\tvalid_0's tweedie: 158.083\n",
      "[298]\tvalid_0's tweedie: 158.083\n",
      "[299]\tvalid_0's tweedie: 158.083\n",
      "[300]\tvalid_0's tweedie: 158.083\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 158.083\n",
      "Training model for level 7 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5514\n",
      "[LightGBM] [Info] Number of data points in the train set: 39228, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.397805\n",
      "[1]\tvalid_0's tweedie: 176.846\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.781\n",
      "[3]\tvalid_0's tweedie: 171.18\n",
      "[4]\tvalid_0's tweedie: 168.983\n",
      "[5]\tvalid_0's tweedie: 167.14\n",
      "[6]\tvalid_0's tweedie: 165.601\n",
      "[7]\tvalid_0's tweedie: 164.318\n",
      "[8]\tvalid_0's tweedie: 163.236\n",
      "[9]\tvalid_0's tweedie: 162.368\n",
      "[10]\tvalid_0's tweedie: 161.626\n",
      "[11]\tvalid_0's tweedie: 161.004\n",
      "[12]\tvalid_0's tweedie: 160.525\n",
      "[13]\tvalid_0's tweedie: 160.11\n",
      "[14]\tvalid_0's tweedie: 159.778\n",
      "[15]\tvalid_0's tweedie: 159.496\n",
      "[16]\tvalid_0's tweedie: 159.26\n",
      "[17]\tvalid_0's tweedie: 159.068\n",
      "[18]\tvalid_0's tweedie: 158.907\n",
      "[19]\tvalid_0's tweedie: 158.777\n",
      "[20]\tvalid_0's tweedie: 158.676\n",
      "[21]\tvalid_0's tweedie: 158.589\n",
      "[22]\tvalid_0's tweedie: 158.516\n",
      "[23]\tvalid_0's tweedie: 158.457\n",
      "[24]\tvalid_0's tweedie: 158.399\n",
      "[25]\tvalid_0's tweedie: 158.353\n",
      "[26]\tvalid_0's tweedie: 158.318\n",
      "[27]\tvalid_0's tweedie: 158.289\n",
      "[28]\tvalid_0's tweedie: 158.265\n",
      "[29]\tvalid_0's tweedie: 158.241\n",
      "[30]\tvalid_0's tweedie: 158.225\n",
      "[31]\tvalid_0's tweedie: 158.207\n",
      "[32]\tvalid_0's tweedie: 158.195\n",
      "[33]\tvalid_0's tweedie: 158.184\n",
      "[34]\tvalid_0's tweedie: 158.176\n",
      "[35]\tvalid_0's tweedie: 158.165\n",
      "[36]\tvalid_0's tweedie: 158.16\n",
      "[37]\tvalid_0's tweedie: 158.155\n",
      "[38]\tvalid_0's tweedie: 158.153\n",
      "[39]\tvalid_0's tweedie: 158.15\n",
      "[40]\tvalid_0's tweedie: 158.148\n",
      "[41]\tvalid_0's tweedie: 158.146\n",
      "[42]\tvalid_0's tweedie: 158.145\n",
      "[43]\tvalid_0's tweedie: 158.143\n",
      "[44]\tvalid_0's tweedie: 158.14\n",
      "[45]\tvalid_0's tweedie: 158.139\n",
      "[46]\tvalid_0's tweedie: 158.139\n",
      "[47]\tvalid_0's tweedie: 158.136\n",
      "[48]\tvalid_0's tweedie: 158.133\n",
      "[49]\tvalid_0's tweedie: 158.132\n",
      "[50]\tvalid_0's tweedie: 158.131\n",
      "[51]\tvalid_0's tweedie: 158.131\n",
      "[52]\tvalid_0's tweedie: 158.13\n",
      "[53]\tvalid_0's tweedie: 158.129\n",
      "[54]\tvalid_0's tweedie: 158.129\n",
      "[55]\tvalid_0's tweedie: 158.129\n",
      "[56]\tvalid_0's tweedie: 158.129\n",
      "[57]\tvalid_0's tweedie: 158.129\n",
      "[58]\tvalid_0's tweedie: 158.129\n",
      "[59]\tvalid_0's tweedie: 158.129\n",
      "[60]\tvalid_0's tweedie: 158.129\n",
      "[61]\tvalid_0's tweedie: 158.128\n",
      "[62]\tvalid_0's tweedie: 158.128\n",
      "[63]\tvalid_0's tweedie: 158.128\n",
      "[64]\tvalid_0's tweedie: 158.127\n",
      "[65]\tvalid_0's tweedie: 158.127\n",
      "[66]\tvalid_0's tweedie: 158.127\n",
      "[67]\tvalid_0's tweedie: 158.126\n",
      "[68]\tvalid_0's tweedie: 158.126\n",
      "[69]\tvalid_0's tweedie: 158.122\n",
      "[70]\tvalid_0's tweedie: 158.12\n",
      "[71]\tvalid_0's tweedie: 158.12\n",
      "[72]\tvalid_0's tweedie: 158.12\n",
      "[73]\tvalid_0's tweedie: 158.12\n",
      "[74]\tvalid_0's tweedie: 158.12\n",
      "[75]\tvalid_0's tweedie: 158.119\n",
      "[76]\tvalid_0's tweedie: 158.119\n",
      "[77]\tvalid_0's tweedie: 158.119\n",
      "[78]\tvalid_0's tweedie: 158.119\n",
      "[79]\tvalid_0's tweedie: 158.119\n",
      "[80]\tvalid_0's tweedie: 158.118\n",
      "[81]\tvalid_0's tweedie: 158.118\n",
      "[82]\tvalid_0's tweedie: 158.113\n",
      "[83]\tvalid_0's tweedie: 158.113\n",
      "[84]\tvalid_0's tweedie: 158.113\n",
      "[85]\tvalid_0's tweedie: 158.113\n",
      "[86]\tvalid_0's tweedie: 158.112\n",
      "[87]\tvalid_0's tweedie: 158.112\n",
      "[88]\tvalid_0's tweedie: 158.112\n",
      "[89]\tvalid_0's tweedie: 158.112\n",
      "[90]\tvalid_0's tweedie: 158.112\n",
      "[91]\tvalid_0's tweedie: 158.112\n",
      "[92]\tvalid_0's tweedie: 158.111\n",
      "[93]\tvalid_0's tweedie: 158.111\n",
      "[94]\tvalid_0's tweedie: 158.112\n",
      "[95]\tvalid_0's tweedie: 158.112\n",
      "[96]\tvalid_0's tweedie: 158.112\n",
      "[97]\tvalid_0's tweedie: 158.111\n",
      "[98]\tvalid_0's tweedie: 158.111\n",
      "[99]\tvalid_0's tweedie: 158.111\n",
      "[100]\tvalid_0's tweedie: 158.111\n",
      "[101]\tvalid_0's tweedie: 158.111\n",
      "[102]\tvalid_0's tweedie: 158.111\n",
      "[103]\tvalid_0's tweedie: 158.111\n",
      "[104]\tvalid_0's tweedie: 158.11\n",
      "[105]\tvalid_0's tweedie: 158.11\n",
      "[106]\tvalid_0's tweedie: 158.11\n",
      "[107]\tvalid_0's tweedie: 158.11\n",
      "[108]\tvalid_0's tweedie: 158.11\n",
      "[109]\tvalid_0's tweedie: 158.11\n",
      "[110]\tvalid_0's tweedie: 158.11\n",
      "[111]\tvalid_0's tweedie: 158.11\n",
      "[112]\tvalid_0's tweedie: 158.109\n",
      "[113]\tvalid_0's tweedie: 158.109\n",
      "[114]\tvalid_0's tweedie: 158.11\n",
      "[115]\tvalid_0's tweedie: 158.107\n",
      "[116]\tvalid_0's tweedie: 158.107\n",
      "[117]\tvalid_0's tweedie: 158.107\n",
      "[118]\tvalid_0's tweedie: 158.107\n",
      "[119]\tvalid_0's tweedie: 158.107\n",
      "[120]\tvalid_0's tweedie: 158.107\n",
      "[121]\tvalid_0's tweedie: 158.107\n",
      "[122]\tvalid_0's tweedie: 158.107\n",
      "[123]\tvalid_0's tweedie: 158.107\n",
      "[124]\tvalid_0's tweedie: 158.106\n",
      "[125]\tvalid_0's tweedie: 158.106\n",
      "[126]\tvalid_0's tweedie: 158.106\n",
      "[127]\tvalid_0's tweedie: 158.106\n",
      "[128]\tvalid_0's tweedie: 158.106\n",
      "[129]\tvalid_0's tweedie: 158.105\n",
      "[130]\tvalid_0's tweedie: 158.105\n",
      "[131]\tvalid_0's tweedie: 158.105\n",
      "[132]\tvalid_0's tweedie: 158.105\n",
      "[133]\tvalid_0's tweedie: 158.105\n",
      "[134]\tvalid_0's tweedie: 158.105\n",
      "[135]\tvalid_0's tweedie: 158.105\n",
      "[136]\tvalid_0's tweedie: 158.105\n",
      "[137]\tvalid_0's tweedie: 158.105\n",
      "[138]\tvalid_0's tweedie: 158.104\n",
      "[139]\tvalid_0's tweedie: 158.105\n",
      "[140]\tvalid_0's tweedie: 158.104\n",
      "[141]\tvalid_0's tweedie: 158.104\n",
      "[142]\tvalid_0's tweedie: 158.104\n",
      "[143]\tvalid_0's tweedie: 158.104\n",
      "[144]\tvalid_0's tweedie: 158.103\n",
      "[145]\tvalid_0's tweedie: 158.103\n",
      "[146]\tvalid_0's tweedie: 158.103\n",
      "[147]\tvalid_0's tweedie: 158.103\n",
      "[148]\tvalid_0's tweedie: 158.103\n",
      "[149]\tvalid_0's tweedie: 158.103\n",
      "[150]\tvalid_0's tweedie: 158.103\n",
      "[151]\tvalid_0's tweedie: 158.103\n",
      "[152]\tvalid_0's tweedie: 158.103\n",
      "[153]\tvalid_0's tweedie: 158.101\n",
      "[154]\tvalid_0's tweedie: 158.099\n",
      "[155]\tvalid_0's tweedie: 158.099\n",
      "[156]\tvalid_0's tweedie: 158.099\n",
      "[157]\tvalid_0's tweedie: 158.099\n",
      "[158]\tvalid_0's tweedie: 158.099\n",
      "[159]\tvalid_0's tweedie: 158.099\n",
      "[160]\tvalid_0's tweedie: 158.099\n",
      "[161]\tvalid_0's tweedie: 158.099\n",
      "[162]\tvalid_0's tweedie: 158.099\n",
      "[163]\tvalid_0's tweedie: 158.099\n",
      "[164]\tvalid_0's tweedie: 158.099\n",
      "[165]\tvalid_0's tweedie: 158.099\n",
      "[166]\tvalid_0's tweedie: 158.098\n",
      "[167]\tvalid_0's tweedie: 158.098\n",
      "[168]\tvalid_0's tweedie: 158.097\n",
      "[169]\tvalid_0's tweedie: 158.097\n",
      "[170]\tvalid_0's tweedie: 158.097\n",
      "[171]\tvalid_0's tweedie: 158.098\n",
      "[172]\tvalid_0's tweedie: 158.098\n",
      "[173]\tvalid_0's tweedie: 158.098\n",
      "[174]\tvalid_0's tweedie: 158.098\n",
      "[175]\tvalid_0's tweedie: 158.098\n",
      "[176]\tvalid_0's tweedie: 158.097\n",
      "[177]\tvalid_0's tweedie: 158.097\n",
      "[178]\tvalid_0's tweedie: 158.097\n",
      "[179]\tvalid_0's tweedie: 158.097\n",
      "[180]\tvalid_0's tweedie: 158.097\n",
      "[181]\tvalid_0's tweedie: 158.097\n",
      "[182]\tvalid_0's tweedie: 158.097\n",
      "[183]\tvalid_0's tweedie: 158.097\n",
      "[184]\tvalid_0's tweedie: 158.097\n",
      "[185]\tvalid_0's tweedie: 158.097\n",
      "[186]\tvalid_0's tweedie: 158.097\n",
      "[187]\tvalid_0's tweedie: 158.097\n",
      "[188]\tvalid_0's tweedie: 158.097\n",
      "[189]\tvalid_0's tweedie: 158.097\n",
      "[190]\tvalid_0's tweedie: 158.097\n",
      "[191]\tvalid_0's tweedie: 158.097\n",
      "[192]\tvalid_0's tweedie: 158.097\n",
      "[193]\tvalid_0's tweedie: 158.097\n",
      "[194]\tvalid_0's tweedie: 158.097\n",
      "[195]\tvalid_0's tweedie: 158.097\n",
      "[196]\tvalid_0's tweedie: 158.097\n",
      "[197]\tvalid_0's tweedie: 158.097\n",
      "[198]\tvalid_0's tweedie: 158.097\n",
      "[199]\tvalid_0's tweedie: 158.097\n",
      "[200]\tvalid_0's tweedie: 158.097\n",
      "[201]\tvalid_0's tweedie: 158.097\n",
      "[202]\tvalid_0's tweedie: 158.097\n",
      "[203]\tvalid_0's tweedie: 158.097\n",
      "[204]\tvalid_0's tweedie: 158.097\n",
      "[205]\tvalid_0's tweedie: 158.097\n",
      "[206]\tvalid_0's tweedie: 158.096\n",
      "[207]\tvalid_0's tweedie: 158.096\n",
      "[208]\tvalid_0's tweedie: 158.096\n",
      "[209]\tvalid_0's tweedie: 158.096\n",
      "[210]\tvalid_0's tweedie: 158.096\n",
      "[211]\tvalid_0's tweedie: 158.096\n",
      "[212]\tvalid_0's tweedie: 158.096\n",
      "[213]\tvalid_0's tweedie: 158.096\n",
      "[214]\tvalid_0's tweedie: 158.096\n",
      "[215]\tvalid_0's tweedie: 158.096\n",
      "[216]\tvalid_0's tweedie: 158.096\n",
      "[217]\tvalid_0's tweedie: 158.096\n",
      "[218]\tvalid_0's tweedie: 158.095\n",
      "[219]\tvalid_0's tweedie: 158.095\n",
      "[220]\tvalid_0's tweedie: 158.094\n",
      "[221]\tvalid_0's tweedie: 158.094\n",
      "[222]\tvalid_0's tweedie: 158.094\n",
      "[223]\tvalid_0's tweedie: 158.094\n",
      "[224]\tvalid_0's tweedie: 158.094\n",
      "[225]\tvalid_0's tweedie: 158.092\n",
      "[226]\tvalid_0's tweedie: 158.092\n",
      "[227]\tvalid_0's tweedie: 158.092\n",
      "[228]\tvalid_0's tweedie: 158.092\n",
      "[229]\tvalid_0's tweedie: 158.092\n",
      "[230]\tvalid_0's tweedie: 158.092\n",
      "[231]\tvalid_0's tweedie: 158.092\n",
      "[232]\tvalid_0's tweedie: 158.092\n",
      "[233]\tvalid_0's tweedie: 158.091\n",
      "[234]\tvalid_0's tweedie: 158.091\n",
      "[235]\tvalid_0's tweedie: 158.091\n",
      "[236]\tvalid_0's tweedie: 158.091\n",
      "[237]\tvalid_0's tweedie: 158.091\n",
      "[238]\tvalid_0's tweedie: 158.091\n",
      "[239]\tvalid_0's tweedie: 158.09\n",
      "[240]\tvalid_0's tweedie: 158.09\n",
      "[241]\tvalid_0's tweedie: 158.09\n",
      "[242]\tvalid_0's tweedie: 158.09\n",
      "[243]\tvalid_0's tweedie: 158.09\n",
      "[244]\tvalid_0's tweedie: 158.09\n",
      "[245]\tvalid_0's tweedie: 158.091\n",
      "[246]\tvalid_0's tweedie: 158.09\n",
      "[247]\tvalid_0's tweedie: 158.091\n",
      "[248]\tvalid_0's tweedie: 158.09\n",
      "[249]\tvalid_0's tweedie: 158.09\n",
      "[250]\tvalid_0's tweedie: 158.09\n",
      "[251]\tvalid_0's tweedie: 158.09\n",
      "[252]\tvalid_0's tweedie: 158.091\n",
      "[253]\tvalid_0's tweedie: 158.091\n",
      "[254]\tvalid_0's tweedie: 158.091\n",
      "[255]\tvalid_0's tweedie: 158.091\n",
      "[256]\tvalid_0's tweedie: 158.091\n",
      "[257]\tvalid_0's tweedie: 158.091\n",
      "[258]\tvalid_0's tweedie: 158.091\n",
      "[259]\tvalid_0's tweedie: 158.091\n",
      "[260]\tvalid_0's tweedie: 158.091\n",
      "[261]\tvalid_0's tweedie: 158.091\n",
      "[262]\tvalid_0's tweedie: 158.091\n",
      "[263]\tvalid_0's tweedie: 158.091\n",
      "[264]\tvalid_0's tweedie: 158.091\n",
      "[265]\tvalid_0's tweedie: 158.089\n",
      "[266]\tvalid_0's tweedie: 158.089\n",
      "[267]\tvalid_0's tweedie: 158.089\n",
      "[268]\tvalid_0's tweedie: 158.089\n",
      "[269]\tvalid_0's tweedie: 158.089\n",
      "[270]\tvalid_0's tweedie: 158.088\n",
      "[271]\tvalid_0's tweedie: 158.088\n",
      "[272]\tvalid_0's tweedie: 158.088\n",
      "[273]\tvalid_0's tweedie: 158.088\n",
      "[274]\tvalid_0's tweedie: 158.088\n",
      "[275]\tvalid_0's tweedie: 158.088\n",
      "[276]\tvalid_0's tweedie: 158.088\n",
      "[277]\tvalid_0's tweedie: 158.088\n",
      "[278]\tvalid_0's tweedie: 158.088\n",
      "[279]\tvalid_0's tweedie: 158.088\n",
      "[280]\tvalid_0's tweedie: 158.088\n",
      "[281]\tvalid_0's tweedie: 158.088\n",
      "[282]\tvalid_0's tweedie: 158.087\n",
      "[283]\tvalid_0's tweedie: 158.087\n",
      "[284]\tvalid_0's tweedie: 158.087\n",
      "[285]\tvalid_0's tweedie: 158.087\n",
      "[286]\tvalid_0's tweedie: 158.087\n",
      "[287]\tvalid_0's tweedie: 158.088\n",
      "[288]\tvalid_0's tweedie: 158.088\n",
      "[289]\tvalid_0's tweedie: 158.088\n",
      "[290]\tvalid_0's tweedie: 158.087\n",
      "[291]\tvalid_0's tweedie: 158.087\n",
      "[292]\tvalid_0's tweedie: 158.087\n",
      "[293]\tvalid_0's tweedie: 158.087\n",
      "[294]\tvalid_0's tweedie: 158.087\n",
      "[295]\tvalid_0's tweedie: 158.087\n",
      "[296]\tvalid_0's tweedie: 158.087\n",
      "[297]\tvalid_0's tweedie: 158.087\n",
      "[298]\tvalid_0's tweedie: 158.087\n",
      "[299]\tvalid_0's tweedie: 158.087\n",
      "[300]\tvalid_0's tweedie: 158.087\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[298]\tvalid_0's tweedie: 158.087\n",
      "Training model for level 7 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 39207, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.397964\n",
      "[1]\tvalid_0's tweedie: 176.844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.779\n",
      "[3]\tvalid_0's tweedie: 171.179\n",
      "[4]\tvalid_0's tweedie: 168.987\n",
      "[5]\tvalid_0's tweedie: 167.145\n",
      "[6]\tvalid_0's tweedie: 165.604\n",
      "[7]\tvalid_0's tweedie: 164.321\n",
      "[8]\tvalid_0's tweedie: 163.237\n",
      "[9]\tvalid_0's tweedie: 162.368\n",
      "[10]\tvalid_0's tweedie: 161.626\n",
      "[11]\tvalid_0's tweedie: 161.014\n",
      "[12]\tvalid_0's tweedie: 160.524\n",
      "[13]\tvalid_0's tweedie: 160.11\n",
      "[14]\tvalid_0's tweedie: 159.77\n",
      "[15]\tvalid_0's tweedie: 159.504\n",
      "[16]\tvalid_0's tweedie: 159.273\n",
      "[17]\tvalid_0's tweedie: 159.078\n",
      "[18]\tvalid_0's tweedie: 158.92\n",
      "[19]\tvalid_0's tweedie: 158.792\n",
      "[20]\tvalid_0's tweedie: 158.683\n",
      "[21]\tvalid_0's tweedie: 158.586\n",
      "[22]\tvalid_0's tweedie: 158.512\n",
      "[23]\tvalid_0's tweedie: 158.445\n",
      "[24]\tvalid_0's tweedie: 158.391\n",
      "[25]\tvalid_0's tweedie: 158.345\n",
      "[26]\tvalid_0's tweedie: 158.311\n",
      "[27]\tvalid_0's tweedie: 158.28\n",
      "[28]\tvalid_0's tweedie: 158.256\n",
      "[29]\tvalid_0's tweedie: 158.234\n",
      "[30]\tvalid_0's tweedie: 158.218\n",
      "[31]\tvalid_0's tweedie: 158.204\n",
      "[32]\tvalid_0's tweedie: 158.19\n",
      "[33]\tvalid_0's tweedie: 158.182\n",
      "[34]\tvalid_0's tweedie: 158.169\n",
      "[35]\tvalid_0's tweedie: 158.161\n",
      "[36]\tvalid_0's tweedie: 158.153\n",
      "[37]\tvalid_0's tweedie: 158.146\n",
      "[38]\tvalid_0's tweedie: 158.142\n",
      "[39]\tvalid_0's tweedie: 158.136\n",
      "[40]\tvalid_0's tweedie: 158.133\n",
      "[41]\tvalid_0's tweedie: 158.13\n",
      "[42]\tvalid_0's tweedie: 158.13\n",
      "[43]\tvalid_0's tweedie: 158.128\n",
      "[44]\tvalid_0's tweedie: 158.127\n",
      "[45]\tvalid_0's tweedie: 158.126\n",
      "[46]\tvalid_0's tweedie: 158.125\n",
      "[47]\tvalid_0's tweedie: 158.123\n",
      "[48]\tvalid_0's tweedie: 158.122\n",
      "[49]\tvalid_0's tweedie: 158.12\n",
      "[50]\tvalid_0's tweedie: 158.12\n",
      "[51]\tvalid_0's tweedie: 158.117\n",
      "[52]\tvalid_0's tweedie: 158.115\n",
      "[53]\tvalid_0's tweedie: 158.115\n",
      "[54]\tvalid_0's tweedie: 158.112\n",
      "[55]\tvalid_0's tweedie: 158.112\n",
      "[56]\tvalid_0's tweedie: 158.112\n",
      "[57]\tvalid_0's tweedie: 158.111\n",
      "[58]\tvalid_0's tweedie: 158.111\n",
      "[59]\tvalid_0's tweedie: 158.111\n",
      "[60]\tvalid_0's tweedie: 158.11\n",
      "[61]\tvalid_0's tweedie: 158.108\n",
      "[62]\tvalid_0's tweedie: 158.108\n",
      "[63]\tvalid_0's tweedie: 158.105\n",
      "[64]\tvalid_0's tweedie: 158.104\n",
      "[65]\tvalid_0's tweedie: 158.103\n",
      "[66]\tvalid_0's tweedie: 158.102\n",
      "[67]\tvalid_0's tweedie: 158.103\n",
      "[68]\tvalid_0's tweedie: 158.103\n",
      "[69]\tvalid_0's tweedie: 158.102\n",
      "[70]\tvalid_0's tweedie: 158.102\n",
      "[71]\tvalid_0's tweedie: 158.102\n",
      "[72]\tvalid_0's tweedie: 158.102\n",
      "[73]\tvalid_0's tweedie: 158.1\n",
      "[74]\tvalid_0's tweedie: 158.099\n",
      "[75]\tvalid_0's tweedie: 158.099\n",
      "[76]\tvalid_0's tweedie: 158.098\n",
      "[77]\tvalid_0's tweedie: 158.098\n",
      "[78]\tvalid_0's tweedie: 158.098\n",
      "[79]\tvalid_0's tweedie: 158.097\n",
      "[80]\tvalid_0's tweedie: 158.097\n",
      "[81]\tvalid_0's tweedie: 158.097\n",
      "[82]\tvalid_0's tweedie: 158.097\n",
      "[83]\tvalid_0's tweedie: 158.097\n",
      "[84]\tvalid_0's tweedie: 158.097\n",
      "[85]\tvalid_0's tweedie: 158.097\n",
      "[86]\tvalid_0's tweedie: 158.097\n",
      "[87]\tvalid_0's tweedie: 158.097\n",
      "[88]\tvalid_0's tweedie: 158.096\n",
      "[89]\tvalid_0's tweedie: 158.096\n",
      "[90]\tvalid_0's tweedie: 158.096\n",
      "[91]\tvalid_0's tweedie: 158.096\n",
      "[92]\tvalid_0's tweedie: 158.095\n",
      "[93]\tvalid_0's tweedie: 158.095\n",
      "[94]\tvalid_0's tweedie: 158.095\n",
      "[95]\tvalid_0's tweedie: 158.095\n",
      "[96]\tvalid_0's tweedie: 158.095\n",
      "[97]\tvalid_0's tweedie: 158.095\n",
      "[98]\tvalid_0's tweedie: 158.094\n",
      "[99]\tvalid_0's tweedie: 158.094\n",
      "[100]\tvalid_0's tweedie: 158.093\n",
      "[101]\tvalid_0's tweedie: 158.093\n",
      "[102]\tvalid_0's tweedie: 158.093\n",
      "[103]\tvalid_0's tweedie: 158.093\n",
      "[104]\tvalid_0's tweedie: 158.093\n",
      "[105]\tvalid_0's tweedie: 158.093\n",
      "[106]\tvalid_0's tweedie: 158.092\n",
      "[107]\tvalid_0's tweedie: 158.092\n",
      "[108]\tvalid_0's tweedie: 158.092\n",
      "[109]\tvalid_0's tweedie: 158.092\n",
      "[110]\tvalid_0's tweedie: 158.092\n",
      "[111]\tvalid_0's tweedie: 158.092\n",
      "[112]\tvalid_0's tweedie: 158.091\n",
      "[113]\tvalid_0's tweedie: 158.091\n",
      "[114]\tvalid_0's tweedie: 158.091\n",
      "[115]\tvalid_0's tweedie: 158.091\n",
      "[116]\tvalid_0's tweedie: 158.09\n",
      "[117]\tvalid_0's tweedie: 158.09\n",
      "[118]\tvalid_0's tweedie: 158.09\n",
      "[119]\tvalid_0's tweedie: 158.09\n",
      "[120]\tvalid_0's tweedie: 158.09\n",
      "[121]\tvalid_0's tweedie: 158.09\n",
      "[122]\tvalid_0's tweedie: 158.09\n",
      "[123]\tvalid_0's tweedie: 158.09\n",
      "[124]\tvalid_0's tweedie: 158.089\n",
      "[125]\tvalid_0's tweedie: 158.089\n",
      "[126]\tvalid_0's tweedie: 158.089\n",
      "[127]\tvalid_0's tweedie: 158.089\n",
      "[128]\tvalid_0's tweedie: 158.089\n",
      "[129]\tvalid_0's tweedie: 158.089\n",
      "[130]\tvalid_0's tweedie: 158.088\n",
      "[131]\tvalid_0's tweedie: 158.088\n",
      "[132]\tvalid_0's tweedie: 158.088\n",
      "[133]\tvalid_0's tweedie: 158.088\n",
      "[134]\tvalid_0's tweedie: 158.088\n",
      "[135]\tvalid_0's tweedie: 158.088\n",
      "[136]\tvalid_0's tweedie: 158.088\n",
      "[137]\tvalid_0's tweedie: 158.088\n",
      "[138]\tvalid_0's tweedie: 158.087\n",
      "[139]\tvalid_0's tweedie: 158.087\n",
      "[140]\tvalid_0's tweedie: 158.087\n",
      "[141]\tvalid_0's tweedie: 158.087\n",
      "[142]\tvalid_0's tweedie: 158.087\n",
      "[143]\tvalid_0's tweedie: 158.086\n",
      "[144]\tvalid_0's tweedie: 158.086\n",
      "[145]\tvalid_0's tweedie: 158.086\n",
      "[146]\tvalid_0's tweedie: 158.086\n",
      "[147]\tvalid_0's tweedie: 158.086\n",
      "[148]\tvalid_0's tweedie: 158.086\n",
      "[149]\tvalid_0's tweedie: 158.086\n",
      "[150]\tvalid_0's tweedie: 158.086\n",
      "[151]\tvalid_0's tweedie: 158.086\n",
      "[152]\tvalid_0's tweedie: 158.086\n",
      "[153]\tvalid_0's tweedie: 158.086\n",
      "[154]\tvalid_0's tweedie: 158.086\n",
      "[155]\tvalid_0's tweedie: 158.086\n",
      "[156]\tvalid_0's tweedie: 158.086\n",
      "[157]\tvalid_0's tweedie: 158.085\n",
      "[158]\tvalid_0's tweedie: 158.086\n",
      "[159]\tvalid_0's tweedie: 158.085\n",
      "[160]\tvalid_0's tweedie: 158.085\n",
      "[161]\tvalid_0's tweedie: 158.085\n",
      "[162]\tvalid_0's tweedie: 158.085\n",
      "[163]\tvalid_0's tweedie: 158.085\n",
      "[164]\tvalid_0's tweedie: 158.085\n",
      "[165]\tvalid_0's tweedie: 158.085\n",
      "[166]\tvalid_0's tweedie: 158.084\n",
      "[167]\tvalid_0's tweedie: 158.084\n",
      "[168]\tvalid_0's tweedie: 158.084\n",
      "[169]\tvalid_0's tweedie: 158.084\n",
      "[170]\tvalid_0's tweedie: 158.084\n",
      "[171]\tvalid_0's tweedie: 158.084\n",
      "[172]\tvalid_0's tweedie: 158.084\n",
      "[173]\tvalid_0's tweedie: 158.084\n",
      "[174]\tvalid_0's tweedie: 158.084\n",
      "[175]\tvalid_0's tweedie: 158.084\n",
      "[176]\tvalid_0's tweedie: 158.084\n",
      "[177]\tvalid_0's tweedie: 158.083\n",
      "[178]\tvalid_0's tweedie: 158.083\n",
      "[179]\tvalid_0's tweedie: 158.083\n",
      "[180]\tvalid_0's tweedie: 158.083\n",
      "[181]\tvalid_0's tweedie: 158.083\n",
      "[182]\tvalid_0's tweedie: 158.083\n",
      "[183]\tvalid_0's tweedie: 158.083\n",
      "[184]\tvalid_0's tweedie: 158.083\n",
      "[185]\tvalid_0's tweedie: 158.083\n",
      "[186]\tvalid_0's tweedie: 158.083\n",
      "[187]\tvalid_0's tweedie: 158.083\n",
      "[188]\tvalid_0's tweedie: 158.083\n",
      "[189]\tvalid_0's tweedie: 158.083\n",
      "[190]\tvalid_0's tweedie: 158.083\n",
      "[191]\tvalid_0's tweedie: 158.083\n",
      "[192]\tvalid_0's tweedie: 158.083\n",
      "[193]\tvalid_0's tweedie: 158.083\n",
      "[194]\tvalid_0's tweedie: 158.083\n",
      "[195]\tvalid_0's tweedie: 158.083\n",
      "[196]\tvalid_0's tweedie: 158.083\n",
      "[197]\tvalid_0's tweedie: 158.083\n",
      "[198]\tvalid_0's tweedie: 158.083\n",
      "[199]\tvalid_0's tweedie: 158.082\n",
      "[200]\tvalid_0's tweedie: 158.082\n",
      "[201]\tvalid_0's tweedie: 158.082\n",
      "[202]\tvalid_0's tweedie: 158.083\n",
      "[203]\tvalid_0's tweedie: 158.082\n",
      "[204]\tvalid_0's tweedie: 158.083\n",
      "[205]\tvalid_0's tweedie: 158.082\n",
      "[206]\tvalid_0's tweedie: 158.082\n",
      "[207]\tvalid_0's tweedie: 158.083\n",
      "[208]\tvalid_0's tweedie: 158.083\n",
      "[209]\tvalid_0's tweedie: 158.081\n",
      "[210]\tvalid_0's tweedie: 158.081\n",
      "[211]\tvalid_0's tweedie: 158.081\n",
      "[212]\tvalid_0's tweedie: 158.081\n",
      "[213]\tvalid_0's tweedie: 158.081\n",
      "[214]\tvalid_0's tweedie: 158.081\n",
      "[215]\tvalid_0's tweedie: 158.081\n",
      "[216]\tvalid_0's tweedie: 158.081\n",
      "[217]\tvalid_0's tweedie: 158.08\n",
      "[218]\tvalid_0's tweedie: 158.08\n",
      "[219]\tvalid_0's tweedie: 158.08\n",
      "[220]\tvalid_0's tweedie: 158.08\n",
      "[221]\tvalid_0's tweedie: 158.08\n",
      "[222]\tvalid_0's tweedie: 158.08\n",
      "[223]\tvalid_0's tweedie: 158.08\n",
      "[224]\tvalid_0's tweedie: 158.08\n",
      "[225]\tvalid_0's tweedie: 158.08\n",
      "[226]\tvalid_0's tweedie: 158.08\n",
      "[227]\tvalid_0's tweedie: 158.08\n",
      "[228]\tvalid_0's tweedie: 158.08\n",
      "[229]\tvalid_0's tweedie: 158.08\n",
      "[230]\tvalid_0's tweedie: 158.08\n",
      "[231]\tvalid_0's tweedie: 158.079\n",
      "[232]\tvalid_0's tweedie: 158.08\n",
      "[233]\tvalid_0's tweedie: 158.079\n",
      "[234]\tvalid_0's tweedie: 158.079\n",
      "[235]\tvalid_0's tweedie: 158.079\n",
      "[236]\tvalid_0's tweedie: 158.079\n",
      "[237]\tvalid_0's tweedie: 158.079\n",
      "[238]\tvalid_0's tweedie: 158.079\n",
      "[239]\tvalid_0's tweedie: 158.079\n",
      "[240]\tvalid_0's tweedie: 158.079\n",
      "[241]\tvalid_0's tweedie: 158.079\n",
      "[242]\tvalid_0's tweedie: 158.079\n",
      "[243]\tvalid_0's tweedie: 158.079\n",
      "[244]\tvalid_0's tweedie: 158.079\n",
      "[245]\tvalid_0's tweedie: 158.08\n",
      "[246]\tvalid_0's tweedie: 158.08\n",
      "[247]\tvalid_0's tweedie: 158.079\n",
      "[248]\tvalid_0's tweedie: 158.079\n",
      "[249]\tvalid_0's tweedie: 158.079\n",
      "[250]\tvalid_0's tweedie: 158.079\n",
      "[251]\tvalid_0's tweedie: 158.079\n",
      "[252]\tvalid_0's tweedie: 158.079\n",
      "[253]\tvalid_0's tweedie: 158.079\n",
      "[254]\tvalid_0's tweedie: 158.079\n",
      "[255]\tvalid_0's tweedie: 158.079\n",
      "[256]\tvalid_0's tweedie: 158.078\n",
      "[257]\tvalid_0's tweedie: 158.078\n",
      "[258]\tvalid_0's tweedie: 158.078\n",
      "[259]\tvalid_0's tweedie: 158.078\n",
      "[260]\tvalid_0's tweedie: 158.078\n",
      "[261]\tvalid_0's tweedie: 158.078\n",
      "[262]\tvalid_0's tweedie: 158.078\n",
      "[263]\tvalid_0's tweedie: 158.079\n",
      "[264]\tvalid_0's tweedie: 158.079\n",
      "[265]\tvalid_0's tweedie: 158.079\n",
      "[266]\tvalid_0's tweedie: 158.079\n",
      "[267]\tvalid_0's tweedie: 158.079\n",
      "[268]\tvalid_0's tweedie: 158.079\n",
      "[269]\tvalid_0's tweedie: 158.079\n",
      "[270]\tvalid_0's tweedie: 158.079\n",
      "[271]\tvalid_0's tweedie: 158.079\n",
      "[272]\tvalid_0's tweedie: 158.078\n",
      "[273]\tvalid_0's tweedie: 158.078\n",
      "[274]\tvalid_0's tweedie: 158.078\n",
      "[275]\tvalid_0's tweedie: 158.078\n",
      "[276]\tvalid_0's tweedie: 158.078\n",
      "[277]\tvalid_0's tweedie: 158.078\n",
      "[278]\tvalid_0's tweedie: 158.078\n",
      "[279]\tvalid_0's tweedie: 158.078\n",
      "[280]\tvalid_0's tweedie: 158.078\n",
      "[281]\tvalid_0's tweedie: 158.078\n",
      "[282]\tvalid_0's tweedie: 158.078\n",
      "[283]\tvalid_0's tweedie: 158.078\n",
      "[284]\tvalid_0's tweedie: 158.077\n",
      "[285]\tvalid_0's tweedie: 158.077\n",
      "[286]\tvalid_0's tweedie: 158.077\n",
      "[287]\tvalid_0's tweedie: 158.077\n",
      "[288]\tvalid_0's tweedie: 158.077\n",
      "[289]\tvalid_0's tweedie: 158.077\n",
      "[290]\tvalid_0's tweedie: 158.078\n",
      "[291]\tvalid_0's tweedie: 158.078\n",
      "[292]\tvalid_0's tweedie: 158.078\n",
      "[293]\tvalid_0's tweedie: 158.078\n",
      "[294]\tvalid_0's tweedie: 158.078\n",
      "[295]\tvalid_0's tweedie: 158.078\n",
      "[296]\tvalid_0's tweedie: 158.078\n",
      "[297]\tvalid_0's tweedie: 158.078\n",
      "[298]\tvalid_0's tweedie: 158.078\n",
      "[299]\tvalid_0's tweedie: 158.078\n",
      "[300]\tvalid_0's tweedie: 158.078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[285]\tvalid_0's tweedie: 158.077\n",
      "Training model for level 7 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5512\n",
      "[LightGBM] [Info] Number of data points in the train set: 39186, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398165\n",
      "[1]\tvalid_0's tweedie: 176.847\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.78\n",
      "[3]\tvalid_0's tweedie: 171.19\n",
      "[4]\tvalid_0's tweedie: 168.993\n",
      "[5]\tvalid_0's tweedie: 167.14\n",
      "[6]\tvalid_0's tweedie: 165.598\n",
      "[7]\tvalid_0's tweedie: 164.304\n",
      "[8]\tvalid_0's tweedie: 163.236\n",
      "[9]\tvalid_0's tweedie: 162.349\n",
      "[10]\tvalid_0's tweedie: 161.612\n",
      "[11]\tvalid_0's tweedie: 161.022\n",
      "[12]\tvalid_0's tweedie: 160.522\n",
      "[13]\tvalid_0's tweedie: 160.107\n",
      "[14]\tvalid_0's tweedie: 159.768\n",
      "[15]\tvalid_0's tweedie: 159.485\n",
      "[16]\tvalid_0's tweedie: 159.265\n",
      "[17]\tvalid_0's tweedie: 159.071\n",
      "[18]\tvalid_0's tweedie: 158.915\n",
      "[19]\tvalid_0's tweedie: 158.785\n",
      "[20]\tvalid_0's tweedie: 158.675\n",
      "[21]\tvalid_0's tweedie: 158.581\n",
      "[22]\tvalid_0's tweedie: 158.508\n",
      "[23]\tvalid_0's tweedie: 158.45\n",
      "[24]\tvalid_0's tweedie: 158.392\n",
      "[25]\tvalid_0's tweedie: 158.347\n",
      "[26]\tvalid_0's tweedie: 158.314\n",
      "[27]\tvalid_0's tweedie: 158.282\n",
      "[28]\tvalid_0's tweedie: 158.255\n",
      "[29]\tvalid_0's tweedie: 158.235\n",
      "[30]\tvalid_0's tweedie: 158.218\n",
      "[31]\tvalid_0's tweedie: 158.201\n",
      "[32]\tvalid_0's tweedie: 158.187\n",
      "[33]\tvalid_0's tweedie: 158.179\n",
      "[34]\tvalid_0's tweedie: 158.169\n",
      "[35]\tvalid_0's tweedie: 158.16\n",
      "[36]\tvalid_0's tweedie: 158.152\n",
      "[37]\tvalid_0's tweedie: 158.144\n",
      "[38]\tvalid_0's tweedie: 158.141\n",
      "[39]\tvalid_0's tweedie: 158.138\n",
      "[40]\tvalid_0's tweedie: 158.135\n",
      "[41]\tvalid_0's tweedie: 158.134\n",
      "[42]\tvalid_0's tweedie: 158.13\n",
      "[43]\tvalid_0's tweedie: 158.128\n",
      "[44]\tvalid_0's tweedie: 158.126\n",
      "[45]\tvalid_0's tweedie: 158.124\n",
      "[46]\tvalid_0's tweedie: 158.124\n",
      "[47]\tvalid_0's tweedie: 158.121\n",
      "[48]\tvalid_0's tweedie: 158.12\n",
      "[49]\tvalid_0's tweedie: 158.12\n",
      "[50]\tvalid_0's tweedie: 158.119\n",
      "[51]\tvalid_0's tweedie: 158.119\n",
      "[52]\tvalid_0's tweedie: 158.118\n",
      "[53]\tvalid_0's tweedie: 158.118\n",
      "[54]\tvalid_0's tweedie: 158.118\n",
      "[55]\tvalid_0's tweedie: 158.117\n",
      "[56]\tvalid_0's tweedie: 158.115\n",
      "[57]\tvalid_0's tweedie: 158.111\n",
      "[58]\tvalid_0's tweedie: 158.111\n",
      "[59]\tvalid_0's tweedie: 158.111\n",
      "[60]\tvalid_0's tweedie: 158.111\n",
      "[61]\tvalid_0's tweedie: 158.111\n",
      "[62]\tvalid_0's tweedie: 158.108\n",
      "[63]\tvalid_0's tweedie: 158.109\n",
      "[64]\tvalid_0's tweedie: 158.108\n",
      "[65]\tvalid_0's tweedie: 158.108\n",
      "[66]\tvalid_0's tweedie: 158.107\n",
      "[67]\tvalid_0's tweedie: 158.105\n",
      "[68]\tvalid_0's tweedie: 158.103\n",
      "[69]\tvalid_0's tweedie: 158.102\n",
      "[70]\tvalid_0's tweedie: 158.101\n",
      "[71]\tvalid_0's tweedie: 158.101\n",
      "[72]\tvalid_0's tweedie: 158.101\n",
      "[73]\tvalid_0's tweedie: 158.101\n",
      "[74]\tvalid_0's tweedie: 158.1\n",
      "[75]\tvalid_0's tweedie: 158.099\n",
      "[76]\tvalid_0's tweedie: 158.097\n",
      "[77]\tvalid_0's tweedie: 158.097\n",
      "[78]\tvalid_0's tweedie: 158.097\n",
      "[79]\tvalid_0's tweedie: 158.097\n",
      "[80]\tvalid_0's tweedie: 158.096\n",
      "[81]\tvalid_0's tweedie: 158.095\n",
      "[82]\tvalid_0's tweedie: 158.095\n",
      "[83]\tvalid_0's tweedie: 158.093\n",
      "[84]\tvalid_0's tweedie: 158.093\n",
      "[85]\tvalid_0's tweedie: 158.092\n",
      "[86]\tvalid_0's tweedie: 158.092\n",
      "[87]\tvalid_0's tweedie: 158.092\n",
      "[88]\tvalid_0's tweedie: 158.092\n",
      "[89]\tvalid_0's tweedie: 158.092\n",
      "[90]\tvalid_0's tweedie: 158.092\n",
      "[91]\tvalid_0's tweedie: 158.092\n",
      "[92]\tvalid_0's tweedie: 158.091\n",
      "[93]\tvalid_0's tweedie: 158.091\n",
      "[94]\tvalid_0's tweedie: 158.091\n",
      "[95]\tvalid_0's tweedie: 158.089\n",
      "[96]\tvalid_0's tweedie: 158.09\n",
      "[97]\tvalid_0's tweedie: 158.089\n",
      "[98]\tvalid_0's tweedie: 158.089\n",
      "[99]\tvalid_0's tweedie: 158.089\n",
      "[100]\tvalid_0's tweedie: 158.089\n",
      "[101]\tvalid_0's tweedie: 158.089\n",
      "[102]\tvalid_0's tweedie: 158.089\n",
      "[103]\tvalid_0's tweedie: 158.089\n",
      "[104]\tvalid_0's tweedie: 158.089\n",
      "[105]\tvalid_0's tweedie: 158.088\n",
      "[106]\tvalid_0's tweedie: 158.088\n",
      "[107]\tvalid_0's tweedie: 158.088\n",
      "[108]\tvalid_0's tweedie: 158.087\n",
      "[109]\tvalid_0's tweedie: 158.087\n",
      "[110]\tvalid_0's tweedie: 158.086\n",
      "[111]\tvalid_0's tweedie: 158.086\n",
      "[112]\tvalid_0's tweedie: 158.086\n",
      "[113]\tvalid_0's tweedie: 158.086\n",
      "[114]\tvalid_0's tweedie: 158.085\n",
      "[115]\tvalid_0's tweedie: 158.085\n",
      "[116]\tvalid_0's tweedie: 158.085\n",
      "[117]\tvalid_0's tweedie: 158.085\n",
      "[118]\tvalid_0's tweedie: 158.085\n",
      "[119]\tvalid_0's tweedie: 158.085\n",
      "[120]\tvalid_0's tweedie: 158.085\n",
      "[121]\tvalid_0's tweedie: 158.085\n",
      "[122]\tvalid_0's tweedie: 158.085\n",
      "[123]\tvalid_0's tweedie: 158.084\n",
      "[124]\tvalid_0's tweedie: 158.084\n",
      "[125]\tvalid_0's tweedie: 158.084\n",
      "[126]\tvalid_0's tweedie: 158.084\n",
      "[127]\tvalid_0's tweedie: 158.084\n",
      "[128]\tvalid_0's tweedie: 158.084\n",
      "[129]\tvalid_0's tweedie: 158.084\n",
      "[130]\tvalid_0's tweedie: 158.084\n",
      "[131]\tvalid_0's tweedie: 158.084\n",
      "[132]\tvalid_0's tweedie: 158.084\n",
      "[133]\tvalid_0's tweedie: 158.084\n",
      "[134]\tvalid_0's tweedie: 158.084\n",
      "[135]\tvalid_0's tweedie: 158.083\n",
      "[136]\tvalid_0's tweedie: 158.083\n",
      "[137]\tvalid_0's tweedie: 158.083\n",
      "[138]\tvalid_0's tweedie: 158.083\n",
      "[139]\tvalid_0's tweedie: 158.083\n",
      "[140]\tvalid_0's tweedie: 158.083\n",
      "[141]\tvalid_0's tweedie: 158.083\n",
      "[142]\tvalid_0's tweedie: 158.083\n",
      "[143]\tvalid_0's tweedie: 158.083\n",
      "[144]\tvalid_0's tweedie: 158.083\n",
      "[145]\tvalid_0's tweedie: 158.083\n",
      "[146]\tvalid_0's tweedie: 158.083\n",
      "[147]\tvalid_0's tweedie: 158.083\n",
      "[148]\tvalid_0's tweedie: 158.083\n",
      "[149]\tvalid_0's tweedie: 158.083\n",
      "[150]\tvalid_0's tweedie: 158.083\n",
      "[151]\tvalid_0's tweedie: 158.083\n",
      "[152]\tvalid_0's tweedie: 158.083\n",
      "[153]\tvalid_0's tweedie: 158.083\n",
      "[154]\tvalid_0's tweedie: 158.083\n",
      "[155]\tvalid_0's tweedie: 158.083\n",
      "[156]\tvalid_0's tweedie: 158.083\n",
      "[157]\tvalid_0's tweedie: 158.082\n",
      "[158]\tvalid_0's tweedie: 158.082\n",
      "[159]\tvalid_0's tweedie: 158.082\n",
      "[160]\tvalid_0's tweedie: 158.082\n",
      "[161]\tvalid_0's tweedie: 158.082\n",
      "[162]\tvalid_0's tweedie: 158.082\n",
      "[163]\tvalid_0's tweedie: 158.082\n",
      "[164]\tvalid_0's tweedie: 158.082\n",
      "[165]\tvalid_0's tweedie: 158.082\n",
      "[166]\tvalid_0's tweedie: 158.082\n",
      "[167]\tvalid_0's tweedie: 158.082\n",
      "[168]\tvalid_0's tweedie: 158.082\n",
      "[169]\tvalid_0's tweedie: 158.082\n",
      "[170]\tvalid_0's tweedie: 158.082\n",
      "[171]\tvalid_0's tweedie: 158.082\n",
      "[172]\tvalid_0's tweedie: 158.082\n",
      "[173]\tvalid_0's tweedie: 158.082\n",
      "[174]\tvalid_0's tweedie: 158.082\n",
      "[175]\tvalid_0's tweedie: 158.082\n",
      "[176]\tvalid_0's tweedie: 158.082\n",
      "[177]\tvalid_0's tweedie: 158.082\n",
      "[178]\tvalid_0's tweedie: 158.082\n",
      "[179]\tvalid_0's tweedie: 158.082\n",
      "[180]\tvalid_0's tweedie: 158.082\n",
      "[181]\tvalid_0's tweedie: 158.082\n",
      "[182]\tvalid_0's tweedie: 158.083\n",
      "[183]\tvalid_0's tweedie: 158.083\n",
      "[184]\tvalid_0's tweedie: 158.083\n",
      "[185]\tvalid_0's tweedie: 158.083\n",
      "[186]\tvalid_0's tweedie: 158.082\n",
      "[187]\tvalid_0's tweedie: 158.082\n",
      "[188]\tvalid_0's tweedie: 158.082\n",
      "[189]\tvalid_0's tweedie: 158.082\n",
      "[190]\tvalid_0's tweedie: 158.083\n",
      "[191]\tvalid_0's tweedie: 158.082\n",
      "[192]\tvalid_0's tweedie: 158.083\n",
      "[193]\tvalid_0's tweedie: 158.082\n",
      "[194]\tvalid_0's tweedie: 158.082\n",
      "[195]\tvalid_0's tweedie: 158.082\n",
      "[196]\tvalid_0's tweedie: 158.082\n",
      "[197]\tvalid_0's tweedie: 158.082\n",
      "[198]\tvalid_0's tweedie: 158.082\n",
      "[199]\tvalid_0's tweedie: 158.082\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's tweedie: 158.082\n",
      "Training model for level 7 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5511\n",
      "[LightGBM] [Info] Number of data points in the train set: 39165, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398383\n",
      "[1]\tvalid_0's tweedie: 176.845\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.776\n",
      "[3]\tvalid_0's tweedie: 171.184\n",
      "[4]\tvalid_0's tweedie: 168.99\n",
      "[5]\tvalid_0's tweedie: 167.144\n",
      "[6]\tvalid_0's tweedie: 165.6\n",
      "[7]\tvalid_0's tweedie: 164.305\n",
      "[8]\tvalid_0's tweedie: 163.223\n",
      "[9]\tvalid_0's tweedie: 162.36\n",
      "[10]\tvalid_0's tweedie: 161.624\n",
      "[11]\tvalid_0's tweedie: 161.009\n",
      "[12]\tvalid_0's tweedie: 160.511\n",
      "[13]\tvalid_0's tweedie: 160.091\n",
      "[14]\tvalid_0's tweedie: 159.75\n",
      "[15]\tvalid_0's tweedie: 159.466\n",
      "[16]\tvalid_0's tweedie: 159.238\n",
      "[17]\tvalid_0's tweedie: 159.042\n",
      "[18]\tvalid_0's tweedie: 158.881\n",
      "[19]\tvalid_0's tweedie: 158.753\n",
      "[20]\tvalid_0's tweedie: 158.652\n",
      "[21]\tvalid_0's tweedie: 158.564\n",
      "[22]\tvalid_0's tweedie: 158.491\n",
      "[23]\tvalid_0's tweedie: 158.428\n",
      "[24]\tvalid_0's tweedie: 158.378\n",
      "[25]\tvalid_0's tweedie: 158.333\n",
      "[26]\tvalid_0's tweedie: 158.293\n",
      "[27]\tvalid_0's tweedie: 158.262\n",
      "[28]\tvalid_0's tweedie: 158.237\n",
      "[29]\tvalid_0's tweedie: 158.216\n",
      "[30]\tvalid_0's tweedie: 158.198\n",
      "[31]\tvalid_0's tweedie: 158.183\n",
      "[32]\tvalid_0's tweedie: 158.169\n",
      "[33]\tvalid_0's tweedie: 158.158\n",
      "[34]\tvalid_0's tweedie: 158.151\n",
      "[35]\tvalid_0's tweedie: 158.146\n",
      "[36]\tvalid_0's tweedie: 158.14\n",
      "[37]\tvalid_0's tweedie: 158.136\n",
      "[38]\tvalid_0's tweedie: 158.134\n",
      "[39]\tvalid_0's tweedie: 158.129\n",
      "[40]\tvalid_0's tweedie: 158.126\n",
      "[41]\tvalid_0's tweedie: 158.125\n",
      "[42]\tvalid_0's tweedie: 158.121\n",
      "[43]\tvalid_0's tweedie: 158.119\n",
      "[44]\tvalid_0's tweedie: 158.117\n",
      "[45]\tvalid_0's tweedie: 158.115\n",
      "[46]\tvalid_0's tweedie: 158.115\n",
      "[47]\tvalid_0's tweedie: 158.114\n",
      "[48]\tvalid_0's tweedie: 158.113\n",
      "[49]\tvalid_0's tweedie: 158.11\n",
      "[50]\tvalid_0's tweedie: 158.109\n",
      "[51]\tvalid_0's tweedie: 158.109\n",
      "[52]\tvalid_0's tweedie: 158.108\n",
      "[53]\tvalid_0's tweedie: 158.105\n",
      "[54]\tvalid_0's tweedie: 158.105\n",
      "[55]\tvalid_0's tweedie: 158.105\n",
      "[56]\tvalid_0's tweedie: 158.105\n",
      "[57]\tvalid_0's tweedie: 158.105\n",
      "[58]\tvalid_0's tweedie: 158.105\n",
      "[59]\tvalid_0's tweedie: 158.105\n",
      "[60]\tvalid_0's tweedie: 158.105\n",
      "[61]\tvalid_0's tweedie: 158.105\n",
      "[62]\tvalid_0's tweedie: 158.103\n",
      "[63]\tvalid_0's tweedie: 158.103\n",
      "[64]\tvalid_0's tweedie: 158.102\n",
      "[65]\tvalid_0's tweedie: 158.102\n",
      "[66]\tvalid_0's tweedie: 158.102\n",
      "[67]\tvalid_0's tweedie: 158.102\n",
      "[68]\tvalid_0's tweedie: 158.102\n",
      "[69]\tvalid_0's tweedie: 158.102\n",
      "[70]\tvalid_0's tweedie: 158.102\n",
      "[71]\tvalid_0's tweedie: 158.1\n",
      "[72]\tvalid_0's tweedie: 158.1\n",
      "[73]\tvalid_0's tweedie: 158.099\n",
      "[74]\tvalid_0's tweedie: 158.099\n",
      "[75]\tvalid_0's tweedie: 158.099\n",
      "[76]\tvalid_0's tweedie: 158.098\n",
      "[77]\tvalid_0's tweedie: 158.098\n",
      "[78]\tvalid_0's tweedie: 158.098\n",
      "[79]\tvalid_0's tweedie: 158.098\n",
      "[80]\tvalid_0's tweedie: 158.097\n",
      "[81]\tvalid_0's tweedie: 158.096\n",
      "[82]\tvalid_0's tweedie: 158.096\n",
      "[83]\tvalid_0's tweedie: 158.096\n",
      "[84]\tvalid_0's tweedie: 158.096\n",
      "[85]\tvalid_0's tweedie: 158.096\n",
      "[86]\tvalid_0's tweedie: 158.096\n",
      "[87]\tvalid_0's tweedie: 158.096\n",
      "[88]\tvalid_0's tweedie: 158.096\n",
      "[89]\tvalid_0's tweedie: 158.096\n",
      "[90]\tvalid_0's tweedie: 158.096\n",
      "[91]\tvalid_0's tweedie: 158.096\n",
      "[92]\tvalid_0's tweedie: 158.096\n",
      "[93]\tvalid_0's tweedie: 158.096\n",
      "[94]\tvalid_0's tweedie: 158.096\n",
      "[95]\tvalid_0's tweedie: 158.093\n",
      "[96]\tvalid_0's tweedie: 158.092\n",
      "[97]\tvalid_0's tweedie: 158.092\n",
      "[98]\tvalid_0's tweedie: 158.092\n",
      "[99]\tvalid_0's tweedie: 158.092\n",
      "[100]\tvalid_0's tweedie: 158.092\n",
      "[101]\tvalid_0's tweedie: 158.092\n",
      "[102]\tvalid_0's tweedie: 158.092\n",
      "[103]\tvalid_0's tweedie: 158.091\n",
      "[104]\tvalid_0's tweedie: 158.089\n",
      "[105]\tvalid_0's tweedie: 158.088\n",
      "[106]\tvalid_0's tweedie: 158.088\n",
      "[107]\tvalid_0's tweedie: 158.088\n",
      "[108]\tvalid_0's tweedie: 158.088\n",
      "[109]\tvalid_0's tweedie: 158.088\n",
      "[110]\tvalid_0's tweedie: 158.088\n",
      "[111]\tvalid_0's tweedie: 158.088\n",
      "[112]\tvalid_0's tweedie: 158.088\n",
      "[113]\tvalid_0's tweedie: 158.087\n",
      "[114]\tvalid_0's tweedie: 158.087\n",
      "[115]\tvalid_0's tweedie: 158.087\n",
      "[116]\tvalid_0's tweedie: 158.087\n",
      "[117]\tvalid_0's tweedie: 158.087\n",
      "[118]\tvalid_0's tweedie: 158.088\n",
      "[119]\tvalid_0's tweedie: 158.088\n",
      "[120]\tvalid_0's tweedie: 158.088\n",
      "[121]\tvalid_0's tweedie: 158.088\n",
      "[122]\tvalid_0's tweedie: 158.088\n",
      "[123]\tvalid_0's tweedie: 158.088\n",
      "[124]\tvalid_0's tweedie: 158.087\n",
      "[125]\tvalid_0's tweedie: 158.086\n",
      "[126]\tvalid_0's tweedie: 158.086\n",
      "[127]\tvalid_0's tweedie: 158.086\n",
      "[128]\tvalid_0's tweedie: 158.086\n",
      "[129]\tvalid_0's tweedie: 158.086\n",
      "[130]\tvalid_0's tweedie: 158.086\n",
      "[131]\tvalid_0's tweedie: 158.086\n",
      "[132]\tvalid_0's tweedie: 158.086\n",
      "[133]\tvalid_0's tweedie: 158.085\n",
      "[134]\tvalid_0's tweedie: 158.085\n",
      "[135]\tvalid_0's tweedie: 158.086\n",
      "[136]\tvalid_0's tweedie: 158.086\n",
      "[137]\tvalid_0's tweedie: 158.086\n",
      "[138]\tvalid_0's tweedie: 158.086\n",
      "[139]\tvalid_0's tweedie: 158.085\n",
      "[140]\tvalid_0's tweedie: 158.084\n",
      "[141]\tvalid_0's tweedie: 158.084\n",
      "[142]\tvalid_0's tweedie: 158.084\n",
      "[143]\tvalid_0's tweedie: 158.084\n",
      "[144]\tvalid_0's tweedie: 158.084\n",
      "[145]\tvalid_0's tweedie: 158.084\n",
      "[146]\tvalid_0's tweedie: 158.084\n",
      "[147]\tvalid_0's tweedie: 158.084\n",
      "[148]\tvalid_0's tweedie: 158.084\n",
      "[149]\tvalid_0's tweedie: 158.083\n",
      "[150]\tvalid_0's tweedie: 158.083\n",
      "[151]\tvalid_0's tweedie: 158.083\n",
      "[152]\tvalid_0's tweedie: 158.083\n",
      "[153]\tvalid_0's tweedie: 158.082\n",
      "[154]\tvalid_0's tweedie: 158.082\n",
      "[155]\tvalid_0's tweedie: 158.082\n",
      "[156]\tvalid_0's tweedie: 158.082\n",
      "[157]\tvalid_0's tweedie: 158.082\n",
      "[158]\tvalid_0's tweedie: 158.082\n",
      "[159]\tvalid_0's tweedie: 158.082\n",
      "[160]\tvalid_0's tweedie: 158.082\n",
      "[161]\tvalid_0's tweedie: 158.082\n",
      "[162]\tvalid_0's tweedie: 158.082\n",
      "[163]\tvalid_0's tweedie: 158.082\n",
      "[164]\tvalid_0's tweedie: 158.082\n",
      "[165]\tvalid_0's tweedie: 158.082\n",
      "[166]\tvalid_0's tweedie: 158.082\n",
      "[167]\tvalid_0's tweedie: 158.082\n",
      "[168]\tvalid_0's tweedie: 158.082\n",
      "[169]\tvalid_0's tweedie: 158.082\n",
      "[170]\tvalid_0's tweedie: 158.082\n",
      "[171]\tvalid_0's tweedie: 158.082\n",
      "[172]\tvalid_0's tweedie: 158.082\n",
      "[173]\tvalid_0's tweedie: 158.082\n",
      "[174]\tvalid_0's tweedie: 158.082\n",
      "[175]\tvalid_0's tweedie: 158.082\n",
      "[176]\tvalid_0's tweedie: 158.082\n",
      "[177]\tvalid_0's tweedie: 158.082\n",
      "[178]\tvalid_0's tweedie: 158.081\n",
      "[179]\tvalid_0's tweedie: 158.081\n",
      "[180]\tvalid_0's tweedie: 158.081\n",
      "[181]\tvalid_0's tweedie: 158.081\n",
      "[182]\tvalid_0's tweedie: 158.081\n",
      "[183]\tvalid_0's tweedie: 158.081\n",
      "[184]\tvalid_0's tweedie: 158.081\n",
      "[185]\tvalid_0's tweedie: 158.081\n",
      "[186]\tvalid_0's tweedie: 158.081\n",
      "[187]\tvalid_0's tweedie: 158.081\n",
      "[188]\tvalid_0's tweedie: 158.081\n",
      "[189]\tvalid_0's tweedie: 158.081\n",
      "[190]\tvalid_0's tweedie: 158.081\n",
      "[191]\tvalid_0's tweedie: 158.081\n",
      "[192]\tvalid_0's tweedie: 158.081\n",
      "[193]\tvalid_0's tweedie: 158.081\n",
      "[194]\tvalid_0's tweedie: 158.081\n",
      "[195]\tvalid_0's tweedie: 158.081\n",
      "[196]\tvalid_0's tweedie: 158.081\n",
      "[197]\tvalid_0's tweedie: 158.081\n",
      "[198]\tvalid_0's tweedie: 158.081\n",
      "[199]\tvalid_0's tweedie: 158.081\n",
      "[200]\tvalid_0's tweedie: 158.081\n",
      "[201]\tvalid_0's tweedie: 158.08\n",
      "[202]\tvalid_0's tweedie: 158.08\n",
      "[203]\tvalid_0's tweedie: 158.08\n",
      "[204]\tvalid_0's tweedie: 158.08\n",
      "[205]\tvalid_0's tweedie: 158.08\n",
      "[206]\tvalid_0's tweedie: 158.08\n",
      "[207]\tvalid_0's tweedie: 158.08\n",
      "[208]\tvalid_0's tweedie: 158.08\n",
      "[209]\tvalid_0's tweedie: 158.08\n",
      "[210]\tvalid_0's tweedie: 158.079\n",
      "[211]\tvalid_0's tweedie: 158.079\n",
      "[212]\tvalid_0's tweedie: 158.079\n",
      "[213]\tvalid_0's tweedie: 158.079\n",
      "[214]\tvalid_0's tweedie: 158.079\n",
      "[215]\tvalid_0's tweedie: 158.079\n",
      "[216]\tvalid_0's tweedie: 158.079\n",
      "[217]\tvalid_0's tweedie: 158.079\n",
      "[218]\tvalid_0's tweedie: 158.079\n",
      "[219]\tvalid_0's tweedie: 158.079\n",
      "[220]\tvalid_0's tweedie: 158.079\n",
      "[221]\tvalid_0's tweedie: 158.078\n",
      "[222]\tvalid_0's tweedie: 158.078\n",
      "[223]\tvalid_0's tweedie: 158.078\n",
      "[224]\tvalid_0's tweedie: 158.078\n",
      "[225]\tvalid_0's tweedie: 158.078\n",
      "[226]\tvalid_0's tweedie: 158.078\n",
      "[227]\tvalid_0's tweedie: 158.078\n",
      "[228]\tvalid_0's tweedie: 158.078\n",
      "[229]\tvalid_0's tweedie: 158.078\n",
      "[230]\tvalid_0's tweedie: 158.077\n",
      "[231]\tvalid_0's tweedie: 158.077\n",
      "[232]\tvalid_0's tweedie: 158.077\n",
      "[233]\tvalid_0's tweedie: 158.077\n",
      "[234]\tvalid_0's tweedie: 158.077\n",
      "[235]\tvalid_0's tweedie: 158.077\n",
      "[236]\tvalid_0's tweedie: 158.077\n",
      "[237]\tvalid_0's tweedie: 158.077\n",
      "[238]\tvalid_0's tweedie: 158.077\n",
      "[239]\tvalid_0's tweedie: 158.077\n",
      "[240]\tvalid_0's tweedie: 158.077\n",
      "[241]\tvalid_0's tweedie: 158.077\n",
      "[242]\tvalid_0's tweedie: 158.077\n",
      "[243]\tvalid_0's tweedie: 158.077\n",
      "[244]\tvalid_0's tweedie: 158.077\n",
      "[245]\tvalid_0's tweedie: 158.077\n",
      "[246]\tvalid_0's tweedie: 158.077\n",
      "[247]\tvalid_0's tweedie: 158.077\n",
      "[248]\tvalid_0's tweedie: 158.077\n",
      "[249]\tvalid_0's tweedie: 158.077\n",
      "[250]\tvalid_0's tweedie: 158.077\n",
      "[251]\tvalid_0's tweedie: 158.077\n",
      "[252]\tvalid_0's tweedie: 158.078\n",
      "[253]\tvalid_0's tweedie: 158.078\n",
      "[254]\tvalid_0's tweedie: 158.078\n",
      "[255]\tvalid_0's tweedie: 158.078\n",
      "[256]\tvalid_0's tweedie: 158.078\n",
      "[257]\tvalid_0's tweedie: 158.078\n",
      "[258]\tvalid_0's tweedie: 158.078\n",
      "[259]\tvalid_0's tweedie: 158.078\n",
      "[260]\tvalid_0's tweedie: 158.078\n",
      "[261]\tvalid_0's tweedie: 158.078\n",
      "[262]\tvalid_0's tweedie: 158.078\n",
      "[263]\tvalid_0's tweedie: 158.077\n",
      "[264]\tvalid_0's tweedie: 158.077\n",
      "[265]\tvalid_0's tweedie: 158.077\n",
      "[266]\tvalid_0's tweedie: 158.077\n",
      "[267]\tvalid_0's tweedie: 158.077\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's tweedie: 158.077\n",
      "Training model for level 7 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5510\n",
      "[LightGBM] [Info] Number of data points in the train set: 39144, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398549\n",
      "[1]\tvalid_0's tweedie: 176.844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.81\n",
      "[3]\tvalid_0's tweedie: 171.217\n",
      "[4]\tvalid_0's tweedie: 169.052\n",
      "[5]\tvalid_0's tweedie: 167.2\n",
      "[6]\tvalid_0's tweedie: 165.662\n",
      "[7]\tvalid_0's tweedie: 164.381\n",
      "[8]\tvalid_0's tweedie: 163.291\n",
      "[9]\tvalid_0's tweedie: 162.398\n",
      "[10]\tvalid_0's tweedie: 161.648\n",
      "[11]\tvalid_0's tweedie: 161.041\n",
      "[12]\tvalid_0's tweedie: 160.561\n",
      "[13]\tvalid_0's tweedie: 160.17\n",
      "[14]\tvalid_0's tweedie: 159.828\n",
      "[15]\tvalid_0's tweedie: 159.543\n",
      "[16]\tvalid_0's tweedie: 159.301\n",
      "[17]\tvalid_0's tweedie: 159.105\n",
      "[18]\tvalid_0's tweedie: 158.946\n",
      "[19]\tvalid_0's tweedie: 158.814\n",
      "[20]\tvalid_0's tweedie: 158.706\n",
      "[21]\tvalid_0's tweedie: 158.616\n",
      "[22]\tvalid_0's tweedie: 158.537\n",
      "[23]\tvalid_0's tweedie: 158.478\n",
      "[24]\tvalid_0's tweedie: 158.429\n",
      "[25]\tvalid_0's tweedie: 158.391\n",
      "[26]\tvalid_0's tweedie: 158.356\n",
      "[27]\tvalid_0's tweedie: 158.328\n",
      "[28]\tvalid_0's tweedie: 158.299\n",
      "[29]\tvalid_0's tweedie: 158.273\n",
      "[30]\tvalid_0's tweedie: 158.257\n",
      "[31]\tvalid_0's tweedie: 158.246\n",
      "[32]\tvalid_0's tweedie: 158.231\n",
      "[33]\tvalid_0's tweedie: 158.221\n",
      "[34]\tvalid_0's tweedie: 158.209\n",
      "[35]\tvalid_0's tweedie: 158.198\n",
      "[36]\tvalid_0's tweedie: 158.189\n",
      "[37]\tvalid_0's tweedie: 158.183\n",
      "[38]\tvalid_0's tweedie: 158.18\n",
      "[39]\tvalid_0's tweedie: 158.176\n",
      "[40]\tvalid_0's tweedie: 158.173\n",
      "[41]\tvalid_0's tweedie: 158.167\n",
      "[42]\tvalid_0's tweedie: 158.165\n",
      "[43]\tvalid_0's tweedie: 158.161\n",
      "[44]\tvalid_0's tweedie: 158.16\n",
      "[45]\tvalid_0's tweedie: 158.157\n",
      "[46]\tvalid_0's tweedie: 158.155\n",
      "[47]\tvalid_0's tweedie: 158.154\n",
      "[48]\tvalid_0's tweedie: 158.152\n",
      "[49]\tvalid_0's tweedie: 158.153\n",
      "[50]\tvalid_0's tweedie: 158.152\n",
      "[51]\tvalid_0's tweedie: 158.147\n",
      "[52]\tvalid_0's tweedie: 158.146\n",
      "[53]\tvalid_0's tweedie: 158.145\n",
      "[54]\tvalid_0's tweedie: 158.146\n",
      "[55]\tvalid_0's tweedie: 158.145\n",
      "[56]\tvalid_0's tweedie: 158.142\n",
      "[57]\tvalid_0's tweedie: 158.142\n",
      "[58]\tvalid_0's tweedie: 158.142\n",
      "[59]\tvalid_0's tweedie: 158.139\n",
      "[60]\tvalid_0's tweedie: 158.138\n",
      "[61]\tvalid_0's tweedie: 158.137\n",
      "[62]\tvalid_0's tweedie: 158.137\n",
      "[63]\tvalid_0's tweedie: 158.137\n",
      "[64]\tvalid_0's tweedie: 158.136\n",
      "[65]\tvalid_0's tweedie: 158.136\n",
      "[66]\tvalid_0's tweedie: 158.135\n",
      "[67]\tvalid_0's tweedie: 158.135\n",
      "[68]\tvalid_0's tweedie: 158.135\n",
      "[69]\tvalid_0's tweedie: 158.135\n",
      "[70]\tvalid_0's tweedie: 158.135\n",
      "[71]\tvalid_0's tweedie: 158.135\n",
      "[72]\tvalid_0's tweedie: 158.134\n",
      "[73]\tvalid_0's tweedie: 158.134\n",
      "[74]\tvalid_0's tweedie: 158.133\n",
      "[75]\tvalid_0's tweedie: 158.131\n",
      "[76]\tvalid_0's tweedie: 158.131\n",
      "[77]\tvalid_0's tweedie: 158.13\n",
      "[78]\tvalid_0's tweedie: 158.125\n",
      "[79]\tvalid_0's tweedie: 158.125\n",
      "[80]\tvalid_0's tweedie: 158.125\n",
      "[81]\tvalid_0's tweedie: 158.124\n",
      "[82]\tvalid_0's tweedie: 158.124\n",
      "[83]\tvalid_0's tweedie: 158.124\n",
      "[84]\tvalid_0's tweedie: 158.122\n",
      "[85]\tvalid_0's tweedie: 158.12\n",
      "[86]\tvalid_0's tweedie: 158.12\n",
      "[87]\tvalid_0's tweedie: 158.12\n",
      "[88]\tvalid_0's tweedie: 158.12\n",
      "[89]\tvalid_0's tweedie: 158.12\n",
      "[90]\tvalid_0's tweedie: 158.12\n",
      "[91]\tvalid_0's tweedie: 158.12\n",
      "[92]\tvalid_0's tweedie: 158.12\n",
      "[93]\tvalid_0's tweedie: 158.119\n",
      "[94]\tvalid_0's tweedie: 158.119\n",
      "[95]\tvalid_0's tweedie: 158.118\n",
      "[96]\tvalid_0's tweedie: 158.117\n",
      "[97]\tvalid_0's tweedie: 158.116\n",
      "[98]\tvalid_0's tweedie: 158.116\n",
      "[99]\tvalid_0's tweedie: 158.116\n",
      "[100]\tvalid_0's tweedie: 158.115\n",
      "[101]\tvalid_0's tweedie: 158.115\n",
      "[102]\tvalid_0's tweedie: 158.115\n",
      "[103]\tvalid_0's tweedie: 158.115\n",
      "[104]\tvalid_0's tweedie: 158.115\n",
      "[105]\tvalid_0's tweedie: 158.115\n",
      "[106]\tvalid_0's tweedie: 158.115\n",
      "[107]\tvalid_0's tweedie: 158.115\n",
      "[108]\tvalid_0's tweedie: 158.115\n",
      "[109]\tvalid_0's tweedie: 158.115\n",
      "[110]\tvalid_0's tweedie: 158.115\n",
      "[111]\tvalid_0's tweedie: 158.115\n",
      "[112]\tvalid_0's tweedie: 158.114\n",
      "[113]\tvalid_0's tweedie: 158.114\n",
      "[114]\tvalid_0's tweedie: 158.114\n",
      "[115]\tvalid_0's tweedie: 158.114\n",
      "[116]\tvalid_0's tweedie: 158.114\n",
      "[117]\tvalid_0's tweedie: 158.113\n",
      "[118]\tvalid_0's tweedie: 158.113\n",
      "[119]\tvalid_0's tweedie: 158.113\n",
      "[120]\tvalid_0's tweedie: 158.113\n",
      "[121]\tvalid_0's tweedie: 158.113\n",
      "[122]\tvalid_0's tweedie: 158.113\n",
      "[123]\tvalid_0's tweedie: 158.112\n",
      "[124]\tvalid_0's tweedie: 158.112\n",
      "[125]\tvalid_0's tweedie: 158.112\n",
      "[126]\tvalid_0's tweedie: 158.112\n",
      "[127]\tvalid_0's tweedie: 158.112\n",
      "[128]\tvalid_0's tweedie: 158.112\n",
      "[129]\tvalid_0's tweedie: 158.111\n",
      "[130]\tvalid_0's tweedie: 158.111\n",
      "[131]\tvalid_0's tweedie: 158.111\n",
      "[132]\tvalid_0's tweedie: 158.111\n",
      "[133]\tvalid_0's tweedie: 158.111\n",
      "[134]\tvalid_0's tweedie: 158.111\n",
      "[135]\tvalid_0's tweedie: 158.111\n",
      "[136]\tvalid_0's tweedie: 158.111\n",
      "[137]\tvalid_0's tweedie: 158.111\n",
      "[138]\tvalid_0's tweedie: 158.111\n",
      "[139]\tvalid_0's tweedie: 158.111\n",
      "[140]\tvalid_0's tweedie: 158.11\n",
      "[141]\tvalid_0's tweedie: 158.108\n",
      "[142]\tvalid_0's tweedie: 158.108\n",
      "[143]\tvalid_0's tweedie: 158.108\n",
      "[144]\tvalid_0's tweedie: 158.108\n",
      "[145]\tvalid_0's tweedie: 158.108\n",
      "[146]\tvalid_0's tweedie: 158.108\n",
      "[147]\tvalid_0's tweedie: 158.108\n",
      "[148]\tvalid_0's tweedie: 158.108\n",
      "[149]\tvalid_0's tweedie: 158.108\n",
      "[150]\tvalid_0's tweedie: 158.108\n",
      "[151]\tvalid_0's tweedie: 158.108\n",
      "[152]\tvalid_0's tweedie: 158.108\n",
      "[153]\tvalid_0's tweedie: 158.108\n",
      "[154]\tvalid_0's tweedie: 158.108\n",
      "[155]\tvalid_0's tweedie: 158.108\n",
      "[156]\tvalid_0's tweedie: 158.108\n",
      "[157]\tvalid_0's tweedie: 158.108\n",
      "[158]\tvalid_0's tweedie: 158.108\n",
      "[159]\tvalid_0's tweedie: 158.107\n",
      "[160]\tvalid_0's tweedie: 158.107\n",
      "[161]\tvalid_0's tweedie: 158.107\n",
      "[162]\tvalid_0's tweedie: 158.107\n",
      "[163]\tvalid_0's tweedie: 158.107\n",
      "[164]\tvalid_0's tweedie: 158.107\n",
      "[165]\tvalid_0's tweedie: 158.108\n",
      "[166]\tvalid_0's tweedie: 158.106\n",
      "[167]\tvalid_0's tweedie: 158.106\n",
      "[168]\tvalid_0's tweedie: 158.106\n",
      "[169]\tvalid_0's tweedie: 158.106\n",
      "[170]\tvalid_0's tweedie: 158.106\n",
      "[171]\tvalid_0's tweedie: 158.106\n",
      "[172]\tvalid_0's tweedie: 158.105\n",
      "[173]\tvalid_0's tweedie: 158.106\n",
      "[174]\tvalid_0's tweedie: 158.106\n",
      "[175]\tvalid_0's tweedie: 158.106\n",
      "[176]\tvalid_0's tweedie: 158.106\n",
      "[177]\tvalid_0's tweedie: 158.106\n",
      "[178]\tvalid_0's tweedie: 158.106\n",
      "[179]\tvalid_0's tweedie: 158.106\n",
      "[180]\tvalid_0's tweedie: 158.106\n",
      "[181]\tvalid_0's tweedie: 158.106\n",
      "[182]\tvalid_0's tweedie: 158.106\n",
      "[183]\tvalid_0's tweedie: 158.106\n",
      "[184]\tvalid_0's tweedie: 158.105\n",
      "[185]\tvalid_0's tweedie: 158.105\n",
      "[186]\tvalid_0's tweedie: 158.105\n",
      "[187]\tvalid_0's tweedie: 158.105\n",
      "[188]\tvalid_0's tweedie: 158.105\n",
      "[189]\tvalid_0's tweedie: 158.105\n",
      "[190]\tvalid_0's tweedie: 158.105\n",
      "[191]\tvalid_0's tweedie: 158.105\n",
      "[192]\tvalid_0's tweedie: 158.105\n",
      "[193]\tvalid_0's tweedie: 158.105\n",
      "[194]\tvalid_0's tweedie: 158.105\n",
      "[195]\tvalid_0's tweedie: 158.105\n",
      "[196]\tvalid_0's tweedie: 158.102\n",
      "[197]\tvalid_0's tweedie: 158.102\n",
      "[198]\tvalid_0's tweedie: 158.102\n",
      "[199]\tvalid_0's tweedie: 158.102\n",
      "[200]\tvalid_0's tweedie: 158.102\n",
      "[201]\tvalid_0's tweedie: 158.102\n",
      "[202]\tvalid_0's tweedie: 158.102\n",
      "[203]\tvalid_0's tweedie: 158.102\n",
      "[204]\tvalid_0's tweedie: 158.102\n",
      "[205]\tvalid_0's tweedie: 158.101\n",
      "[206]\tvalid_0's tweedie: 158.101\n",
      "[207]\tvalid_0's tweedie: 158.101\n",
      "[208]\tvalid_0's tweedie: 158.101\n",
      "[209]\tvalid_0's tweedie: 158.101\n",
      "[210]\tvalid_0's tweedie: 158.101\n",
      "[211]\tvalid_0's tweedie: 158.101\n",
      "[212]\tvalid_0's tweedie: 158.101\n",
      "[213]\tvalid_0's tweedie: 158.101\n",
      "[214]\tvalid_0's tweedie: 158.101\n",
      "[215]\tvalid_0's tweedie: 158.101\n",
      "[216]\tvalid_0's tweedie: 158.101\n",
      "[217]\tvalid_0's tweedie: 158.101\n",
      "[218]\tvalid_0's tweedie: 158.101\n",
      "[219]\tvalid_0's tweedie: 158.101\n",
      "[220]\tvalid_0's tweedie: 158.101\n",
      "[221]\tvalid_0's tweedie: 158.101\n",
      "[222]\tvalid_0's tweedie: 158.101\n",
      "[223]\tvalid_0's tweedie: 158.101\n",
      "[224]\tvalid_0's tweedie: 158.101\n",
      "[225]\tvalid_0's tweedie: 158.101\n",
      "[226]\tvalid_0's tweedie: 158.101\n",
      "[227]\tvalid_0's tweedie: 158.101\n",
      "[228]\tvalid_0's tweedie: 158.1\n",
      "[229]\tvalid_0's tweedie: 158.1\n",
      "[230]\tvalid_0's tweedie: 158.1\n",
      "[231]\tvalid_0's tweedie: 158.1\n",
      "[232]\tvalid_0's tweedie: 158.1\n",
      "[233]\tvalid_0's tweedie: 158.1\n",
      "[234]\tvalid_0's tweedie: 158.1\n",
      "[235]\tvalid_0's tweedie: 158.1\n",
      "[236]\tvalid_0's tweedie: 158.1\n",
      "[237]\tvalid_0's tweedie: 158.1\n",
      "[238]\tvalid_0's tweedie: 158.1\n",
      "[239]\tvalid_0's tweedie: 158.1\n",
      "[240]\tvalid_0's tweedie: 158.1\n",
      "[241]\tvalid_0's tweedie: 158.1\n",
      "[242]\tvalid_0's tweedie: 158.1\n",
      "[243]\tvalid_0's tweedie: 158.1\n",
      "[244]\tvalid_0's tweedie: 158.1\n",
      "[245]\tvalid_0's tweedie: 158.1\n",
      "[246]\tvalid_0's tweedie: 158.1\n",
      "[247]\tvalid_0's tweedie: 158.1\n",
      "[248]\tvalid_0's tweedie: 158.1\n",
      "[249]\tvalid_0's tweedie: 158.1\n",
      "[250]\tvalid_0's tweedie: 158.1\n",
      "[251]\tvalid_0's tweedie: 158.099\n",
      "[252]\tvalid_0's tweedie: 158.099\n",
      "[253]\tvalid_0's tweedie: 158.099\n",
      "[254]\tvalid_0's tweedie: 158.099\n",
      "[255]\tvalid_0's tweedie: 158.099\n",
      "[256]\tvalid_0's tweedie: 158.099\n",
      "[257]\tvalid_0's tweedie: 158.099\n",
      "[258]\tvalid_0's tweedie: 158.099\n",
      "[259]\tvalid_0's tweedie: 158.099\n",
      "[260]\tvalid_0's tweedie: 158.099\n",
      "[261]\tvalid_0's tweedie: 158.099\n",
      "[262]\tvalid_0's tweedie: 158.099\n",
      "[263]\tvalid_0's tweedie: 158.099\n",
      "[264]\tvalid_0's tweedie: 158.099\n",
      "[265]\tvalid_0's tweedie: 158.099\n",
      "[266]\tvalid_0's tweedie: 158.099\n",
      "[267]\tvalid_0's tweedie: 158.099\n",
      "[268]\tvalid_0's tweedie: 158.099\n",
      "[269]\tvalid_0's tweedie: 158.099\n",
      "[270]\tvalid_0's tweedie: 158.099\n",
      "[271]\tvalid_0's tweedie: 158.099\n",
      "[272]\tvalid_0's tweedie: 158.099\n",
      "[273]\tvalid_0's tweedie: 158.099\n",
      "[274]\tvalid_0's tweedie: 158.099\n",
      "[275]\tvalid_0's tweedie: 158.099\n",
      "[276]\tvalid_0's tweedie: 158.099\n",
      "[277]\tvalid_0's tweedie: 158.1\n",
      "[278]\tvalid_0's tweedie: 158.099\n",
      "[279]\tvalid_0's tweedie: 158.099\n",
      "[280]\tvalid_0's tweedie: 158.099\n",
      "[281]\tvalid_0's tweedie: 158.099\n",
      "[282]\tvalid_0's tweedie: 158.099\n",
      "[283]\tvalid_0's tweedie: 158.099\n",
      "[284]\tvalid_0's tweedie: 158.099\n",
      "[285]\tvalid_0's tweedie: 158.099\n",
      "[286]\tvalid_0's tweedie: 158.099\n",
      "[287]\tvalid_0's tweedie: 158.099\n",
      "[288]\tvalid_0's tweedie: 158.099\n",
      "[289]\tvalid_0's tweedie: 158.099\n",
      "[290]\tvalid_0's tweedie: 158.099\n",
      "[291]\tvalid_0's tweedie: 158.099\n",
      "[292]\tvalid_0's tweedie: 158.099\n",
      "[293]\tvalid_0's tweedie: 158.099\n",
      "[294]\tvalid_0's tweedie: 158.099\n",
      "[295]\tvalid_0's tweedie: 158.099\n",
      "[296]\tvalid_0's tweedie: 158.099\n",
      "[297]\tvalid_0's tweedie: 158.099\n",
      "[298]\tvalid_0's tweedie: 158.099\n",
      "[299]\tvalid_0's tweedie: 158.099\n",
      "[300]\tvalid_0's tweedie: 158.099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 158.099\n",
      "Training model for level 7 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 39123, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398590\n",
      "[1]\tvalid_0's tweedie: 176.852\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.799\n",
      "[3]\tvalid_0's tweedie: 171.206\n",
      "[4]\tvalid_0's tweedie: 169.02\n",
      "[5]\tvalid_0's tweedie: 167.183\n",
      "[6]\tvalid_0's tweedie: 165.648\n",
      "[7]\tvalid_0's tweedie: 164.404\n",
      "[8]\tvalid_0's tweedie: 163.352\n",
      "[9]\tvalid_0's tweedie: 162.453\n",
      "[10]\tvalid_0's tweedie: 161.735\n",
      "[11]\tvalid_0's tweedie: 161.133\n",
      "[12]\tvalid_0's tweedie: 160.626\n",
      "[13]\tvalid_0's tweedie: 160.221\n",
      "[14]\tvalid_0's tweedie: 159.868\n",
      "[15]\tvalid_0's tweedie: 159.583\n",
      "[16]\tvalid_0's tweedie: 159.35\n",
      "[17]\tvalid_0's tweedie: 159.156\n",
      "[18]\tvalid_0's tweedie: 158.991\n",
      "[19]\tvalid_0's tweedie: 158.859\n",
      "[20]\tvalid_0's tweedie: 158.744\n",
      "[21]\tvalid_0's tweedie: 158.659\n",
      "[22]\tvalid_0's tweedie: 158.585\n",
      "[23]\tvalid_0's tweedie: 158.524\n",
      "[24]\tvalid_0's tweedie: 158.473\n",
      "[25]\tvalid_0's tweedie: 158.431\n",
      "[26]\tvalid_0's tweedie: 158.395\n",
      "[27]\tvalid_0's tweedie: 158.366\n",
      "[28]\tvalid_0's tweedie: 158.341\n",
      "[29]\tvalid_0's tweedie: 158.32\n",
      "[30]\tvalid_0's tweedie: 158.304\n",
      "[31]\tvalid_0's tweedie: 158.286\n",
      "[32]\tvalid_0's tweedie: 158.275\n",
      "[33]\tvalid_0's tweedie: 158.264\n",
      "[34]\tvalid_0's tweedie: 158.257\n",
      "[35]\tvalid_0's tweedie: 158.246\n",
      "[36]\tvalid_0's tweedie: 158.234\n",
      "[37]\tvalid_0's tweedie: 158.227\n",
      "[38]\tvalid_0's tweedie: 158.22\n",
      "[39]\tvalid_0's tweedie: 158.217\n",
      "[40]\tvalid_0's tweedie: 158.213\n",
      "[41]\tvalid_0's tweedie: 158.209\n",
      "[42]\tvalid_0's tweedie: 158.207\n",
      "[43]\tvalid_0's tweedie: 158.204\n",
      "[44]\tvalid_0's tweedie: 158.202\n",
      "[45]\tvalid_0's tweedie: 158.201\n",
      "[46]\tvalid_0's tweedie: 158.202\n",
      "[47]\tvalid_0's tweedie: 158.201\n",
      "[48]\tvalid_0's tweedie: 158.201\n",
      "[49]\tvalid_0's tweedie: 158.199\n",
      "[50]\tvalid_0's tweedie: 158.195\n",
      "[51]\tvalid_0's tweedie: 158.192\n",
      "[52]\tvalid_0's tweedie: 158.192\n",
      "[53]\tvalid_0's tweedie: 158.192\n",
      "[54]\tvalid_0's tweedie: 158.191\n",
      "[55]\tvalid_0's tweedie: 158.191\n",
      "[56]\tvalid_0's tweedie: 158.189\n",
      "[57]\tvalid_0's tweedie: 158.189\n",
      "[58]\tvalid_0's tweedie: 158.188\n",
      "[59]\tvalid_0's tweedie: 158.185\n",
      "[60]\tvalid_0's tweedie: 158.185\n",
      "[61]\tvalid_0's tweedie: 158.184\n",
      "[62]\tvalid_0's tweedie: 158.183\n",
      "[63]\tvalid_0's tweedie: 158.178\n",
      "[64]\tvalid_0's tweedie: 158.177\n",
      "[65]\tvalid_0's tweedie: 158.176\n",
      "[66]\tvalid_0's tweedie: 158.176\n",
      "[67]\tvalid_0's tweedie: 158.173\n",
      "[68]\tvalid_0's tweedie: 158.171\n",
      "[69]\tvalid_0's tweedie: 158.171\n",
      "[70]\tvalid_0's tweedie: 158.17\n",
      "[71]\tvalid_0's tweedie: 158.169\n",
      "[72]\tvalid_0's tweedie: 158.169\n",
      "[73]\tvalid_0's tweedie: 158.165\n",
      "[74]\tvalid_0's tweedie: 158.165\n",
      "[75]\tvalid_0's tweedie: 158.16\n",
      "[76]\tvalid_0's tweedie: 158.16\n",
      "[77]\tvalid_0's tweedie: 158.16\n",
      "[78]\tvalid_0's tweedie: 158.158\n",
      "[79]\tvalid_0's tweedie: 158.157\n",
      "[80]\tvalid_0's tweedie: 158.157\n",
      "[81]\tvalid_0's tweedie: 158.157\n",
      "[82]\tvalid_0's tweedie: 158.156\n",
      "[83]\tvalid_0's tweedie: 158.156\n",
      "[84]\tvalid_0's tweedie: 158.156\n",
      "[85]\tvalid_0's tweedie: 158.156\n",
      "[86]\tvalid_0's tweedie: 158.154\n",
      "[87]\tvalid_0's tweedie: 158.154\n",
      "[88]\tvalid_0's tweedie: 158.154\n",
      "[89]\tvalid_0's tweedie: 158.154\n",
      "[90]\tvalid_0's tweedie: 158.152\n",
      "[91]\tvalid_0's tweedie: 158.152\n",
      "[92]\tvalid_0's tweedie: 158.151\n",
      "[93]\tvalid_0's tweedie: 158.151\n",
      "[94]\tvalid_0's tweedie: 158.151\n",
      "[95]\tvalid_0's tweedie: 158.144\n",
      "[96]\tvalid_0's tweedie: 158.144\n",
      "[97]\tvalid_0's tweedie: 158.144\n",
      "[98]\tvalid_0's tweedie: 158.143\n",
      "[99]\tvalid_0's tweedie: 158.143\n",
      "[100]\tvalid_0's tweedie: 158.143\n",
      "[101]\tvalid_0's tweedie: 158.142\n",
      "[102]\tvalid_0's tweedie: 158.141\n",
      "[103]\tvalid_0's tweedie: 158.141\n",
      "[104]\tvalid_0's tweedie: 158.141\n",
      "[105]\tvalid_0's tweedie: 158.141\n",
      "[106]\tvalid_0's tweedie: 158.141\n",
      "[107]\tvalid_0's tweedie: 158.141\n",
      "[108]\tvalid_0's tweedie: 158.141\n",
      "[109]\tvalid_0's tweedie: 158.141\n",
      "[110]\tvalid_0's tweedie: 158.141\n",
      "[111]\tvalid_0's tweedie: 158.141\n",
      "[112]\tvalid_0's tweedie: 158.141\n",
      "[113]\tvalid_0's tweedie: 158.141\n",
      "[114]\tvalid_0's tweedie: 158.14\n",
      "[115]\tvalid_0's tweedie: 158.14\n",
      "[116]\tvalid_0's tweedie: 158.14\n",
      "[117]\tvalid_0's tweedie: 158.14\n",
      "[118]\tvalid_0's tweedie: 158.14\n",
      "[119]\tvalid_0's tweedie: 158.14\n",
      "[120]\tvalid_0's tweedie: 158.139\n",
      "[121]\tvalid_0's tweedie: 158.137\n",
      "[122]\tvalid_0's tweedie: 158.137\n",
      "[123]\tvalid_0's tweedie: 158.137\n",
      "[124]\tvalid_0's tweedie: 158.137\n",
      "[125]\tvalid_0's tweedie: 158.137\n",
      "[126]\tvalid_0's tweedie: 158.137\n",
      "[127]\tvalid_0's tweedie: 158.137\n",
      "[128]\tvalid_0's tweedie: 158.136\n",
      "[129]\tvalid_0's tweedie: 158.136\n",
      "[130]\tvalid_0's tweedie: 158.136\n",
      "[131]\tvalid_0's tweedie: 158.135\n",
      "[132]\tvalid_0's tweedie: 158.135\n",
      "[133]\tvalid_0's tweedie: 158.135\n",
      "[134]\tvalid_0's tweedie: 158.135\n",
      "[135]\tvalid_0's tweedie: 158.136\n",
      "[136]\tvalid_0's tweedie: 158.135\n",
      "[137]\tvalid_0's tweedie: 158.135\n",
      "[138]\tvalid_0's tweedie: 158.135\n",
      "[139]\tvalid_0's tweedie: 158.135\n",
      "[140]\tvalid_0's tweedie: 158.133\n",
      "[141]\tvalid_0's tweedie: 158.133\n",
      "[142]\tvalid_0's tweedie: 158.133\n",
      "[143]\tvalid_0's tweedie: 158.133\n",
      "[144]\tvalid_0's tweedie: 158.133\n",
      "[145]\tvalid_0's tweedie: 158.133\n",
      "[146]\tvalid_0's tweedie: 158.133\n",
      "[147]\tvalid_0's tweedie: 158.133\n",
      "[148]\tvalid_0's tweedie: 158.132\n",
      "[149]\tvalid_0's tweedie: 158.132\n",
      "[150]\tvalid_0's tweedie: 158.132\n",
      "[151]\tvalid_0's tweedie: 158.132\n",
      "[152]\tvalid_0's tweedie: 158.132\n",
      "[153]\tvalid_0's tweedie: 158.132\n",
      "[154]\tvalid_0's tweedie: 158.132\n",
      "[155]\tvalid_0's tweedie: 158.132\n",
      "[156]\tvalid_0's tweedie: 158.132\n",
      "[157]\tvalid_0's tweedie: 158.132\n",
      "[158]\tvalid_0's tweedie: 158.132\n",
      "[159]\tvalid_0's tweedie: 158.132\n",
      "[160]\tvalid_0's tweedie: 158.132\n",
      "[161]\tvalid_0's tweedie: 158.132\n",
      "[162]\tvalid_0's tweedie: 158.131\n",
      "[163]\tvalid_0's tweedie: 158.131\n",
      "[164]\tvalid_0's tweedie: 158.131\n",
      "[165]\tvalid_0's tweedie: 158.131\n",
      "[166]\tvalid_0's tweedie: 158.131\n",
      "[167]\tvalid_0's tweedie: 158.13\n",
      "[168]\tvalid_0's tweedie: 158.13\n",
      "[169]\tvalid_0's tweedie: 158.13\n",
      "[170]\tvalid_0's tweedie: 158.13\n",
      "[171]\tvalid_0's tweedie: 158.13\n",
      "[172]\tvalid_0's tweedie: 158.13\n",
      "[173]\tvalid_0's tweedie: 158.126\n",
      "[174]\tvalid_0's tweedie: 158.126\n",
      "[175]\tvalid_0's tweedie: 158.127\n",
      "[176]\tvalid_0's tweedie: 158.126\n",
      "[177]\tvalid_0's tweedie: 158.126\n",
      "[178]\tvalid_0's tweedie: 158.125\n",
      "[179]\tvalid_0's tweedie: 158.125\n",
      "[180]\tvalid_0's tweedie: 158.125\n",
      "[181]\tvalid_0's tweedie: 158.126\n",
      "[182]\tvalid_0's tweedie: 158.126\n",
      "[183]\tvalid_0's tweedie: 158.126\n",
      "[184]\tvalid_0's tweedie: 158.126\n",
      "[185]\tvalid_0's tweedie: 158.126\n",
      "[186]\tvalid_0's tweedie: 158.125\n",
      "[187]\tvalid_0's tweedie: 158.125\n",
      "[188]\tvalid_0's tweedie: 158.125\n",
      "[189]\tvalid_0's tweedie: 158.125\n",
      "[190]\tvalid_0's tweedie: 158.125\n",
      "[191]\tvalid_0's tweedie: 158.125\n",
      "[192]\tvalid_0's tweedie: 158.125\n",
      "[193]\tvalid_0's tweedie: 158.125\n",
      "[194]\tvalid_0's tweedie: 158.125\n",
      "[195]\tvalid_0's tweedie: 158.125\n",
      "[196]\tvalid_0's tweedie: 158.125\n",
      "[197]\tvalid_0's tweedie: 158.125\n",
      "[198]\tvalid_0's tweedie: 158.125\n",
      "[199]\tvalid_0's tweedie: 158.125\n",
      "[200]\tvalid_0's tweedie: 158.125\n",
      "[201]\tvalid_0's tweedie: 158.125\n",
      "[202]\tvalid_0's tweedie: 158.125\n",
      "[203]\tvalid_0's tweedie: 158.125\n",
      "[204]\tvalid_0's tweedie: 158.125\n",
      "[205]\tvalid_0's tweedie: 158.125\n",
      "[206]\tvalid_0's tweedie: 158.124\n",
      "[207]\tvalid_0's tweedie: 158.124\n",
      "[208]\tvalid_0's tweedie: 158.124\n",
      "[209]\tvalid_0's tweedie: 158.124\n",
      "[210]\tvalid_0's tweedie: 158.124\n",
      "[211]\tvalid_0's tweedie: 158.124\n",
      "[212]\tvalid_0's tweedie: 158.124\n",
      "[213]\tvalid_0's tweedie: 158.124\n",
      "[214]\tvalid_0's tweedie: 158.121\n",
      "[215]\tvalid_0's tweedie: 158.121\n",
      "[216]\tvalid_0's tweedie: 158.121\n",
      "[217]\tvalid_0's tweedie: 158.121\n",
      "[218]\tvalid_0's tweedie: 158.121\n",
      "[219]\tvalid_0's tweedie: 158.121\n",
      "[220]\tvalid_0's tweedie: 158.121\n",
      "[221]\tvalid_0's tweedie: 158.121\n",
      "[222]\tvalid_0's tweedie: 158.121\n",
      "[223]\tvalid_0's tweedie: 158.121\n",
      "[224]\tvalid_0's tweedie: 158.121\n",
      "[225]\tvalid_0's tweedie: 158.121\n",
      "[226]\tvalid_0's tweedie: 158.121\n",
      "[227]\tvalid_0's tweedie: 158.121\n",
      "[228]\tvalid_0's tweedie: 158.121\n",
      "[229]\tvalid_0's tweedie: 158.121\n",
      "[230]\tvalid_0's tweedie: 158.121\n",
      "[231]\tvalid_0's tweedie: 158.121\n",
      "[232]\tvalid_0's tweedie: 158.121\n",
      "[233]\tvalid_0's tweedie: 158.121\n",
      "[234]\tvalid_0's tweedie: 158.121\n",
      "[235]\tvalid_0's tweedie: 158.121\n",
      "[236]\tvalid_0's tweedie: 158.121\n",
      "[237]\tvalid_0's tweedie: 158.121\n",
      "[238]\tvalid_0's tweedie: 158.121\n",
      "[239]\tvalid_0's tweedie: 158.121\n",
      "[240]\tvalid_0's tweedie: 158.121\n",
      "[241]\tvalid_0's tweedie: 158.121\n",
      "[242]\tvalid_0's tweedie: 158.121\n",
      "[243]\tvalid_0's tweedie: 158.121\n",
      "[244]\tvalid_0's tweedie: 158.121\n",
      "[245]\tvalid_0's tweedie: 158.121\n",
      "[246]\tvalid_0's tweedie: 158.121\n",
      "[247]\tvalid_0's tweedie: 158.121\n",
      "[248]\tvalid_0's tweedie: 158.121\n",
      "[249]\tvalid_0's tweedie: 158.121\n",
      "[250]\tvalid_0's tweedie: 158.12\n",
      "[251]\tvalid_0's tweedie: 158.12\n",
      "[252]\tvalid_0's tweedie: 158.12\n",
      "[253]\tvalid_0's tweedie: 158.12\n",
      "[254]\tvalid_0's tweedie: 158.12\n",
      "[255]\tvalid_0's tweedie: 158.12\n",
      "[256]\tvalid_0's tweedie: 158.12\n",
      "[257]\tvalid_0's tweedie: 158.12\n",
      "[258]\tvalid_0's tweedie: 158.12\n",
      "[259]\tvalid_0's tweedie: 158.12\n",
      "[260]\tvalid_0's tweedie: 158.12\n",
      "[261]\tvalid_0's tweedie: 158.12\n",
      "[262]\tvalid_0's tweedie: 158.12\n",
      "[263]\tvalid_0's tweedie: 158.12\n",
      "[264]\tvalid_0's tweedie: 158.12\n",
      "[265]\tvalid_0's tweedie: 158.12\n",
      "[266]\tvalid_0's tweedie: 158.119\n",
      "[267]\tvalid_0's tweedie: 158.119\n",
      "[268]\tvalid_0's tweedie: 158.12\n",
      "[269]\tvalid_0's tweedie: 158.12\n",
      "[270]\tvalid_0's tweedie: 158.118\n",
      "[271]\tvalid_0's tweedie: 158.118\n",
      "[272]\tvalid_0's tweedie: 158.118\n",
      "[273]\tvalid_0's tweedie: 158.118\n",
      "[274]\tvalid_0's tweedie: 158.118\n",
      "[275]\tvalid_0's tweedie: 158.118\n",
      "[276]\tvalid_0's tweedie: 158.118\n",
      "[277]\tvalid_0's tweedie: 158.118\n",
      "[278]\tvalid_0's tweedie: 158.117\n",
      "[279]\tvalid_0's tweedie: 158.117\n",
      "[280]\tvalid_0's tweedie: 158.117\n",
      "[281]\tvalid_0's tweedie: 158.117\n",
      "[282]\tvalid_0's tweedie: 158.117\n",
      "[283]\tvalid_0's tweedie: 158.117\n",
      "[284]\tvalid_0's tweedie: 158.117\n",
      "[285]\tvalid_0's tweedie: 158.117\n",
      "[286]\tvalid_0's tweedie: 158.117\n",
      "[287]\tvalid_0's tweedie: 158.116\n",
      "[288]\tvalid_0's tweedie: 158.116\n",
      "[289]\tvalid_0's tweedie: 158.116\n",
      "[290]\tvalid_0's tweedie: 158.116\n",
      "[291]\tvalid_0's tweedie: 158.116\n",
      "[292]\tvalid_0's tweedie: 158.116\n",
      "[293]\tvalid_0's tweedie: 158.117\n",
      "[294]\tvalid_0's tweedie: 158.116\n",
      "[295]\tvalid_0's tweedie: 158.116\n",
      "[296]\tvalid_0's tweedie: 158.118\n",
      "[297]\tvalid_0's tweedie: 158.118\n",
      "[298]\tvalid_0's tweedie: 158.118\n",
      "[299]\tvalid_0's tweedie: 158.119\n",
      "[300]\tvalid_0's tweedie: 158.119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[291]\tvalid_0's tweedie: 158.116\n",
      "Training model for level 7 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 39102, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398668\n",
      "[1]\tvalid_0's tweedie: 176.851\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.813\n",
      "[3]\tvalid_0's tweedie: 171.225\n",
      "[4]\tvalid_0's tweedie: 169.031\n",
      "[5]\tvalid_0's tweedie: 167.206\n",
      "[6]\tvalid_0's tweedie: 165.672\n",
      "[7]\tvalid_0's tweedie: 164.394\n",
      "[8]\tvalid_0's tweedie: 163.352\n",
      "[9]\tvalid_0's tweedie: 162.448\n",
      "[10]\tvalid_0's tweedie: 161.717\n",
      "[11]\tvalid_0's tweedie: 161.14\n",
      "[12]\tvalid_0's tweedie: 160.635\n",
      "[13]\tvalid_0's tweedie: 160.233\n",
      "[14]\tvalid_0's tweedie: 159.885\n",
      "[15]\tvalid_0's tweedie: 159.603\n",
      "[16]\tvalid_0's tweedie: 159.366\n",
      "[17]\tvalid_0's tweedie: 159.17\n",
      "[18]\tvalid_0's tweedie: 159.01\n",
      "[19]\tvalid_0's tweedie: 158.88\n",
      "[20]\tvalid_0's tweedie: 158.77\n",
      "[21]\tvalid_0's tweedie: 158.679\n",
      "[22]\tvalid_0's tweedie: 158.604\n",
      "[23]\tvalid_0's tweedie: 158.542\n",
      "[24]\tvalid_0's tweedie: 158.489\n",
      "[25]\tvalid_0's tweedie: 158.446\n",
      "[26]\tvalid_0's tweedie: 158.412\n",
      "[27]\tvalid_0's tweedie: 158.381\n",
      "[28]\tvalid_0's tweedie: 158.356\n",
      "[29]\tvalid_0's tweedie: 158.338\n",
      "[30]\tvalid_0's tweedie: 158.316\n",
      "[31]\tvalid_0's tweedie: 158.302\n",
      "[32]\tvalid_0's tweedie: 158.29\n",
      "[33]\tvalid_0's tweedie: 158.282\n",
      "[34]\tvalid_0's tweedie: 158.27\n",
      "[35]\tvalid_0's tweedie: 158.26\n",
      "[36]\tvalid_0's tweedie: 158.25\n",
      "[37]\tvalid_0's tweedie: 158.243\n",
      "[38]\tvalid_0's tweedie: 158.233\n",
      "[39]\tvalid_0's tweedie: 158.228\n",
      "[40]\tvalid_0's tweedie: 158.224\n",
      "[41]\tvalid_0's tweedie: 158.221\n",
      "[42]\tvalid_0's tweedie: 158.219\n",
      "[43]\tvalid_0's tweedie: 158.215\n",
      "[44]\tvalid_0's tweedie: 158.213\n",
      "[45]\tvalid_0's tweedie: 158.21\n",
      "[46]\tvalid_0's tweedie: 158.207\n",
      "[47]\tvalid_0's tweedie: 158.207\n",
      "[48]\tvalid_0's tweedie: 158.203\n",
      "[49]\tvalid_0's tweedie: 158.201\n",
      "[50]\tvalid_0's tweedie: 158.199\n",
      "[51]\tvalid_0's tweedie: 158.199\n",
      "[52]\tvalid_0's tweedie: 158.197\n",
      "[53]\tvalid_0's tweedie: 158.196\n",
      "[54]\tvalid_0's tweedie: 158.196\n",
      "[55]\tvalid_0's tweedie: 158.195\n",
      "[56]\tvalid_0's tweedie: 158.194\n",
      "[57]\tvalid_0's tweedie: 158.191\n",
      "[58]\tvalid_0's tweedie: 158.19\n",
      "[59]\tvalid_0's tweedie: 158.19\n",
      "[60]\tvalid_0's tweedie: 158.19\n",
      "[61]\tvalid_0's tweedie: 158.19\n",
      "[62]\tvalid_0's tweedie: 158.19\n",
      "[63]\tvalid_0's tweedie: 158.187\n",
      "[64]\tvalid_0's tweedie: 158.187\n",
      "[65]\tvalid_0's tweedie: 158.188\n",
      "[66]\tvalid_0's tweedie: 158.187\n",
      "[67]\tvalid_0's tweedie: 158.187\n",
      "[68]\tvalid_0's tweedie: 158.187\n",
      "[69]\tvalid_0's tweedie: 158.187\n",
      "[70]\tvalid_0's tweedie: 158.187\n",
      "[71]\tvalid_0's tweedie: 158.187\n",
      "[72]\tvalid_0's tweedie: 158.187\n",
      "[73]\tvalid_0's tweedie: 158.186\n",
      "[74]\tvalid_0's tweedie: 158.18\n",
      "[75]\tvalid_0's tweedie: 158.178\n",
      "[76]\tvalid_0's tweedie: 158.178\n",
      "[77]\tvalid_0's tweedie: 158.178\n",
      "[78]\tvalid_0's tweedie: 158.177\n",
      "[79]\tvalid_0's tweedie: 158.175\n",
      "[80]\tvalid_0's tweedie: 158.175\n",
      "[81]\tvalid_0's tweedie: 158.174\n",
      "[82]\tvalid_0's tweedie: 158.174\n",
      "[83]\tvalid_0's tweedie: 158.174\n",
      "[84]\tvalid_0's tweedie: 158.174\n",
      "[85]\tvalid_0's tweedie: 158.167\n",
      "[86]\tvalid_0's tweedie: 158.167\n",
      "[87]\tvalid_0's tweedie: 158.167\n",
      "[88]\tvalid_0's tweedie: 158.167\n",
      "[89]\tvalid_0's tweedie: 158.167\n",
      "[90]\tvalid_0's tweedie: 158.164\n",
      "[91]\tvalid_0's tweedie: 158.164\n",
      "[92]\tvalid_0's tweedie: 158.164\n",
      "[93]\tvalid_0's tweedie: 158.164\n",
      "[94]\tvalid_0's tweedie: 158.164\n",
      "[95]\tvalid_0's tweedie: 158.162\n",
      "[96]\tvalid_0's tweedie: 158.162\n",
      "[97]\tvalid_0's tweedie: 158.162\n",
      "[98]\tvalid_0's tweedie: 158.162\n",
      "[99]\tvalid_0's tweedie: 158.162\n",
      "[100]\tvalid_0's tweedie: 158.162\n",
      "[101]\tvalid_0's tweedie: 158.162\n",
      "[102]\tvalid_0's tweedie: 158.162\n",
      "[103]\tvalid_0's tweedie: 158.161\n",
      "[104]\tvalid_0's tweedie: 158.158\n",
      "[105]\tvalid_0's tweedie: 158.158\n",
      "[106]\tvalid_0's tweedie: 158.158\n",
      "[107]\tvalid_0's tweedie: 158.158\n",
      "[108]\tvalid_0's tweedie: 158.157\n",
      "[109]\tvalid_0's tweedie: 158.157\n",
      "[110]\tvalid_0's tweedie: 158.157\n",
      "[111]\tvalid_0's tweedie: 158.157\n",
      "[112]\tvalid_0's tweedie: 158.157\n",
      "[113]\tvalid_0's tweedie: 158.157\n",
      "[114]\tvalid_0's tweedie: 158.157\n",
      "[115]\tvalid_0's tweedie: 158.157\n",
      "[116]\tvalid_0's tweedie: 158.157\n",
      "[117]\tvalid_0's tweedie: 158.157\n",
      "[118]\tvalid_0's tweedie: 158.157\n",
      "[119]\tvalid_0's tweedie: 158.157\n",
      "[120]\tvalid_0's tweedie: 158.157\n",
      "[121]\tvalid_0's tweedie: 158.157\n",
      "[122]\tvalid_0's tweedie: 158.156\n",
      "[123]\tvalid_0's tweedie: 158.156\n",
      "[124]\tvalid_0's tweedie: 158.155\n",
      "[125]\tvalid_0's tweedie: 158.155\n",
      "[126]\tvalid_0's tweedie: 158.155\n",
      "[127]\tvalid_0's tweedie: 158.155\n",
      "[128]\tvalid_0's tweedie: 158.155\n",
      "[129]\tvalid_0's tweedie: 158.155\n",
      "[130]\tvalid_0's tweedie: 158.155\n",
      "[131]\tvalid_0's tweedie: 158.155\n",
      "[132]\tvalid_0's tweedie: 158.155\n",
      "[133]\tvalid_0's tweedie: 158.155\n",
      "[134]\tvalid_0's tweedie: 158.155\n",
      "[135]\tvalid_0's tweedie: 158.154\n",
      "[136]\tvalid_0's tweedie: 158.152\n",
      "[137]\tvalid_0's tweedie: 158.152\n",
      "[138]\tvalid_0's tweedie: 158.152\n",
      "[139]\tvalid_0's tweedie: 158.152\n",
      "[140]\tvalid_0's tweedie: 158.152\n",
      "[141]\tvalid_0's tweedie: 158.152\n",
      "[142]\tvalid_0's tweedie: 158.153\n",
      "[143]\tvalid_0's tweedie: 158.153\n",
      "[144]\tvalid_0's tweedie: 158.152\n",
      "[145]\tvalid_0's tweedie: 158.149\n",
      "[146]\tvalid_0's tweedie: 158.149\n",
      "[147]\tvalid_0's tweedie: 158.15\n",
      "[148]\tvalid_0's tweedie: 158.149\n",
      "[149]\tvalid_0's tweedie: 158.149\n",
      "[150]\tvalid_0's tweedie: 158.148\n",
      "[151]\tvalid_0's tweedie: 158.148\n",
      "[152]\tvalid_0's tweedie: 158.148\n",
      "[153]\tvalid_0's tweedie: 158.147\n",
      "[154]\tvalid_0's tweedie: 158.147\n",
      "[155]\tvalid_0's tweedie: 158.147\n",
      "[156]\tvalid_0's tweedie: 158.147\n",
      "[157]\tvalid_0's tweedie: 158.147\n",
      "[158]\tvalid_0's tweedie: 158.147\n",
      "[159]\tvalid_0's tweedie: 158.147\n",
      "[160]\tvalid_0's tweedie: 158.146\n",
      "[161]\tvalid_0's tweedie: 158.146\n",
      "[162]\tvalid_0's tweedie: 158.146\n",
      "[163]\tvalid_0's tweedie: 158.146\n",
      "[164]\tvalid_0's tweedie: 158.146\n",
      "[165]\tvalid_0's tweedie: 158.146\n",
      "[166]\tvalid_0's tweedie: 158.146\n",
      "[167]\tvalid_0's tweedie: 158.146\n",
      "[168]\tvalid_0's tweedie: 158.146\n",
      "[169]\tvalid_0's tweedie: 158.146\n",
      "[170]\tvalid_0's tweedie: 158.146\n",
      "[171]\tvalid_0's tweedie: 158.146\n",
      "[172]\tvalid_0's tweedie: 158.145\n",
      "[173]\tvalid_0's tweedie: 158.146\n",
      "[174]\tvalid_0's tweedie: 158.145\n",
      "[175]\tvalid_0's tweedie: 158.145\n",
      "[176]\tvalid_0's tweedie: 158.145\n",
      "[177]\tvalid_0's tweedie: 158.145\n",
      "[178]\tvalid_0's tweedie: 158.143\n",
      "[179]\tvalid_0's tweedie: 158.143\n",
      "[180]\tvalid_0's tweedie: 158.142\n",
      "[181]\tvalid_0's tweedie: 158.142\n",
      "[182]\tvalid_0's tweedie: 158.142\n",
      "[183]\tvalid_0's tweedie: 158.142\n",
      "[184]\tvalid_0's tweedie: 158.142\n",
      "[185]\tvalid_0's tweedie: 158.142\n",
      "[186]\tvalid_0's tweedie: 158.142\n",
      "[187]\tvalid_0's tweedie: 158.142\n",
      "[188]\tvalid_0's tweedie: 158.142\n",
      "[189]\tvalid_0's tweedie: 158.142\n",
      "[190]\tvalid_0's tweedie: 158.142\n",
      "[191]\tvalid_0's tweedie: 158.142\n",
      "[192]\tvalid_0's tweedie: 158.141\n",
      "[193]\tvalid_0's tweedie: 158.142\n",
      "[194]\tvalid_0's tweedie: 158.141\n",
      "[195]\tvalid_0's tweedie: 158.141\n",
      "[196]\tvalid_0's tweedie: 158.141\n",
      "[197]\tvalid_0's tweedie: 158.141\n",
      "[198]\tvalid_0's tweedie: 158.141\n",
      "[199]\tvalid_0's tweedie: 158.141\n",
      "[200]\tvalid_0's tweedie: 158.141\n",
      "[201]\tvalid_0's tweedie: 158.141\n",
      "[202]\tvalid_0's tweedie: 158.141\n",
      "[203]\tvalid_0's tweedie: 158.141\n",
      "[204]\tvalid_0's tweedie: 158.141\n",
      "[205]\tvalid_0's tweedie: 158.141\n",
      "[206]\tvalid_0's tweedie: 158.141\n",
      "[207]\tvalid_0's tweedie: 158.14\n",
      "[208]\tvalid_0's tweedie: 158.14\n",
      "[209]\tvalid_0's tweedie: 158.14\n",
      "[210]\tvalid_0's tweedie: 158.14\n",
      "[211]\tvalid_0's tweedie: 158.138\n",
      "[212]\tvalid_0's tweedie: 158.138\n",
      "[213]\tvalid_0's tweedie: 158.139\n",
      "[214]\tvalid_0's tweedie: 158.139\n",
      "[215]\tvalid_0's tweedie: 158.139\n",
      "[216]\tvalid_0's tweedie: 158.139\n",
      "[217]\tvalid_0's tweedie: 158.139\n",
      "[218]\tvalid_0's tweedie: 158.138\n",
      "[219]\tvalid_0's tweedie: 158.138\n",
      "[220]\tvalid_0's tweedie: 158.138\n",
      "[221]\tvalid_0's tweedie: 158.138\n",
      "[222]\tvalid_0's tweedie: 158.138\n",
      "[223]\tvalid_0's tweedie: 158.138\n",
      "[224]\tvalid_0's tweedie: 158.138\n",
      "[225]\tvalid_0's tweedie: 158.138\n",
      "[226]\tvalid_0's tweedie: 158.138\n",
      "[227]\tvalid_0's tweedie: 158.138\n",
      "[228]\tvalid_0's tweedie: 158.138\n",
      "[229]\tvalid_0's tweedie: 158.138\n",
      "[230]\tvalid_0's tweedie: 158.138\n",
      "[231]\tvalid_0's tweedie: 158.138\n",
      "[232]\tvalid_0's tweedie: 158.138\n",
      "[233]\tvalid_0's tweedie: 158.138\n",
      "[234]\tvalid_0's tweedie: 158.138\n",
      "[235]\tvalid_0's tweedie: 158.138\n",
      "[236]\tvalid_0's tweedie: 158.138\n",
      "[237]\tvalid_0's tweedie: 158.138\n",
      "[238]\tvalid_0's tweedie: 158.138\n",
      "[239]\tvalid_0's tweedie: 158.138\n",
      "[240]\tvalid_0's tweedie: 158.138\n",
      "[241]\tvalid_0's tweedie: 158.138\n",
      "[242]\tvalid_0's tweedie: 158.138\n",
      "[243]\tvalid_0's tweedie: 158.138\n",
      "[244]\tvalid_0's tweedie: 158.138\n",
      "[245]\tvalid_0's tweedie: 158.138\n",
      "[246]\tvalid_0's tweedie: 158.138\n",
      "[247]\tvalid_0's tweedie: 158.138\n",
      "[248]\tvalid_0's tweedie: 158.138\n",
      "[249]\tvalid_0's tweedie: 158.138\n",
      "[250]\tvalid_0's tweedie: 158.138\n",
      "[251]\tvalid_0's tweedie: 158.136\n",
      "[252]\tvalid_0's tweedie: 158.136\n",
      "[253]\tvalid_0's tweedie: 158.136\n",
      "[254]\tvalid_0's tweedie: 158.136\n",
      "[255]\tvalid_0's tweedie: 158.134\n",
      "[256]\tvalid_0's tweedie: 158.132\n",
      "[257]\tvalid_0's tweedie: 158.132\n",
      "[258]\tvalid_0's tweedie: 158.132\n",
      "[259]\tvalid_0's tweedie: 158.132\n",
      "[260]\tvalid_0's tweedie: 158.132\n",
      "[261]\tvalid_0's tweedie: 158.132\n",
      "[262]\tvalid_0's tweedie: 158.132\n",
      "[263]\tvalid_0's tweedie: 158.132\n",
      "[264]\tvalid_0's tweedie: 158.132\n",
      "[265]\tvalid_0's tweedie: 158.132\n",
      "[266]\tvalid_0's tweedie: 158.132\n",
      "[267]\tvalid_0's tweedie: 158.132\n",
      "[268]\tvalid_0's tweedie: 158.132\n",
      "[269]\tvalid_0's tweedie: 158.132\n",
      "[270]\tvalid_0's tweedie: 158.132\n",
      "[271]\tvalid_0's tweedie: 158.132\n",
      "[272]\tvalid_0's tweedie: 158.132\n",
      "[273]\tvalid_0's tweedie: 158.132\n",
      "[274]\tvalid_0's tweedie: 158.132\n",
      "[275]\tvalid_0's tweedie: 158.132\n",
      "[276]\tvalid_0's tweedie: 158.132\n",
      "[277]\tvalid_0's tweedie: 158.132\n",
      "[278]\tvalid_0's tweedie: 158.131\n",
      "[279]\tvalid_0's tweedie: 158.131\n",
      "[280]\tvalid_0's tweedie: 158.131\n",
      "[281]\tvalid_0's tweedie: 158.131\n",
      "[282]\tvalid_0's tweedie: 158.131\n",
      "[283]\tvalid_0's tweedie: 158.131\n",
      "[284]\tvalid_0's tweedie: 158.132\n",
      "[285]\tvalid_0's tweedie: 158.132\n",
      "[286]\tvalid_0's tweedie: 158.131\n",
      "[287]\tvalid_0's tweedie: 158.131\n",
      "[288]\tvalid_0's tweedie: 158.132\n",
      "[289]\tvalid_0's tweedie: 158.132\n",
      "[290]\tvalid_0's tweedie: 158.132\n",
      "[291]\tvalid_0's tweedie: 158.132\n",
      "[292]\tvalid_0's tweedie: 158.132\n",
      "[293]\tvalid_0's tweedie: 158.132\n",
      "[294]\tvalid_0's tweedie: 158.132\n",
      "[295]\tvalid_0's tweedie: 158.132\n",
      "[296]\tvalid_0's tweedie: 158.132\n",
      "[297]\tvalid_0's tweedie: 158.132\n",
      "[298]\tvalid_0's tweedie: 158.13\n",
      "[299]\tvalid_0's tweedie: 158.13\n",
      "[300]\tvalid_0's tweedie: 158.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 158.13\n",
      "Training model for level 7 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 39081, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.398830\n",
      "[1]\tvalid_0's tweedie: 176.846\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.8\n",
      "[3]\tvalid_0's tweedie: 171.213\n",
      "[4]\tvalid_0's tweedie: 169.052\n",
      "[5]\tvalid_0's tweedie: 167.218\n",
      "[6]\tvalid_0's tweedie: 165.68\n",
      "[7]\tvalid_0's tweedie: 164.386\n",
      "[8]\tvalid_0's tweedie: 163.329\n",
      "[9]\tvalid_0's tweedie: 162.46\n",
      "[10]\tvalid_0's tweedie: 161.745\n",
      "[11]\tvalid_0's tweedie: 161.13\n",
      "[12]\tvalid_0's tweedie: 160.626\n",
      "[13]\tvalid_0's tweedie: 160.209\n",
      "[14]\tvalid_0's tweedie: 159.87\n",
      "[15]\tvalid_0's tweedie: 159.578\n",
      "[16]\tvalid_0's tweedie: 159.349\n",
      "[17]\tvalid_0's tweedie: 159.154\n",
      "[18]\tvalid_0's tweedie: 158.989\n",
      "[19]\tvalid_0's tweedie: 158.869\n",
      "[20]\tvalid_0's tweedie: 158.762\n",
      "[21]\tvalid_0's tweedie: 158.667\n",
      "[22]\tvalid_0's tweedie: 158.593\n",
      "[23]\tvalid_0's tweedie: 158.529\n",
      "[24]\tvalid_0's tweedie: 158.477\n",
      "[25]\tvalid_0's tweedie: 158.434\n",
      "[26]\tvalid_0's tweedie: 158.395\n",
      "[27]\tvalid_0's tweedie: 158.362\n",
      "[28]\tvalid_0's tweedie: 158.339\n",
      "[29]\tvalid_0's tweedie: 158.315\n",
      "[30]\tvalid_0's tweedie: 158.301\n",
      "[31]\tvalid_0's tweedie: 158.285\n",
      "[32]\tvalid_0's tweedie: 158.271\n",
      "[33]\tvalid_0's tweedie: 158.264\n",
      "[34]\tvalid_0's tweedie: 158.255\n",
      "[35]\tvalid_0's tweedie: 158.248\n",
      "[36]\tvalid_0's tweedie: 158.241\n",
      "[37]\tvalid_0's tweedie: 158.234\n",
      "[38]\tvalid_0's tweedie: 158.23\n",
      "[39]\tvalid_0's tweedie: 158.222\n",
      "[40]\tvalid_0's tweedie: 158.219\n",
      "[41]\tvalid_0's tweedie: 158.216\n",
      "[42]\tvalid_0's tweedie: 158.213\n",
      "[43]\tvalid_0's tweedie: 158.208\n",
      "[44]\tvalid_0's tweedie: 158.205\n",
      "[45]\tvalid_0's tweedie: 158.2\n",
      "[46]\tvalid_0's tweedie: 158.199\n",
      "[47]\tvalid_0's tweedie: 158.198\n",
      "[48]\tvalid_0's tweedie: 158.197\n",
      "[49]\tvalid_0's tweedie: 158.197\n",
      "[50]\tvalid_0's tweedie: 158.195\n",
      "[51]\tvalid_0's tweedie: 158.194\n",
      "[52]\tvalid_0's tweedie: 158.194\n",
      "[53]\tvalid_0's tweedie: 158.193\n",
      "[54]\tvalid_0's tweedie: 158.193\n",
      "[55]\tvalid_0's tweedie: 158.192\n",
      "[56]\tvalid_0's tweedie: 158.192\n",
      "[57]\tvalid_0's tweedie: 158.192\n",
      "[58]\tvalid_0's tweedie: 158.191\n",
      "[59]\tvalid_0's tweedie: 158.189\n",
      "[60]\tvalid_0's tweedie: 158.187\n",
      "[61]\tvalid_0's tweedie: 158.188\n",
      "[62]\tvalid_0's tweedie: 158.187\n",
      "[63]\tvalid_0's tweedie: 158.185\n",
      "[64]\tvalid_0's tweedie: 158.185\n",
      "[65]\tvalid_0's tweedie: 158.185\n",
      "[66]\tvalid_0's tweedie: 158.185\n",
      "[67]\tvalid_0's tweedie: 158.185\n",
      "[68]\tvalid_0's tweedie: 158.185\n",
      "[69]\tvalid_0's tweedie: 158.185\n",
      "[70]\tvalid_0's tweedie: 158.185\n",
      "[71]\tvalid_0's tweedie: 158.182\n",
      "[72]\tvalid_0's tweedie: 158.181\n",
      "[73]\tvalid_0's tweedie: 158.181\n",
      "[74]\tvalid_0's tweedie: 158.18\n",
      "[75]\tvalid_0's tweedie: 158.18\n",
      "[76]\tvalid_0's tweedie: 158.18\n",
      "[77]\tvalid_0's tweedie: 158.179\n",
      "[78]\tvalid_0's tweedie: 158.172\n",
      "[79]\tvalid_0's tweedie: 158.172\n",
      "[80]\tvalid_0's tweedie: 158.172\n",
      "[81]\tvalid_0's tweedie: 158.169\n",
      "[82]\tvalid_0's tweedie: 158.169\n",
      "[83]\tvalid_0's tweedie: 158.169\n",
      "[84]\tvalid_0's tweedie: 158.169\n",
      "[85]\tvalid_0's tweedie: 158.168\n",
      "[86]\tvalid_0's tweedie: 158.166\n",
      "[87]\tvalid_0's tweedie: 158.163\n",
      "[88]\tvalid_0's tweedie: 158.163\n",
      "[89]\tvalid_0's tweedie: 158.163\n",
      "[90]\tvalid_0's tweedie: 158.163\n",
      "[91]\tvalid_0's tweedie: 158.163\n",
      "[92]\tvalid_0's tweedie: 158.163\n",
      "[93]\tvalid_0's tweedie: 158.162\n",
      "[94]\tvalid_0's tweedie: 158.156\n",
      "[95]\tvalid_0's tweedie: 158.156\n",
      "[96]\tvalid_0's tweedie: 158.156\n",
      "[97]\tvalid_0's tweedie: 158.156\n",
      "[98]\tvalid_0's tweedie: 158.156\n",
      "[99]\tvalid_0's tweedie: 158.156\n",
      "[100]\tvalid_0's tweedie: 158.155\n",
      "[101]\tvalid_0's tweedie: 158.155\n",
      "[102]\tvalid_0's tweedie: 158.155\n",
      "[103]\tvalid_0's tweedie: 158.155\n",
      "[104]\tvalid_0's tweedie: 158.15\n",
      "[105]\tvalid_0's tweedie: 158.15\n",
      "[106]\tvalid_0's tweedie: 158.15\n",
      "[107]\tvalid_0's tweedie: 158.148\n",
      "[108]\tvalid_0's tweedie: 158.148\n",
      "[109]\tvalid_0's tweedie: 158.148\n",
      "[110]\tvalid_0's tweedie: 158.148\n",
      "[111]\tvalid_0's tweedie: 158.148\n",
      "[112]\tvalid_0's tweedie: 158.148\n",
      "[113]\tvalid_0's tweedie: 158.148\n",
      "[114]\tvalid_0's tweedie: 158.148\n",
      "[115]\tvalid_0's tweedie: 158.148\n",
      "[116]\tvalid_0's tweedie: 158.147\n",
      "[117]\tvalid_0's tweedie: 158.147\n",
      "[118]\tvalid_0's tweedie: 158.147\n",
      "[119]\tvalid_0's tweedie: 158.147\n",
      "[120]\tvalid_0's tweedie: 158.147\n",
      "[121]\tvalid_0's tweedie: 158.147\n",
      "[122]\tvalid_0's tweedie: 158.147\n",
      "[123]\tvalid_0's tweedie: 158.147\n",
      "[124]\tvalid_0's tweedie: 158.147\n",
      "[125]\tvalid_0's tweedie: 158.147\n",
      "[126]\tvalid_0's tweedie: 158.147\n",
      "[127]\tvalid_0's tweedie: 158.146\n",
      "[128]\tvalid_0's tweedie: 158.146\n",
      "[129]\tvalid_0's tweedie: 158.146\n",
      "[130]\tvalid_0's tweedie: 158.146\n",
      "[131]\tvalid_0's tweedie: 158.146\n",
      "[132]\tvalid_0's tweedie: 158.146\n",
      "[133]\tvalid_0's tweedie: 158.146\n",
      "[134]\tvalid_0's tweedie: 158.146\n",
      "[135]\tvalid_0's tweedie: 158.146\n",
      "[136]\tvalid_0's tweedie: 158.146\n",
      "[137]\tvalid_0's tweedie: 158.146\n",
      "[138]\tvalid_0's tweedie: 158.146\n",
      "[139]\tvalid_0's tweedie: 158.146\n",
      "[140]\tvalid_0's tweedie: 158.145\n",
      "[141]\tvalid_0's tweedie: 158.145\n",
      "[142]\tvalid_0's tweedie: 158.146\n",
      "[143]\tvalid_0's tweedie: 158.146\n",
      "[144]\tvalid_0's tweedie: 158.145\n",
      "[145]\tvalid_0's tweedie: 158.146\n",
      "[146]\tvalid_0's tweedie: 158.146\n",
      "[147]\tvalid_0's tweedie: 158.146\n",
      "[148]\tvalid_0's tweedie: 158.146\n",
      "[149]\tvalid_0's tweedie: 158.146\n",
      "[150]\tvalid_0's tweedie: 158.143\n",
      "[151]\tvalid_0's tweedie: 158.143\n",
      "[152]\tvalid_0's tweedie: 158.143\n",
      "[153]\tvalid_0's tweedie: 158.143\n",
      "[154]\tvalid_0's tweedie: 158.143\n",
      "[155]\tvalid_0's tweedie: 158.143\n",
      "[156]\tvalid_0's tweedie: 158.143\n",
      "[157]\tvalid_0's tweedie: 158.143\n",
      "[158]\tvalid_0's tweedie: 158.143\n",
      "[159]\tvalid_0's tweedie: 158.143\n",
      "[160]\tvalid_0's tweedie: 158.143\n",
      "[161]\tvalid_0's tweedie: 158.143\n",
      "[162]\tvalid_0's tweedie: 158.14\n",
      "[163]\tvalid_0's tweedie: 158.14\n",
      "[164]\tvalid_0's tweedie: 158.14\n",
      "[165]\tvalid_0's tweedie: 158.14\n",
      "[166]\tvalid_0's tweedie: 158.14\n",
      "[167]\tvalid_0's tweedie: 158.14\n",
      "[168]\tvalid_0's tweedie: 158.14\n",
      "[169]\tvalid_0's tweedie: 158.138\n",
      "[170]\tvalid_0's tweedie: 158.137\n",
      "[171]\tvalid_0's tweedie: 158.137\n",
      "[172]\tvalid_0's tweedie: 158.137\n",
      "[173]\tvalid_0's tweedie: 158.137\n",
      "[174]\tvalid_0's tweedie: 158.136\n",
      "[175]\tvalid_0's tweedie: 158.136\n",
      "[176]\tvalid_0's tweedie: 158.137\n",
      "[177]\tvalid_0's tweedie: 158.136\n",
      "[178]\tvalid_0's tweedie: 158.136\n",
      "[179]\tvalid_0's tweedie: 158.137\n",
      "[180]\tvalid_0's tweedie: 158.137\n",
      "[181]\tvalid_0's tweedie: 158.136\n",
      "[182]\tvalid_0's tweedie: 158.137\n",
      "[183]\tvalid_0's tweedie: 158.137\n",
      "[184]\tvalid_0's tweedie: 158.136\n",
      "[185]\tvalid_0's tweedie: 158.136\n",
      "[186]\tvalid_0's tweedie: 158.137\n",
      "[187]\tvalid_0's tweedie: 158.137\n",
      "[188]\tvalid_0's tweedie: 158.137\n",
      "[189]\tvalid_0's tweedie: 158.137\n",
      "[190]\tvalid_0's tweedie: 158.137\n",
      "[191]\tvalid_0's tweedie: 158.135\n",
      "[192]\tvalid_0's tweedie: 158.135\n",
      "[193]\tvalid_0's tweedie: 158.135\n",
      "[194]\tvalid_0's tweedie: 158.135\n",
      "[195]\tvalid_0's tweedie: 158.135\n",
      "[196]\tvalid_0's tweedie: 158.135\n",
      "[197]\tvalid_0's tweedie: 158.135\n",
      "[198]\tvalid_0's tweedie: 158.135\n",
      "[199]\tvalid_0's tweedie: 158.135\n",
      "[200]\tvalid_0's tweedie: 158.135\n",
      "[201]\tvalid_0's tweedie: 158.135\n",
      "[202]\tvalid_0's tweedie: 158.135\n",
      "[203]\tvalid_0's tweedie: 158.135\n",
      "[204]\tvalid_0's tweedie: 158.135\n",
      "[205]\tvalid_0's tweedie: 158.135\n",
      "[206]\tvalid_0's tweedie: 158.135\n",
      "[207]\tvalid_0's tweedie: 158.134\n",
      "[208]\tvalid_0's tweedie: 158.134\n",
      "[209]\tvalid_0's tweedie: 158.134\n",
      "[210]\tvalid_0's tweedie: 158.134\n",
      "[211]\tvalid_0's tweedie: 158.134\n",
      "[212]\tvalid_0's tweedie: 158.134\n",
      "[213]\tvalid_0's tweedie: 158.134\n",
      "[214]\tvalid_0's tweedie: 158.134\n",
      "[215]\tvalid_0's tweedie: 158.134\n",
      "[216]\tvalid_0's tweedie: 158.134\n",
      "[217]\tvalid_0's tweedie: 158.134\n",
      "[218]\tvalid_0's tweedie: 158.134\n",
      "[219]\tvalid_0's tweedie: 158.134\n",
      "[220]\tvalid_0's tweedie: 158.134\n",
      "[221]\tvalid_0's tweedie: 158.134\n",
      "[222]\tvalid_0's tweedie: 158.134\n",
      "[223]\tvalid_0's tweedie: 158.134\n",
      "[224]\tvalid_0's tweedie: 158.134\n",
      "[225]\tvalid_0's tweedie: 158.134\n",
      "[226]\tvalid_0's tweedie: 158.134\n",
      "[227]\tvalid_0's tweedie: 158.135\n",
      "[228]\tvalid_0's tweedie: 158.135\n",
      "[229]\tvalid_0's tweedie: 158.135\n",
      "[230]\tvalid_0's tweedie: 158.134\n",
      "[231]\tvalid_0's tweedie: 158.134\n",
      "[232]\tvalid_0's tweedie: 158.132\n",
      "[233]\tvalid_0's tweedie: 158.132\n",
      "[234]\tvalid_0's tweedie: 158.132\n",
      "[235]\tvalid_0's tweedie: 158.132\n",
      "[236]\tvalid_0's tweedie: 158.132\n",
      "[237]\tvalid_0's tweedie: 158.132\n",
      "[238]\tvalid_0's tweedie: 158.132\n",
      "[239]\tvalid_0's tweedie: 158.132\n",
      "[240]\tvalid_0's tweedie: 158.132\n",
      "[241]\tvalid_0's tweedie: 158.132\n",
      "[242]\tvalid_0's tweedie: 158.132\n",
      "[243]\tvalid_0's tweedie: 158.132\n",
      "[244]\tvalid_0's tweedie: 158.132\n",
      "[245]\tvalid_0's tweedie: 158.132\n",
      "[246]\tvalid_0's tweedie: 158.131\n",
      "[247]\tvalid_0's tweedie: 158.131\n",
      "[248]\tvalid_0's tweedie: 158.131\n",
      "[249]\tvalid_0's tweedie: 158.131\n",
      "[250]\tvalid_0's tweedie: 158.131\n",
      "[251]\tvalid_0's tweedie: 158.131\n",
      "[252]\tvalid_0's tweedie: 158.131\n",
      "[253]\tvalid_0's tweedie: 158.131\n",
      "[254]\tvalid_0's tweedie: 158.131\n",
      "[255]\tvalid_0's tweedie: 158.131\n",
      "[256]\tvalid_0's tweedie: 158.131\n",
      "[257]\tvalid_0's tweedie: 158.131\n",
      "[258]\tvalid_0's tweedie: 158.131\n",
      "[259]\tvalid_0's tweedie: 158.133\n",
      "[260]\tvalid_0's tweedie: 158.133\n",
      "[261]\tvalid_0's tweedie: 158.133\n",
      "[262]\tvalid_0's tweedie: 158.133\n",
      "[263]\tvalid_0's tweedie: 158.133\n",
      "[264]\tvalid_0's tweedie: 158.133\n",
      "[265]\tvalid_0's tweedie: 158.133\n",
      "[266]\tvalid_0's tweedie: 158.133\n",
      "[267]\tvalid_0's tweedie: 158.133\n",
      "[268]\tvalid_0's tweedie: 158.133\n",
      "[269]\tvalid_0's tweedie: 158.133\n",
      "[270]\tvalid_0's tweedie: 158.133\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's tweedie: 158.131\n",
      "Training model for level 7 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 39060, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399047\n",
      "[1]\tvalid_0's tweedie: 176.85\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.821\n",
      "[3]\tvalid_0's tweedie: 171.226\n",
      "[4]\tvalid_0's tweedie: 169.036\n",
      "[5]\tvalid_0's tweedie: 167.22\n",
      "[6]\tvalid_0's tweedie: 165.68\n",
      "[7]\tvalid_0's tweedie: 164.441\n",
      "[8]\tvalid_0's tweedie: 163.355\n",
      "[9]\tvalid_0's tweedie: 162.457\n",
      "[10]\tvalid_0's tweedie: 161.71\n",
      "[11]\tvalid_0's tweedie: 161.126\n",
      "[12]\tvalid_0's tweedie: 160.62\n",
      "[13]\tvalid_0's tweedie: 160.216\n",
      "[14]\tvalid_0's tweedie: 159.889\n",
      "[15]\tvalid_0's tweedie: 159.6\n",
      "[16]\tvalid_0's tweedie: 159.366\n",
      "[17]\tvalid_0's tweedie: 159.166\n",
      "[18]\tvalid_0's tweedie: 159.004\n",
      "[19]\tvalid_0's tweedie: 158.869\n",
      "[20]\tvalid_0's tweedie: 158.759\n",
      "[21]\tvalid_0's tweedie: 158.666\n",
      "[22]\tvalid_0's tweedie: 158.592\n",
      "[23]\tvalid_0's tweedie: 158.528\n",
      "[24]\tvalid_0's tweedie: 158.475\n",
      "[25]\tvalid_0's tweedie: 158.429\n",
      "[26]\tvalid_0's tweedie: 158.398\n",
      "[27]\tvalid_0's tweedie: 158.372\n",
      "[28]\tvalid_0's tweedie: 158.349\n",
      "[29]\tvalid_0's tweedie: 158.329\n",
      "[30]\tvalid_0's tweedie: 158.313\n",
      "[31]\tvalid_0's tweedie: 158.301\n",
      "[32]\tvalid_0's tweedie: 158.286\n",
      "[33]\tvalid_0's tweedie: 158.273\n",
      "[34]\tvalid_0's tweedie: 158.26\n",
      "[35]\tvalid_0's tweedie: 158.249\n",
      "[36]\tvalid_0's tweedie: 158.243\n",
      "[37]\tvalid_0's tweedie: 158.236\n",
      "[38]\tvalid_0's tweedie: 158.232\n",
      "[39]\tvalid_0's tweedie: 158.227\n",
      "[40]\tvalid_0's tweedie: 158.224\n",
      "[41]\tvalid_0's tweedie: 158.221\n",
      "[42]\tvalid_0's tweedie: 158.218\n",
      "[43]\tvalid_0's tweedie: 158.217\n",
      "[44]\tvalid_0's tweedie: 158.215\n",
      "[45]\tvalid_0's tweedie: 158.213\n",
      "[46]\tvalid_0's tweedie: 158.213\n",
      "[47]\tvalid_0's tweedie: 158.211\n",
      "[48]\tvalid_0's tweedie: 158.209\n",
      "[49]\tvalid_0's tweedie: 158.205\n",
      "[50]\tvalid_0's tweedie: 158.204\n",
      "[51]\tvalid_0's tweedie: 158.203\n",
      "[52]\tvalid_0's tweedie: 158.202\n",
      "[53]\tvalid_0's tweedie: 158.201\n",
      "[54]\tvalid_0's tweedie: 158.2\n",
      "[55]\tvalid_0's tweedie: 158.2\n",
      "[56]\tvalid_0's tweedie: 158.198\n",
      "[57]\tvalid_0's tweedie: 158.195\n",
      "[58]\tvalid_0's tweedie: 158.196\n",
      "[59]\tvalid_0's tweedie: 158.196\n",
      "[60]\tvalid_0's tweedie: 158.195\n",
      "[61]\tvalid_0's tweedie: 158.195\n",
      "[62]\tvalid_0's tweedie: 158.194\n",
      "[63]\tvalid_0's tweedie: 158.194\n",
      "[64]\tvalid_0's tweedie: 158.193\n",
      "[65]\tvalid_0's tweedie: 158.192\n",
      "[66]\tvalid_0's tweedie: 158.189\n",
      "[67]\tvalid_0's tweedie: 158.189\n",
      "[68]\tvalid_0's tweedie: 158.189\n",
      "[69]\tvalid_0's tweedie: 158.189\n",
      "[70]\tvalid_0's tweedie: 158.188\n",
      "[71]\tvalid_0's tweedie: 158.185\n",
      "[72]\tvalid_0's tweedie: 158.185\n",
      "[73]\tvalid_0's tweedie: 158.185\n",
      "[74]\tvalid_0's tweedie: 158.184\n",
      "[75]\tvalid_0's tweedie: 158.184\n",
      "[76]\tvalid_0's tweedie: 158.183\n",
      "[77]\tvalid_0's tweedie: 158.177\n",
      "[78]\tvalid_0's tweedie: 158.177\n",
      "[79]\tvalid_0's tweedie: 158.176\n",
      "[80]\tvalid_0's tweedie: 158.177\n",
      "[81]\tvalid_0's tweedie: 158.177\n",
      "[82]\tvalid_0's tweedie: 158.177\n",
      "[83]\tvalid_0's tweedie: 158.177\n",
      "[84]\tvalid_0's tweedie: 158.176\n",
      "[85]\tvalid_0's tweedie: 158.168\n",
      "[86]\tvalid_0's tweedie: 158.168\n",
      "[87]\tvalid_0's tweedie: 158.163\n",
      "[88]\tvalid_0's tweedie: 158.161\n",
      "[89]\tvalid_0's tweedie: 158.16\n",
      "[90]\tvalid_0's tweedie: 158.158\n",
      "[91]\tvalid_0's tweedie: 158.159\n",
      "[92]\tvalid_0's tweedie: 158.158\n",
      "[93]\tvalid_0's tweedie: 158.158\n",
      "[94]\tvalid_0's tweedie: 158.158\n",
      "[95]\tvalid_0's tweedie: 158.158\n",
      "[96]\tvalid_0's tweedie: 158.158\n",
      "[97]\tvalid_0's tweedie: 158.157\n",
      "[98]\tvalid_0's tweedie: 158.157\n",
      "[99]\tvalid_0's tweedie: 158.157\n",
      "[100]\tvalid_0's tweedie: 158.156\n",
      "[101]\tvalid_0's tweedie: 158.157\n",
      "[102]\tvalid_0's tweedie: 158.157\n",
      "[103]\tvalid_0's tweedie: 158.156\n",
      "[104]\tvalid_0's tweedie: 158.156\n",
      "[105]\tvalid_0's tweedie: 158.156\n",
      "[106]\tvalid_0's tweedie: 158.156\n",
      "[107]\tvalid_0's tweedie: 158.156\n",
      "[108]\tvalid_0's tweedie: 158.156\n",
      "[109]\tvalid_0's tweedie: 158.156\n",
      "[110]\tvalid_0's tweedie: 158.156\n",
      "[111]\tvalid_0's tweedie: 158.156\n",
      "[112]\tvalid_0's tweedie: 158.156\n",
      "[113]\tvalid_0's tweedie: 158.156\n",
      "[114]\tvalid_0's tweedie: 158.156\n",
      "[115]\tvalid_0's tweedie: 158.149\n",
      "[116]\tvalid_0's tweedie: 158.149\n",
      "[117]\tvalid_0's tweedie: 158.149\n",
      "[118]\tvalid_0's tweedie: 158.149\n",
      "[119]\tvalid_0's tweedie: 158.149\n",
      "[120]\tvalid_0's tweedie: 158.15\n",
      "[121]\tvalid_0's tweedie: 158.15\n",
      "[122]\tvalid_0's tweedie: 158.15\n",
      "[123]\tvalid_0's tweedie: 158.149\n",
      "[124]\tvalid_0's tweedie: 158.149\n",
      "[125]\tvalid_0's tweedie: 158.148\n",
      "[126]\tvalid_0's tweedie: 158.149\n",
      "[127]\tvalid_0's tweedie: 158.144\n",
      "[128]\tvalid_0's tweedie: 158.144\n",
      "[129]\tvalid_0's tweedie: 158.143\n",
      "[130]\tvalid_0's tweedie: 158.143\n",
      "[131]\tvalid_0's tweedie: 158.143\n",
      "[132]\tvalid_0's tweedie: 158.143\n",
      "[133]\tvalid_0's tweedie: 158.143\n",
      "[134]\tvalid_0's tweedie: 158.14\n",
      "[135]\tvalid_0's tweedie: 158.14\n",
      "[136]\tvalid_0's tweedie: 158.14\n",
      "[137]\tvalid_0's tweedie: 158.14\n",
      "[138]\tvalid_0's tweedie: 158.14\n",
      "[139]\tvalid_0's tweedie: 158.14\n",
      "[140]\tvalid_0's tweedie: 158.14\n",
      "[141]\tvalid_0's tweedie: 158.14\n",
      "[142]\tvalid_0's tweedie: 158.14\n",
      "[143]\tvalid_0's tweedie: 158.14\n",
      "[144]\tvalid_0's tweedie: 158.14\n",
      "[145]\tvalid_0's tweedie: 158.139\n",
      "[146]\tvalid_0's tweedie: 158.139\n",
      "[147]\tvalid_0's tweedie: 158.139\n",
      "[148]\tvalid_0's tweedie: 158.139\n",
      "[149]\tvalid_0's tweedie: 158.139\n",
      "[150]\tvalid_0's tweedie: 158.139\n",
      "[151]\tvalid_0's tweedie: 158.139\n",
      "[152]\tvalid_0's tweedie: 158.139\n",
      "[153]\tvalid_0's tweedie: 158.134\n",
      "[154]\tvalid_0's tweedie: 158.134\n",
      "[155]\tvalid_0's tweedie: 158.134\n",
      "[156]\tvalid_0's tweedie: 158.134\n",
      "[157]\tvalid_0's tweedie: 158.134\n",
      "[158]\tvalid_0's tweedie: 158.132\n",
      "[159]\tvalid_0's tweedie: 158.132\n",
      "[160]\tvalid_0's tweedie: 158.132\n",
      "[161]\tvalid_0's tweedie: 158.132\n",
      "[162]\tvalid_0's tweedie: 158.132\n",
      "[163]\tvalid_0's tweedie: 158.132\n",
      "[164]\tvalid_0's tweedie: 158.132\n",
      "[165]\tvalid_0's tweedie: 158.131\n",
      "[166]\tvalid_0's tweedie: 158.131\n",
      "[167]\tvalid_0's tweedie: 158.131\n",
      "[168]\tvalid_0's tweedie: 158.131\n",
      "[169]\tvalid_0's tweedie: 158.131\n",
      "[170]\tvalid_0's tweedie: 158.129\n",
      "[171]\tvalid_0's tweedie: 158.129\n",
      "[172]\tvalid_0's tweedie: 158.129\n",
      "[173]\tvalid_0's tweedie: 158.129\n",
      "[174]\tvalid_0's tweedie: 158.129\n",
      "[175]\tvalid_0's tweedie: 158.129\n",
      "[176]\tvalid_0's tweedie: 158.129\n",
      "[177]\tvalid_0's tweedie: 158.129\n",
      "[178]\tvalid_0's tweedie: 158.129\n",
      "[179]\tvalid_0's tweedie: 158.129\n",
      "[180]\tvalid_0's tweedie: 158.129\n",
      "[181]\tvalid_0's tweedie: 158.129\n",
      "[182]\tvalid_0's tweedie: 158.129\n",
      "[183]\tvalid_0's tweedie: 158.129\n",
      "[184]\tvalid_0's tweedie: 158.129\n",
      "[185]\tvalid_0's tweedie: 158.129\n",
      "[186]\tvalid_0's tweedie: 158.129\n",
      "[187]\tvalid_0's tweedie: 158.129\n",
      "[188]\tvalid_0's tweedie: 158.129\n",
      "[189]\tvalid_0's tweedie: 158.129\n",
      "[190]\tvalid_0's tweedie: 158.129\n",
      "[191]\tvalid_0's tweedie: 158.129\n",
      "[192]\tvalid_0's tweedie: 158.129\n",
      "[193]\tvalid_0's tweedie: 158.129\n",
      "[194]\tvalid_0's tweedie: 158.129\n",
      "[195]\tvalid_0's tweedie: 158.129\n",
      "[196]\tvalid_0's tweedie: 158.129\n",
      "[197]\tvalid_0's tweedie: 158.129\n",
      "[198]\tvalid_0's tweedie: 158.129\n",
      "[199]\tvalid_0's tweedie: 158.129\n",
      "[200]\tvalid_0's tweedie: 158.129\n",
      "[201]\tvalid_0's tweedie: 158.128\n",
      "[202]\tvalid_0's tweedie: 158.128\n",
      "[203]\tvalid_0's tweedie: 158.127\n",
      "[204]\tvalid_0's tweedie: 158.127\n",
      "[205]\tvalid_0's tweedie: 158.127\n",
      "[206]\tvalid_0's tweedie: 158.127\n",
      "[207]\tvalid_0's tweedie: 158.127\n",
      "[208]\tvalid_0's tweedie: 158.127\n",
      "[209]\tvalid_0's tweedie: 158.127\n",
      "[210]\tvalid_0's tweedie: 158.127\n",
      "[211]\tvalid_0's tweedie: 158.127\n",
      "[212]\tvalid_0's tweedie: 158.127\n",
      "[213]\tvalid_0's tweedie: 158.127\n",
      "[214]\tvalid_0's tweedie: 158.127\n",
      "[215]\tvalid_0's tweedie: 158.127\n",
      "[216]\tvalid_0's tweedie: 158.126\n",
      "[217]\tvalid_0's tweedie: 158.126\n",
      "[218]\tvalid_0's tweedie: 158.126\n",
      "[219]\tvalid_0's tweedie: 158.126\n",
      "[220]\tvalid_0's tweedie: 158.126\n",
      "[221]\tvalid_0's tweedie: 158.126\n",
      "[222]\tvalid_0's tweedie: 158.126\n",
      "[223]\tvalid_0's tweedie: 158.126\n",
      "[224]\tvalid_0's tweedie: 158.126\n",
      "[225]\tvalid_0's tweedie: 158.126\n",
      "[226]\tvalid_0's tweedie: 158.127\n",
      "[227]\tvalid_0's tweedie: 158.127\n",
      "[228]\tvalid_0's tweedie: 158.127\n",
      "[229]\tvalid_0's tweedie: 158.127\n",
      "[230]\tvalid_0's tweedie: 158.127\n",
      "[231]\tvalid_0's tweedie: 158.127\n",
      "[232]\tvalid_0's tweedie: 158.127\n",
      "[233]\tvalid_0's tweedie: 158.127\n",
      "[234]\tvalid_0's tweedie: 158.127\n",
      "[235]\tvalid_0's tweedie: 158.127\n",
      "[236]\tvalid_0's tweedie: 158.127\n",
      "[237]\tvalid_0's tweedie: 158.127\n",
      "[238]\tvalid_0's tweedie: 158.127\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's tweedie: 158.126\n",
      "Training model for level 7 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 39039, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399259\n",
      "[1]\tvalid_0's tweedie: 176.861\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.831\n",
      "[3]\tvalid_0's tweedie: 171.239\n",
      "[4]\tvalid_0's tweedie: 169.063\n",
      "[5]\tvalid_0's tweedie: 167.229\n",
      "[6]\tvalid_0's tweedie: 165.691\n",
      "[7]\tvalid_0's tweedie: 164.4\n",
      "[8]\tvalid_0's tweedie: 163.326\n",
      "[9]\tvalid_0's tweedie: 162.455\n",
      "[10]\tvalid_0's tweedie: 161.743\n",
      "[11]\tvalid_0's tweedie: 161.136\n",
      "[12]\tvalid_0's tweedie: 160.625\n",
      "[13]\tvalid_0's tweedie: 160.226\n",
      "[14]\tvalid_0's tweedie: 159.876\n",
      "[15]\tvalid_0's tweedie: 159.593\n",
      "[16]\tvalid_0's tweedie: 159.352\n",
      "[17]\tvalid_0's tweedie: 159.155\n",
      "[18]\tvalid_0's tweedie: 158.992\n",
      "[19]\tvalid_0's tweedie: 158.863\n",
      "[20]\tvalid_0's tweedie: 158.756\n",
      "[21]\tvalid_0's tweedie: 158.658\n",
      "[22]\tvalid_0's tweedie: 158.583\n",
      "[23]\tvalid_0's tweedie: 158.522\n",
      "[24]\tvalid_0's tweedie: 158.465\n",
      "[25]\tvalid_0's tweedie: 158.424\n",
      "[26]\tvalid_0's tweedie: 158.389\n",
      "[27]\tvalid_0's tweedie: 158.358\n",
      "[28]\tvalid_0's tweedie: 158.331\n",
      "[29]\tvalid_0's tweedie: 158.308\n",
      "[30]\tvalid_0's tweedie: 158.293\n",
      "[31]\tvalid_0's tweedie: 158.28\n",
      "[32]\tvalid_0's tweedie: 158.266\n",
      "[33]\tvalid_0's tweedie: 158.252\n",
      "[34]\tvalid_0's tweedie: 158.245\n",
      "[35]\tvalid_0's tweedie: 158.239\n",
      "[36]\tvalid_0's tweedie: 158.232\n",
      "[37]\tvalid_0's tweedie: 158.228\n",
      "[38]\tvalid_0's tweedie: 158.225\n",
      "[39]\tvalid_0's tweedie: 158.218\n",
      "[40]\tvalid_0's tweedie: 158.216\n",
      "[41]\tvalid_0's tweedie: 158.213\n",
      "[42]\tvalid_0's tweedie: 158.208\n",
      "[43]\tvalid_0's tweedie: 158.205\n",
      "[44]\tvalid_0's tweedie: 158.203\n",
      "[45]\tvalid_0's tweedie: 158.202\n",
      "[46]\tvalid_0's tweedie: 158.199\n",
      "[47]\tvalid_0's tweedie: 158.198\n",
      "[48]\tvalid_0's tweedie: 158.197\n",
      "[49]\tvalid_0's tweedie: 158.196\n",
      "[50]\tvalid_0's tweedie: 158.195\n",
      "[51]\tvalid_0's tweedie: 158.195\n",
      "[52]\tvalid_0's tweedie: 158.194\n",
      "[53]\tvalid_0's tweedie: 158.19\n",
      "[54]\tvalid_0's tweedie: 158.19\n",
      "[55]\tvalid_0's tweedie: 158.191\n",
      "[56]\tvalid_0's tweedie: 158.191\n",
      "[57]\tvalid_0's tweedie: 158.19\n",
      "[58]\tvalid_0's tweedie: 158.189\n",
      "[59]\tvalid_0's tweedie: 158.189\n",
      "[60]\tvalid_0's tweedie: 158.188\n",
      "[61]\tvalid_0's tweedie: 158.185\n",
      "[62]\tvalid_0's tweedie: 158.185\n",
      "[63]\tvalid_0's tweedie: 158.184\n",
      "[64]\tvalid_0's tweedie: 158.182\n",
      "[65]\tvalid_0's tweedie: 158.181\n",
      "[66]\tvalid_0's tweedie: 158.18\n",
      "[67]\tvalid_0's tweedie: 158.178\n",
      "[68]\tvalid_0's tweedie: 158.178\n",
      "[69]\tvalid_0's tweedie: 158.179\n",
      "[70]\tvalid_0's tweedie: 158.176\n",
      "[71]\tvalid_0's tweedie: 158.174\n",
      "[72]\tvalid_0's tweedie: 158.173\n",
      "[73]\tvalid_0's tweedie: 158.172\n",
      "[74]\tvalid_0's tweedie: 158.164\n",
      "[75]\tvalid_0's tweedie: 158.164\n",
      "[76]\tvalid_0's tweedie: 158.163\n",
      "[77]\tvalid_0's tweedie: 158.156\n",
      "[78]\tvalid_0's tweedie: 158.156\n",
      "[79]\tvalid_0's tweedie: 158.156\n",
      "[80]\tvalid_0's tweedie: 158.155\n",
      "[81]\tvalid_0's tweedie: 158.155\n",
      "[82]\tvalid_0's tweedie: 158.154\n",
      "[83]\tvalid_0's tweedie: 158.154\n",
      "[84]\tvalid_0's tweedie: 158.154\n",
      "[85]\tvalid_0's tweedie: 158.154\n",
      "[86]\tvalid_0's tweedie: 158.154\n",
      "[87]\tvalid_0's tweedie: 158.154\n",
      "[88]\tvalid_0's tweedie: 158.154\n",
      "[89]\tvalid_0's tweedie: 158.149\n",
      "[90]\tvalid_0's tweedie: 158.148\n",
      "[91]\tvalid_0's tweedie: 158.147\n",
      "[92]\tvalid_0's tweedie: 158.147\n",
      "[93]\tvalid_0's tweedie: 158.147\n",
      "[94]\tvalid_0's tweedie: 158.147\n",
      "[95]\tvalid_0's tweedie: 158.147\n",
      "[96]\tvalid_0's tweedie: 158.147\n",
      "[97]\tvalid_0's tweedie: 158.147\n",
      "[98]\tvalid_0's tweedie: 158.147\n",
      "[99]\tvalid_0's tweedie: 158.146\n",
      "[100]\tvalid_0's tweedie: 158.147\n",
      "[101]\tvalid_0's tweedie: 158.147\n",
      "[102]\tvalid_0's tweedie: 158.143\n",
      "[103]\tvalid_0's tweedie: 158.143\n",
      "[104]\tvalid_0's tweedie: 158.14\n",
      "[105]\tvalid_0's tweedie: 158.14\n",
      "[106]\tvalid_0's tweedie: 158.14\n",
      "[107]\tvalid_0's tweedie: 158.14\n",
      "[108]\tvalid_0's tweedie: 158.14\n",
      "[109]\tvalid_0's tweedie: 158.14\n",
      "[110]\tvalid_0's tweedie: 158.14\n",
      "[111]\tvalid_0's tweedie: 158.14\n",
      "[112]\tvalid_0's tweedie: 158.139\n",
      "[113]\tvalid_0's tweedie: 158.139\n",
      "[114]\tvalid_0's tweedie: 158.138\n",
      "[115]\tvalid_0's tweedie: 158.138\n",
      "[116]\tvalid_0's tweedie: 158.135\n",
      "[117]\tvalid_0's tweedie: 158.135\n",
      "[118]\tvalid_0's tweedie: 158.135\n",
      "[119]\tvalid_0's tweedie: 158.134\n",
      "[120]\tvalid_0's tweedie: 158.134\n",
      "[121]\tvalid_0's tweedie: 158.134\n",
      "[122]\tvalid_0's tweedie: 158.134\n",
      "[123]\tvalid_0's tweedie: 158.134\n",
      "[124]\tvalid_0's tweedie: 158.133\n",
      "[125]\tvalid_0's tweedie: 158.133\n",
      "[126]\tvalid_0's tweedie: 158.133\n",
      "[127]\tvalid_0's tweedie: 158.133\n",
      "[128]\tvalid_0's tweedie: 158.134\n",
      "[129]\tvalid_0's tweedie: 158.134\n",
      "[130]\tvalid_0's tweedie: 158.133\n",
      "[131]\tvalid_0's tweedie: 158.129\n",
      "[132]\tvalid_0's tweedie: 158.129\n",
      "[133]\tvalid_0's tweedie: 158.129\n",
      "[134]\tvalid_0's tweedie: 158.129\n",
      "[135]\tvalid_0's tweedie: 158.129\n",
      "[136]\tvalid_0's tweedie: 158.13\n",
      "[137]\tvalid_0's tweedie: 158.129\n",
      "[138]\tvalid_0's tweedie: 158.128\n",
      "[139]\tvalid_0's tweedie: 158.128\n",
      "[140]\tvalid_0's tweedie: 158.127\n",
      "[141]\tvalid_0's tweedie: 158.127\n",
      "[142]\tvalid_0's tweedie: 158.127\n",
      "[143]\tvalid_0's tweedie: 158.127\n",
      "[144]\tvalid_0's tweedie: 158.127\n",
      "[145]\tvalid_0's tweedie: 158.127\n",
      "[146]\tvalid_0's tweedie: 158.127\n",
      "[147]\tvalid_0's tweedie: 158.127\n",
      "[148]\tvalid_0's tweedie: 158.127\n",
      "[149]\tvalid_0's tweedie: 158.127\n",
      "[150]\tvalid_0's tweedie: 158.127\n",
      "[151]\tvalid_0's tweedie: 158.127\n",
      "[152]\tvalid_0's tweedie: 158.127\n",
      "[153]\tvalid_0's tweedie: 158.127\n",
      "[154]\tvalid_0's tweedie: 158.126\n",
      "[155]\tvalid_0's tweedie: 158.126\n",
      "[156]\tvalid_0's tweedie: 158.126\n",
      "[157]\tvalid_0's tweedie: 158.126\n",
      "[158]\tvalid_0's tweedie: 158.127\n",
      "[159]\tvalid_0's tweedie: 158.125\n",
      "[160]\tvalid_0's tweedie: 158.125\n",
      "[161]\tvalid_0's tweedie: 158.125\n",
      "[162]\tvalid_0's tweedie: 158.125\n",
      "[163]\tvalid_0's tweedie: 158.125\n",
      "[164]\tvalid_0's tweedie: 158.125\n",
      "[165]\tvalid_0's tweedie: 158.124\n",
      "[166]\tvalid_0's tweedie: 158.125\n",
      "[167]\tvalid_0's tweedie: 158.124\n",
      "[168]\tvalid_0's tweedie: 158.124\n",
      "[169]\tvalid_0's tweedie: 158.124\n",
      "[170]\tvalid_0's tweedie: 158.124\n",
      "[171]\tvalid_0's tweedie: 158.124\n",
      "[172]\tvalid_0's tweedie: 158.124\n",
      "[173]\tvalid_0's tweedie: 158.124\n",
      "[174]\tvalid_0's tweedie: 158.124\n",
      "[175]\tvalid_0's tweedie: 158.124\n",
      "[176]\tvalid_0's tweedie: 158.124\n",
      "[177]\tvalid_0's tweedie: 158.124\n",
      "[178]\tvalid_0's tweedie: 158.123\n",
      "[179]\tvalid_0's tweedie: 158.123\n",
      "[180]\tvalid_0's tweedie: 158.121\n",
      "[181]\tvalid_0's tweedie: 158.121\n",
      "[182]\tvalid_0's tweedie: 158.121\n",
      "[183]\tvalid_0's tweedie: 158.121\n",
      "[184]\tvalid_0's tweedie: 158.121\n",
      "[185]\tvalid_0's tweedie: 158.121\n",
      "[186]\tvalid_0's tweedie: 158.121\n",
      "[187]\tvalid_0's tweedie: 158.121\n",
      "[188]\tvalid_0's tweedie: 158.121\n",
      "[189]\tvalid_0's tweedie: 158.121\n",
      "[190]\tvalid_0's tweedie: 158.121\n",
      "[191]\tvalid_0's tweedie: 158.121\n",
      "[192]\tvalid_0's tweedie: 158.121\n",
      "[193]\tvalid_0's tweedie: 158.121\n",
      "[194]\tvalid_0's tweedie: 158.121\n",
      "[195]\tvalid_0's tweedie: 158.121\n",
      "[196]\tvalid_0's tweedie: 158.119\n",
      "[197]\tvalid_0's tweedie: 158.119\n",
      "[198]\tvalid_0's tweedie: 158.118\n",
      "[199]\tvalid_0's tweedie: 158.118\n",
      "[200]\tvalid_0's tweedie: 158.118\n",
      "[201]\tvalid_0's tweedie: 158.118\n",
      "[202]\tvalid_0's tweedie: 158.118\n",
      "[203]\tvalid_0's tweedie: 158.118\n",
      "[204]\tvalid_0's tweedie: 158.118\n",
      "[205]\tvalid_0's tweedie: 158.118\n",
      "[206]\tvalid_0's tweedie: 158.118\n",
      "[207]\tvalid_0's tweedie: 158.118\n",
      "[208]\tvalid_0's tweedie: 158.118\n",
      "[209]\tvalid_0's tweedie: 158.118\n",
      "[210]\tvalid_0's tweedie: 158.118\n",
      "[211]\tvalid_0's tweedie: 158.117\n",
      "[212]\tvalid_0's tweedie: 158.118\n",
      "[213]\tvalid_0's tweedie: 158.118\n",
      "[214]\tvalid_0's tweedie: 158.118\n",
      "[215]\tvalid_0's tweedie: 158.118\n",
      "[216]\tvalid_0's tweedie: 158.118\n",
      "[217]\tvalid_0's tweedie: 158.118\n",
      "[218]\tvalid_0's tweedie: 158.118\n",
      "[219]\tvalid_0's tweedie: 158.118\n",
      "[220]\tvalid_0's tweedie: 158.118\n",
      "[221]\tvalid_0's tweedie: 158.118\n",
      "[222]\tvalid_0's tweedie: 158.118\n",
      "[223]\tvalid_0's tweedie: 158.118\n",
      "[224]\tvalid_0's tweedie: 158.118\n",
      "[225]\tvalid_0's tweedie: 158.118\n",
      "[226]\tvalid_0's tweedie: 158.118\n",
      "[227]\tvalid_0's tweedie: 158.118\n",
      "[228]\tvalid_0's tweedie: 158.118\n",
      "[229]\tvalid_0's tweedie: 158.118\n",
      "[230]\tvalid_0's tweedie: 158.118\n",
      "[231]\tvalid_0's tweedie: 158.118\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's tweedie: 158.117\n",
      "Training model for level 7 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 39018, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399480\n",
      "[1]\tvalid_0's tweedie: 176.841\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.802\n",
      "[3]\tvalid_0's tweedie: 171.198\n",
      "[4]\tvalid_0's tweedie: 169.022\n",
      "[5]\tvalid_0's tweedie: 167.178\n",
      "[6]\tvalid_0's tweedie: 165.64\n",
      "[7]\tvalid_0's tweedie: 164.348\n",
      "[8]\tvalid_0's tweedie: 163.273\n",
      "[9]\tvalid_0's tweedie: 162.377\n",
      "[10]\tvalid_0's tweedie: 161.649\n",
      "[11]\tvalid_0's tweedie: 161.051\n",
      "[12]\tvalid_0's tweedie: 160.556\n",
      "[13]\tvalid_0's tweedie: 160.157\n",
      "[14]\tvalid_0's tweedie: 159.809\n",
      "[15]\tvalid_0's tweedie: 159.52\n",
      "[16]\tvalid_0's tweedie: 159.291\n",
      "[17]\tvalid_0's tweedie: 159.107\n",
      "[18]\tvalid_0's tweedie: 158.947\n",
      "[19]\tvalid_0's tweedie: 158.817\n",
      "[20]\tvalid_0's tweedie: 158.708\n",
      "[21]\tvalid_0's tweedie: 158.617\n",
      "[22]\tvalid_0's tweedie: 158.544\n",
      "[23]\tvalid_0's tweedie: 158.48\n",
      "[24]\tvalid_0's tweedie: 158.428\n",
      "[25]\tvalid_0's tweedie: 158.388\n",
      "[26]\tvalid_0's tweedie: 158.355\n",
      "[27]\tvalid_0's tweedie: 158.323\n",
      "[28]\tvalid_0's tweedie: 158.3\n",
      "[29]\tvalid_0's tweedie: 158.282\n",
      "[30]\tvalid_0's tweedie: 158.263\n",
      "[31]\tvalid_0's tweedie: 158.252\n",
      "[32]\tvalid_0's tweedie: 158.241\n",
      "[33]\tvalid_0's tweedie: 158.234\n",
      "[34]\tvalid_0's tweedie: 158.223\n",
      "[35]\tvalid_0's tweedie: 158.217\n",
      "[36]\tvalid_0's tweedie: 158.208\n",
      "[37]\tvalid_0's tweedie: 158.202\n",
      "[38]\tvalid_0's tweedie: 158.197\n",
      "[39]\tvalid_0's tweedie: 158.192\n",
      "[40]\tvalid_0's tweedie: 158.19\n",
      "[41]\tvalid_0's tweedie: 158.187\n",
      "[42]\tvalid_0's tweedie: 158.186\n",
      "[43]\tvalid_0's tweedie: 158.185\n",
      "[44]\tvalid_0's tweedie: 158.182\n",
      "[45]\tvalid_0's tweedie: 158.181\n",
      "[46]\tvalid_0's tweedie: 158.18\n",
      "[47]\tvalid_0's tweedie: 158.176\n",
      "[48]\tvalid_0's tweedie: 158.176\n",
      "[49]\tvalid_0's tweedie: 158.175\n",
      "[50]\tvalid_0's tweedie: 158.175\n",
      "[51]\tvalid_0's tweedie: 158.175\n",
      "[52]\tvalid_0's tweedie: 158.176\n",
      "[53]\tvalid_0's tweedie: 158.175\n",
      "[54]\tvalid_0's tweedie: 158.174\n",
      "[55]\tvalid_0's tweedie: 158.173\n",
      "[56]\tvalid_0's tweedie: 158.174\n",
      "[57]\tvalid_0's tweedie: 158.175\n",
      "[58]\tvalid_0's tweedie: 158.174\n",
      "[59]\tvalid_0's tweedie: 158.174\n",
      "[60]\tvalid_0's tweedie: 158.174\n",
      "[61]\tvalid_0's tweedie: 158.174\n",
      "[62]\tvalid_0's tweedie: 158.174\n",
      "[63]\tvalid_0's tweedie: 158.174\n",
      "[64]\tvalid_0's tweedie: 158.173\n",
      "[65]\tvalid_0's tweedie: 158.173\n",
      "[66]\tvalid_0's tweedie: 158.173\n",
      "[67]\tvalid_0's tweedie: 158.17\n",
      "[68]\tvalid_0's tweedie: 158.169\n",
      "[69]\tvalid_0's tweedie: 158.17\n",
      "[70]\tvalid_0's tweedie: 158.169\n",
      "[71]\tvalid_0's tweedie: 158.161\n",
      "[72]\tvalid_0's tweedie: 158.16\n",
      "[73]\tvalid_0's tweedie: 158.16\n",
      "[74]\tvalid_0's tweedie: 158.16\n",
      "[75]\tvalid_0's tweedie: 158.153\n",
      "[76]\tvalid_0's tweedie: 158.148\n",
      "[77]\tvalid_0's tweedie: 158.146\n",
      "[78]\tvalid_0's tweedie: 158.146\n",
      "[79]\tvalid_0's tweedie: 158.146\n",
      "[80]\tvalid_0's tweedie: 158.146\n",
      "[81]\tvalid_0's tweedie: 158.146\n",
      "[82]\tvalid_0's tweedie: 158.146\n",
      "[83]\tvalid_0's tweedie: 158.146\n",
      "[84]\tvalid_0's tweedie: 158.145\n",
      "[85]\tvalid_0's tweedie: 158.145\n",
      "[86]\tvalid_0's tweedie: 158.145\n",
      "[87]\tvalid_0's tweedie: 158.145\n",
      "[88]\tvalid_0's tweedie: 158.142\n",
      "[89]\tvalid_0's tweedie: 158.141\n",
      "[90]\tvalid_0's tweedie: 158.141\n",
      "[91]\tvalid_0's tweedie: 158.14\n",
      "[92]\tvalid_0's tweedie: 158.141\n",
      "[93]\tvalid_0's tweedie: 158.14\n",
      "[94]\tvalid_0's tweedie: 158.14\n",
      "[95]\tvalid_0's tweedie: 158.14\n",
      "[96]\tvalid_0's tweedie: 158.14\n",
      "[97]\tvalid_0's tweedie: 158.14\n",
      "[98]\tvalid_0's tweedie: 158.135\n",
      "[99]\tvalid_0's tweedie: 158.135\n",
      "[100]\tvalid_0's tweedie: 158.135\n",
      "[101]\tvalid_0's tweedie: 158.135\n",
      "[102]\tvalid_0's tweedie: 158.135\n",
      "[103]\tvalid_0's tweedie: 158.135\n",
      "[104]\tvalid_0's tweedie: 158.135\n",
      "[105]\tvalid_0's tweedie: 158.135\n",
      "[106]\tvalid_0's tweedie: 158.132\n",
      "[107]\tvalid_0's tweedie: 158.131\n",
      "[108]\tvalid_0's tweedie: 158.131\n",
      "[109]\tvalid_0's tweedie: 158.129\n",
      "[110]\tvalid_0's tweedie: 158.129\n",
      "[111]\tvalid_0's tweedie: 158.129\n",
      "[112]\tvalid_0's tweedie: 158.129\n",
      "[113]\tvalid_0's tweedie: 158.129\n",
      "[114]\tvalid_0's tweedie: 158.129\n",
      "[115]\tvalid_0's tweedie: 158.129\n",
      "[116]\tvalid_0's tweedie: 158.129\n",
      "[117]\tvalid_0's tweedie: 158.129\n",
      "[118]\tvalid_0's tweedie: 158.129\n",
      "[119]\tvalid_0's tweedie: 158.128\n",
      "[120]\tvalid_0's tweedie: 158.128\n",
      "[121]\tvalid_0's tweedie: 158.127\n",
      "[122]\tvalid_0's tweedie: 158.127\n",
      "[123]\tvalid_0's tweedie: 158.127\n",
      "[124]\tvalid_0's tweedie: 158.127\n",
      "[125]\tvalid_0's tweedie: 158.127\n",
      "[126]\tvalid_0's tweedie: 158.127\n",
      "[127]\tvalid_0's tweedie: 158.127\n",
      "[128]\tvalid_0's tweedie: 158.127\n",
      "[129]\tvalid_0's tweedie: 158.127\n",
      "[130]\tvalid_0's tweedie: 158.127\n",
      "[131]\tvalid_0's tweedie: 158.127\n",
      "[132]\tvalid_0's tweedie: 158.127\n",
      "[133]\tvalid_0's tweedie: 158.127\n",
      "[134]\tvalid_0's tweedie: 158.124\n",
      "[135]\tvalid_0's tweedie: 158.123\n",
      "[136]\tvalid_0's tweedie: 158.121\n",
      "[137]\tvalid_0's tweedie: 158.121\n",
      "[138]\tvalid_0's tweedie: 158.121\n",
      "[139]\tvalid_0's tweedie: 158.122\n",
      "[140]\tvalid_0's tweedie: 158.121\n",
      "[141]\tvalid_0's tweedie: 158.121\n",
      "[142]\tvalid_0's tweedie: 158.121\n",
      "[143]\tvalid_0's tweedie: 158.121\n",
      "[144]\tvalid_0's tweedie: 158.121\n",
      "[145]\tvalid_0's tweedie: 158.121\n",
      "[146]\tvalid_0's tweedie: 158.121\n",
      "[147]\tvalid_0's tweedie: 158.121\n",
      "[148]\tvalid_0's tweedie: 158.121\n",
      "[149]\tvalid_0's tweedie: 158.121\n",
      "[150]\tvalid_0's tweedie: 158.121\n",
      "[151]\tvalid_0's tweedie: 158.121\n",
      "[152]\tvalid_0's tweedie: 158.121\n",
      "[153]\tvalid_0's tweedie: 158.12\n",
      "[154]\tvalid_0's tweedie: 158.12\n",
      "[155]\tvalid_0's tweedie: 158.12\n",
      "[156]\tvalid_0's tweedie: 158.12\n",
      "[157]\tvalid_0's tweedie: 158.12\n",
      "[158]\tvalid_0's tweedie: 158.12\n",
      "[159]\tvalid_0's tweedie: 158.12\n",
      "[160]\tvalid_0's tweedie: 158.12\n",
      "[161]\tvalid_0's tweedie: 158.12\n",
      "[162]\tvalid_0's tweedie: 158.118\n",
      "[163]\tvalid_0's tweedie: 158.118\n",
      "[164]\tvalid_0's tweedie: 158.118\n",
      "[165]\tvalid_0's tweedie: 158.118\n",
      "[166]\tvalid_0's tweedie: 158.118\n",
      "[167]\tvalid_0's tweedie: 158.117\n",
      "[168]\tvalid_0's tweedie: 158.117\n",
      "[169]\tvalid_0's tweedie: 158.117\n",
      "[170]\tvalid_0's tweedie: 158.117\n",
      "[171]\tvalid_0's tweedie: 158.116\n",
      "[172]\tvalid_0's tweedie: 158.116\n",
      "[173]\tvalid_0's tweedie: 158.116\n",
      "[174]\tvalid_0's tweedie: 158.116\n",
      "[175]\tvalid_0's tweedie: 158.116\n",
      "[176]\tvalid_0's tweedie: 158.116\n",
      "[177]\tvalid_0's tweedie: 158.116\n",
      "[178]\tvalid_0's tweedie: 158.116\n",
      "[179]\tvalid_0's tweedie: 158.116\n",
      "[180]\tvalid_0's tweedie: 158.116\n",
      "[181]\tvalid_0's tweedie: 158.116\n",
      "[182]\tvalid_0's tweedie: 158.116\n",
      "[183]\tvalid_0's tweedie: 158.116\n",
      "[184]\tvalid_0's tweedie: 158.116\n",
      "[185]\tvalid_0's tweedie: 158.116\n",
      "[186]\tvalid_0's tweedie: 158.116\n",
      "[187]\tvalid_0's tweedie: 158.116\n",
      "[188]\tvalid_0's tweedie: 158.116\n",
      "[189]\tvalid_0's tweedie: 158.116\n",
      "[190]\tvalid_0's tweedie: 158.116\n",
      "[191]\tvalid_0's tweedie: 158.116\n",
      "[192]\tvalid_0's tweedie: 158.116\n",
      "[193]\tvalid_0's tweedie: 158.116\n",
      "[194]\tvalid_0's tweedie: 158.116\n",
      "[195]\tvalid_0's tweedie: 158.116\n",
      "[196]\tvalid_0's tweedie: 158.116\n",
      "[197]\tvalid_0's tweedie: 158.116\n",
      "[198]\tvalid_0's tweedie: 158.116\n",
      "[199]\tvalid_0's tweedie: 158.116\n",
      "[200]\tvalid_0's tweedie: 158.114\n",
      "[201]\tvalid_0's tweedie: 158.114\n",
      "[202]\tvalid_0's tweedie: 158.114\n",
      "[203]\tvalid_0's tweedie: 158.114\n",
      "[204]\tvalid_0's tweedie: 158.114\n",
      "[205]\tvalid_0's tweedie: 158.114\n",
      "[206]\tvalid_0's tweedie: 158.114\n",
      "[207]\tvalid_0's tweedie: 158.114\n",
      "[208]\tvalid_0's tweedie: 158.114\n",
      "[209]\tvalid_0's tweedie: 158.114\n",
      "[210]\tvalid_0's tweedie: 158.114\n",
      "[211]\tvalid_0's tweedie: 158.114\n",
      "[212]\tvalid_0's tweedie: 158.114\n",
      "[213]\tvalid_0's tweedie: 158.114\n",
      "[214]\tvalid_0's tweedie: 158.114\n",
      "[215]\tvalid_0's tweedie: 158.114\n",
      "[216]\tvalid_0's tweedie: 158.114\n",
      "[217]\tvalid_0's tweedie: 158.114\n",
      "[218]\tvalid_0's tweedie: 158.112\n",
      "[219]\tvalid_0's tweedie: 158.112\n",
      "[220]\tvalid_0's tweedie: 158.112\n",
      "[221]\tvalid_0's tweedie: 158.112\n",
      "[222]\tvalid_0's tweedie: 158.112\n",
      "[223]\tvalid_0's tweedie: 158.112\n",
      "[224]\tvalid_0's tweedie: 158.113\n",
      "[225]\tvalid_0's tweedie: 158.113\n",
      "[226]\tvalid_0's tweedie: 158.113\n",
      "[227]\tvalid_0's tweedie: 158.113\n",
      "[228]\tvalid_0's tweedie: 158.113\n",
      "[229]\tvalid_0's tweedie: 158.113\n",
      "[230]\tvalid_0's tweedie: 158.113\n",
      "[231]\tvalid_0's tweedie: 158.113\n",
      "[232]\tvalid_0's tweedie: 158.113\n",
      "[233]\tvalid_0's tweedie: 158.113\n",
      "[234]\tvalid_0's tweedie: 158.113\n",
      "[235]\tvalid_0's tweedie: 158.113\n",
      "[236]\tvalid_0's tweedie: 158.113\n",
      "[237]\tvalid_0's tweedie: 158.113\n",
      "[238]\tvalid_0's tweedie: 158.113\n",
      "[239]\tvalid_0's tweedie: 158.113\n",
      "[240]\tvalid_0's tweedie: 158.113\n",
      "[241]\tvalid_0's tweedie: 158.113\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's tweedie: 158.112\n",
      "Training model for level 7 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 38997, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399665\n",
      "[1]\tvalid_0's tweedie: 176.792\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.704\n",
      "[3]\tvalid_0's tweedie: 171.08\n",
      "[4]\tvalid_0's tweedie: 168.877\n",
      "[5]\tvalid_0's tweedie: 167.022\n",
      "[6]\tvalid_0's tweedie: 165.486\n",
      "[7]\tvalid_0's tweedie: 164.212\n",
      "[8]\tvalid_0's tweedie: 163.143\n",
      "[9]\tvalid_0's tweedie: 162.265\n",
      "[10]\tvalid_0's tweedie: 161.531\n",
      "[11]\tvalid_0's tweedie: 160.916\n",
      "[12]\tvalid_0's tweedie: 160.417\n",
      "[13]\tvalid_0's tweedie: 159.998\n",
      "[14]\tvalid_0's tweedie: 159.667\n",
      "[15]\tvalid_0's tweedie: 159.388\n",
      "[16]\tvalid_0's tweedie: 159.165\n",
      "[17]\tvalid_0's tweedie: 158.979\n",
      "[18]\tvalid_0's tweedie: 158.827\n",
      "[19]\tvalid_0's tweedie: 158.709\n",
      "[20]\tvalid_0's tweedie: 158.607\n",
      "[21]\tvalid_0's tweedie: 158.523\n",
      "[22]\tvalid_0's tweedie: 158.457\n",
      "[23]\tvalid_0's tweedie: 158.399\n",
      "[24]\tvalid_0's tweedie: 158.35\n",
      "[25]\tvalid_0's tweedie: 158.313\n",
      "[26]\tvalid_0's tweedie: 158.285\n",
      "[27]\tvalid_0's tweedie: 158.26\n",
      "[28]\tvalid_0's tweedie: 158.239\n",
      "[29]\tvalid_0's tweedie: 158.222\n",
      "[30]\tvalid_0's tweedie: 158.209\n",
      "[31]\tvalid_0's tweedie: 158.2\n",
      "[32]\tvalid_0's tweedie: 158.189\n",
      "[33]\tvalid_0's tweedie: 158.181\n",
      "[34]\tvalid_0's tweedie: 158.173\n",
      "[35]\tvalid_0's tweedie: 158.167\n",
      "[36]\tvalid_0's tweedie: 158.162\n",
      "[37]\tvalid_0's tweedie: 158.159\n",
      "[38]\tvalid_0's tweedie: 158.156\n",
      "[39]\tvalid_0's tweedie: 158.154\n",
      "[40]\tvalid_0's tweedie: 158.153\n",
      "[41]\tvalid_0's tweedie: 158.151\n",
      "[42]\tvalid_0's tweedie: 158.149\n",
      "[43]\tvalid_0's tweedie: 158.148\n",
      "[44]\tvalid_0's tweedie: 158.148\n",
      "[45]\tvalid_0's tweedie: 158.146\n",
      "[46]\tvalid_0's tweedie: 158.146\n",
      "[47]\tvalid_0's tweedie: 158.145\n",
      "[48]\tvalid_0's tweedie: 158.144\n",
      "[49]\tvalid_0's tweedie: 158.144\n",
      "[50]\tvalid_0's tweedie: 158.143\n",
      "[51]\tvalid_0's tweedie: 158.144\n",
      "[52]\tvalid_0's tweedie: 158.144\n",
      "[53]\tvalid_0's tweedie: 158.144\n",
      "[54]\tvalid_0's tweedie: 158.143\n",
      "[55]\tvalid_0's tweedie: 158.143\n",
      "[56]\tvalid_0's tweedie: 158.144\n",
      "[57]\tvalid_0's tweedie: 158.143\n",
      "[58]\tvalid_0's tweedie: 158.142\n",
      "[59]\tvalid_0's tweedie: 158.144\n",
      "[60]\tvalid_0's tweedie: 158.142\n",
      "[61]\tvalid_0's tweedie: 158.142\n",
      "[62]\tvalid_0's tweedie: 158.141\n",
      "[63]\tvalid_0's tweedie: 158.14\n",
      "[64]\tvalid_0's tweedie: 158.139\n",
      "[65]\tvalid_0's tweedie: 158.14\n",
      "[66]\tvalid_0's tweedie: 158.139\n",
      "[67]\tvalid_0's tweedie: 158.138\n",
      "[68]\tvalid_0's tweedie: 158.138\n",
      "[69]\tvalid_0's tweedie: 158.136\n",
      "[70]\tvalid_0's tweedie: 158.135\n",
      "[71]\tvalid_0's tweedie: 158.135\n",
      "[72]\tvalid_0's tweedie: 158.135\n",
      "[73]\tvalid_0's tweedie: 158.135\n",
      "[74]\tvalid_0's tweedie: 158.135\n",
      "[75]\tvalid_0's tweedie: 158.135\n",
      "[76]\tvalid_0's tweedie: 158.135\n",
      "[77]\tvalid_0's tweedie: 158.136\n",
      "[78]\tvalid_0's tweedie: 158.136\n",
      "[79]\tvalid_0's tweedie: 158.135\n",
      "[80]\tvalid_0's tweedie: 158.135\n",
      "[81]\tvalid_0's tweedie: 158.135\n",
      "[82]\tvalid_0's tweedie: 158.134\n",
      "[83]\tvalid_0's tweedie: 158.134\n",
      "[84]\tvalid_0's tweedie: 158.134\n",
      "[85]\tvalid_0's tweedie: 158.134\n",
      "[86]\tvalid_0's tweedie: 158.128\n",
      "[87]\tvalid_0's tweedie: 158.128\n",
      "[88]\tvalid_0's tweedie: 158.128\n",
      "[89]\tvalid_0's tweedie: 158.124\n",
      "[90]\tvalid_0's tweedie: 158.123\n",
      "[91]\tvalid_0's tweedie: 158.123\n",
      "[92]\tvalid_0's tweedie: 158.123\n",
      "[93]\tvalid_0's tweedie: 158.123\n",
      "[94]\tvalid_0's tweedie: 158.123\n",
      "[95]\tvalid_0's tweedie: 158.122\n",
      "[96]\tvalid_0's tweedie: 158.122\n",
      "[97]\tvalid_0's tweedie: 158.122\n",
      "[98]\tvalid_0's tweedie: 158.122\n",
      "[99]\tvalid_0's tweedie: 158.122\n",
      "[100]\tvalid_0's tweedie: 158.122\n",
      "[101]\tvalid_0's tweedie: 158.122\n",
      "[102]\tvalid_0's tweedie: 158.122\n",
      "[103]\tvalid_0's tweedie: 158.122\n",
      "[104]\tvalid_0's tweedie: 158.122\n",
      "[105]\tvalid_0's tweedie: 158.122\n",
      "[106]\tvalid_0's tweedie: 158.121\n",
      "[107]\tvalid_0's tweedie: 158.121\n",
      "[108]\tvalid_0's tweedie: 158.121\n",
      "[109]\tvalid_0's tweedie: 158.12\n",
      "[110]\tvalid_0's tweedie: 158.117\n",
      "[111]\tvalid_0's tweedie: 158.117\n",
      "[112]\tvalid_0's tweedie: 158.116\n",
      "[113]\tvalid_0's tweedie: 158.116\n",
      "[114]\tvalid_0's tweedie: 158.116\n",
      "[115]\tvalid_0's tweedie: 158.115\n",
      "[116]\tvalid_0's tweedie: 158.116\n",
      "[117]\tvalid_0's tweedie: 158.116\n",
      "[118]\tvalid_0's tweedie: 158.116\n",
      "[119]\tvalid_0's tweedie: 158.115\n",
      "[120]\tvalid_0's tweedie: 158.112\n",
      "[121]\tvalid_0's tweedie: 158.112\n",
      "[122]\tvalid_0's tweedie: 158.112\n",
      "[123]\tvalid_0's tweedie: 158.112\n",
      "[124]\tvalid_0's tweedie: 158.111\n",
      "[125]\tvalid_0's tweedie: 158.11\n",
      "[126]\tvalid_0's tweedie: 158.11\n",
      "[127]\tvalid_0's tweedie: 158.11\n",
      "[128]\tvalid_0's tweedie: 158.11\n",
      "[129]\tvalid_0's tweedie: 158.11\n",
      "[130]\tvalid_0's tweedie: 158.109\n",
      "[131]\tvalid_0's tweedie: 158.109\n",
      "[132]\tvalid_0's tweedie: 158.109\n",
      "[133]\tvalid_0's tweedie: 158.109\n",
      "[134]\tvalid_0's tweedie: 158.109\n",
      "[135]\tvalid_0's tweedie: 158.109\n",
      "[136]\tvalid_0's tweedie: 158.109\n",
      "[137]\tvalid_0's tweedie: 158.108\n",
      "[138]\tvalid_0's tweedie: 158.108\n",
      "[139]\tvalid_0's tweedie: 158.108\n",
      "[140]\tvalid_0's tweedie: 158.107\n",
      "[141]\tvalid_0's tweedie: 158.107\n",
      "[142]\tvalid_0's tweedie: 158.107\n",
      "[143]\tvalid_0's tweedie: 158.106\n",
      "[144]\tvalid_0's tweedie: 158.106\n",
      "[145]\tvalid_0's tweedie: 158.106\n",
      "[146]\tvalid_0's tweedie: 158.106\n",
      "[147]\tvalid_0's tweedie: 158.106\n",
      "[148]\tvalid_0's tweedie: 158.106\n",
      "[149]\tvalid_0's tweedie: 158.106\n",
      "[150]\tvalid_0's tweedie: 158.106\n",
      "[151]\tvalid_0's tweedie: 158.106\n",
      "[152]\tvalid_0's tweedie: 158.105\n",
      "[153]\tvalid_0's tweedie: 158.105\n",
      "[154]\tvalid_0's tweedie: 158.105\n",
      "[155]\tvalid_0's tweedie: 158.105\n",
      "[156]\tvalid_0's tweedie: 158.105\n",
      "[157]\tvalid_0's tweedie: 158.105\n",
      "[158]\tvalid_0's tweedie: 158.105\n",
      "[159]\tvalid_0's tweedie: 158.105\n",
      "[160]\tvalid_0's tweedie: 158.105\n",
      "[161]\tvalid_0's tweedie: 158.105\n",
      "[162]\tvalid_0's tweedie: 158.105\n",
      "[163]\tvalid_0's tweedie: 158.105\n",
      "[164]\tvalid_0's tweedie: 158.105\n",
      "[165]\tvalid_0's tweedie: 158.105\n",
      "[166]\tvalid_0's tweedie: 158.105\n",
      "[167]\tvalid_0's tweedie: 158.105\n",
      "[168]\tvalid_0's tweedie: 158.105\n",
      "[169]\tvalid_0's tweedie: 158.105\n",
      "[170]\tvalid_0's tweedie: 158.105\n",
      "[171]\tvalid_0's tweedie: 158.105\n",
      "[172]\tvalid_0's tweedie: 158.105\n",
      "[173]\tvalid_0's tweedie: 158.105\n",
      "[174]\tvalid_0's tweedie: 158.105\n",
      "[175]\tvalid_0's tweedie: 158.105\n",
      "[176]\tvalid_0's tweedie: 158.105\n",
      "[177]\tvalid_0's tweedie: 158.104\n",
      "[178]\tvalid_0's tweedie: 158.104\n",
      "[179]\tvalid_0's tweedie: 158.104\n",
      "[180]\tvalid_0's tweedie: 158.104\n",
      "[181]\tvalid_0's tweedie: 158.104\n",
      "[182]\tvalid_0's tweedie: 158.104\n",
      "[183]\tvalid_0's tweedie: 158.104\n",
      "[184]\tvalid_0's tweedie: 158.104\n",
      "[185]\tvalid_0's tweedie: 158.104\n",
      "[186]\tvalid_0's tweedie: 158.104\n",
      "[187]\tvalid_0's tweedie: 158.104\n",
      "[188]\tvalid_0's tweedie: 158.104\n",
      "[189]\tvalid_0's tweedie: 158.104\n",
      "[190]\tvalid_0's tweedie: 158.104\n",
      "[191]\tvalid_0's tweedie: 158.104\n",
      "[192]\tvalid_0's tweedie: 158.104\n",
      "[193]\tvalid_0's tweedie: 158.104\n",
      "[194]\tvalid_0's tweedie: 158.104\n",
      "[195]\tvalid_0's tweedie: 158.103\n",
      "[196]\tvalid_0's tweedie: 158.103\n",
      "[197]\tvalid_0's tweedie: 158.103\n",
      "[198]\tvalid_0's tweedie: 158.103\n",
      "[199]\tvalid_0's tweedie: 158.103\n",
      "[200]\tvalid_0's tweedie: 158.103\n",
      "[201]\tvalid_0's tweedie: 158.103\n",
      "[202]\tvalid_0's tweedie: 158.103\n",
      "[203]\tvalid_0's tweedie: 158.103\n",
      "[204]\tvalid_0's tweedie: 158.103\n",
      "[205]\tvalid_0's tweedie: 158.103\n",
      "[206]\tvalid_0's tweedie: 158.103\n",
      "[207]\tvalid_0's tweedie: 158.103\n",
      "[208]\tvalid_0's tweedie: 158.103\n",
      "[209]\tvalid_0's tweedie: 158.103\n",
      "[210]\tvalid_0's tweedie: 158.103\n",
      "[211]\tvalid_0's tweedie: 158.103\n",
      "[212]\tvalid_0's tweedie: 158.103\n",
      "[213]\tvalid_0's tweedie: 158.102\n",
      "[214]\tvalid_0's tweedie: 158.102\n",
      "[215]\tvalid_0's tweedie: 158.102\n",
      "[216]\tvalid_0's tweedie: 158.102\n",
      "[217]\tvalid_0's tweedie: 158.102\n",
      "[218]\tvalid_0's tweedie: 158.102\n",
      "[219]\tvalid_0's tweedie: 158.102\n",
      "[220]\tvalid_0's tweedie: 158.102\n",
      "[221]\tvalid_0's tweedie: 158.103\n",
      "[222]\tvalid_0's tweedie: 158.103\n",
      "[223]\tvalid_0's tweedie: 158.103\n",
      "[224]\tvalid_0's tweedie: 158.103\n",
      "[225]\tvalid_0's tweedie: 158.103\n",
      "[226]\tvalid_0's tweedie: 158.103\n",
      "[227]\tvalid_0's tweedie: 158.103\n",
      "[228]\tvalid_0's tweedie: 158.103\n",
      "[229]\tvalid_0's tweedie: 158.103\n",
      "[230]\tvalid_0's tweedie: 158.103\n",
      "[231]\tvalid_0's tweedie: 158.104\n",
      "[232]\tvalid_0's tweedie: 158.103\n",
      "[233]\tvalid_0's tweedie: 158.103\n",
      "[234]\tvalid_0's tweedie: 158.103\n",
      "[235]\tvalid_0's tweedie: 158.103\n",
      "[236]\tvalid_0's tweedie: 158.103\n",
      "[237]\tvalid_0's tweedie: 158.103\n",
      "[238]\tvalid_0's tweedie: 158.103\n",
      "[239]\tvalid_0's tweedie: 158.103\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's tweedie: 158.102\n",
      "Training model for level 7 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 38976, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399734\n",
      "[1]\tvalid_0's tweedie: 176.783\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.687\n",
      "[3]\tvalid_0's tweedie: 171.071\n",
      "[4]\tvalid_0's tweedie: 168.868\n",
      "[5]\tvalid_0's tweedie: 167.021\n",
      "[6]\tvalid_0's tweedie: 165.478\n",
      "[7]\tvalid_0's tweedie: 164.21\n",
      "[8]\tvalid_0's tweedie: 163.14\n",
      "[9]\tvalid_0's tweedie: 162.26\n",
      "[10]\tvalid_0's tweedie: 161.512\n",
      "[11]\tvalid_0's tweedie: 160.906\n",
      "[12]\tvalid_0's tweedie: 160.413\n",
      "[13]\tvalid_0's tweedie: 160.01\n",
      "[14]\tvalid_0's tweedie: 159.668\n",
      "[15]\tvalid_0's tweedie: 159.391\n",
      "[16]\tvalid_0's tweedie: 159.161\n",
      "[17]\tvalid_0's tweedie: 158.976\n",
      "[18]\tvalid_0's tweedie: 158.828\n",
      "[19]\tvalid_0's tweedie: 158.697\n",
      "[20]\tvalid_0's tweedie: 158.595\n",
      "[21]\tvalid_0's tweedie: 158.509\n",
      "[22]\tvalid_0's tweedie: 158.442\n",
      "[23]\tvalid_0's tweedie: 158.385\n",
      "[24]\tvalid_0's tweedie: 158.34\n",
      "[25]\tvalid_0's tweedie: 158.303\n",
      "[26]\tvalid_0's tweedie: 158.272\n",
      "[27]\tvalid_0's tweedie: 158.248\n",
      "[28]\tvalid_0's tweedie: 158.23\n",
      "[29]\tvalid_0's tweedie: 158.211\n",
      "[30]\tvalid_0's tweedie: 158.197\n",
      "[31]\tvalid_0's tweedie: 158.185\n",
      "[32]\tvalid_0's tweedie: 158.177\n",
      "[33]\tvalid_0's tweedie: 158.168\n",
      "[34]\tvalid_0's tweedie: 158.161\n",
      "[35]\tvalid_0's tweedie: 158.155\n",
      "[36]\tvalid_0's tweedie: 158.15\n",
      "[37]\tvalid_0's tweedie: 158.144\n",
      "[38]\tvalid_0's tweedie: 158.141\n",
      "[39]\tvalid_0's tweedie: 158.138\n",
      "[40]\tvalid_0's tweedie: 158.136\n",
      "[41]\tvalid_0's tweedie: 158.134\n",
      "[42]\tvalid_0's tweedie: 158.133\n",
      "[43]\tvalid_0's tweedie: 158.131\n",
      "[44]\tvalid_0's tweedie: 158.129\n",
      "[45]\tvalid_0's tweedie: 158.129\n",
      "[46]\tvalid_0's tweedie: 158.128\n",
      "[47]\tvalid_0's tweedie: 158.128\n",
      "[48]\tvalid_0's tweedie: 158.128\n",
      "[49]\tvalid_0's tweedie: 158.127\n",
      "[50]\tvalid_0's tweedie: 158.127\n",
      "[51]\tvalid_0's tweedie: 158.126\n",
      "[52]\tvalid_0's tweedie: 158.125\n",
      "[53]\tvalid_0's tweedie: 158.125\n",
      "[54]\tvalid_0's tweedie: 158.124\n",
      "[55]\tvalid_0's tweedie: 158.124\n",
      "[56]\tvalid_0's tweedie: 158.124\n",
      "[57]\tvalid_0's tweedie: 158.123\n",
      "[58]\tvalid_0's tweedie: 158.123\n",
      "[59]\tvalid_0's tweedie: 158.123\n",
      "[60]\tvalid_0's tweedie: 158.123\n",
      "[61]\tvalid_0's tweedie: 158.124\n",
      "[62]\tvalid_0's tweedie: 158.125\n",
      "[63]\tvalid_0's tweedie: 158.124\n",
      "[64]\tvalid_0's tweedie: 158.124\n",
      "[65]\tvalid_0's tweedie: 158.124\n",
      "[66]\tvalid_0's tweedie: 158.123\n",
      "[67]\tvalid_0's tweedie: 158.123\n",
      "[68]\tvalid_0's tweedie: 158.122\n",
      "[69]\tvalid_0's tweedie: 158.122\n",
      "[70]\tvalid_0's tweedie: 158.122\n",
      "[71]\tvalid_0's tweedie: 158.122\n",
      "[72]\tvalid_0's tweedie: 158.122\n",
      "[73]\tvalid_0's tweedie: 158.121\n",
      "[74]\tvalid_0's tweedie: 158.118\n",
      "[75]\tvalid_0's tweedie: 158.117\n",
      "[76]\tvalid_0's tweedie: 158.115\n",
      "[77]\tvalid_0's tweedie: 158.115\n",
      "[78]\tvalid_0's tweedie: 158.115\n",
      "[79]\tvalid_0's tweedie: 158.115\n",
      "[80]\tvalid_0's tweedie: 158.115\n",
      "[81]\tvalid_0's tweedie: 158.115\n",
      "[82]\tvalid_0's tweedie: 158.115\n",
      "[83]\tvalid_0's tweedie: 158.115\n",
      "[84]\tvalid_0's tweedie: 158.115\n",
      "[85]\tvalid_0's tweedie: 158.114\n",
      "[86]\tvalid_0's tweedie: 158.114\n",
      "[87]\tvalid_0's tweedie: 158.114\n",
      "[88]\tvalid_0's tweedie: 158.114\n",
      "[89]\tvalid_0's tweedie: 158.113\n",
      "[90]\tvalid_0's tweedie: 158.113\n",
      "[91]\tvalid_0's tweedie: 158.112\n",
      "[92]\tvalid_0's tweedie: 158.112\n",
      "[93]\tvalid_0's tweedie: 158.111\n",
      "[94]\tvalid_0's tweedie: 158.11\n",
      "[95]\tvalid_0's tweedie: 158.11\n",
      "[96]\tvalid_0's tweedie: 158.11\n",
      "[97]\tvalid_0's tweedie: 158.109\n",
      "[98]\tvalid_0's tweedie: 158.106\n",
      "[99]\tvalid_0's tweedie: 158.105\n",
      "[100]\tvalid_0's tweedie: 158.105\n",
      "[101]\tvalid_0's tweedie: 158.105\n",
      "[102]\tvalid_0's tweedie: 158.104\n",
      "[103]\tvalid_0's tweedie: 158.104\n",
      "[104]\tvalid_0's tweedie: 158.104\n",
      "[105]\tvalid_0's tweedie: 158.104\n",
      "[106]\tvalid_0's tweedie: 158.104\n",
      "[107]\tvalid_0's tweedie: 158.104\n",
      "[108]\tvalid_0's tweedie: 158.104\n",
      "[109]\tvalid_0's tweedie: 158.104\n",
      "[110]\tvalid_0's tweedie: 158.102\n",
      "[111]\tvalid_0's tweedie: 158.101\n",
      "[112]\tvalid_0's tweedie: 158.101\n",
      "[113]\tvalid_0's tweedie: 158.101\n",
      "[114]\tvalid_0's tweedie: 158.101\n",
      "[115]\tvalid_0's tweedie: 158.1\n",
      "[116]\tvalid_0's tweedie: 158.1\n",
      "[117]\tvalid_0's tweedie: 158.098\n",
      "[118]\tvalid_0's tweedie: 158.098\n",
      "[119]\tvalid_0's tweedie: 158.098\n",
      "[120]\tvalid_0's tweedie: 158.098\n",
      "[121]\tvalid_0's tweedie: 158.098\n",
      "[122]\tvalid_0's tweedie: 158.098\n",
      "[123]\tvalid_0's tweedie: 158.098\n",
      "[124]\tvalid_0's tweedie: 158.098\n",
      "[125]\tvalid_0's tweedie: 158.098\n",
      "[126]\tvalid_0's tweedie: 158.097\n",
      "[127]\tvalid_0's tweedie: 158.096\n",
      "[128]\tvalid_0's tweedie: 158.097\n",
      "[129]\tvalid_0's tweedie: 158.097\n",
      "[130]\tvalid_0's tweedie: 158.097\n",
      "[131]\tvalid_0's tweedie: 158.097\n",
      "[132]\tvalid_0's tweedie: 158.097\n",
      "[133]\tvalid_0's tweedie: 158.097\n",
      "[134]\tvalid_0's tweedie: 158.097\n",
      "[135]\tvalid_0's tweedie: 158.097\n",
      "[136]\tvalid_0's tweedie: 158.097\n",
      "[137]\tvalid_0's tweedie: 158.097\n",
      "[138]\tvalid_0's tweedie: 158.097\n",
      "[139]\tvalid_0's tweedie: 158.097\n",
      "[140]\tvalid_0's tweedie: 158.097\n",
      "[141]\tvalid_0's tweedie: 158.096\n",
      "[142]\tvalid_0's tweedie: 158.096\n",
      "[143]\tvalid_0's tweedie: 158.096\n",
      "[144]\tvalid_0's tweedie: 158.096\n",
      "[145]\tvalid_0's tweedie: 158.096\n",
      "[146]\tvalid_0's tweedie: 158.095\n",
      "[147]\tvalid_0's tweedie: 158.096\n",
      "[148]\tvalid_0's tweedie: 158.096\n",
      "[149]\tvalid_0's tweedie: 158.096\n",
      "[150]\tvalid_0's tweedie: 158.096\n",
      "[151]\tvalid_0's tweedie: 158.096\n",
      "[152]\tvalid_0's tweedie: 158.096\n",
      "[153]\tvalid_0's tweedie: 158.096\n",
      "[154]\tvalid_0's tweedie: 158.096\n",
      "[155]\tvalid_0's tweedie: 158.095\n",
      "[156]\tvalid_0's tweedie: 158.095\n",
      "[157]\tvalid_0's tweedie: 158.095\n",
      "[158]\tvalid_0's tweedie: 158.095\n",
      "[159]\tvalid_0's tweedie: 158.095\n",
      "[160]\tvalid_0's tweedie: 158.095\n",
      "[161]\tvalid_0's tweedie: 158.095\n",
      "[162]\tvalid_0's tweedie: 158.094\n",
      "[163]\tvalid_0's tweedie: 158.094\n",
      "[164]\tvalid_0's tweedie: 158.094\n",
      "[165]\tvalid_0's tweedie: 158.094\n",
      "[166]\tvalid_0's tweedie: 158.092\n",
      "[167]\tvalid_0's tweedie: 158.092\n",
      "[168]\tvalid_0's tweedie: 158.093\n",
      "[169]\tvalid_0's tweedie: 158.093\n",
      "[170]\tvalid_0's tweedie: 158.093\n",
      "[171]\tvalid_0's tweedie: 158.093\n",
      "[172]\tvalid_0's tweedie: 158.093\n",
      "[173]\tvalid_0's tweedie: 158.093\n",
      "[174]\tvalid_0's tweedie: 158.093\n",
      "[175]\tvalid_0's tweedie: 158.093\n",
      "[176]\tvalid_0's tweedie: 158.093\n",
      "[177]\tvalid_0's tweedie: 158.093\n",
      "[178]\tvalid_0's tweedie: 158.093\n",
      "[179]\tvalid_0's tweedie: 158.092\n",
      "[180]\tvalid_0's tweedie: 158.092\n",
      "[181]\tvalid_0's tweedie: 158.092\n",
      "[182]\tvalid_0's tweedie: 158.092\n",
      "[183]\tvalid_0's tweedie: 158.092\n",
      "[184]\tvalid_0's tweedie: 158.092\n",
      "[185]\tvalid_0's tweedie: 158.092\n",
      "[186]\tvalid_0's tweedie: 158.092\n",
      "[187]\tvalid_0's tweedie: 158.091\n",
      "[188]\tvalid_0's tweedie: 158.092\n",
      "[189]\tvalid_0's tweedie: 158.091\n",
      "[190]\tvalid_0's tweedie: 158.092\n",
      "[191]\tvalid_0's tweedie: 158.091\n",
      "[192]\tvalid_0's tweedie: 158.091\n",
      "[193]\tvalid_0's tweedie: 158.091\n",
      "[194]\tvalid_0's tweedie: 158.091\n",
      "[195]\tvalid_0's tweedie: 158.091\n",
      "[196]\tvalid_0's tweedie: 158.091\n",
      "[197]\tvalid_0's tweedie: 158.092\n",
      "[198]\tvalid_0's tweedie: 158.091\n",
      "[199]\tvalid_0's tweedie: 158.091\n",
      "[200]\tvalid_0's tweedie: 158.091\n",
      "[201]\tvalid_0's tweedie: 158.091\n",
      "[202]\tvalid_0's tweedie: 158.091\n",
      "[203]\tvalid_0's tweedie: 158.091\n",
      "[204]\tvalid_0's tweedie: 158.092\n",
      "[205]\tvalid_0's tweedie: 158.092\n",
      "[206]\tvalid_0's tweedie: 158.092\n",
      "[207]\tvalid_0's tweedie: 158.092\n",
      "[208]\tvalid_0's tweedie: 158.092\n",
      "[209]\tvalid_0's tweedie: 158.092\n",
      "[210]\tvalid_0's tweedie: 158.091\n",
      "[211]\tvalid_0's tweedie: 158.092\n",
      "[212]\tvalid_0's tweedie: 158.091\n",
      "[213]\tvalid_0's tweedie: 158.091\n",
      "[214]\tvalid_0's tweedie: 158.091\n",
      "[215]\tvalid_0's tweedie: 158.091\n",
      "[216]\tvalid_0's tweedie: 158.091\n",
      "[217]\tvalid_0's tweedie: 158.091\n",
      "[218]\tvalid_0's tweedie: 158.091\n",
      "[219]\tvalid_0's tweedie: 158.091\n",
      "[220]\tvalid_0's tweedie: 158.091\n",
      "[221]\tvalid_0's tweedie: 158.09\n",
      "[222]\tvalid_0's tweedie: 158.091\n",
      "[223]\tvalid_0's tweedie: 158.091\n",
      "[224]\tvalid_0's tweedie: 158.091\n",
      "[225]\tvalid_0's tweedie: 158.091\n",
      "[226]\tvalid_0's tweedie: 158.091\n",
      "[227]\tvalid_0's tweedie: 158.091\n",
      "[228]\tvalid_0's tweedie: 158.091\n",
      "[229]\tvalid_0's tweedie: 158.091\n",
      "[230]\tvalid_0's tweedie: 158.091\n",
      "[231]\tvalid_0's tweedie: 158.091\n",
      "[232]\tvalid_0's tweedie: 158.091\n",
      "[233]\tvalid_0's tweedie: 158.091\n",
      "[234]\tvalid_0's tweedie: 158.091\n",
      "[235]\tvalid_0's tweedie: 158.091\n",
      "[236]\tvalid_0's tweedie: 158.091\n",
      "[237]\tvalid_0's tweedie: 158.092\n",
      "[238]\tvalid_0's tweedie: 158.092\n",
      "[239]\tvalid_0's tweedie: 158.092\n",
      "[240]\tvalid_0's tweedie: 158.092\n",
      "[241]\tvalid_0's tweedie: 158.092\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's tweedie: 158.09\n",
      "Training model for level 7 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 38955, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.399823\n",
      "[1]\tvalid_0's tweedie: 176.781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.677\n",
      "[3]\tvalid_0's tweedie: 171.073\n",
      "[4]\tvalid_0's tweedie: 168.87\n",
      "[5]\tvalid_0's tweedie: 167.019\n",
      "[6]\tvalid_0's tweedie: 165.47\n",
      "[7]\tvalid_0's tweedie: 164.198\n",
      "[8]\tvalid_0's tweedie: 163.127\n",
      "[9]\tvalid_0's tweedie: 162.255\n",
      "[10]\tvalid_0's tweedie: 161.518\n",
      "[11]\tvalid_0's tweedie: 160.91\n",
      "[12]\tvalid_0's tweedie: 160.4\n",
      "[13]\tvalid_0's tweedie: 159.988\n",
      "[14]\tvalid_0's tweedie: 159.65\n",
      "[15]\tvalid_0's tweedie: 159.373\n",
      "[16]\tvalid_0's tweedie: 159.144\n",
      "[17]\tvalid_0's tweedie: 158.958\n",
      "[18]\tvalid_0's tweedie: 158.808\n",
      "[19]\tvalid_0's tweedie: 158.68\n",
      "[20]\tvalid_0's tweedie: 158.579\n",
      "[21]\tvalid_0's tweedie: 158.501\n",
      "[22]\tvalid_0's tweedie: 158.432\n",
      "[23]\tvalid_0's tweedie: 158.376\n",
      "[24]\tvalid_0's tweedie: 158.33\n",
      "[25]\tvalid_0's tweedie: 158.289\n",
      "[26]\tvalid_0's tweedie: 158.254\n",
      "[27]\tvalid_0's tweedie: 158.233\n",
      "[28]\tvalid_0's tweedie: 158.213\n",
      "[29]\tvalid_0's tweedie: 158.195\n",
      "[30]\tvalid_0's tweedie: 158.182\n",
      "[31]\tvalid_0's tweedie: 158.168\n",
      "[32]\tvalid_0's tweedie: 158.159\n",
      "[33]\tvalid_0's tweedie: 158.151\n",
      "[34]\tvalid_0's tweedie: 158.145\n",
      "[35]\tvalid_0's tweedie: 158.14\n",
      "[36]\tvalid_0's tweedie: 158.135\n",
      "[37]\tvalid_0's tweedie: 158.13\n",
      "[38]\tvalid_0's tweedie: 158.126\n",
      "[39]\tvalid_0's tweedie: 158.124\n",
      "[40]\tvalid_0's tweedie: 158.122\n",
      "[41]\tvalid_0's tweedie: 158.122\n",
      "[42]\tvalid_0's tweedie: 158.12\n",
      "[43]\tvalid_0's tweedie: 158.119\n",
      "[44]\tvalid_0's tweedie: 158.119\n",
      "[45]\tvalid_0's tweedie: 158.117\n",
      "[46]\tvalid_0's tweedie: 158.115\n",
      "[47]\tvalid_0's tweedie: 158.114\n",
      "[48]\tvalid_0's tweedie: 158.113\n",
      "[49]\tvalid_0's tweedie: 158.113\n",
      "[50]\tvalid_0's tweedie: 158.113\n",
      "[51]\tvalid_0's tweedie: 158.113\n",
      "[52]\tvalid_0's tweedie: 158.113\n",
      "[53]\tvalid_0's tweedie: 158.112\n",
      "[54]\tvalid_0's tweedie: 158.111\n",
      "[55]\tvalid_0's tweedie: 158.111\n",
      "[56]\tvalid_0's tweedie: 158.111\n",
      "[57]\tvalid_0's tweedie: 158.112\n",
      "[58]\tvalid_0's tweedie: 158.112\n",
      "[59]\tvalid_0's tweedie: 158.112\n",
      "[60]\tvalid_0's tweedie: 158.112\n",
      "[61]\tvalid_0's tweedie: 158.113\n",
      "[62]\tvalid_0's tweedie: 158.113\n",
      "[63]\tvalid_0's tweedie: 158.115\n",
      "[64]\tvalid_0's tweedie: 158.115\n",
      "[65]\tvalid_0's tweedie: 158.114\n",
      "[66]\tvalid_0's tweedie: 158.114\n",
      "[67]\tvalid_0's tweedie: 158.113\n",
      "[68]\tvalid_0's tweedie: 158.113\n",
      "[69]\tvalid_0's tweedie: 158.113\n",
      "[70]\tvalid_0's tweedie: 158.112\n",
      "[71]\tvalid_0's tweedie: 158.113\n",
      "[72]\tvalid_0's tweedie: 158.112\n",
      "[73]\tvalid_0's tweedie: 158.111\n",
      "[74]\tvalid_0's tweedie: 158.111\n",
      "[75]\tvalid_0's tweedie: 158.111\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's tweedie: 158.111\n",
      "Training model for level 7 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 38934, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400029\n",
      "[1]\tvalid_0's tweedie: 176.779\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.679\n",
      "[3]\tvalid_0's tweedie: 171.069\n",
      "[4]\tvalid_0's tweedie: 168.866\n",
      "[5]\tvalid_0's tweedie: 167.016\n",
      "[6]\tvalid_0's tweedie: 165.474\n",
      "[7]\tvalid_0's tweedie: 164.199\n",
      "[8]\tvalid_0's tweedie: 163.137\n",
      "[9]\tvalid_0's tweedie: 162.251\n",
      "[10]\tvalid_0's tweedie: 161.507\n",
      "[11]\tvalid_0's tweedie: 160.894\n",
      "[12]\tvalid_0's tweedie: 160.389\n",
      "[13]\tvalid_0's tweedie: 159.984\n",
      "[14]\tvalid_0's tweedie: 159.652\n",
      "[15]\tvalid_0's tweedie: 159.372\n",
      "[16]\tvalid_0's tweedie: 159.142\n",
      "[17]\tvalid_0's tweedie: 158.954\n",
      "[18]\tvalid_0's tweedie: 158.798\n",
      "[19]\tvalid_0's tweedie: 158.677\n",
      "[20]\tvalid_0's tweedie: 158.572\n",
      "[21]\tvalid_0's tweedie: 158.495\n",
      "[22]\tvalid_0's tweedie: 158.427\n",
      "[23]\tvalid_0's tweedie: 158.367\n",
      "[24]\tvalid_0's tweedie: 158.322\n",
      "[25]\tvalid_0's tweedie: 158.286\n",
      "[26]\tvalid_0's tweedie: 158.252\n",
      "[27]\tvalid_0's tweedie: 158.227\n",
      "[28]\tvalid_0's tweedie: 158.207\n",
      "[29]\tvalid_0's tweedie: 158.19\n",
      "[30]\tvalid_0's tweedie: 158.177\n",
      "[31]\tvalid_0's tweedie: 158.167\n",
      "[32]\tvalid_0's tweedie: 158.157\n",
      "[33]\tvalid_0's tweedie: 158.148\n",
      "[34]\tvalid_0's tweedie: 158.141\n",
      "[35]\tvalid_0's tweedie: 158.135\n",
      "[36]\tvalid_0's tweedie: 158.131\n",
      "[37]\tvalid_0's tweedie: 158.127\n",
      "[38]\tvalid_0's tweedie: 158.124\n",
      "[39]\tvalid_0's tweedie: 158.122\n",
      "[40]\tvalid_0's tweedie: 158.119\n",
      "[41]\tvalid_0's tweedie: 158.119\n",
      "[42]\tvalid_0's tweedie: 158.117\n",
      "[43]\tvalid_0's tweedie: 158.116\n",
      "[44]\tvalid_0's tweedie: 158.115\n",
      "[45]\tvalid_0's tweedie: 158.115\n",
      "[46]\tvalid_0's tweedie: 158.115\n",
      "[47]\tvalid_0's tweedie: 158.115\n",
      "[48]\tvalid_0's tweedie: 158.114\n",
      "[49]\tvalid_0's tweedie: 158.113\n",
      "[50]\tvalid_0's tweedie: 158.112\n",
      "[51]\tvalid_0's tweedie: 158.113\n",
      "[52]\tvalid_0's tweedie: 158.112\n",
      "[53]\tvalid_0's tweedie: 158.113\n",
      "[54]\tvalid_0's tweedie: 158.113\n",
      "[55]\tvalid_0's tweedie: 158.113\n",
      "[56]\tvalid_0's tweedie: 158.113\n",
      "[57]\tvalid_0's tweedie: 158.113\n",
      "[58]\tvalid_0's tweedie: 158.113\n",
      "[59]\tvalid_0's tweedie: 158.113\n",
      "[60]\tvalid_0's tweedie: 158.112\n",
      "[61]\tvalid_0's tweedie: 158.112\n",
      "[62]\tvalid_0's tweedie: 158.111\n",
      "[63]\tvalid_0's tweedie: 158.111\n",
      "[64]\tvalid_0's tweedie: 158.111\n",
      "[65]\tvalid_0's tweedie: 158.111\n",
      "[66]\tvalid_0's tweedie: 158.111\n",
      "[67]\tvalid_0's tweedie: 158.111\n",
      "[68]\tvalid_0's tweedie: 158.111\n",
      "[69]\tvalid_0's tweedie: 158.11\n",
      "[70]\tvalid_0's tweedie: 158.11\n",
      "[71]\tvalid_0's tweedie: 158.11\n",
      "[72]\tvalid_0's tweedie: 158.11\n",
      "[73]\tvalid_0's tweedie: 158.109\n",
      "[74]\tvalid_0's tweedie: 158.109\n",
      "[75]\tvalid_0's tweedie: 158.11\n",
      "[76]\tvalid_0's tweedie: 158.11\n",
      "[77]\tvalid_0's tweedie: 158.11\n",
      "[78]\tvalid_0's tweedie: 158.11\n",
      "[79]\tvalid_0's tweedie: 158.109\n",
      "[80]\tvalid_0's tweedie: 158.109\n",
      "[81]\tvalid_0's tweedie: 158.108\n",
      "[82]\tvalid_0's tweedie: 158.108\n",
      "[83]\tvalid_0's tweedie: 158.108\n",
      "[84]\tvalid_0's tweedie: 158.108\n",
      "[85]\tvalid_0's tweedie: 158.108\n",
      "[86]\tvalid_0's tweedie: 158.108\n",
      "[87]\tvalid_0's tweedie: 158.107\n",
      "[88]\tvalid_0's tweedie: 158.107\n",
      "[89]\tvalid_0's tweedie: 158.106\n",
      "[90]\tvalid_0's tweedie: 158.106\n",
      "[91]\tvalid_0's tweedie: 158.106\n",
      "[92]\tvalid_0's tweedie: 158.105\n",
      "[93]\tvalid_0's tweedie: 158.105\n",
      "[94]\tvalid_0's tweedie: 158.105\n",
      "[95]\tvalid_0's tweedie: 158.105\n",
      "[96]\tvalid_0's tweedie: 158.105\n",
      "[97]\tvalid_0's tweedie: 158.105\n",
      "[98]\tvalid_0's tweedie: 158.102\n",
      "[99]\tvalid_0's tweedie: 158.101\n",
      "[100]\tvalid_0's tweedie: 158.101\n",
      "[101]\tvalid_0's tweedie: 158.101\n",
      "[102]\tvalid_0's tweedie: 158.1\n",
      "[103]\tvalid_0's tweedie: 158.1\n",
      "[104]\tvalid_0's tweedie: 158.1\n",
      "[105]\tvalid_0's tweedie: 158.099\n",
      "[106]\tvalid_0's tweedie: 158.099\n",
      "[107]\tvalid_0's tweedie: 158.099\n",
      "[108]\tvalid_0's tweedie: 158.099\n",
      "[109]\tvalid_0's tweedie: 158.099\n",
      "[110]\tvalid_0's tweedie: 158.099\n",
      "[111]\tvalid_0's tweedie: 158.099\n",
      "[112]\tvalid_0's tweedie: 158.099\n",
      "[113]\tvalid_0's tweedie: 158.099\n",
      "[114]\tvalid_0's tweedie: 158.099\n",
      "[115]\tvalid_0's tweedie: 158.099\n",
      "[116]\tvalid_0's tweedie: 158.099\n",
      "[117]\tvalid_0's tweedie: 158.099\n",
      "[118]\tvalid_0's tweedie: 158.099\n",
      "[119]\tvalid_0's tweedie: 158.099\n",
      "[120]\tvalid_0's tweedie: 158.099\n",
      "[121]\tvalid_0's tweedie: 158.099\n",
      "[122]\tvalid_0's tweedie: 158.099\n",
      "[123]\tvalid_0's tweedie: 158.099\n",
      "[124]\tvalid_0's tweedie: 158.099\n",
      "[125]\tvalid_0's tweedie: 158.099\n",
      "[126]\tvalid_0's tweedie: 158.099\n",
      "[127]\tvalid_0's tweedie: 158.098\n",
      "[128]\tvalid_0's tweedie: 158.098\n",
      "[129]\tvalid_0's tweedie: 158.098\n",
      "[130]\tvalid_0's tweedie: 158.098\n",
      "[131]\tvalid_0's tweedie: 158.098\n",
      "[132]\tvalid_0's tweedie: 158.098\n",
      "[133]\tvalid_0's tweedie: 158.098\n",
      "[134]\tvalid_0's tweedie: 158.098\n",
      "[135]\tvalid_0's tweedie: 158.098\n",
      "[136]\tvalid_0's tweedie: 158.098\n",
      "[137]\tvalid_0's tweedie: 158.098\n",
      "[138]\tvalid_0's tweedie: 158.098\n",
      "[139]\tvalid_0's tweedie: 158.098\n",
      "[140]\tvalid_0's tweedie: 158.097\n",
      "[141]\tvalid_0's tweedie: 158.097\n",
      "[142]\tvalid_0's tweedie: 158.097\n",
      "[143]\tvalid_0's tweedie: 158.097\n",
      "[144]\tvalid_0's tweedie: 158.097\n",
      "[145]\tvalid_0's tweedie: 158.097\n",
      "[146]\tvalid_0's tweedie: 158.096\n",
      "[147]\tvalid_0's tweedie: 158.096\n",
      "[148]\tvalid_0's tweedie: 158.096\n",
      "[149]\tvalid_0's tweedie: 158.096\n",
      "[150]\tvalid_0's tweedie: 158.096\n",
      "[151]\tvalid_0's tweedie: 158.096\n",
      "[152]\tvalid_0's tweedie: 158.096\n",
      "[153]\tvalid_0's tweedie: 158.096\n",
      "[154]\tvalid_0's tweedie: 158.096\n",
      "[155]\tvalid_0's tweedie: 158.096\n",
      "[156]\tvalid_0's tweedie: 158.096\n",
      "[157]\tvalid_0's tweedie: 158.096\n",
      "[158]\tvalid_0's tweedie: 158.096\n",
      "[159]\tvalid_0's tweedie: 158.095\n",
      "[160]\tvalid_0's tweedie: 158.096\n",
      "[161]\tvalid_0's tweedie: 158.095\n",
      "[162]\tvalid_0's tweedie: 158.095\n",
      "[163]\tvalid_0's tweedie: 158.096\n",
      "[164]\tvalid_0's tweedie: 158.096\n",
      "[165]\tvalid_0's tweedie: 158.095\n",
      "[166]\tvalid_0's tweedie: 158.095\n",
      "[167]\tvalid_0's tweedie: 158.095\n",
      "[168]\tvalid_0's tweedie: 158.095\n",
      "[169]\tvalid_0's tweedie: 158.095\n",
      "[170]\tvalid_0's tweedie: 158.095\n",
      "[171]\tvalid_0's tweedie: 158.095\n",
      "[172]\tvalid_0's tweedie: 158.095\n",
      "[173]\tvalid_0's tweedie: 158.095\n",
      "[174]\tvalid_0's tweedie: 158.095\n",
      "[175]\tvalid_0's tweedie: 158.095\n",
      "[176]\tvalid_0's tweedie: 158.095\n",
      "[177]\tvalid_0's tweedie: 158.095\n",
      "[178]\tvalid_0's tweedie: 158.095\n",
      "[179]\tvalid_0's tweedie: 158.095\n",
      "[180]\tvalid_0's tweedie: 158.095\n",
      "[181]\tvalid_0's tweedie: 158.095\n",
      "[182]\tvalid_0's tweedie: 158.095\n",
      "[183]\tvalid_0's tweedie: 158.095\n",
      "[184]\tvalid_0's tweedie: 158.095\n",
      "[185]\tvalid_0's tweedie: 158.095\n",
      "[186]\tvalid_0's tweedie: 158.095\n",
      "[187]\tvalid_0's tweedie: 158.095\n",
      "[188]\tvalid_0's tweedie: 158.095\n",
      "[189]\tvalid_0's tweedie: 158.095\n",
      "[190]\tvalid_0's tweedie: 158.094\n",
      "[191]\tvalid_0's tweedie: 158.094\n",
      "[192]\tvalid_0's tweedie: 158.094\n",
      "[193]\tvalid_0's tweedie: 158.094\n",
      "[194]\tvalid_0's tweedie: 158.094\n",
      "[195]\tvalid_0's tweedie: 158.094\n",
      "[196]\tvalid_0's tweedie: 158.094\n",
      "[197]\tvalid_0's tweedie: 158.094\n",
      "[198]\tvalid_0's tweedie: 158.094\n",
      "[199]\tvalid_0's tweedie: 158.094\n",
      "[200]\tvalid_0's tweedie: 158.094\n",
      "[201]\tvalid_0's tweedie: 158.094\n",
      "[202]\tvalid_0's tweedie: 158.094\n",
      "[203]\tvalid_0's tweedie: 158.094\n",
      "[204]\tvalid_0's tweedie: 158.094\n",
      "[205]\tvalid_0's tweedie: 158.094\n",
      "[206]\tvalid_0's tweedie: 158.094\n",
      "[207]\tvalid_0's tweedie: 158.094\n",
      "[208]\tvalid_0's tweedie: 158.094\n",
      "[209]\tvalid_0's tweedie: 158.094\n",
      "[210]\tvalid_0's tweedie: 158.094\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's tweedie: 158.094\n",
      "Training model for level 7 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 38913, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400209\n",
      "[1]\tvalid_0's tweedie: 176.779\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.694\n",
      "[3]\tvalid_0's tweedie: 171.077\n",
      "[4]\tvalid_0's tweedie: 168.87\n",
      "[5]\tvalid_0's tweedie: 167.021\n",
      "[6]\tvalid_0's tweedie: 165.474\n",
      "[7]\tvalid_0's tweedie: 164.189\n",
      "[8]\tvalid_0's tweedie: 163.136\n",
      "[9]\tvalid_0's tweedie: 162.252\n",
      "[10]\tvalid_0's tweedie: 161.509\n",
      "[11]\tvalid_0's tweedie: 160.898\n",
      "[12]\tvalid_0's tweedie: 160.392\n",
      "[13]\tvalid_0's tweedie: 159.983\n",
      "[14]\tvalid_0's tweedie: 159.645\n",
      "[15]\tvalid_0's tweedie: 159.369\n",
      "[16]\tvalid_0's tweedie: 159.142\n",
      "[17]\tvalid_0's tweedie: 158.958\n",
      "[18]\tvalid_0's tweedie: 158.805\n",
      "[19]\tvalid_0's tweedie: 158.682\n",
      "[20]\tvalid_0's tweedie: 158.586\n",
      "[21]\tvalid_0's tweedie: 158.498\n",
      "[22]\tvalid_0's tweedie: 158.43\n",
      "[23]\tvalid_0's tweedie: 158.377\n",
      "[24]\tvalid_0's tweedie: 158.332\n",
      "[25]\tvalid_0's tweedie: 158.292\n",
      "[26]\tvalid_0's tweedie: 158.261\n",
      "[27]\tvalid_0's tweedie: 158.24\n",
      "[28]\tvalid_0's tweedie: 158.216\n",
      "[29]\tvalid_0's tweedie: 158.197\n",
      "[30]\tvalid_0's tweedie: 158.183\n",
      "[31]\tvalid_0's tweedie: 158.17\n",
      "[32]\tvalid_0's tweedie: 158.161\n",
      "[33]\tvalid_0's tweedie: 158.154\n",
      "[34]\tvalid_0's tweedie: 158.147\n",
      "[35]\tvalid_0's tweedie: 158.141\n",
      "[36]\tvalid_0's tweedie: 158.136\n",
      "[37]\tvalid_0's tweedie: 158.133\n",
      "[38]\tvalid_0's tweedie: 158.129\n",
      "[39]\tvalid_0's tweedie: 158.126\n",
      "[40]\tvalid_0's tweedie: 158.124\n",
      "[41]\tvalid_0's tweedie: 158.125\n",
      "[42]\tvalid_0's tweedie: 158.126\n",
      "[43]\tvalid_0's tweedie: 158.124\n",
      "[44]\tvalid_0's tweedie: 158.122\n",
      "[45]\tvalid_0's tweedie: 158.122\n",
      "[46]\tvalid_0's tweedie: 158.121\n",
      "[47]\tvalid_0's tweedie: 158.121\n",
      "[48]\tvalid_0's tweedie: 158.12\n",
      "[49]\tvalid_0's tweedie: 158.12\n",
      "[50]\tvalid_0's tweedie: 158.12\n",
      "[51]\tvalid_0's tweedie: 158.12\n",
      "[52]\tvalid_0's tweedie: 158.118\n",
      "[53]\tvalid_0's tweedie: 158.118\n",
      "[54]\tvalid_0's tweedie: 158.119\n",
      "[55]\tvalid_0's tweedie: 158.118\n",
      "[56]\tvalid_0's tweedie: 158.117\n",
      "[57]\tvalid_0's tweedie: 158.117\n",
      "[58]\tvalid_0's tweedie: 158.118\n",
      "[59]\tvalid_0's tweedie: 158.118\n",
      "[60]\tvalid_0's tweedie: 158.118\n",
      "[61]\tvalid_0's tweedie: 158.117\n",
      "[62]\tvalid_0's tweedie: 158.117\n",
      "[63]\tvalid_0's tweedie: 158.116\n",
      "[64]\tvalid_0's tweedie: 158.115\n",
      "[65]\tvalid_0's tweedie: 158.116\n",
      "[66]\tvalid_0's tweedie: 158.115\n",
      "[67]\tvalid_0's tweedie: 158.114\n",
      "[68]\tvalid_0's tweedie: 158.114\n",
      "[69]\tvalid_0's tweedie: 158.115\n",
      "[70]\tvalid_0's tweedie: 158.114\n",
      "[71]\tvalid_0's tweedie: 158.114\n",
      "[72]\tvalid_0's tweedie: 158.113\n",
      "[73]\tvalid_0's tweedie: 158.113\n",
      "[74]\tvalid_0's tweedie: 158.113\n",
      "[75]\tvalid_0's tweedie: 158.111\n",
      "[76]\tvalid_0's tweedie: 158.111\n",
      "[77]\tvalid_0's tweedie: 158.11\n",
      "[78]\tvalid_0's tweedie: 158.109\n",
      "[79]\tvalid_0's tweedie: 158.109\n",
      "[80]\tvalid_0's tweedie: 158.108\n",
      "[81]\tvalid_0's tweedie: 158.108\n",
      "[82]\tvalid_0's tweedie: 158.108\n",
      "[83]\tvalid_0's tweedie: 158.107\n",
      "[84]\tvalid_0's tweedie: 158.107\n",
      "[85]\tvalid_0's tweedie: 158.107\n",
      "[86]\tvalid_0's tweedie: 158.107\n",
      "[87]\tvalid_0's tweedie: 158.106\n",
      "[88]\tvalid_0's tweedie: 158.105\n",
      "[89]\tvalid_0's tweedie: 158.104\n",
      "[90]\tvalid_0's tweedie: 158.105\n",
      "[91]\tvalid_0's tweedie: 158.104\n",
      "[92]\tvalid_0's tweedie: 158.104\n",
      "[93]\tvalid_0's tweedie: 158.103\n",
      "[94]\tvalid_0's tweedie: 158.103\n",
      "[95]\tvalid_0's tweedie: 158.103\n",
      "[96]\tvalid_0's tweedie: 158.103\n",
      "[97]\tvalid_0's tweedie: 158.102\n",
      "[98]\tvalid_0's tweedie: 158.102\n",
      "[99]\tvalid_0's tweedie: 158.102\n",
      "[100]\tvalid_0's tweedie: 158.102\n",
      "[101]\tvalid_0's tweedie: 158.102\n",
      "[102]\tvalid_0's tweedie: 158.102\n",
      "[103]\tvalid_0's tweedie: 158.102\n",
      "[104]\tvalid_0's tweedie: 158.101\n",
      "[105]\tvalid_0's tweedie: 158.1\n",
      "[106]\tvalid_0's tweedie: 158.101\n",
      "[107]\tvalid_0's tweedie: 158.1\n",
      "[108]\tvalid_0's tweedie: 158.1\n",
      "[109]\tvalid_0's tweedie: 158.1\n",
      "[110]\tvalid_0's tweedie: 158.101\n",
      "[111]\tvalid_0's tweedie: 158.1\n",
      "[112]\tvalid_0's tweedie: 158.1\n",
      "[113]\tvalid_0's tweedie: 158.1\n",
      "[114]\tvalid_0's tweedie: 158.1\n",
      "[115]\tvalid_0's tweedie: 158.1\n",
      "[116]\tvalid_0's tweedie: 158.1\n",
      "[117]\tvalid_0's tweedie: 158.1\n",
      "[118]\tvalid_0's tweedie: 158.1\n",
      "[119]\tvalid_0's tweedie: 158.101\n",
      "[120]\tvalid_0's tweedie: 158.1\n",
      "[121]\tvalid_0's tweedie: 158.1\n",
      "[122]\tvalid_0's tweedie: 158.099\n",
      "[123]\tvalid_0's tweedie: 158.099\n",
      "[124]\tvalid_0's tweedie: 158.099\n",
      "[125]\tvalid_0's tweedie: 158.098\n",
      "[126]\tvalid_0's tweedie: 158.098\n",
      "[127]\tvalid_0's tweedie: 158.098\n",
      "[128]\tvalid_0's tweedie: 158.098\n",
      "[129]\tvalid_0's tweedie: 158.098\n",
      "[130]\tvalid_0's tweedie: 158.098\n",
      "[131]\tvalid_0's tweedie: 158.098\n",
      "[132]\tvalid_0's tweedie: 158.097\n",
      "[133]\tvalid_0's tweedie: 158.097\n",
      "[134]\tvalid_0's tweedie: 158.097\n",
      "[135]\tvalid_0's tweedie: 158.097\n",
      "[136]\tvalid_0's tweedie: 158.097\n",
      "[137]\tvalid_0's tweedie: 158.097\n",
      "[138]\tvalid_0's tweedie: 158.097\n",
      "[139]\tvalid_0's tweedie: 158.097\n",
      "[140]\tvalid_0's tweedie: 158.097\n",
      "[141]\tvalid_0's tweedie: 158.097\n",
      "[142]\tvalid_0's tweedie: 158.097\n",
      "[143]\tvalid_0's tweedie: 158.096\n",
      "[144]\tvalid_0's tweedie: 158.096\n",
      "[145]\tvalid_0's tweedie: 158.096\n",
      "[146]\tvalid_0's tweedie: 158.096\n",
      "[147]\tvalid_0's tweedie: 158.096\n",
      "[148]\tvalid_0's tweedie: 158.096\n",
      "[149]\tvalid_0's tweedie: 158.096\n",
      "[150]\tvalid_0's tweedie: 158.096\n",
      "[151]\tvalid_0's tweedie: 158.096\n",
      "[152]\tvalid_0's tweedie: 158.096\n",
      "[153]\tvalid_0's tweedie: 158.096\n",
      "[154]\tvalid_0's tweedie: 158.096\n",
      "[155]\tvalid_0's tweedie: 158.096\n",
      "[156]\tvalid_0's tweedie: 158.096\n",
      "[157]\tvalid_0's tweedie: 158.096\n",
      "[158]\tvalid_0's tweedie: 158.096\n",
      "[159]\tvalid_0's tweedie: 158.096\n",
      "[160]\tvalid_0's tweedie: 158.094\n",
      "[161]\tvalid_0's tweedie: 158.094\n",
      "[162]\tvalid_0's tweedie: 158.094\n",
      "[163]\tvalid_0's tweedie: 158.094\n",
      "[164]\tvalid_0's tweedie: 158.094\n",
      "[165]\tvalid_0's tweedie: 158.093\n",
      "[166]\tvalid_0's tweedie: 158.093\n",
      "[167]\tvalid_0's tweedie: 158.093\n",
      "[168]\tvalid_0's tweedie: 158.093\n",
      "[169]\tvalid_0's tweedie: 158.093\n",
      "[170]\tvalid_0's tweedie: 158.093\n",
      "[171]\tvalid_0's tweedie: 158.093\n",
      "[172]\tvalid_0's tweedie: 158.093\n",
      "[173]\tvalid_0's tweedie: 158.093\n",
      "[174]\tvalid_0's tweedie: 158.093\n",
      "[175]\tvalid_0's tweedie: 158.093\n",
      "[176]\tvalid_0's tweedie: 158.093\n",
      "[177]\tvalid_0's tweedie: 158.093\n",
      "[178]\tvalid_0's tweedie: 158.093\n",
      "[179]\tvalid_0's tweedie: 158.093\n",
      "[180]\tvalid_0's tweedie: 158.093\n",
      "[181]\tvalid_0's tweedie: 158.093\n",
      "[182]\tvalid_0's tweedie: 158.093\n",
      "[183]\tvalid_0's tweedie: 158.093\n",
      "[184]\tvalid_0's tweedie: 158.093\n",
      "[185]\tvalid_0's tweedie: 158.093\n",
      "[186]\tvalid_0's tweedie: 158.093\n",
      "[187]\tvalid_0's tweedie: 158.093\n",
      "[188]\tvalid_0's tweedie: 158.093\n",
      "[189]\tvalid_0's tweedie: 158.093\n",
      "[190]\tvalid_0's tweedie: 158.093\n",
      "[191]\tvalid_0's tweedie: 158.092\n",
      "[192]\tvalid_0's tweedie: 158.092\n",
      "[193]\tvalid_0's tweedie: 158.092\n",
      "[194]\tvalid_0's tweedie: 158.092\n",
      "[195]\tvalid_0's tweedie: 158.092\n",
      "[196]\tvalid_0's tweedie: 158.092\n",
      "[197]\tvalid_0's tweedie: 158.092\n",
      "[198]\tvalid_0's tweedie: 158.092\n",
      "[199]\tvalid_0's tweedie: 158.093\n",
      "[200]\tvalid_0's tweedie: 158.092\n",
      "[201]\tvalid_0's tweedie: 158.092\n",
      "[202]\tvalid_0's tweedie: 158.092\n",
      "[203]\tvalid_0's tweedie: 158.092\n",
      "[204]\tvalid_0's tweedie: 158.092\n",
      "[205]\tvalid_0's tweedie: 158.092\n",
      "[206]\tvalid_0's tweedie: 158.092\n",
      "[207]\tvalid_0's tweedie: 158.092\n",
      "[208]\tvalid_0's tweedie: 158.092\n",
      "[209]\tvalid_0's tweedie: 158.092\n",
      "[210]\tvalid_0's tweedie: 158.092\n",
      "[211]\tvalid_0's tweedie: 158.092\n",
      "[212]\tvalid_0's tweedie: 158.092\n",
      "[213]\tvalid_0's tweedie: 158.092\n",
      "[214]\tvalid_0's tweedie: 158.092\n",
      "[215]\tvalid_0's tweedie: 158.092\n",
      "[216]\tvalid_0's tweedie: 158.092\n",
      "[217]\tvalid_0's tweedie: 158.092\n",
      "[218]\tvalid_0's tweedie: 158.092\n",
      "[219]\tvalid_0's tweedie: 158.092\n",
      "[220]\tvalid_0's tweedie: 158.091\n",
      "[221]\tvalid_0's tweedie: 158.091\n",
      "[222]\tvalid_0's tweedie: 158.091\n",
      "[223]\tvalid_0's tweedie: 158.092\n",
      "[224]\tvalid_0's tweedie: 158.091\n",
      "[225]\tvalid_0's tweedie: 158.091\n",
      "[226]\tvalid_0's tweedie: 158.092\n",
      "[227]\tvalid_0's tweedie: 158.091\n",
      "[228]\tvalid_0's tweedie: 158.091\n",
      "[229]\tvalid_0's tweedie: 158.091\n",
      "[230]\tvalid_0's tweedie: 158.091\n",
      "[231]\tvalid_0's tweedie: 158.091\n",
      "[232]\tvalid_0's tweedie: 158.091\n",
      "[233]\tvalid_0's tweedie: 158.091\n",
      "[234]\tvalid_0's tweedie: 158.091\n",
      "[235]\tvalid_0's tweedie: 158.091\n",
      "[236]\tvalid_0's tweedie: 158.091\n",
      "[237]\tvalid_0's tweedie: 158.091\n",
      "[238]\tvalid_0's tweedie: 158.091\n",
      "[239]\tvalid_0's tweedie: 158.091\n",
      "[240]\tvalid_0's tweedie: 158.091\n",
      "[241]\tvalid_0's tweedie: 158.091\n",
      "[242]\tvalid_0's tweedie: 158.091\n",
      "[243]\tvalid_0's tweedie: 158.091\n",
      "[244]\tvalid_0's tweedie: 158.09\n",
      "[245]\tvalid_0's tweedie: 158.09\n",
      "[246]\tvalid_0's tweedie: 158.09\n",
      "[247]\tvalid_0's tweedie: 158.09\n",
      "[248]\tvalid_0's tweedie: 158.09\n",
      "[249]\tvalid_0's tweedie: 158.09\n",
      "[250]\tvalid_0's tweedie: 158.09\n",
      "[251]\tvalid_0's tweedie: 158.09\n",
      "[252]\tvalid_0's tweedie: 158.09\n",
      "[253]\tvalid_0's tweedie: 158.09\n",
      "[254]\tvalid_0's tweedie: 158.09\n",
      "[255]\tvalid_0's tweedie: 158.09\n",
      "[256]\tvalid_0's tweedie: 158.09\n",
      "[257]\tvalid_0's tweedie: 158.09\n",
      "[258]\tvalid_0's tweedie: 158.09\n",
      "[259]\tvalid_0's tweedie: 158.09\n",
      "[260]\tvalid_0's tweedie: 158.091\n",
      "[261]\tvalid_0's tweedie: 158.091\n",
      "[262]\tvalid_0's tweedie: 158.091\n",
      "[263]\tvalid_0's tweedie: 158.091\n",
      "[264]\tvalid_0's tweedie: 158.091\n",
      "[265]\tvalid_0's tweedie: 158.091\n",
      "[266]\tvalid_0's tweedie: 158.091\n",
      "[267]\tvalid_0's tweedie: 158.091\n",
      "[268]\tvalid_0's tweedie: 158.09\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's tweedie: 158.09\n",
      "Training model for level 7 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 38892, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400403\n",
      "[1]\tvalid_0's tweedie: 176.781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.692\n",
      "[3]\tvalid_0's tweedie: 171.075\n",
      "[4]\tvalid_0's tweedie: 168.869\n",
      "[5]\tvalid_0's tweedie: 167.023\n",
      "[6]\tvalid_0's tweedie: 165.478\n",
      "[7]\tvalid_0's tweedie: 164.191\n",
      "[8]\tvalid_0's tweedie: 163.132\n",
      "[9]\tvalid_0's tweedie: 162.243\n",
      "[10]\tvalid_0's tweedie: 161.503\n",
      "[11]\tvalid_0's tweedie: 160.896\n",
      "[12]\tvalid_0's tweedie: 160.392\n",
      "[13]\tvalid_0's tweedie: 159.976\n",
      "[14]\tvalid_0's tweedie: 159.639\n",
      "[15]\tvalid_0's tweedie: 159.363\n",
      "[16]\tvalid_0's tweedie: 159.137\n",
      "[17]\tvalid_0's tweedie: 158.951\n",
      "[18]\tvalid_0's tweedie: 158.799\n",
      "[19]\tvalid_0's tweedie: 158.681\n",
      "[20]\tvalid_0's tweedie: 158.572\n",
      "[21]\tvalid_0's tweedie: 158.491\n",
      "[22]\tvalid_0's tweedie: 158.425\n",
      "[23]\tvalid_0's tweedie: 158.367\n",
      "[24]\tvalid_0's tweedie: 158.32\n",
      "[25]\tvalid_0's tweedie: 158.279\n",
      "[26]\tvalid_0's tweedie: 158.249\n",
      "[27]\tvalid_0's tweedie: 158.221\n",
      "[28]\tvalid_0's tweedie: 158.205\n",
      "[29]\tvalid_0's tweedie: 158.187\n",
      "[30]\tvalid_0's tweedie: 158.174\n",
      "[31]\tvalid_0's tweedie: 158.164\n",
      "[32]\tvalid_0's tweedie: 158.152\n",
      "[33]\tvalid_0's tweedie: 158.147\n",
      "[34]\tvalid_0's tweedie: 158.14\n",
      "[35]\tvalid_0's tweedie: 158.134\n",
      "[36]\tvalid_0's tweedie: 158.13\n",
      "[37]\tvalid_0's tweedie: 158.126\n",
      "[38]\tvalid_0's tweedie: 158.124\n",
      "[39]\tvalid_0's tweedie: 158.122\n",
      "[40]\tvalid_0's tweedie: 158.12\n",
      "[41]\tvalid_0's tweedie: 158.117\n",
      "[42]\tvalid_0's tweedie: 158.116\n",
      "[43]\tvalid_0's tweedie: 158.116\n",
      "[44]\tvalid_0's tweedie: 158.117\n",
      "[45]\tvalid_0's tweedie: 158.116\n",
      "[46]\tvalid_0's tweedie: 158.115\n",
      "[47]\tvalid_0's tweedie: 158.114\n",
      "[48]\tvalid_0's tweedie: 158.114\n",
      "[49]\tvalid_0's tweedie: 158.115\n",
      "[50]\tvalid_0's tweedie: 158.115\n",
      "[51]\tvalid_0's tweedie: 158.115\n",
      "[52]\tvalid_0's tweedie: 158.114\n",
      "[53]\tvalid_0's tweedie: 158.114\n",
      "[54]\tvalid_0's tweedie: 158.115\n",
      "[55]\tvalid_0's tweedie: 158.115\n",
      "[56]\tvalid_0's tweedie: 158.115\n",
      "[57]\tvalid_0's tweedie: 158.115\n",
      "[58]\tvalid_0's tweedie: 158.114\n",
      "[59]\tvalid_0's tweedie: 158.113\n",
      "[60]\tvalid_0's tweedie: 158.111\n",
      "[61]\tvalid_0's tweedie: 158.111\n",
      "[62]\tvalid_0's tweedie: 158.112\n",
      "[63]\tvalid_0's tweedie: 158.111\n",
      "[64]\tvalid_0's tweedie: 158.11\n",
      "[65]\tvalid_0's tweedie: 158.11\n",
      "[66]\tvalid_0's tweedie: 158.11\n",
      "[67]\tvalid_0's tweedie: 158.11\n",
      "[68]\tvalid_0's tweedie: 158.11\n",
      "[69]\tvalid_0's tweedie: 158.11\n",
      "[70]\tvalid_0's tweedie: 158.111\n",
      "[71]\tvalid_0's tweedie: 158.11\n",
      "[72]\tvalid_0's tweedie: 158.109\n",
      "[73]\tvalid_0's tweedie: 158.109\n",
      "[74]\tvalid_0's tweedie: 158.108\n",
      "[75]\tvalid_0's tweedie: 158.109\n",
      "[76]\tvalid_0's tweedie: 158.108\n",
      "[77]\tvalid_0's tweedie: 158.107\n",
      "[78]\tvalid_0's tweedie: 158.107\n",
      "[79]\tvalid_0's tweedie: 158.107\n",
      "[80]\tvalid_0's tweedie: 158.107\n",
      "[81]\tvalid_0's tweedie: 158.106\n",
      "[82]\tvalid_0's tweedie: 158.106\n",
      "[83]\tvalid_0's tweedie: 158.106\n",
      "[84]\tvalid_0's tweedie: 158.106\n",
      "[85]\tvalid_0's tweedie: 158.106\n",
      "[86]\tvalid_0's tweedie: 158.105\n",
      "[87]\tvalid_0's tweedie: 158.105\n",
      "[88]\tvalid_0's tweedie: 158.105\n",
      "[89]\tvalid_0's tweedie: 158.105\n",
      "[90]\tvalid_0's tweedie: 158.104\n",
      "[91]\tvalid_0's tweedie: 158.104\n",
      "[92]\tvalid_0's tweedie: 158.104\n",
      "[93]\tvalid_0's tweedie: 158.104\n",
      "[94]\tvalid_0's tweedie: 158.103\n",
      "[95]\tvalid_0's tweedie: 158.103\n",
      "[96]\tvalid_0's tweedie: 158.103\n",
      "[97]\tvalid_0's tweedie: 158.103\n",
      "[98]\tvalid_0's tweedie: 158.103\n",
      "[99]\tvalid_0's tweedie: 158.103\n",
      "[100]\tvalid_0's tweedie: 158.103\n",
      "[101]\tvalid_0's tweedie: 158.102\n",
      "[102]\tvalid_0's tweedie: 158.102\n",
      "[103]\tvalid_0's tweedie: 158.101\n",
      "[104]\tvalid_0's tweedie: 158.101\n",
      "[105]\tvalid_0's tweedie: 158.101\n",
      "[106]\tvalid_0's tweedie: 158.101\n",
      "[107]\tvalid_0's tweedie: 158.101\n",
      "[108]\tvalid_0's tweedie: 158.101\n",
      "[109]\tvalid_0's tweedie: 158.101\n",
      "[110]\tvalid_0's tweedie: 158.101\n",
      "[111]\tvalid_0's tweedie: 158.101\n",
      "[112]\tvalid_0's tweedie: 158.101\n",
      "[113]\tvalid_0's tweedie: 158.1\n",
      "[114]\tvalid_0's tweedie: 158.1\n",
      "[115]\tvalid_0's tweedie: 158.099\n",
      "[116]\tvalid_0's tweedie: 158.099\n",
      "[117]\tvalid_0's tweedie: 158.099\n",
      "[118]\tvalid_0's tweedie: 158.099\n",
      "[119]\tvalid_0's tweedie: 158.099\n",
      "[120]\tvalid_0's tweedie: 158.099\n",
      "[121]\tvalid_0's tweedie: 158.099\n",
      "[122]\tvalid_0's tweedie: 158.099\n",
      "[123]\tvalid_0's tweedie: 158.098\n",
      "[124]\tvalid_0's tweedie: 158.098\n",
      "[125]\tvalid_0's tweedie: 158.097\n",
      "[126]\tvalid_0's tweedie: 158.097\n",
      "[127]\tvalid_0's tweedie: 158.097\n",
      "[128]\tvalid_0's tweedie: 158.097\n",
      "[129]\tvalid_0's tweedie: 158.097\n",
      "[130]\tvalid_0's tweedie: 158.097\n",
      "[131]\tvalid_0's tweedie: 158.096\n",
      "[132]\tvalid_0's tweedie: 158.096\n",
      "[133]\tvalid_0's tweedie: 158.096\n",
      "[134]\tvalid_0's tweedie: 158.096\n",
      "[135]\tvalid_0's tweedie: 158.096\n",
      "[136]\tvalid_0's tweedie: 158.097\n",
      "[137]\tvalid_0's tweedie: 158.097\n",
      "[138]\tvalid_0's tweedie: 158.097\n",
      "[139]\tvalid_0's tweedie: 158.096\n",
      "[140]\tvalid_0's tweedie: 158.096\n",
      "[141]\tvalid_0's tweedie: 158.096\n",
      "[142]\tvalid_0's tweedie: 158.096\n",
      "[143]\tvalid_0's tweedie: 158.096\n",
      "[144]\tvalid_0's tweedie: 158.096\n",
      "[145]\tvalid_0's tweedie: 158.096\n",
      "[146]\tvalid_0's tweedie: 158.096\n",
      "[147]\tvalid_0's tweedie: 158.096\n",
      "[148]\tvalid_0's tweedie: 158.096\n",
      "[149]\tvalid_0's tweedie: 158.095\n",
      "[150]\tvalid_0's tweedie: 158.094\n",
      "[151]\tvalid_0's tweedie: 158.094\n",
      "[152]\tvalid_0's tweedie: 158.094\n",
      "[153]\tvalid_0's tweedie: 158.094\n",
      "[154]\tvalid_0's tweedie: 158.094\n",
      "[155]\tvalid_0's tweedie: 158.094\n",
      "[156]\tvalid_0's tweedie: 158.094\n",
      "[157]\tvalid_0's tweedie: 158.094\n",
      "[158]\tvalid_0's tweedie: 158.094\n",
      "[159]\tvalid_0's tweedie: 158.094\n",
      "[160]\tvalid_0's tweedie: 158.094\n",
      "[161]\tvalid_0's tweedie: 158.094\n",
      "[162]\tvalid_0's tweedie: 158.094\n",
      "[163]\tvalid_0's tweedie: 158.094\n",
      "[164]\tvalid_0's tweedie: 158.094\n",
      "[165]\tvalid_0's tweedie: 158.094\n",
      "[166]\tvalid_0's tweedie: 158.094\n",
      "[167]\tvalid_0's tweedie: 158.094\n",
      "[168]\tvalid_0's tweedie: 158.094\n",
      "[169]\tvalid_0's tweedie: 158.094\n",
      "[170]\tvalid_0's tweedie: 158.094\n",
      "[171]\tvalid_0's tweedie: 158.094\n",
      "[172]\tvalid_0's tweedie: 158.094\n",
      "[173]\tvalid_0's tweedie: 158.094\n",
      "[174]\tvalid_0's tweedie: 158.094\n",
      "[175]\tvalid_0's tweedie: 158.094\n",
      "[176]\tvalid_0's tweedie: 158.094\n",
      "[177]\tvalid_0's tweedie: 158.094\n",
      "[178]\tvalid_0's tweedie: 158.093\n",
      "[179]\tvalid_0's tweedie: 158.093\n",
      "[180]\tvalid_0's tweedie: 158.093\n",
      "[181]\tvalid_0's tweedie: 158.093\n",
      "[182]\tvalid_0's tweedie: 158.093\n",
      "[183]\tvalid_0's tweedie: 158.093\n",
      "[184]\tvalid_0's tweedie: 158.093\n",
      "[185]\tvalid_0's tweedie: 158.093\n",
      "[186]\tvalid_0's tweedie: 158.093\n",
      "[187]\tvalid_0's tweedie: 158.093\n",
      "[188]\tvalid_0's tweedie: 158.092\n",
      "[189]\tvalid_0's tweedie: 158.092\n",
      "[190]\tvalid_0's tweedie: 158.092\n",
      "[191]\tvalid_0's tweedie: 158.092\n",
      "[192]\tvalid_0's tweedie: 158.092\n",
      "[193]\tvalid_0's tweedie: 158.092\n",
      "[194]\tvalid_0's tweedie: 158.092\n",
      "[195]\tvalid_0's tweedie: 158.092\n",
      "[196]\tvalid_0's tweedie: 158.092\n",
      "[197]\tvalid_0's tweedie: 158.092\n",
      "[198]\tvalid_0's tweedie: 158.092\n",
      "[199]\tvalid_0's tweedie: 158.092\n",
      "[200]\tvalid_0's tweedie: 158.092\n",
      "[201]\tvalid_0's tweedie: 158.092\n",
      "[202]\tvalid_0's tweedie: 158.092\n",
      "[203]\tvalid_0's tweedie: 158.092\n",
      "[204]\tvalid_0's tweedie: 158.092\n",
      "[205]\tvalid_0's tweedie: 158.092\n",
      "[206]\tvalid_0's tweedie: 158.092\n",
      "[207]\tvalid_0's tweedie: 158.092\n",
      "[208]\tvalid_0's tweedie: 158.092\n",
      "[209]\tvalid_0's tweedie: 158.092\n",
      "[210]\tvalid_0's tweedie: 158.092\n",
      "[211]\tvalid_0's tweedie: 158.092\n",
      "[212]\tvalid_0's tweedie: 158.092\n",
      "[213]\tvalid_0's tweedie: 158.092\n",
      "[214]\tvalid_0's tweedie: 158.092\n",
      "[215]\tvalid_0's tweedie: 158.092\n",
      "[216]\tvalid_0's tweedie: 158.092\n",
      "[217]\tvalid_0's tweedie: 158.09\n",
      "[218]\tvalid_0's tweedie: 158.09\n",
      "[219]\tvalid_0's tweedie: 158.09\n",
      "[220]\tvalid_0's tweedie: 158.09\n",
      "[221]\tvalid_0's tweedie: 158.09\n",
      "[222]\tvalid_0's tweedie: 158.09\n",
      "[223]\tvalid_0's tweedie: 158.09\n",
      "[224]\tvalid_0's tweedie: 158.09\n",
      "[225]\tvalid_0's tweedie: 158.09\n",
      "[226]\tvalid_0's tweedie: 158.09\n",
      "[227]\tvalid_0's tweedie: 158.09\n",
      "[228]\tvalid_0's tweedie: 158.09\n",
      "[229]\tvalid_0's tweedie: 158.09\n",
      "[230]\tvalid_0's tweedie: 158.09\n",
      "[231]\tvalid_0's tweedie: 158.091\n",
      "[232]\tvalid_0's tweedie: 158.091\n",
      "[233]\tvalid_0's tweedie: 158.091\n",
      "[234]\tvalid_0's tweedie: 158.091\n",
      "[235]\tvalid_0's tweedie: 158.091\n",
      "[236]\tvalid_0's tweedie: 158.091\n",
      "[237]\tvalid_0's tweedie: 158.091\n",
      "[238]\tvalid_0's tweedie: 158.091\n",
      "[239]\tvalid_0's tweedie: 158.091\n",
      "[240]\tvalid_0's tweedie: 158.091\n",
      "[241]\tvalid_0's tweedie: 158.091\n",
      "[242]\tvalid_0's tweedie: 158.091\n",
      "[243]\tvalid_0's tweedie: 158.09\n",
      "[244]\tvalid_0's tweedie: 158.09\n",
      "[245]\tvalid_0's tweedie: 158.091\n",
      "[246]\tvalid_0's tweedie: 158.091\n",
      "[247]\tvalid_0's tweedie: 158.091\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's tweedie: 158.09\n",
      "Training model for level 7 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 38871, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400574\n",
      "[1]\tvalid_0's tweedie: 176.777\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.685\n",
      "[3]\tvalid_0's tweedie: 171.069\n",
      "[4]\tvalid_0's tweedie: 168.864\n",
      "[5]\tvalid_0's tweedie: 167.012\n",
      "[6]\tvalid_0's tweedie: 165.465\n",
      "[7]\tvalid_0's tweedie: 164.186\n",
      "[8]\tvalid_0's tweedie: 163.11\n",
      "[9]\tvalid_0's tweedie: 162.226\n",
      "[10]\tvalid_0's tweedie: 161.484\n",
      "[11]\tvalid_0's tweedie: 160.877\n",
      "[12]\tvalid_0's tweedie: 160.369\n",
      "[13]\tvalid_0's tweedie: 159.955\n",
      "[14]\tvalid_0's tweedie: 159.613\n",
      "[15]\tvalid_0's tweedie: 159.33\n",
      "[16]\tvalid_0's tweedie: 159.102\n",
      "[17]\tvalid_0's tweedie: 158.927\n",
      "[18]\tvalid_0's tweedie: 158.773\n",
      "[19]\tvalid_0's tweedie: 158.649\n",
      "[20]\tvalid_0's tweedie: 158.548\n",
      "[21]\tvalid_0's tweedie: 158.467\n",
      "[22]\tvalid_0's tweedie: 158.394\n",
      "[23]\tvalid_0's tweedie: 158.342\n",
      "[24]\tvalid_0's tweedie: 158.296\n",
      "[25]\tvalid_0's tweedie: 158.263\n",
      "[26]\tvalid_0's tweedie: 158.232\n",
      "[27]\tvalid_0's tweedie: 158.205\n",
      "[28]\tvalid_0's tweedie: 158.183\n",
      "[29]\tvalid_0's tweedie: 158.167\n",
      "[30]\tvalid_0's tweedie: 158.15\n",
      "[31]\tvalid_0's tweedie: 158.139\n",
      "[32]\tvalid_0's tweedie: 158.131\n",
      "[33]\tvalid_0's tweedie: 158.121\n",
      "[34]\tvalid_0's tweedie: 158.115\n",
      "[35]\tvalid_0's tweedie: 158.11\n",
      "[36]\tvalid_0's tweedie: 158.106\n",
      "[37]\tvalid_0's tweedie: 158.103\n",
      "[38]\tvalid_0's tweedie: 158.101\n",
      "[39]\tvalid_0's tweedie: 158.099\n",
      "[40]\tvalid_0's tweedie: 158.098\n",
      "[41]\tvalid_0's tweedie: 158.096\n",
      "[42]\tvalid_0's tweedie: 158.096\n",
      "[43]\tvalid_0's tweedie: 158.098\n",
      "[44]\tvalid_0's tweedie: 158.098\n",
      "[45]\tvalid_0's tweedie: 158.097\n",
      "[46]\tvalid_0's tweedie: 158.097\n",
      "[47]\tvalid_0's tweedie: 158.097\n",
      "[48]\tvalid_0's tweedie: 158.096\n",
      "[49]\tvalid_0's tweedie: 158.095\n",
      "[50]\tvalid_0's tweedie: 158.095\n",
      "[51]\tvalid_0's tweedie: 158.095\n",
      "[52]\tvalid_0's tweedie: 158.095\n",
      "[53]\tvalid_0's tweedie: 158.095\n",
      "[54]\tvalid_0's tweedie: 158.094\n",
      "[55]\tvalid_0's tweedie: 158.095\n",
      "[56]\tvalid_0's tweedie: 158.095\n",
      "[57]\tvalid_0's tweedie: 158.095\n",
      "[58]\tvalid_0's tweedie: 158.094\n",
      "[59]\tvalid_0's tweedie: 158.094\n",
      "[60]\tvalid_0's tweedie: 158.094\n",
      "[61]\tvalid_0's tweedie: 158.094\n",
      "[62]\tvalid_0's tweedie: 158.094\n",
      "[63]\tvalid_0's tweedie: 158.094\n",
      "[64]\tvalid_0's tweedie: 158.095\n",
      "[65]\tvalid_0's tweedie: 158.093\n",
      "[66]\tvalid_0's tweedie: 158.093\n",
      "[67]\tvalid_0's tweedie: 158.093\n",
      "[68]\tvalid_0's tweedie: 158.093\n",
      "[69]\tvalid_0's tweedie: 158.093\n",
      "[70]\tvalid_0's tweedie: 158.093\n",
      "[71]\tvalid_0's tweedie: 158.092\n",
      "[72]\tvalid_0's tweedie: 158.091\n",
      "[73]\tvalid_0's tweedie: 158.09\n",
      "[74]\tvalid_0's tweedie: 158.09\n",
      "[75]\tvalid_0's tweedie: 158.091\n",
      "[76]\tvalid_0's tweedie: 158.091\n",
      "[77]\tvalid_0's tweedie: 158.091\n",
      "[78]\tvalid_0's tweedie: 158.09\n",
      "[79]\tvalid_0's tweedie: 158.09\n",
      "[80]\tvalid_0's tweedie: 158.089\n",
      "[81]\tvalid_0's tweedie: 158.089\n",
      "[82]\tvalid_0's tweedie: 158.09\n",
      "[83]\tvalid_0's tweedie: 158.089\n",
      "[84]\tvalid_0's tweedie: 158.089\n",
      "[85]\tvalid_0's tweedie: 158.089\n",
      "[86]\tvalid_0's tweedie: 158.089\n",
      "[87]\tvalid_0's tweedie: 158.089\n",
      "[88]\tvalid_0's tweedie: 158.089\n",
      "[89]\tvalid_0's tweedie: 158.089\n",
      "[90]\tvalid_0's tweedie: 158.089\n",
      "[91]\tvalid_0's tweedie: 158.089\n",
      "[92]\tvalid_0's tweedie: 158.089\n",
      "[93]\tvalid_0's tweedie: 158.089\n",
      "[94]\tvalid_0's tweedie: 158.089\n",
      "[95]\tvalid_0's tweedie: 158.089\n",
      "[96]\tvalid_0's tweedie: 158.089\n",
      "[97]\tvalid_0's tweedie: 158.088\n",
      "[98]\tvalid_0's tweedie: 158.088\n",
      "[99]\tvalid_0's tweedie: 158.088\n",
      "[100]\tvalid_0's tweedie: 158.088\n",
      "[101]\tvalid_0's tweedie: 158.087\n",
      "[102]\tvalid_0's tweedie: 158.087\n",
      "[103]\tvalid_0's tweedie: 158.087\n",
      "[104]\tvalid_0's tweedie: 158.087\n",
      "[105]\tvalid_0's tweedie: 158.087\n",
      "[106]\tvalid_0's tweedie: 158.087\n",
      "[107]\tvalid_0's tweedie: 158.087\n",
      "[108]\tvalid_0's tweedie: 158.087\n",
      "[109]\tvalid_0's tweedie: 158.087\n",
      "[110]\tvalid_0's tweedie: 158.087\n",
      "[111]\tvalid_0's tweedie: 158.086\n",
      "[112]\tvalid_0's tweedie: 158.086\n",
      "[113]\tvalid_0's tweedie: 158.086\n",
      "[114]\tvalid_0's tweedie: 158.086\n",
      "[115]\tvalid_0's tweedie: 158.086\n",
      "[116]\tvalid_0's tweedie: 158.085\n",
      "[117]\tvalid_0's tweedie: 158.085\n",
      "[118]\tvalid_0's tweedie: 158.085\n",
      "[119]\tvalid_0's tweedie: 158.084\n",
      "[120]\tvalid_0's tweedie: 158.084\n",
      "[121]\tvalid_0's tweedie: 158.084\n",
      "[122]\tvalid_0's tweedie: 158.084\n",
      "[123]\tvalid_0's tweedie: 158.084\n",
      "[124]\tvalid_0's tweedie: 158.084\n",
      "[125]\tvalid_0's tweedie: 158.084\n",
      "[126]\tvalid_0's tweedie: 158.084\n",
      "[127]\tvalid_0's tweedie: 158.084\n",
      "[128]\tvalid_0's tweedie: 158.084\n",
      "[129]\tvalid_0's tweedie: 158.084\n",
      "[130]\tvalid_0's tweedie: 158.084\n",
      "[131]\tvalid_0's tweedie: 158.083\n",
      "[132]\tvalid_0's tweedie: 158.084\n",
      "[133]\tvalid_0's tweedie: 158.083\n",
      "[134]\tvalid_0's tweedie: 158.083\n",
      "[135]\tvalid_0's tweedie: 158.083\n",
      "[136]\tvalid_0's tweedie: 158.083\n",
      "[137]\tvalid_0's tweedie: 158.083\n",
      "[138]\tvalid_0's tweedie: 158.083\n",
      "[139]\tvalid_0's tweedie: 158.083\n",
      "[140]\tvalid_0's tweedie: 158.083\n",
      "[141]\tvalid_0's tweedie: 158.083\n",
      "[142]\tvalid_0's tweedie: 158.082\n",
      "[143]\tvalid_0's tweedie: 158.083\n",
      "[144]\tvalid_0's tweedie: 158.083\n",
      "[145]\tvalid_0's tweedie: 158.083\n",
      "[146]\tvalid_0's tweedie: 158.083\n",
      "[147]\tvalid_0's tweedie: 158.082\n",
      "[148]\tvalid_0's tweedie: 158.082\n",
      "[149]\tvalid_0's tweedie: 158.082\n",
      "[150]\tvalid_0's tweedie: 158.082\n",
      "[151]\tvalid_0's tweedie: 158.082\n",
      "[152]\tvalid_0's tweedie: 158.081\n",
      "[153]\tvalid_0's tweedie: 158.081\n",
      "[154]\tvalid_0's tweedie: 158.081\n",
      "[155]\tvalid_0's tweedie: 158.081\n",
      "[156]\tvalid_0's tweedie: 158.081\n",
      "[157]\tvalid_0's tweedie: 158.081\n",
      "[158]\tvalid_0's tweedie: 158.081\n",
      "[159]\tvalid_0's tweedie: 158.081\n",
      "[160]\tvalid_0's tweedie: 158.081\n",
      "[161]\tvalid_0's tweedie: 158.081\n",
      "[162]\tvalid_0's tweedie: 158.081\n",
      "[163]\tvalid_0's tweedie: 158.081\n",
      "[164]\tvalid_0's tweedie: 158.081\n",
      "[165]\tvalid_0's tweedie: 158.081\n",
      "[166]\tvalid_0's tweedie: 158.081\n",
      "[167]\tvalid_0's tweedie: 158.082\n",
      "[168]\tvalid_0's tweedie: 158.081\n",
      "[169]\tvalid_0's tweedie: 158.082\n",
      "[170]\tvalid_0's tweedie: 158.082\n",
      "[171]\tvalid_0's tweedie: 158.082\n",
      "[172]\tvalid_0's tweedie: 158.082\n",
      "[173]\tvalid_0's tweedie: 158.082\n",
      "[174]\tvalid_0's tweedie: 158.082\n",
      "[175]\tvalid_0's tweedie: 158.082\n",
      "[176]\tvalid_0's tweedie: 158.082\n",
      "[177]\tvalid_0's tweedie: 158.082\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's tweedie: 158.081\n",
      "Training model for level 7 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 38850, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400744\n",
      "[1]\tvalid_0's tweedie: 176.771\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.684\n",
      "[3]\tvalid_0's tweedie: 171.061\n",
      "[4]\tvalid_0's tweedie: 168.853\n",
      "[5]\tvalid_0's tweedie: 166.993\n",
      "[6]\tvalid_0's tweedie: 165.45\n",
      "[7]\tvalid_0's tweedie: 164.164\n",
      "[8]\tvalid_0's tweedie: 163.096\n",
      "[9]\tvalid_0's tweedie: 162.187\n",
      "[10]\tvalid_0's tweedie: 161.46\n",
      "[11]\tvalid_0's tweedie: 160.839\n",
      "[12]\tvalid_0's tweedie: 160.335\n",
      "[13]\tvalid_0's tweedie: 159.917\n",
      "[14]\tvalid_0's tweedie: 159.576\n",
      "[15]\tvalid_0's tweedie: 159.306\n",
      "[16]\tvalid_0's tweedie: 159.083\n",
      "[17]\tvalid_0's tweedie: 158.9\n",
      "[18]\tvalid_0's tweedie: 158.745\n",
      "[19]\tvalid_0's tweedie: 158.619\n",
      "[20]\tvalid_0's tweedie: 158.522\n",
      "[21]\tvalid_0's tweedie: 158.44\n",
      "[22]\tvalid_0's tweedie: 158.378\n",
      "[23]\tvalid_0's tweedie: 158.322\n",
      "[24]\tvalid_0's tweedie: 158.28\n",
      "[25]\tvalid_0's tweedie: 158.239\n",
      "[26]\tvalid_0's tweedie: 158.204\n",
      "[27]\tvalid_0's tweedie: 158.18\n",
      "[28]\tvalid_0's tweedie: 158.157\n",
      "[29]\tvalid_0's tweedie: 158.141\n",
      "[30]\tvalid_0's tweedie: 158.127\n",
      "[31]\tvalid_0's tweedie: 158.117\n",
      "[32]\tvalid_0's tweedie: 158.107\n",
      "[33]\tvalid_0's tweedie: 158.101\n",
      "[34]\tvalid_0's tweedie: 158.095\n",
      "[35]\tvalid_0's tweedie: 158.092\n",
      "[36]\tvalid_0's tweedie: 158.087\n",
      "[37]\tvalid_0's tweedie: 158.084\n",
      "[38]\tvalid_0's tweedie: 158.081\n",
      "[39]\tvalid_0's tweedie: 158.079\n",
      "[40]\tvalid_0's tweedie: 158.078\n",
      "[41]\tvalid_0's tweedie: 158.077\n",
      "[42]\tvalid_0's tweedie: 158.077\n",
      "[43]\tvalid_0's tweedie: 158.077\n",
      "[44]\tvalid_0's tweedie: 158.077\n",
      "[45]\tvalid_0's tweedie: 158.077\n",
      "[46]\tvalid_0's tweedie: 158.077\n",
      "[47]\tvalid_0's tweedie: 158.076\n",
      "[48]\tvalid_0's tweedie: 158.075\n",
      "[49]\tvalid_0's tweedie: 158.075\n",
      "[50]\tvalid_0's tweedie: 158.075\n",
      "[51]\tvalid_0's tweedie: 158.075\n",
      "[52]\tvalid_0's tweedie: 158.076\n",
      "[53]\tvalid_0's tweedie: 158.076\n",
      "[54]\tvalid_0's tweedie: 158.076\n",
      "[55]\tvalid_0's tweedie: 158.076\n",
      "[56]\tvalid_0's tweedie: 158.075\n",
      "[57]\tvalid_0's tweedie: 158.076\n",
      "[58]\tvalid_0's tweedie: 158.075\n",
      "[59]\tvalid_0's tweedie: 158.074\n",
      "[60]\tvalid_0's tweedie: 158.073\n",
      "[61]\tvalid_0's tweedie: 158.073\n",
      "[62]\tvalid_0's tweedie: 158.073\n",
      "[63]\tvalid_0's tweedie: 158.073\n",
      "[64]\tvalid_0's tweedie: 158.073\n",
      "[65]\tvalid_0's tweedie: 158.073\n",
      "[66]\tvalid_0's tweedie: 158.072\n",
      "[67]\tvalid_0's tweedie: 158.071\n",
      "[68]\tvalid_0's tweedie: 158.07\n",
      "[69]\tvalid_0's tweedie: 158.07\n",
      "[70]\tvalid_0's tweedie: 158.069\n",
      "[71]\tvalid_0's tweedie: 158.069\n",
      "[72]\tvalid_0's tweedie: 158.069\n",
      "[73]\tvalid_0's tweedie: 158.068\n",
      "[74]\tvalid_0's tweedie: 158.068\n",
      "[75]\tvalid_0's tweedie: 158.068\n",
      "[76]\tvalid_0's tweedie: 158.068\n",
      "[77]\tvalid_0's tweedie: 158.068\n",
      "[78]\tvalid_0's tweedie: 158.068\n",
      "[79]\tvalid_0's tweedie: 158.067\n",
      "[80]\tvalid_0's tweedie: 158.067\n",
      "[81]\tvalid_0's tweedie: 158.067\n",
      "[82]\tvalid_0's tweedie: 158.067\n",
      "[83]\tvalid_0's tweedie: 158.067\n",
      "[84]\tvalid_0's tweedie: 158.067\n",
      "[85]\tvalid_0's tweedie: 158.067\n",
      "[86]\tvalid_0's tweedie: 158.067\n",
      "[87]\tvalid_0's tweedie: 158.066\n",
      "[88]\tvalid_0's tweedie: 158.066\n",
      "[89]\tvalid_0's tweedie: 158.066\n",
      "[90]\tvalid_0's tweedie: 158.066\n",
      "[91]\tvalid_0's tweedie: 158.066\n",
      "[92]\tvalid_0's tweedie: 158.065\n",
      "[93]\tvalid_0's tweedie: 158.065\n",
      "[94]\tvalid_0's tweedie: 158.065\n",
      "[95]\tvalid_0's tweedie: 158.064\n",
      "[96]\tvalid_0's tweedie: 158.064\n",
      "[97]\tvalid_0's tweedie: 158.064\n",
      "[98]\tvalid_0's tweedie: 158.064\n",
      "[99]\tvalid_0's tweedie: 158.064\n",
      "[100]\tvalid_0's tweedie: 158.064\n",
      "[101]\tvalid_0's tweedie: 158.063\n",
      "[102]\tvalid_0's tweedie: 158.062\n",
      "[103]\tvalid_0's tweedie: 158.062\n",
      "[104]\tvalid_0's tweedie: 158.062\n",
      "[105]\tvalid_0's tweedie: 158.062\n",
      "[106]\tvalid_0's tweedie: 158.062\n",
      "[107]\tvalid_0's tweedie: 158.062\n",
      "[108]\tvalid_0's tweedie: 158.062\n",
      "[109]\tvalid_0's tweedie: 158.061\n",
      "[110]\tvalid_0's tweedie: 158.061\n",
      "[111]\tvalid_0's tweedie: 158.061\n",
      "[112]\tvalid_0's tweedie: 158.061\n",
      "[113]\tvalid_0's tweedie: 158.061\n",
      "[114]\tvalid_0's tweedie: 158.06\n",
      "[115]\tvalid_0's tweedie: 158.06\n",
      "[116]\tvalid_0's tweedie: 158.06\n",
      "[117]\tvalid_0's tweedie: 158.06\n",
      "[118]\tvalid_0's tweedie: 158.06\n",
      "[119]\tvalid_0's tweedie: 158.06\n",
      "[120]\tvalid_0's tweedie: 158.06\n",
      "[121]\tvalid_0's tweedie: 158.06\n",
      "[122]\tvalid_0's tweedie: 158.06\n",
      "[123]\tvalid_0's tweedie: 158.06\n",
      "[124]\tvalid_0's tweedie: 158.06\n",
      "[125]\tvalid_0's tweedie: 158.06\n",
      "[126]\tvalid_0's tweedie: 158.06\n",
      "[127]\tvalid_0's tweedie: 158.059\n",
      "[128]\tvalid_0's tweedie: 158.059\n",
      "[129]\tvalid_0's tweedie: 158.059\n",
      "[130]\tvalid_0's tweedie: 158.059\n",
      "[131]\tvalid_0's tweedie: 158.059\n",
      "[132]\tvalid_0's tweedie: 158.059\n",
      "[133]\tvalid_0's tweedie: 158.059\n",
      "[134]\tvalid_0's tweedie: 158.059\n",
      "[135]\tvalid_0's tweedie: 158.059\n",
      "[136]\tvalid_0's tweedie: 158.059\n",
      "[137]\tvalid_0's tweedie: 158.059\n",
      "[138]\tvalid_0's tweedie: 158.059\n",
      "[139]\tvalid_0's tweedie: 158.059\n",
      "[140]\tvalid_0's tweedie: 158.059\n",
      "[141]\tvalid_0's tweedie: 158.059\n",
      "[142]\tvalid_0's tweedie: 158.059\n",
      "[143]\tvalid_0's tweedie: 158.058\n",
      "[144]\tvalid_0's tweedie: 158.058\n",
      "[145]\tvalid_0's tweedie: 158.058\n",
      "[146]\tvalid_0's tweedie: 158.058\n",
      "[147]\tvalid_0's tweedie: 158.058\n",
      "[148]\tvalid_0's tweedie: 158.058\n",
      "[149]\tvalid_0's tweedie: 158.058\n",
      "[150]\tvalid_0's tweedie: 158.058\n",
      "[151]\tvalid_0's tweedie: 158.058\n",
      "[152]\tvalid_0's tweedie: 158.058\n",
      "[153]\tvalid_0's tweedie: 158.058\n",
      "[154]\tvalid_0's tweedie: 158.058\n",
      "[155]\tvalid_0's tweedie: 158.057\n",
      "[156]\tvalid_0's tweedie: 158.057\n",
      "[157]\tvalid_0's tweedie: 158.057\n",
      "[158]\tvalid_0's tweedie: 158.057\n",
      "[159]\tvalid_0's tweedie: 158.057\n",
      "[160]\tvalid_0's tweedie: 158.057\n",
      "[161]\tvalid_0's tweedie: 158.057\n",
      "[162]\tvalid_0's tweedie: 158.057\n",
      "[163]\tvalid_0's tweedie: 158.057\n",
      "[164]\tvalid_0's tweedie: 158.057\n",
      "[165]\tvalid_0's tweedie: 158.057\n",
      "[166]\tvalid_0's tweedie: 158.057\n",
      "[167]\tvalid_0's tweedie: 158.057\n",
      "[168]\tvalid_0's tweedie: 158.057\n",
      "[169]\tvalid_0's tweedie: 158.057\n",
      "[170]\tvalid_0's tweedie: 158.057\n",
      "[171]\tvalid_0's tweedie: 158.057\n",
      "[172]\tvalid_0's tweedie: 158.057\n",
      "[173]\tvalid_0's tweedie: 158.057\n",
      "[174]\tvalid_0's tweedie: 158.057\n",
      "[175]\tvalid_0's tweedie: 158.057\n",
      "[176]\tvalid_0's tweedie: 158.057\n",
      "[177]\tvalid_0's tweedie: 158.056\n",
      "[178]\tvalid_0's tweedie: 158.056\n",
      "[179]\tvalid_0's tweedie: 158.056\n",
      "[180]\tvalid_0's tweedie: 158.056\n",
      "[181]\tvalid_0's tweedie: 158.056\n",
      "[182]\tvalid_0's tweedie: 158.057\n",
      "[183]\tvalid_0's tweedie: 158.057\n",
      "[184]\tvalid_0's tweedie: 158.057\n",
      "[185]\tvalid_0's tweedie: 158.057\n",
      "[186]\tvalid_0's tweedie: 158.057\n",
      "[187]\tvalid_0's tweedie: 158.057\n",
      "[188]\tvalid_0's tweedie: 158.058\n",
      "[189]\tvalid_0's tweedie: 158.057\n",
      "[190]\tvalid_0's tweedie: 158.057\n",
      "[191]\tvalid_0's tweedie: 158.057\n",
      "[192]\tvalid_0's tweedie: 158.057\n",
      "[193]\tvalid_0's tweedie: 158.057\n",
      "[194]\tvalid_0's tweedie: 158.057\n",
      "[195]\tvalid_0's tweedie: 158.057\n",
      "[196]\tvalid_0's tweedie: 158.057\n",
      "[197]\tvalid_0's tweedie: 158.057\n",
      "[198]\tvalid_0's tweedie: 158.057\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's tweedie: 158.056\n",
      "Training model for level 7 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 38829, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400794\n",
      "[1]\tvalid_0's tweedie: 176.775\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.677\n",
      "[3]\tvalid_0's tweedie: 171.049\n",
      "[4]\tvalid_0's tweedie: 168.847\n",
      "[5]\tvalid_0's tweedie: 166.994\n",
      "[6]\tvalid_0's tweedie: 165.45\n",
      "[7]\tvalid_0's tweedie: 164.159\n",
      "[8]\tvalid_0's tweedie: 163.083\n",
      "[9]\tvalid_0's tweedie: 162.179\n",
      "[10]\tvalid_0's tweedie: 161.435\n",
      "[11]\tvalid_0's tweedie: 160.828\n",
      "[12]\tvalid_0's tweedie: 160.335\n",
      "[13]\tvalid_0's tweedie: 159.909\n",
      "[14]\tvalid_0's tweedie: 159.585\n",
      "[15]\tvalid_0's tweedie: 159.311\n",
      "[16]\tvalid_0's tweedie: 159.085\n",
      "[17]\tvalid_0's tweedie: 158.899\n",
      "[18]\tvalid_0's tweedie: 158.747\n",
      "[19]\tvalid_0's tweedie: 158.623\n",
      "[20]\tvalid_0's tweedie: 158.524\n",
      "[21]\tvalid_0's tweedie: 158.443\n",
      "[22]\tvalid_0's tweedie: 158.374\n",
      "[23]\tvalid_0's tweedie: 158.322\n",
      "[24]\tvalid_0's tweedie: 158.276\n",
      "[25]\tvalid_0's tweedie: 158.24\n",
      "[26]\tvalid_0's tweedie: 158.21\n",
      "[27]\tvalid_0's tweedie: 158.183\n",
      "[28]\tvalid_0's tweedie: 158.163\n",
      "[29]\tvalid_0's tweedie: 158.148\n",
      "[30]\tvalid_0's tweedie: 158.131\n",
      "[31]\tvalid_0's tweedie: 158.121\n",
      "[32]\tvalid_0's tweedie: 158.112\n",
      "[33]\tvalid_0's tweedie: 158.105\n",
      "[34]\tvalid_0's tweedie: 158.1\n",
      "[35]\tvalid_0's tweedie: 158.095\n",
      "[36]\tvalid_0's tweedie: 158.092\n",
      "[37]\tvalid_0's tweedie: 158.088\n",
      "[38]\tvalid_0's tweedie: 158.086\n",
      "[39]\tvalid_0's tweedie: 158.084\n",
      "[40]\tvalid_0's tweedie: 158.083\n",
      "[41]\tvalid_0's tweedie: 158.083\n",
      "[42]\tvalid_0's tweedie: 158.082\n",
      "[43]\tvalid_0's tweedie: 158.08\n",
      "[44]\tvalid_0's tweedie: 158.079\n",
      "[45]\tvalid_0's tweedie: 158.079\n",
      "[46]\tvalid_0's tweedie: 158.078\n",
      "[47]\tvalid_0's tweedie: 158.078\n",
      "[48]\tvalid_0's tweedie: 158.078\n",
      "[49]\tvalid_0's tweedie: 158.077\n",
      "[50]\tvalid_0's tweedie: 158.078\n",
      "[51]\tvalid_0's tweedie: 158.079\n",
      "[52]\tvalid_0's tweedie: 158.079\n",
      "[53]\tvalid_0's tweedie: 158.08\n",
      "[54]\tvalid_0's tweedie: 158.078\n",
      "[55]\tvalid_0's tweedie: 158.078\n",
      "[56]\tvalid_0's tweedie: 158.079\n",
      "[57]\tvalid_0's tweedie: 158.078\n",
      "[58]\tvalid_0's tweedie: 158.078\n",
      "[59]\tvalid_0's tweedie: 158.078\n",
      "[60]\tvalid_0's tweedie: 158.078\n",
      "[61]\tvalid_0's tweedie: 158.077\n",
      "[62]\tvalid_0's tweedie: 158.077\n",
      "[63]\tvalid_0's tweedie: 158.076\n",
      "[64]\tvalid_0's tweedie: 158.076\n",
      "[65]\tvalid_0's tweedie: 158.076\n",
      "[66]\tvalid_0's tweedie: 158.075\n",
      "[67]\tvalid_0's tweedie: 158.075\n",
      "[68]\tvalid_0's tweedie: 158.075\n",
      "[69]\tvalid_0's tweedie: 158.075\n",
      "[70]\tvalid_0's tweedie: 158.074\n",
      "[71]\tvalid_0's tweedie: 158.074\n",
      "[72]\tvalid_0's tweedie: 158.075\n",
      "[73]\tvalid_0's tweedie: 158.075\n",
      "[74]\tvalid_0's tweedie: 158.074\n",
      "[75]\tvalid_0's tweedie: 158.075\n",
      "[76]\tvalid_0's tweedie: 158.074\n",
      "[77]\tvalid_0's tweedie: 158.074\n",
      "[78]\tvalid_0's tweedie: 158.073\n",
      "[79]\tvalid_0's tweedie: 158.073\n",
      "[80]\tvalid_0's tweedie: 158.075\n",
      "[81]\tvalid_0's tweedie: 158.075\n",
      "[82]\tvalid_0's tweedie: 158.074\n",
      "[83]\tvalid_0's tweedie: 158.074\n",
      "[84]\tvalid_0's tweedie: 158.073\n",
      "[85]\tvalid_0's tweedie: 158.073\n",
      "[86]\tvalid_0's tweedie: 158.073\n",
      "[87]\tvalid_0's tweedie: 158.073\n",
      "[88]\tvalid_0's tweedie: 158.072\n",
      "[89]\tvalid_0's tweedie: 158.073\n",
      "[90]\tvalid_0's tweedie: 158.072\n",
      "[91]\tvalid_0's tweedie: 158.072\n",
      "[92]\tvalid_0's tweedie: 158.071\n",
      "[93]\tvalid_0's tweedie: 158.072\n",
      "[94]\tvalid_0's tweedie: 158.071\n",
      "[95]\tvalid_0's tweedie: 158.071\n",
      "[96]\tvalid_0's tweedie: 158.071\n",
      "[97]\tvalid_0's tweedie: 158.07\n",
      "[98]\tvalid_0's tweedie: 158.07\n",
      "[99]\tvalid_0's tweedie: 158.07\n",
      "[100]\tvalid_0's tweedie: 158.07\n",
      "[101]\tvalid_0's tweedie: 158.07\n",
      "[102]\tvalid_0's tweedie: 158.07\n",
      "[103]\tvalid_0's tweedie: 158.07\n",
      "[104]\tvalid_0's tweedie: 158.07\n",
      "[105]\tvalid_0's tweedie: 158.069\n",
      "[106]\tvalid_0's tweedie: 158.069\n",
      "[107]\tvalid_0's tweedie: 158.069\n",
      "[108]\tvalid_0's tweedie: 158.069\n",
      "[109]\tvalid_0's tweedie: 158.069\n",
      "[110]\tvalid_0's tweedie: 158.069\n",
      "[111]\tvalid_0's tweedie: 158.069\n",
      "[112]\tvalid_0's tweedie: 158.069\n",
      "[113]\tvalid_0's tweedie: 158.068\n",
      "[114]\tvalid_0's tweedie: 158.068\n",
      "[115]\tvalid_0's tweedie: 158.068\n",
      "[116]\tvalid_0's tweedie: 158.069\n",
      "[117]\tvalid_0's tweedie: 158.069\n",
      "[118]\tvalid_0's tweedie: 158.069\n",
      "[119]\tvalid_0's tweedie: 158.069\n",
      "[120]\tvalid_0's tweedie: 158.069\n",
      "[121]\tvalid_0's tweedie: 158.068\n",
      "[122]\tvalid_0's tweedie: 158.068\n",
      "[123]\tvalid_0's tweedie: 158.068\n",
      "[124]\tvalid_0's tweedie: 158.068\n",
      "[125]\tvalid_0's tweedie: 158.068\n",
      "[126]\tvalid_0's tweedie: 158.068\n",
      "[127]\tvalid_0's tweedie: 158.068\n",
      "[128]\tvalid_0's tweedie: 158.068\n",
      "[129]\tvalid_0's tweedie: 158.068\n",
      "[130]\tvalid_0's tweedie: 158.068\n",
      "[131]\tvalid_0's tweedie: 158.068\n",
      "[132]\tvalid_0's tweedie: 158.069\n",
      "[133]\tvalid_0's tweedie: 158.07\n",
      "[134]\tvalid_0's tweedie: 158.07\n",
      "[135]\tvalid_0's tweedie: 158.07\n",
      "[136]\tvalid_0's tweedie: 158.07\n",
      "[137]\tvalid_0's tweedie: 158.07\n",
      "[138]\tvalid_0's tweedie: 158.07\n",
      "[139]\tvalid_0's tweedie: 158.07\n",
      "[140]\tvalid_0's tweedie: 158.07\n",
      "[141]\tvalid_0's tweedie: 158.07\n",
      "[142]\tvalid_0's tweedie: 158.069\n",
      "[143]\tvalid_0's tweedie: 158.069\n",
      "[144]\tvalid_0's tweedie: 158.069\n",
      "[145]\tvalid_0's tweedie: 158.069\n",
      "[146]\tvalid_0's tweedie: 158.069\n",
      "[147]\tvalid_0's tweedie: 158.069\n",
      "[148]\tvalid_0's tweedie: 158.069\n",
      "[149]\tvalid_0's tweedie: 158.069\n",
      "[150]\tvalid_0's tweedie: 158.069\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's tweedie: 158.068\n",
      "Training model for level 7 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 38808, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400786\n",
      "[1]\tvalid_0's tweedie: 176.772\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.677\n",
      "[3]\tvalid_0's tweedie: 171.055\n",
      "[4]\tvalid_0's tweedie: 168.841\n",
      "[5]\tvalid_0's tweedie: 166.987\n",
      "[6]\tvalid_0's tweedie: 165.436\n",
      "[7]\tvalid_0's tweedie: 164.148\n",
      "[8]\tvalid_0's tweedie: 163.079\n",
      "[9]\tvalid_0's tweedie: 162.172\n",
      "[10]\tvalid_0's tweedie: 161.428\n",
      "[11]\tvalid_0's tweedie: 160.824\n",
      "[12]\tvalid_0's tweedie: 160.328\n",
      "[13]\tvalid_0's tweedie: 159.92\n",
      "[14]\tvalid_0's tweedie: 159.582\n",
      "[15]\tvalid_0's tweedie: 159.309\n",
      "[16]\tvalid_0's tweedie: 159.078\n",
      "[17]\tvalid_0's tweedie: 158.893\n",
      "[18]\tvalid_0's tweedie: 158.744\n",
      "[19]\tvalid_0's tweedie: 158.623\n",
      "[20]\tvalid_0's tweedie: 158.52\n",
      "[21]\tvalid_0's tweedie: 158.432\n",
      "[22]\tvalid_0's tweedie: 158.375\n",
      "[23]\tvalid_0's tweedie: 158.323\n",
      "[24]\tvalid_0's tweedie: 158.275\n",
      "[25]\tvalid_0's tweedie: 158.239\n",
      "[26]\tvalid_0's tweedie: 158.209\n",
      "[27]\tvalid_0's tweedie: 158.185\n",
      "[28]\tvalid_0's tweedie: 158.166\n",
      "[29]\tvalid_0's tweedie: 158.149\n",
      "[30]\tvalid_0's tweedie: 158.134\n",
      "[31]\tvalid_0's tweedie: 158.123\n",
      "[32]\tvalid_0's tweedie: 158.115\n",
      "[33]\tvalid_0's tweedie: 158.108\n",
      "[34]\tvalid_0's tweedie: 158.104\n",
      "[35]\tvalid_0's tweedie: 158.096\n",
      "[36]\tvalid_0's tweedie: 158.094\n",
      "[37]\tvalid_0's tweedie: 158.091\n",
      "[38]\tvalid_0's tweedie: 158.089\n",
      "[39]\tvalid_0's tweedie: 158.085\n",
      "[40]\tvalid_0's tweedie: 158.084\n",
      "[41]\tvalid_0's tweedie: 158.083\n",
      "[42]\tvalid_0's tweedie: 158.083\n",
      "[43]\tvalid_0's tweedie: 158.082\n",
      "[44]\tvalid_0's tweedie: 158.081\n",
      "[45]\tvalid_0's tweedie: 158.082\n",
      "[46]\tvalid_0's tweedie: 158.081\n",
      "[47]\tvalid_0's tweedie: 158.081\n",
      "[48]\tvalid_0's tweedie: 158.08\n",
      "[49]\tvalid_0's tweedie: 158.08\n",
      "[50]\tvalid_0's tweedie: 158.08\n",
      "[51]\tvalid_0's tweedie: 158.08\n",
      "[52]\tvalid_0's tweedie: 158.08\n",
      "[53]\tvalid_0's tweedie: 158.081\n",
      "[54]\tvalid_0's tweedie: 158.081\n",
      "[55]\tvalid_0's tweedie: 158.081\n",
      "[56]\tvalid_0's tweedie: 158.08\n",
      "[57]\tvalid_0's tweedie: 158.08\n",
      "[58]\tvalid_0's tweedie: 158.08\n",
      "[59]\tvalid_0's tweedie: 158.081\n",
      "[60]\tvalid_0's tweedie: 158.081\n",
      "[61]\tvalid_0's tweedie: 158.079\n",
      "[62]\tvalid_0's tweedie: 158.079\n",
      "[63]\tvalid_0's tweedie: 158.079\n",
      "[64]\tvalid_0's tweedie: 158.079\n",
      "[65]\tvalid_0's tweedie: 158.078\n",
      "[66]\tvalid_0's tweedie: 158.078\n",
      "[67]\tvalid_0's tweedie: 158.078\n",
      "[68]\tvalid_0's tweedie: 158.078\n",
      "[69]\tvalid_0's tweedie: 158.078\n",
      "[70]\tvalid_0's tweedie: 158.078\n",
      "[71]\tvalid_0's tweedie: 158.078\n",
      "[72]\tvalid_0's tweedie: 158.078\n",
      "[73]\tvalid_0's tweedie: 158.078\n",
      "[74]\tvalid_0's tweedie: 158.078\n",
      "[75]\tvalid_0's tweedie: 158.078\n",
      "[76]\tvalid_0's tweedie: 158.078\n",
      "[77]\tvalid_0's tweedie: 158.077\n",
      "[78]\tvalid_0's tweedie: 158.077\n",
      "[79]\tvalid_0's tweedie: 158.077\n",
      "[80]\tvalid_0's tweedie: 158.076\n",
      "[81]\tvalid_0's tweedie: 158.076\n",
      "[82]\tvalid_0's tweedie: 158.076\n",
      "[83]\tvalid_0's tweedie: 158.076\n",
      "[84]\tvalid_0's tweedie: 158.076\n",
      "[85]\tvalid_0's tweedie: 158.076\n",
      "[86]\tvalid_0's tweedie: 158.075\n",
      "[87]\tvalid_0's tweedie: 158.074\n",
      "[88]\tvalid_0's tweedie: 158.074\n",
      "[89]\tvalid_0's tweedie: 158.074\n",
      "[90]\tvalid_0's tweedie: 158.074\n",
      "[91]\tvalid_0's tweedie: 158.074\n",
      "[92]\tvalid_0's tweedie: 158.075\n",
      "[93]\tvalid_0's tweedie: 158.074\n",
      "[94]\tvalid_0's tweedie: 158.074\n",
      "[95]\tvalid_0's tweedie: 158.073\n",
      "[96]\tvalid_0's tweedie: 158.073\n",
      "[97]\tvalid_0's tweedie: 158.073\n",
      "[98]\tvalid_0's tweedie: 158.073\n",
      "[99]\tvalid_0's tweedie: 158.073\n",
      "[100]\tvalid_0's tweedie: 158.073\n",
      "[101]\tvalid_0's tweedie: 158.073\n",
      "[102]\tvalid_0's tweedie: 158.072\n",
      "[103]\tvalid_0's tweedie: 158.072\n",
      "[104]\tvalid_0's tweedie: 158.072\n",
      "[105]\tvalid_0's tweedie: 158.072\n",
      "[106]\tvalid_0's tweedie: 158.072\n",
      "[107]\tvalid_0's tweedie: 158.071\n",
      "[108]\tvalid_0's tweedie: 158.071\n",
      "[109]\tvalid_0's tweedie: 158.071\n",
      "[110]\tvalid_0's tweedie: 158.071\n",
      "[111]\tvalid_0's tweedie: 158.071\n",
      "[112]\tvalid_0's tweedie: 158.071\n",
      "[113]\tvalid_0's tweedie: 158.071\n",
      "[114]\tvalid_0's tweedie: 158.07\n",
      "[115]\tvalid_0's tweedie: 158.07\n",
      "[116]\tvalid_0's tweedie: 158.07\n",
      "[117]\tvalid_0's tweedie: 158.07\n",
      "[118]\tvalid_0's tweedie: 158.07\n",
      "[119]\tvalid_0's tweedie: 158.07\n",
      "[120]\tvalid_0's tweedie: 158.07\n",
      "[121]\tvalid_0's tweedie: 158.07\n",
      "[122]\tvalid_0's tweedie: 158.07\n",
      "[123]\tvalid_0's tweedie: 158.07\n",
      "[124]\tvalid_0's tweedie: 158.07\n",
      "[125]\tvalid_0's tweedie: 158.07\n",
      "[126]\tvalid_0's tweedie: 158.07\n",
      "[127]\tvalid_0's tweedie: 158.069\n",
      "[128]\tvalid_0's tweedie: 158.069\n",
      "[129]\tvalid_0's tweedie: 158.069\n",
      "[130]\tvalid_0's tweedie: 158.069\n",
      "[131]\tvalid_0's tweedie: 158.069\n",
      "[132]\tvalid_0's tweedie: 158.068\n",
      "[133]\tvalid_0's tweedie: 158.068\n",
      "[134]\tvalid_0's tweedie: 158.068\n",
      "[135]\tvalid_0's tweedie: 158.068\n",
      "[136]\tvalid_0's tweedie: 158.068\n",
      "[137]\tvalid_0's tweedie: 158.068\n",
      "[138]\tvalid_0's tweedie: 158.068\n",
      "[139]\tvalid_0's tweedie: 158.068\n",
      "[140]\tvalid_0's tweedie: 158.067\n",
      "[141]\tvalid_0's tweedie: 158.067\n",
      "[142]\tvalid_0's tweedie: 158.067\n",
      "[143]\tvalid_0's tweedie: 158.067\n",
      "[144]\tvalid_0's tweedie: 158.067\n",
      "[145]\tvalid_0's tweedie: 158.066\n",
      "[146]\tvalid_0's tweedie: 158.066\n",
      "[147]\tvalid_0's tweedie: 158.066\n",
      "[148]\tvalid_0's tweedie: 158.066\n",
      "[149]\tvalid_0's tweedie: 158.066\n",
      "[150]\tvalid_0's tweedie: 158.067\n",
      "[151]\tvalid_0's tweedie: 158.066\n",
      "[152]\tvalid_0's tweedie: 158.066\n",
      "[153]\tvalid_0's tweedie: 158.066\n",
      "[154]\tvalid_0's tweedie: 158.066\n",
      "[155]\tvalid_0's tweedie: 158.066\n",
      "[156]\tvalid_0's tweedie: 158.066\n",
      "[157]\tvalid_0's tweedie: 158.066\n",
      "[158]\tvalid_0's tweedie: 158.066\n",
      "[159]\tvalid_0's tweedie: 158.066\n",
      "[160]\tvalid_0's tweedie: 158.066\n",
      "[161]\tvalid_0's tweedie: 158.066\n",
      "[162]\tvalid_0's tweedie: 158.066\n",
      "[163]\tvalid_0's tweedie: 158.066\n",
      "[164]\tvalid_0's tweedie: 158.066\n",
      "[165]\tvalid_0's tweedie: 158.066\n",
      "[166]\tvalid_0's tweedie: 158.065\n",
      "[167]\tvalid_0's tweedie: 158.065\n",
      "[168]\tvalid_0's tweedie: 158.065\n",
      "[169]\tvalid_0's tweedie: 158.065\n",
      "[170]\tvalid_0's tweedie: 158.066\n",
      "[171]\tvalid_0's tweedie: 158.066\n",
      "[172]\tvalid_0's tweedie: 158.066\n",
      "[173]\tvalid_0's tweedie: 158.066\n",
      "[174]\tvalid_0's tweedie: 158.066\n",
      "[175]\tvalid_0's tweedie: 158.066\n",
      "[176]\tvalid_0's tweedie: 158.066\n",
      "[177]\tvalid_0's tweedie: 158.066\n",
      "[178]\tvalid_0's tweedie: 158.066\n",
      "[179]\tvalid_0's tweedie: 158.066\n",
      "[180]\tvalid_0's tweedie: 158.066\n",
      "[181]\tvalid_0's tweedie: 158.066\n",
      "[182]\tvalid_0's tweedie: 158.066\n",
      "[183]\tvalid_0's tweedie: 158.066\n",
      "[184]\tvalid_0's tweedie: 158.066\n",
      "[185]\tvalid_0's tweedie: 158.066\n",
      "[186]\tvalid_0's tweedie: 158.066\n",
      "[187]\tvalid_0's tweedie: 158.066\n",
      "[188]\tvalid_0's tweedie: 158.066\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's tweedie: 158.065\n",
      "Training model for level 7 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 38787, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.400941\n",
      "[1]\tvalid_0's tweedie: 176.765\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.673\n",
      "[3]\tvalid_0's tweedie: 171.06\n",
      "[4]\tvalid_0's tweedie: 168.845\n",
      "[5]\tvalid_0's tweedie: 166.993\n",
      "[6]\tvalid_0's tweedie: 165.445\n",
      "[7]\tvalid_0's tweedie: 164.155\n",
      "[8]\tvalid_0's tweedie: 163.087\n",
      "[9]\tvalid_0's tweedie: 162.184\n",
      "[10]\tvalid_0's tweedie: 161.446\n",
      "[11]\tvalid_0's tweedie: 160.831\n",
      "[12]\tvalid_0's tweedie: 160.323\n",
      "[13]\tvalid_0's tweedie: 159.914\n",
      "[14]\tvalid_0's tweedie: 159.575\n",
      "[15]\tvalid_0's tweedie: 159.304\n",
      "[16]\tvalid_0's tweedie: 159.083\n",
      "[17]\tvalid_0's tweedie: 158.89\n",
      "[18]\tvalid_0's tweedie: 158.744\n",
      "[19]\tvalid_0's tweedie: 158.629\n",
      "[20]\tvalid_0's tweedie: 158.519\n",
      "[21]\tvalid_0's tweedie: 158.441\n",
      "[22]\tvalid_0's tweedie: 158.372\n",
      "[23]\tvalid_0's tweedie: 158.32\n",
      "[24]\tvalid_0's tweedie: 158.276\n",
      "[25]\tvalid_0's tweedie: 158.238\n",
      "[26]\tvalid_0's tweedie: 158.21\n",
      "[27]\tvalid_0's tweedie: 158.183\n",
      "[28]\tvalid_0's tweedie: 158.163\n",
      "[29]\tvalid_0's tweedie: 158.15\n",
      "[30]\tvalid_0's tweedie: 158.135\n",
      "[31]\tvalid_0's tweedie: 158.122\n",
      "[32]\tvalid_0's tweedie: 158.114\n",
      "[33]\tvalid_0's tweedie: 158.107\n",
      "[34]\tvalid_0's tweedie: 158.102\n",
      "[35]\tvalid_0's tweedie: 158.099\n",
      "[36]\tvalid_0's tweedie: 158.097\n",
      "[37]\tvalid_0's tweedie: 158.094\n",
      "[38]\tvalid_0's tweedie: 158.092\n",
      "[39]\tvalid_0's tweedie: 158.091\n",
      "[40]\tvalid_0's tweedie: 158.09\n",
      "[41]\tvalid_0's tweedie: 158.088\n",
      "[42]\tvalid_0's tweedie: 158.089\n",
      "[43]\tvalid_0's tweedie: 158.089\n",
      "[44]\tvalid_0's tweedie: 158.089\n",
      "[45]\tvalid_0's tweedie: 158.089\n",
      "[46]\tvalid_0's tweedie: 158.089\n",
      "[47]\tvalid_0's tweedie: 158.091\n",
      "[48]\tvalid_0's tweedie: 158.09\n",
      "[49]\tvalid_0's tweedie: 158.089\n",
      "[50]\tvalid_0's tweedie: 158.088\n",
      "[51]\tvalid_0's tweedie: 158.088\n",
      "[52]\tvalid_0's tweedie: 158.086\n",
      "[53]\tvalid_0's tweedie: 158.086\n",
      "[54]\tvalid_0's tweedie: 158.086\n",
      "[55]\tvalid_0's tweedie: 158.087\n",
      "[56]\tvalid_0's tweedie: 158.087\n",
      "[57]\tvalid_0's tweedie: 158.086\n",
      "[58]\tvalid_0's tweedie: 158.085\n",
      "[59]\tvalid_0's tweedie: 158.084\n",
      "[60]\tvalid_0's tweedie: 158.084\n",
      "[61]\tvalid_0's tweedie: 158.085\n",
      "[62]\tvalid_0's tweedie: 158.084\n",
      "[63]\tvalid_0's tweedie: 158.083\n",
      "[64]\tvalid_0's tweedie: 158.083\n",
      "[65]\tvalid_0's tweedie: 158.083\n",
      "[66]\tvalid_0's tweedie: 158.083\n",
      "[67]\tvalid_0's tweedie: 158.082\n",
      "[68]\tvalid_0's tweedie: 158.083\n",
      "[69]\tvalid_0's tweedie: 158.082\n",
      "[70]\tvalid_0's tweedie: 158.081\n",
      "[71]\tvalid_0's tweedie: 158.08\n",
      "[72]\tvalid_0's tweedie: 158.079\n",
      "[73]\tvalid_0's tweedie: 158.079\n",
      "[74]\tvalid_0's tweedie: 158.079\n",
      "[75]\tvalid_0's tweedie: 158.079\n",
      "[76]\tvalid_0's tweedie: 158.078\n",
      "[77]\tvalid_0's tweedie: 158.078\n",
      "[78]\tvalid_0's tweedie: 158.078\n",
      "[79]\tvalid_0's tweedie: 158.078\n",
      "[80]\tvalid_0's tweedie: 158.078\n",
      "[81]\tvalid_0's tweedie: 158.078\n",
      "[82]\tvalid_0's tweedie: 158.078\n",
      "[83]\tvalid_0's tweedie: 158.077\n",
      "[84]\tvalid_0's tweedie: 158.077\n",
      "[85]\tvalid_0's tweedie: 158.077\n",
      "[86]\tvalid_0's tweedie: 158.078\n",
      "[87]\tvalid_0's tweedie: 158.077\n",
      "[88]\tvalid_0's tweedie: 158.077\n",
      "[89]\tvalid_0's tweedie: 158.077\n",
      "[90]\tvalid_0's tweedie: 158.077\n",
      "[91]\tvalid_0's tweedie: 158.077\n",
      "[92]\tvalid_0's tweedie: 158.076\n",
      "[93]\tvalid_0's tweedie: 158.076\n",
      "[94]\tvalid_0's tweedie: 158.076\n",
      "[95]\tvalid_0's tweedie: 158.076\n",
      "[96]\tvalid_0's tweedie: 158.076\n",
      "[97]\tvalid_0's tweedie: 158.076\n",
      "[98]\tvalid_0's tweedie: 158.076\n",
      "[99]\tvalid_0's tweedie: 158.076\n",
      "[100]\tvalid_0's tweedie: 158.075\n",
      "[101]\tvalid_0's tweedie: 158.074\n",
      "[102]\tvalid_0's tweedie: 158.074\n",
      "[103]\tvalid_0's tweedie: 158.074\n",
      "[104]\tvalid_0's tweedie: 158.074\n",
      "[105]\tvalid_0's tweedie: 158.074\n",
      "[106]\tvalid_0's tweedie: 158.073\n",
      "[107]\tvalid_0's tweedie: 158.073\n",
      "[108]\tvalid_0's tweedie: 158.073\n",
      "[109]\tvalid_0's tweedie: 158.073\n",
      "[110]\tvalid_0's tweedie: 158.073\n",
      "[111]\tvalid_0's tweedie: 158.073\n",
      "[112]\tvalid_0's tweedie: 158.073\n",
      "[113]\tvalid_0's tweedie: 158.073\n",
      "[114]\tvalid_0's tweedie: 158.072\n",
      "[115]\tvalid_0's tweedie: 158.072\n",
      "[116]\tvalid_0's tweedie: 158.073\n",
      "[117]\tvalid_0's tweedie: 158.072\n",
      "[118]\tvalid_0's tweedie: 158.072\n",
      "[119]\tvalid_0's tweedie: 158.072\n",
      "[120]\tvalid_0's tweedie: 158.072\n",
      "[121]\tvalid_0's tweedie: 158.072\n",
      "[122]\tvalid_0's tweedie: 158.072\n",
      "[123]\tvalid_0's tweedie: 158.072\n",
      "[124]\tvalid_0's tweedie: 158.071\n",
      "[125]\tvalid_0's tweedie: 158.071\n",
      "[126]\tvalid_0's tweedie: 158.071\n",
      "[127]\tvalid_0's tweedie: 158.071\n",
      "[128]\tvalid_0's tweedie: 158.071\n",
      "[129]\tvalid_0's tweedie: 158.072\n",
      "[130]\tvalid_0's tweedie: 158.072\n",
      "[131]\tvalid_0's tweedie: 158.072\n",
      "[132]\tvalid_0's tweedie: 158.071\n",
      "[133]\tvalid_0's tweedie: 158.071\n",
      "[134]\tvalid_0's tweedie: 158.071\n",
      "[135]\tvalid_0's tweedie: 158.071\n",
      "[136]\tvalid_0's tweedie: 158.071\n",
      "[137]\tvalid_0's tweedie: 158.071\n",
      "[138]\tvalid_0's tweedie: 158.071\n",
      "[139]\tvalid_0's tweedie: 158.071\n",
      "[140]\tvalid_0's tweedie: 158.071\n",
      "[141]\tvalid_0's tweedie: 158.071\n",
      "[142]\tvalid_0's tweedie: 158.071\n",
      "[143]\tvalid_0's tweedie: 158.07\n",
      "[144]\tvalid_0's tweedie: 158.07\n",
      "[145]\tvalid_0's tweedie: 158.07\n",
      "[146]\tvalid_0's tweedie: 158.07\n",
      "[147]\tvalid_0's tweedie: 158.072\n",
      "[148]\tvalid_0's tweedie: 158.072\n",
      "[149]\tvalid_0's tweedie: 158.072\n",
      "[150]\tvalid_0's tweedie: 158.071\n",
      "[151]\tvalid_0's tweedie: 158.071\n",
      "[152]\tvalid_0's tweedie: 158.072\n",
      "[153]\tvalid_0's tweedie: 158.072\n",
      "[154]\tvalid_0's tweedie: 158.072\n",
      "[155]\tvalid_0's tweedie: 158.071\n",
      "[156]\tvalid_0's tweedie: 158.071\n",
      "[157]\tvalid_0's tweedie: 158.071\n",
      "[158]\tvalid_0's tweedie: 158.071\n",
      "[159]\tvalid_0's tweedie: 158.072\n",
      "[160]\tvalid_0's tweedie: 158.072\n",
      "[161]\tvalid_0's tweedie: 158.071\n",
      "[162]\tvalid_0's tweedie: 158.071\n",
      "[163]\tvalid_0's tweedie: 158.071\n",
      "[164]\tvalid_0's tweedie: 158.071\n",
      "[165]\tvalid_0's tweedie: 158.071\n",
      "[166]\tvalid_0's tweedie: 158.071\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's tweedie: 158.07\n",
      "Training model for level 7 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5492\n",
      "[LightGBM] [Info] Number of data points in the train set: 38766, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.401124\n",
      "[1]\tvalid_0's tweedie: 176.763\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.674\n",
      "[3]\tvalid_0's tweedie: 171.054\n",
      "[4]\tvalid_0's tweedie: 168.844\n",
      "[5]\tvalid_0's tweedie: 167.01\n",
      "[6]\tvalid_0's tweedie: 165.456\n",
      "[7]\tvalid_0's tweedie: 164.171\n",
      "[8]\tvalid_0's tweedie: 163.095\n",
      "[9]\tvalid_0's tweedie: 162.19\n",
      "[10]\tvalid_0's tweedie: 161.454\n",
      "[11]\tvalid_0's tweedie: 160.833\n",
      "[12]\tvalid_0's tweedie: 160.335\n",
      "[13]\tvalid_0's tweedie: 159.922\n",
      "[14]\tvalid_0's tweedie: 159.579\n",
      "[15]\tvalid_0's tweedie: 159.309\n",
      "[16]\tvalid_0's tweedie: 159.075\n",
      "[17]\tvalid_0's tweedie: 158.889\n",
      "[18]\tvalid_0's tweedie: 158.74\n",
      "[19]\tvalid_0's tweedie: 158.617\n",
      "[20]\tvalid_0's tweedie: 158.521\n",
      "[21]\tvalid_0's tweedie: 158.443\n",
      "[22]\tvalid_0's tweedie: 158.381\n",
      "[23]\tvalid_0's tweedie: 158.326\n",
      "[24]\tvalid_0's tweedie: 158.282\n",
      "[25]\tvalid_0's tweedie: 158.243\n",
      "[26]\tvalid_0's tweedie: 158.216\n",
      "[27]\tvalid_0's tweedie: 158.189\n",
      "[28]\tvalid_0's tweedie: 158.17\n",
      "[29]\tvalid_0's tweedie: 158.155\n",
      "[30]\tvalid_0's tweedie: 158.138\n",
      "[31]\tvalid_0's tweedie: 158.127\n",
      "[32]\tvalid_0's tweedie: 158.118\n",
      "[33]\tvalid_0's tweedie: 158.11\n",
      "[34]\tvalid_0's tweedie: 158.104\n",
      "[35]\tvalid_0's tweedie: 158.098\n",
      "[36]\tvalid_0's tweedie: 158.095\n",
      "[37]\tvalid_0's tweedie: 158.091\n",
      "[38]\tvalid_0's tweedie: 158.088\n",
      "[39]\tvalid_0's tweedie: 158.086\n",
      "[40]\tvalid_0's tweedie: 158.085\n",
      "[41]\tvalid_0's tweedie: 158.084\n",
      "[42]\tvalid_0's tweedie: 158.084\n",
      "[43]\tvalid_0's tweedie: 158.084\n",
      "[44]\tvalid_0's tweedie: 158.083\n",
      "[45]\tvalid_0's tweedie: 158.082\n",
      "[46]\tvalid_0's tweedie: 158.082\n",
      "[47]\tvalid_0's tweedie: 158.081\n",
      "[48]\tvalid_0's tweedie: 158.08\n",
      "[49]\tvalid_0's tweedie: 158.08\n",
      "[50]\tvalid_0's tweedie: 158.079\n",
      "[51]\tvalid_0's tweedie: 158.078\n",
      "[52]\tvalid_0's tweedie: 158.078\n",
      "[53]\tvalid_0's tweedie: 158.079\n",
      "[54]\tvalid_0's tweedie: 158.079\n",
      "[55]\tvalid_0's tweedie: 158.078\n",
      "[56]\tvalid_0's tweedie: 158.08\n",
      "[57]\tvalid_0's tweedie: 158.08\n",
      "[58]\tvalid_0's tweedie: 158.081\n",
      "[59]\tvalid_0's tweedie: 158.079\n",
      "[60]\tvalid_0's tweedie: 158.08\n",
      "[61]\tvalid_0's tweedie: 158.08\n",
      "[62]\tvalid_0's tweedie: 158.08\n",
      "[63]\tvalid_0's tweedie: 158.079\n",
      "[64]\tvalid_0's tweedie: 158.079\n",
      "[65]\tvalid_0's tweedie: 158.079\n",
      "[66]\tvalid_0's tweedie: 158.079\n",
      "[67]\tvalid_0's tweedie: 158.079\n",
      "[68]\tvalid_0's tweedie: 158.078\n",
      "[69]\tvalid_0's tweedie: 158.078\n",
      "[70]\tvalid_0's tweedie: 158.078\n",
      "[71]\tvalid_0's tweedie: 158.077\n",
      "[72]\tvalid_0's tweedie: 158.077\n",
      "[73]\tvalid_0's tweedie: 158.078\n",
      "[74]\tvalid_0's tweedie: 158.077\n",
      "[75]\tvalid_0's tweedie: 158.077\n",
      "[76]\tvalid_0's tweedie: 158.076\n",
      "[77]\tvalid_0's tweedie: 158.076\n",
      "[78]\tvalid_0's tweedie: 158.075\n",
      "[79]\tvalid_0's tweedie: 158.075\n",
      "[80]\tvalid_0's tweedie: 158.075\n",
      "[81]\tvalid_0's tweedie: 158.075\n",
      "[82]\tvalid_0's tweedie: 158.075\n",
      "[83]\tvalid_0's tweedie: 158.074\n",
      "[84]\tvalid_0's tweedie: 158.074\n",
      "[85]\tvalid_0's tweedie: 158.074\n",
      "[86]\tvalid_0's tweedie: 158.073\n",
      "[87]\tvalid_0's tweedie: 158.073\n",
      "[88]\tvalid_0's tweedie: 158.072\n",
      "[89]\tvalid_0's tweedie: 158.072\n",
      "[90]\tvalid_0's tweedie: 158.072\n",
      "[91]\tvalid_0's tweedie: 158.072\n",
      "[92]\tvalid_0's tweedie: 158.072\n",
      "[93]\tvalid_0's tweedie: 158.071\n",
      "[94]\tvalid_0's tweedie: 158.071\n",
      "[95]\tvalid_0's tweedie: 158.071\n",
      "[96]\tvalid_0's tweedie: 158.071\n",
      "[97]\tvalid_0's tweedie: 158.071\n",
      "[98]\tvalid_0's tweedie: 158.071\n",
      "[99]\tvalid_0's tweedie: 158.071\n",
      "[100]\tvalid_0's tweedie: 158.071\n",
      "[101]\tvalid_0's tweedie: 158.07\n",
      "[102]\tvalid_0's tweedie: 158.07\n",
      "[103]\tvalid_0's tweedie: 158.07\n",
      "[104]\tvalid_0's tweedie: 158.07\n",
      "[105]\tvalid_0's tweedie: 158.07\n",
      "[106]\tvalid_0's tweedie: 158.069\n",
      "[107]\tvalid_0's tweedie: 158.069\n",
      "[108]\tvalid_0's tweedie: 158.069\n",
      "[109]\tvalid_0's tweedie: 158.07\n",
      "[110]\tvalid_0's tweedie: 158.07\n",
      "[111]\tvalid_0's tweedie: 158.071\n",
      "[112]\tvalid_0's tweedie: 158.071\n",
      "[113]\tvalid_0's tweedie: 158.072\n",
      "[114]\tvalid_0's tweedie: 158.071\n",
      "[115]\tvalid_0's tweedie: 158.071\n",
      "[116]\tvalid_0's tweedie: 158.071\n",
      "[117]\tvalid_0's tweedie: 158.071\n",
      "[118]\tvalid_0's tweedie: 158.071\n",
      "[119]\tvalid_0's tweedie: 158.071\n",
      "[120]\tvalid_0's tweedie: 158.071\n",
      "[121]\tvalid_0's tweedie: 158.07\n",
      "[122]\tvalid_0's tweedie: 158.071\n",
      "[123]\tvalid_0's tweedie: 158.07\n",
      "[124]\tvalid_0's tweedie: 158.07\n",
      "[125]\tvalid_0's tweedie: 158.07\n",
      "[126]\tvalid_0's tweedie: 158.07\n",
      "[127]\tvalid_0's tweedie: 158.07\n",
      "[128]\tvalid_0's tweedie: 158.07\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's tweedie: 158.069\n",
      "Training model for level 7 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5491\n",
      "[LightGBM] [Info] Number of data points in the train set: 38745, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.401310\n",
      "[1]\tvalid_0's tweedie: 176.76\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.669\n",
      "[3]\tvalid_0's tweedie: 171.049\n",
      "[4]\tvalid_0's tweedie: 168.85\n",
      "[5]\tvalid_0's tweedie: 166.999\n",
      "[6]\tvalid_0's tweedie: 165.449\n",
      "[7]\tvalid_0's tweedie: 164.154\n",
      "[8]\tvalid_0's tweedie: 163.077\n",
      "[9]\tvalid_0's tweedie: 162.181\n",
      "[10]\tvalid_0's tweedie: 161.438\n",
      "[11]\tvalid_0's tweedie: 160.837\n",
      "[12]\tvalid_0's tweedie: 160.329\n",
      "[13]\tvalid_0's tweedie: 159.906\n",
      "[14]\tvalid_0's tweedie: 159.575\n",
      "[15]\tvalid_0's tweedie: 159.31\n",
      "[16]\tvalid_0's tweedie: 159.081\n",
      "[17]\tvalid_0's tweedie: 158.894\n",
      "[18]\tvalid_0's tweedie: 158.745\n",
      "[19]\tvalid_0's tweedie: 158.622\n",
      "[20]\tvalid_0's tweedie: 158.518\n",
      "[21]\tvalid_0's tweedie: 158.441\n",
      "[22]\tvalid_0's tweedie: 158.375\n",
      "[23]\tvalid_0's tweedie: 158.322\n",
      "[24]\tvalid_0's tweedie: 158.276\n",
      "[25]\tvalid_0's tweedie: 158.238\n",
      "[26]\tvalid_0's tweedie: 158.207\n",
      "[27]\tvalid_0's tweedie: 158.182\n",
      "[28]\tvalid_0's tweedie: 158.16\n",
      "[29]\tvalid_0's tweedie: 158.145\n",
      "[30]\tvalid_0's tweedie: 158.132\n",
      "[31]\tvalid_0's tweedie: 158.122\n",
      "[32]\tvalid_0's tweedie: 158.113\n",
      "[33]\tvalid_0's tweedie: 158.107\n",
      "[34]\tvalid_0's tweedie: 158.099\n",
      "[35]\tvalid_0's tweedie: 158.092\n",
      "[36]\tvalid_0's tweedie: 158.087\n",
      "[37]\tvalid_0's tweedie: 158.085\n",
      "[38]\tvalid_0's tweedie: 158.083\n",
      "[39]\tvalid_0's tweedie: 158.082\n",
      "[40]\tvalid_0's tweedie: 158.081\n",
      "[41]\tvalid_0's tweedie: 158.081\n",
      "[42]\tvalid_0's tweedie: 158.081\n",
      "[43]\tvalid_0's tweedie: 158.08\n",
      "[44]\tvalid_0's tweedie: 158.079\n",
      "[45]\tvalid_0's tweedie: 158.079\n",
      "[46]\tvalid_0's tweedie: 158.079\n",
      "[47]\tvalid_0's tweedie: 158.079\n",
      "[48]\tvalid_0's tweedie: 158.079\n",
      "[49]\tvalid_0's tweedie: 158.079\n",
      "[50]\tvalid_0's tweedie: 158.078\n",
      "[51]\tvalid_0's tweedie: 158.078\n",
      "[52]\tvalid_0's tweedie: 158.078\n",
      "[53]\tvalid_0's tweedie: 158.078\n",
      "[54]\tvalid_0's tweedie: 158.078\n",
      "[55]\tvalid_0's tweedie: 158.079\n",
      "[56]\tvalid_0's tweedie: 158.079\n",
      "[57]\tvalid_0's tweedie: 158.079\n",
      "[58]\tvalid_0's tweedie: 158.079\n",
      "[59]\tvalid_0's tweedie: 158.079\n",
      "[60]\tvalid_0's tweedie: 158.079\n",
      "[61]\tvalid_0's tweedie: 158.078\n",
      "[62]\tvalid_0's tweedie: 158.077\n",
      "[63]\tvalid_0's tweedie: 158.079\n",
      "[64]\tvalid_0's tweedie: 158.08\n",
      "[65]\tvalid_0's tweedie: 158.079\n",
      "[66]\tvalid_0's tweedie: 158.079\n",
      "[67]\tvalid_0's tweedie: 158.08\n",
      "[68]\tvalid_0's tweedie: 158.079\n",
      "[69]\tvalid_0's tweedie: 158.078\n",
      "[70]\tvalid_0's tweedie: 158.078\n",
      "[71]\tvalid_0's tweedie: 158.077\n",
      "[72]\tvalid_0's tweedie: 158.077\n",
      "[73]\tvalid_0's tweedie: 158.077\n",
      "[74]\tvalid_0's tweedie: 158.075\n",
      "[75]\tvalid_0's tweedie: 158.075\n",
      "[76]\tvalid_0's tweedie: 158.075\n",
      "[77]\tvalid_0's tweedie: 158.075\n",
      "[78]\tvalid_0's tweedie: 158.075\n",
      "[79]\tvalid_0's tweedie: 158.075\n",
      "[80]\tvalid_0's tweedie: 158.075\n",
      "[81]\tvalid_0's tweedie: 158.074\n",
      "[82]\tvalid_0's tweedie: 158.075\n",
      "[83]\tvalid_0's tweedie: 158.075\n",
      "[84]\tvalid_0's tweedie: 158.075\n",
      "[85]\tvalid_0's tweedie: 158.075\n",
      "[86]\tvalid_0's tweedie: 158.075\n",
      "[87]\tvalid_0's tweedie: 158.074\n",
      "[88]\tvalid_0's tweedie: 158.073\n",
      "[89]\tvalid_0's tweedie: 158.073\n",
      "[90]\tvalid_0's tweedie: 158.073\n",
      "[91]\tvalid_0's tweedie: 158.072\n",
      "[92]\tvalid_0's tweedie: 158.072\n",
      "[93]\tvalid_0's tweedie: 158.071\n",
      "[94]\tvalid_0's tweedie: 158.071\n",
      "[95]\tvalid_0's tweedie: 158.071\n",
      "[96]\tvalid_0's tweedie: 158.071\n",
      "[97]\tvalid_0's tweedie: 158.071\n",
      "[98]\tvalid_0's tweedie: 158.071\n",
      "[99]\tvalid_0's tweedie: 158.071\n",
      "[100]\tvalid_0's tweedie: 158.071\n",
      "[101]\tvalid_0's tweedie: 158.071\n",
      "[102]\tvalid_0's tweedie: 158.07\n",
      "[103]\tvalid_0's tweedie: 158.07\n",
      "[104]\tvalid_0's tweedie: 158.07\n",
      "[105]\tvalid_0's tweedie: 158.07\n",
      "[106]\tvalid_0's tweedie: 158.07\n",
      "[107]\tvalid_0's tweedie: 158.07\n",
      "[108]\tvalid_0's tweedie: 158.07\n",
      "[109]\tvalid_0's tweedie: 158.07\n",
      "[110]\tvalid_0's tweedie: 158.07\n",
      "[111]\tvalid_0's tweedie: 158.07\n",
      "[112]\tvalid_0's tweedie: 158.07\n",
      "[113]\tvalid_0's tweedie: 158.07\n",
      "[114]\tvalid_0's tweedie: 158.07\n",
      "[115]\tvalid_0's tweedie: 158.07\n",
      "[116]\tvalid_0's tweedie: 158.071\n",
      "[117]\tvalid_0's tweedie: 158.07\n",
      "[118]\tvalid_0's tweedie: 158.07\n",
      "[119]\tvalid_0's tweedie: 158.07\n",
      "[120]\tvalid_0's tweedie: 158.07\n",
      "[121]\tvalid_0's tweedie: 158.07\n",
      "[122]\tvalid_0's tweedie: 158.07\n",
      "[123]\tvalid_0's tweedie: 158.07\n",
      "[124]\tvalid_0's tweedie: 158.07\n",
      "[125]\tvalid_0's tweedie: 158.07\n",
      "[126]\tvalid_0's tweedie: 158.07\n",
      "[127]\tvalid_0's tweedie: 158.07\n",
      "[128]\tvalid_0's tweedie: 158.07\n",
      "[129]\tvalid_0's tweedie: 158.07\n",
      "[130]\tvalid_0's tweedie: 158.07\n",
      "[131]\tvalid_0's tweedie: 158.07\n",
      "[132]\tvalid_0's tweedie: 158.07\n",
      "[133]\tvalid_0's tweedie: 158.071\n",
      "[134]\tvalid_0's tweedie: 158.071\n",
      "[135]\tvalid_0's tweedie: 158.071\n",
      "[136]\tvalid_0's tweedie: 158.071\n",
      "[137]\tvalid_0's tweedie: 158.07\n",
      "[138]\tvalid_0's tweedie: 158.07\n",
      "[139]\tvalid_0's tweedie: 158.07\n",
      "[140]\tvalid_0's tweedie: 158.07\n",
      "[141]\tvalid_0's tweedie: 158.07\n",
      "[142]\tvalid_0's tweedie: 158.07\n",
      "[143]\tvalid_0's tweedie: 158.07\n",
      "[144]\tvalid_0's tweedie: 158.07\n",
      "[145]\tvalid_0's tweedie: 158.07\n",
      "[146]\tvalid_0's tweedie: 158.07\n",
      "[147]\tvalid_0's tweedie: 158.069\n",
      "[148]\tvalid_0's tweedie: 158.07\n",
      "[149]\tvalid_0's tweedie: 158.069\n",
      "[150]\tvalid_0's tweedie: 158.069\n",
      "[151]\tvalid_0's tweedie: 158.07\n",
      "[152]\tvalid_0's tweedie: 158.07\n",
      "[153]\tvalid_0's tweedie: 158.07\n",
      "[154]\tvalid_0's tweedie: 158.07\n",
      "[155]\tvalid_0's tweedie: 158.07\n",
      "[156]\tvalid_0's tweedie: 158.07\n",
      "[157]\tvalid_0's tweedie: 158.069\n",
      "[158]\tvalid_0's tweedie: 158.069\n",
      "[159]\tvalid_0's tweedie: 158.069\n",
      "[160]\tvalid_0's tweedie: 158.069\n",
      "[161]\tvalid_0's tweedie: 158.069\n",
      "[162]\tvalid_0's tweedie: 158.069\n",
      "[163]\tvalid_0's tweedie: 158.069\n",
      "[164]\tvalid_0's tweedie: 158.069\n",
      "[165]\tvalid_0's tweedie: 158.069\n",
      "[166]\tvalid_0's tweedie: 158.069\n",
      "[167]\tvalid_0's tweedie: 158.069\n",
      "[168]\tvalid_0's tweedie: 158.069\n",
      "[169]\tvalid_0's tweedie: 158.069\n",
      "[170]\tvalid_0's tweedie: 158.069\n",
      "[171]\tvalid_0's tweedie: 158.07\n",
      "[172]\tvalid_0's tweedie: 158.07\n",
      "[173]\tvalid_0's tweedie: 158.07\n",
      "[174]\tvalid_0's tweedie: 158.07\n",
      "[175]\tvalid_0's tweedie: 158.07\n",
      "[176]\tvalid_0's tweedie: 158.07\n",
      "[177]\tvalid_0's tweedie: 158.07\n",
      "[178]\tvalid_0's tweedie: 158.07\n",
      "[179]\tvalid_0's tweedie: 158.07\n",
      "[180]\tvalid_0's tweedie: 158.07\n",
      "[181]\tvalid_0's tweedie: 158.07\n",
      "[182]\tvalid_0's tweedie: 158.07\n",
      "[183]\tvalid_0's tweedie: 158.07\n",
      "[184]\tvalid_0's tweedie: 158.07\n",
      "[185]\tvalid_0's tweedie: 158.07\n",
      "[186]\tvalid_0's tweedie: 158.069\n",
      "[187]\tvalid_0's tweedie: 158.07\n",
      "[188]\tvalid_0's tweedie: 158.07\n",
      "[189]\tvalid_0's tweedie: 158.07\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's tweedie: 158.069\n",
      "Training model for level 7 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/7/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5490\n",
      "[LightGBM] [Info] Number of data points in the train set: 38724, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.401496\n",
      "[1]\tvalid_0's tweedie: 176.763\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 173.676\n",
      "[3]\tvalid_0's tweedie: 171.055\n",
      "[4]\tvalid_0's tweedie: 168.852\n",
      "[5]\tvalid_0's tweedie: 166.994\n",
      "[6]\tvalid_0's tweedie: 165.457\n",
      "[7]\tvalid_0's tweedie: 164.164\n",
      "[8]\tvalid_0's tweedie: 163.088\n",
      "[9]\tvalid_0's tweedie: 162.195\n",
      "[10]\tvalid_0's tweedie: 161.446\n",
      "[11]\tvalid_0's tweedie: 160.83\n",
      "[12]\tvalid_0's tweedie: 160.321\n",
      "[13]\tvalid_0's tweedie: 159.918\n",
      "[14]\tvalid_0's tweedie: 159.571\n",
      "[15]\tvalid_0's tweedie: 159.295\n",
      "[16]\tvalid_0's tweedie: 159.065\n",
      "[17]\tvalid_0's tweedie: 158.88\n",
      "[18]\tvalid_0's tweedie: 158.731\n",
      "[19]\tvalid_0's tweedie: 158.61\n",
      "[20]\tvalid_0's tweedie: 158.506\n",
      "[21]\tvalid_0's tweedie: 158.429\n",
      "[22]\tvalid_0's tweedie: 158.363\n",
      "[23]\tvalid_0's tweedie: 158.306\n",
      "[24]\tvalid_0's tweedie: 158.263\n",
      "[25]\tvalid_0's tweedie: 158.227\n",
      "[26]\tvalid_0's tweedie: 158.197\n",
      "[27]\tvalid_0's tweedie: 158.174\n",
      "[28]\tvalid_0's tweedie: 158.156\n",
      "[29]\tvalid_0's tweedie: 158.14\n",
      "[30]\tvalid_0's tweedie: 158.126\n",
      "[31]\tvalid_0's tweedie: 158.114\n",
      "[32]\tvalid_0's tweedie: 158.105\n",
      "[33]\tvalid_0's tweedie: 158.1\n",
      "[34]\tvalid_0's tweedie: 158.094\n",
      "[35]\tvalid_0's tweedie: 158.089\n",
      "[36]\tvalid_0's tweedie: 158.087\n",
      "[37]\tvalid_0's tweedie: 158.085\n",
      "[38]\tvalid_0's tweedie: 158.083\n",
      "[39]\tvalid_0's tweedie: 158.082\n",
      "[40]\tvalid_0's tweedie: 158.081\n",
      "[41]\tvalid_0's tweedie: 158.079\n",
      "[42]\tvalid_0's tweedie: 158.078\n",
      "[43]\tvalid_0's tweedie: 158.078\n",
      "[44]\tvalid_0's tweedie: 158.076\n",
      "[45]\tvalid_0's tweedie: 158.074\n",
      "[46]\tvalid_0's tweedie: 158.074\n",
      "[47]\tvalid_0's tweedie: 158.075\n",
      "[48]\tvalid_0's tweedie: 158.074\n",
      "[49]\tvalid_0's tweedie: 158.073\n",
      "[50]\tvalid_0's tweedie: 158.073\n",
      "[51]\tvalid_0's tweedie: 158.073\n",
      "[52]\tvalid_0's tweedie: 158.073\n",
      "[53]\tvalid_0's tweedie: 158.073\n",
      "[54]\tvalid_0's tweedie: 158.074\n",
      "[55]\tvalid_0's tweedie: 158.072\n",
      "[56]\tvalid_0's tweedie: 158.073\n",
      "[57]\tvalid_0's tweedie: 158.073\n",
      "[58]\tvalid_0's tweedie: 158.073\n",
      "[59]\tvalid_0's tweedie: 158.072\n",
      "[60]\tvalid_0's tweedie: 158.071\n",
      "[61]\tvalid_0's tweedie: 158.071\n",
      "[62]\tvalid_0's tweedie: 158.071\n",
      "[63]\tvalid_0's tweedie: 158.071\n",
      "[64]\tvalid_0's tweedie: 158.07\n",
      "[65]\tvalid_0's tweedie: 158.07\n",
      "[66]\tvalid_0's tweedie: 158.07\n",
      "[67]\tvalid_0's tweedie: 158.068\n",
      "[68]\tvalid_0's tweedie: 158.068\n",
      "[69]\tvalid_0's tweedie: 158.068\n",
      "[70]\tvalid_0's tweedie: 158.068\n",
      "[71]\tvalid_0's tweedie: 158.07\n",
      "[72]\tvalid_0's tweedie: 158.07\n",
      "[73]\tvalid_0's tweedie: 158.07\n",
      "[74]\tvalid_0's tweedie: 158.07\n",
      "[75]\tvalid_0's tweedie: 158.07\n",
      "[76]\tvalid_0's tweedie: 158.07\n",
      "[77]\tvalid_0's tweedie: 158.07\n",
      "[78]\tvalid_0's tweedie: 158.07\n",
      "[79]\tvalid_0's tweedie: 158.07\n",
      "[80]\tvalid_0's tweedie: 158.069\n",
      "[81]\tvalid_0's tweedie: 158.069\n",
      "[82]\tvalid_0's tweedie: 158.069\n",
      "[83]\tvalid_0's tweedie: 158.069\n",
      "[84]\tvalid_0's tweedie: 158.068\n",
      "[85]\tvalid_0's tweedie: 158.068\n",
      "[86]\tvalid_0's tweedie: 158.068\n",
      "[87]\tvalid_0's tweedie: 158.068\n",
      "[88]\tvalid_0's tweedie: 158.068\n",
      "[89]\tvalid_0's tweedie: 158.068\n",
      "[90]\tvalid_0's tweedie: 158.068\n",
      "[91]\tvalid_0's tweedie: 158.068\n",
      "[92]\tvalid_0's tweedie: 158.067\n",
      "[93]\tvalid_0's tweedie: 158.067\n",
      "[94]\tvalid_0's tweedie: 158.067\n",
      "[95]\tvalid_0's tweedie: 158.066\n",
      "[96]\tvalid_0's tweedie: 158.066\n",
      "[97]\tvalid_0's tweedie: 158.064\n",
      "[98]\tvalid_0's tweedie: 158.064\n",
      "[99]\tvalid_0's tweedie: 158.064\n",
      "[100]\tvalid_0's tweedie: 158.063\n",
      "[101]\tvalid_0's tweedie: 158.063\n",
      "[102]\tvalid_0's tweedie: 158.063\n",
      "[103]\tvalid_0's tweedie: 158.063\n",
      "[104]\tvalid_0's tweedie: 158.063\n",
      "[105]\tvalid_0's tweedie: 158.063\n",
      "[106]\tvalid_0's tweedie: 158.063\n",
      "[107]\tvalid_0's tweedie: 158.063\n",
      "[108]\tvalid_0's tweedie: 158.063\n",
      "[109]\tvalid_0's tweedie: 158.063\n",
      "[110]\tvalid_0's tweedie: 158.062\n",
      "[111]\tvalid_0's tweedie: 158.062\n",
      "[112]\tvalid_0's tweedie: 158.062\n",
      "[113]\tvalid_0's tweedie: 158.062\n",
      "[114]\tvalid_0's tweedie: 158.062\n",
      "[115]\tvalid_0's tweedie: 158.062\n",
      "[116]\tvalid_0's tweedie: 158.062\n",
      "[117]\tvalid_0's tweedie: 158.062\n",
      "[118]\tvalid_0's tweedie: 158.062\n",
      "[119]\tvalid_0's tweedie: 158.061\n",
      "[120]\tvalid_0's tweedie: 158.06\n",
      "[121]\tvalid_0's tweedie: 158.06\n",
      "[122]\tvalid_0's tweedie: 158.06\n",
      "[123]\tvalid_0's tweedie: 158.06\n",
      "[124]\tvalid_0's tweedie: 158.06\n",
      "[125]\tvalid_0's tweedie: 158.06\n",
      "[126]\tvalid_0's tweedie: 158.06\n",
      "[127]\tvalid_0's tweedie: 158.059\n",
      "[128]\tvalid_0's tweedie: 158.06\n",
      "[129]\tvalid_0's tweedie: 158.06\n",
      "[130]\tvalid_0's tweedie: 158.06\n",
      "[131]\tvalid_0's tweedie: 158.06\n",
      "[132]\tvalid_0's tweedie: 158.06\n",
      "[133]\tvalid_0's tweedie: 158.06\n",
      "[134]\tvalid_0's tweedie: 158.06\n",
      "[135]\tvalid_0's tweedie: 158.06\n",
      "[136]\tvalid_0's tweedie: 158.06\n",
      "[137]\tvalid_0's tweedie: 158.06\n",
      "[138]\tvalid_0's tweedie: 158.06\n",
      "[139]\tvalid_0's tweedie: 158.059\n",
      "[140]\tvalid_0's tweedie: 158.059\n",
      "[141]\tvalid_0's tweedie: 158.059\n",
      "[142]\tvalid_0's tweedie: 158.059\n",
      "[143]\tvalid_0's tweedie: 158.059\n",
      "[144]\tvalid_0's tweedie: 158.059\n",
      "[145]\tvalid_0's tweedie: 158.059\n",
      "[146]\tvalid_0's tweedie: 158.059\n",
      "[147]\tvalid_0's tweedie: 158.058\n",
      "[148]\tvalid_0's tweedie: 158.058\n",
      "[149]\tvalid_0's tweedie: 158.058\n",
      "[150]\tvalid_0's tweedie: 158.058\n",
      "[151]\tvalid_0's tweedie: 158.058\n",
      "[152]\tvalid_0's tweedie: 158.058\n",
      "[153]\tvalid_0's tweedie: 158.058\n",
      "[154]\tvalid_0's tweedie: 158.058\n",
      "[155]\tvalid_0's tweedie: 158.057\n",
      "[156]\tvalid_0's tweedie: 158.057\n",
      "[157]\tvalid_0's tweedie: 158.057\n",
      "[158]\tvalid_0's tweedie: 158.056\n",
      "[159]\tvalid_0's tweedie: 158.056\n",
      "[160]\tvalid_0's tweedie: 158.056\n",
      "[161]\tvalid_0's tweedie: 158.056\n",
      "[162]\tvalid_0's tweedie: 158.056\n",
      "[163]\tvalid_0's tweedie: 158.056\n",
      "[164]\tvalid_0's tweedie: 158.056\n",
      "[165]\tvalid_0's tweedie: 158.056\n",
      "[166]\tvalid_0's tweedie: 158.056\n",
      "[167]\tvalid_0's tweedie: 158.056\n",
      "[168]\tvalid_0's tweedie: 158.056\n",
      "[169]\tvalid_0's tweedie: 158.056\n",
      "[170]\tvalid_0's tweedie: 158.056\n",
      "[171]\tvalid_0's tweedie: 158.056\n",
      "[172]\tvalid_0's tweedie: 158.056\n",
      "[173]\tvalid_0's tweedie: 158.056\n",
      "[174]\tvalid_0's tweedie: 158.056\n",
      "[175]\tvalid_0's tweedie: 158.056\n",
      "[176]\tvalid_0's tweedie: 158.056\n",
      "[177]\tvalid_0's tweedie: 158.056\n",
      "[178]\tvalid_0's tweedie: 158.056\n",
      "[179]\tvalid_0's tweedie: 158.056\n",
      "[180]\tvalid_0's tweedie: 158.055\n",
      "[181]\tvalid_0's tweedie: 158.055\n",
      "[182]\tvalid_0's tweedie: 158.055\n",
      "[183]\tvalid_0's tweedie: 158.055\n",
      "[184]\tvalid_0's tweedie: 158.054\n",
      "[185]\tvalid_0's tweedie: 158.054\n",
      "[186]\tvalid_0's tweedie: 158.054\n",
      "[187]\tvalid_0's tweedie: 158.054\n",
      "[188]\tvalid_0's tweedie: 158.054\n",
      "[189]\tvalid_0's tweedie: 158.054\n",
      "[190]\tvalid_0's tweedie: 158.054\n",
      "[191]\tvalid_0's tweedie: 158.054\n",
      "[192]\tvalid_0's tweedie: 158.054\n",
      "[193]\tvalid_0's tweedie: 158.056\n",
      "[194]\tvalid_0's tweedie: 158.056\n",
      "[195]\tvalid_0's tweedie: 158.056\n",
      "[196]\tvalid_0's tweedie: 158.056\n",
      "[197]\tvalid_0's tweedie: 158.056\n",
      "[198]\tvalid_0's tweedie: 158.055\n",
      "[199]\tvalid_0's tweedie: 158.055\n",
      "[200]\tvalid_0's tweedie: 158.056\n",
      "[201]\tvalid_0's tweedie: 158.056\n",
      "[202]\tvalid_0's tweedie: 158.055\n",
      "[203]\tvalid_0's tweedie: 158.056\n",
      "[204]\tvalid_0's tweedie: 158.056\n",
      "[205]\tvalid_0's tweedie: 158.056\n",
      "[206]\tvalid_0's tweedie: 158.056\n",
      "[207]\tvalid_0's tweedie: 158.056\n",
      "[208]\tvalid_0's tweedie: 158.056\n",
      "[209]\tvalid_0's tweedie: 158.056\n",
      "[210]\tvalid_0's tweedie: 158.056\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's tweedie: 158.054\n",
      "Training model for level 8\n",
      "Training model for level 8 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5520\n",
      "[LightGBM] [Info] Number of data points in the train set: 56130, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.040976\n",
      "[1]\tvalid_0's tweedie: 148.726\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.862\n",
      "[3]\tvalid_0's tweedie: 145.301\n",
      "[4]\tvalid_0's tweedie: 144.02\n",
      "[5]\tvalid_0's tweedie: 142.946\n",
      "[6]\tvalid_0's tweedie: 142.073\n",
      "[7]\tvalid_0's tweedie: 141.359\n",
      "[8]\tvalid_0's tweedie: 140.769\n",
      "[9]\tvalid_0's tweedie: 140.29\n",
      "[10]\tvalid_0's tweedie: 139.892\n",
      "[11]\tvalid_0's tweedie: 139.565\n",
      "[12]\tvalid_0's tweedie: 139.299\n",
      "[13]\tvalid_0's tweedie: 139.087\n",
      "[14]\tvalid_0's tweedie: 138.909\n",
      "[15]\tvalid_0's tweedie: 138.766\n",
      "[16]\tvalid_0's tweedie: 138.649\n",
      "[17]\tvalid_0's tweedie: 138.551\n",
      "[18]\tvalid_0's tweedie: 138.471\n",
      "[19]\tvalid_0's tweedie: 138.404\n",
      "[20]\tvalid_0's tweedie: 138.352\n",
      "[21]\tvalid_0's tweedie: 138.307\n",
      "[22]\tvalid_0's tweedie: 138.271\n",
      "[23]\tvalid_0's tweedie: 138.24\n",
      "[24]\tvalid_0's tweedie: 138.217\n",
      "[25]\tvalid_0's tweedie: 138.196\n",
      "[26]\tvalid_0's tweedie: 138.18\n",
      "[27]\tvalid_0's tweedie: 138.168\n",
      "[28]\tvalid_0's tweedie: 138.158\n",
      "[29]\tvalid_0's tweedie: 138.149\n",
      "[30]\tvalid_0's tweedie: 138.142\n",
      "[31]\tvalid_0's tweedie: 138.136\n",
      "[32]\tvalid_0's tweedie: 138.13\n",
      "[33]\tvalid_0's tweedie: 138.126\n",
      "[34]\tvalid_0's tweedie: 138.123\n",
      "[35]\tvalid_0's tweedie: 138.12\n",
      "[36]\tvalid_0's tweedie: 138.117\n",
      "[37]\tvalid_0's tweedie: 138.115\n",
      "[38]\tvalid_0's tweedie: 138.113\n",
      "[39]\tvalid_0's tweedie: 138.112\n",
      "[40]\tvalid_0's tweedie: 138.111\n",
      "[41]\tvalid_0's tweedie: 138.11\n",
      "[42]\tvalid_0's tweedie: 138.108\n",
      "[43]\tvalid_0's tweedie: 138.107\n",
      "[44]\tvalid_0's tweedie: 138.107\n",
      "[45]\tvalid_0's tweedie: 138.106\n",
      "[46]\tvalid_0's tweedie: 138.105\n",
      "[47]\tvalid_0's tweedie: 138.105\n",
      "[48]\tvalid_0's tweedie: 138.104\n",
      "[49]\tvalid_0's tweedie: 138.104\n",
      "[50]\tvalid_0's tweedie: 138.104\n",
      "[51]\tvalid_0's tweedie: 138.103\n",
      "[52]\tvalid_0's tweedie: 138.103\n",
      "[53]\tvalid_0's tweedie: 138.102\n",
      "[54]\tvalid_0's tweedie: 138.102\n",
      "[55]\tvalid_0's tweedie: 138.102\n",
      "[56]\tvalid_0's tweedie: 138.102\n",
      "[57]\tvalid_0's tweedie: 138.102\n",
      "[58]\tvalid_0's tweedie: 138.102\n",
      "[59]\tvalid_0's tweedie: 138.101\n",
      "[60]\tvalid_0's tweedie: 138.101\n",
      "[61]\tvalid_0's tweedie: 138.101\n",
      "[62]\tvalid_0's tweedie: 138.101\n",
      "[63]\tvalid_0's tweedie: 138.101\n",
      "[64]\tvalid_0's tweedie: 138.101\n",
      "[65]\tvalid_0's tweedie: 138.101\n",
      "[66]\tvalid_0's tweedie: 138.101\n",
      "[67]\tvalid_0's tweedie: 138.1\n",
      "[68]\tvalid_0's tweedie: 138.101\n",
      "[69]\tvalid_0's tweedie: 138.1\n",
      "[70]\tvalid_0's tweedie: 138.1\n",
      "[71]\tvalid_0's tweedie: 138.1\n",
      "[72]\tvalid_0's tweedie: 138.1\n",
      "[73]\tvalid_0's tweedie: 138.1\n",
      "[74]\tvalid_0's tweedie: 138.1\n",
      "[75]\tvalid_0's tweedie: 138.1\n",
      "[76]\tvalid_0's tweedie: 138.1\n",
      "[77]\tvalid_0's tweedie: 138.1\n",
      "[78]\tvalid_0's tweedie: 138.099\n",
      "[79]\tvalid_0's tweedie: 138.099\n",
      "[80]\tvalid_0's tweedie: 138.099\n",
      "[81]\tvalid_0's tweedie: 138.098\n",
      "[82]\tvalid_0's tweedie: 138.098\n",
      "[83]\tvalid_0's tweedie: 138.098\n",
      "[84]\tvalid_0's tweedie: 138.098\n",
      "[85]\tvalid_0's tweedie: 138.098\n",
      "[86]\tvalid_0's tweedie: 138.098\n",
      "[87]\tvalid_0's tweedie: 138.098\n",
      "[88]\tvalid_0's tweedie: 138.098\n",
      "[89]\tvalid_0's tweedie: 138.097\n",
      "[90]\tvalid_0's tweedie: 138.097\n",
      "[91]\tvalid_0's tweedie: 138.097\n",
      "[92]\tvalid_0's tweedie: 138.097\n",
      "[93]\tvalid_0's tweedie: 138.097\n",
      "[94]\tvalid_0's tweedie: 138.097\n",
      "[95]\tvalid_0's tweedie: 138.097\n",
      "[96]\tvalid_0's tweedie: 138.097\n",
      "[97]\tvalid_0's tweedie: 138.096\n",
      "[98]\tvalid_0's tweedie: 138.096\n",
      "[99]\tvalid_0's tweedie: 138.096\n",
      "[100]\tvalid_0's tweedie: 138.096\n",
      "[101]\tvalid_0's tweedie: 138.096\n",
      "[102]\tvalid_0's tweedie: 138.096\n",
      "[103]\tvalid_0's tweedie: 138.095\n",
      "[104]\tvalid_0's tweedie: 138.095\n",
      "[105]\tvalid_0's tweedie: 138.095\n",
      "[106]\tvalid_0's tweedie: 138.095\n",
      "[107]\tvalid_0's tweedie: 138.095\n",
      "[108]\tvalid_0's tweedie: 138.095\n",
      "[109]\tvalid_0's tweedie: 138.095\n",
      "[110]\tvalid_0's tweedie: 138.095\n",
      "[111]\tvalid_0's tweedie: 138.095\n",
      "[112]\tvalid_0's tweedie: 138.095\n",
      "[113]\tvalid_0's tweedie: 138.095\n",
      "[114]\tvalid_0's tweedie: 138.095\n",
      "[115]\tvalid_0's tweedie: 138.095\n",
      "[116]\tvalid_0's tweedie: 138.095\n",
      "[117]\tvalid_0's tweedie: 138.095\n",
      "[118]\tvalid_0's tweedie: 138.094\n",
      "[119]\tvalid_0's tweedie: 138.094\n",
      "[120]\tvalid_0's tweedie: 138.094\n",
      "[121]\tvalid_0's tweedie: 138.095\n",
      "[122]\tvalid_0's tweedie: 138.094\n",
      "[123]\tvalid_0's tweedie: 138.094\n",
      "[124]\tvalid_0's tweedie: 138.094\n",
      "[125]\tvalid_0's tweedie: 138.094\n",
      "[126]\tvalid_0's tweedie: 138.094\n",
      "[127]\tvalid_0's tweedie: 138.094\n",
      "[128]\tvalid_0's tweedie: 138.094\n",
      "[129]\tvalid_0's tweedie: 138.094\n",
      "[130]\tvalid_0's tweedie: 138.094\n",
      "[131]\tvalid_0's tweedie: 138.094\n",
      "[132]\tvalid_0's tweedie: 138.094\n",
      "[133]\tvalid_0's tweedie: 138.094\n",
      "[134]\tvalid_0's tweedie: 138.094\n",
      "[135]\tvalid_0's tweedie: 138.093\n",
      "[136]\tvalid_0's tweedie: 138.093\n",
      "[137]\tvalid_0's tweedie: 138.093\n",
      "[138]\tvalid_0's tweedie: 138.093\n",
      "[139]\tvalid_0's tweedie: 138.093\n",
      "[140]\tvalid_0's tweedie: 138.093\n",
      "[141]\tvalid_0's tweedie: 138.093\n",
      "[142]\tvalid_0's tweedie: 138.093\n",
      "[143]\tvalid_0's tweedie: 138.093\n",
      "[144]\tvalid_0's tweedie: 138.093\n",
      "[145]\tvalid_0's tweedie: 138.093\n",
      "[146]\tvalid_0's tweedie: 138.093\n",
      "[147]\tvalid_0's tweedie: 138.093\n",
      "[148]\tvalid_0's tweedie: 138.093\n",
      "[149]\tvalid_0's tweedie: 138.093\n",
      "[150]\tvalid_0's tweedie: 138.093\n",
      "[151]\tvalid_0's tweedie: 138.093\n",
      "[152]\tvalid_0's tweedie: 138.093\n",
      "[153]\tvalid_0's tweedie: 138.093\n",
      "[154]\tvalid_0's tweedie: 138.092\n",
      "[155]\tvalid_0's tweedie: 138.092\n",
      "[156]\tvalid_0's tweedie: 138.092\n",
      "[157]\tvalid_0's tweedie: 138.092\n",
      "[158]\tvalid_0's tweedie: 138.092\n",
      "[159]\tvalid_0's tweedie: 138.092\n",
      "[160]\tvalid_0's tweedie: 138.092\n",
      "[161]\tvalid_0's tweedie: 138.092\n",
      "[162]\tvalid_0's tweedie: 138.091\n",
      "[163]\tvalid_0's tweedie: 138.091\n",
      "[164]\tvalid_0's tweedie: 138.091\n",
      "[165]\tvalid_0's tweedie: 138.091\n",
      "[166]\tvalid_0's tweedie: 138.091\n",
      "[167]\tvalid_0's tweedie: 138.091\n",
      "[168]\tvalid_0's tweedie: 138.091\n",
      "[169]\tvalid_0's tweedie: 138.091\n",
      "[170]\tvalid_0's tweedie: 138.091\n",
      "[171]\tvalid_0's tweedie: 138.091\n",
      "[172]\tvalid_0's tweedie: 138.091\n",
      "[173]\tvalid_0's tweedie: 138.091\n",
      "[174]\tvalid_0's tweedie: 138.091\n",
      "[175]\tvalid_0's tweedie: 138.091\n",
      "[176]\tvalid_0's tweedie: 138.091\n",
      "[177]\tvalid_0's tweedie: 138.091\n",
      "[178]\tvalid_0's tweedie: 138.091\n",
      "[179]\tvalid_0's tweedie: 138.091\n",
      "[180]\tvalid_0's tweedie: 138.09\n",
      "[181]\tvalid_0's tweedie: 138.09\n",
      "[182]\tvalid_0's tweedie: 138.09\n",
      "[183]\tvalid_0's tweedie: 138.09\n",
      "[184]\tvalid_0's tweedie: 138.09\n",
      "[185]\tvalid_0's tweedie: 138.09\n",
      "[186]\tvalid_0's tweedie: 138.09\n",
      "[187]\tvalid_0's tweedie: 138.09\n",
      "[188]\tvalid_0's tweedie: 138.09\n",
      "[189]\tvalid_0's tweedie: 138.09\n",
      "[190]\tvalid_0's tweedie: 138.09\n",
      "[191]\tvalid_0's tweedie: 138.09\n",
      "[192]\tvalid_0's tweedie: 138.09\n",
      "[193]\tvalid_0's tweedie: 138.09\n",
      "[194]\tvalid_0's tweedie: 138.09\n",
      "[195]\tvalid_0's tweedie: 138.09\n",
      "[196]\tvalid_0's tweedie: 138.09\n",
      "[197]\tvalid_0's tweedie: 138.09\n",
      "[198]\tvalid_0's tweedie: 138.09\n",
      "[199]\tvalid_0's tweedie: 138.09\n",
      "[200]\tvalid_0's tweedie: 138.09\n",
      "[201]\tvalid_0's tweedie: 138.09\n",
      "[202]\tvalid_0's tweedie: 138.09\n",
      "[203]\tvalid_0's tweedie: 138.09\n",
      "[204]\tvalid_0's tweedie: 138.09\n",
      "[205]\tvalid_0's tweedie: 138.09\n",
      "[206]\tvalid_0's tweedie: 138.09\n",
      "[207]\tvalid_0's tweedie: 138.09\n",
      "[208]\tvalid_0's tweedie: 138.09\n",
      "[209]\tvalid_0's tweedie: 138.09\n",
      "[210]\tvalid_0's tweedie: 138.09\n",
      "[211]\tvalid_0's tweedie: 138.09\n",
      "[212]\tvalid_0's tweedie: 138.089\n",
      "[213]\tvalid_0's tweedie: 138.089\n",
      "[214]\tvalid_0's tweedie: 138.089\n",
      "[215]\tvalid_0's tweedie: 138.089\n",
      "[216]\tvalid_0's tweedie: 138.089\n",
      "[217]\tvalid_0's tweedie: 138.089\n",
      "[218]\tvalid_0's tweedie: 138.089\n",
      "[219]\tvalid_0's tweedie: 138.089\n",
      "[220]\tvalid_0's tweedie: 138.089\n",
      "[221]\tvalid_0's tweedie: 138.089\n",
      "[222]\tvalid_0's tweedie: 138.089\n",
      "[223]\tvalid_0's tweedie: 138.089\n",
      "[224]\tvalid_0's tweedie: 138.089\n",
      "[225]\tvalid_0's tweedie: 138.089\n",
      "[226]\tvalid_0's tweedie: 138.089\n",
      "[227]\tvalid_0's tweedie: 138.089\n",
      "[228]\tvalid_0's tweedie: 138.089\n",
      "[229]\tvalid_0's tweedie: 138.089\n",
      "[230]\tvalid_0's tweedie: 138.089\n",
      "[231]\tvalid_0's tweedie: 138.089\n",
      "[232]\tvalid_0's tweedie: 138.089\n",
      "[233]\tvalid_0's tweedie: 138.089\n",
      "[234]\tvalid_0's tweedie: 138.089\n",
      "[235]\tvalid_0's tweedie: 138.089\n",
      "[236]\tvalid_0's tweedie: 138.089\n",
      "[237]\tvalid_0's tweedie: 138.089\n",
      "[238]\tvalid_0's tweedie: 138.089\n",
      "[239]\tvalid_0's tweedie: 138.089\n",
      "[240]\tvalid_0's tweedie: 138.089\n",
      "[241]\tvalid_0's tweedie: 138.089\n",
      "[242]\tvalid_0's tweedie: 138.089\n",
      "[243]\tvalid_0's tweedie: 138.089\n",
      "[244]\tvalid_0's tweedie: 138.089\n",
      "[245]\tvalid_0's tweedie: 138.089\n",
      "[246]\tvalid_0's tweedie: 138.089\n",
      "[247]\tvalid_0's tweedie: 138.089\n",
      "[248]\tvalid_0's tweedie: 138.089\n",
      "[249]\tvalid_0's tweedie: 138.089\n",
      "[250]\tvalid_0's tweedie: 138.089\n",
      "[251]\tvalid_0's tweedie: 138.089\n",
      "[252]\tvalid_0's tweedie: 138.089\n",
      "[253]\tvalid_0's tweedie: 138.089\n",
      "[254]\tvalid_0's tweedie: 138.089\n",
      "[255]\tvalid_0's tweedie: 138.089\n",
      "[256]\tvalid_0's tweedie: 138.089\n",
      "[257]\tvalid_0's tweedie: 138.089\n",
      "[258]\tvalid_0's tweedie: 138.089\n",
      "[259]\tvalid_0's tweedie: 138.088\n",
      "[260]\tvalid_0's tweedie: 138.088\n",
      "[261]\tvalid_0's tweedie: 138.088\n",
      "[262]\tvalid_0's tweedie: 138.088\n",
      "[263]\tvalid_0's tweedie: 138.088\n",
      "[264]\tvalid_0's tweedie: 138.088\n",
      "[265]\tvalid_0's tweedie: 138.088\n",
      "[266]\tvalid_0's tweedie: 138.088\n",
      "[267]\tvalid_0's tweedie: 138.088\n",
      "[268]\tvalid_0's tweedie: 138.088\n",
      "[269]\tvalid_0's tweedie: 138.088\n",
      "[270]\tvalid_0's tweedie: 138.088\n",
      "[271]\tvalid_0's tweedie: 138.088\n",
      "[272]\tvalid_0's tweedie: 138.088\n",
      "[273]\tvalid_0's tweedie: 138.088\n",
      "[274]\tvalid_0's tweedie: 138.088\n",
      "[275]\tvalid_0's tweedie: 138.088\n",
      "[276]\tvalid_0's tweedie: 138.088\n",
      "[277]\tvalid_0's tweedie: 138.088\n",
      "[278]\tvalid_0's tweedie: 138.088\n",
      "[279]\tvalid_0's tweedie: 138.088\n",
      "[280]\tvalid_0's tweedie: 138.088\n",
      "[281]\tvalid_0's tweedie: 138.088\n",
      "[282]\tvalid_0's tweedie: 138.088\n",
      "[283]\tvalid_0's tweedie: 138.088\n",
      "[284]\tvalid_0's tweedie: 138.088\n",
      "[285]\tvalid_0's tweedie: 138.088\n",
      "[286]\tvalid_0's tweedie: 138.088\n",
      "[287]\tvalid_0's tweedie: 138.088\n",
      "[288]\tvalid_0's tweedie: 138.088\n",
      "[289]\tvalid_0's tweedie: 138.088\n",
      "[290]\tvalid_0's tweedie: 138.088\n",
      "[291]\tvalid_0's tweedie: 138.088\n",
      "[292]\tvalid_0's tweedie: 138.088\n",
      "[293]\tvalid_0's tweedie: 138.088\n",
      "[294]\tvalid_0's tweedie: 138.088\n",
      "[295]\tvalid_0's tweedie: 138.088\n",
      "[296]\tvalid_0's tweedie: 138.088\n",
      "[297]\tvalid_0's tweedie: 138.088\n",
      "[298]\tvalid_0's tweedie: 138.088\n",
      "[299]\tvalid_0's tweedie: 138.088\n",
      "[300]\tvalid_0's tweedie: 138.088\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[290]\tvalid_0's tweedie: 138.088\n",
      "Training model for level 8 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5519\n",
      "[LightGBM] [Info] Number of data points in the train set: 56100, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.040968\n",
      "[1]\tvalid_0's tweedie: 148.761\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.9\n",
      "[3]\tvalid_0's tweedie: 145.346\n",
      "[4]\tvalid_0's tweedie: 144.048\n",
      "[5]\tvalid_0's tweedie: 143.001\n",
      "[6]\tvalid_0's tweedie: 142.13\n",
      "[7]\tvalid_0's tweedie: 141.425\n",
      "[8]\tvalid_0's tweedie: 140.833\n",
      "[9]\tvalid_0's tweedie: 140.345\n",
      "[10]\tvalid_0's tweedie: 139.953\n",
      "[11]\tvalid_0's tweedie: 139.626\n",
      "[12]\tvalid_0's tweedie: 139.36\n",
      "[13]\tvalid_0's tweedie: 139.139\n",
      "[14]\tvalid_0's tweedie: 138.965\n",
      "[15]\tvalid_0's tweedie: 138.818\n",
      "[16]\tvalid_0's tweedie: 138.699\n",
      "[17]\tvalid_0's tweedie: 138.597\n",
      "[18]\tvalid_0's tweedie: 138.517\n",
      "[19]\tvalid_0's tweedie: 138.451\n",
      "[20]\tvalid_0's tweedie: 138.396\n",
      "[21]\tvalid_0's tweedie: 138.349\n",
      "[22]\tvalid_0's tweedie: 138.313\n",
      "[23]\tvalid_0's tweedie: 138.28\n",
      "[24]\tvalid_0's tweedie: 138.255\n",
      "[25]\tvalid_0's tweedie: 138.236\n",
      "[26]\tvalid_0's tweedie: 138.219\n",
      "[27]\tvalid_0's tweedie: 138.205\n",
      "[28]\tvalid_0's tweedie: 138.194\n",
      "[29]\tvalid_0's tweedie: 138.184\n",
      "[30]\tvalid_0's tweedie: 138.177\n",
      "[31]\tvalid_0's tweedie: 138.17\n",
      "[32]\tvalid_0's tweedie: 138.164\n",
      "[33]\tvalid_0's tweedie: 138.159\n",
      "[34]\tvalid_0's tweedie: 138.156\n",
      "[35]\tvalid_0's tweedie: 138.153\n",
      "[36]\tvalid_0's tweedie: 138.149\n",
      "[37]\tvalid_0's tweedie: 138.147\n",
      "[38]\tvalid_0's tweedie: 138.145\n",
      "[39]\tvalid_0's tweedie: 138.143\n",
      "[40]\tvalid_0's tweedie: 138.142\n",
      "[41]\tvalid_0's tweedie: 138.141\n",
      "[42]\tvalid_0's tweedie: 138.141\n",
      "[43]\tvalid_0's tweedie: 138.14\n",
      "[44]\tvalid_0's tweedie: 138.139\n",
      "[45]\tvalid_0's tweedie: 138.138\n",
      "[46]\tvalid_0's tweedie: 138.137\n",
      "[47]\tvalid_0's tweedie: 138.137\n",
      "[48]\tvalid_0's tweedie: 138.136\n",
      "[49]\tvalid_0's tweedie: 138.135\n",
      "[50]\tvalid_0's tweedie: 138.135\n",
      "[51]\tvalid_0's tweedie: 138.134\n",
      "[52]\tvalid_0's tweedie: 138.134\n",
      "[53]\tvalid_0's tweedie: 138.134\n",
      "[54]\tvalid_0's tweedie: 138.134\n",
      "[55]\tvalid_0's tweedie: 138.133\n",
      "[56]\tvalid_0's tweedie: 138.132\n",
      "[57]\tvalid_0's tweedie: 138.132\n",
      "[58]\tvalid_0's tweedie: 138.131\n",
      "[59]\tvalid_0's tweedie: 138.131\n",
      "[60]\tvalid_0's tweedie: 138.131\n",
      "[61]\tvalid_0's tweedie: 138.13\n",
      "[62]\tvalid_0's tweedie: 138.13\n",
      "[63]\tvalid_0's tweedie: 138.13\n",
      "[64]\tvalid_0's tweedie: 138.13\n",
      "[65]\tvalid_0's tweedie: 138.129\n",
      "[66]\tvalid_0's tweedie: 138.129\n",
      "[67]\tvalid_0's tweedie: 138.128\n",
      "[68]\tvalid_0's tweedie: 138.128\n",
      "[69]\tvalid_0's tweedie: 138.127\n",
      "[70]\tvalid_0's tweedie: 138.127\n",
      "[71]\tvalid_0's tweedie: 138.127\n",
      "[72]\tvalid_0's tweedie: 138.127\n",
      "[73]\tvalid_0's tweedie: 138.127\n",
      "[74]\tvalid_0's tweedie: 138.127\n",
      "[75]\tvalid_0's tweedie: 138.126\n",
      "[76]\tvalid_0's tweedie: 138.124\n",
      "[77]\tvalid_0's tweedie: 138.124\n",
      "[78]\tvalid_0's tweedie: 138.123\n",
      "[79]\tvalid_0's tweedie: 138.123\n",
      "[80]\tvalid_0's tweedie: 138.123\n",
      "[81]\tvalid_0's tweedie: 138.123\n",
      "[82]\tvalid_0's tweedie: 138.123\n",
      "[83]\tvalid_0's tweedie: 138.123\n",
      "[84]\tvalid_0's tweedie: 138.121\n",
      "[85]\tvalid_0's tweedie: 138.12\n",
      "[86]\tvalid_0's tweedie: 138.12\n",
      "[87]\tvalid_0's tweedie: 138.12\n",
      "[88]\tvalid_0's tweedie: 138.12\n",
      "[89]\tvalid_0's tweedie: 138.12\n",
      "[90]\tvalid_0's tweedie: 138.119\n",
      "[91]\tvalid_0's tweedie: 138.118\n",
      "[92]\tvalid_0's tweedie: 138.118\n",
      "[93]\tvalid_0's tweedie: 138.118\n",
      "[94]\tvalid_0's tweedie: 138.118\n",
      "[95]\tvalid_0's tweedie: 138.119\n",
      "[96]\tvalid_0's tweedie: 138.119\n",
      "[97]\tvalid_0's tweedie: 138.118\n",
      "[98]\tvalid_0's tweedie: 138.118\n",
      "[99]\tvalid_0's tweedie: 138.118\n",
      "[100]\tvalid_0's tweedie: 138.118\n",
      "[101]\tvalid_0's tweedie: 138.118\n",
      "[102]\tvalid_0's tweedie: 138.118\n",
      "[103]\tvalid_0's tweedie: 138.118\n",
      "[104]\tvalid_0's tweedie: 138.118\n",
      "[105]\tvalid_0's tweedie: 138.117\n",
      "[106]\tvalid_0's tweedie: 138.117\n",
      "[107]\tvalid_0's tweedie: 138.117\n",
      "[108]\tvalid_0's tweedie: 138.117\n",
      "[109]\tvalid_0's tweedie: 138.117\n",
      "[110]\tvalid_0's tweedie: 138.117\n",
      "[111]\tvalid_0's tweedie: 138.117\n",
      "[112]\tvalid_0's tweedie: 138.117\n",
      "[113]\tvalid_0's tweedie: 138.117\n",
      "[114]\tvalid_0's tweedie: 138.116\n",
      "[115]\tvalid_0's tweedie: 138.117\n",
      "[116]\tvalid_0's tweedie: 138.117\n",
      "[117]\tvalid_0's tweedie: 138.116\n",
      "[118]\tvalid_0's tweedie: 138.116\n",
      "[119]\tvalid_0's tweedie: 138.116\n",
      "[120]\tvalid_0's tweedie: 138.116\n",
      "[121]\tvalid_0's tweedie: 138.116\n",
      "[122]\tvalid_0's tweedie: 138.116\n",
      "[123]\tvalid_0's tweedie: 138.116\n",
      "[124]\tvalid_0's tweedie: 138.116\n",
      "[125]\tvalid_0's tweedie: 138.115\n",
      "[126]\tvalid_0's tweedie: 138.115\n",
      "[127]\tvalid_0's tweedie: 138.115\n",
      "[128]\tvalid_0's tweedie: 138.115\n",
      "[129]\tvalid_0's tweedie: 138.115\n",
      "[130]\tvalid_0's tweedie: 138.115\n",
      "[131]\tvalid_0's tweedie: 138.115\n",
      "[132]\tvalid_0's tweedie: 138.115\n",
      "[133]\tvalid_0's tweedie: 138.115\n",
      "[134]\tvalid_0's tweedie: 138.115\n",
      "[135]\tvalid_0's tweedie: 138.115\n",
      "[136]\tvalid_0's tweedie: 138.115\n",
      "[137]\tvalid_0's tweedie: 138.114\n",
      "[138]\tvalid_0's tweedie: 138.114\n",
      "[139]\tvalid_0's tweedie: 138.115\n",
      "[140]\tvalid_0's tweedie: 138.115\n",
      "[141]\tvalid_0's tweedie: 138.115\n",
      "[142]\tvalid_0's tweedie: 138.115\n",
      "[143]\tvalid_0's tweedie: 138.114\n",
      "[144]\tvalid_0's tweedie: 138.115\n",
      "[145]\tvalid_0's tweedie: 138.114\n",
      "[146]\tvalid_0's tweedie: 138.114\n",
      "[147]\tvalid_0's tweedie: 138.114\n",
      "[148]\tvalid_0's tweedie: 138.114\n",
      "[149]\tvalid_0's tweedie: 138.114\n",
      "[150]\tvalid_0's tweedie: 138.114\n",
      "[151]\tvalid_0's tweedie: 138.114\n",
      "[152]\tvalid_0's tweedie: 138.114\n",
      "[153]\tvalid_0's tweedie: 138.114\n",
      "[154]\tvalid_0's tweedie: 138.114\n",
      "[155]\tvalid_0's tweedie: 138.114\n",
      "[156]\tvalid_0's tweedie: 138.114\n",
      "[157]\tvalid_0's tweedie: 138.114\n",
      "[158]\tvalid_0's tweedie: 138.114\n",
      "[159]\tvalid_0's tweedie: 138.114\n",
      "[160]\tvalid_0's tweedie: 138.114\n",
      "[161]\tvalid_0's tweedie: 138.114\n",
      "[162]\tvalid_0's tweedie: 138.114\n",
      "[163]\tvalid_0's tweedie: 138.114\n",
      "[164]\tvalid_0's tweedie: 138.114\n",
      "[165]\tvalid_0's tweedie: 138.114\n",
      "[166]\tvalid_0's tweedie: 138.114\n",
      "[167]\tvalid_0's tweedie: 138.114\n",
      "[168]\tvalid_0's tweedie: 138.114\n",
      "[169]\tvalid_0's tweedie: 138.113\n",
      "[170]\tvalid_0's tweedie: 138.113\n",
      "[171]\tvalid_0's tweedie: 138.113\n",
      "[172]\tvalid_0's tweedie: 138.113\n",
      "[173]\tvalid_0's tweedie: 138.113\n",
      "[174]\tvalid_0's tweedie: 138.114\n",
      "[175]\tvalid_0's tweedie: 138.113\n",
      "[176]\tvalid_0's tweedie: 138.113\n",
      "[177]\tvalid_0's tweedie: 138.113\n",
      "[178]\tvalid_0's tweedie: 138.113\n",
      "[179]\tvalid_0's tweedie: 138.113\n",
      "[180]\tvalid_0's tweedie: 138.113\n",
      "[181]\tvalid_0's tweedie: 138.113\n",
      "[182]\tvalid_0's tweedie: 138.113\n",
      "[183]\tvalid_0's tweedie: 138.113\n",
      "[184]\tvalid_0's tweedie: 138.113\n",
      "[185]\tvalid_0's tweedie: 138.113\n",
      "[186]\tvalid_0's tweedie: 138.113\n",
      "[187]\tvalid_0's tweedie: 138.113\n",
      "[188]\tvalid_0's tweedie: 138.113\n",
      "[189]\tvalid_0's tweedie: 138.113\n",
      "[190]\tvalid_0's tweedie: 138.113\n",
      "[191]\tvalid_0's tweedie: 138.113\n",
      "[192]\tvalid_0's tweedie: 138.113\n",
      "[193]\tvalid_0's tweedie: 138.113\n",
      "[194]\tvalid_0's tweedie: 138.112\n",
      "[195]\tvalid_0's tweedie: 138.112\n",
      "[196]\tvalid_0's tweedie: 138.112\n",
      "[197]\tvalid_0's tweedie: 138.112\n",
      "[198]\tvalid_0's tweedie: 138.112\n",
      "[199]\tvalid_0's tweedie: 138.112\n",
      "[200]\tvalid_0's tweedie: 138.112\n",
      "[201]\tvalid_0's tweedie: 138.112\n",
      "[202]\tvalid_0's tweedie: 138.112\n",
      "[203]\tvalid_0's tweedie: 138.112\n",
      "[204]\tvalid_0's tweedie: 138.112\n",
      "[205]\tvalid_0's tweedie: 138.112\n",
      "[206]\tvalid_0's tweedie: 138.112\n",
      "[207]\tvalid_0's tweedie: 138.112\n",
      "[208]\tvalid_0's tweedie: 138.112\n",
      "[209]\tvalid_0's tweedie: 138.112\n",
      "[210]\tvalid_0's tweedie: 138.112\n",
      "[211]\tvalid_0's tweedie: 138.112\n",
      "[212]\tvalid_0's tweedie: 138.112\n",
      "[213]\tvalid_0's tweedie: 138.112\n",
      "[214]\tvalid_0's tweedie: 138.112\n",
      "[215]\tvalid_0's tweedie: 138.112\n",
      "[216]\tvalid_0's tweedie: 138.112\n",
      "[217]\tvalid_0's tweedie: 138.112\n",
      "[218]\tvalid_0's tweedie: 138.112\n",
      "[219]\tvalid_0's tweedie: 138.112\n",
      "[220]\tvalid_0's tweedie: 138.112\n",
      "[221]\tvalid_0's tweedie: 138.112\n",
      "[222]\tvalid_0's tweedie: 138.112\n",
      "[223]\tvalid_0's tweedie: 138.112\n",
      "[224]\tvalid_0's tweedie: 138.112\n",
      "[225]\tvalid_0's tweedie: 138.112\n",
      "[226]\tvalid_0's tweedie: 138.112\n",
      "[227]\tvalid_0's tweedie: 138.112\n",
      "[228]\tvalid_0's tweedie: 138.112\n",
      "[229]\tvalid_0's tweedie: 138.112\n",
      "[230]\tvalid_0's tweedie: 138.112\n",
      "[231]\tvalid_0's tweedie: 138.112\n",
      "[232]\tvalid_0's tweedie: 138.112\n",
      "[233]\tvalid_0's tweedie: 138.112\n",
      "[234]\tvalid_0's tweedie: 138.112\n",
      "[235]\tvalid_0's tweedie: 138.112\n",
      "[236]\tvalid_0's tweedie: 138.112\n",
      "[237]\tvalid_0's tweedie: 138.112\n",
      "[238]\tvalid_0's tweedie: 138.112\n",
      "[239]\tvalid_0's tweedie: 138.112\n",
      "[240]\tvalid_0's tweedie: 138.112\n",
      "[241]\tvalid_0's tweedie: 138.112\n",
      "[242]\tvalid_0's tweedie: 138.112\n",
      "[243]\tvalid_0's tweedie: 138.112\n",
      "[244]\tvalid_0's tweedie: 138.112\n",
      "[245]\tvalid_0's tweedie: 138.112\n",
      "[246]\tvalid_0's tweedie: 138.112\n",
      "[247]\tvalid_0's tweedie: 138.112\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's tweedie: 138.112\n",
      "Training model for level 8 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5518\n",
      "[LightGBM] [Info] Number of data points in the train set: 56070, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.040935\n",
      "[1]\tvalid_0's tweedie: 148.754\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.894\n",
      "[3]\tvalid_0's tweedie: 145.367\n",
      "[4]\tvalid_0's tweedie: 144.08\n",
      "[5]\tvalid_0's tweedie: 143.014\n",
      "[6]\tvalid_0's tweedie: 142.142\n",
      "[7]\tvalid_0's tweedie: 141.43\n",
      "[8]\tvalid_0's tweedie: 140.838\n",
      "[9]\tvalid_0's tweedie: 140.347\n",
      "[10]\tvalid_0's tweedie: 139.947\n",
      "[11]\tvalid_0's tweedie: 139.621\n",
      "[12]\tvalid_0's tweedie: 139.356\n",
      "[13]\tvalid_0's tweedie: 139.135\n",
      "[14]\tvalid_0's tweedie: 138.957\n",
      "[15]\tvalid_0's tweedie: 138.811\n",
      "[16]\tvalid_0's tweedie: 138.689\n",
      "[17]\tvalid_0's tweedie: 138.593\n",
      "[18]\tvalid_0's tweedie: 138.513\n",
      "[19]\tvalid_0's tweedie: 138.446\n",
      "[20]\tvalid_0's tweedie: 138.393\n",
      "[21]\tvalid_0's tweedie: 138.348\n",
      "[22]\tvalid_0's tweedie: 138.311\n",
      "[23]\tvalid_0's tweedie: 138.281\n",
      "[24]\tvalid_0's tweedie: 138.255\n",
      "[25]\tvalid_0's tweedie: 138.235\n",
      "[26]\tvalid_0's tweedie: 138.217\n",
      "[27]\tvalid_0's tweedie: 138.204\n",
      "[28]\tvalid_0's tweedie: 138.194\n",
      "[29]\tvalid_0's tweedie: 138.184\n",
      "[30]\tvalid_0's tweedie: 138.176\n",
      "[31]\tvalid_0's tweedie: 138.169\n",
      "[32]\tvalid_0's tweedie: 138.164\n",
      "[33]\tvalid_0's tweedie: 138.16\n",
      "[34]\tvalid_0's tweedie: 138.156\n",
      "[35]\tvalid_0's tweedie: 138.153\n",
      "[36]\tvalid_0's tweedie: 138.15\n",
      "[37]\tvalid_0's tweedie: 138.148\n",
      "[38]\tvalid_0's tweedie: 138.147\n",
      "[39]\tvalid_0's tweedie: 138.145\n",
      "[40]\tvalid_0's tweedie: 138.144\n",
      "[41]\tvalid_0's tweedie: 138.142\n",
      "[42]\tvalid_0's tweedie: 138.142\n",
      "[43]\tvalid_0's tweedie: 138.141\n",
      "[44]\tvalid_0's tweedie: 138.14\n",
      "[45]\tvalid_0's tweedie: 138.139\n",
      "[46]\tvalid_0's tweedie: 138.138\n",
      "[47]\tvalid_0's tweedie: 138.137\n",
      "[48]\tvalid_0's tweedie: 138.136\n",
      "[49]\tvalid_0's tweedie: 138.135\n",
      "[50]\tvalid_0's tweedie: 138.135\n",
      "[51]\tvalid_0's tweedie: 138.135\n",
      "[52]\tvalid_0's tweedie: 138.134\n",
      "[53]\tvalid_0's tweedie: 138.134\n",
      "[54]\tvalid_0's tweedie: 138.134\n",
      "[55]\tvalid_0's tweedie: 138.133\n",
      "[56]\tvalid_0's tweedie: 138.133\n",
      "[57]\tvalid_0's tweedie: 138.132\n",
      "[58]\tvalid_0's tweedie: 138.131\n",
      "[59]\tvalid_0's tweedie: 138.131\n",
      "[60]\tvalid_0's tweedie: 138.131\n",
      "[61]\tvalid_0's tweedie: 138.131\n",
      "[62]\tvalid_0's tweedie: 138.131\n",
      "[63]\tvalid_0's tweedie: 138.131\n",
      "[64]\tvalid_0's tweedie: 138.13\n",
      "[65]\tvalid_0's tweedie: 138.13\n",
      "[66]\tvalid_0's tweedie: 138.13\n",
      "[67]\tvalid_0's tweedie: 138.13\n",
      "[68]\tvalid_0's tweedie: 138.13\n",
      "[69]\tvalid_0's tweedie: 138.13\n",
      "[70]\tvalid_0's tweedie: 138.13\n",
      "[71]\tvalid_0's tweedie: 138.129\n",
      "[72]\tvalid_0's tweedie: 138.129\n",
      "[73]\tvalid_0's tweedie: 138.128\n",
      "[74]\tvalid_0's tweedie: 138.128\n",
      "[75]\tvalid_0's tweedie: 138.128\n",
      "[76]\tvalid_0's tweedie: 138.127\n",
      "[77]\tvalid_0's tweedie: 138.127\n",
      "[78]\tvalid_0's tweedie: 138.127\n",
      "[79]\tvalid_0's tweedie: 138.126\n",
      "[80]\tvalid_0's tweedie: 138.126\n",
      "[81]\tvalid_0's tweedie: 138.126\n",
      "[82]\tvalid_0's tweedie: 138.126\n",
      "[83]\tvalid_0's tweedie: 138.126\n",
      "[84]\tvalid_0's tweedie: 138.126\n",
      "[85]\tvalid_0's tweedie: 138.125\n",
      "[86]\tvalid_0's tweedie: 138.125\n",
      "[87]\tvalid_0's tweedie: 138.125\n",
      "[88]\tvalid_0's tweedie: 138.125\n",
      "[89]\tvalid_0's tweedie: 138.125\n",
      "[90]\tvalid_0's tweedie: 138.124\n",
      "[91]\tvalid_0's tweedie: 138.124\n",
      "[92]\tvalid_0's tweedie: 138.124\n",
      "[93]\tvalid_0's tweedie: 138.124\n",
      "[94]\tvalid_0's tweedie: 138.124\n",
      "[95]\tvalid_0's tweedie: 138.124\n",
      "[96]\tvalid_0's tweedie: 138.124\n",
      "[97]\tvalid_0's tweedie: 138.124\n",
      "[98]\tvalid_0's tweedie: 138.124\n",
      "[99]\tvalid_0's tweedie: 138.124\n",
      "[100]\tvalid_0's tweedie: 138.124\n",
      "[101]\tvalid_0's tweedie: 138.123\n",
      "[102]\tvalid_0's tweedie: 138.122\n",
      "[103]\tvalid_0's tweedie: 138.122\n",
      "[104]\tvalid_0's tweedie: 138.122\n",
      "[105]\tvalid_0's tweedie: 138.122\n",
      "[106]\tvalid_0's tweedie: 138.122\n",
      "[107]\tvalid_0's tweedie: 138.122\n",
      "[108]\tvalid_0's tweedie: 138.122\n",
      "[109]\tvalid_0's tweedie: 138.122\n",
      "[110]\tvalid_0's tweedie: 138.122\n",
      "[111]\tvalid_0's tweedie: 138.122\n",
      "[112]\tvalid_0's tweedie: 138.122\n",
      "[113]\tvalid_0's tweedie: 138.122\n",
      "[114]\tvalid_0's tweedie: 138.12\n",
      "[115]\tvalid_0's tweedie: 138.12\n",
      "[116]\tvalid_0's tweedie: 138.12\n",
      "[117]\tvalid_0's tweedie: 138.12\n",
      "[118]\tvalid_0's tweedie: 138.12\n",
      "[119]\tvalid_0's tweedie: 138.12\n",
      "[120]\tvalid_0's tweedie: 138.12\n",
      "[121]\tvalid_0's tweedie: 138.12\n",
      "[122]\tvalid_0's tweedie: 138.12\n",
      "[123]\tvalid_0's tweedie: 138.12\n",
      "[124]\tvalid_0's tweedie: 138.12\n",
      "[125]\tvalid_0's tweedie: 138.119\n",
      "[126]\tvalid_0's tweedie: 138.119\n",
      "[127]\tvalid_0's tweedie: 138.119\n",
      "[128]\tvalid_0's tweedie: 138.119\n",
      "[129]\tvalid_0's tweedie: 138.12\n",
      "[130]\tvalid_0's tweedie: 138.12\n",
      "[131]\tvalid_0's tweedie: 138.12\n",
      "[132]\tvalid_0's tweedie: 138.12\n",
      "[133]\tvalid_0's tweedie: 138.12\n",
      "[134]\tvalid_0's tweedie: 138.119\n",
      "[135]\tvalid_0's tweedie: 138.119\n",
      "[136]\tvalid_0's tweedie: 138.119\n",
      "[137]\tvalid_0's tweedie: 138.119\n",
      "[138]\tvalid_0's tweedie: 138.12\n",
      "[139]\tvalid_0's tweedie: 138.12\n",
      "[140]\tvalid_0's tweedie: 138.12\n",
      "[141]\tvalid_0's tweedie: 138.12\n",
      "[142]\tvalid_0's tweedie: 138.12\n",
      "[143]\tvalid_0's tweedie: 138.12\n",
      "[144]\tvalid_0's tweedie: 138.12\n",
      "[145]\tvalid_0's tweedie: 138.12\n",
      "[146]\tvalid_0's tweedie: 138.12\n",
      "[147]\tvalid_0's tweedie: 138.12\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's tweedie: 138.119\n",
      "Training model for level 8 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5517\n",
      "[LightGBM] [Info] Number of data points in the train set: 56040, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041130\n",
      "[1]\tvalid_0's tweedie: 148.759\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.872\n",
      "[3]\tvalid_0's tweedie: 145.344\n",
      "[4]\tvalid_0's tweedie: 144.075\n",
      "[5]\tvalid_0's tweedie: 143.003\n",
      "[6]\tvalid_0's tweedie: 142.142\n",
      "[7]\tvalid_0's tweedie: 141.43\n",
      "[8]\tvalid_0's tweedie: 140.839\n",
      "[9]\tvalid_0's tweedie: 140.347\n",
      "[10]\tvalid_0's tweedie: 139.952\n",
      "[11]\tvalid_0's tweedie: 139.631\n",
      "[12]\tvalid_0's tweedie: 139.362\n",
      "[13]\tvalid_0's tweedie: 139.144\n",
      "[14]\tvalid_0's tweedie: 138.971\n",
      "[15]\tvalid_0's tweedie: 138.822\n",
      "[16]\tvalid_0's tweedie: 138.701\n",
      "[17]\tvalid_0's tweedie: 138.603\n",
      "[18]\tvalid_0's tweedie: 138.52\n",
      "[19]\tvalid_0's tweedie: 138.455\n",
      "[20]\tvalid_0's tweedie: 138.399\n",
      "[21]\tvalid_0's tweedie: 138.357\n",
      "[22]\tvalid_0's tweedie: 138.32\n",
      "[23]\tvalid_0's tweedie: 138.29\n",
      "[24]\tvalid_0's tweedie: 138.265\n",
      "[25]\tvalid_0's tweedie: 138.245\n",
      "[26]\tvalid_0's tweedie: 138.226\n",
      "[27]\tvalid_0's tweedie: 138.212\n",
      "[28]\tvalid_0's tweedie: 138.202\n",
      "[29]\tvalid_0's tweedie: 138.192\n",
      "[30]\tvalid_0's tweedie: 138.184\n",
      "[31]\tvalid_0's tweedie: 138.177\n",
      "[32]\tvalid_0's tweedie: 138.171\n",
      "[33]\tvalid_0's tweedie: 138.166\n",
      "[34]\tvalid_0's tweedie: 138.163\n",
      "[35]\tvalid_0's tweedie: 138.158\n",
      "[36]\tvalid_0's tweedie: 138.156\n",
      "[37]\tvalid_0's tweedie: 138.152\n",
      "[38]\tvalid_0's tweedie: 138.151\n",
      "[39]\tvalid_0's tweedie: 138.148\n",
      "[40]\tvalid_0's tweedie: 138.148\n",
      "[41]\tvalid_0's tweedie: 138.146\n",
      "[42]\tvalid_0's tweedie: 138.145\n",
      "[43]\tvalid_0's tweedie: 138.145\n",
      "[44]\tvalid_0's tweedie: 138.144\n",
      "[45]\tvalid_0's tweedie: 138.143\n",
      "[46]\tvalid_0's tweedie: 138.142\n",
      "[47]\tvalid_0's tweedie: 138.141\n",
      "[48]\tvalid_0's tweedie: 138.141\n",
      "[49]\tvalid_0's tweedie: 138.141\n",
      "[50]\tvalid_0's tweedie: 138.141\n",
      "[51]\tvalid_0's tweedie: 138.14\n",
      "[52]\tvalid_0's tweedie: 138.14\n",
      "[53]\tvalid_0's tweedie: 138.14\n",
      "[54]\tvalid_0's tweedie: 138.139\n",
      "[55]\tvalid_0's tweedie: 138.139\n",
      "[56]\tvalid_0's tweedie: 138.138\n",
      "[57]\tvalid_0's tweedie: 138.138\n",
      "[58]\tvalid_0's tweedie: 138.138\n",
      "[59]\tvalid_0's tweedie: 138.137\n",
      "[60]\tvalid_0's tweedie: 138.137\n",
      "[61]\tvalid_0's tweedie: 138.137\n",
      "[62]\tvalid_0's tweedie: 138.137\n",
      "[63]\tvalid_0's tweedie: 138.137\n",
      "[64]\tvalid_0's tweedie: 138.137\n",
      "[65]\tvalid_0's tweedie: 138.137\n",
      "[66]\tvalid_0's tweedie: 138.137\n",
      "[67]\tvalid_0's tweedie: 138.136\n",
      "[68]\tvalid_0's tweedie: 138.136\n",
      "[69]\tvalid_0's tweedie: 138.136\n",
      "[70]\tvalid_0's tweedie: 138.136\n",
      "[71]\tvalid_0's tweedie: 138.136\n",
      "[72]\tvalid_0's tweedie: 138.136\n",
      "[73]\tvalid_0's tweedie: 138.136\n",
      "[74]\tvalid_0's tweedie: 138.136\n",
      "[75]\tvalid_0's tweedie: 138.136\n",
      "[76]\tvalid_0's tweedie: 138.135\n",
      "[77]\tvalid_0's tweedie: 138.135\n",
      "[78]\tvalid_0's tweedie: 138.135\n",
      "[79]\tvalid_0's tweedie: 138.135\n",
      "[80]\tvalid_0's tweedie: 138.133\n",
      "[81]\tvalid_0's tweedie: 138.133\n",
      "[82]\tvalid_0's tweedie: 138.133\n",
      "[83]\tvalid_0's tweedie: 138.132\n",
      "[84]\tvalid_0's tweedie: 138.133\n",
      "[85]\tvalid_0's tweedie: 138.13\n",
      "[86]\tvalid_0's tweedie: 138.131\n",
      "[87]\tvalid_0's tweedie: 138.131\n",
      "[88]\tvalid_0's tweedie: 138.131\n",
      "[89]\tvalid_0's tweedie: 138.131\n",
      "[90]\tvalid_0's tweedie: 138.13\n",
      "[91]\tvalid_0's tweedie: 138.13\n",
      "[92]\tvalid_0's tweedie: 138.13\n",
      "[93]\tvalid_0's tweedie: 138.13\n",
      "[94]\tvalid_0's tweedie: 138.13\n",
      "[95]\tvalid_0's tweedie: 138.13\n",
      "[96]\tvalid_0's tweedie: 138.13\n",
      "[97]\tvalid_0's tweedie: 138.128\n",
      "[98]\tvalid_0's tweedie: 138.128\n",
      "[99]\tvalid_0's tweedie: 138.128\n",
      "[100]\tvalid_0's tweedie: 138.128\n",
      "[101]\tvalid_0's tweedie: 138.128\n",
      "[102]\tvalid_0's tweedie: 138.128\n",
      "[103]\tvalid_0's tweedie: 138.127\n",
      "[104]\tvalid_0's tweedie: 138.127\n",
      "[105]\tvalid_0's tweedie: 138.127\n",
      "[106]\tvalid_0's tweedie: 138.127\n",
      "[107]\tvalid_0's tweedie: 138.127\n",
      "[108]\tvalid_0's tweedie: 138.127\n",
      "[109]\tvalid_0's tweedie: 138.127\n",
      "[110]\tvalid_0's tweedie: 138.127\n",
      "[111]\tvalid_0's tweedie: 138.126\n",
      "[112]\tvalid_0's tweedie: 138.126\n",
      "[113]\tvalid_0's tweedie: 138.126\n",
      "[114]\tvalid_0's tweedie: 138.127\n",
      "[115]\tvalid_0's tweedie: 138.126\n",
      "[116]\tvalid_0's tweedie: 138.126\n",
      "[117]\tvalid_0's tweedie: 138.126\n",
      "[118]\tvalid_0's tweedie: 138.125\n",
      "[119]\tvalid_0's tweedie: 138.125\n",
      "[120]\tvalid_0's tweedie: 138.126\n",
      "[121]\tvalid_0's tweedie: 138.125\n",
      "[122]\tvalid_0's tweedie: 138.126\n",
      "[123]\tvalid_0's tweedie: 138.125\n",
      "[124]\tvalid_0's tweedie: 138.125\n",
      "[125]\tvalid_0's tweedie: 138.125\n",
      "[126]\tvalid_0's tweedie: 138.125\n",
      "[127]\tvalid_0's tweedie: 138.125\n",
      "[128]\tvalid_0's tweedie: 138.125\n",
      "[129]\tvalid_0's tweedie: 138.125\n",
      "[130]\tvalid_0's tweedie: 138.125\n",
      "[131]\tvalid_0's tweedie: 138.124\n",
      "[132]\tvalid_0's tweedie: 138.125\n",
      "[133]\tvalid_0's tweedie: 138.125\n",
      "[134]\tvalid_0's tweedie: 138.125\n",
      "[135]\tvalid_0's tweedie: 138.124\n",
      "[136]\tvalid_0's tweedie: 138.124\n",
      "[137]\tvalid_0's tweedie: 138.124\n",
      "[138]\tvalid_0's tweedie: 138.124\n",
      "[139]\tvalid_0's tweedie: 138.124\n",
      "[140]\tvalid_0's tweedie: 138.124\n",
      "[141]\tvalid_0's tweedie: 138.124\n",
      "[142]\tvalid_0's tweedie: 138.125\n",
      "[143]\tvalid_0's tweedie: 138.125\n",
      "[144]\tvalid_0's tweedie: 138.125\n",
      "[145]\tvalid_0's tweedie: 138.125\n",
      "[146]\tvalid_0's tweedie: 138.125\n",
      "[147]\tvalid_0's tweedie: 138.125\n",
      "[148]\tvalid_0's tweedie: 138.125\n",
      "[149]\tvalid_0's tweedie: 138.125\n",
      "[150]\tvalid_0's tweedie: 138.125\n",
      "[151]\tvalid_0's tweedie: 138.125\n",
      "[152]\tvalid_0's tweedie: 138.125\n",
      "[153]\tvalid_0's tweedie: 138.125\n",
      "[154]\tvalid_0's tweedie: 138.125\n",
      "[155]\tvalid_0's tweedie: 138.124\n",
      "[156]\tvalid_0's tweedie: 138.124\n",
      "[157]\tvalid_0's tweedie: 138.124\n",
      "[158]\tvalid_0's tweedie: 138.124\n",
      "[159]\tvalid_0's tweedie: 138.124\n",
      "[160]\tvalid_0's tweedie: 138.124\n",
      "[161]\tvalid_0's tweedie: 138.124\n",
      "[162]\tvalid_0's tweedie: 138.124\n",
      "[163]\tvalid_0's tweedie: 138.124\n",
      "[164]\tvalid_0's tweedie: 138.124\n",
      "[165]\tvalid_0's tweedie: 138.124\n",
      "[166]\tvalid_0's tweedie: 138.124\n",
      "[167]\tvalid_0's tweedie: 138.125\n",
      "[168]\tvalid_0's tweedie: 138.125\n",
      "[169]\tvalid_0's tweedie: 138.124\n",
      "[170]\tvalid_0's tweedie: 138.124\n",
      "[171]\tvalid_0's tweedie: 138.124\n",
      "[172]\tvalid_0's tweedie: 138.124\n",
      "[173]\tvalid_0's tweedie: 138.124\n",
      "[174]\tvalid_0's tweedie: 138.124\n",
      "[175]\tvalid_0's tweedie: 138.124\n",
      "[176]\tvalid_0's tweedie: 138.124\n",
      "[177]\tvalid_0's tweedie: 138.124\n",
      "[178]\tvalid_0's tweedie: 138.124\n",
      "[179]\tvalid_0's tweedie: 138.124\n",
      "[180]\tvalid_0's tweedie: 138.124\n",
      "[181]\tvalid_0's tweedie: 138.124\n",
      "[182]\tvalid_0's tweedie: 138.124\n",
      "[183]\tvalid_0's tweedie: 138.124\n",
      "[184]\tvalid_0's tweedie: 138.124\n",
      "[185]\tvalid_0's tweedie: 138.124\n",
      "[186]\tvalid_0's tweedie: 138.124\n",
      "[187]\tvalid_0's tweedie: 138.124\n",
      "[188]\tvalid_0's tweedie: 138.124\n",
      "[189]\tvalid_0's tweedie: 138.124\n",
      "[190]\tvalid_0's tweedie: 138.124\n",
      "[191]\tvalid_0's tweedie: 138.124\n",
      "[192]\tvalid_0's tweedie: 138.124\n",
      "[193]\tvalid_0's tweedie: 138.124\n",
      "[194]\tvalid_0's tweedie: 138.124\n",
      "[195]\tvalid_0's tweedie: 138.124\n",
      "[196]\tvalid_0's tweedie: 138.123\n",
      "[197]\tvalid_0's tweedie: 138.123\n",
      "[198]\tvalid_0's tweedie: 138.123\n",
      "[199]\tvalid_0's tweedie: 138.123\n",
      "[200]\tvalid_0's tweedie: 138.123\n",
      "[201]\tvalid_0's tweedie: 138.123\n",
      "[202]\tvalid_0's tweedie: 138.123\n",
      "[203]\tvalid_0's tweedie: 138.123\n",
      "[204]\tvalid_0's tweedie: 138.123\n",
      "[205]\tvalid_0's tweedie: 138.123\n",
      "[206]\tvalid_0's tweedie: 138.123\n",
      "[207]\tvalid_0's tweedie: 138.123\n",
      "[208]\tvalid_0's tweedie: 138.123\n",
      "[209]\tvalid_0's tweedie: 138.123\n",
      "[210]\tvalid_0's tweedie: 138.123\n",
      "[211]\tvalid_0's tweedie: 138.123\n",
      "[212]\tvalid_0's tweedie: 138.123\n",
      "[213]\tvalid_0's tweedie: 138.123\n",
      "[214]\tvalid_0's tweedie: 138.123\n",
      "[215]\tvalid_0's tweedie: 138.123\n",
      "[216]\tvalid_0's tweedie: 138.123\n",
      "[217]\tvalid_0's tweedie: 138.123\n",
      "[218]\tvalid_0's tweedie: 138.123\n",
      "[219]\tvalid_0's tweedie: 138.123\n",
      "[220]\tvalid_0's tweedie: 138.123\n",
      "[221]\tvalid_0's tweedie: 138.123\n",
      "[222]\tvalid_0's tweedie: 138.123\n",
      "[223]\tvalid_0's tweedie: 138.123\n",
      "[224]\tvalid_0's tweedie: 138.123\n",
      "[225]\tvalid_0's tweedie: 138.123\n",
      "[226]\tvalid_0's tweedie: 138.123\n",
      "[227]\tvalid_0's tweedie: 138.123\n",
      "[228]\tvalid_0's tweedie: 138.123\n",
      "[229]\tvalid_0's tweedie: 138.123\n",
      "[230]\tvalid_0's tweedie: 138.123\n",
      "[231]\tvalid_0's tweedie: 138.123\n",
      "[232]\tvalid_0's tweedie: 138.123\n",
      "[233]\tvalid_0's tweedie: 138.123\n",
      "[234]\tvalid_0's tweedie: 138.123\n",
      "[235]\tvalid_0's tweedie: 138.123\n",
      "[236]\tvalid_0's tweedie: 138.123\n",
      "[237]\tvalid_0's tweedie: 138.123\n",
      "[238]\tvalid_0's tweedie: 138.123\n",
      "[239]\tvalid_0's tweedie: 138.123\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's tweedie: 138.123\n",
      "Training model for level 8 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5516\n",
      "[LightGBM] [Info] Number of data points in the train set: 56010, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041289\n",
      "[1]\tvalid_0's tweedie: 148.758\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.87\n",
      "[3]\tvalid_0's tweedie: 145.343\n",
      "[4]\tvalid_0's tweedie: 144.072\n",
      "[5]\tvalid_0's tweedie: 143.006\n",
      "[6]\tvalid_0's tweedie: 142.138\n",
      "[7]\tvalid_0's tweedie: 141.425\n",
      "[8]\tvalid_0's tweedie: 140.851\n",
      "[9]\tvalid_0's tweedie: 140.361\n",
      "[10]\tvalid_0's tweedie: 139.96\n",
      "[11]\tvalid_0's tweedie: 139.645\n",
      "[12]\tvalid_0's tweedie: 139.374\n",
      "[13]\tvalid_0's tweedie: 139.153\n",
      "[14]\tvalid_0's tweedie: 138.973\n",
      "[15]\tvalid_0's tweedie: 138.828\n",
      "[16]\tvalid_0's tweedie: 138.71\n",
      "[17]\tvalid_0's tweedie: 138.611\n",
      "[18]\tvalid_0's tweedie: 138.531\n",
      "[19]\tvalid_0's tweedie: 138.463\n",
      "[20]\tvalid_0's tweedie: 138.407\n",
      "[21]\tvalid_0's tweedie: 138.362\n",
      "[22]\tvalid_0's tweedie: 138.324\n",
      "[23]\tvalid_0's tweedie: 138.292\n",
      "[24]\tvalid_0's tweedie: 138.267\n",
      "[25]\tvalid_0's tweedie: 138.246\n",
      "[26]\tvalid_0's tweedie: 138.229\n",
      "[27]\tvalid_0's tweedie: 138.214\n",
      "[28]\tvalid_0's tweedie: 138.201\n",
      "[29]\tvalid_0's tweedie: 138.193\n",
      "[30]\tvalid_0's tweedie: 138.185\n",
      "[31]\tvalid_0's tweedie: 138.178\n",
      "[32]\tvalid_0's tweedie: 138.172\n",
      "[33]\tvalid_0's tweedie: 138.168\n",
      "[34]\tvalid_0's tweedie: 138.165\n",
      "[35]\tvalid_0's tweedie: 138.161\n",
      "[36]\tvalid_0's tweedie: 138.159\n",
      "[37]\tvalid_0's tweedie: 138.157\n",
      "[38]\tvalid_0's tweedie: 138.155\n",
      "[39]\tvalid_0's tweedie: 138.154\n",
      "[40]\tvalid_0's tweedie: 138.153\n",
      "[41]\tvalid_0's tweedie: 138.151\n",
      "[42]\tvalid_0's tweedie: 138.151\n",
      "[43]\tvalid_0's tweedie: 138.15\n",
      "[44]\tvalid_0's tweedie: 138.15\n",
      "[45]\tvalid_0's tweedie: 138.148\n",
      "[46]\tvalid_0's tweedie: 138.147\n",
      "[47]\tvalid_0's tweedie: 138.146\n",
      "[48]\tvalid_0's tweedie: 138.146\n",
      "[49]\tvalid_0's tweedie: 138.145\n",
      "[50]\tvalid_0's tweedie: 138.144\n",
      "[51]\tvalid_0's tweedie: 138.143\n",
      "[52]\tvalid_0's tweedie: 138.142\n",
      "[53]\tvalid_0's tweedie: 138.143\n",
      "[54]\tvalid_0's tweedie: 138.143\n",
      "[55]\tvalid_0's tweedie: 138.142\n",
      "[56]\tvalid_0's tweedie: 138.142\n",
      "[57]\tvalid_0's tweedie: 138.141\n",
      "[58]\tvalid_0's tweedie: 138.141\n",
      "[59]\tvalid_0's tweedie: 138.14\n",
      "[60]\tvalid_0's tweedie: 138.14\n",
      "[61]\tvalid_0's tweedie: 138.141\n",
      "[62]\tvalid_0's tweedie: 138.141\n",
      "[63]\tvalid_0's tweedie: 138.14\n",
      "[64]\tvalid_0's tweedie: 138.14\n",
      "[65]\tvalid_0's tweedie: 138.14\n",
      "[66]\tvalid_0's tweedie: 138.14\n",
      "[67]\tvalid_0's tweedie: 138.14\n",
      "[68]\tvalid_0's tweedie: 138.141\n",
      "[69]\tvalid_0's tweedie: 138.141\n",
      "[70]\tvalid_0's tweedie: 138.141\n",
      "[71]\tvalid_0's tweedie: 138.141\n",
      "[72]\tvalid_0's tweedie: 138.141\n",
      "[73]\tvalid_0's tweedie: 138.141\n",
      "[74]\tvalid_0's tweedie: 138.141\n",
      "[75]\tvalid_0's tweedie: 138.141\n",
      "[76]\tvalid_0's tweedie: 138.141\n",
      "[77]\tvalid_0's tweedie: 138.141\n",
      "[78]\tvalid_0's tweedie: 138.141\n",
      "[79]\tvalid_0's tweedie: 138.141\n",
      "[80]\tvalid_0's tweedie: 138.141\n",
      "[81]\tvalid_0's tweedie: 138.14\n",
      "[82]\tvalid_0's tweedie: 138.14\n",
      "[83]\tvalid_0's tweedie: 138.138\n",
      "[84]\tvalid_0's tweedie: 138.138\n",
      "[85]\tvalid_0's tweedie: 138.135\n",
      "[86]\tvalid_0's tweedie: 138.135\n",
      "[87]\tvalid_0's tweedie: 138.135\n",
      "[88]\tvalid_0's tweedie: 138.135\n",
      "[89]\tvalid_0's tweedie: 138.133\n",
      "[90]\tvalid_0's tweedie: 138.133\n",
      "[91]\tvalid_0's tweedie: 138.133\n",
      "[92]\tvalid_0's tweedie: 138.133\n",
      "[93]\tvalid_0's tweedie: 138.133\n",
      "[94]\tvalid_0's tweedie: 138.133\n",
      "[95]\tvalid_0's tweedie: 138.133\n",
      "[96]\tvalid_0's tweedie: 138.133\n",
      "[97]\tvalid_0's tweedie: 138.133\n",
      "[98]\tvalid_0's tweedie: 138.133\n",
      "[99]\tvalid_0's tweedie: 138.133\n",
      "[100]\tvalid_0's tweedie: 138.133\n",
      "[101]\tvalid_0's tweedie: 138.133\n",
      "[102]\tvalid_0's tweedie: 138.133\n",
      "[103]\tvalid_0's tweedie: 138.133\n",
      "[104]\tvalid_0's tweedie: 138.133\n",
      "[105]\tvalid_0's tweedie: 138.133\n",
      "[106]\tvalid_0's tweedie: 138.133\n",
      "[107]\tvalid_0's tweedie: 138.132\n",
      "[108]\tvalid_0's tweedie: 138.132\n",
      "[109]\tvalid_0's tweedie: 138.132\n",
      "[110]\tvalid_0's tweedie: 138.132\n",
      "[111]\tvalid_0's tweedie: 138.132\n",
      "[112]\tvalid_0's tweedie: 138.131\n",
      "[113]\tvalid_0's tweedie: 138.131\n",
      "[114]\tvalid_0's tweedie: 138.131\n",
      "[115]\tvalid_0's tweedie: 138.131\n",
      "[116]\tvalid_0's tweedie: 138.13\n",
      "[117]\tvalid_0's tweedie: 138.13\n",
      "[118]\tvalid_0's tweedie: 138.13\n",
      "[119]\tvalid_0's tweedie: 138.13\n",
      "[120]\tvalid_0's tweedie: 138.13\n",
      "[121]\tvalid_0's tweedie: 138.13\n",
      "[122]\tvalid_0's tweedie: 138.13\n",
      "[123]\tvalid_0's tweedie: 138.13\n",
      "[124]\tvalid_0's tweedie: 138.13\n",
      "[125]\tvalid_0's tweedie: 138.13\n",
      "[126]\tvalid_0's tweedie: 138.13\n",
      "[127]\tvalid_0's tweedie: 138.131\n",
      "[128]\tvalid_0's tweedie: 138.131\n",
      "[129]\tvalid_0's tweedie: 138.131\n",
      "[130]\tvalid_0's tweedie: 138.131\n",
      "[131]\tvalid_0's tweedie: 138.131\n",
      "[132]\tvalid_0's tweedie: 138.131\n",
      "[133]\tvalid_0's tweedie: 138.131\n",
      "[134]\tvalid_0's tweedie: 138.131\n",
      "[135]\tvalid_0's tweedie: 138.13\n",
      "[136]\tvalid_0's tweedie: 138.13\n",
      "[137]\tvalid_0's tweedie: 138.13\n",
      "[138]\tvalid_0's tweedie: 138.13\n",
      "[139]\tvalid_0's tweedie: 138.13\n",
      "[140]\tvalid_0's tweedie: 138.13\n",
      "[141]\tvalid_0's tweedie: 138.13\n",
      "[142]\tvalid_0's tweedie: 138.13\n",
      "[143]\tvalid_0's tweedie: 138.13\n",
      "[144]\tvalid_0's tweedie: 138.13\n",
      "[145]\tvalid_0's tweedie: 138.13\n",
      "[146]\tvalid_0's tweedie: 138.13\n",
      "[147]\tvalid_0's tweedie: 138.13\n",
      "[148]\tvalid_0's tweedie: 138.13\n",
      "[149]\tvalid_0's tweedie: 138.13\n",
      "[150]\tvalid_0's tweedie: 138.13\n",
      "[151]\tvalid_0's tweedie: 138.13\n",
      "[152]\tvalid_0's tweedie: 138.13\n",
      "[153]\tvalid_0's tweedie: 138.13\n",
      "[154]\tvalid_0's tweedie: 138.13\n",
      "[155]\tvalid_0's tweedie: 138.13\n",
      "[156]\tvalid_0's tweedie: 138.13\n",
      "[157]\tvalid_0's tweedie: 138.13\n",
      "[158]\tvalid_0's tweedie: 138.13\n",
      "[159]\tvalid_0's tweedie: 138.13\n",
      "[160]\tvalid_0's tweedie: 138.13\n",
      "[161]\tvalid_0's tweedie: 138.13\n",
      "[162]\tvalid_0's tweedie: 138.13\n",
      "[163]\tvalid_0's tweedie: 138.13\n",
      "[164]\tvalid_0's tweedie: 138.13\n",
      "[165]\tvalid_0's tweedie: 138.13\n",
      "[166]\tvalid_0's tweedie: 138.13\n",
      "[167]\tvalid_0's tweedie: 138.129\n",
      "[168]\tvalid_0's tweedie: 138.129\n",
      "[169]\tvalid_0's tweedie: 138.129\n",
      "[170]\tvalid_0's tweedie: 138.129\n",
      "[171]\tvalid_0's tweedie: 138.129\n",
      "[172]\tvalid_0's tweedie: 138.129\n",
      "[173]\tvalid_0's tweedie: 138.129\n",
      "[174]\tvalid_0's tweedie: 138.129\n",
      "[175]\tvalid_0's tweedie: 138.129\n",
      "[176]\tvalid_0's tweedie: 138.129\n",
      "[177]\tvalid_0's tweedie: 138.129\n",
      "[178]\tvalid_0's tweedie: 138.129\n",
      "[179]\tvalid_0's tweedie: 138.129\n",
      "[180]\tvalid_0's tweedie: 138.129\n",
      "[181]\tvalid_0's tweedie: 138.129\n",
      "[182]\tvalid_0's tweedie: 138.129\n",
      "[183]\tvalid_0's tweedie: 138.13\n",
      "[184]\tvalid_0's tweedie: 138.129\n",
      "[185]\tvalid_0's tweedie: 138.129\n",
      "[186]\tvalid_0's tweedie: 138.129\n",
      "[187]\tvalid_0's tweedie: 138.129\n",
      "[188]\tvalid_0's tweedie: 138.129\n",
      "[189]\tvalid_0's tweedie: 138.129\n",
      "[190]\tvalid_0's tweedie: 138.129\n",
      "[191]\tvalid_0's tweedie: 138.129\n",
      "[192]\tvalid_0's tweedie: 138.129\n",
      "[193]\tvalid_0's tweedie: 138.129\n",
      "[194]\tvalid_0's tweedie: 138.129\n",
      "[195]\tvalid_0's tweedie: 138.13\n",
      "[196]\tvalid_0's tweedie: 138.13\n",
      "[197]\tvalid_0's tweedie: 138.129\n",
      "[198]\tvalid_0's tweedie: 138.13\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's tweedie: 138.129\n",
      "Training model for level 8 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5515\n",
      "[LightGBM] [Info] Number of data points in the train set: 55980, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041490\n",
      "[1]\tvalid_0's tweedie: 148.757\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.868\n",
      "[3]\tvalid_0's tweedie: 145.337\n",
      "[4]\tvalid_0's tweedie: 144.071\n",
      "[5]\tvalid_0's tweedie: 142.996\n",
      "[6]\tvalid_0's tweedie: 142.133\n",
      "[7]\tvalid_0's tweedie: 141.41\n",
      "[8]\tvalid_0's tweedie: 140.824\n",
      "[9]\tvalid_0's tweedie: 140.339\n",
      "[10]\tvalid_0's tweedie: 139.94\n",
      "[11]\tvalid_0's tweedie: 139.618\n",
      "[12]\tvalid_0's tweedie: 139.35\n",
      "[13]\tvalid_0's tweedie: 139.139\n",
      "[14]\tvalid_0's tweedie: 138.963\n",
      "[15]\tvalid_0's tweedie: 138.816\n",
      "[16]\tvalid_0's tweedie: 138.699\n",
      "[17]\tvalid_0's tweedie: 138.601\n",
      "[18]\tvalid_0's tweedie: 138.521\n",
      "[19]\tvalid_0's tweedie: 138.454\n",
      "[20]\tvalid_0's tweedie: 138.397\n",
      "[21]\tvalid_0's tweedie: 138.351\n",
      "[22]\tvalid_0's tweedie: 138.314\n",
      "[23]\tvalid_0's tweedie: 138.284\n",
      "[24]\tvalid_0's tweedie: 138.258\n",
      "[25]\tvalid_0's tweedie: 138.238\n",
      "[26]\tvalid_0's tweedie: 138.221\n",
      "[27]\tvalid_0's tweedie: 138.209\n",
      "[28]\tvalid_0's tweedie: 138.198\n",
      "[29]\tvalid_0's tweedie: 138.188\n",
      "[30]\tvalid_0's tweedie: 138.18\n",
      "[31]\tvalid_0's tweedie: 138.174\n",
      "[32]\tvalid_0's tweedie: 138.168\n",
      "[33]\tvalid_0's tweedie: 138.164\n",
      "[34]\tvalid_0's tweedie: 138.161\n",
      "[35]\tvalid_0's tweedie: 138.158\n",
      "[36]\tvalid_0's tweedie: 138.155\n",
      "[37]\tvalid_0's tweedie: 138.153\n",
      "[38]\tvalid_0's tweedie: 138.152\n",
      "[39]\tvalid_0's tweedie: 138.149\n",
      "[40]\tvalid_0's tweedie: 138.148\n",
      "[41]\tvalid_0's tweedie: 138.146\n",
      "[42]\tvalid_0's tweedie: 138.145\n",
      "[43]\tvalid_0's tweedie: 138.144\n",
      "[44]\tvalid_0's tweedie: 138.143\n",
      "[45]\tvalid_0's tweedie: 138.142\n",
      "[46]\tvalid_0's tweedie: 138.141\n",
      "[47]\tvalid_0's tweedie: 138.141\n",
      "[48]\tvalid_0's tweedie: 138.142\n",
      "[49]\tvalid_0's tweedie: 138.141\n",
      "[50]\tvalid_0's tweedie: 138.14\n",
      "[51]\tvalid_0's tweedie: 138.139\n",
      "[52]\tvalid_0's tweedie: 138.139\n",
      "[53]\tvalid_0's tweedie: 138.139\n",
      "[54]\tvalid_0's tweedie: 138.14\n",
      "[55]\tvalid_0's tweedie: 138.137\n",
      "[56]\tvalid_0's tweedie: 138.137\n",
      "[57]\tvalid_0's tweedie: 138.137\n",
      "[58]\tvalid_0's tweedie: 138.137\n",
      "[59]\tvalid_0's tweedie: 138.134\n",
      "[60]\tvalid_0's tweedie: 138.135\n",
      "[61]\tvalid_0's tweedie: 138.135\n",
      "[62]\tvalid_0's tweedie: 138.135\n",
      "[63]\tvalid_0's tweedie: 138.134\n",
      "[64]\tvalid_0's tweedie: 138.133\n",
      "[65]\tvalid_0's tweedie: 138.133\n",
      "[66]\tvalid_0's tweedie: 138.133\n",
      "[67]\tvalid_0's tweedie: 138.133\n",
      "[68]\tvalid_0's tweedie: 138.133\n",
      "[69]\tvalid_0's tweedie: 138.133\n",
      "[70]\tvalid_0's tweedie: 138.133\n",
      "[71]\tvalid_0's tweedie: 138.133\n",
      "[72]\tvalid_0's tweedie: 138.133\n",
      "[73]\tvalid_0's tweedie: 138.133\n",
      "[74]\tvalid_0's tweedie: 138.133\n",
      "[75]\tvalid_0's tweedie: 138.132\n",
      "[76]\tvalid_0's tweedie: 138.132\n",
      "[77]\tvalid_0's tweedie: 138.132\n",
      "[78]\tvalid_0's tweedie: 138.132\n",
      "[79]\tvalid_0's tweedie: 138.132\n",
      "[80]\tvalid_0's tweedie: 138.132\n",
      "[81]\tvalid_0's tweedie: 138.132\n",
      "[82]\tvalid_0's tweedie: 138.13\n",
      "[83]\tvalid_0's tweedie: 138.13\n",
      "[84]\tvalid_0's tweedie: 138.13\n",
      "[85]\tvalid_0's tweedie: 138.13\n",
      "[86]\tvalid_0's tweedie: 138.13\n",
      "[87]\tvalid_0's tweedie: 138.13\n",
      "[88]\tvalid_0's tweedie: 138.128\n",
      "[89]\tvalid_0's tweedie: 138.128\n",
      "[90]\tvalid_0's tweedie: 138.127\n",
      "[91]\tvalid_0's tweedie: 138.127\n",
      "[92]\tvalid_0's tweedie: 138.127\n",
      "[93]\tvalid_0's tweedie: 138.127\n",
      "[94]\tvalid_0's tweedie: 138.127\n",
      "[95]\tvalid_0's tweedie: 138.127\n",
      "[96]\tvalid_0's tweedie: 138.127\n",
      "[97]\tvalid_0's tweedie: 138.127\n",
      "[98]\tvalid_0's tweedie: 138.127\n",
      "[99]\tvalid_0's tweedie: 138.128\n",
      "[100]\tvalid_0's tweedie: 138.127\n",
      "[101]\tvalid_0's tweedie: 138.127\n",
      "[102]\tvalid_0's tweedie: 138.125\n",
      "[103]\tvalid_0's tweedie: 138.125\n",
      "[104]\tvalid_0's tweedie: 138.125\n",
      "[105]\tvalid_0's tweedie: 138.125\n",
      "[106]\tvalid_0's tweedie: 138.125\n",
      "[107]\tvalid_0's tweedie: 138.125\n",
      "[108]\tvalid_0's tweedie: 138.125\n",
      "[109]\tvalid_0's tweedie: 138.125\n",
      "[110]\tvalid_0's tweedie: 138.125\n",
      "[111]\tvalid_0's tweedie: 138.125\n",
      "[112]\tvalid_0's tweedie: 138.125\n",
      "[113]\tvalid_0's tweedie: 138.125\n",
      "[114]\tvalid_0's tweedie: 138.125\n",
      "[115]\tvalid_0's tweedie: 138.125\n",
      "[116]\tvalid_0's tweedie: 138.125\n",
      "[117]\tvalid_0's tweedie: 138.125\n",
      "[118]\tvalid_0's tweedie: 138.125\n",
      "[119]\tvalid_0's tweedie: 138.125\n",
      "[120]\tvalid_0's tweedie: 138.125\n",
      "[121]\tvalid_0's tweedie: 138.125\n",
      "[122]\tvalid_0's tweedie: 138.124\n",
      "[123]\tvalid_0's tweedie: 138.123\n",
      "[124]\tvalid_0's tweedie: 138.123\n",
      "[125]\tvalid_0's tweedie: 138.123\n",
      "[126]\tvalid_0's tweedie: 138.123\n",
      "[127]\tvalid_0's tweedie: 138.123\n",
      "[128]\tvalid_0's tweedie: 138.123\n",
      "[129]\tvalid_0's tweedie: 138.123\n",
      "[130]\tvalid_0's tweedie: 138.123\n",
      "[131]\tvalid_0's tweedie: 138.123\n",
      "[132]\tvalid_0's tweedie: 138.123\n",
      "[133]\tvalid_0's tweedie: 138.123\n",
      "[134]\tvalid_0's tweedie: 138.123\n",
      "[135]\tvalid_0's tweedie: 138.124\n",
      "[136]\tvalid_0's tweedie: 138.124\n",
      "[137]\tvalid_0's tweedie: 138.124\n",
      "[138]\tvalid_0's tweedie: 138.124\n",
      "[139]\tvalid_0's tweedie: 138.124\n",
      "[140]\tvalid_0's tweedie: 138.124\n",
      "[141]\tvalid_0's tweedie: 138.124\n",
      "[142]\tvalid_0's tweedie: 138.124\n",
      "[143]\tvalid_0's tweedie: 138.124\n",
      "[144]\tvalid_0's tweedie: 138.124\n",
      "[145]\tvalid_0's tweedie: 138.124\n",
      "[146]\tvalid_0's tweedie: 138.124\n",
      "[147]\tvalid_0's tweedie: 138.123\n",
      "[148]\tvalid_0's tweedie: 138.123\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's tweedie: 138.123\n",
      "Training model for level 8 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5514\n",
      "[LightGBM] [Info] Number of data points in the train set: 55950, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041708\n",
      "[1]\tvalid_0's tweedie: 148.757\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.867\n",
      "[3]\tvalid_0's tweedie: 145.338\n",
      "[4]\tvalid_0's tweedie: 144.072\n",
      "[5]\tvalid_0's tweedie: 143.003\n",
      "[6]\tvalid_0's tweedie: 142.134\n",
      "[7]\tvalid_0's tweedie: 141.426\n",
      "[8]\tvalid_0's tweedie: 140.838\n",
      "[9]\tvalid_0's tweedie: 140.35\n",
      "[10]\tvalid_0's tweedie: 139.955\n",
      "[11]\tvalid_0's tweedie: 139.622\n",
      "[12]\tvalid_0's tweedie: 139.357\n",
      "[13]\tvalid_0's tweedie: 139.139\n",
      "[14]\tvalid_0's tweedie: 138.96\n",
      "[15]\tvalid_0's tweedie: 138.812\n",
      "[16]\tvalid_0's tweedie: 138.697\n",
      "[17]\tvalid_0's tweedie: 138.596\n",
      "[18]\tvalid_0's tweedie: 138.517\n",
      "[19]\tvalid_0's tweedie: 138.448\n",
      "[20]\tvalid_0's tweedie: 138.395\n",
      "[21]\tvalid_0's tweedie: 138.351\n",
      "[22]\tvalid_0's tweedie: 138.313\n",
      "[23]\tvalid_0's tweedie: 138.282\n",
      "[24]\tvalid_0's tweedie: 138.258\n",
      "[25]\tvalid_0's tweedie: 138.238\n",
      "[26]\tvalid_0's tweedie: 138.222\n",
      "[27]\tvalid_0's tweedie: 138.209\n",
      "[28]\tvalid_0's tweedie: 138.197\n",
      "[29]\tvalid_0's tweedie: 138.19\n",
      "[30]\tvalid_0's tweedie: 138.182\n",
      "[31]\tvalid_0's tweedie: 138.177\n",
      "[32]\tvalid_0's tweedie: 138.172\n",
      "[33]\tvalid_0's tweedie: 138.166\n",
      "[34]\tvalid_0's tweedie: 138.163\n",
      "[35]\tvalid_0's tweedie: 138.161\n",
      "[36]\tvalid_0's tweedie: 138.158\n",
      "[37]\tvalid_0's tweedie: 138.157\n",
      "[38]\tvalid_0's tweedie: 138.154\n",
      "[39]\tvalid_0's tweedie: 138.152\n",
      "[40]\tvalid_0's tweedie: 138.15\n",
      "[41]\tvalid_0's tweedie: 138.149\n",
      "[42]\tvalid_0's tweedie: 138.148\n",
      "[43]\tvalid_0's tweedie: 138.148\n",
      "[44]\tvalid_0's tweedie: 138.146\n",
      "[45]\tvalid_0's tweedie: 138.146\n",
      "[46]\tvalid_0's tweedie: 138.145\n",
      "[47]\tvalid_0's tweedie: 138.145\n",
      "[48]\tvalid_0's tweedie: 138.145\n",
      "[49]\tvalid_0's tweedie: 138.145\n",
      "[50]\tvalid_0's tweedie: 138.144\n",
      "[51]\tvalid_0's tweedie: 138.144\n",
      "[52]\tvalid_0's tweedie: 138.142\n",
      "[53]\tvalid_0's tweedie: 138.142\n",
      "[54]\tvalid_0's tweedie: 138.141\n",
      "[55]\tvalid_0's tweedie: 138.141\n",
      "[56]\tvalid_0's tweedie: 138.141\n",
      "[57]\tvalid_0's tweedie: 138.141\n",
      "[58]\tvalid_0's tweedie: 138.141\n",
      "[59]\tvalid_0's tweedie: 138.14\n",
      "[60]\tvalid_0's tweedie: 138.14\n",
      "[61]\tvalid_0's tweedie: 138.14\n",
      "[62]\tvalid_0's tweedie: 138.14\n",
      "[63]\tvalid_0's tweedie: 138.14\n",
      "[64]\tvalid_0's tweedie: 138.14\n",
      "[65]\tvalid_0's tweedie: 138.14\n",
      "[66]\tvalid_0's tweedie: 138.14\n",
      "[67]\tvalid_0's tweedie: 138.14\n",
      "[68]\tvalid_0's tweedie: 138.14\n",
      "[69]\tvalid_0's tweedie: 138.139\n",
      "[70]\tvalid_0's tweedie: 138.14\n",
      "[71]\tvalid_0's tweedie: 138.139\n",
      "[72]\tvalid_0's tweedie: 138.139\n",
      "[73]\tvalid_0's tweedie: 138.139\n",
      "[74]\tvalid_0's tweedie: 138.139\n",
      "[75]\tvalid_0's tweedie: 138.139\n",
      "[76]\tvalid_0's tweedie: 138.139\n",
      "[77]\tvalid_0's tweedie: 138.139\n",
      "[78]\tvalid_0's tweedie: 138.138\n",
      "[79]\tvalid_0's tweedie: 138.138\n",
      "[80]\tvalid_0's tweedie: 138.138\n",
      "[81]\tvalid_0's tweedie: 138.138\n",
      "[82]\tvalid_0's tweedie: 138.137\n",
      "[83]\tvalid_0's tweedie: 138.137\n",
      "[84]\tvalid_0's tweedie: 138.137\n",
      "[85]\tvalid_0's tweedie: 138.137\n",
      "[86]\tvalid_0's tweedie: 138.137\n",
      "[87]\tvalid_0's tweedie: 138.137\n",
      "[88]\tvalid_0's tweedie: 138.137\n",
      "[89]\tvalid_0's tweedie: 138.137\n",
      "[90]\tvalid_0's tweedie: 138.137\n",
      "[91]\tvalid_0's tweedie: 138.137\n",
      "[92]\tvalid_0's tweedie: 138.137\n",
      "[93]\tvalid_0's tweedie: 138.137\n",
      "[94]\tvalid_0's tweedie: 138.137\n",
      "[95]\tvalid_0's tweedie: 138.137\n",
      "[96]\tvalid_0's tweedie: 138.137\n",
      "[97]\tvalid_0's tweedie: 138.137\n",
      "[98]\tvalid_0's tweedie: 138.137\n",
      "[99]\tvalid_0's tweedie: 138.137\n",
      "[100]\tvalid_0's tweedie: 138.136\n",
      "[101]\tvalid_0's tweedie: 138.136\n",
      "[102]\tvalid_0's tweedie: 138.136\n",
      "[103]\tvalid_0's tweedie: 138.136\n",
      "[104]\tvalid_0's tweedie: 138.137\n",
      "[105]\tvalid_0's tweedie: 138.137\n",
      "[106]\tvalid_0's tweedie: 138.137\n",
      "[107]\tvalid_0's tweedie: 138.137\n",
      "[108]\tvalid_0's tweedie: 138.137\n",
      "[109]\tvalid_0's tweedie: 138.137\n",
      "[110]\tvalid_0's tweedie: 138.137\n",
      "[111]\tvalid_0's tweedie: 138.137\n",
      "[112]\tvalid_0's tweedie: 138.136\n",
      "[113]\tvalid_0's tweedie: 138.136\n",
      "[114]\tvalid_0's tweedie: 138.136\n",
      "[115]\tvalid_0's tweedie: 138.135\n",
      "[116]\tvalid_0's tweedie: 138.135\n",
      "[117]\tvalid_0's tweedie: 138.135\n",
      "[118]\tvalid_0's tweedie: 138.135\n",
      "[119]\tvalid_0's tweedie: 138.135\n",
      "[120]\tvalid_0's tweedie: 138.134\n",
      "[121]\tvalid_0's tweedie: 138.134\n",
      "[122]\tvalid_0's tweedie: 138.133\n",
      "[123]\tvalid_0's tweedie: 138.133\n",
      "[124]\tvalid_0's tweedie: 138.133\n",
      "[125]\tvalid_0's tweedie: 138.133\n",
      "[126]\tvalid_0's tweedie: 138.133\n",
      "[127]\tvalid_0's tweedie: 138.133\n",
      "[128]\tvalid_0's tweedie: 138.133\n",
      "[129]\tvalid_0's tweedie: 138.133\n",
      "[130]\tvalid_0's tweedie: 138.133\n",
      "[131]\tvalid_0's tweedie: 138.133\n",
      "[132]\tvalid_0's tweedie: 138.133\n",
      "[133]\tvalid_0's tweedie: 138.133\n",
      "[134]\tvalid_0's tweedie: 138.133\n",
      "[135]\tvalid_0's tweedie: 138.133\n",
      "[136]\tvalid_0's tweedie: 138.132\n",
      "[137]\tvalid_0's tweedie: 138.132\n",
      "[138]\tvalid_0's tweedie: 138.132\n",
      "[139]\tvalid_0's tweedie: 138.132\n",
      "[140]\tvalid_0's tweedie: 138.132\n",
      "[141]\tvalid_0's tweedie: 138.132\n",
      "[142]\tvalid_0's tweedie: 138.132\n",
      "[143]\tvalid_0's tweedie: 138.132\n",
      "[144]\tvalid_0's tweedie: 138.132\n",
      "[145]\tvalid_0's tweedie: 138.132\n",
      "[146]\tvalid_0's tweedie: 138.132\n",
      "[147]\tvalid_0's tweedie: 138.132\n",
      "[148]\tvalid_0's tweedie: 138.132\n",
      "[149]\tvalid_0's tweedie: 138.132\n",
      "[150]\tvalid_0's tweedie: 138.132\n",
      "[151]\tvalid_0's tweedie: 138.132\n",
      "[152]\tvalid_0's tweedie: 138.132\n",
      "[153]\tvalid_0's tweedie: 138.132\n",
      "[154]\tvalid_0's tweedie: 138.131\n",
      "[155]\tvalid_0's tweedie: 138.131\n",
      "[156]\tvalid_0's tweedie: 138.131\n",
      "[157]\tvalid_0's tweedie: 138.131\n",
      "[158]\tvalid_0's tweedie: 138.132\n",
      "[159]\tvalid_0's tweedie: 138.132\n",
      "[160]\tvalid_0's tweedie: 138.132\n",
      "[161]\tvalid_0's tweedie: 138.132\n",
      "[162]\tvalid_0's tweedie: 138.132\n",
      "[163]\tvalid_0's tweedie: 138.132\n",
      "[164]\tvalid_0's tweedie: 138.131\n",
      "[165]\tvalid_0's tweedie: 138.131\n",
      "[166]\tvalid_0's tweedie: 138.131\n",
      "[167]\tvalid_0's tweedie: 138.131\n",
      "[168]\tvalid_0's tweedie: 138.131\n",
      "[169]\tvalid_0's tweedie: 138.131\n",
      "[170]\tvalid_0's tweedie: 138.131\n",
      "[171]\tvalid_0's tweedie: 138.13\n",
      "[172]\tvalid_0's tweedie: 138.13\n",
      "[173]\tvalid_0's tweedie: 138.13\n",
      "[174]\tvalid_0's tweedie: 138.13\n",
      "[175]\tvalid_0's tweedie: 138.13\n",
      "[176]\tvalid_0's tweedie: 138.13\n",
      "[177]\tvalid_0's tweedie: 138.13\n",
      "[178]\tvalid_0's tweedie: 138.13\n",
      "[179]\tvalid_0's tweedie: 138.13\n",
      "[180]\tvalid_0's tweedie: 138.131\n",
      "[181]\tvalid_0's tweedie: 138.131\n",
      "[182]\tvalid_0's tweedie: 138.13\n",
      "[183]\tvalid_0's tweedie: 138.13\n",
      "[184]\tvalid_0's tweedie: 138.13\n",
      "[185]\tvalid_0's tweedie: 138.13\n",
      "[186]\tvalid_0's tweedie: 138.13\n",
      "[187]\tvalid_0's tweedie: 138.13\n",
      "[188]\tvalid_0's tweedie: 138.13\n",
      "[189]\tvalid_0's tweedie: 138.13\n",
      "[190]\tvalid_0's tweedie: 138.13\n",
      "[191]\tvalid_0's tweedie: 138.13\n",
      "[192]\tvalid_0's tweedie: 138.13\n",
      "[193]\tvalid_0's tweedie: 138.13\n",
      "[194]\tvalid_0's tweedie: 138.13\n",
      "[195]\tvalid_0's tweedie: 138.13\n",
      "[196]\tvalid_0's tweedie: 138.13\n",
      "[197]\tvalid_0's tweedie: 138.13\n",
      "[198]\tvalid_0's tweedie: 138.13\n",
      "[199]\tvalid_0's tweedie: 138.129\n",
      "[200]\tvalid_0's tweedie: 138.129\n",
      "[201]\tvalid_0's tweedie: 138.129\n",
      "[202]\tvalid_0's tweedie: 138.129\n",
      "[203]\tvalid_0's tweedie: 138.129\n",
      "[204]\tvalid_0's tweedie: 138.128\n",
      "[205]\tvalid_0's tweedie: 138.128\n",
      "[206]\tvalid_0's tweedie: 138.128\n",
      "[207]\tvalid_0's tweedie: 138.128\n",
      "[208]\tvalid_0's tweedie: 138.128\n",
      "[209]\tvalid_0's tweedie: 138.128\n",
      "[210]\tvalid_0's tweedie: 138.128\n",
      "[211]\tvalid_0's tweedie: 138.128\n",
      "[212]\tvalid_0's tweedie: 138.128\n",
      "[213]\tvalid_0's tweedie: 138.128\n",
      "[214]\tvalid_0's tweedie: 138.128\n",
      "[215]\tvalid_0's tweedie: 138.128\n",
      "[216]\tvalid_0's tweedie: 138.129\n",
      "[217]\tvalid_0's tweedie: 138.129\n",
      "[218]\tvalid_0's tweedie: 138.129\n",
      "[219]\tvalid_0's tweedie: 138.129\n",
      "[220]\tvalid_0's tweedie: 138.129\n",
      "[221]\tvalid_0's tweedie: 138.129\n",
      "[222]\tvalid_0's tweedie: 138.129\n",
      "[223]\tvalid_0's tweedie: 138.129\n",
      "[224]\tvalid_0's tweedie: 138.129\n",
      "[225]\tvalid_0's tweedie: 138.129\n",
      "[226]\tvalid_0's tweedie: 138.129\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's tweedie: 138.128\n",
      "Training model for level 8 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 55920, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041874\n",
      "[1]\tvalid_0's tweedie: 148.76\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.921\n",
      "[3]\tvalid_0's tweedie: 145.42\n",
      "[4]\tvalid_0's tweedie: 144.15\n",
      "[5]\tvalid_0's tweedie: 143.108\n",
      "[6]\tvalid_0's tweedie: 142.242\n",
      "[7]\tvalid_0's tweedie: 141.536\n",
      "[8]\tvalid_0's tweedie: 140.968\n",
      "[9]\tvalid_0's tweedie: 140.493\n",
      "[10]\tvalid_0's tweedie: 140.085\n",
      "[11]\tvalid_0's tweedie: 139.754\n",
      "[12]\tvalid_0's tweedie: 139.479\n",
      "[13]\tvalid_0's tweedie: 139.256\n",
      "[14]\tvalid_0's tweedie: 139.071\n",
      "[15]\tvalid_0's tweedie: 138.916\n",
      "[16]\tvalid_0's tweedie: 138.79\n",
      "[17]\tvalid_0's tweedie: 138.686\n",
      "[18]\tvalid_0's tweedie: 138.598\n",
      "[19]\tvalid_0's tweedie: 138.529\n",
      "[20]\tvalid_0's tweedie: 138.472\n",
      "[21]\tvalid_0's tweedie: 138.424\n",
      "[22]\tvalid_0's tweedie: 138.382\n",
      "[23]\tvalid_0's tweedie: 138.35\n",
      "[24]\tvalid_0's tweedie: 138.326\n",
      "[25]\tvalid_0's tweedie: 138.305\n",
      "[26]\tvalid_0's tweedie: 138.285\n",
      "[27]\tvalid_0's tweedie: 138.27\n",
      "[28]\tvalid_0's tweedie: 138.256\n",
      "[29]\tvalid_0's tweedie: 138.247\n",
      "[30]\tvalid_0's tweedie: 138.237\n",
      "[31]\tvalid_0's tweedie: 138.229\n",
      "[32]\tvalid_0's tweedie: 138.225\n",
      "[33]\tvalid_0's tweedie: 138.219\n",
      "[34]\tvalid_0's tweedie: 138.214\n",
      "[35]\tvalid_0's tweedie: 138.209\n",
      "[36]\tvalid_0's tweedie: 138.207\n",
      "[37]\tvalid_0's tweedie: 138.203\n",
      "[38]\tvalid_0's tweedie: 138.202\n",
      "[39]\tvalid_0's tweedie: 138.201\n",
      "[40]\tvalid_0's tweedie: 138.199\n",
      "[41]\tvalid_0's tweedie: 138.197\n",
      "[42]\tvalid_0's tweedie: 138.194\n",
      "[43]\tvalid_0's tweedie: 138.193\n",
      "[44]\tvalid_0's tweedie: 138.192\n",
      "[45]\tvalid_0's tweedie: 138.191\n",
      "[46]\tvalid_0's tweedie: 138.189\n",
      "[47]\tvalid_0's tweedie: 138.188\n",
      "[48]\tvalid_0's tweedie: 138.187\n",
      "[49]\tvalid_0's tweedie: 138.187\n",
      "[50]\tvalid_0's tweedie: 138.186\n",
      "[51]\tvalid_0's tweedie: 138.185\n",
      "[52]\tvalid_0's tweedie: 138.185\n",
      "[53]\tvalid_0's tweedie: 138.184\n",
      "[54]\tvalid_0's tweedie: 138.185\n",
      "[55]\tvalid_0's tweedie: 138.183\n",
      "[56]\tvalid_0's tweedie: 138.183\n",
      "[57]\tvalid_0's tweedie: 138.182\n",
      "[58]\tvalid_0's tweedie: 138.182\n",
      "[59]\tvalid_0's tweedie: 138.181\n",
      "[60]\tvalid_0's tweedie: 138.18\n",
      "[61]\tvalid_0's tweedie: 138.18\n",
      "[62]\tvalid_0's tweedie: 138.18\n",
      "[63]\tvalid_0's tweedie: 138.179\n",
      "[64]\tvalid_0's tweedie: 138.179\n",
      "[65]\tvalid_0's tweedie: 138.179\n",
      "[66]\tvalid_0's tweedie: 138.179\n",
      "[67]\tvalid_0's tweedie: 138.18\n",
      "[68]\tvalid_0's tweedie: 138.177\n",
      "[69]\tvalid_0's tweedie: 138.177\n",
      "[70]\tvalid_0's tweedie: 138.176\n",
      "[71]\tvalid_0's tweedie: 138.176\n",
      "[72]\tvalid_0's tweedie: 138.176\n",
      "[73]\tvalid_0's tweedie: 138.176\n",
      "[74]\tvalid_0's tweedie: 138.176\n",
      "[75]\tvalid_0's tweedie: 138.175\n",
      "[76]\tvalid_0's tweedie: 138.175\n",
      "[77]\tvalid_0's tweedie: 138.176\n",
      "[78]\tvalid_0's tweedie: 138.176\n",
      "[79]\tvalid_0's tweedie: 138.176\n",
      "[80]\tvalid_0's tweedie: 138.176\n",
      "[81]\tvalid_0's tweedie: 138.176\n",
      "[82]\tvalid_0's tweedie: 138.177\n",
      "[83]\tvalid_0's tweedie: 138.177\n",
      "[84]\tvalid_0's tweedie: 138.175\n",
      "[85]\tvalid_0's tweedie: 138.175\n",
      "[86]\tvalid_0's tweedie: 138.174\n",
      "[87]\tvalid_0's tweedie: 138.174\n",
      "[88]\tvalid_0's tweedie: 138.174\n",
      "[89]\tvalid_0's tweedie: 138.174\n",
      "[90]\tvalid_0's tweedie: 138.174\n",
      "[91]\tvalid_0's tweedie: 138.174\n",
      "[92]\tvalid_0's tweedie: 138.174\n",
      "[93]\tvalid_0's tweedie: 138.174\n",
      "[94]\tvalid_0's tweedie: 138.174\n",
      "[95]\tvalid_0's tweedie: 138.174\n",
      "[96]\tvalid_0's tweedie: 138.174\n",
      "[97]\tvalid_0's tweedie: 138.174\n",
      "[98]\tvalid_0's tweedie: 138.173\n",
      "[99]\tvalid_0's tweedie: 138.173\n",
      "[100]\tvalid_0's tweedie: 138.173\n",
      "[101]\tvalid_0's tweedie: 138.173\n",
      "[102]\tvalid_0's tweedie: 138.173\n",
      "[103]\tvalid_0's tweedie: 138.173\n",
      "[104]\tvalid_0's tweedie: 138.173\n",
      "[105]\tvalid_0's tweedie: 138.173\n",
      "[106]\tvalid_0's tweedie: 138.171\n",
      "[107]\tvalid_0's tweedie: 138.17\n",
      "[108]\tvalid_0's tweedie: 138.17\n",
      "[109]\tvalid_0's tweedie: 138.17\n",
      "[110]\tvalid_0's tweedie: 138.17\n",
      "[111]\tvalid_0's tweedie: 138.171\n",
      "[112]\tvalid_0's tweedie: 138.171\n",
      "[113]\tvalid_0's tweedie: 138.17\n",
      "[114]\tvalid_0's tweedie: 138.17\n",
      "[115]\tvalid_0's tweedie: 138.17\n",
      "[116]\tvalid_0's tweedie: 138.17\n",
      "[117]\tvalid_0's tweedie: 138.17\n",
      "[118]\tvalid_0's tweedie: 138.17\n",
      "[119]\tvalid_0's tweedie: 138.17\n",
      "[120]\tvalid_0's tweedie: 138.17\n",
      "[121]\tvalid_0's tweedie: 138.17\n",
      "[122]\tvalid_0's tweedie: 138.17\n",
      "[123]\tvalid_0's tweedie: 138.17\n",
      "[124]\tvalid_0's tweedie: 138.168\n",
      "[125]\tvalid_0's tweedie: 138.168\n",
      "[126]\tvalid_0's tweedie: 138.168\n",
      "[127]\tvalid_0's tweedie: 138.168\n",
      "[128]\tvalid_0's tweedie: 138.168\n",
      "[129]\tvalid_0's tweedie: 138.168\n",
      "[130]\tvalid_0's tweedie: 138.167\n",
      "[131]\tvalid_0's tweedie: 138.167\n",
      "[132]\tvalid_0's tweedie: 138.166\n",
      "[133]\tvalid_0's tweedie: 138.167\n",
      "[134]\tvalid_0's tweedie: 138.165\n",
      "[135]\tvalid_0's tweedie: 138.164\n",
      "[136]\tvalid_0's tweedie: 138.165\n",
      "[137]\tvalid_0's tweedie: 138.164\n",
      "[138]\tvalid_0's tweedie: 138.165\n",
      "[139]\tvalid_0's tweedie: 138.165\n",
      "[140]\tvalid_0's tweedie: 138.165\n",
      "[141]\tvalid_0's tweedie: 138.165\n",
      "[142]\tvalid_0's tweedie: 138.165\n",
      "[143]\tvalid_0's tweedie: 138.165\n",
      "[144]\tvalid_0's tweedie: 138.165\n",
      "[145]\tvalid_0's tweedie: 138.165\n",
      "[146]\tvalid_0's tweedie: 138.165\n",
      "[147]\tvalid_0's tweedie: 138.165\n",
      "[148]\tvalid_0's tweedie: 138.164\n",
      "[149]\tvalid_0's tweedie: 138.164\n",
      "[150]\tvalid_0's tweedie: 138.164\n",
      "[151]\tvalid_0's tweedie: 138.165\n",
      "[152]\tvalid_0's tweedie: 138.165\n",
      "[153]\tvalid_0's tweedie: 138.165\n",
      "[154]\tvalid_0's tweedie: 138.165\n",
      "[155]\tvalid_0's tweedie: 138.164\n",
      "[156]\tvalid_0's tweedie: 138.164\n",
      "[157]\tvalid_0's tweedie: 138.164\n",
      "[158]\tvalid_0's tweedie: 138.164\n",
      "[159]\tvalid_0's tweedie: 138.164\n",
      "[160]\tvalid_0's tweedie: 138.164\n",
      "[161]\tvalid_0's tweedie: 138.164\n",
      "[162]\tvalid_0's tweedie: 138.164\n",
      "[163]\tvalid_0's tweedie: 138.164\n",
      "[164]\tvalid_0's tweedie: 138.164\n",
      "[165]\tvalid_0's tweedie: 138.163\n",
      "[166]\tvalid_0's tweedie: 138.163\n",
      "[167]\tvalid_0's tweedie: 138.164\n",
      "[168]\tvalid_0's tweedie: 138.164\n",
      "[169]\tvalid_0's tweedie: 138.164\n",
      "[170]\tvalid_0's tweedie: 138.164\n",
      "[171]\tvalid_0's tweedie: 138.163\n",
      "[172]\tvalid_0's tweedie: 138.164\n",
      "[173]\tvalid_0's tweedie: 138.164\n",
      "[174]\tvalid_0's tweedie: 138.163\n",
      "[175]\tvalid_0's tweedie: 138.163\n",
      "[176]\tvalid_0's tweedie: 138.163\n",
      "[177]\tvalid_0's tweedie: 138.163\n",
      "[178]\tvalid_0's tweedie: 138.163\n",
      "[179]\tvalid_0's tweedie: 138.163\n",
      "[180]\tvalid_0's tweedie: 138.163\n",
      "[181]\tvalid_0's tweedie: 138.163\n",
      "[182]\tvalid_0's tweedie: 138.163\n",
      "[183]\tvalid_0's tweedie: 138.163\n",
      "[184]\tvalid_0's tweedie: 138.163\n",
      "[185]\tvalid_0's tweedie: 138.163\n",
      "[186]\tvalid_0's tweedie: 138.163\n",
      "[187]\tvalid_0's tweedie: 138.163\n",
      "[188]\tvalid_0's tweedie: 138.163\n",
      "[189]\tvalid_0's tweedie: 138.163\n",
      "[190]\tvalid_0's tweedie: 138.163\n",
      "[191]\tvalid_0's tweedie: 138.163\n",
      "[192]\tvalid_0's tweedie: 138.162\n",
      "[193]\tvalid_0's tweedie: 138.162\n",
      "[194]\tvalid_0's tweedie: 138.162\n",
      "[195]\tvalid_0's tweedie: 138.162\n",
      "[196]\tvalid_0's tweedie: 138.162\n",
      "[197]\tvalid_0's tweedie: 138.162\n",
      "[198]\tvalid_0's tweedie: 138.162\n",
      "[199]\tvalid_0's tweedie: 138.161\n",
      "[200]\tvalid_0's tweedie: 138.161\n",
      "[201]\tvalid_0's tweedie: 138.162\n",
      "[202]\tvalid_0's tweedie: 138.162\n",
      "[203]\tvalid_0's tweedie: 138.162\n",
      "[204]\tvalid_0's tweedie: 138.162\n",
      "[205]\tvalid_0's tweedie: 138.162\n",
      "[206]\tvalid_0's tweedie: 138.162\n",
      "[207]\tvalid_0's tweedie: 138.162\n",
      "[208]\tvalid_0's tweedie: 138.162\n",
      "[209]\tvalid_0's tweedie: 138.162\n",
      "[210]\tvalid_0's tweedie: 138.162\n",
      "[211]\tvalid_0's tweedie: 138.162\n",
      "[212]\tvalid_0's tweedie: 138.162\n",
      "[213]\tvalid_0's tweedie: 138.162\n",
      "[214]\tvalid_0's tweedie: 138.162\n",
      "[215]\tvalid_0's tweedie: 138.161\n",
      "[216]\tvalid_0's tweedie: 138.162\n",
      "[217]\tvalid_0's tweedie: 138.161\n",
      "[218]\tvalid_0's tweedie: 138.162\n",
      "[219]\tvalid_0's tweedie: 138.162\n",
      "[220]\tvalid_0's tweedie: 138.162\n",
      "[221]\tvalid_0's tweedie: 138.162\n",
      "[222]\tvalid_0's tweedie: 138.162\n",
      "[223]\tvalid_0's tweedie: 138.162\n",
      "[224]\tvalid_0's tweedie: 138.162\n",
      "[225]\tvalid_0's tweedie: 138.162\n",
      "[226]\tvalid_0's tweedie: 138.162\n",
      "[227]\tvalid_0's tweedie: 138.162\n",
      "[228]\tvalid_0's tweedie: 138.162\n",
      "[229]\tvalid_0's tweedie: 138.162\n",
      "[230]\tvalid_0's tweedie: 138.162\n",
      "[231]\tvalid_0's tweedie: 138.162\n",
      "[232]\tvalid_0's tweedie: 138.162\n",
      "[233]\tvalid_0's tweedie: 138.162\n",
      "[234]\tvalid_0's tweedie: 138.162\n",
      "[235]\tvalid_0's tweedie: 138.162\n",
      "[236]\tvalid_0's tweedie: 138.162\n",
      "[237]\tvalid_0's tweedie: 138.161\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's tweedie: 138.161\n",
      "Training model for level 8 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5512\n",
      "[LightGBM] [Info] Number of data points in the train set: 55890, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041915\n",
      "[1]\tvalid_0's tweedie: 148.769\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.935\n",
      "[3]\tvalid_0's tweedie: 145.421\n",
      "[4]\tvalid_0's tweedie: 144.171\n",
      "[5]\tvalid_0's tweedie: 143.142\n",
      "[6]\tvalid_0's tweedie: 142.282\n",
      "[7]\tvalid_0's tweedie: 141.555\n",
      "[8]\tvalid_0's tweedie: 140.975\n",
      "[9]\tvalid_0's tweedie: 140.505\n",
      "[10]\tvalid_0's tweedie: 140.096\n",
      "[11]\tvalid_0's tweedie: 139.772\n",
      "[12]\tvalid_0's tweedie: 139.51\n",
      "[13]\tvalid_0's tweedie: 139.299\n",
      "[14]\tvalid_0's tweedie: 139.119\n",
      "[15]\tvalid_0's tweedie: 138.968\n",
      "[16]\tvalid_0's tweedie: 138.839\n",
      "[17]\tvalid_0's tweedie: 138.732\n",
      "[18]\tvalid_0's tweedie: 138.643\n",
      "[19]\tvalid_0's tweedie: 138.569\n",
      "[20]\tvalid_0's tweedie: 138.511\n",
      "[21]\tvalid_0's tweedie: 138.462\n",
      "[22]\tvalid_0's tweedie: 138.42\n",
      "[23]\tvalid_0's tweedie: 138.386\n",
      "[24]\tvalid_0's tweedie: 138.357\n",
      "[25]\tvalid_0's tweedie: 138.334\n",
      "[26]\tvalid_0's tweedie: 138.315\n",
      "[27]\tvalid_0's tweedie: 138.299\n",
      "[28]\tvalid_0's tweedie: 138.286\n",
      "[29]\tvalid_0's tweedie: 138.275\n",
      "[30]\tvalid_0's tweedie: 138.268\n",
      "[31]\tvalid_0's tweedie: 138.259\n",
      "[32]\tvalid_0's tweedie: 138.254\n",
      "[33]\tvalid_0's tweedie: 138.248\n",
      "[34]\tvalid_0's tweedie: 138.243\n",
      "[35]\tvalid_0's tweedie: 138.239\n",
      "[36]\tvalid_0's tweedie: 138.235\n",
      "[37]\tvalid_0's tweedie: 138.233\n",
      "[38]\tvalid_0's tweedie: 138.231\n",
      "[39]\tvalid_0's tweedie: 138.227\n",
      "[40]\tvalid_0's tweedie: 138.224\n",
      "[41]\tvalid_0's tweedie: 138.222\n",
      "[42]\tvalid_0's tweedie: 138.22\n",
      "[43]\tvalid_0's tweedie: 138.218\n",
      "[44]\tvalid_0's tweedie: 138.218\n",
      "[45]\tvalid_0's tweedie: 138.218\n",
      "[46]\tvalid_0's tweedie: 138.216\n",
      "[47]\tvalid_0's tweedie: 138.215\n",
      "[48]\tvalid_0's tweedie: 138.213\n",
      "[49]\tvalid_0's tweedie: 138.213\n",
      "[50]\tvalid_0's tweedie: 138.212\n",
      "[51]\tvalid_0's tweedie: 138.211\n",
      "[52]\tvalid_0's tweedie: 138.21\n",
      "[53]\tvalid_0's tweedie: 138.209\n",
      "[54]\tvalid_0's tweedie: 138.209\n",
      "[55]\tvalid_0's tweedie: 138.209\n",
      "[56]\tvalid_0's tweedie: 138.208\n",
      "[57]\tvalid_0's tweedie: 138.209\n",
      "[58]\tvalid_0's tweedie: 138.21\n",
      "[59]\tvalid_0's tweedie: 138.21\n",
      "[60]\tvalid_0's tweedie: 138.207\n",
      "[61]\tvalid_0's tweedie: 138.203\n",
      "[62]\tvalid_0's tweedie: 138.203\n",
      "[63]\tvalid_0's tweedie: 138.201\n",
      "[64]\tvalid_0's tweedie: 138.199\n",
      "[65]\tvalid_0's tweedie: 138.198\n",
      "[66]\tvalid_0's tweedie: 138.198\n",
      "[67]\tvalid_0's tweedie: 138.197\n",
      "[68]\tvalid_0's tweedie: 138.197\n",
      "[69]\tvalid_0's tweedie: 138.198\n",
      "[70]\tvalid_0's tweedie: 138.197\n",
      "[71]\tvalid_0's tweedie: 138.197\n",
      "[72]\tvalid_0's tweedie: 138.197\n",
      "[73]\tvalid_0's tweedie: 138.196\n",
      "[74]\tvalid_0's tweedie: 138.196\n",
      "[75]\tvalid_0's tweedie: 138.196\n",
      "[76]\tvalid_0's tweedie: 138.196\n",
      "[77]\tvalid_0's tweedie: 138.195\n",
      "[78]\tvalid_0's tweedie: 138.195\n",
      "[79]\tvalid_0's tweedie: 138.195\n",
      "[80]\tvalid_0's tweedie: 138.195\n",
      "[81]\tvalid_0's tweedie: 138.195\n",
      "[82]\tvalid_0's tweedie: 138.194\n",
      "[83]\tvalid_0's tweedie: 138.194\n",
      "[84]\tvalid_0's tweedie: 138.194\n",
      "[85]\tvalid_0's tweedie: 138.194\n",
      "[86]\tvalid_0's tweedie: 138.194\n",
      "[87]\tvalid_0's tweedie: 138.194\n",
      "[88]\tvalid_0's tweedie: 138.194\n",
      "[89]\tvalid_0's tweedie: 138.194\n",
      "[90]\tvalid_0's tweedie: 138.193\n",
      "[91]\tvalid_0's tweedie: 138.194\n",
      "[92]\tvalid_0's tweedie: 138.194\n",
      "[93]\tvalid_0's tweedie: 138.193\n",
      "[94]\tvalid_0's tweedie: 138.193\n",
      "[95]\tvalid_0's tweedie: 138.193\n",
      "[96]\tvalid_0's tweedie: 138.193\n",
      "[97]\tvalid_0's tweedie: 138.193\n",
      "[98]\tvalid_0's tweedie: 138.193\n",
      "[99]\tvalid_0's tweedie: 138.193\n",
      "[100]\tvalid_0's tweedie: 138.192\n",
      "[101]\tvalid_0's tweedie: 138.192\n",
      "[102]\tvalid_0's tweedie: 138.192\n",
      "[103]\tvalid_0's tweedie: 138.192\n",
      "[104]\tvalid_0's tweedie: 138.189\n",
      "[105]\tvalid_0's tweedie: 138.188\n",
      "[106]\tvalid_0's tweedie: 138.188\n",
      "[107]\tvalid_0's tweedie: 138.188\n",
      "[108]\tvalid_0's tweedie: 138.188\n",
      "[109]\tvalid_0's tweedie: 138.188\n",
      "[110]\tvalid_0's tweedie: 138.188\n",
      "[111]\tvalid_0's tweedie: 138.188\n",
      "[112]\tvalid_0's tweedie: 138.187\n",
      "[113]\tvalid_0's tweedie: 138.187\n",
      "[114]\tvalid_0's tweedie: 138.187\n",
      "[115]\tvalid_0's tweedie: 138.187\n",
      "[116]\tvalid_0's tweedie: 138.187\n",
      "[117]\tvalid_0's tweedie: 138.187\n",
      "[118]\tvalid_0's tweedie: 138.187\n",
      "[119]\tvalid_0's tweedie: 138.187\n",
      "[120]\tvalid_0's tweedie: 138.187\n",
      "[121]\tvalid_0's tweedie: 138.187\n",
      "[122]\tvalid_0's tweedie: 138.187\n",
      "[123]\tvalid_0's tweedie: 138.187\n",
      "[124]\tvalid_0's tweedie: 138.187\n",
      "[125]\tvalid_0's tweedie: 138.187\n",
      "[126]\tvalid_0's tweedie: 138.187\n",
      "[127]\tvalid_0's tweedie: 138.185\n",
      "[128]\tvalid_0's tweedie: 138.185\n",
      "[129]\tvalid_0's tweedie: 138.185\n",
      "[130]\tvalid_0's tweedie: 138.185\n",
      "[131]\tvalid_0's tweedie: 138.185\n",
      "[132]\tvalid_0's tweedie: 138.185\n",
      "[133]\tvalid_0's tweedie: 138.185\n",
      "[134]\tvalid_0's tweedie: 138.185\n",
      "[135]\tvalid_0's tweedie: 138.185\n",
      "[136]\tvalid_0's tweedie: 138.185\n",
      "[137]\tvalid_0's tweedie: 138.185\n",
      "[138]\tvalid_0's tweedie: 138.185\n",
      "[139]\tvalid_0's tweedie: 138.185\n",
      "[140]\tvalid_0's tweedie: 138.185\n",
      "[141]\tvalid_0's tweedie: 138.185\n",
      "[142]\tvalid_0's tweedie: 138.185\n",
      "[143]\tvalid_0's tweedie: 138.185\n",
      "[144]\tvalid_0's tweedie: 138.185\n",
      "[145]\tvalid_0's tweedie: 138.185\n",
      "[146]\tvalid_0's tweedie: 138.185\n",
      "[147]\tvalid_0's tweedie: 138.185\n",
      "[148]\tvalid_0's tweedie: 138.185\n",
      "[149]\tvalid_0's tweedie: 138.185\n",
      "[150]\tvalid_0's tweedie: 138.185\n",
      "[151]\tvalid_0's tweedie: 138.185\n",
      "[152]\tvalid_0's tweedie: 138.185\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's tweedie: 138.185\n",
      "Training model for level 8 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5511\n",
      "[LightGBM] [Info] Number of data points in the train set: 55860, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.041993\n",
      "[1]\tvalid_0's tweedie: 148.772\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.938\n",
      "[3]\tvalid_0's tweedie: 145.424\n",
      "[4]\tvalid_0's tweedie: 144.173\n",
      "[5]\tvalid_0's tweedie: 143.144\n",
      "[6]\tvalid_0's tweedie: 142.291\n",
      "[7]\tvalid_0's tweedie: 141.573\n",
      "[8]\tvalid_0's tweedie: 140.994\n",
      "[9]\tvalid_0's tweedie: 140.521\n",
      "[10]\tvalid_0's tweedie: 140.122\n",
      "[11]\tvalid_0's tweedie: 139.806\n",
      "[12]\tvalid_0's tweedie: 139.535\n",
      "[13]\tvalid_0's tweedie: 139.312\n",
      "[14]\tvalid_0's tweedie: 139.127\n",
      "[15]\tvalid_0's tweedie: 138.975\n",
      "[16]\tvalid_0's tweedie: 138.853\n",
      "[17]\tvalid_0's tweedie: 138.75\n",
      "[18]\tvalid_0's tweedie: 138.659\n",
      "[19]\tvalid_0's tweedie: 138.591\n",
      "[20]\tvalid_0's tweedie: 138.534\n",
      "[21]\tvalid_0's tweedie: 138.483\n",
      "[22]\tvalid_0's tweedie: 138.443\n",
      "[23]\tvalid_0's tweedie: 138.411\n",
      "[24]\tvalid_0's tweedie: 138.382\n",
      "[25]\tvalid_0's tweedie: 138.362\n",
      "[26]\tvalid_0's tweedie: 138.343\n",
      "[27]\tvalid_0's tweedie: 138.328\n",
      "[28]\tvalid_0's tweedie: 138.314\n",
      "[29]\tvalid_0's tweedie: 138.301\n",
      "[30]\tvalid_0's tweedie: 138.29\n",
      "[31]\tvalid_0's tweedie: 138.282\n",
      "[32]\tvalid_0's tweedie: 138.278\n",
      "[33]\tvalid_0's tweedie: 138.274\n",
      "[34]\tvalid_0's tweedie: 138.267\n",
      "[35]\tvalid_0's tweedie: 138.261\n",
      "[36]\tvalid_0's tweedie: 138.257\n",
      "[37]\tvalid_0's tweedie: 138.253\n",
      "[38]\tvalid_0's tweedie: 138.25\n",
      "[39]\tvalid_0's tweedie: 138.249\n",
      "[40]\tvalid_0's tweedie: 138.246\n",
      "[41]\tvalid_0's tweedie: 138.244\n",
      "[42]\tvalid_0's tweedie: 138.242\n",
      "[43]\tvalid_0's tweedie: 138.241\n",
      "[44]\tvalid_0's tweedie: 138.236\n",
      "[45]\tvalid_0's tweedie: 138.235\n",
      "[46]\tvalid_0's tweedie: 138.235\n",
      "[47]\tvalid_0's tweedie: 138.234\n",
      "[48]\tvalid_0's tweedie: 138.232\n",
      "[49]\tvalid_0's tweedie: 138.231\n",
      "[50]\tvalid_0's tweedie: 138.232\n",
      "[51]\tvalid_0's tweedie: 138.232\n",
      "[52]\tvalid_0's tweedie: 138.231\n",
      "[53]\tvalid_0's tweedie: 138.231\n",
      "[54]\tvalid_0's tweedie: 138.229\n",
      "[55]\tvalid_0's tweedie: 138.228\n",
      "[56]\tvalid_0's tweedie: 138.227\n",
      "[57]\tvalid_0's tweedie: 138.228\n",
      "[58]\tvalid_0's tweedie: 138.227\n",
      "[59]\tvalid_0's tweedie: 138.228\n",
      "[60]\tvalid_0's tweedie: 138.228\n",
      "[61]\tvalid_0's tweedie: 138.227\n",
      "[62]\tvalid_0's tweedie: 138.227\n",
      "[63]\tvalid_0's tweedie: 138.227\n",
      "[64]\tvalid_0's tweedie: 138.226\n",
      "[65]\tvalid_0's tweedie: 138.225\n",
      "[66]\tvalid_0's tweedie: 138.222\n",
      "[67]\tvalid_0's tweedie: 138.223\n",
      "[68]\tvalid_0's tweedie: 138.222\n",
      "[69]\tvalid_0's tweedie: 138.222\n",
      "[70]\tvalid_0's tweedie: 138.222\n",
      "[71]\tvalid_0's tweedie: 138.222\n",
      "[72]\tvalid_0's tweedie: 138.22\n",
      "[73]\tvalid_0's tweedie: 138.22\n",
      "[74]\tvalid_0's tweedie: 138.22\n",
      "[75]\tvalid_0's tweedie: 138.219\n",
      "[76]\tvalid_0's tweedie: 138.219\n",
      "[77]\tvalid_0's tweedie: 138.219\n",
      "[78]\tvalid_0's tweedie: 138.217\n",
      "[79]\tvalid_0's tweedie: 138.216\n",
      "[80]\tvalid_0's tweedie: 138.216\n",
      "[81]\tvalid_0's tweedie: 138.216\n",
      "[82]\tvalid_0's tweedie: 138.216\n",
      "[83]\tvalid_0's tweedie: 138.216\n",
      "[84]\tvalid_0's tweedie: 138.216\n",
      "[85]\tvalid_0's tweedie: 138.216\n",
      "[86]\tvalid_0's tweedie: 138.216\n",
      "[87]\tvalid_0's tweedie: 138.215\n",
      "[88]\tvalid_0's tweedie: 138.215\n",
      "[89]\tvalid_0's tweedie: 138.215\n",
      "[90]\tvalid_0's tweedie: 138.215\n",
      "[91]\tvalid_0's tweedie: 138.215\n",
      "[92]\tvalid_0's tweedie: 138.214\n",
      "[93]\tvalid_0's tweedie: 138.214\n",
      "[94]\tvalid_0's tweedie: 138.214\n",
      "[95]\tvalid_0's tweedie: 138.214\n",
      "[96]\tvalid_0's tweedie: 138.214\n",
      "[97]\tvalid_0's tweedie: 138.214\n",
      "[98]\tvalid_0's tweedie: 138.214\n",
      "[99]\tvalid_0's tweedie: 138.213\n",
      "[100]\tvalid_0's tweedie: 138.214\n",
      "[101]\tvalid_0's tweedie: 138.217\n",
      "[102]\tvalid_0's tweedie: 138.216\n",
      "[103]\tvalid_0's tweedie: 138.216\n",
      "[104]\tvalid_0's tweedie: 138.216\n",
      "[105]\tvalid_0's tweedie: 138.217\n",
      "[106]\tvalid_0's tweedie: 138.217\n",
      "[107]\tvalid_0's tweedie: 138.216\n",
      "[108]\tvalid_0's tweedie: 138.216\n",
      "[109]\tvalid_0's tweedie: 138.216\n",
      "[110]\tvalid_0's tweedie: 138.216\n",
      "[111]\tvalid_0's tweedie: 138.213\n",
      "[112]\tvalid_0's tweedie: 138.213\n",
      "[113]\tvalid_0's tweedie: 138.213\n",
      "[114]\tvalid_0's tweedie: 138.213\n",
      "[115]\tvalid_0's tweedie: 138.213\n",
      "[116]\tvalid_0's tweedie: 138.213\n",
      "[117]\tvalid_0's tweedie: 138.212\n",
      "[118]\tvalid_0's tweedie: 138.212\n",
      "[119]\tvalid_0's tweedie: 138.212\n",
      "[120]\tvalid_0's tweedie: 138.212\n",
      "[121]\tvalid_0's tweedie: 138.212\n",
      "[122]\tvalid_0's tweedie: 138.212\n",
      "[123]\tvalid_0's tweedie: 138.212\n",
      "[124]\tvalid_0's tweedie: 138.212\n",
      "[125]\tvalid_0's tweedie: 138.212\n",
      "[126]\tvalid_0's tweedie: 138.212\n",
      "[127]\tvalid_0's tweedie: 138.212\n",
      "[128]\tvalid_0's tweedie: 138.212\n",
      "[129]\tvalid_0's tweedie: 138.212\n",
      "[130]\tvalid_0's tweedie: 138.211\n",
      "[131]\tvalid_0's tweedie: 138.211\n",
      "[132]\tvalid_0's tweedie: 138.211\n",
      "[133]\tvalid_0's tweedie: 138.211\n",
      "[134]\tvalid_0's tweedie: 138.21\n",
      "[135]\tvalid_0's tweedie: 138.21\n",
      "[136]\tvalid_0's tweedie: 138.211\n",
      "[137]\tvalid_0's tweedie: 138.211\n",
      "[138]\tvalid_0's tweedie: 138.208\n",
      "[139]\tvalid_0's tweedie: 138.209\n",
      "[140]\tvalid_0's tweedie: 138.209\n",
      "[141]\tvalid_0's tweedie: 138.209\n",
      "[142]\tvalid_0's tweedie: 138.209\n",
      "[143]\tvalid_0's tweedie: 138.209\n",
      "[144]\tvalid_0's tweedie: 138.209\n",
      "[145]\tvalid_0's tweedie: 138.209\n",
      "[146]\tvalid_0's tweedie: 138.209\n",
      "[147]\tvalid_0's tweedie: 138.209\n",
      "[148]\tvalid_0's tweedie: 138.208\n",
      "[149]\tvalid_0's tweedie: 138.207\n",
      "[150]\tvalid_0's tweedie: 138.207\n",
      "[151]\tvalid_0's tweedie: 138.208\n",
      "[152]\tvalid_0's tweedie: 138.207\n",
      "[153]\tvalid_0's tweedie: 138.207\n",
      "[154]\tvalid_0's tweedie: 138.207\n",
      "[155]\tvalid_0's tweedie: 138.207\n",
      "[156]\tvalid_0's tweedie: 138.206\n",
      "[157]\tvalid_0's tweedie: 138.206\n",
      "[158]\tvalid_0's tweedie: 138.206\n",
      "[159]\tvalid_0's tweedie: 138.206\n",
      "[160]\tvalid_0's tweedie: 138.205\n",
      "[161]\tvalid_0's tweedie: 138.205\n",
      "[162]\tvalid_0's tweedie: 138.205\n",
      "[163]\tvalid_0's tweedie: 138.205\n",
      "[164]\tvalid_0's tweedie: 138.205\n",
      "[165]\tvalid_0's tweedie: 138.205\n",
      "[166]\tvalid_0's tweedie: 138.205\n",
      "[167]\tvalid_0's tweedie: 138.205\n",
      "[168]\tvalid_0's tweedie: 138.205\n",
      "[169]\tvalid_0's tweedie: 138.205\n",
      "[170]\tvalid_0's tweedie: 138.205\n",
      "[171]\tvalid_0's tweedie: 138.204\n",
      "[172]\tvalid_0's tweedie: 138.204\n",
      "[173]\tvalid_0's tweedie: 138.204\n",
      "[174]\tvalid_0's tweedie: 138.204\n",
      "[175]\tvalid_0's tweedie: 138.204\n",
      "[176]\tvalid_0's tweedie: 138.205\n",
      "[177]\tvalid_0's tweedie: 138.205\n",
      "[178]\tvalid_0's tweedie: 138.205\n",
      "[179]\tvalid_0's tweedie: 138.205\n",
      "[180]\tvalid_0's tweedie: 138.205\n",
      "[181]\tvalid_0's tweedie: 138.205\n",
      "[182]\tvalid_0's tweedie: 138.205\n",
      "[183]\tvalid_0's tweedie: 138.205\n",
      "[184]\tvalid_0's tweedie: 138.205\n",
      "[185]\tvalid_0's tweedie: 138.204\n",
      "[186]\tvalid_0's tweedie: 138.204\n",
      "[187]\tvalid_0's tweedie: 138.204\n",
      "[188]\tvalid_0's tweedie: 138.204\n",
      "[189]\tvalid_0's tweedie: 138.204\n",
      "[190]\tvalid_0's tweedie: 138.204\n",
      "[191]\tvalid_0's tweedie: 138.204\n",
      "[192]\tvalid_0's tweedie: 138.204\n",
      "[193]\tvalid_0's tweedie: 138.204\n",
      "[194]\tvalid_0's tweedie: 138.204\n",
      "[195]\tvalid_0's tweedie: 138.204\n",
      "[196]\tvalid_0's tweedie: 138.204\n",
      "[197]\tvalid_0's tweedie: 138.204\n",
      "[198]\tvalid_0's tweedie: 138.204\n",
      "[199]\tvalid_0's tweedie: 138.204\n",
      "[200]\tvalid_0's tweedie: 138.204\n",
      "[201]\tvalid_0's tweedie: 138.204\n",
      "[202]\tvalid_0's tweedie: 138.203\n",
      "[203]\tvalid_0's tweedie: 138.203\n",
      "[204]\tvalid_0's tweedie: 138.203\n",
      "[205]\tvalid_0's tweedie: 138.203\n",
      "[206]\tvalid_0's tweedie: 138.203\n",
      "[207]\tvalid_0's tweedie: 138.203\n",
      "[208]\tvalid_0's tweedie: 138.203\n",
      "[209]\tvalid_0's tweedie: 138.203\n",
      "[210]\tvalid_0's tweedie: 138.203\n",
      "[211]\tvalid_0's tweedie: 138.203\n",
      "[212]\tvalid_0's tweedie: 138.203\n",
      "[213]\tvalid_0's tweedie: 138.203\n",
      "[214]\tvalid_0's tweedie: 138.203\n",
      "[215]\tvalid_0's tweedie: 138.203\n",
      "[216]\tvalid_0's tweedie: 138.203\n",
      "[217]\tvalid_0's tweedie: 138.203\n",
      "[218]\tvalid_0's tweedie: 138.203\n",
      "[219]\tvalid_0's tweedie: 138.203\n",
      "[220]\tvalid_0's tweedie: 138.203\n",
      "[221]\tvalid_0's tweedie: 138.203\n",
      "[222]\tvalid_0's tweedie: 138.203\n",
      "[223]\tvalid_0's tweedie: 138.203\n",
      "[224]\tvalid_0's tweedie: 138.203\n",
      "[225]\tvalid_0's tweedie: 138.203\n",
      "[226]\tvalid_0's tweedie: 138.202\n",
      "[227]\tvalid_0's tweedie: 138.203\n",
      "[228]\tvalid_0's tweedie: 138.203\n",
      "[229]\tvalid_0's tweedie: 138.203\n",
      "[230]\tvalid_0's tweedie: 138.203\n",
      "[231]\tvalid_0's tweedie: 138.203\n",
      "[232]\tvalid_0's tweedie: 138.202\n",
      "[233]\tvalid_0's tweedie: 138.202\n",
      "[234]\tvalid_0's tweedie: 138.202\n",
      "[235]\tvalid_0's tweedie: 138.202\n",
      "[236]\tvalid_0's tweedie: 138.202\n",
      "[237]\tvalid_0's tweedie: 138.202\n",
      "[238]\tvalid_0's tweedie: 138.202\n",
      "[239]\tvalid_0's tweedie: 138.202\n",
      "[240]\tvalid_0's tweedie: 138.202\n",
      "[241]\tvalid_0's tweedie: 138.202\n",
      "[242]\tvalid_0's tweedie: 138.202\n",
      "[243]\tvalid_0's tweedie: 138.202\n",
      "[244]\tvalid_0's tweedie: 138.202\n",
      "[245]\tvalid_0's tweedie: 138.202\n",
      "[246]\tvalid_0's tweedie: 138.202\n",
      "[247]\tvalid_0's tweedie: 138.202\n",
      "[248]\tvalid_0's tweedie: 138.202\n",
      "[249]\tvalid_0's tweedie: 138.202\n",
      "[250]\tvalid_0's tweedie: 138.201\n",
      "[251]\tvalid_0's tweedie: 138.201\n",
      "[252]\tvalid_0's tweedie: 138.202\n",
      "[253]\tvalid_0's tweedie: 138.202\n",
      "[254]\tvalid_0's tweedie: 138.201\n",
      "[255]\tvalid_0's tweedie: 138.201\n",
      "[256]\tvalid_0's tweedie: 138.201\n",
      "[257]\tvalid_0's tweedie: 138.201\n",
      "[258]\tvalid_0's tweedie: 138.201\n",
      "[259]\tvalid_0's tweedie: 138.201\n",
      "[260]\tvalid_0's tweedie: 138.201\n",
      "[261]\tvalid_0's tweedie: 138.201\n",
      "[262]\tvalid_0's tweedie: 138.201\n",
      "[263]\tvalid_0's tweedie: 138.201\n",
      "[264]\tvalid_0's tweedie: 138.201\n",
      "[265]\tvalid_0's tweedie: 138.201\n",
      "[266]\tvalid_0's tweedie: 138.2\n",
      "[267]\tvalid_0's tweedie: 138.201\n",
      "[268]\tvalid_0's tweedie: 138.2\n",
      "[269]\tvalid_0's tweedie: 138.2\n",
      "[270]\tvalid_0's tweedie: 138.2\n",
      "[271]\tvalid_0's tweedie: 138.2\n",
      "[272]\tvalid_0's tweedie: 138.2\n",
      "[273]\tvalid_0's tweedie: 138.2\n",
      "[274]\tvalid_0's tweedie: 138.2\n",
      "[275]\tvalid_0's tweedie: 138.2\n",
      "[276]\tvalid_0's tweedie: 138.2\n",
      "[277]\tvalid_0's tweedie: 138.2\n",
      "[278]\tvalid_0's tweedie: 138.2\n",
      "[279]\tvalid_0's tweedie: 138.2\n",
      "[280]\tvalid_0's tweedie: 138.2\n",
      "[281]\tvalid_0's tweedie: 138.2\n",
      "[282]\tvalid_0's tweedie: 138.2\n",
      "[283]\tvalid_0's tweedie: 138.2\n",
      "[284]\tvalid_0's tweedie: 138.2\n",
      "[285]\tvalid_0's tweedie: 138.2\n",
      "[286]\tvalid_0's tweedie: 138.2\n",
      "[287]\tvalid_0's tweedie: 138.2\n",
      "[288]\tvalid_0's tweedie: 138.2\n",
      "[289]\tvalid_0's tweedie: 138.2\n",
      "[290]\tvalid_0's tweedie: 138.2\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's tweedie: 138.2\n",
      "Training model for level 8 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5510\n",
      "[LightGBM] [Info] Number of data points in the train set: 55830, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.042155\n",
      "[1]\tvalid_0's tweedie: 148.77\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.936\n",
      "[3]\tvalid_0's tweedie: 145.426\n",
      "[4]\tvalid_0's tweedie: 144.176\n",
      "[5]\tvalid_0's tweedie: 143.145\n",
      "[6]\tvalid_0's tweedie: 142.286\n",
      "[7]\tvalid_0's tweedie: 141.558\n",
      "[8]\tvalid_0's tweedie: 140.977\n",
      "[9]\tvalid_0's tweedie: 140.507\n",
      "[10]\tvalid_0's tweedie: 140.111\n",
      "[11]\tvalid_0's tweedie: 139.795\n",
      "[12]\tvalid_0's tweedie: 139.522\n",
      "[13]\tvalid_0's tweedie: 139.303\n",
      "[14]\tvalid_0's tweedie: 139.117\n",
      "[15]\tvalid_0's tweedie: 138.963\n",
      "[16]\tvalid_0's tweedie: 138.842\n",
      "[17]\tvalid_0's tweedie: 138.737\n",
      "[18]\tvalid_0's tweedie: 138.643\n",
      "[19]\tvalid_0's tweedie: 138.572\n",
      "[20]\tvalid_0's tweedie: 138.513\n",
      "[21]\tvalid_0's tweedie: 138.465\n",
      "[22]\tvalid_0's tweedie: 138.424\n",
      "[23]\tvalid_0's tweedie: 138.395\n",
      "[24]\tvalid_0's tweedie: 138.369\n",
      "[25]\tvalid_0's tweedie: 138.346\n",
      "[26]\tvalid_0's tweedie: 138.328\n",
      "[27]\tvalid_0's tweedie: 138.312\n",
      "[28]\tvalid_0's tweedie: 138.299\n",
      "[29]\tvalid_0's tweedie: 138.287\n",
      "[30]\tvalid_0's tweedie: 138.278\n",
      "[31]\tvalid_0's tweedie: 138.269\n",
      "[32]\tvalid_0's tweedie: 138.261\n",
      "[33]\tvalid_0's tweedie: 138.258\n",
      "[34]\tvalid_0's tweedie: 138.253\n",
      "[35]\tvalid_0's tweedie: 138.249\n",
      "[36]\tvalid_0's tweedie: 138.245\n",
      "[37]\tvalid_0's tweedie: 138.242\n",
      "[38]\tvalid_0's tweedie: 138.237\n",
      "[39]\tvalid_0's tweedie: 138.235\n",
      "[40]\tvalid_0's tweedie: 138.234\n",
      "[41]\tvalid_0's tweedie: 138.232\n",
      "[42]\tvalid_0's tweedie: 138.229\n",
      "[43]\tvalid_0's tweedie: 138.228\n",
      "[44]\tvalid_0's tweedie: 138.226\n",
      "[45]\tvalid_0's tweedie: 138.227\n",
      "[46]\tvalid_0's tweedie: 138.228\n",
      "[47]\tvalid_0's tweedie: 138.227\n",
      "[48]\tvalid_0's tweedie: 138.226\n",
      "[49]\tvalid_0's tweedie: 138.225\n",
      "[50]\tvalid_0's tweedie: 138.224\n",
      "[51]\tvalid_0's tweedie: 138.223\n",
      "[52]\tvalid_0's tweedie: 138.222\n",
      "[53]\tvalid_0's tweedie: 138.219\n",
      "[54]\tvalid_0's tweedie: 138.22\n",
      "[55]\tvalid_0's tweedie: 138.219\n",
      "[56]\tvalid_0's tweedie: 138.218\n",
      "[57]\tvalid_0's tweedie: 138.217\n",
      "[58]\tvalid_0's tweedie: 138.217\n",
      "[59]\tvalid_0's tweedie: 138.217\n",
      "[60]\tvalid_0's tweedie: 138.216\n",
      "[61]\tvalid_0's tweedie: 138.216\n",
      "[62]\tvalid_0's tweedie: 138.215\n",
      "[63]\tvalid_0's tweedie: 138.215\n",
      "[64]\tvalid_0's tweedie: 138.215\n",
      "[65]\tvalid_0's tweedie: 138.213\n",
      "[66]\tvalid_0's tweedie: 138.213\n",
      "[67]\tvalid_0's tweedie: 138.212\n",
      "[68]\tvalid_0's tweedie: 138.212\n",
      "[69]\tvalid_0's tweedie: 138.212\n",
      "[70]\tvalid_0's tweedie: 138.212\n",
      "[71]\tvalid_0's tweedie: 138.212\n",
      "[72]\tvalid_0's tweedie: 138.212\n",
      "[73]\tvalid_0's tweedie: 138.211\n",
      "[74]\tvalid_0's tweedie: 138.211\n",
      "[75]\tvalid_0's tweedie: 138.21\n",
      "[76]\tvalid_0's tweedie: 138.21\n",
      "[77]\tvalid_0's tweedie: 138.211\n",
      "[78]\tvalid_0's tweedie: 138.211\n",
      "[79]\tvalid_0's tweedie: 138.211\n",
      "[80]\tvalid_0's tweedie: 138.21\n",
      "[81]\tvalid_0's tweedie: 138.211\n",
      "[82]\tvalid_0's tweedie: 138.211\n",
      "[83]\tvalid_0's tweedie: 138.211\n",
      "[84]\tvalid_0's tweedie: 138.212\n",
      "[85]\tvalid_0's tweedie: 138.212\n",
      "[86]\tvalid_0's tweedie: 138.212\n",
      "[87]\tvalid_0's tweedie: 138.211\n",
      "[88]\tvalid_0's tweedie: 138.211\n",
      "[89]\tvalid_0's tweedie: 138.211\n",
      "[90]\tvalid_0's tweedie: 138.211\n",
      "[91]\tvalid_0's tweedie: 138.211\n",
      "[92]\tvalid_0's tweedie: 138.211\n",
      "[93]\tvalid_0's tweedie: 138.21\n",
      "[94]\tvalid_0's tweedie: 138.21\n",
      "[95]\tvalid_0's tweedie: 138.21\n",
      "[96]\tvalid_0's tweedie: 138.21\n",
      "[97]\tvalid_0's tweedie: 138.21\n",
      "[98]\tvalid_0's tweedie: 138.207\n",
      "[99]\tvalid_0's tweedie: 138.207\n",
      "[100]\tvalid_0's tweedie: 138.206\n",
      "[101]\tvalid_0's tweedie: 138.207\n",
      "[102]\tvalid_0's tweedie: 138.207\n",
      "[103]\tvalid_0's tweedie: 138.206\n",
      "[104]\tvalid_0's tweedie: 138.203\n",
      "[105]\tvalid_0's tweedie: 138.203\n",
      "[106]\tvalid_0's tweedie: 138.203\n",
      "[107]\tvalid_0's tweedie: 138.203\n",
      "[108]\tvalid_0's tweedie: 138.203\n",
      "[109]\tvalid_0's tweedie: 138.203\n",
      "[110]\tvalid_0's tweedie: 138.203\n",
      "[111]\tvalid_0's tweedie: 138.202\n",
      "[112]\tvalid_0's tweedie: 138.202\n",
      "[113]\tvalid_0's tweedie: 138.202\n",
      "[114]\tvalid_0's tweedie: 138.202\n",
      "[115]\tvalid_0's tweedie: 138.202\n",
      "[116]\tvalid_0's tweedie: 138.202\n",
      "[117]\tvalid_0's tweedie: 138.202\n",
      "[118]\tvalid_0's tweedie: 138.202\n",
      "[119]\tvalid_0's tweedie: 138.202\n",
      "[120]\tvalid_0's tweedie: 138.202\n",
      "[121]\tvalid_0's tweedie: 138.202\n",
      "[122]\tvalid_0's tweedie: 138.201\n",
      "[123]\tvalid_0's tweedie: 138.201\n",
      "[124]\tvalid_0's tweedie: 138.202\n",
      "[125]\tvalid_0's tweedie: 138.202\n",
      "[126]\tvalid_0's tweedie: 138.201\n",
      "[127]\tvalid_0's tweedie: 138.199\n",
      "[128]\tvalid_0's tweedie: 138.198\n",
      "[129]\tvalid_0's tweedie: 138.198\n",
      "[130]\tvalid_0's tweedie: 138.198\n",
      "[131]\tvalid_0's tweedie: 138.198\n",
      "[132]\tvalid_0's tweedie: 138.198\n",
      "[133]\tvalid_0's tweedie: 138.198\n",
      "[134]\tvalid_0's tweedie: 138.198\n",
      "[135]\tvalid_0's tweedie: 138.198\n",
      "[136]\tvalid_0's tweedie: 138.198\n",
      "[137]\tvalid_0's tweedie: 138.198\n",
      "[138]\tvalid_0's tweedie: 138.198\n",
      "[139]\tvalid_0's tweedie: 138.198\n",
      "[140]\tvalid_0's tweedie: 138.197\n",
      "[141]\tvalid_0's tweedie: 138.197\n",
      "[142]\tvalid_0's tweedie: 138.197\n",
      "[143]\tvalid_0's tweedie: 138.197\n",
      "[144]\tvalid_0's tweedie: 138.197\n",
      "[145]\tvalid_0's tweedie: 138.197\n",
      "[146]\tvalid_0's tweedie: 138.197\n",
      "[147]\tvalid_0's tweedie: 138.197\n",
      "[148]\tvalid_0's tweedie: 138.197\n",
      "[149]\tvalid_0's tweedie: 138.197\n",
      "[150]\tvalid_0's tweedie: 138.197\n",
      "[151]\tvalid_0's tweedie: 138.197\n",
      "[152]\tvalid_0's tweedie: 138.197\n",
      "[153]\tvalid_0's tweedie: 138.197\n",
      "[154]\tvalid_0's tweedie: 138.196\n",
      "[155]\tvalid_0's tweedie: 138.196\n",
      "[156]\tvalid_0's tweedie: 138.196\n",
      "[157]\tvalid_0's tweedie: 138.196\n",
      "[158]\tvalid_0's tweedie: 138.196\n",
      "[159]\tvalid_0's tweedie: 138.196\n",
      "[160]\tvalid_0's tweedie: 138.196\n",
      "[161]\tvalid_0's tweedie: 138.196\n",
      "[162]\tvalid_0's tweedie: 138.196\n",
      "[163]\tvalid_0's tweedie: 138.196\n",
      "[164]\tvalid_0's tweedie: 138.196\n",
      "[165]\tvalid_0's tweedie: 138.195\n",
      "[166]\tvalid_0's tweedie: 138.195\n",
      "[167]\tvalid_0's tweedie: 138.195\n",
      "[168]\tvalid_0's tweedie: 138.195\n",
      "[169]\tvalid_0's tweedie: 138.195\n",
      "[170]\tvalid_0's tweedie: 138.195\n",
      "[171]\tvalid_0's tweedie: 138.195\n",
      "[172]\tvalid_0's tweedie: 138.193\n",
      "[173]\tvalid_0's tweedie: 138.193\n",
      "[174]\tvalid_0's tweedie: 138.193\n",
      "[175]\tvalid_0's tweedie: 138.193\n",
      "[176]\tvalid_0's tweedie: 138.193\n",
      "[177]\tvalid_0's tweedie: 138.193\n",
      "[178]\tvalid_0's tweedie: 138.193\n",
      "[179]\tvalid_0's tweedie: 138.193\n",
      "[180]\tvalid_0's tweedie: 138.193\n",
      "[181]\tvalid_0's tweedie: 138.193\n",
      "[182]\tvalid_0's tweedie: 138.193\n",
      "[183]\tvalid_0's tweedie: 138.193\n",
      "[184]\tvalid_0's tweedie: 138.193\n",
      "[185]\tvalid_0's tweedie: 138.193\n",
      "[186]\tvalid_0's tweedie: 138.193\n",
      "[187]\tvalid_0's tweedie: 138.193\n",
      "[188]\tvalid_0's tweedie: 138.193\n",
      "[189]\tvalid_0's tweedie: 138.193\n",
      "[190]\tvalid_0's tweedie: 138.193\n",
      "[191]\tvalid_0's tweedie: 138.193\n",
      "[192]\tvalid_0's tweedie: 138.193\n",
      "[193]\tvalid_0's tweedie: 138.193\n",
      "[194]\tvalid_0's tweedie: 138.193\n",
      "[195]\tvalid_0's tweedie: 138.193\n",
      "[196]\tvalid_0's tweedie: 138.193\n",
      "[197]\tvalid_0's tweedie: 138.193\n",
      "[198]\tvalid_0's tweedie: 138.193\n",
      "[199]\tvalid_0's tweedie: 138.193\n",
      "[200]\tvalid_0's tweedie: 138.193\n",
      "[201]\tvalid_0's tweedie: 138.193\n",
      "[202]\tvalid_0's tweedie: 138.193\n",
      "[203]\tvalid_0's tweedie: 138.193\n",
      "[204]\tvalid_0's tweedie: 138.193\n",
      "[205]\tvalid_0's tweedie: 138.192\n",
      "[206]\tvalid_0's tweedie: 138.192\n",
      "[207]\tvalid_0's tweedie: 138.192\n",
      "[208]\tvalid_0's tweedie: 138.192\n",
      "[209]\tvalid_0's tweedie: 138.192\n",
      "[210]\tvalid_0's tweedie: 138.193\n",
      "[211]\tvalid_0's tweedie: 138.193\n",
      "[212]\tvalid_0's tweedie: 138.192\n",
      "[213]\tvalid_0's tweedie: 138.192\n",
      "[214]\tvalid_0's tweedie: 138.192\n",
      "[215]\tvalid_0's tweedie: 138.192\n",
      "[216]\tvalid_0's tweedie: 138.192\n",
      "[217]\tvalid_0's tweedie: 138.192\n",
      "[218]\tvalid_0's tweedie: 138.192\n",
      "[219]\tvalid_0's tweedie: 138.192\n",
      "[220]\tvalid_0's tweedie: 138.192\n",
      "[221]\tvalid_0's tweedie: 138.191\n",
      "[222]\tvalid_0's tweedie: 138.192\n",
      "[223]\tvalid_0's tweedie: 138.191\n",
      "[224]\tvalid_0's tweedie: 138.191\n",
      "[225]\tvalid_0's tweedie: 138.191\n",
      "[226]\tvalid_0's tweedie: 138.191\n",
      "[227]\tvalid_0's tweedie: 138.191\n",
      "[228]\tvalid_0's tweedie: 138.191\n",
      "[229]\tvalid_0's tweedie: 138.191\n",
      "[230]\tvalid_0's tweedie: 138.191\n",
      "[231]\tvalid_0's tweedie: 138.191\n",
      "[232]\tvalid_0's tweedie: 138.191\n",
      "[233]\tvalid_0's tweedie: 138.191\n",
      "[234]\tvalid_0's tweedie: 138.191\n",
      "[235]\tvalid_0's tweedie: 138.191\n",
      "[236]\tvalid_0's tweedie: 138.191\n",
      "[237]\tvalid_0's tweedie: 138.191\n",
      "[238]\tvalid_0's tweedie: 138.191\n",
      "[239]\tvalid_0's tweedie: 138.191\n",
      "[240]\tvalid_0's tweedie: 138.191\n",
      "[241]\tvalid_0's tweedie: 138.191\n",
      "[242]\tvalid_0's tweedie: 138.191\n",
      "[243]\tvalid_0's tweedie: 138.191\n",
      "[244]\tvalid_0's tweedie: 138.191\n",
      "[245]\tvalid_0's tweedie: 138.191\n",
      "[246]\tvalid_0's tweedie: 138.191\n",
      "[247]\tvalid_0's tweedie: 138.191\n",
      "[248]\tvalid_0's tweedie: 138.19\n",
      "[249]\tvalid_0's tweedie: 138.19\n",
      "[250]\tvalid_0's tweedie: 138.19\n",
      "[251]\tvalid_0's tweedie: 138.19\n",
      "[252]\tvalid_0's tweedie: 138.19\n",
      "[253]\tvalid_0's tweedie: 138.19\n",
      "[254]\tvalid_0's tweedie: 138.19\n",
      "[255]\tvalid_0's tweedie: 138.19\n",
      "[256]\tvalid_0's tweedie: 138.189\n",
      "[257]\tvalid_0's tweedie: 138.189\n",
      "[258]\tvalid_0's tweedie: 138.189\n",
      "[259]\tvalid_0's tweedie: 138.19\n",
      "[260]\tvalid_0's tweedie: 138.19\n",
      "[261]\tvalid_0's tweedie: 138.189\n",
      "[262]\tvalid_0's tweedie: 138.189\n",
      "[263]\tvalid_0's tweedie: 138.189\n",
      "[264]\tvalid_0's tweedie: 138.189\n",
      "[265]\tvalid_0's tweedie: 138.189\n",
      "[266]\tvalid_0's tweedie: 138.188\n",
      "[267]\tvalid_0's tweedie: 138.188\n",
      "[268]\tvalid_0's tweedie: 138.188\n",
      "[269]\tvalid_0's tweedie: 138.188\n",
      "[270]\tvalid_0's tweedie: 138.188\n",
      "[271]\tvalid_0's tweedie: 138.188\n",
      "[272]\tvalid_0's tweedie: 138.188\n",
      "[273]\tvalid_0's tweedie: 138.188\n",
      "[274]\tvalid_0's tweedie: 138.188\n",
      "[275]\tvalid_0's tweedie: 138.188\n",
      "[276]\tvalid_0's tweedie: 138.188\n",
      "[277]\tvalid_0's tweedie: 138.188\n",
      "[278]\tvalid_0's tweedie: 138.188\n",
      "[279]\tvalid_0's tweedie: 138.188\n",
      "[280]\tvalid_0's tweedie: 138.188\n",
      "[281]\tvalid_0's tweedie: 138.188\n",
      "[282]\tvalid_0's tweedie: 138.188\n",
      "[283]\tvalid_0's tweedie: 138.188\n",
      "[284]\tvalid_0's tweedie: 138.188\n",
      "[285]\tvalid_0's tweedie: 138.188\n",
      "[286]\tvalid_0's tweedie: 138.188\n",
      "[287]\tvalid_0's tweedie: 138.188\n",
      "[288]\tvalid_0's tweedie: 138.188\n",
      "[289]\tvalid_0's tweedie: 138.188\n",
      "[290]\tvalid_0's tweedie: 138.188\n",
      "[291]\tvalid_0's tweedie: 138.188\n",
      "[292]\tvalid_0's tweedie: 138.188\n",
      "[293]\tvalid_0's tweedie: 138.188\n",
      "[294]\tvalid_0's tweedie: 138.188\n",
      "[295]\tvalid_0's tweedie: 138.188\n",
      "[296]\tvalid_0's tweedie: 138.188\n",
      "[297]\tvalid_0's tweedie: 138.188\n",
      "[298]\tvalid_0's tweedie: 138.187\n",
      "[299]\tvalid_0's tweedie: 138.187\n",
      "[300]\tvalid_0's tweedie: 138.188\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 138.187\n",
      "Training model for level 8 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5509\n",
      "[LightGBM] [Info] Number of data points in the train set: 55800, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.042372\n",
      "[1]\tvalid_0's tweedie: 148.768\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.936\n",
      "[3]\tvalid_0's tweedie: 145.434\n",
      "[4]\tvalid_0's tweedie: 144.179\n",
      "[5]\tvalid_0's tweedie: 143.146\n",
      "[6]\tvalid_0's tweedie: 142.281\n",
      "[7]\tvalid_0's tweedie: 141.578\n",
      "[8]\tvalid_0's tweedie: 141.001\n",
      "[9]\tvalid_0's tweedie: 140.526\n",
      "[10]\tvalid_0's tweedie: 140.129\n",
      "[11]\tvalid_0's tweedie: 139.807\n",
      "[12]\tvalid_0's tweedie: 139.541\n",
      "[13]\tvalid_0's tweedie: 139.321\n",
      "[14]\tvalid_0's tweedie: 139.138\n",
      "[15]\tvalid_0's tweedie: 138.985\n",
      "[16]\tvalid_0's tweedie: 138.858\n",
      "[17]\tvalid_0's tweedie: 138.756\n",
      "[18]\tvalid_0's tweedie: 138.669\n",
      "[19]\tvalid_0's tweedie: 138.596\n",
      "[20]\tvalid_0's tweedie: 138.54\n",
      "[21]\tvalid_0's tweedie: 138.49\n",
      "[22]\tvalid_0's tweedie: 138.451\n",
      "[23]\tvalid_0's tweedie: 138.416\n",
      "[24]\tvalid_0's tweedie: 138.392\n",
      "[25]\tvalid_0's tweedie: 138.368\n",
      "[26]\tvalid_0's tweedie: 138.35\n",
      "[27]\tvalid_0's tweedie: 138.336\n",
      "[28]\tvalid_0's tweedie: 138.324\n",
      "[29]\tvalid_0's tweedie: 138.313\n",
      "[30]\tvalid_0's tweedie: 138.303\n",
      "[31]\tvalid_0's tweedie: 138.293\n",
      "[32]\tvalid_0's tweedie: 138.288\n",
      "[33]\tvalid_0's tweedie: 138.282\n",
      "[34]\tvalid_0's tweedie: 138.277\n",
      "[35]\tvalid_0's tweedie: 138.274\n",
      "[36]\tvalid_0's tweedie: 138.27\n",
      "[37]\tvalid_0's tweedie: 138.266\n",
      "[38]\tvalid_0's tweedie: 138.263\n",
      "[39]\tvalid_0's tweedie: 138.261\n",
      "[40]\tvalid_0's tweedie: 138.26\n",
      "[41]\tvalid_0's tweedie: 138.258\n",
      "[42]\tvalid_0's tweedie: 138.259\n",
      "[43]\tvalid_0's tweedie: 138.257\n",
      "[44]\tvalid_0's tweedie: 138.255\n",
      "[45]\tvalid_0's tweedie: 138.253\n",
      "[46]\tvalid_0's tweedie: 138.252\n",
      "[47]\tvalid_0's tweedie: 138.251\n",
      "[48]\tvalid_0's tweedie: 138.248\n",
      "[49]\tvalid_0's tweedie: 138.249\n",
      "[50]\tvalid_0's tweedie: 138.248\n",
      "[51]\tvalid_0's tweedie: 138.246\n",
      "[52]\tvalid_0's tweedie: 138.244\n",
      "[53]\tvalid_0's tweedie: 138.24\n",
      "[54]\tvalid_0's tweedie: 138.239\n",
      "[55]\tvalid_0's tweedie: 138.237\n",
      "[56]\tvalid_0's tweedie: 138.236\n",
      "[57]\tvalid_0's tweedie: 138.237\n",
      "[58]\tvalid_0's tweedie: 138.236\n",
      "[59]\tvalid_0's tweedie: 138.236\n",
      "[60]\tvalid_0's tweedie: 138.236\n",
      "[61]\tvalid_0's tweedie: 138.236\n",
      "[62]\tvalid_0's tweedie: 138.235\n",
      "[63]\tvalid_0's tweedie: 138.234\n",
      "[64]\tvalid_0's tweedie: 138.234\n",
      "[65]\tvalid_0's tweedie: 138.234\n",
      "[66]\tvalid_0's tweedie: 138.234\n",
      "[67]\tvalid_0's tweedie: 138.234\n",
      "[68]\tvalid_0's tweedie: 138.233\n",
      "[69]\tvalid_0's tweedie: 138.233\n",
      "[70]\tvalid_0's tweedie: 138.232\n",
      "[71]\tvalid_0's tweedie: 138.232\n",
      "[72]\tvalid_0's tweedie: 138.232\n",
      "[73]\tvalid_0's tweedie: 138.231\n",
      "[74]\tvalid_0's tweedie: 138.231\n",
      "[75]\tvalid_0's tweedie: 138.23\n",
      "[76]\tvalid_0's tweedie: 138.23\n",
      "[77]\tvalid_0's tweedie: 138.229\n",
      "[78]\tvalid_0's tweedie: 138.229\n",
      "[79]\tvalid_0's tweedie: 138.229\n",
      "[80]\tvalid_0's tweedie: 138.229\n",
      "[81]\tvalid_0's tweedie: 138.228\n",
      "[82]\tvalid_0's tweedie: 138.228\n",
      "[83]\tvalid_0's tweedie: 138.227\n",
      "[84]\tvalid_0's tweedie: 138.227\n",
      "[85]\tvalid_0's tweedie: 138.228\n",
      "[86]\tvalid_0's tweedie: 138.222\n",
      "[87]\tvalid_0's tweedie: 138.222\n",
      "[88]\tvalid_0's tweedie: 138.223\n",
      "[89]\tvalid_0's tweedie: 138.222\n",
      "[90]\tvalid_0's tweedie: 138.222\n",
      "[91]\tvalid_0's tweedie: 138.222\n",
      "[92]\tvalid_0's tweedie: 138.222\n",
      "[93]\tvalid_0's tweedie: 138.222\n",
      "[94]\tvalid_0's tweedie: 138.222\n",
      "[95]\tvalid_0's tweedie: 138.221\n",
      "[96]\tvalid_0's tweedie: 138.221\n",
      "[97]\tvalid_0's tweedie: 138.221\n",
      "[98]\tvalid_0's tweedie: 138.222\n",
      "[99]\tvalid_0's tweedie: 138.221\n",
      "[100]\tvalid_0's tweedie: 138.217\n",
      "[101]\tvalid_0's tweedie: 138.214\n",
      "[102]\tvalid_0's tweedie: 138.214\n",
      "[103]\tvalid_0's tweedie: 138.214\n",
      "[104]\tvalid_0's tweedie: 138.213\n",
      "[105]\tvalid_0's tweedie: 138.213\n",
      "[106]\tvalid_0's tweedie: 138.213\n",
      "[107]\tvalid_0's tweedie: 138.213\n",
      "[108]\tvalid_0's tweedie: 138.213\n",
      "[109]\tvalid_0's tweedie: 138.213\n",
      "[110]\tvalid_0's tweedie: 138.212\n",
      "[111]\tvalid_0's tweedie: 138.212\n",
      "[112]\tvalid_0's tweedie: 138.212\n",
      "[113]\tvalid_0's tweedie: 138.212\n",
      "[114]\tvalid_0's tweedie: 138.212\n",
      "[115]\tvalid_0's tweedie: 138.212\n",
      "[116]\tvalid_0's tweedie: 138.212\n",
      "[117]\tvalid_0's tweedie: 138.212\n",
      "[118]\tvalid_0's tweedie: 138.212\n",
      "[119]\tvalid_0's tweedie: 138.212\n",
      "[120]\tvalid_0's tweedie: 138.211\n",
      "[121]\tvalid_0's tweedie: 138.211\n",
      "[122]\tvalid_0's tweedie: 138.211\n",
      "[123]\tvalid_0's tweedie: 138.211\n",
      "[124]\tvalid_0's tweedie: 138.209\n",
      "[125]\tvalid_0's tweedie: 138.209\n",
      "[126]\tvalid_0's tweedie: 138.209\n",
      "[127]\tvalid_0's tweedie: 138.209\n",
      "[128]\tvalid_0's tweedie: 138.209\n",
      "[129]\tvalid_0's tweedie: 138.209\n",
      "[130]\tvalid_0's tweedie: 138.209\n",
      "[131]\tvalid_0's tweedie: 138.209\n",
      "[132]\tvalid_0's tweedie: 138.209\n",
      "[133]\tvalid_0's tweedie: 138.209\n",
      "[134]\tvalid_0's tweedie: 138.209\n",
      "[135]\tvalid_0's tweedie: 138.208\n",
      "[136]\tvalid_0's tweedie: 138.208\n",
      "[137]\tvalid_0's tweedie: 138.208\n",
      "[138]\tvalid_0's tweedie: 138.208\n",
      "[139]\tvalid_0's tweedie: 138.207\n",
      "[140]\tvalid_0's tweedie: 138.207\n",
      "[141]\tvalid_0's tweedie: 138.207\n",
      "[142]\tvalid_0's tweedie: 138.207\n",
      "[143]\tvalid_0's tweedie: 138.207\n",
      "[144]\tvalid_0's tweedie: 138.207\n",
      "[145]\tvalid_0's tweedie: 138.207\n",
      "[146]\tvalid_0's tweedie: 138.205\n",
      "[147]\tvalid_0's tweedie: 138.205\n",
      "[148]\tvalid_0's tweedie: 138.205\n",
      "[149]\tvalid_0's tweedie: 138.205\n",
      "[150]\tvalid_0's tweedie: 138.205\n",
      "[151]\tvalid_0's tweedie: 138.204\n",
      "[152]\tvalid_0's tweedie: 138.204\n",
      "[153]\tvalid_0's tweedie: 138.204\n",
      "[154]\tvalid_0's tweedie: 138.204\n",
      "[155]\tvalid_0's tweedie: 138.204\n",
      "[156]\tvalid_0's tweedie: 138.204\n",
      "[157]\tvalid_0's tweedie: 138.204\n",
      "[158]\tvalid_0's tweedie: 138.204\n",
      "[159]\tvalid_0's tweedie: 138.204\n",
      "[160]\tvalid_0's tweedie: 138.204\n",
      "[161]\tvalid_0's tweedie: 138.204\n",
      "[162]\tvalid_0's tweedie: 138.204\n",
      "[163]\tvalid_0's tweedie: 138.204\n",
      "[164]\tvalid_0's tweedie: 138.204\n",
      "[165]\tvalid_0's tweedie: 138.204\n",
      "[166]\tvalid_0's tweedie: 138.204\n",
      "[167]\tvalid_0's tweedie: 138.204\n",
      "[168]\tvalid_0's tweedie: 138.204\n",
      "[169]\tvalid_0's tweedie: 138.204\n",
      "[170]\tvalid_0's tweedie: 138.204\n",
      "[171]\tvalid_0's tweedie: 138.203\n",
      "[172]\tvalid_0's tweedie: 138.203\n",
      "[173]\tvalid_0's tweedie: 138.203\n",
      "[174]\tvalid_0's tweedie: 138.203\n",
      "[175]\tvalid_0's tweedie: 138.203\n",
      "[176]\tvalid_0's tweedie: 138.202\n",
      "[177]\tvalid_0's tweedie: 138.201\n",
      "[178]\tvalid_0's tweedie: 138.201\n",
      "[179]\tvalid_0's tweedie: 138.201\n",
      "[180]\tvalid_0's tweedie: 138.201\n",
      "[181]\tvalid_0's tweedie: 138.201\n",
      "[182]\tvalid_0's tweedie: 138.201\n",
      "[183]\tvalid_0's tweedie: 138.201\n",
      "[184]\tvalid_0's tweedie: 138.201\n",
      "[185]\tvalid_0's tweedie: 138.201\n",
      "[186]\tvalid_0's tweedie: 138.201\n",
      "[187]\tvalid_0's tweedie: 138.2\n",
      "[188]\tvalid_0's tweedie: 138.199\n",
      "[189]\tvalid_0's tweedie: 138.199\n",
      "[190]\tvalid_0's tweedie: 138.199\n",
      "[191]\tvalid_0's tweedie: 138.199\n",
      "[192]\tvalid_0's tweedie: 138.199\n",
      "[193]\tvalid_0's tweedie: 138.199\n",
      "[194]\tvalid_0's tweedie: 138.199\n",
      "[195]\tvalid_0's tweedie: 138.199\n",
      "[196]\tvalid_0's tweedie: 138.199\n",
      "[197]\tvalid_0's tweedie: 138.199\n",
      "[198]\tvalid_0's tweedie: 138.199\n",
      "[199]\tvalid_0's tweedie: 138.199\n",
      "[200]\tvalid_0's tweedie: 138.199\n",
      "[201]\tvalid_0's tweedie: 138.198\n",
      "[202]\tvalid_0's tweedie: 138.198\n",
      "[203]\tvalid_0's tweedie: 138.198\n",
      "[204]\tvalid_0's tweedie: 138.198\n",
      "[205]\tvalid_0's tweedie: 138.198\n",
      "[206]\tvalid_0's tweedie: 138.198\n",
      "[207]\tvalid_0's tweedie: 138.198\n",
      "[208]\tvalid_0's tweedie: 138.198\n",
      "[209]\tvalid_0's tweedie: 138.198\n",
      "[210]\tvalid_0's tweedie: 138.198\n",
      "[211]\tvalid_0's tweedie: 138.198\n",
      "[212]\tvalid_0's tweedie: 138.198\n",
      "[213]\tvalid_0's tweedie: 138.198\n",
      "[214]\tvalid_0's tweedie: 138.198\n",
      "[215]\tvalid_0's tweedie: 138.198\n",
      "[216]\tvalid_0's tweedie: 138.198\n",
      "[217]\tvalid_0's tweedie: 138.198\n",
      "[218]\tvalid_0's tweedie: 138.198\n",
      "[219]\tvalid_0's tweedie: 138.198\n",
      "[220]\tvalid_0's tweedie: 138.198\n",
      "[221]\tvalid_0's tweedie: 138.198\n",
      "[222]\tvalid_0's tweedie: 138.198\n",
      "[223]\tvalid_0's tweedie: 138.198\n",
      "[224]\tvalid_0's tweedie: 138.198\n",
      "[225]\tvalid_0's tweedie: 138.198\n",
      "[226]\tvalid_0's tweedie: 138.198\n",
      "[227]\tvalid_0's tweedie: 138.198\n",
      "[228]\tvalid_0's tweedie: 138.198\n",
      "[229]\tvalid_0's tweedie: 138.198\n",
      "[230]\tvalid_0's tweedie: 138.198\n",
      "[231]\tvalid_0's tweedie: 138.198\n",
      "[232]\tvalid_0's tweedie: 138.198\n",
      "[233]\tvalid_0's tweedie: 138.197\n",
      "[234]\tvalid_0's tweedie: 138.197\n",
      "[235]\tvalid_0's tweedie: 138.197\n",
      "[236]\tvalid_0's tweedie: 138.197\n",
      "[237]\tvalid_0's tweedie: 138.197\n",
      "[238]\tvalid_0's tweedie: 138.197\n",
      "[239]\tvalid_0's tweedie: 138.196\n",
      "[240]\tvalid_0's tweedie: 138.196\n",
      "[241]\tvalid_0's tweedie: 138.196\n",
      "[242]\tvalid_0's tweedie: 138.196\n",
      "[243]\tvalid_0's tweedie: 138.196\n",
      "[244]\tvalid_0's tweedie: 138.196\n",
      "[245]\tvalid_0's tweedie: 138.196\n",
      "[246]\tvalid_0's tweedie: 138.196\n",
      "[247]\tvalid_0's tweedie: 138.196\n",
      "[248]\tvalid_0's tweedie: 138.196\n",
      "[249]\tvalid_0's tweedie: 138.196\n",
      "[250]\tvalid_0's tweedie: 138.196\n",
      "[251]\tvalid_0's tweedie: 138.196\n",
      "[252]\tvalid_0's tweedie: 138.196\n",
      "[253]\tvalid_0's tweedie: 138.196\n",
      "[254]\tvalid_0's tweedie: 138.195\n",
      "[255]\tvalid_0's tweedie: 138.195\n",
      "[256]\tvalid_0's tweedie: 138.195\n",
      "[257]\tvalid_0's tweedie: 138.196\n",
      "[258]\tvalid_0's tweedie: 138.196\n",
      "[259]\tvalid_0's tweedie: 138.196\n",
      "[260]\tvalid_0's tweedie: 138.196\n",
      "[261]\tvalid_0's tweedie: 138.196\n",
      "[262]\tvalid_0's tweedie: 138.196\n",
      "[263]\tvalid_0's tweedie: 138.196\n",
      "[264]\tvalid_0's tweedie: 138.196\n",
      "[265]\tvalid_0's tweedie: 138.196\n",
      "[266]\tvalid_0's tweedie: 138.196\n",
      "[267]\tvalid_0's tweedie: 138.196\n",
      "[268]\tvalid_0's tweedie: 138.195\n",
      "[269]\tvalid_0's tweedie: 138.195\n",
      "[270]\tvalid_0's tweedie: 138.195\n",
      "[271]\tvalid_0's tweedie: 138.195\n",
      "[272]\tvalid_0's tweedie: 138.195\n",
      "[273]\tvalid_0's tweedie: 138.195\n",
      "[274]\tvalid_0's tweedie: 138.195\n",
      "[275]\tvalid_0's tweedie: 138.195\n",
      "[276]\tvalid_0's tweedie: 138.195\n",
      "[277]\tvalid_0's tweedie: 138.195\n",
      "[278]\tvalid_0's tweedie: 138.195\n",
      "[279]\tvalid_0's tweedie: 138.195\n",
      "[280]\tvalid_0's tweedie: 138.195\n",
      "[281]\tvalid_0's tweedie: 138.195\n",
      "[282]\tvalid_0's tweedie: 138.195\n",
      "[283]\tvalid_0's tweedie: 138.195\n",
      "[284]\tvalid_0's tweedie: 138.195\n",
      "[285]\tvalid_0's tweedie: 138.195\n",
      "[286]\tvalid_0's tweedie: 138.195\n",
      "[287]\tvalid_0's tweedie: 138.195\n",
      "[288]\tvalid_0's tweedie: 138.194\n",
      "[289]\tvalid_0's tweedie: 138.194\n",
      "[290]\tvalid_0's tweedie: 138.194\n",
      "[291]\tvalid_0's tweedie: 138.195\n",
      "[292]\tvalid_0's tweedie: 138.195\n",
      "[293]\tvalid_0's tweedie: 138.195\n",
      "[294]\tvalid_0's tweedie: 138.195\n",
      "[295]\tvalid_0's tweedie: 138.195\n",
      "[296]\tvalid_0's tweedie: 138.195\n",
      "[297]\tvalid_0's tweedie: 138.195\n",
      "[298]\tvalid_0's tweedie: 138.195\n",
      "[299]\tvalid_0's tweedie: 138.195\n",
      "[300]\tvalid_0's tweedie: 138.195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[290]\tvalid_0's tweedie: 138.194\n",
      "Training model for level 8 and step 13\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/13/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5508\n",
      "[LightGBM] [Info] Number of data points in the train set: 55770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.042584\n",
      "[1]\tvalid_0's tweedie: 148.764\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.934\n",
      "[3]\tvalid_0's tweedie: 145.431\n",
      "[4]\tvalid_0's tweedie: 144.174\n",
      "[5]\tvalid_0's tweedie: 143.139\n",
      "[6]\tvalid_0's tweedie: 142.28\n",
      "[7]\tvalid_0's tweedie: 141.554\n",
      "[8]\tvalid_0's tweedie: 140.98\n",
      "[9]\tvalid_0's tweedie: 140.509\n",
      "[10]\tvalid_0's tweedie: 140.122\n",
      "[11]\tvalid_0's tweedie: 139.797\n",
      "[12]\tvalid_0's tweedie: 139.531\n",
      "[13]\tvalid_0's tweedie: 139.309\n",
      "[14]\tvalid_0's tweedie: 139.13\n",
      "[15]\tvalid_0's tweedie: 138.977\n",
      "[16]\tvalid_0's tweedie: 138.857\n",
      "[17]\tvalid_0's tweedie: 138.756\n",
      "[18]\tvalid_0's tweedie: 138.663\n",
      "[19]\tvalid_0's tweedie: 138.591\n",
      "[20]\tvalid_0's tweedie: 138.528\n",
      "[21]\tvalid_0's tweedie: 138.478\n",
      "[22]\tvalid_0's tweedie: 138.438\n",
      "[23]\tvalid_0's tweedie: 138.404\n",
      "[24]\tvalid_0's tweedie: 138.38\n",
      "[25]\tvalid_0's tweedie: 138.359\n",
      "[26]\tvalid_0's tweedie: 138.34\n",
      "[27]\tvalid_0's tweedie: 138.322\n",
      "[28]\tvalid_0's tweedie: 138.31\n",
      "[29]\tvalid_0's tweedie: 138.298\n",
      "[30]\tvalid_0's tweedie: 138.288\n",
      "[31]\tvalid_0's tweedie: 138.282\n",
      "[32]\tvalid_0's tweedie: 138.274\n",
      "[33]\tvalid_0's tweedie: 138.268\n",
      "[34]\tvalid_0's tweedie: 138.263\n",
      "[35]\tvalid_0's tweedie: 138.258\n",
      "[36]\tvalid_0's tweedie: 138.254\n",
      "[37]\tvalid_0's tweedie: 138.251\n",
      "[38]\tvalid_0's tweedie: 138.25\n",
      "[39]\tvalid_0's tweedie: 138.248\n",
      "[40]\tvalid_0's tweedie: 138.244\n",
      "[41]\tvalid_0's tweedie: 138.243\n",
      "[42]\tvalid_0's tweedie: 138.242\n",
      "[43]\tvalid_0's tweedie: 138.239\n",
      "[44]\tvalid_0's tweedie: 138.237\n",
      "[45]\tvalid_0's tweedie: 138.235\n",
      "[46]\tvalid_0's tweedie: 138.234\n",
      "[47]\tvalid_0's tweedie: 138.233\n",
      "[48]\tvalid_0's tweedie: 138.234\n",
      "[49]\tvalid_0's tweedie: 138.228\n",
      "[50]\tvalid_0's tweedie: 138.227\n",
      "[51]\tvalid_0's tweedie: 138.226\n",
      "[52]\tvalid_0's tweedie: 138.227\n",
      "[53]\tvalid_0's tweedie: 138.226\n",
      "[54]\tvalid_0's tweedie: 138.226\n",
      "[55]\tvalid_0's tweedie: 138.225\n",
      "[56]\tvalid_0's tweedie: 138.224\n",
      "[57]\tvalid_0's tweedie: 138.223\n",
      "[58]\tvalid_0's tweedie: 138.223\n",
      "[59]\tvalid_0's tweedie: 138.223\n",
      "[60]\tvalid_0's tweedie: 138.223\n",
      "[61]\tvalid_0's tweedie: 138.224\n",
      "[62]\tvalid_0's tweedie: 138.223\n",
      "[63]\tvalid_0's tweedie: 138.221\n",
      "[64]\tvalid_0's tweedie: 138.22\n",
      "[65]\tvalid_0's tweedie: 138.22\n",
      "[66]\tvalid_0's tweedie: 138.22\n",
      "[67]\tvalid_0's tweedie: 138.219\n",
      "[68]\tvalid_0's tweedie: 138.219\n",
      "[69]\tvalid_0's tweedie: 138.217\n",
      "[70]\tvalid_0's tweedie: 138.214\n",
      "[71]\tvalid_0's tweedie: 138.213\n",
      "[72]\tvalid_0's tweedie: 138.213\n",
      "[73]\tvalid_0's tweedie: 138.214\n",
      "[74]\tvalid_0's tweedie: 138.213\n",
      "[75]\tvalid_0's tweedie: 138.212\n",
      "[76]\tvalid_0's tweedie: 138.212\n",
      "[77]\tvalid_0's tweedie: 138.211\n",
      "[78]\tvalid_0's tweedie: 138.209\n",
      "[79]\tvalid_0's tweedie: 138.204\n",
      "[80]\tvalid_0's tweedie: 138.204\n",
      "[81]\tvalid_0's tweedie: 138.204\n",
      "[82]\tvalid_0's tweedie: 138.204\n",
      "[83]\tvalid_0's tweedie: 138.204\n",
      "[84]\tvalid_0's tweedie: 138.199\n",
      "[85]\tvalid_0's tweedie: 138.2\n",
      "[86]\tvalid_0's tweedie: 138.199\n",
      "[87]\tvalid_0's tweedie: 138.199\n",
      "[88]\tvalid_0's tweedie: 138.199\n",
      "[89]\tvalid_0's tweedie: 138.199\n",
      "[90]\tvalid_0's tweedie: 138.199\n",
      "[91]\tvalid_0's tweedie: 138.199\n",
      "[92]\tvalid_0's tweedie: 138.199\n",
      "[93]\tvalid_0's tweedie: 138.199\n",
      "[94]\tvalid_0's tweedie: 138.199\n",
      "[95]\tvalid_0's tweedie: 138.199\n",
      "[96]\tvalid_0's tweedie: 138.198\n",
      "[97]\tvalid_0's tweedie: 138.199\n",
      "[98]\tvalid_0's tweedie: 138.198\n",
      "[99]\tvalid_0's tweedie: 138.198\n",
      "[100]\tvalid_0's tweedie: 138.198\n",
      "[101]\tvalid_0's tweedie: 138.198\n",
      "[102]\tvalid_0's tweedie: 138.197\n",
      "[103]\tvalid_0's tweedie: 138.197\n",
      "[104]\tvalid_0's tweedie: 138.194\n",
      "[105]\tvalid_0's tweedie: 138.194\n",
      "[106]\tvalid_0's tweedie: 138.194\n",
      "[107]\tvalid_0's tweedie: 138.194\n",
      "[108]\tvalid_0's tweedie: 138.194\n",
      "[109]\tvalid_0's tweedie: 138.193\n",
      "[110]\tvalid_0's tweedie: 138.194\n",
      "[111]\tvalid_0's tweedie: 138.194\n",
      "[112]\tvalid_0's tweedie: 138.193\n",
      "[113]\tvalid_0's tweedie: 138.193\n",
      "[114]\tvalid_0's tweedie: 138.191\n",
      "[115]\tvalid_0's tweedie: 138.191\n",
      "[116]\tvalid_0's tweedie: 138.19\n",
      "[117]\tvalid_0's tweedie: 138.19\n",
      "[118]\tvalid_0's tweedie: 138.19\n",
      "[119]\tvalid_0's tweedie: 138.191\n",
      "[120]\tvalid_0's tweedie: 138.19\n",
      "[121]\tvalid_0's tweedie: 138.19\n",
      "[122]\tvalid_0's tweedie: 138.19\n",
      "[123]\tvalid_0's tweedie: 138.189\n",
      "[124]\tvalid_0's tweedie: 138.189\n",
      "[125]\tvalid_0's tweedie: 138.189\n",
      "[126]\tvalid_0's tweedie: 138.189\n",
      "[127]\tvalid_0's tweedie: 138.189\n",
      "[128]\tvalid_0's tweedie: 138.189\n",
      "[129]\tvalid_0's tweedie: 138.189\n",
      "[130]\tvalid_0's tweedie: 138.189\n",
      "[131]\tvalid_0's tweedie: 138.187\n",
      "[132]\tvalid_0's tweedie: 138.187\n",
      "[133]\tvalid_0's tweedie: 138.187\n",
      "[134]\tvalid_0's tweedie: 138.187\n",
      "[135]\tvalid_0's tweedie: 138.187\n",
      "[136]\tvalid_0's tweedie: 138.187\n",
      "[137]\tvalid_0's tweedie: 138.187\n",
      "[138]\tvalid_0's tweedie: 138.187\n",
      "[139]\tvalid_0's tweedie: 138.187\n",
      "[140]\tvalid_0's tweedie: 138.187\n",
      "[141]\tvalid_0's tweedie: 138.186\n",
      "[142]\tvalid_0's tweedie: 138.184\n",
      "[143]\tvalid_0's tweedie: 138.184\n",
      "[144]\tvalid_0's tweedie: 138.184\n",
      "[145]\tvalid_0's tweedie: 138.184\n",
      "[146]\tvalid_0's tweedie: 138.184\n",
      "[147]\tvalid_0's tweedie: 138.184\n",
      "[148]\tvalid_0's tweedie: 138.184\n",
      "[149]\tvalid_0's tweedie: 138.184\n",
      "[150]\tvalid_0's tweedie: 138.184\n",
      "[151]\tvalid_0's tweedie: 138.184\n",
      "[152]\tvalid_0's tweedie: 138.184\n",
      "[153]\tvalid_0's tweedie: 138.184\n",
      "[154]\tvalid_0's tweedie: 138.182\n",
      "[155]\tvalid_0's tweedie: 138.182\n",
      "[156]\tvalid_0's tweedie: 138.182\n",
      "[157]\tvalid_0's tweedie: 138.182\n",
      "[158]\tvalid_0's tweedie: 138.182\n",
      "[159]\tvalid_0's tweedie: 138.182\n",
      "[160]\tvalid_0's tweedie: 138.182\n",
      "[161]\tvalid_0's tweedie: 138.181\n",
      "[162]\tvalid_0's tweedie: 138.182\n",
      "[163]\tvalid_0's tweedie: 138.181\n",
      "[164]\tvalid_0's tweedie: 138.181\n",
      "[165]\tvalid_0's tweedie: 138.181\n",
      "[166]\tvalid_0's tweedie: 138.181\n",
      "[167]\tvalid_0's tweedie: 138.181\n",
      "[168]\tvalid_0's tweedie: 138.181\n",
      "[169]\tvalid_0's tweedie: 138.181\n",
      "[170]\tvalid_0's tweedie: 138.181\n",
      "[171]\tvalid_0's tweedie: 138.181\n",
      "[172]\tvalid_0's tweedie: 138.181\n",
      "[173]\tvalid_0's tweedie: 138.181\n",
      "[174]\tvalid_0's tweedie: 138.181\n",
      "[175]\tvalid_0's tweedie: 138.182\n",
      "[176]\tvalid_0's tweedie: 138.182\n",
      "[177]\tvalid_0's tweedie: 138.181\n",
      "[178]\tvalid_0's tweedie: 138.181\n",
      "[179]\tvalid_0's tweedie: 138.181\n",
      "[180]\tvalid_0's tweedie: 138.181\n",
      "[181]\tvalid_0's tweedie: 138.18\n",
      "[182]\tvalid_0's tweedie: 138.18\n",
      "[183]\tvalid_0's tweedie: 138.18\n",
      "[184]\tvalid_0's tweedie: 138.18\n",
      "[185]\tvalid_0's tweedie: 138.179\n",
      "[186]\tvalid_0's tweedie: 138.179\n",
      "[187]\tvalid_0's tweedie: 138.179\n",
      "[188]\tvalid_0's tweedie: 138.179\n",
      "[189]\tvalid_0's tweedie: 138.179\n",
      "[190]\tvalid_0's tweedie: 138.179\n",
      "[191]\tvalid_0's tweedie: 138.179\n",
      "[192]\tvalid_0's tweedie: 138.179\n",
      "[193]\tvalid_0's tweedie: 138.179\n",
      "[194]\tvalid_0's tweedie: 138.18\n",
      "[195]\tvalid_0's tweedie: 138.179\n",
      "[196]\tvalid_0's tweedie: 138.179\n",
      "[197]\tvalid_0's tweedie: 138.179\n",
      "[198]\tvalid_0's tweedie: 138.179\n",
      "[199]\tvalid_0's tweedie: 138.179\n",
      "[200]\tvalid_0's tweedie: 138.179\n",
      "[201]\tvalid_0's tweedie: 138.178\n",
      "[202]\tvalid_0's tweedie: 138.178\n",
      "[203]\tvalid_0's tweedie: 138.178\n",
      "[204]\tvalid_0's tweedie: 138.177\n",
      "[205]\tvalid_0's tweedie: 138.178\n",
      "[206]\tvalid_0's tweedie: 138.177\n",
      "[207]\tvalid_0's tweedie: 138.177\n",
      "[208]\tvalid_0's tweedie: 138.177\n",
      "[209]\tvalid_0's tweedie: 138.177\n",
      "[210]\tvalid_0's tweedie: 138.177\n",
      "[211]\tvalid_0's tweedie: 138.177\n",
      "[212]\tvalid_0's tweedie: 138.177\n",
      "[213]\tvalid_0's tweedie: 138.177\n",
      "[214]\tvalid_0's tweedie: 138.177\n",
      "[215]\tvalid_0's tweedie: 138.177\n",
      "[216]\tvalid_0's tweedie: 138.177\n",
      "[217]\tvalid_0's tweedie: 138.177\n",
      "[218]\tvalid_0's tweedie: 138.177\n",
      "[219]\tvalid_0's tweedie: 138.176\n",
      "[220]\tvalid_0's tweedie: 138.176\n",
      "[221]\tvalid_0's tweedie: 138.176\n",
      "[222]\tvalid_0's tweedie: 138.176\n",
      "[223]\tvalid_0's tweedie: 138.176\n",
      "[224]\tvalid_0's tweedie: 138.176\n",
      "[225]\tvalid_0's tweedie: 138.175\n",
      "[226]\tvalid_0's tweedie: 138.175\n",
      "[227]\tvalid_0's tweedie: 138.175\n",
      "[228]\tvalid_0's tweedie: 138.175\n",
      "[229]\tvalid_0's tweedie: 138.175\n",
      "[230]\tvalid_0's tweedie: 138.175\n",
      "[231]\tvalid_0's tweedie: 138.175\n",
      "[232]\tvalid_0's tweedie: 138.175\n",
      "[233]\tvalid_0's tweedie: 138.175\n",
      "[234]\tvalid_0's tweedie: 138.176\n",
      "[235]\tvalid_0's tweedie: 138.176\n",
      "[236]\tvalid_0's tweedie: 138.176\n",
      "[237]\tvalid_0's tweedie: 138.174\n",
      "[238]\tvalid_0's tweedie: 138.174\n",
      "[239]\tvalid_0's tweedie: 138.174\n",
      "[240]\tvalid_0's tweedie: 138.174\n",
      "[241]\tvalid_0's tweedie: 138.174\n",
      "[242]\tvalid_0's tweedie: 138.174\n",
      "[243]\tvalid_0's tweedie: 138.174\n",
      "[244]\tvalid_0's tweedie: 138.174\n",
      "[245]\tvalid_0's tweedie: 138.174\n",
      "[246]\tvalid_0's tweedie: 138.175\n",
      "[247]\tvalid_0's tweedie: 138.174\n",
      "[248]\tvalid_0's tweedie: 138.174\n",
      "[249]\tvalid_0's tweedie: 138.174\n",
      "[250]\tvalid_0's tweedie: 138.174\n",
      "[251]\tvalid_0's tweedie: 138.174\n",
      "[252]\tvalid_0's tweedie: 138.174\n",
      "[253]\tvalid_0's tweedie: 138.174\n",
      "[254]\tvalid_0's tweedie: 138.174\n",
      "[255]\tvalid_0's tweedie: 138.174\n",
      "[256]\tvalid_0's tweedie: 138.174\n",
      "[257]\tvalid_0's tweedie: 138.174\n",
      "[258]\tvalid_0's tweedie: 138.174\n",
      "[259]\tvalid_0's tweedie: 138.174\n",
      "[260]\tvalid_0's tweedie: 138.174\n",
      "[261]\tvalid_0's tweedie: 138.174\n",
      "[262]\tvalid_0's tweedie: 138.174\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's tweedie: 138.174\n",
      "Training model for level 8 and step 14\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/14/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5507\n",
      "[LightGBM] [Info] Number of data points in the train set: 55740, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.042805\n",
      "[1]\tvalid_0's tweedie: 148.756\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.927\n",
      "[3]\tvalid_0's tweedie: 145.412\n",
      "[4]\tvalid_0's tweedie: 144.145\n",
      "[5]\tvalid_0's tweedie: 143.097\n",
      "[6]\tvalid_0's tweedie: 142.245\n",
      "[7]\tvalid_0's tweedie: 141.53\n",
      "[8]\tvalid_0's tweedie: 140.939\n",
      "[9]\tvalid_0's tweedie: 140.459\n",
      "[10]\tvalid_0's tweedie: 140.052\n",
      "[11]\tvalid_0's tweedie: 139.727\n",
      "[12]\tvalid_0's tweedie: 139.454\n",
      "[13]\tvalid_0's tweedie: 139.234\n",
      "[14]\tvalid_0's tweedie: 139.048\n",
      "[15]\tvalid_0's tweedie: 138.901\n",
      "[16]\tvalid_0's tweedie: 138.781\n",
      "[17]\tvalid_0's tweedie: 138.68\n",
      "[18]\tvalid_0's tweedie: 138.599\n",
      "[19]\tvalid_0's tweedie: 138.528\n",
      "[20]\tvalid_0's tweedie: 138.471\n",
      "[21]\tvalid_0's tweedie: 138.425\n",
      "[22]\tvalid_0's tweedie: 138.388\n",
      "[23]\tvalid_0's tweedie: 138.355\n",
      "[24]\tvalid_0's tweedie: 138.331\n",
      "[25]\tvalid_0's tweedie: 138.311\n",
      "[26]\tvalid_0's tweedie: 138.291\n",
      "[27]\tvalid_0's tweedie: 138.278\n",
      "[28]\tvalid_0's tweedie: 138.267\n",
      "[29]\tvalid_0's tweedie: 138.255\n",
      "[30]\tvalid_0's tweedie: 138.246\n",
      "[31]\tvalid_0's tweedie: 138.239\n",
      "[32]\tvalid_0's tweedie: 138.232\n",
      "[33]\tvalid_0's tweedie: 138.228\n",
      "[34]\tvalid_0's tweedie: 138.225\n",
      "[35]\tvalid_0's tweedie: 138.222\n",
      "[36]\tvalid_0's tweedie: 138.219\n",
      "[37]\tvalid_0's tweedie: 138.216\n",
      "[38]\tvalid_0's tweedie: 138.214\n",
      "[39]\tvalid_0's tweedie: 138.211\n",
      "[40]\tvalid_0's tweedie: 138.212\n",
      "[41]\tvalid_0's tweedie: 138.21\n",
      "[42]\tvalid_0's tweedie: 138.208\n",
      "[43]\tvalid_0's tweedie: 138.206\n",
      "[44]\tvalid_0's tweedie: 138.204\n",
      "[45]\tvalid_0's tweedie: 138.204\n",
      "[46]\tvalid_0's tweedie: 138.203\n",
      "[47]\tvalid_0's tweedie: 138.202\n",
      "[48]\tvalid_0's tweedie: 138.2\n",
      "[49]\tvalid_0's tweedie: 138.202\n",
      "[50]\tvalid_0's tweedie: 138.2\n",
      "[51]\tvalid_0's tweedie: 138.199\n",
      "[52]\tvalid_0's tweedie: 138.194\n",
      "[53]\tvalid_0's tweedie: 138.194\n",
      "[54]\tvalid_0's tweedie: 138.195\n",
      "[55]\tvalid_0's tweedie: 138.195\n",
      "[56]\tvalid_0's tweedie: 138.196\n",
      "[57]\tvalid_0's tweedie: 138.195\n",
      "[58]\tvalid_0's tweedie: 138.194\n",
      "[59]\tvalid_0's tweedie: 138.195\n",
      "[60]\tvalid_0's tweedie: 138.195\n",
      "[61]\tvalid_0's tweedie: 138.195\n",
      "[62]\tvalid_0's tweedie: 138.194\n",
      "[63]\tvalid_0's tweedie: 138.194\n",
      "[64]\tvalid_0's tweedie: 138.194\n",
      "[65]\tvalid_0's tweedie: 138.193\n",
      "[66]\tvalid_0's tweedie: 138.193\n",
      "[67]\tvalid_0's tweedie: 138.19\n",
      "[68]\tvalid_0's tweedie: 138.19\n",
      "[69]\tvalid_0's tweedie: 138.189\n",
      "[70]\tvalid_0's tweedie: 138.189\n",
      "[71]\tvalid_0's tweedie: 138.189\n",
      "[72]\tvalid_0's tweedie: 138.188\n",
      "[73]\tvalid_0's tweedie: 138.188\n",
      "[74]\tvalid_0's tweedie: 138.188\n",
      "[75]\tvalid_0's tweedie: 138.187\n",
      "[76]\tvalid_0's tweedie: 138.187\n",
      "[77]\tvalid_0's tweedie: 138.187\n",
      "[78]\tvalid_0's tweedie: 138.187\n",
      "[79]\tvalid_0's tweedie: 138.187\n",
      "[80]\tvalid_0's tweedie: 138.187\n",
      "[81]\tvalid_0's tweedie: 138.19\n",
      "[82]\tvalid_0's tweedie: 138.19\n",
      "[83]\tvalid_0's tweedie: 138.19\n",
      "[84]\tvalid_0's tweedie: 138.19\n",
      "[85]\tvalid_0's tweedie: 138.19\n",
      "[86]\tvalid_0's tweedie: 138.193\n",
      "[87]\tvalid_0's tweedie: 138.196\n",
      "[88]\tvalid_0's tweedie: 138.195\n",
      "[89]\tvalid_0's tweedie: 138.196\n",
      "[90]\tvalid_0's tweedie: 138.196\n",
      "[91]\tvalid_0's tweedie: 138.196\n",
      "[92]\tvalid_0's tweedie: 138.196\n",
      "[93]\tvalid_0's tweedie: 138.193\n",
      "[94]\tvalid_0's tweedie: 138.191\n",
      "[95]\tvalid_0's tweedie: 138.191\n",
      "[96]\tvalid_0's tweedie: 138.191\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's tweedie: 138.187\n",
      "Training model for level 8 and step 15\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/15/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5506\n",
      "[LightGBM] [Info] Number of data points in the train set: 55710, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.042990\n",
      "[1]\tvalid_0's tweedie: 148.693\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.827\n",
      "[3]\tvalid_0's tweedie: 145.264\n",
      "[4]\tvalid_0's tweedie: 143.991\n",
      "[5]\tvalid_0's tweedie: 142.934\n",
      "[6]\tvalid_0's tweedie: 142.061\n",
      "[7]\tvalid_0's tweedie: 141.358\n",
      "[8]\tvalid_0's tweedie: 140.775\n",
      "[9]\tvalid_0's tweedie: 140.31\n",
      "[10]\tvalid_0's tweedie: 139.917\n",
      "[11]\tvalid_0's tweedie: 139.602\n",
      "[12]\tvalid_0's tweedie: 139.346\n",
      "[13]\tvalid_0's tweedie: 139.139\n",
      "[14]\tvalid_0's tweedie: 138.969\n",
      "[15]\tvalid_0's tweedie: 138.828\n",
      "[16]\tvalid_0's tweedie: 138.713\n",
      "[17]\tvalid_0's tweedie: 138.621\n",
      "[18]\tvalid_0's tweedie: 138.543\n",
      "[19]\tvalid_0's tweedie: 138.481\n",
      "[20]\tvalid_0's tweedie: 138.429\n",
      "[21]\tvalid_0's tweedie: 138.388\n",
      "[22]\tvalid_0's tweedie: 138.35\n",
      "[23]\tvalid_0's tweedie: 138.322\n",
      "[24]\tvalid_0's tweedie: 138.298\n",
      "[25]\tvalid_0's tweedie: 138.277\n",
      "[26]\tvalid_0's tweedie: 138.263\n",
      "[27]\tvalid_0's tweedie: 138.251\n",
      "[28]\tvalid_0's tweedie: 138.238\n",
      "[29]\tvalid_0's tweedie: 138.231\n",
      "[30]\tvalid_0's tweedie: 138.223\n",
      "[31]\tvalid_0's tweedie: 138.215\n",
      "[32]\tvalid_0's tweedie: 138.211\n",
      "[33]\tvalid_0's tweedie: 138.207\n",
      "[34]\tvalid_0's tweedie: 138.204\n",
      "[35]\tvalid_0's tweedie: 138.201\n",
      "[36]\tvalid_0's tweedie: 138.197\n",
      "[37]\tvalid_0's tweedie: 138.195\n",
      "[38]\tvalid_0's tweedie: 138.193\n",
      "[39]\tvalid_0's tweedie: 138.191\n",
      "[40]\tvalid_0's tweedie: 138.189\n",
      "[41]\tvalid_0's tweedie: 138.189\n",
      "[42]\tvalid_0's tweedie: 138.19\n",
      "[43]\tvalid_0's tweedie: 138.188\n",
      "[44]\tvalid_0's tweedie: 138.186\n",
      "[45]\tvalid_0's tweedie: 138.185\n",
      "[46]\tvalid_0's tweedie: 138.182\n",
      "[47]\tvalid_0's tweedie: 138.182\n",
      "[48]\tvalid_0's tweedie: 138.18\n",
      "[49]\tvalid_0's tweedie: 138.179\n",
      "[50]\tvalid_0's tweedie: 138.177\n",
      "[51]\tvalid_0's tweedie: 138.178\n",
      "[52]\tvalid_0's tweedie: 138.176\n",
      "[53]\tvalid_0's tweedie: 138.177\n",
      "[54]\tvalid_0's tweedie: 138.175\n",
      "[55]\tvalid_0's tweedie: 138.174\n",
      "[56]\tvalid_0's tweedie: 138.173\n",
      "[57]\tvalid_0's tweedie: 138.173\n",
      "[58]\tvalid_0's tweedie: 138.174\n",
      "[59]\tvalid_0's tweedie: 138.173\n",
      "[60]\tvalid_0's tweedie: 138.174\n",
      "[61]\tvalid_0's tweedie: 138.174\n",
      "[62]\tvalid_0's tweedie: 138.174\n",
      "[63]\tvalid_0's tweedie: 138.174\n",
      "[64]\tvalid_0's tweedie: 138.173\n",
      "[65]\tvalid_0's tweedie: 138.174\n",
      "[66]\tvalid_0's tweedie: 138.174\n",
      "[67]\tvalid_0's tweedie: 138.173\n",
      "[68]\tvalid_0's tweedie: 138.172\n",
      "[69]\tvalid_0's tweedie: 138.173\n",
      "[70]\tvalid_0's tweedie: 138.173\n",
      "[71]\tvalid_0's tweedie: 138.172\n",
      "[72]\tvalid_0's tweedie: 138.172\n",
      "[73]\tvalid_0's tweedie: 138.172\n",
      "[74]\tvalid_0's tweedie: 138.172\n",
      "[75]\tvalid_0's tweedie: 138.172\n",
      "[76]\tvalid_0's tweedie: 138.172\n",
      "[77]\tvalid_0's tweedie: 138.171\n",
      "[78]\tvalid_0's tweedie: 138.171\n",
      "[79]\tvalid_0's tweedie: 138.171\n",
      "[80]\tvalid_0's tweedie: 138.17\n",
      "[81]\tvalid_0's tweedie: 138.17\n",
      "[82]\tvalid_0's tweedie: 138.17\n",
      "[83]\tvalid_0's tweedie: 138.17\n",
      "[84]\tvalid_0's tweedie: 138.17\n",
      "[85]\tvalid_0's tweedie: 138.169\n",
      "[86]\tvalid_0's tweedie: 138.169\n",
      "[87]\tvalid_0's tweedie: 138.169\n",
      "[88]\tvalid_0's tweedie: 138.169\n",
      "[89]\tvalid_0's tweedie: 138.169\n",
      "[90]\tvalid_0's tweedie: 138.168\n",
      "[91]\tvalid_0's tweedie: 138.168\n",
      "[92]\tvalid_0's tweedie: 138.168\n",
      "[93]\tvalid_0's tweedie: 138.168\n",
      "[94]\tvalid_0's tweedie: 138.168\n",
      "[95]\tvalid_0's tweedie: 138.166\n",
      "[96]\tvalid_0's tweedie: 138.166\n",
      "[97]\tvalid_0's tweedie: 138.166\n",
      "[98]\tvalid_0's tweedie: 138.166\n",
      "[99]\tvalid_0's tweedie: 138.166\n",
      "[100]\tvalid_0's tweedie: 138.166\n",
      "[101]\tvalid_0's tweedie: 138.165\n",
      "[102]\tvalid_0's tweedie: 138.165\n",
      "[103]\tvalid_0's tweedie: 138.165\n",
      "[104]\tvalid_0's tweedie: 138.165\n",
      "[105]\tvalid_0's tweedie: 138.165\n",
      "[106]\tvalid_0's tweedie: 138.165\n",
      "[107]\tvalid_0's tweedie: 138.164\n",
      "[108]\tvalid_0's tweedie: 138.165\n",
      "[109]\tvalid_0's tweedie: 138.165\n",
      "[110]\tvalid_0's tweedie: 138.164\n",
      "[111]\tvalid_0's tweedie: 138.164\n",
      "[112]\tvalid_0's tweedie: 138.164\n",
      "[113]\tvalid_0's tweedie: 138.164\n",
      "[114]\tvalid_0's tweedie: 138.162\n",
      "[115]\tvalid_0's tweedie: 138.162\n",
      "[116]\tvalid_0's tweedie: 138.162\n",
      "[117]\tvalid_0's tweedie: 138.162\n",
      "[118]\tvalid_0's tweedie: 138.162\n",
      "[119]\tvalid_0's tweedie: 138.162\n",
      "[120]\tvalid_0's tweedie: 138.162\n",
      "[121]\tvalid_0's tweedie: 138.161\n",
      "[122]\tvalid_0's tweedie: 138.161\n",
      "[123]\tvalid_0's tweedie: 138.161\n",
      "[124]\tvalid_0's tweedie: 138.161\n",
      "[125]\tvalid_0's tweedie: 138.161\n",
      "[126]\tvalid_0's tweedie: 138.161\n",
      "[127]\tvalid_0's tweedie: 138.16\n",
      "[128]\tvalid_0's tweedie: 138.16\n",
      "[129]\tvalid_0's tweedie: 138.16\n",
      "[130]\tvalid_0's tweedie: 138.16\n",
      "[131]\tvalid_0's tweedie: 138.16\n",
      "[132]\tvalid_0's tweedie: 138.16\n",
      "[133]\tvalid_0's tweedie: 138.159\n",
      "[134]\tvalid_0's tweedie: 138.159\n",
      "[135]\tvalid_0's tweedie: 138.159\n",
      "[136]\tvalid_0's tweedie: 138.159\n",
      "[137]\tvalid_0's tweedie: 138.159\n",
      "[138]\tvalid_0's tweedie: 138.159\n",
      "[139]\tvalid_0's tweedie: 138.159\n",
      "[140]\tvalid_0's tweedie: 138.159\n",
      "[141]\tvalid_0's tweedie: 138.159\n",
      "[142]\tvalid_0's tweedie: 138.158\n",
      "[143]\tvalid_0's tweedie: 138.158\n",
      "[144]\tvalid_0's tweedie: 138.159\n",
      "[145]\tvalid_0's tweedie: 138.159\n",
      "[146]\tvalid_0's tweedie: 138.159\n",
      "[147]\tvalid_0's tweedie: 138.159\n",
      "[148]\tvalid_0's tweedie: 138.158\n",
      "[149]\tvalid_0's tweedie: 138.158\n",
      "[150]\tvalid_0's tweedie: 138.158\n",
      "[151]\tvalid_0's tweedie: 138.158\n",
      "[152]\tvalid_0's tweedie: 138.158\n",
      "[153]\tvalid_0's tweedie: 138.157\n",
      "[154]\tvalid_0's tweedie: 138.157\n",
      "[155]\tvalid_0's tweedie: 138.157\n",
      "[156]\tvalid_0's tweedie: 138.158\n",
      "[157]\tvalid_0's tweedie: 138.157\n",
      "[158]\tvalid_0's tweedie: 138.157\n",
      "[159]\tvalid_0's tweedie: 138.157\n",
      "[160]\tvalid_0's tweedie: 138.157\n",
      "[161]\tvalid_0's tweedie: 138.157\n",
      "[162]\tvalid_0's tweedie: 138.157\n",
      "[163]\tvalid_0's tweedie: 138.157\n",
      "[164]\tvalid_0's tweedie: 138.157\n",
      "[165]\tvalid_0's tweedie: 138.157\n",
      "[166]\tvalid_0's tweedie: 138.157\n",
      "[167]\tvalid_0's tweedie: 138.157\n",
      "[168]\tvalid_0's tweedie: 138.157\n",
      "[169]\tvalid_0's tweedie: 138.157\n",
      "[170]\tvalid_0's tweedie: 138.157\n",
      "[171]\tvalid_0's tweedie: 138.157\n",
      "[172]\tvalid_0's tweedie: 138.157\n",
      "[173]\tvalid_0's tweedie: 138.157\n",
      "[174]\tvalid_0's tweedie: 138.157\n",
      "[175]\tvalid_0's tweedie: 138.157\n",
      "[176]\tvalid_0's tweedie: 138.157\n",
      "[177]\tvalid_0's tweedie: 138.157\n",
      "[178]\tvalid_0's tweedie: 138.157\n",
      "[179]\tvalid_0's tweedie: 138.157\n",
      "[180]\tvalid_0's tweedie: 138.157\n",
      "[181]\tvalid_0's tweedie: 138.157\n",
      "[182]\tvalid_0's tweedie: 138.157\n",
      "[183]\tvalid_0's tweedie: 138.157\n",
      "[184]\tvalid_0's tweedie: 138.157\n",
      "[185]\tvalid_0's tweedie: 138.157\n",
      "[186]\tvalid_0's tweedie: 138.157\n",
      "[187]\tvalid_0's tweedie: 138.154\n",
      "[188]\tvalid_0's tweedie: 138.154\n",
      "[189]\tvalid_0's tweedie: 138.154\n",
      "[190]\tvalid_0's tweedie: 138.154\n",
      "[191]\tvalid_0's tweedie: 138.154\n",
      "[192]\tvalid_0's tweedie: 138.154\n",
      "[193]\tvalid_0's tweedie: 138.154\n",
      "[194]\tvalid_0's tweedie: 138.154\n",
      "[195]\tvalid_0's tweedie: 138.154\n",
      "[196]\tvalid_0's tweedie: 138.154\n",
      "[197]\tvalid_0's tweedie: 138.154\n",
      "[198]\tvalid_0's tweedie: 138.154\n",
      "[199]\tvalid_0's tweedie: 138.154\n",
      "[200]\tvalid_0's tweedie: 138.154\n",
      "[201]\tvalid_0's tweedie: 138.154\n",
      "[202]\tvalid_0's tweedie: 138.154\n",
      "[203]\tvalid_0's tweedie: 138.154\n",
      "[204]\tvalid_0's tweedie: 138.154\n",
      "[205]\tvalid_0's tweedie: 138.154\n",
      "[206]\tvalid_0's tweedie: 138.154\n",
      "[207]\tvalid_0's tweedie: 138.153\n",
      "[208]\tvalid_0's tweedie: 138.153\n",
      "[209]\tvalid_0's tweedie: 138.153\n",
      "[210]\tvalid_0's tweedie: 138.153\n",
      "[211]\tvalid_0's tweedie: 138.153\n",
      "[212]\tvalid_0's tweedie: 138.153\n",
      "[213]\tvalid_0's tweedie: 138.153\n",
      "[214]\tvalid_0's tweedie: 138.153\n",
      "[215]\tvalid_0's tweedie: 138.153\n",
      "[216]\tvalid_0's tweedie: 138.153\n",
      "[217]\tvalid_0's tweedie: 138.152\n",
      "[218]\tvalid_0's tweedie: 138.153\n",
      "[219]\tvalid_0's tweedie: 138.153\n",
      "[220]\tvalid_0's tweedie: 138.153\n",
      "[221]\tvalid_0's tweedie: 138.153\n",
      "[222]\tvalid_0's tweedie: 138.153\n",
      "[223]\tvalid_0's tweedie: 138.153\n",
      "[224]\tvalid_0's tweedie: 138.153\n",
      "[225]\tvalid_0's tweedie: 138.153\n",
      "[226]\tvalid_0's tweedie: 138.153\n",
      "[227]\tvalid_0's tweedie: 138.152\n",
      "[228]\tvalid_0's tweedie: 138.152\n",
      "[229]\tvalid_0's tweedie: 138.152\n",
      "[230]\tvalid_0's tweedie: 138.152\n",
      "[231]\tvalid_0's tweedie: 138.152\n",
      "[232]\tvalid_0's tweedie: 138.152\n",
      "[233]\tvalid_0's tweedie: 138.152\n",
      "[234]\tvalid_0's tweedie: 138.152\n",
      "[235]\tvalid_0's tweedie: 138.152\n",
      "[236]\tvalid_0's tweedie: 138.152\n",
      "[237]\tvalid_0's tweedie: 138.152\n",
      "[238]\tvalid_0's tweedie: 138.152\n",
      "[239]\tvalid_0's tweedie: 138.152\n",
      "[240]\tvalid_0's tweedie: 138.152\n",
      "[241]\tvalid_0's tweedie: 138.152\n",
      "[242]\tvalid_0's tweedie: 138.152\n",
      "[243]\tvalid_0's tweedie: 138.152\n",
      "[244]\tvalid_0's tweedie: 138.152\n",
      "[245]\tvalid_0's tweedie: 138.152\n",
      "[246]\tvalid_0's tweedie: 138.152\n",
      "[247]\tvalid_0's tweedie: 138.152\n",
      "[248]\tvalid_0's tweedie: 138.152\n",
      "[249]\tvalid_0's tweedie: 138.152\n",
      "[250]\tvalid_0's tweedie: 138.152\n",
      "[251]\tvalid_0's tweedie: 138.152\n",
      "[252]\tvalid_0's tweedie: 138.152\n",
      "[253]\tvalid_0's tweedie: 138.152\n",
      "[254]\tvalid_0's tweedie: 138.152\n",
      "[255]\tvalid_0's tweedie: 138.152\n",
      "[256]\tvalid_0's tweedie: 138.151\n",
      "[257]\tvalid_0's tweedie: 138.151\n",
      "[258]\tvalid_0's tweedie: 138.151\n",
      "[259]\tvalid_0's tweedie: 138.151\n",
      "[260]\tvalid_0's tweedie: 138.151\n",
      "[261]\tvalid_0's tweedie: 138.151\n",
      "[262]\tvalid_0's tweedie: 138.151\n",
      "[263]\tvalid_0's tweedie: 138.151\n",
      "[264]\tvalid_0's tweedie: 138.151\n",
      "[265]\tvalid_0's tweedie: 138.151\n",
      "[266]\tvalid_0's tweedie: 138.151\n",
      "[267]\tvalid_0's tweedie: 138.151\n",
      "[268]\tvalid_0's tweedie: 138.151\n",
      "[269]\tvalid_0's tweedie: 138.151\n",
      "[270]\tvalid_0's tweedie: 138.15\n",
      "[271]\tvalid_0's tweedie: 138.15\n",
      "[272]\tvalid_0's tweedie: 138.15\n",
      "[273]\tvalid_0's tweedie: 138.15\n",
      "[274]\tvalid_0's tweedie: 138.15\n",
      "[275]\tvalid_0's tweedie: 138.15\n",
      "[276]\tvalid_0's tweedie: 138.15\n",
      "[277]\tvalid_0's tweedie: 138.151\n",
      "[278]\tvalid_0's tweedie: 138.15\n",
      "[279]\tvalid_0's tweedie: 138.151\n",
      "[280]\tvalid_0's tweedie: 138.151\n",
      "[281]\tvalid_0's tweedie: 138.151\n",
      "[282]\tvalid_0's tweedie: 138.15\n",
      "[283]\tvalid_0's tweedie: 138.15\n",
      "[284]\tvalid_0's tweedie: 138.15\n",
      "[285]\tvalid_0's tweedie: 138.15\n",
      "[286]\tvalid_0's tweedie: 138.15\n",
      "[287]\tvalid_0's tweedie: 138.15\n",
      "[288]\tvalid_0's tweedie: 138.15\n",
      "[289]\tvalid_0's tweedie: 138.15\n",
      "[290]\tvalid_0's tweedie: 138.15\n",
      "[291]\tvalid_0's tweedie: 138.15\n",
      "[292]\tvalid_0's tweedie: 138.15\n",
      "[293]\tvalid_0's tweedie: 138.15\n",
      "[294]\tvalid_0's tweedie: 138.15\n",
      "[295]\tvalid_0's tweedie: 138.15\n",
      "[296]\tvalid_0's tweedie: 138.149\n",
      "[297]\tvalid_0's tweedie: 138.149\n",
      "[298]\tvalid_0's tweedie: 138.149\n",
      "[299]\tvalid_0's tweedie: 138.149\n",
      "[300]\tvalid_0's tweedie: 138.149\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 138.149\n",
      "Training model for level 8 and step 16\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/16/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 55680, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043059\n",
      "[1]\tvalid_0's tweedie: 148.688\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.818\n",
      "[3]\tvalid_0's tweedie: 145.246\n",
      "[4]\tvalid_0's tweedie: 143.969\n",
      "[5]\tvalid_0's tweedie: 142.92\n",
      "[6]\tvalid_0's tweedie: 142.047\n",
      "[7]\tvalid_0's tweedie: 141.339\n",
      "[8]\tvalid_0's tweedie: 140.765\n",
      "[9]\tvalid_0's tweedie: 140.283\n",
      "[10]\tvalid_0's tweedie: 139.899\n",
      "[11]\tvalid_0's tweedie: 139.59\n",
      "[12]\tvalid_0's tweedie: 139.333\n",
      "[13]\tvalid_0's tweedie: 139.121\n",
      "[14]\tvalid_0's tweedie: 138.945\n",
      "[15]\tvalid_0's tweedie: 138.806\n",
      "[16]\tvalid_0's tweedie: 138.691\n",
      "[17]\tvalid_0's tweedie: 138.598\n",
      "[18]\tvalid_0's tweedie: 138.522\n",
      "[19]\tvalid_0's tweedie: 138.458\n",
      "[20]\tvalid_0's tweedie: 138.406\n",
      "[21]\tvalid_0's tweedie: 138.365\n",
      "[22]\tvalid_0's tweedie: 138.331\n",
      "[23]\tvalid_0's tweedie: 138.302\n",
      "[24]\tvalid_0's tweedie: 138.277\n",
      "[25]\tvalid_0's tweedie: 138.256\n",
      "[26]\tvalid_0's tweedie: 138.24\n",
      "[27]\tvalid_0's tweedie: 138.229\n",
      "[28]\tvalid_0's tweedie: 138.218\n",
      "[29]\tvalid_0's tweedie: 138.211\n",
      "[30]\tvalid_0's tweedie: 138.204\n",
      "[31]\tvalid_0's tweedie: 138.2\n",
      "[32]\tvalid_0's tweedie: 138.194\n",
      "[33]\tvalid_0's tweedie: 138.19\n",
      "[34]\tvalid_0's tweedie: 138.188\n",
      "[35]\tvalid_0's tweedie: 138.185\n",
      "[36]\tvalid_0's tweedie: 138.183\n",
      "[37]\tvalid_0's tweedie: 138.182\n",
      "[38]\tvalid_0's tweedie: 138.18\n",
      "[39]\tvalid_0's tweedie: 138.177\n",
      "[40]\tvalid_0's tweedie: 138.176\n",
      "[41]\tvalid_0's tweedie: 138.174\n",
      "[42]\tvalid_0's tweedie: 138.175\n",
      "[43]\tvalid_0's tweedie: 138.173\n",
      "[44]\tvalid_0's tweedie: 138.172\n",
      "[45]\tvalid_0's tweedie: 138.171\n",
      "[46]\tvalid_0's tweedie: 138.169\n",
      "[47]\tvalid_0's tweedie: 138.168\n",
      "[48]\tvalid_0's tweedie: 138.167\n",
      "[49]\tvalid_0's tweedie: 138.167\n",
      "[50]\tvalid_0's tweedie: 138.168\n",
      "[51]\tvalid_0's tweedie: 138.167\n",
      "[52]\tvalid_0's tweedie: 138.166\n",
      "[53]\tvalid_0's tweedie: 138.165\n",
      "[54]\tvalid_0's tweedie: 138.166\n",
      "[55]\tvalid_0's tweedie: 138.165\n",
      "[56]\tvalid_0's tweedie: 138.166\n",
      "[57]\tvalid_0's tweedie: 138.166\n",
      "[58]\tvalid_0's tweedie: 138.165\n",
      "[59]\tvalid_0's tweedie: 138.165\n",
      "[60]\tvalid_0's tweedie: 138.164\n",
      "[61]\tvalid_0's tweedie: 138.165\n",
      "[62]\tvalid_0's tweedie: 138.165\n",
      "[63]\tvalid_0's tweedie: 138.165\n",
      "[64]\tvalid_0's tweedie: 138.165\n",
      "[65]\tvalid_0's tweedie: 138.165\n",
      "[66]\tvalid_0's tweedie: 138.165\n",
      "[67]\tvalid_0's tweedie: 138.165\n",
      "[68]\tvalid_0's tweedie: 138.165\n",
      "[69]\tvalid_0's tweedie: 138.165\n",
      "[70]\tvalid_0's tweedie: 138.165\n",
      "[71]\tvalid_0's tweedie: 138.165\n",
      "[72]\tvalid_0's tweedie: 138.165\n",
      "[73]\tvalid_0's tweedie: 138.165\n",
      "[74]\tvalid_0's tweedie: 138.166\n",
      "[75]\tvalid_0's tweedie: 138.166\n",
      "[76]\tvalid_0's tweedie: 138.166\n",
      "[77]\tvalid_0's tweedie: 138.165\n",
      "[78]\tvalid_0's tweedie: 138.165\n",
      "[79]\tvalid_0's tweedie: 138.165\n",
      "[80]\tvalid_0's tweedie: 138.165\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's tweedie: 138.164\n",
      "Training model for level 8 and step 17\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/17/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5504\n",
      "[LightGBM] [Info] Number of data points in the train set: 55650, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043148\n",
      "[1]\tvalid_0's tweedie: 148.686\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.812\n",
      "[3]\tvalid_0's tweedie: 145.26\n",
      "[4]\tvalid_0's tweedie: 143.97\n",
      "[5]\tvalid_0's tweedie: 142.911\n",
      "[6]\tvalid_0's tweedie: 142.05\n",
      "[7]\tvalid_0's tweedie: 141.345\n",
      "[8]\tvalid_0's tweedie: 140.756\n",
      "[9]\tvalid_0's tweedie: 140.281\n",
      "[10]\tvalid_0's tweedie: 139.893\n",
      "[11]\tvalid_0's tweedie: 139.58\n",
      "[12]\tvalid_0's tweedie: 139.324\n",
      "[13]\tvalid_0's tweedie: 139.11\n",
      "[14]\tvalid_0's tweedie: 138.937\n",
      "[15]\tvalid_0's tweedie: 138.802\n",
      "[16]\tvalid_0's tweedie: 138.685\n",
      "[17]\tvalid_0's tweedie: 138.594\n",
      "[18]\tvalid_0's tweedie: 138.519\n",
      "[19]\tvalid_0's tweedie: 138.457\n",
      "[20]\tvalid_0's tweedie: 138.403\n",
      "[21]\tvalid_0's tweedie: 138.361\n",
      "[22]\tvalid_0's tweedie: 138.326\n",
      "[23]\tvalid_0's tweedie: 138.301\n",
      "[24]\tvalid_0's tweedie: 138.278\n",
      "[25]\tvalid_0's tweedie: 138.258\n",
      "[26]\tvalid_0's tweedie: 138.244\n",
      "[27]\tvalid_0's tweedie: 138.231\n",
      "[28]\tvalid_0's tweedie: 138.222\n",
      "[29]\tvalid_0's tweedie: 138.214\n",
      "[30]\tvalid_0's tweedie: 138.205\n",
      "[31]\tvalid_0's tweedie: 138.198\n",
      "[32]\tvalid_0's tweedie: 138.193\n",
      "[33]\tvalid_0's tweedie: 138.19\n",
      "[34]\tvalid_0's tweedie: 138.186\n",
      "[35]\tvalid_0's tweedie: 138.183\n",
      "[36]\tvalid_0's tweedie: 138.18\n",
      "[37]\tvalid_0's tweedie: 138.179\n",
      "[38]\tvalid_0's tweedie: 138.178\n",
      "[39]\tvalid_0's tweedie: 138.177\n",
      "[40]\tvalid_0's tweedie: 138.175\n",
      "[41]\tvalid_0's tweedie: 138.174\n",
      "[42]\tvalid_0's tweedie: 138.174\n",
      "[43]\tvalid_0's tweedie: 138.173\n",
      "[44]\tvalid_0's tweedie: 138.171\n",
      "[45]\tvalid_0's tweedie: 138.17\n",
      "[46]\tvalid_0's tweedie: 138.169\n",
      "[47]\tvalid_0's tweedie: 138.168\n",
      "[48]\tvalid_0's tweedie: 138.167\n",
      "[49]\tvalid_0's tweedie: 138.166\n",
      "[50]\tvalid_0's tweedie: 138.166\n",
      "[51]\tvalid_0's tweedie: 138.167\n",
      "[52]\tvalid_0's tweedie: 138.167\n",
      "[53]\tvalid_0's tweedie: 138.168\n",
      "[54]\tvalid_0's tweedie: 138.167\n",
      "[55]\tvalid_0's tweedie: 138.167\n",
      "[56]\tvalid_0's tweedie: 138.167\n",
      "[57]\tvalid_0's tweedie: 138.166\n",
      "[58]\tvalid_0's tweedie: 138.166\n",
      "[59]\tvalid_0's tweedie: 138.166\n",
      "[60]\tvalid_0's tweedie: 138.165\n",
      "[61]\tvalid_0's tweedie: 138.166\n",
      "[62]\tvalid_0's tweedie: 138.166\n",
      "[63]\tvalid_0's tweedie: 138.166\n",
      "[64]\tvalid_0's tweedie: 138.166\n",
      "[65]\tvalid_0's tweedie: 138.166\n",
      "[66]\tvalid_0's tweedie: 138.166\n",
      "[67]\tvalid_0's tweedie: 138.164\n",
      "[68]\tvalid_0's tweedie: 138.164\n",
      "[69]\tvalid_0's tweedie: 138.164\n",
      "[70]\tvalid_0's tweedie: 138.164\n",
      "[71]\tvalid_0's tweedie: 138.164\n",
      "[72]\tvalid_0's tweedie: 138.164\n",
      "[73]\tvalid_0's tweedie: 138.164\n",
      "[74]\tvalid_0's tweedie: 138.164\n",
      "[75]\tvalid_0's tweedie: 138.164\n",
      "[76]\tvalid_0's tweedie: 138.163\n",
      "[77]\tvalid_0's tweedie: 138.163\n",
      "[78]\tvalid_0's tweedie: 138.163\n",
      "[79]\tvalid_0's tweedie: 138.163\n",
      "[80]\tvalid_0's tweedie: 138.163\n",
      "[81]\tvalid_0's tweedie: 138.163\n",
      "[82]\tvalid_0's tweedie: 138.162\n",
      "[83]\tvalid_0's tweedie: 138.161\n",
      "[84]\tvalid_0's tweedie: 138.161\n",
      "[85]\tvalid_0's tweedie: 138.161\n",
      "[86]\tvalid_0's tweedie: 138.161\n",
      "[87]\tvalid_0's tweedie: 138.16\n",
      "[88]\tvalid_0's tweedie: 138.16\n",
      "[89]\tvalid_0's tweedie: 138.16\n",
      "[90]\tvalid_0's tweedie: 138.159\n",
      "[91]\tvalid_0's tweedie: 138.159\n",
      "[92]\tvalid_0's tweedie: 138.159\n",
      "[93]\tvalid_0's tweedie: 138.159\n",
      "[94]\tvalid_0's tweedie: 138.158\n",
      "[95]\tvalid_0's tweedie: 138.158\n",
      "[96]\tvalid_0's tweedie: 138.158\n",
      "[97]\tvalid_0's tweedie: 138.158\n",
      "[98]\tvalid_0's tweedie: 138.158\n",
      "[99]\tvalid_0's tweedie: 138.156\n",
      "[100]\tvalid_0's tweedie: 138.156\n",
      "[101]\tvalid_0's tweedie: 138.156\n",
      "[102]\tvalid_0's tweedie: 138.156\n",
      "[103]\tvalid_0's tweedie: 138.155\n",
      "[104]\tvalid_0's tweedie: 138.155\n",
      "[105]\tvalid_0's tweedie: 138.155\n",
      "[106]\tvalid_0's tweedie: 138.155\n",
      "[107]\tvalid_0's tweedie: 138.155\n",
      "[108]\tvalid_0's tweedie: 138.155\n",
      "[109]\tvalid_0's tweedie: 138.155\n",
      "[110]\tvalid_0's tweedie: 138.155\n",
      "[111]\tvalid_0's tweedie: 138.155\n",
      "[112]\tvalid_0's tweedie: 138.155\n",
      "[113]\tvalid_0's tweedie: 138.154\n",
      "[114]\tvalid_0's tweedie: 138.154\n",
      "[115]\tvalid_0's tweedie: 138.154\n",
      "[116]\tvalid_0's tweedie: 138.154\n",
      "[117]\tvalid_0's tweedie: 138.154\n",
      "[118]\tvalid_0's tweedie: 138.154\n",
      "[119]\tvalid_0's tweedie: 138.154\n",
      "[120]\tvalid_0's tweedie: 138.154\n",
      "[121]\tvalid_0's tweedie: 138.154\n",
      "[122]\tvalid_0's tweedie: 138.153\n",
      "[123]\tvalid_0's tweedie: 138.153\n",
      "[124]\tvalid_0's tweedie: 138.153\n",
      "[125]\tvalid_0's tweedie: 138.153\n",
      "[126]\tvalid_0's tweedie: 138.153\n",
      "[127]\tvalid_0's tweedie: 138.153\n",
      "[128]\tvalid_0's tweedie: 138.153\n",
      "[129]\tvalid_0's tweedie: 138.153\n",
      "[130]\tvalid_0's tweedie: 138.153\n",
      "[131]\tvalid_0's tweedie: 138.153\n",
      "[132]\tvalid_0's tweedie: 138.153\n",
      "[133]\tvalid_0's tweedie: 138.153\n",
      "[134]\tvalid_0's tweedie: 138.153\n",
      "[135]\tvalid_0's tweedie: 138.152\n",
      "[136]\tvalid_0's tweedie: 138.152\n",
      "[137]\tvalid_0's tweedie: 138.152\n",
      "[138]\tvalid_0's tweedie: 138.152\n",
      "[139]\tvalid_0's tweedie: 138.152\n",
      "[140]\tvalid_0's tweedie: 138.152\n",
      "[141]\tvalid_0's tweedie: 138.152\n",
      "[142]\tvalid_0's tweedie: 138.152\n",
      "[143]\tvalid_0's tweedie: 138.152\n",
      "[144]\tvalid_0's tweedie: 138.152\n",
      "[145]\tvalid_0's tweedie: 138.152\n",
      "[146]\tvalid_0's tweedie: 138.152\n",
      "[147]\tvalid_0's tweedie: 138.152\n",
      "[148]\tvalid_0's tweedie: 138.152\n",
      "[149]\tvalid_0's tweedie: 138.152\n",
      "[150]\tvalid_0's tweedie: 138.152\n",
      "[151]\tvalid_0's tweedie: 138.152\n",
      "[152]\tvalid_0's tweedie: 138.152\n",
      "[153]\tvalid_0's tweedie: 138.152\n",
      "[154]\tvalid_0's tweedie: 138.151\n",
      "[155]\tvalid_0's tweedie: 138.151\n",
      "[156]\tvalid_0's tweedie: 138.151\n",
      "[157]\tvalid_0's tweedie: 138.151\n",
      "[158]\tvalid_0's tweedie: 138.151\n",
      "[159]\tvalid_0's tweedie: 138.152\n",
      "[160]\tvalid_0's tweedie: 138.152\n",
      "[161]\tvalid_0's tweedie: 138.152\n",
      "[162]\tvalid_0's tweedie: 138.151\n",
      "[163]\tvalid_0's tweedie: 138.152\n",
      "[164]\tvalid_0's tweedie: 138.152\n",
      "[165]\tvalid_0's tweedie: 138.151\n",
      "[166]\tvalid_0's tweedie: 138.151\n",
      "[167]\tvalid_0's tweedie: 138.151\n",
      "[168]\tvalid_0's tweedie: 138.151\n",
      "[169]\tvalid_0's tweedie: 138.151\n",
      "[170]\tvalid_0's tweedie: 138.151\n",
      "[171]\tvalid_0's tweedie: 138.151\n",
      "[172]\tvalid_0's tweedie: 138.151\n",
      "[173]\tvalid_0's tweedie: 138.151\n",
      "[174]\tvalid_0's tweedie: 138.151\n",
      "[175]\tvalid_0's tweedie: 138.15\n",
      "[176]\tvalid_0's tweedie: 138.15\n",
      "[177]\tvalid_0's tweedie: 138.15\n",
      "[178]\tvalid_0's tweedie: 138.15\n",
      "[179]\tvalid_0's tweedie: 138.15\n",
      "[180]\tvalid_0's tweedie: 138.15\n",
      "[181]\tvalid_0's tweedie: 138.15\n",
      "[182]\tvalid_0's tweedie: 138.15\n",
      "[183]\tvalid_0's tweedie: 138.15\n",
      "[184]\tvalid_0's tweedie: 138.15\n",
      "[185]\tvalid_0's tweedie: 138.15\n",
      "[186]\tvalid_0's tweedie: 138.15\n",
      "[187]\tvalid_0's tweedie: 138.15\n",
      "[188]\tvalid_0's tweedie: 138.149\n",
      "[189]\tvalid_0's tweedie: 138.149\n",
      "[190]\tvalid_0's tweedie: 138.149\n",
      "[191]\tvalid_0's tweedie: 138.149\n",
      "[192]\tvalid_0's tweedie: 138.149\n",
      "[193]\tvalid_0's tweedie: 138.149\n",
      "[194]\tvalid_0's tweedie: 138.149\n",
      "[195]\tvalid_0's tweedie: 138.149\n",
      "[196]\tvalid_0's tweedie: 138.149\n",
      "[197]\tvalid_0's tweedie: 138.149\n",
      "[198]\tvalid_0's tweedie: 138.149\n",
      "[199]\tvalid_0's tweedie: 138.149\n",
      "[200]\tvalid_0's tweedie: 138.149\n",
      "[201]\tvalid_0's tweedie: 138.149\n",
      "[202]\tvalid_0's tweedie: 138.149\n",
      "[203]\tvalid_0's tweedie: 138.148\n",
      "[204]\tvalid_0's tweedie: 138.147\n",
      "[205]\tvalid_0's tweedie: 138.147\n",
      "[206]\tvalid_0's tweedie: 138.147\n",
      "[207]\tvalid_0's tweedie: 138.147\n",
      "[208]\tvalid_0's tweedie: 138.147\n",
      "[209]\tvalid_0's tweedie: 138.147\n",
      "[210]\tvalid_0's tweedie: 138.147\n",
      "[211]\tvalid_0's tweedie: 138.147\n",
      "[212]\tvalid_0's tweedie: 138.147\n",
      "[213]\tvalid_0's tweedie: 138.147\n",
      "[214]\tvalid_0's tweedie: 138.147\n",
      "[215]\tvalid_0's tweedie: 138.147\n",
      "[216]\tvalid_0's tweedie: 138.147\n",
      "[217]\tvalid_0's tweedie: 138.147\n",
      "[218]\tvalid_0's tweedie: 138.147\n",
      "[219]\tvalid_0's tweedie: 138.147\n",
      "[220]\tvalid_0's tweedie: 138.147\n",
      "[221]\tvalid_0's tweedie: 138.147\n",
      "[222]\tvalid_0's tweedie: 138.147\n",
      "[223]\tvalid_0's tweedie: 138.146\n",
      "[224]\tvalid_0's tweedie: 138.146\n",
      "[225]\tvalid_0's tweedie: 138.146\n",
      "[226]\tvalid_0's tweedie: 138.146\n",
      "[227]\tvalid_0's tweedie: 138.146\n",
      "[228]\tvalid_0's tweedie: 138.147\n",
      "[229]\tvalid_0's tweedie: 138.146\n",
      "[230]\tvalid_0's tweedie: 138.147\n",
      "[231]\tvalid_0's tweedie: 138.146\n",
      "[232]\tvalid_0's tweedie: 138.146\n",
      "[233]\tvalid_0's tweedie: 138.146\n",
      "[234]\tvalid_0's tweedie: 138.146\n",
      "[235]\tvalid_0's tweedie: 138.146\n",
      "[236]\tvalid_0's tweedie: 138.146\n",
      "[237]\tvalid_0's tweedie: 138.146\n",
      "[238]\tvalid_0's tweedie: 138.145\n",
      "[239]\tvalid_0's tweedie: 138.145\n",
      "[240]\tvalid_0's tweedie: 138.145\n",
      "[241]\tvalid_0's tweedie: 138.145\n",
      "[242]\tvalid_0's tweedie: 138.145\n",
      "[243]\tvalid_0's tweedie: 138.145\n",
      "[244]\tvalid_0's tweedie: 138.145\n",
      "[245]\tvalid_0's tweedie: 138.145\n",
      "[246]\tvalid_0's tweedie: 138.145\n",
      "[247]\tvalid_0's tweedie: 138.145\n",
      "[248]\tvalid_0's tweedie: 138.145\n",
      "[249]\tvalid_0's tweedie: 138.145\n",
      "[250]\tvalid_0's tweedie: 138.145\n",
      "[251]\tvalid_0's tweedie: 138.145\n",
      "[252]\tvalid_0's tweedie: 138.145\n",
      "[253]\tvalid_0's tweedie: 138.145\n",
      "[254]\tvalid_0's tweedie: 138.145\n",
      "[255]\tvalid_0's tweedie: 138.145\n",
      "[256]\tvalid_0's tweedie: 138.145\n",
      "[257]\tvalid_0's tweedie: 138.145\n",
      "[258]\tvalid_0's tweedie: 138.145\n",
      "[259]\tvalid_0's tweedie: 138.145\n",
      "[260]\tvalid_0's tweedie: 138.145\n",
      "[261]\tvalid_0's tweedie: 138.145\n",
      "[262]\tvalid_0's tweedie: 138.145\n",
      "[263]\tvalid_0's tweedie: 138.145\n",
      "[264]\tvalid_0's tweedie: 138.145\n",
      "[265]\tvalid_0's tweedie: 138.145\n",
      "[266]\tvalid_0's tweedie: 138.145\n",
      "[267]\tvalid_0's tweedie: 138.145\n",
      "[268]\tvalid_0's tweedie: 138.145\n",
      "[269]\tvalid_0's tweedie: 138.145\n",
      "[270]\tvalid_0's tweedie: 138.145\n",
      "[271]\tvalid_0's tweedie: 138.145\n",
      "[272]\tvalid_0's tweedie: 138.145\n",
      "[273]\tvalid_0's tweedie: 138.145\n",
      "[274]\tvalid_0's tweedie: 138.145\n",
      "[275]\tvalid_0's tweedie: 138.145\n",
      "[276]\tvalid_0's tweedie: 138.145\n",
      "[277]\tvalid_0's tweedie: 138.145\n",
      "[278]\tvalid_0's tweedie: 138.145\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's tweedie: 138.145\n",
      "Training model for level 8 and step 18\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/18/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5503\n",
      "[LightGBM] [Info] Number of data points in the train set: 55620, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043354\n",
      "[1]\tvalid_0's tweedie: 148.701\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.823\n",
      "[3]\tvalid_0's tweedie: 145.264\n",
      "[4]\tvalid_0's tweedie: 143.969\n",
      "[5]\tvalid_0's tweedie: 142.915\n",
      "[6]\tvalid_0's tweedie: 142.038\n",
      "[7]\tvalid_0's tweedie: 141.336\n",
      "[8]\tvalid_0's tweedie: 140.755\n",
      "[9]\tvalid_0's tweedie: 140.28\n",
      "[10]\tvalid_0's tweedie: 139.891\n",
      "[11]\tvalid_0's tweedie: 139.579\n",
      "[12]\tvalid_0's tweedie: 139.321\n",
      "[13]\tvalid_0's tweedie: 139.108\n",
      "[14]\tvalid_0's tweedie: 138.934\n",
      "[15]\tvalid_0's tweedie: 138.798\n",
      "[16]\tvalid_0's tweedie: 138.682\n",
      "[17]\tvalid_0's tweedie: 138.586\n",
      "[18]\tvalid_0's tweedie: 138.509\n",
      "[19]\tvalid_0's tweedie: 138.446\n",
      "[20]\tvalid_0's tweedie: 138.393\n",
      "[21]\tvalid_0's tweedie: 138.352\n",
      "[22]\tvalid_0's tweedie: 138.318\n",
      "[23]\tvalid_0's tweedie: 138.289\n",
      "[24]\tvalid_0's tweedie: 138.267\n",
      "[25]\tvalid_0's tweedie: 138.248\n",
      "[26]\tvalid_0's tweedie: 138.23\n",
      "[27]\tvalid_0's tweedie: 138.22\n",
      "[28]\tvalid_0's tweedie: 138.209\n",
      "[29]\tvalid_0's tweedie: 138.202\n",
      "[30]\tvalid_0's tweedie: 138.195\n",
      "[31]\tvalid_0's tweedie: 138.189\n",
      "[32]\tvalid_0's tweedie: 138.184\n",
      "[33]\tvalid_0's tweedie: 138.18\n",
      "[34]\tvalid_0's tweedie: 138.177\n",
      "[35]\tvalid_0's tweedie: 138.174\n",
      "[36]\tvalid_0's tweedie: 138.171\n",
      "[37]\tvalid_0's tweedie: 138.169\n",
      "[38]\tvalid_0's tweedie: 138.169\n",
      "[39]\tvalid_0's tweedie: 138.169\n",
      "[40]\tvalid_0's tweedie: 138.167\n",
      "[41]\tvalid_0's tweedie: 138.166\n",
      "[42]\tvalid_0's tweedie: 138.166\n",
      "[43]\tvalid_0's tweedie: 138.165\n",
      "[44]\tvalid_0's tweedie: 138.163\n",
      "[45]\tvalid_0's tweedie: 138.161\n",
      "[46]\tvalid_0's tweedie: 138.16\n",
      "[47]\tvalid_0's tweedie: 138.159\n",
      "[48]\tvalid_0's tweedie: 138.159\n",
      "[49]\tvalid_0's tweedie: 138.158\n",
      "[50]\tvalid_0's tweedie: 138.158\n",
      "[51]\tvalid_0's tweedie: 138.157\n",
      "[52]\tvalid_0's tweedie: 138.158\n",
      "[53]\tvalid_0's tweedie: 138.157\n",
      "[54]\tvalid_0's tweedie: 138.157\n",
      "[55]\tvalid_0's tweedie: 138.156\n",
      "[56]\tvalid_0's tweedie: 138.156\n",
      "[57]\tvalid_0's tweedie: 138.156\n",
      "[58]\tvalid_0's tweedie: 138.155\n",
      "[59]\tvalid_0's tweedie: 138.155\n",
      "[60]\tvalid_0's tweedie: 138.155\n",
      "[61]\tvalid_0's tweedie: 138.155\n",
      "[62]\tvalid_0's tweedie: 138.155\n",
      "[63]\tvalid_0's tweedie: 138.155\n",
      "[64]\tvalid_0's tweedie: 138.155\n",
      "[65]\tvalid_0's tweedie: 138.155\n",
      "[66]\tvalid_0's tweedie: 138.154\n",
      "[67]\tvalid_0's tweedie: 138.154\n",
      "[68]\tvalid_0's tweedie: 138.154\n",
      "[69]\tvalid_0's tweedie: 138.154\n",
      "[70]\tvalid_0's tweedie: 138.154\n",
      "[71]\tvalid_0's tweedie: 138.154\n",
      "[72]\tvalid_0's tweedie: 138.154\n",
      "[73]\tvalid_0's tweedie: 138.154\n",
      "[74]\tvalid_0's tweedie: 138.154\n",
      "[75]\tvalid_0's tweedie: 138.154\n",
      "[76]\tvalid_0's tweedie: 138.154\n",
      "[77]\tvalid_0's tweedie: 138.154\n",
      "[78]\tvalid_0's tweedie: 138.154\n",
      "[79]\tvalid_0's tweedie: 138.154\n",
      "[80]\tvalid_0's tweedie: 138.154\n",
      "[81]\tvalid_0's tweedie: 138.155\n",
      "[82]\tvalid_0's tweedie: 138.154\n",
      "[83]\tvalid_0's tweedie: 138.154\n",
      "[84]\tvalid_0's tweedie: 138.153\n",
      "[85]\tvalid_0's tweedie: 138.153\n",
      "[86]\tvalid_0's tweedie: 138.153\n",
      "[87]\tvalid_0's tweedie: 138.153\n",
      "[88]\tvalid_0's tweedie: 138.152\n",
      "[89]\tvalid_0's tweedie: 138.151\n",
      "[90]\tvalid_0's tweedie: 138.151\n",
      "[91]\tvalid_0's tweedie: 138.151\n",
      "[92]\tvalid_0's tweedie: 138.151\n",
      "[93]\tvalid_0's tweedie: 138.15\n",
      "[94]\tvalid_0's tweedie: 138.15\n",
      "[95]\tvalid_0's tweedie: 138.15\n",
      "[96]\tvalid_0's tweedie: 138.15\n",
      "[97]\tvalid_0's tweedie: 138.15\n",
      "[98]\tvalid_0's tweedie: 138.15\n",
      "[99]\tvalid_0's tweedie: 138.15\n",
      "[100]\tvalid_0's tweedie: 138.15\n",
      "[101]\tvalid_0's tweedie: 138.15\n",
      "[102]\tvalid_0's tweedie: 138.149\n",
      "[103]\tvalid_0's tweedie: 138.149\n",
      "[104]\tvalid_0's tweedie: 138.149\n",
      "[105]\tvalid_0's tweedie: 138.149\n",
      "[106]\tvalid_0's tweedie: 138.149\n",
      "[107]\tvalid_0's tweedie: 138.149\n",
      "[108]\tvalid_0's tweedie: 138.149\n",
      "[109]\tvalid_0's tweedie: 138.149\n",
      "[110]\tvalid_0's tweedie: 138.148\n",
      "[111]\tvalid_0's tweedie: 138.148\n",
      "[112]\tvalid_0's tweedie: 138.148\n",
      "[113]\tvalid_0's tweedie: 138.149\n",
      "[114]\tvalid_0's tweedie: 138.148\n",
      "[115]\tvalid_0's tweedie: 138.148\n",
      "[116]\tvalid_0's tweedie: 138.148\n",
      "[117]\tvalid_0's tweedie: 138.148\n",
      "[118]\tvalid_0's tweedie: 138.148\n",
      "[119]\tvalid_0's tweedie: 138.148\n",
      "[120]\tvalid_0's tweedie: 138.149\n",
      "[121]\tvalid_0's tweedie: 138.149\n",
      "[122]\tvalid_0's tweedie: 138.149\n",
      "[123]\tvalid_0's tweedie: 138.149\n",
      "[124]\tvalid_0's tweedie: 138.148\n",
      "[125]\tvalid_0's tweedie: 138.149\n",
      "[126]\tvalid_0's tweedie: 138.148\n",
      "[127]\tvalid_0's tweedie: 138.148\n",
      "[128]\tvalid_0's tweedie: 138.148\n",
      "[129]\tvalid_0's tweedie: 138.148\n",
      "[130]\tvalid_0's tweedie: 138.148\n",
      "[131]\tvalid_0's tweedie: 138.148\n",
      "[132]\tvalid_0's tweedie: 138.148\n",
      "[133]\tvalid_0's tweedie: 138.148\n",
      "[134]\tvalid_0's tweedie: 138.147\n",
      "[135]\tvalid_0's tweedie: 138.147\n",
      "[136]\tvalid_0's tweedie: 138.147\n",
      "[137]\tvalid_0's tweedie: 138.147\n",
      "[138]\tvalid_0's tweedie: 138.147\n",
      "[139]\tvalid_0's tweedie: 138.147\n",
      "[140]\tvalid_0's tweedie: 138.147\n",
      "[141]\tvalid_0's tweedie: 138.147\n",
      "[142]\tvalid_0's tweedie: 138.147\n",
      "[143]\tvalid_0's tweedie: 138.146\n",
      "[144]\tvalid_0's tweedie: 138.146\n",
      "[145]\tvalid_0's tweedie: 138.144\n",
      "[146]\tvalid_0's tweedie: 138.144\n",
      "[147]\tvalid_0's tweedie: 138.144\n",
      "[148]\tvalid_0's tweedie: 138.144\n",
      "[149]\tvalid_0's tweedie: 138.144\n",
      "[150]\tvalid_0's tweedie: 138.144\n",
      "[151]\tvalid_0's tweedie: 138.144\n",
      "[152]\tvalid_0's tweedie: 138.144\n",
      "[153]\tvalid_0's tweedie: 138.144\n",
      "[154]\tvalid_0's tweedie: 138.144\n",
      "[155]\tvalid_0's tweedie: 138.144\n",
      "[156]\tvalid_0's tweedie: 138.143\n",
      "[157]\tvalid_0's tweedie: 138.143\n",
      "[158]\tvalid_0's tweedie: 138.143\n",
      "[159]\tvalid_0's tweedie: 138.143\n",
      "[160]\tvalid_0's tweedie: 138.143\n",
      "[161]\tvalid_0's tweedie: 138.143\n",
      "[162]\tvalid_0's tweedie: 138.143\n",
      "[163]\tvalid_0's tweedie: 138.143\n",
      "[164]\tvalid_0's tweedie: 138.143\n",
      "[165]\tvalid_0's tweedie: 138.143\n",
      "[166]\tvalid_0's tweedie: 138.142\n",
      "[167]\tvalid_0's tweedie: 138.142\n",
      "[168]\tvalid_0's tweedie: 138.142\n",
      "[169]\tvalid_0's tweedie: 138.142\n",
      "[170]\tvalid_0's tweedie: 138.142\n",
      "[171]\tvalid_0's tweedie: 138.142\n",
      "[172]\tvalid_0's tweedie: 138.142\n",
      "[173]\tvalid_0's tweedie: 138.142\n",
      "[174]\tvalid_0's tweedie: 138.142\n",
      "[175]\tvalid_0's tweedie: 138.142\n",
      "[176]\tvalid_0's tweedie: 138.141\n",
      "[177]\tvalid_0's tweedie: 138.141\n",
      "[178]\tvalid_0's tweedie: 138.141\n",
      "[179]\tvalid_0's tweedie: 138.141\n",
      "[180]\tvalid_0's tweedie: 138.141\n",
      "[181]\tvalid_0's tweedie: 138.141\n",
      "[182]\tvalid_0's tweedie: 138.141\n",
      "[183]\tvalid_0's tweedie: 138.141\n",
      "[184]\tvalid_0's tweedie: 138.141\n",
      "[185]\tvalid_0's tweedie: 138.141\n",
      "[186]\tvalid_0's tweedie: 138.141\n",
      "[187]\tvalid_0's tweedie: 138.141\n",
      "[188]\tvalid_0's tweedie: 138.141\n",
      "[189]\tvalid_0's tweedie: 138.141\n",
      "[190]\tvalid_0's tweedie: 138.141\n",
      "[191]\tvalid_0's tweedie: 138.141\n",
      "[192]\tvalid_0's tweedie: 138.141\n",
      "[193]\tvalid_0's tweedie: 138.141\n",
      "[194]\tvalid_0's tweedie: 138.141\n",
      "[195]\tvalid_0's tweedie: 138.141\n",
      "[196]\tvalid_0's tweedie: 138.141\n",
      "[197]\tvalid_0's tweedie: 138.141\n",
      "[198]\tvalid_0's tweedie: 138.141\n",
      "[199]\tvalid_0's tweedie: 138.141\n",
      "[200]\tvalid_0's tweedie: 138.141\n",
      "[201]\tvalid_0's tweedie: 138.14\n",
      "[202]\tvalid_0's tweedie: 138.14\n",
      "[203]\tvalid_0's tweedie: 138.14\n",
      "[204]\tvalid_0's tweedie: 138.14\n",
      "[205]\tvalid_0's tweedie: 138.14\n",
      "[206]\tvalid_0's tweedie: 138.14\n",
      "[207]\tvalid_0's tweedie: 138.14\n",
      "[208]\tvalid_0's tweedie: 138.141\n",
      "[209]\tvalid_0's tweedie: 138.141\n",
      "[210]\tvalid_0's tweedie: 138.14\n",
      "[211]\tvalid_0's tweedie: 138.141\n",
      "[212]\tvalid_0's tweedie: 138.141\n",
      "[213]\tvalid_0's tweedie: 138.141\n",
      "[214]\tvalid_0's tweedie: 138.141\n",
      "[215]\tvalid_0's tweedie: 138.141\n",
      "[216]\tvalid_0's tweedie: 138.141\n",
      "[217]\tvalid_0's tweedie: 138.141\n",
      "[218]\tvalid_0's tweedie: 138.141\n",
      "[219]\tvalid_0's tweedie: 138.141\n",
      "[220]\tvalid_0's tweedie: 138.141\n",
      "[221]\tvalid_0's tweedie: 138.141\n",
      "[222]\tvalid_0's tweedie: 138.141\n",
      "[223]\tvalid_0's tweedie: 138.14\n",
      "[224]\tvalid_0's tweedie: 138.141\n",
      "[225]\tvalid_0's tweedie: 138.14\n",
      "[226]\tvalid_0's tweedie: 138.14\n",
      "[227]\tvalid_0's tweedie: 138.14\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's tweedie: 138.14\n",
      "Training model for level 8 and step 19\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/19/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5502\n",
      "[LightGBM] [Info] Number of data points in the train set: 55590, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043534\n",
      "[1]\tvalid_0's tweedie: 148.697\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.808\n",
      "[3]\tvalid_0's tweedie: 145.261\n",
      "[4]\tvalid_0's tweedie: 143.972\n",
      "[5]\tvalid_0's tweedie: 142.921\n",
      "[6]\tvalid_0's tweedie: 142.058\n",
      "[7]\tvalid_0's tweedie: 141.34\n",
      "[8]\tvalid_0's tweedie: 140.773\n",
      "[9]\tvalid_0's tweedie: 140.291\n",
      "[10]\tvalid_0's tweedie: 139.902\n",
      "[11]\tvalid_0's tweedie: 139.583\n",
      "[12]\tvalid_0's tweedie: 139.323\n",
      "[13]\tvalid_0's tweedie: 139.111\n",
      "[14]\tvalid_0's tweedie: 138.938\n",
      "[15]\tvalid_0's tweedie: 138.798\n",
      "[16]\tvalid_0's tweedie: 138.681\n",
      "[17]\tvalid_0's tweedie: 138.584\n",
      "[18]\tvalid_0's tweedie: 138.506\n",
      "[19]\tvalid_0's tweedie: 138.445\n",
      "[20]\tvalid_0's tweedie: 138.394\n",
      "[21]\tvalid_0's tweedie: 138.354\n",
      "[22]\tvalid_0's tweedie: 138.319\n",
      "[23]\tvalid_0's tweedie: 138.29\n",
      "[24]\tvalid_0's tweedie: 138.266\n",
      "[25]\tvalid_0's tweedie: 138.248\n",
      "[26]\tvalid_0's tweedie: 138.232\n",
      "[27]\tvalid_0's tweedie: 138.221\n",
      "[28]\tvalid_0's tweedie: 138.213\n",
      "[29]\tvalid_0's tweedie: 138.204\n",
      "[30]\tvalid_0's tweedie: 138.199\n",
      "[31]\tvalid_0's tweedie: 138.194\n",
      "[32]\tvalid_0's tweedie: 138.188\n",
      "[33]\tvalid_0's tweedie: 138.183\n",
      "[34]\tvalid_0's tweedie: 138.181\n",
      "[35]\tvalid_0's tweedie: 138.178\n",
      "[36]\tvalid_0's tweedie: 138.175\n",
      "[37]\tvalid_0's tweedie: 138.173\n",
      "[38]\tvalid_0's tweedie: 138.172\n",
      "[39]\tvalid_0's tweedie: 138.171\n",
      "[40]\tvalid_0's tweedie: 138.17\n",
      "[41]\tvalid_0's tweedie: 138.169\n",
      "[42]\tvalid_0's tweedie: 138.168\n",
      "[43]\tvalid_0's tweedie: 138.167\n",
      "[44]\tvalid_0's tweedie: 138.168\n",
      "[45]\tvalid_0's tweedie: 138.166\n",
      "[46]\tvalid_0's tweedie: 138.164\n",
      "[47]\tvalid_0's tweedie: 138.163\n",
      "[48]\tvalid_0's tweedie: 138.164\n",
      "[49]\tvalid_0's tweedie: 138.163\n",
      "[50]\tvalid_0's tweedie: 138.163\n",
      "[51]\tvalid_0's tweedie: 138.163\n",
      "[52]\tvalid_0's tweedie: 138.162\n",
      "[53]\tvalid_0's tweedie: 138.161\n",
      "[54]\tvalid_0's tweedie: 138.161\n",
      "[55]\tvalid_0's tweedie: 138.161\n",
      "[56]\tvalid_0's tweedie: 138.16\n",
      "[57]\tvalid_0's tweedie: 138.159\n",
      "[58]\tvalid_0's tweedie: 138.16\n",
      "[59]\tvalid_0's tweedie: 138.161\n",
      "[60]\tvalid_0's tweedie: 138.161\n",
      "[61]\tvalid_0's tweedie: 138.16\n",
      "[62]\tvalid_0's tweedie: 138.16\n",
      "[63]\tvalid_0's tweedie: 138.16\n",
      "[64]\tvalid_0's tweedie: 138.159\n",
      "[65]\tvalid_0's tweedie: 138.159\n",
      "[66]\tvalid_0's tweedie: 138.159\n",
      "[67]\tvalid_0's tweedie: 138.159\n",
      "[68]\tvalid_0's tweedie: 138.159\n",
      "[69]\tvalid_0's tweedie: 138.159\n",
      "[70]\tvalid_0's tweedie: 138.159\n",
      "[71]\tvalid_0's tweedie: 138.159\n",
      "[72]\tvalid_0's tweedie: 138.159\n",
      "[73]\tvalid_0's tweedie: 138.159\n",
      "[74]\tvalid_0's tweedie: 138.158\n",
      "[75]\tvalid_0's tweedie: 138.158\n",
      "[76]\tvalid_0's tweedie: 138.158\n",
      "[77]\tvalid_0's tweedie: 138.158\n",
      "[78]\tvalid_0's tweedie: 138.158\n",
      "[79]\tvalid_0's tweedie: 138.158\n",
      "[80]\tvalid_0's tweedie: 138.158\n",
      "[81]\tvalid_0's tweedie: 138.158\n",
      "[82]\tvalid_0's tweedie: 138.158\n",
      "[83]\tvalid_0's tweedie: 138.157\n",
      "[84]\tvalid_0's tweedie: 138.157\n",
      "[85]\tvalid_0's tweedie: 138.157\n",
      "[86]\tvalid_0's tweedie: 138.157\n",
      "[87]\tvalid_0's tweedie: 138.157\n",
      "[88]\tvalid_0's tweedie: 138.156\n",
      "[89]\tvalid_0's tweedie: 138.156\n",
      "[90]\tvalid_0's tweedie: 138.156\n",
      "[91]\tvalid_0's tweedie: 138.156\n",
      "[92]\tvalid_0's tweedie: 138.154\n",
      "[93]\tvalid_0's tweedie: 138.154\n",
      "[94]\tvalid_0's tweedie: 138.153\n",
      "[95]\tvalid_0's tweedie: 138.153\n",
      "[96]\tvalid_0's tweedie: 138.153\n",
      "[97]\tvalid_0's tweedie: 138.153\n",
      "[98]\tvalid_0's tweedie: 138.153\n",
      "[99]\tvalid_0's tweedie: 138.153\n",
      "[100]\tvalid_0's tweedie: 138.153\n",
      "[101]\tvalid_0's tweedie: 138.153\n",
      "[102]\tvalid_0's tweedie: 138.153\n",
      "[103]\tvalid_0's tweedie: 138.153\n",
      "[104]\tvalid_0's tweedie: 138.153\n",
      "[105]\tvalid_0's tweedie: 138.153\n",
      "[106]\tvalid_0's tweedie: 138.152\n",
      "[107]\tvalid_0's tweedie: 138.153\n",
      "[108]\tvalid_0's tweedie: 138.152\n",
      "[109]\tvalid_0's tweedie: 138.153\n",
      "[110]\tvalid_0's tweedie: 138.152\n",
      "[111]\tvalid_0's tweedie: 138.152\n",
      "[112]\tvalid_0's tweedie: 138.153\n",
      "[113]\tvalid_0's tweedie: 138.153\n",
      "[114]\tvalid_0's tweedie: 138.153\n",
      "[115]\tvalid_0's tweedie: 138.152\n",
      "[116]\tvalid_0's tweedie: 138.152\n",
      "[117]\tvalid_0's tweedie: 138.153\n",
      "[118]\tvalid_0's tweedie: 138.152\n",
      "[119]\tvalid_0's tweedie: 138.152\n",
      "[120]\tvalid_0's tweedie: 138.152\n",
      "[121]\tvalid_0's tweedie: 138.15\n",
      "[122]\tvalid_0's tweedie: 138.15\n",
      "[123]\tvalid_0's tweedie: 138.15\n",
      "[124]\tvalid_0's tweedie: 138.15\n",
      "[125]\tvalid_0's tweedie: 138.15\n",
      "[126]\tvalid_0's tweedie: 138.15\n",
      "[127]\tvalid_0's tweedie: 138.15\n",
      "[128]\tvalid_0's tweedie: 138.15\n",
      "[129]\tvalid_0's tweedie: 138.15\n",
      "[130]\tvalid_0's tweedie: 138.15\n",
      "[131]\tvalid_0's tweedie: 138.15\n",
      "[132]\tvalid_0's tweedie: 138.149\n",
      "[133]\tvalid_0's tweedie: 138.149\n",
      "[134]\tvalid_0's tweedie: 138.149\n",
      "[135]\tvalid_0's tweedie: 138.149\n",
      "[136]\tvalid_0's tweedie: 138.149\n",
      "[137]\tvalid_0's tweedie: 138.148\n",
      "[138]\tvalid_0's tweedie: 138.148\n",
      "[139]\tvalid_0's tweedie: 138.148\n",
      "[140]\tvalid_0's tweedie: 138.148\n",
      "[141]\tvalid_0's tweedie: 138.148\n",
      "[142]\tvalid_0's tweedie: 138.148\n",
      "[143]\tvalid_0's tweedie: 138.148\n",
      "[144]\tvalid_0's tweedie: 138.147\n",
      "[145]\tvalid_0's tweedie: 138.147\n",
      "[146]\tvalid_0's tweedie: 138.147\n",
      "[147]\tvalid_0's tweedie: 138.146\n",
      "[148]\tvalid_0's tweedie: 138.146\n",
      "[149]\tvalid_0's tweedie: 138.146\n",
      "[150]\tvalid_0's tweedie: 138.145\n",
      "[151]\tvalid_0's tweedie: 138.145\n",
      "[152]\tvalid_0's tweedie: 138.145\n",
      "[153]\tvalid_0's tweedie: 138.145\n",
      "[154]\tvalid_0's tweedie: 138.145\n",
      "[155]\tvalid_0's tweedie: 138.145\n",
      "[156]\tvalid_0's tweedie: 138.145\n",
      "[157]\tvalid_0's tweedie: 138.145\n",
      "[158]\tvalid_0's tweedie: 138.145\n",
      "[159]\tvalid_0's tweedie: 138.145\n",
      "[160]\tvalid_0's tweedie: 138.144\n",
      "[161]\tvalid_0's tweedie: 138.144\n",
      "[162]\tvalid_0's tweedie: 138.144\n",
      "[163]\tvalid_0's tweedie: 138.144\n",
      "[164]\tvalid_0's tweedie: 138.144\n",
      "[165]\tvalid_0's tweedie: 138.144\n",
      "[166]\tvalid_0's tweedie: 138.144\n",
      "[167]\tvalid_0's tweedie: 138.144\n",
      "[168]\tvalid_0's tweedie: 138.144\n",
      "[169]\tvalid_0's tweedie: 138.143\n",
      "[170]\tvalid_0's tweedie: 138.143\n",
      "[171]\tvalid_0's tweedie: 138.143\n",
      "[172]\tvalid_0's tweedie: 138.143\n",
      "[173]\tvalid_0's tweedie: 138.143\n",
      "[174]\tvalid_0's tweedie: 138.143\n",
      "[175]\tvalid_0's tweedie: 138.143\n",
      "[176]\tvalid_0's tweedie: 138.143\n",
      "[177]\tvalid_0's tweedie: 138.142\n",
      "[178]\tvalid_0's tweedie: 138.14\n",
      "[179]\tvalid_0's tweedie: 138.14\n",
      "[180]\tvalid_0's tweedie: 138.14\n",
      "[181]\tvalid_0's tweedie: 138.14\n",
      "[182]\tvalid_0's tweedie: 138.14\n",
      "[183]\tvalid_0's tweedie: 138.14\n",
      "[184]\tvalid_0's tweedie: 138.14\n",
      "[185]\tvalid_0's tweedie: 138.14\n",
      "[186]\tvalid_0's tweedie: 138.14\n",
      "[187]\tvalid_0's tweedie: 138.14\n",
      "[188]\tvalid_0's tweedie: 138.139\n",
      "[189]\tvalid_0's tweedie: 138.139\n",
      "[190]\tvalid_0's tweedie: 138.139\n",
      "[191]\tvalid_0's tweedie: 138.139\n",
      "[192]\tvalid_0's tweedie: 138.14\n",
      "[193]\tvalid_0's tweedie: 138.139\n",
      "[194]\tvalid_0's tweedie: 138.139\n",
      "[195]\tvalid_0's tweedie: 138.139\n",
      "[196]\tvalid_0's tweedie: 138.139\n",
      "[197]\tvalid_0's tweedie: 138.139\n",
      "[198]\tvalid_0's tweedie: 138.139\n",
      "[199]\tvalid_0's tweedie: 138.139\n",
      "[200]\tvalid_0's tweedie: 138.139\n",
      "[201]\tvalid_0's tweedie: 138.139\n",
      "[202]\tvalid_0's tweedie: 138.139\n",
      "[203]\tvalid_0's tweedie: 138.139\n",
      "[204]\tvalid_0's tweedie: 138.139\n",
      "[205]\tvalid_0's tweedie: 138.139\n",
      "[206]\tvalid_0's tweedie: 138.139\n",
      "[207]\tvalid_0's tweedie: 138.139\n",
      "[208]\tvalid_0's tweedie: 138.138\n",
      "[209]\tvalid_0's tweedie: 138.139\n",
      "[210]\tvalid_0's tweedie: 138.139\n",
      "[211]\tvalid_0's tweedie: 138.139\n",
      "[212]\tvalid_0's tweedie: 138.138\n",
      "[213]\tvalid_0's tweedie: 138.138\n",
      "[214]\tvalid_0's tweedie: 138.138\n",
      "[215]\tvalid_0's tweedie: 138.138\n",
      "[216]\tvalid_0's tweedie: 138.138\n",
      "[217]\tvalid_0's tweedie: 138.138\n",
      "[218]\tvalid_0's tweedie: 138.138\n",
      "[219]\tvalid_0's tweedie: 138.138\n",
      "[220]\tvalid_0's tweedie: 138.138\n",
      "[221]\tvalid_0's tweedie: 138.138\n",
      "[222]\tvalid_0's tweedie: 138.138\n",
      "[223]\tvalid_0's tweedie: 138.138\n",
      "[224]\tvalid_0's tweedie: 138.138\n",
      "[225]\tvalid_0's tweedie: 138.138\n",
      "[226]\tvalid_0's tweedie: 138.138\n",
      "[227]\tvalid_0's tweedie: 138.138\n",
      "[228]\tvalid_0's tweedie: 138.138\n",
      "[229]\tvalid_0's tweedie: 138.137\n",
      "[230]\tvalid_0's tweedie: 138.137\n",
      "[231]\tvalid_0's tweedie: 138.137\n",
      "[232]\tvalid_0's tweedie: 138.138\n",
      "[233]\tvalid_0's tweedie: 138.137\n",
      "[234]\tvalid_0's tweedie: 138.137\n",
      "[235]\tvalid_0's tweedie: 138.137\n",
      "[236]\tvalid_0's tweedie: 138.137\n",
      "[237]\tvalid_0's tweedie: 138.137\n",
      "[238]\tvalid_0's tweedie: 138.137\n",
      "[239]\tvalid_0's tweedie: 138.137\n",
      "[240]\tvalid_0's tweedie: 138.137\n",
      "[241]\tvalid_0's tweedie: 138.137\n",
      "[242]\tvalid_0's tweedie: 138.137\n",
      "[243]\tvalid_0's tweedie: 138.137\n",
      "[244]\tvalid_0's tweedie: 138.137\n",
      "[245]\tvalid_0's tweedie: 138.137\n",
      "[246]\tvalid_0's tweedie: 138.137\n",
      "[247]\tvalid_0's tweedie: 138.137\n",
      "[248]\tvalid_0's tweedie: 138.137\n",
      "[249]\tvalid_0's tweedie: 138.137\n",
      "[250]\tvalid_0's tweedie: 138.137\n",
      "[251]\tvalid_0's tweedie: 138.137\n",
      "[252]\tvalid_0's tweedie: 138.137\n",
      "[253]\tvalid_0's tweedie: 138.137\n",
      "[254]\tvalid_0's tweedie: 138.137\n",
      "[255]\tvalid_0's tweedie: 138.136\n",
      "[256]\tvalid_0's tweedie: 138.136\n",
      "[257]\tvalid_0's tweedie: 138.136\n",
      "[258]\tvalid_0's tweedie: 138.136\n",
      "[259]\tvalid_0's tweedie: 138.136\n",
      "[260]\tvalid_0's tweedie: 138.136\n",
      "[261]\tvalid_0's tweedie: 138.136\n",
      "[262]\tvalid_0's tweedie: 138.136\n",
      "[263]\tvalid_0's tweedie: 138.136\n",
      "[264]\tvalid_0's tweedie: 138.136\n",
      "[265]\tvalid_0's tweedie: 138.136\n",
      "[266]\tvalid_0's tweedie: 138.136\n",
      "[267]\tvalid_0's tweedie: 138.136\n",
      "[268]\tvalid_0's tweedie: 138.136\n",
      "[269]\tvalid_0's tweedie: 138.136\n",
      "[270]\tvalid_0's tweedie: 138.136\n",
      "[271]\tvalid_0's tweedie: 138.136\n",
      "[272]\tvalid_0's tweedie: 138.136\n",
      "[273]\tvalid_0's tweedie: 138.136\n",
      "[274]\tvalid_0's tweedie: 138.136\n",
      "[275]\tvalid_0's tweedie: 138.136\n",
      "[276]\tvalid_0's tweedie: 138.136\n",
      "[277]\tvalid_0's tweedie: 138.136\n",
      "[278]\tvalid_0's tweedie: 138.136\n",
      "[279]\tvalid_0's tweedie: 138.136\n",
      "[280]\tvalid_0's tweedie: 138.136\n",
      "[281]\tvalid_0's tweedie: 138.136\n",
      "[282]\tvalid_0's tweedie: 138.136\n",
      "[283]\tvalid_0's tweedie: 138.136\n",
      "[284]\tvalid_0's tweedie: 138.135\n",
      "[285]\tvalid_0's tweedie: 138.135\n",
      "[286]\tvalid_0's tweedie: 138.136\n",
      "[287]\tvalid_0's tweedie: 138.135\n",
      "[288]\tvalid_0's tweedie: 138.135\n",
      "[289]\tvalid_0's tweedie: 138.135\n",
      "[290]\tvalid_0's tweedie: 138.135\n",
      "[291]\tvalid_0's tweedie: 138.135\n",
      "[292]\tvalid_0's tweedie: 138.135\n",
      "[293]\tvalid_0's tweedie: 138.135\n",
      "[294]\tvalid_0's tweedie: 138.135\n",
      "[295]\tvalid_0's tweedie: 138.135\n",
      "[296]\tvalid_0's tweedie: 138.135\n",
      "[297]\tvalid_0's tweedie: 138.135\n",
      "[298]\tvalid_0's tweedie: 138.135\n",
      "[299]\tvalid_0's tweedie: 138.135\n",
      "[300]\tvalid_0's tweedie: 138.135\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[294]\tvalid_0's tweedie: 138.135\n",
      "Training model for level 8 and step 20\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/20/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5501\n",
      "[LightGBM] [Info] Number of data points in the train set: 55560, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043728\n",
      "[1]\tvalid_0's tweedie: 148.686\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.811\n",
      "[3]\tvalid_0's tweedie: 145.254\n",
      "[4]\tvalid_0's tweedie: 143.964\n",
      "[5]\tvalid_0's tweedie: 142.904\n",
      "[6]\tvalid_0's tweedie: 142.042\n",
      "[7]\tvalid_0's tweedie: 141.323\n",
      "[8]\tvalid_0's tweedie: 140.745\n",
      "[9]\tvalid_0's tweedie: 140.272\n",
      "[10]\tvalid_0's tweedie: 139.886\n",
      "[11]\tvalid_0's tweedie: 139.57\n",
      "[12]\tvalid_0's tweedie: 139.314\n",
      "[13]\tvalid_0's tweedie: 139.1\n",
      "[14]\tvalid_0's tweedie: 138.926\n",
      "[15]\tvalid_0's tweedie: 138.785\n",
      "[16]\tvalid_0's tweedie: 138.668\n",
      "[17]\tvalid_0's tweedie: 138.573\n",
      "[18]\tvalid_0's tweedie: 138.495\n",
      "[19]\tvalid_0's tweedie: 138.431\n",
      "[20]\tvalid_0's tweedie: 138.382\n",
      "[21]\tvalid_0's tweedie: 138.341\n",
      "[22]\tvalid_0's tweedie: 138.308\n",
      "[23]\tvalid_0's tweedie: 138.279\n",
      "[24]\tvalid_0's tweedie: 138.256\n",
      "[25]\tvalid_0's tweedie: 138.237\n",
      "[26]\tvalid_0's tweedie: 138.224\n",
      "[27]\tvalid_0's tweedie: 138.212\n",
      "[28]\tvalid_0's tweedie: 138.202\n",
      "[29]\tvalid_0's tweedie: 138.194\n",
      "[30]\tvalid_0's tweedie: 138.188\n",
      "[31]\tvalid_0's tweedie: 138.181\n",
      "[32]\tvalid_0's tweedie: 138.177\n",
      "[33]\tvalid_0's tweedie: 138.174\n",
      "[34]\tvalid_0's tweedie: 138.17\n",
      "[35]\tvalid_0's tweedie: 138.169\n",
      "[36]\tvalid_0's tweedie: 138.167\n",
      "[37]\tvalid_0's tweedie: 138.164\n",
      "[38]\tvalid_0's tweedie: 138.163\n",
      "[39]\tvalid_0's tweedie: 138.163\n",
      "[40]\tvalid_0's tweedie: 138.163\n",
      "[41]\tvalid_0's tweedie: 138.162\n",
      "[42]\tvalid_0's tweedie: 138.161\n",
      "[43]\tvalid_0's tweedie: 138.16\n",
      "[44]\tvalid_0's tweedie: 138.16\n",
      "[45]\tvalid_0's tweedie: 138.16\n",
      "[46]\tvalid_0's tweedie: 138.158\n",
      "[47]\tvalid_0's tweedie: 138.156\n",
      "[48]\tvalid_0's tweedie: 138.156\n",
      "[49]\tvalid_0's tweedie: 138.155\n",
      "[50]\tvalid_0's tweedie: 138.155\n",
      "[51]\tvalid_0's tweedie: 138.155\n",
      "[52]\tvalid_0's tweedie: 138.156\n",
      "[53]\tvalid_0's tweedie: 138.156\n",
      "[54]\tvalid_0's tweedie: 138.155\n",
      "[55]\tvalid_0's tweedie: 138.154\n",
      "[56]\tvalid_0's tweedie: 138.154\n",
      "[57]\tvalid_0's tweedie: 138.154\n",
      "[58]\tvalid_0's tweedie: 138.154\n",
      "[59]\tvalid_0's tweedie: 138.155\n",
      "[60]\tvalid_0's tweedie: 138.155\n",
      "[61]\tvalid_0's tweedie: 138.155\n",
      "[62]\tvalid_0's tweedie: 138.154\n",
      "[63]\tvalid_0's tweedie: 138.153\n",
      "[64]\tvalid_0's tweedie: 138.154\n",
      "[65]\tvalid_0's tweedie: 138.153\n",
      "[66]\tvalid_0's tweedie: 138.153\n",
      "[67]\tvalid_0's tweedie: 138.153\n",
      "[68]\tvalid_0's tweedie: 138.153\n",
      "[69]\tvalid_0's tweedie: 138.153\n",
      "[70]\tvalid_0's tweedie: 138.153\n",
      "[71]\tvalid_0's tweedie: 138.153\n",
      "[72]\tvalid_0's tweedie: 138.152\n",
      "[73]\tvalid_0's tweedie: 138.152\n",
      "[74]\tvalid_0's tweedie: 138.152\n",
      "[75]\tvalid_0's tweedie: 138.151\n",
      "[76]\tvalid_0's tweedie: 138.15\n",
      "[77]\tvalid_0's tweedie: 138.15\n",
      "[78]\tvalid_0's tweedie: 138.15\n",
      "[79]\tvalid_0's tweedie: 138.149\n",
      "[80]\tvalid_0's tweedie: 138.149\n",
      "[81]\tvalid_0's tweedie: 138.149\n",
      "[82]\tvalid_0's tweedie: 138.148\n",
      "[83]\tvalid_0's tweedie: 138.148\n",
      "[84]\tvalid_0's tweedie: 138.148\n",
      "[85]\tvalid_0's tweedie: 138.148\n",
      "[86]\tvalid_0's tweedie: 138.148\n",
      "[87]\tvalid_0's tweedie: 138.148\n",
      "[88]\tvalid_0's tweedie: 138.148\n",
      "[89]\tvalid_0's tweedie: 138.148\n",
      "[90]\tvalid_0's tweedie: 138.148\n",
      "[91]\tvalid_0's tweedie: 138.147\n",
      "[92]\tvalid_0's tweedie: 138.147\n",
      "[93]\tvalid_0's tweedie: 138.147\n",
      "[94]\tvalid_0's tweedie: 138.147\n",
      "[95]\tvalid_0's tweedie: 138.147\n",
      "[96]\tvalid_0's tweedie: 138.146\n",
      "[97]\tvalid_0's tweedie: 138.145\n",
      "[98]\tvalid_0's tweedie: 138.145\n",
      "[99]\tvalid_0's tweedie: 138.144\n",
      "[100]\tvalid_0's tweedie: 138.144\n",
      "[101]\tvalid_0's tweedie: 138.144\n",
      "[102]\tvalid_0's tweedie: 138.144\n",
      "[103]\tvalid_0's tweedie: 138.144\n",
      "[104]\tvalid_0's tweedie: 138.144\n",
      "[105]\tvalid_0's tweedie: 138.144\n",
      "[106]\tvalid_0's tweedie: 138.143\n",
      "[107]\tvalid_0's tweedie: 138.143\n",
      "[108]\tvalid_0's tweedie: 138.143\n",
      "[109]\tvalid_0's tweedie: 138.142\n",
      "[110]\tvalid_0's tweedie: 138.142\n",
      "[111]\tvalid_0's tweedie: 138.142\n",
      "[112]\tvalid_0's tweedie: 138.142\n",
      "[113]\tvalid_0's tweedie: 138.142\n",
      "[114]\tvalid_0's tweedie: 138.142\n",
      "[115]\tvalid_0's tweedie: 138.142\n",
      "[116]\tvalid_0's tweedie: 138.142\n",
      "[117]\tvalid_0's tweedie: 138.142\n",
      "[118]\tvalid_0's tweedie: 138.142\n",
      "[119]\tvalid_0's tweedie: 138.142\n",
      "[120]\tvalid_0's tweedie: 138.142\n",
      "[121]\tvalid_0's tweedie: 138.142\n",
      "[122]\tvalid_0's tweedie: 138.142\n",
      "[123]\tvalid_0's tweedie: 138.141\n",
      "[124]\tvalid_0's tweedie: 138.141\n",
      "[125]\tvalid_0's tweedie: 138.141\n",
      "[126]\tvalid_0's tweedie: 138.141\n",
      "[127]\tvalid_0's tweedie: 138.141\n",
      "[128]\tvalid_0's tweedie: 138.141\n",
      "[129]\tvalid_0's tweedie: 138.141\n",
      "[130]\tvalid_0's tweedie: 138.141\n",
      "[131]\tvalid_0's tweedie: 138.14\n",
      "[132]\tvalid_0's tweedie: 138.14\n",
      "[133]\tvalid_0's tweedie: 138.14\n",
      "[134]\tvalid_0's tweedie: 138.14\n",
      "[135]\tvalid_0's tweedie: 138.14\n",
      "[136]\tvalid_0's tweedie: 138.14\n",
      "[137]\tvalid_0's tweedie: 138.14\n",
      "[138]\tvalid_0's tweedie: 138.139\n",
      "[139]\tvalid_0's tweedie: 138.14\n",
      "[140]\tvalid_0's tweedie: 138.139\n",
      "[141]\tvalid_0's tweedie: 138.139\n",
      "[142]\tvalid_0's tweedie: 138.139\n",
      "[143]\tvalid_0's tweedie: 138.139\n",
      "[144]\tvalid_0's tweedie: 138.139\n",
      "[145]\tvalid_0's tweedie: 138.139\n",
      "[146]\tvalid_0's tweedie: 138.14\n",
      "[147]\tvalid_0's tweedie: 138.14\n",
      "[148]\tvalid_0's tweedie: 138.139\n",
      "[149]\tvalid_0's tweedie: 138.139\n",
      "[150]\tvalid_0's tweedie: 138.139\n",
      "[151]\tvalid_0's tweedie: 138.139\n",
      "[152]\tvalid_0's tweedie: 138.139\n",
      "[153]\tvalid_0's tweedie: 138.139\n",
      "[154]\tvalid_0's tweedie: 138.139\n",
      "[155]\tvalid_0's tweedie: 138.139\n",
      "[156]\tvalid_0's tweedie: 138.14\n",
      "[157]\tvalid_0's tweedie: 138.139\n",
      "[158]\tvalid_0's tweedie: 138.139\n",
      "[159]\tvalid_0's tweedie: 138.139\n",
      "[160]\tvalid_0's tweedie: 138.139\n",
      "[161]\tvalid_0's tweedie: 138.139\n",
      "[162]\tvalid_0's tweedie: 138.139\n",
      "[163]\tvalid_0's tweedie: 138.139\n",
      "[164]\tvalid_0's tweedie: 138.139\n",
      "[165]\tvalid_0's tweedie: 138.139\n",
      "[166]\tvalid_0's tweedie: 138.139\n",
      "[167]\tvalid_0's tweedie: 138.139\n",
      "[168]\tvalid_0's tweedie: 138.139\n",
      "[169]\tvalid_0's tweedie: 138.138\n",
      "[170]\tvalid_0's tweedie: 138.138\n",
      "[171]\tvalid_0's tweedie: 138.138\n",
      "[172]\tvalid_0's tweedie: 138.138\n",
      "[173]\tvalid_0's tweedie: 138.138\n",
      "[174]\tvalid_0's tweedie: 138.138\n",
      "[175]\tvalid_0's tweedie: 138.137\n",
      "[176]\tvalid_0's tweedie: 138.137\n",
      "[177]\tvalid_0's tweedie: 138.137\n",
      "[178]\tvalid_0's tweedie: 138.137\n",
      "[179]\tvalid_0's tweedie: 138.137\n",
      "[180]\tvalid_0's tweedie: 138.137\n",
      "[181]\tvalid_0's tweedie: 138.137\n",
      "[182]\tvalid_0's tweedie: 138.137\n",
      "[183]\tvalid_0's tweedie: 138.137\n",
      "[184]\tvalid_0's tweedie: 138.137\n",
      "[185]\tvalid_0's tweedie: 138.137\n",
      "[186]\tvalid_0's tweedie: 138.137\n",
      "[187]\tvalid_0's tweedie: 138.137\n",
      "[188]\tvalid_0's tweedie: 138.137\n",
      "[189]\tvalid_0's tweedie: 138.137\n",
      "[190]\tvalid_0's tweedie: 138.137\n",
      "[191]\tvalid_0's tweedie: 138.137\n",
      "[192]\tvalid_0's tweedie: 138.137\n",
      "[193]\tvalid_0's tweedie: 138.137\n",
      "[194]\tvalid_0's tweedie: 138.137\n",
      "[195]\tvalid_0's tweedie: 138.137\n",
      "[196]\tvalid_0's tweedie: 138.137\n",
      "[197]\tvalid_0's tweedie: 138.137\n",
      "[198]\tvalid_0's tweedie: 138.137\n",
      "[199]\tvalid_0's tweedie: 138.136\n",
      "[200]\tvalid_0's tweedie: 138.136\n",
      "[201]\tvalid_0's tweedie: 138.136\n",
      "[202]\tvalid_0's tweedie: 138.136\n",
      "[203]\tvalid_0's tweedie: 138.136\n",
      "[204]\tvalid_0's tweedie: 138.136\n",
      "[205]\tvalid_0's tweedie: 138.136\n",
      "[206]\tvalid_0's tweedie: 138.135\n",
      "[207]\tvalid_0's tweedie: 138.135\n",
      "[208]\tvalid_0's tweedie: 138.135\n",
      "[209]\tvalid_0's tweedie: 138.135\n",
      "[210]\tvalid_0's tweedie: 138.135\n",
      "[211]\tvalid_0's tweedie: 138.135\n",
      "[212]\tvalid_0's tweedie: 138.135\n",
      "[213]\tvalid_0's tweedie: 138.135\n",
      "[214]\tvalid_0's tweedie: 138.135\n",
      "[215]\tvalid_0's tweedie: 138.135\n",
      "[216]\tvalid_0's tweedie: 138.135\n",
      "[217]\tvalid_0's tweedie: 138.135\n",
      "[218]\tvalid_0's tweedie: 138.135\n",
      "[219]\tvalid_0's tweedie: 138.135\n",
      "[220]\tvalid_0's tweedie: 138.135\n",
      "[221]\tvalid_0's tweedie: 138.135\n",
      "[222]\tvalid_0's tweedie: 138.135\n",
      "[223]\tvalid_0's tweedie: 138.135\n",
      "[224]\tvalid_0's tweedie: 138.135\n",
      "[225]\tvalid_0's tweedie: 138.135\n",
      "[226]\tvalid_0's tweedie: 138.135\n",
      "[227]\tvalid_0's tweedie: 138.135\n",
      "[228]\tvalid_0's tweedie: 138.135\n",
      "[229]\tvalid_0's tweedie: 138.135\n",
      "[230]\tvalid_0's tweedie: 138.135\n",
      "[231]\tvalid_0's tweedie: 138.135\n",
      "[232]\tvalid_0's tweedie: 138.135\n",
      "[233]\tvalid_0's tweedie: 138.134\n",
      "[234]\tvalid_0's tweedie: 138.135\n",
      "[235]\tvalid_0's tweedie: 138.135\n",
      "[236]\tvalid_0's tweedie: 138.134\n",
      "[237]\tvalid_0's tweedie: 138.134\n",
      "[238]\tvalid_0's tweedie: 138.134\n",
      "[239]\tvalid_0's tweedie: 138.134\n",
      "[240]\tvalid_0's tweedie: 138.132\n",
      "[241]\tvalid_0's tweedie: 138.132\n",
      "[242]\tvalid_0's tweedie: 138.132\n",
      "[243]\tvalid_0's tweedie: 138.132\n",
      "[244]\tvalid_0's tweedie: 138.132\n",
      "[245]\tvalid_0's tweedie: 138.132\n",
      "[246]\tvalid_0's tweedie: 138.132\n",
      "[247]\tvalid_0's tweedie: 138.132\n",
      "[248]\tvalid_0's tweedie: 138.132\n",
      "[249]\tvalid_0's tweedie: 138.132\n",
      "[250]\tvalid_0's tweedie: 138.132\n",
      "[251]\tvalid_0's tweedie: 138.132\n",
      "[252]\tvalid_0's tweedie: 138.132\n",
      "[253]\tvalid_0's tweedie: 138.132\n",
      "[254]\tvalid_0's tweedie: 138.132\n",
      "[255]\tvalid_0's tweedie: 138.132\n",
      "[256]\tvalid_0's tweedie: 138.132\n",
      "[257]\tvalid_0's tweedie: 138.132\n",
      "[258]\tvalid_0's tweedie: 138.132\n",
      "[259]\tvalid_0's tweedie: 138.132\n",
      "[260]\tvalid_0's tweedie: 138.132\n",
      "[261]\tvalid_0's tweedie: 138.132\n",
      "[262]\tvalid_0's tweedie: 138.132\n",
      "[263]\tvalid_0's tweedie: 138.132\n",
      "[264]\tvalid_0's tweedie: 138.132\n",
      "[265]\tvalid_0's tweedie: 138.132\n",
      "[266]\tvalid_0's tweedie: 138.132\n",
      "[267]\tvalid_0's tweedie: 138.132\n",
      "[268]\tvalid_0's tweedie: 138.132\n",
      "[269]\tvalid_0's tweedie: 138.132\n",
      "[270]\tvalid_0's tweedie: 138.132\n",
      "[271]\tvalid_0's tweedie: 138.132\n",
      "[272]\tvalid_0's tweedie: 138.132\n",
      "[273]\tvalid_0's tweedie: 138.132\n",
      "[274]\tvalid_0's tweedie: 138.132\n",
      "[275]\tvalid_0's tweedie: 138.132\n",
      "[276]\tvalid_0's tweedie: 138.132\n",
      "[277]\tvalid_0's tweedie: 138.131\n",
      "[278]\tvalid_0's tweedie: 138.131\n",
      "[279]\tvalid_0's tweedie: 138.131\n",
      "[280]\tvalid_0's tweedie: 138.131\n",
      "[281]\tvalid_0's tweedie: 138.131\n",
      "[282]\tvalid_0's tweedie: 138.131\n",
      "[283]\tvalid_0's tweedie: 138.131\n",
      "[284]\tvalid_0's tweedie: 138.131\n",
      "[285]\tvalid_0's tweedie: 138.131\n",
      "[286]\tvalid_0's tweedie: 138.131\n",
      "[287]\tvalid_0's tweedie: 138.131\n",
      "[288]\tvalid_0's tweedie: 138.131\n",
      "[289]\tvalid_0's tweedie: 138.131\n",
      "[290]\tvalid_0's tweedie: 138.131\n",
      "[291]\tvalid_0's tweedie: 138.13\n",
      "[292]\tvalid_0's tweedie: 138.13\n",
      "[293]\tvalid_0's tweedie: 138.13\n",
      "[294]\tvalid_0's tweedie: 138.13\n",
      "[295]\tvalid_0's tweedie: 138.13\n",
      "[296]\tvalid_0's tweedie: 138.13\n",
      "[297]\tvalid_0's tweedie: 138.13\n",
      "[298]\tvalid_0's tweedie: 138.13\n",
      "[299]\tvalid_0's tweedie: 138.13\n",
      "[300]\tvalid_0's tweedie: 138.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 138.13\n",
      "Training model for level 8 and step 21\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/21/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5500\n",
      "[LightGBM] [Info] Number of data points in the train set: 55530, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.043899\n",
      "[1]\tvalid_0's tweedie: 148.688\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.801\n",
      "[3]\tvalid_0's tweedie: 145.249\n",
      "[4]\tvalid_0's tweedie: 143.964\n",
      "[5]\tvalid_0's tweedie: 142.913\n",
      "[6]\tvalid_0's tweedie: 142.038\n",
      "[7]\tvalid_0's tweedie: 141.324\n",
      "[8]\tvalid_0's tweedie: 140.742\n",
      "[9]\tvalid_0's tweedie: 140.266\n",
      "[10]\tvalid_0's tweedie: 139.881\n",
      "[11]\tvalid_0's tweedie: 139.562\n",
      "[12]\tvalid_0's tweedie: 139.301\n",
      "[13]\tvalid_0's tweedie: 139.084\n",
      "[14]\tvalid_0's tweedie: 138.912\n",
      "[15]\tvalid_0's tweedie: 138.772\n",
      "[16]\tvalid_0's tweedie: 138.657\n",
      "[17]\tvalid_0's tweedie: 138.566\n",
      "[18]\tvalid_0's tweedie: 138.489\n",
      "[19]\tvalid_0's tweedie: 138.427\n",
      "[20]\tvalid_0's tweedie: 138.377\n",
      "[21]\tvalid_0's tweedie: 138.335\n",
      "[22]\tvalid_0's tweedie: 138.3\n",
      "[23]\tvalid_0's tweedie: 138.271\n",
      "[24]\tvalid_0's tweedie: 138.248\n",
      "[25]\tvalid_0's tweedie: 138.233\n",
      "[26]\tvalid_0's tweedie: 138.216\n",
      "[27]\tvalid_0's tweedie: 138.206\n",
      "[28]\tvalid_0's tweedie: 138.197\n",
      "[29]\tvalid_0's tweedie: 138.189\n",
      "[30]\tvalid_0's tweedie: 138.183\n",
      "[31]\tvalid_0's tweedie: 138.178\n",
      "[32]\tvalid_0's tweedie: 138.173\n",
      "[33]\tvalid_0's tweedie: 138.168\n",
      "[34]\tvalid_0's tweedie: 138.167\n",
      "[35]\tvalid_0's tweedie: 138.164\n",
      "[36]\tvalid_0's tweedie: 138.162\n",
      "[37]\tvalid_0's tweedie: 138.161\n",
      "[38]\tvalid_0's tweedie: 138.159\n",
      "[39]\tvalid_0's tweedie: 138.157\n",
      "[40]\tvalid_0's tweedie: 138.156\n",
      "[41]\tvalid_0's tweedie: 138.156\n",
      "[42]\tvalid_0's tweedie: 138.156\n",
      "[43]\tvalid_0's tweedie: 138.155\n",
      "[44]\tvalid_0's tweedie: 138.156\n",
      "[45]\tvalid_0's tweedie: 138.155\n",
      "[46]\tvalid_0's tweedie: 138.154\n",
      "[47]\tvalid_0's tweedie: 138.153\n",
      "[48]\tvalid_0's tweedie: 138.152\n",
      "[49]\tvalid_0's tweedie: 138.153\n",
      "[50]\tvalid_0's tweedie: 138.152\n",
      "[51]\tvalid_0's tweedie: 138.15\n",
      "[52]\tvalid_0's tweedie: 138.15\n",
      "[53]\tvalid_0's tweedie: 138.15\n",
      "[54]\tvalid_0's tweedie: 138.151\n",
      "[55]\tvalid_0's tweedie: 138.152\n",
      "[56]\tvalid_0's tweedie: 138.151\n",
      "[57]\tvalid_0's tweedie: 138.151\n",
      "[58]\tvalid_0's tweedie: 138.151\n",
      "[59]\tvalid_0's tweedie: 138.151\n",
      "[60]\tvalid_0's tweedie: 138.151\n",
      "[61]\tvalid_0's tweedie: 138.152\n",
      "[62]\tvalid_0's tweedie: 138.152\n",
      "[63]\tvalid_0's tweedie: 138.152\n",
      "[64]\tvalid_0's tweedie: 138.152\n",
      "[65]\tvalid_0's tweedie: 138.152\n",
      "[66]\tvalid_0's tweedie: 138.152\n",
      "[67]\tvalid_0's tweedie: 138.152\n",
      "[68]\tvalid_0's tweedie: 138.151\n",
      "[69]\tvalid_0's tweedie: 138.151\n",
      "[70]\tvalid_0's tweedie: 138.151\n",
      "[71]\tvalid_0's tweedie: 138.151\n",
      "[72]\tvalid_0's tweedie: 138.151\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's tweedie: 138.15\n",
      "Training model for level 8 and step 22\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/22/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5499\n",
      "[LightGBM] [Info] Number of data points in the train set: 55500, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044069\n",
      "[1]\tvalid_0's tweedie: 148.693\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.823\n",
      "[3]\tvalid_0's tweedie: 145.268\n",
      "[4]\tvalid_0's tweedie: 143.988\n",
      "[5]\tvalid_0's tweedie: 142.926\n",
      "[6]\tvalid_0's tweedie: 142.051\n",
      "[7]\tvalid_0's tweedie: 141.334\n",
      "[8]\tvalid_0's tweedie: 140.755\n",
      "[9]\tvalid_0's tweedie: 140.281\n",
      "[10]\tvalid_0's tweedie: 139.891\n",
      "[11]\tvalid_0's tweedie: 139.577\n",
      "[12]\tvalid_0's tweedie: 139.314\n",
      "[13]\tvalid_0's tweedie: 139.103\n",
      "[14]\tvalid_0's tweedie: 138.929\n",
      "[15]\tvalid_0's tweedie: 138.788\n",
      "[16]\tvalid_0's tweedie: 138.67\n",
      "[17]\tvalid_0's tweedie: 138.576\n",
      "[18]\tvalid_0's tweedie: 138.498\n",
      "[19]\tvalid_0's tweedie: 138.434\n",
      "[20]\tvalid_0's tweedie: 138.381\n",
      "[21]\tvalid_0's tweedie: 138.338\n",
      "[22]\tvalid_0's tweedie: 138.304\n",
      "[23]\tvalid_0's tweedie: 138.275\n",
      "[24]\tvalid_0's tweedie: 138.254\n",
      "[25]\tvalid_0's tweedie: 138.237\n",
      "[26]\tvalid_0's tweedie: 138.221\n",
      "[27]\tvalid_0's tweedie: 138.21\n",
      "[28]\tvalid_0's tweedie: 138.2\n",
      "[29]\tvalid_0's tweedie: 138.191\n",
      "[30]\tvalid_0's tweedie: 138.185\n",
      "[31]\tvalid_0's tweedie: 138.181\n",
      "[32]\tvalid_0's tweedie: 138.176\n",
      "[33]\tvalid_0's tweedie: 138.174\n",
      "[34]\tvalid_0's tweedie: 138.171\n",
      "[35]\tvalid_0's tweedie: 138.17\n",
      "[36]\tvalid_0's tweedie: 138.167\n",
      "[37]\tvalid_0's tweedie: 138.165\n",
      "[38]\tvalid_0's tweedie: 138.164\n",
      "[39]\tvalid_0's tweedie: 138.162\n",
      "[40]\tvalid_0's tweedie: 138.16\n",
      "[41]\tvalid_0's tweedie: 138.158\n",
      "[42]\tvalid_0's tweedie: 138.157\n",
      "[43]\tvalid_0's tweedie: 138.156\n",
      "[44]\tvalid_0's tweedie: 138.156\n",
      "[45]\tvalid_0's tweedie: 138.155\n",
      "[46]\tvalid_0's tweedie: 138.153\n",
      "[47]\tvalid_0's tweedie: 138.153\n",
      "[48]\tvalid_0's tweedie: 138.153\n",
      "[49]\tvalid_0's tweedie: 138.152\n",
      "[50]\tvalid_0's tweedie: 138.151\n",
      "[51]\tvalid_0's tweedie: 138.151\n",
      "[52]\tvalid_0's tweedie: 138.152\n",
      "[53]\tvalid_0's tweedie: 138.152\n",
      "[54]\tvalid_0's tweedie: 138.151\n",
      "[55]\tvalid_0's tweedie: 138.151\n",
      "[56]\tvalid_0's tweedie: 138.151\n",
      "[57]\tvalid_0's tweedie: 138.152\n",
      "[58]\tvalid_0's tweedie: 138.151\n",
      "[59]\tvalid_0's tweedie: 138.152\n",
      "[60]\tvalid_0's tweedie: 138.152\n",
      "[61]\tvalid_0's tweedie: 138.152\n",
      "[62]\tvalid_0's tweedie: 138.152\n",
      "[63]\tvalid_0's tweedie: 138.152\n",
      "[64]\tvalid_0's tweedie: 138.152\n",
      "[65]\tvalid_0's tweedie: 138.152\n",
      "[66]\tvalid_0's tweedie: 138.152\n",
      "[67]\tvalid_0's tweedie: 138.152\n",
      "[68]\tvalid_0's tweedie: 138.152\n",
      "[69]\tvalid_0's tweedie: 138.151\n",
      "[70]\tvalid_0's tweedie: 138.151\n",
      "[71]\tvalid_0's tweedie: 138.151\n",
      "[72]\tvalid_0's tweedie: 138.151\n",
      "[73]\tvalid_0's tweedie: 138.151\n",
      "[74]\tvalid_0's tweedie: 138.151\n",
      "[75]\tvalid_0's tweedie: 138.151\n",
      "[76]\tvalid_0's tweedie: 138.151\n",
      "[77]\tvalid_0's tweedie: 138.151\n",
      "[78]\tvalid_0's tweedie: 138.151\n",
      "[79]\tvalid_0's tweedie: 138.15\n",
      "[80]\tvalid_0's tweedie: 138.15\n",
      "[81]\tvalid_0's tweedie: 138.15\n",
      "[82]\tvalid_0's tweedie: 138.15\n",
      "[83]\tvalid_0's tweedie: 138.15\n",
      "[84]\tvalid_0's tweedie: 138.15\n",
      "[85]\tvalid_0's tweedie: 138.15\n",
      "[86]\tvalid_0's tweedie: 138.15\n",
      "[87]\tvalid_0's tweedie: 138.15\n",
      "[88]\tvalid_0's tweedie: 138.149\n",
      "[89]\tvalid_0's tweedie: 138.149\n",
      "[90]\tvalid_0's tweedie: 138.149\n",
      "[91]\tvalid_0's tweedie: 138.148\n",
      "[92]\tvalid_0's tweedie: 138.148\n",
      "[93]\tvalid_0's tweedie: 138.148\n",
      "[94]\tvalid_0's tweedie: 138.148\n",
      "[95]\tvalid_0's tweedie: 138.148\n",
      "[96]\tvalid_0's tweedie: 138.148\n",
      "[97]\tvalid_0's tweedie: 138.148\n",
      "[98]\tvalid_0's tweedie: 138.148\n",
      "[99]\tvalid_0's tweedie: 138.147\n",
      "[100]\tvalid_0's tweedie: 138.147\n",
      "[101]\tvalid_0's tweedie: 138.147\n",
      "[102]\tvalid_0's tweedie: 138.147\n",
      "[103]\tvalid_0's tweedie: 138.147\n",
      "[104]\tvalid_0's tweedie: 138.147\n",
      "[105]\tvalid_0's tweedie: 138.147\n",
      "[106]\tvalid_0's tweedie: 138.147\n",
      "[107]\tvalid_0's tweedie: 138.147\n",
      "[108]\tvalid_0's tweedie: 138.147\n",
      "[109]\tvalid_0's tweedie: 138.147\n",
      "[110]\tvalid_0's tweedie: 138.147\n",
      "[111]\tvalid_0's tweedie: 138.147\n",
      "[112]\tvalid_0's tweedie: 138.147\n",
      "[113]\tvalid_0's tweedie: 138.146\n",
      "[114]\tvalid_0's tweedie: 138.146\n",
      "[115]\tvalid_0's tweedie: 138.146\n",
      "[116]\tvalid_0's tweedie: 138.146\n",
      "[117]\tvalid_0's tweedie: 138.146\n",
      "[118]\tvalid_0's tweedie: 138.146\n",
      "[119]\tvalid_0's tweedie: 138.146\n",
      "[120]\tvalid_0's tweedie: 138.146\n",
      "[121]\tvalid_0's tweedie: 138.146\n",
      "[122]\tvalid_0's tweedie: 138.146\n",
      "[123]\tvalid_0's tweedie: 138.146\n",
      "[124]\tvalid_0's tweedie: 138.146\n",
      "[125]\tvalid_0's tweedie: 138.145\n",
      "[126]\tvalid_0's tweedie: 138.145\n",
      "[127]\tvalid_0's tweedie: 138.145\n",
      "[128]\tvalid_0's tweedie: 138.145\n",
      "[129]\tvalid_0's tweedie: 138.145\n",
      "[130]\tvalid_0's tweedie: 138.145\n",
      "[131]\tvalid_0's tweedie: 138.145\n",
      "[132]\tvalid_0's tweedie: 138.145\n",
      "[133]\tvalid_0's tweedie: 138.145\n",
      "[134]\tvalid_0's tweedie: 138.144\n",
      "[135]\tvalid_0's tweedie: 138.145\n",
      "[136]\tvalid_0's tweedie: 138.145\n",
      "[137]\tvalid_0's tweedie: 138.145\n",
      "[138]\tvalid_0's tweedie: 138.145\n",
      "[139]\tvalid_0's tweedie: 138.145\n",
      "[140]\tvalid_0's tweedie: 138.143\n",
      "[141]\tvalid_0's tweedie: 138.143\n",
      "[142]\tvalid_0's tweedie: 138.143\n",
      "[143]\tvalid_0's tweedie: 138.143\n",
      "[144]\tvalid_0's tweedie: 138.143\n",
      "[145]\tvalid_0's tweedie: 138.143\n",
      "[146]\tvalid_0's tweedie: 138.143\n",
      "[147]\tvalid_0's tweedie: 138.143\n",
      "[148]\tvalid_0's tweedie: 138.142\n",
      "[149]\tvalid_0's tweedie: 138.142\n",
      "[150]\tvalid_0's tweedie: 138.142\n",
      "[151]\tvalid_0's tweedie: 138.142\n",
      "[152]\tvalid_0's tweedie: 138.142\n",
      "[153]\tvalid_0's tweedie: 138.142\n",
      "[154]\tvalid_0's tweedie: 138.142\n",
      "[155]\tvalid_0's tweedie: 138.142\n",
      "[156]\tvalid_0's tweedie: 138.142\n",
      "[157]\tvalid_0's tweedie: 138.142\n",
      "[158]\tvalid_0's tweedie: 138.142\n",
      "[159]\tvalid_0's tweedie: 138.142\n",
      "[160]\tvalid_0's tweedie: 138.142\n",
      "[161]\tvalid_0's tweedie: 138.141\n",
      "[162]\tvalid_0's tweedie: 138.141\n",
      "[163]\tvalid_0's tweedie: 138.141\n",
      "[164]\tvalid_0's tweedie: 138.141\n",
      "[165]\tvalid_0's tweedie: 138.141\n",
      "[166]\tvalid_0's tweedie: 138.141\n",
      "[167]\tvalid_0's tweedie: 138.141\n",
      "[168]\tvalid_0's tweedie: 138.139\n",
      "[169]\tvalid_0's tweedie: 138.139\n",
      "[170]\tvalid_0's tweedie: 138.139\n",
      "[171]\tvalid_0's tweedie: 138.139\n",
      "[172]\tvalid_0's tweedie: 138.139\n",
      "[173]\tvalid_0's tweedie: 138.139\n",
      "[174]\tvalid_0's tweedie: 138.138\n",
      "[175]\tvalid_0's tweedie: 138.137\n",
      "[176]\tvalid_0's tweedie: 138.137\n",
      "[177]\tvalid_0's tweedie: 138.137\n",
      "[178]\tvalid_0's tweedie: 138.137\n",
      "[179]\tvalid_0's tweedie: 138.137\n",
      "[180]\tvalid_0's tweedie: 138.137\n",
      "[181]\tvalid_0's tweedie: 138.137\n",
      "[182]\tvalid_0's tweedie: 138.137\n",
      "[183]\tvalid_0's tweedie: 138.137\n",
      "[184]\tvalid_0's tweedie: 138.137\n",
      "[185]\tvalid_0's tweedie: 138.137\n",
      "[186]\tvalid_0's tweedie: 138.137\n",
      "[187]\tvalid_0's tweedie: 138.137\n",
      "[188]\tvalid_0's tweedie: 138.137\n",
      "[189]\tvalid_0's tweedie: 138.137\n",
      "[190]\tvalid_0's tweedie: 138.137\n",
      "[191]\tvalid_0's tweedie: 138.137\n",
      "[192]\tvalid_0's tweedie: 138.137\n",
      "[193]\tvalid_0's tweedie: 138.137\n",
      "[194]\tvalid_0's tweedie: 138.136\n",
      "[195]\tvalid_0's tweedie: 138.135\n",
      "[196]\tvalid_0's tweedie: 138.135\n",
      "[197]\tvalid_0's tweedie: 138.135\n",
      "[198]\tvalid_0's tweedie: 138.135\n",
      "[199]\tvalid_0's tweedie: 138.134\n",
      "[200]\tvalid_0's tweedie: 138.134\n",
      "[201]\tvalid_0's tweedie: 138.134\n",
      "[202]\tvalid_0's tweedie: 138.134\n",
      "[203]\tvalid_0's tweedie: 138.134\n",
      "[204]\tvalid_0's tweedie: 138.134\n",
      "[205]\tvalid_0's tweedie: 138.134\n",
      "[206]\tvalid_0's tweedie: 138.133\n",
      "[207]\tvalid_0's tweedie: 138.133\n",
      "[208]\tvalid_0's tweedie: 138.133\n",
      "[209]\tvalid_0's tweedie: 138.133\n",
      "[210]\tvalid_0's tweedie: 138.133\n",
      "[211]\tvalid_0's tweedie: 138.133\n",
      "[212]\tvalid_0's tweedie: 138.133\n",
      "[213]\tvalid_0's tweedie: 138.133\n",
      "[214]\tvalid_0's tweedie: 138.133\n",
      "[215]\tvalid_0's tweedie: 138.133\n",
      "[216]\tvalid_0's tweedie: 138.133\n",
      "[217]\tvalid_0's tweedie: 138.133\n",
      "[218]\tvalid_0's tweedie: 138.133\n",
      "[219]\tvalid_0's tweedie: 138.132\n",
      "[220]\tvalid_0's tweedie: 138.132\n",
      "[221]\tvalid_0's tweedie: 138.132\n",
      "[222]\tvalid_0's tweedie: 138.133\n",
      "[223]\tvalid_0's tweedie: 138.131\n",
      "[224]\tvalid_0's tweedie: 138.131\n",
      "[225]\tvalid_0's tweedie: 138.131\n",
      "[226]\tvalid_0's tweedie: 138.131\n",
      "[227]\tvalid_0's tweedie: 138.131\n",
      "[228]\tvalid_0's tweedie: 138.131\n",
      "[229]\tvalid_0's tweedie: 138.13\n",
      "[230]\tvalid_0's tweedie: 138.13\n",
      "[231]\tvalid_0's tweedie: 138.131\n",
      "[232]\tvalid_0's tweedie: 138.13\n",
      "[233]\tvalid_0's tweedie: 138.13\n",
      "[234]\tvalid_0's tweedie: 138.13\n",
      "[235]\tvalid_0's tweedie: 138.13\n",
      "[236]\tvalid_0's tweedie: 138.13\n",
      "[237]\tvalid_0's tweedie: 138.13\n",
      "[238]\tvalid_0's tweedie: 138.13\n",
      "[239]\tvalid_0's tweedie: 138.13\n",
      "[240]\tvalid_0's tweedie: 138.13\n",
      "[241]\tvalid_0's tweedie: 138.13\n",
      "[242]\tvalid_0's tweedie: 138.13\n",
      "[243]\tvalid_0's tweedie: 138.13\n",
      "[244]\tvalid_0's tweedie: 138.13\n",
      "[245]\tvalid_0's tweedie: 138.13\n",
      "[246]\tvalid_0's tweedie: 138.13\n",
      "[247]\tvalid_0's tweedie: 138.13\n",
      "[248]\tvalid_0's tweedie: 138.13\n",
      "[249]\tvalid_0's tweedie: 138.13\n",
      "[250]\tvalid_0's tweedie: 138.13\n",
      "[251]\tvalid_0's tweedie: 138.13\n",
      "[252]\tvalid_0's tweedie: 138.13\n",
      "[253]\tvalid_0's tweedie: 138.13\n",
      "[254]\tvalid_0's tweedie: 138.129\n",
      "[255]\tvalid_0's tweedie: 138.129\n",
      "[256]\tvalid_0's tweedie: 138.129\n",
      "[257]\tvalid_0's tweedie: 138.129\n",
      "[258]\tvalid_0's tweedie: 138.129\n",
      "[259]\tvalid_0's tweedie: 138.129\n",
      "[260]\tvalid_0's tweedie: 138.129\n",
      "[261]\tvalid_0's tweedie: 138.129\n",
      "[262]\tvalid_0's tweedie: 138.129\n",
      "[263]\tvalid_0's tweedie: 138.129\n",
      "[264]\tvalid_0's tweedie: 138.129\n",
      "[265]\tvalid_0's tweedie: 138.129\n",
      "[266]\tvalid_0's tweedie: 138.129\n",
      "[267]\tvalid_0's tweedie: 138.129\n",
      "[268]\tvalid_0's tweedie: 138.129\n",
      "[269]\tvalid_0's tweedie: 138.129\n",
      "[270]\tvalid_0's tweedie: 138.129\n",
      "[271]\tvalid_0's tweedie: 138.129\n",
      "[272]\tvalid_0's tweedie: 138.129\n",
      "[273]\tvalid_0's tweedie: 138.129\n",
      "[274]\tvalid_0's tweedie: 138.128\n",
      "[275]\tvalid_0's tweedie: 138.128\n",
      "[276]\tvalid_0's tweedie: 138.128\n",
      "[277]\tvalid_0's tweedie: 138.128\n",
      "[278]\tvalid_0's tweedie: 138.128\n",
      "[279]\tvalid_0's tweedie: 138.128\n",
      "[280]\tvalid_0's tweedie: 138.128\n",
      "[281]\tvalid_0's tweedie: 138.128\n",
      "[282]\tvalid_0's tweedie: 138.128\n",
      "[283]\tvalid_0's tweedie: 138.128\n",
      "[284]\tvalid_0's tweedie: 138.128\n",
      "[285]\tvalid_0's tweedie: 138.128\n",
      "[286]\tvalid_0's tweedie: 138.128\n",
      "[287]\tvalid_0's tweedie: 138.127\n",
      "[288]\tvalid_0's tweedie: 138.127\n",
      "[289]\tvalid_0's tweedie: 138.127\n",
      "[290]\tvalid_0's tweedie: 138.127\n",
      "[291]\tvalid_0's tweedie: 138.126\n",
      "[292]\tvalid_0's tweedie: 138.126\n",
      "[293]\tvalid_0's tweedie: 138.126\n",
      "[294]\tvalid_0's tweedie: 138.126\n",
      "[295]\tvalid_0's tweedie: 138.126\n",
      "[296]\tvalid_0's tweedie: 138.126\n",
      "[297]\tvalid_0's tweedie: 138.126\n",
      "[298]\tvalid_0's tweedie: 138.126\n",
      "[299]\tvalid_0's tweedie: 138.126\n",
      "[300]\tvalid_0's tweedie: 138.126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[298]\tvalid_0's tweedie: 138.126\n",
      "Training model for level 8 and step 23\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/23/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5498\n",
      "[LightGBM] [Info] Number of data points in the train set: 55470, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044119\n",
      "[1]\tvalid_0's tweedie: 148.691\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.823\n",
      "[3]\tvalid_0's tweedie: 145.259\n",
      "[4]\tvalid_0's tweedie: 143.978\n",
      "[5]\tvalid_0's tweedie: 142.926\n",
      "[6]\tvalid_0's tweedie: 142.054\n",
      "[7]\tvalid_0's tweedie: 141.337\n",
      "[8]\tvalid_0's tweedie: 140.754\n",
      "[9]\tvalid_0's tweedie: 140.283\n",
      "[10]\tvalid_0's tweedie: 139.896\n",
      "[11]\tvalid_0's tweedie: 139.574\n",
      "[12]\tvalid_0's tweedie: 139.312\n",
      "[13]\tvalid_0's tweedie: 139.099\n",
      "[14]\tvalid_0's tweedie: 138.922\n",
      "[15]\tvalid_0's tweedie: 138.78\n",
      "[16]\tvalid_0's tweedie: 138.666\n",
      "[17]\tvalid_0's tweedie: 138.572\n",
      "[18]\tvalid_0's tweedie: 138.493\n",
      "[19]\tvalid_0's tweedie: 138.43\n",
      "[20]\tvalid_0's tweedie: 138.383\n",
      "[21]\tvalid_0's tweedie: 138.34\n",
      "[22]\tvalid_0's tweedie: 138.307\n",
      "[23]\tvalid_0's tweedie: 138.282\n",
      "[24]\tvalid_0's tweedie: 138.259\n",
      "[25]\tvalid_0's tweedie: 138.241\n",
      "[26]\tvalid_0's tweedie: 138.224\n",
      "[27]\tvalid_0's tweedie: 138.211\n",
      "[28]\tvalid_0's tweedie: 138.2\n",
      "[29]\tvalid_0's tweedie: 138.192\n",
      "[30]\tvalid_0's tweedie: 138.187\n",
      "[31]\tvalid_0's tweedie: 138.182\n",
      "[32]\tvalid_0's tweedie: 138.178\n",
      "[33]\tvalid_0's tweedie: 138.175\n",
      "[34]\tvalid_0's tweedie: 138.173\n",
      "[35]\tvalid_0's tweedie: 138.17\n",
      "[36]\tvalid_0's tweedie: 138.168\n",
      "[37]\tvalid_0's tweedie: 138.166\n",
      "[38]\tvalid_0's tweedie: 138.165\n",
      "[39]\tvalid_0's tweedie: 138.162\n",
      "[40]\tvalid_0's tweedie: 138.161\n",
      "[41]\tvalid_0's tweedie: 138.159\n",
      "[42]\tvalid_0's tweedie: 138.159\n",
      "[43]\tvalid_0's tweedie: 138.157\n",
      "[44]\tvalid_0's tweedie: 138.157\n",
      "[45]\tvalid_0's tweedie: 138.158\n",
      "[46]\tvalid_0's tweedie: 138.156\n",
      "[47]\tvalid_0's tweedie: 138.155\n",
      "[48]\tvalid_0's tweedie: 138.154\n",
      "[49]\tvalid_0's tweedie: 138.154\n",
      "[50]\tvalid_0's tweedie: 138.153\n",
      "[51]\tvalid_0's tweedie: 138.153\n",
      "[52]\tvalid_0's tweedie: 138.153\n",
      "[53]\tvalid_0's tweedie: 138.152\n",
      "[54]\tvalid_0's tweedie: 138.152\n",
      "[55]\tvalid_0's tweedie: 138.151\n",
      "[56]\tvalid_0's tweedie: 138.152\n",
      "[57]\tvalid_0's tweedie: 138.152\n",
      "[58]\tvalid_0's tweedie: 138.152\n",
      "[59]\tvalid_0's tweedie: 138.153\n",
      "[60]\tvalid_0's tweedie: 138.153\n",
      "[61]\tvalid_0's tweedie: 138.153\n",
      "[62]\tvalid_0's tweedie: 138.154\n",
      "[63]\tvalid_0's tweedie: 138.154\n",
      "[64]\tvalid_0's tweedie: 138.154\n",
      "[65]\tvalid_0's tweedie: 138.154\n",
      "[66]\tvalid_0's tweedie: 138.154\n",
      "[67]\tvalid_0's tweedie: 138.154\n",
      "[68]\tvalid_0's tweedie: 138.154\n",
      "[69]\tvalid_0's tweedie: 138.154\n",
      "[70]\tvalid_0's tweedie: 138.153\n",
      "[71]\tvalid_0's tweedie: 138.153\n",
      "[72]\tvalid_0's tweedie: 138.153\n",
      "[73]\tvalid_0's tweedie: 138.153\n",
      "[74]\tvalid_0's tweedie: 138.153\n",
      "[75]\tvalid_0's tweedie: 138.153\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's tweedie: 138.151\n",
      "Training model for level 8 and step 24\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/24/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55440, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044111\n",
      "[1]\tvalid_0's tweedie: 148.69\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.817\n",
      "[3]\tvalid_0's tweedie: 145.262\n",
      "[4]\tvalid_0's tweedie: 143.969\n",
      "[5]\tvalid_0's tweedie: 142.912\n",
      "[6]\tvalid_0's tweedie: 142.044\n",
      "[7]\tvalid_0's tweedie: 141.334\n",
      "[8]\tvalid_0's tweedie: 140.749\n",
      "[9]\tvalid_0's tweedie: 140.276\n",
      "[10]\tvalid_0's tweedie: 139.891\n",
      "[11]\tvalid_0's tweedie: 139.57\n",
      "[12]\tvalid_0's tweedie: 139.313\n",
      "[13]\tvalid_0's tweedie: 139.1\n",
      "[14]\tvalid_0's tweedie: 138.927\n",
      "[15]\tvalid_0's tweedie: 138.782\n",
      "[16]\tvalid_0's tweedie: 138.666\n",
      "[17]\tvalid_0's tweedie: 138.571\n",
      "[18]\tvalid_0's tweedie: 138.495\n",
      "[19]\tvalid_0's tweedie: 138.43\n",
      "[20]\tvalid_0's tweedie: 138.38\n",
      "[21]\tvalid_0's tweedie: 138.337\n",
      "[22]\tvalid_0's tweedie: 138.305\n",
      "[23]\tvalid_0's tweedie: 138.275\n",
      "[24]\tvalid_0's tweedie: 138.252\n",
      "[25]\tvalid_0's tweedie: 138.237\n",
      "[26]\tvalid_0's tweedie: 138.224\n",
      "[27]\tvalid_0's tweedie: 138.212\n",
      "[28]\tvalid_0's tweedie: 138.204\n",
      "[29]\tvalid_0's tweedie: 138.196\n",
      "[30]\tvalid_0's tweedie: 138.189\n",
      "[31]\tvalid_0's tweedie: 138.184\n",
      "[32]\tvalid_0's tweedie: 138.18\n",
      "[33]\tvalid_0's tweedie: 138.177\n",
      "[34]\tvalid_0's tweedie: 138.174\n",
      "[35]\tvalid_0's tweedie: 138.172\n",
      "[36]\tvalid_0's tweedie: 138.17\n",
      "[37]\tvalid_0's tweedie: 138.167\n",
      "[38]\tvalid_0's tweedie: 138.165\n",
      "[39]\tvalid_0's tweedie: 138.164\n",
      "[40]\tvalid_0's tweedie: 138.162\n",
      "[41]\tvalid_0's tweedie: 138.161\n",
      "[42]\tvalid_0's tweedie: 138.162\n",
      "[43]\tvalid_0's tweedie: 138.161\n",
      "[44]\tvalid_0's tweedie: 138.16\n",
      "[45]\tvalid_0's tweedie: 138.16\n",
      "[46]\tvalid_0's tweedie: 138.16\n",
      "[47]\tvalid_0's tweedie: 138.16\n",
      "[48]\tvalid_0's tweedie: 138.158\n",
      "[49]\tvalid_0's tweedie: 138.158\n",
      "[50]\tvalid_0's tweedie: 138.156\n",
      "[51]\tvalid_0's tweedie: 138.155\n",
      "[52]\tvalid_0's tweedie: 138.156\n",
      "[53]\tvalid_0's tweedie: 138.156\n",
      "[54]\tvalid_0's tweedie: 138.156\n",
      "[55]\tvalid_0's tweedie: 138.156\n",
      "[56]\tvalid_0's tweedie: 138.156\n",
      "[57]\tvalid_0's tweedie: 138.155\n",
      "[58]\tvalid_0's tweedie: 138.157\n",
      "[59]\tvalid_0's tweedie: 138.156\n",
      "[60]\tvalid_0's tweedie: 138.157\n",
      "[61]\tvalid_0's tweedie: 138.157\n",
      "[62]\tvalid_0's tweedie: 138.157\n",
      "[63]\tvalid_0's tweedie: 138.158\n",
      "[64]\tvalid_0's tweedie: 138.158\n",
      "[65]\tvalid_0's tweedie: 138.157\n",
      "[66]\tvalid_0's tweedie: 138.157\n",
      "[67]\tvalid_0's tweedie: 138.157\n",
      "[68]\tvalid_0's tweedie: 138.158\n",
      "[69]\tvalid_0's tweedie: 138.158\n",
      "[70]\tvalid_0's tweedie: 138.158\n",
      "[71]\tvalid_0's tweedie: 138.158\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's tweedie: 138.155\n",
      "Training model for level 8 and step 25\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/25/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5496\n",
      "[LightGBM] [Info] Number of data points in the train set: 55410, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044266\n",
      "[1]\tvalid_0's tweedie: 148.69\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.812\n",
      "[3]\tvalid_0's tweedie: 145.261\n",
      "[4]\tvalid_0's tweedie: 143.974\n",
      "[5]\tvalid_0's tweedie: 142.916\n",
      "[6]\tvalid_0's tweedie: 142.048\n",
      "[7]\tvalid_0's tweedie: 141.338\n",
      "[8]\tvalid_0's tweedie: 140.753\n",
      "[9]\tvalid_0's tweedie: 140.283\n",
      "[10]\tvalid_0's tweedie: 139.896\n",
      "[11]\tvalid_0's tweedie: 139.575\n",
      "[12]\tvalid_0's tweedie: 139.319\n",
      "[13]\tvalid_0's tweedie: 139.1\n",
      "[14]\tvalid_0's tweedie: 138.924\n",
      "[15]\tvalid_0's tweedie: 138.782\n",
      "[16]\tvalid_0's tweedie: 138.67\n",
      "[17]\tvalid_0's tweedie: 138.573\n",
      "[18]\tvalid_0's tweedie: 138.497\n",
      "[19]\tvalid_0's tweedie: 138.433\n",
      "[20]\tvalid_0's tweedie: 138.383\n",
      "[21]\tvalid_0's tweedie: 138.34\n",
      "[22]\tvalid_0's tweedie: 138.306\n",
      "[23]\tvalid_0's tweedie: 138.277\n",
      "[24]\tvalid_0's tweedie: 138.256\n",
      "[25]\tvalid_0's tweedie: 138.24\n",
      "[26]\tvalid_0's tweedie: 138.225\n",
      "[27]\tvalid_0's tweedie: 138.214\n",
      "[28]\tvalid_0's tweedie: 138.204\n",
      "[29]\tvalid_0's tweedie: 138.197\n",
      "[30]\tvalid_0's tweedie: 138.192\n",
      "[31]\tvalid_0's tweedie: 138.187\n",
      "[32]\tvalid_0's tweedie: 138.182\n",
      "[33]\tvalid_0's tweedie: 138.178\n",
      "[34]\tvalid_0's tweedie: 138.176\n",
      "[35]\tvalid_0's tweedie: 138.173\n",
      "[36]\tvalid_0's tweedie: 138.172\n",
      "[37]\tvalid_0's tweedie: 138.17\n",
      "[38]\tvalid_0's tweedie: 138.169\n",
      "[39]\tvalid_0's tweedie: 138.166\n",
      "[40]\tvalid_0's tweedie: 138.165\n",
      "[41]\tvalid_0's tweedie: 138.163\n",
      "[42]\tvalid_0's tweedie: 138.161\n",
      "[43]\tvalid_0's tweedie: 138.16\n",
      "[44]\tvalid_0's tweedie: 138.161\n",
      "[45]\tvalid_0's tweedie: 138.161\n",
      "[46]\tvalid_0's tweedie: 138.16\n",
      "[47]\tvalid_0's tweedie: 138.159\n",
      "[48]\tvalid_0's tweedie: 138.16\n",
      "[49]\tvalid_0's tweedie: 138.158\n",
      "[50]\tvalid_0's tweedie: 138.158\n",
      "[51]\tvalid_0's tweedie: 138.156\n",
      "[52]\tvalid_0's tweedie: 138.155\n",
      "[53]\tvalid_0's tweedie: 138.155\n",
      "[54]\tvalid_0's tweedie: 138.155\n",
      "[55]\tvalid_0's tweedie: 138.154\n",
      "[56]\tvalid_0's tweedie: 138.156\n",
      "[57]\tvalid_0's tweedie: 138.156\n",
      "[58]\tvalid_0's tweedie: 138.155\n",
      "[59]\tvalid_0's tweedie: 138.155\n",
      "[60]\tvalid_0's tweedie: 138.155\n",
      "[61]\tvalid_0's tweedie: 138.156\n",
      "[62]\tvalid_0's tweedie: 138.155\n",
      "[63]\tvalid_0's tweedie: 138.155\n",
      "[64]\tvalid_0's tweedie: 138.155\n",
      "[65]\tvalid_0's tweedie: 138.154\n",
      "[66]\tvalid_0's tweedie: 138.154\n",
      "[67]\tvalid_0's tweedie: 138.154\n",
      "[68]\tvalid_0's tweedie: 138.154\n",
      "[69]\tvalid_0's tweedie: 138.154\n",
      "[70]\tvalid_0's tweedie: 138.153\n",
      "[71]\tvalid_0's tweedie: 138.153\n",
      "[72]\tvalid_0's tweedie: 138.153\n",
      "[73]\tvalid_0's tweedie: 138.153\n",
      "[74]\tvalid_0's tweedie: 138.153\n",
      "[75]\tvalid_0's tweedie: 138.153\n",
      "[76]\tvalid_0's tweedie: 138.153\n",
      "[77]\tvalid_0's tweedie: 138.152\n",
      "[78]\tvalid_0's tweedie: 138.152\n",
      "[79]\tvalid_0's tweedie: 138.152\n",
      "[80]\tvalid_0's tweedie: 138.152\n",
      "[81]\tvalid_0's tweedie: 138.152\n",
      "[82]\tvalid_0's tweedie: 138.152\n",
      "[83]\tvalid_0's tweedie: 138.152\n",
      "[84]\tvalid_0's tweedie: 138.152\n",
      "[85]\tvalid_0's tweedie: 138.152\n",
      "[86]\tvalid_0's tweedie: 138.152\n",
      "[87]\tvalid_0's tweedie: 138.152\n",
      "[88]\tvalid_0's tweedie: 138.152\n",
      "[89]\tvalid_0's tweedie: 138.152\n",
      "[90]\tvalid_0's tweedie: 138.152\n",
      "[91]\tvalid_0's tweedie: 138.152\n",
      "[92]\tvalid_0's tweedie: 138.153\n",
      "[93]\tvalid_0's tweedie: 138.152\n",
      "[94]\tvalid_0's tweedie: 138.153\n",
      "[95]\tvalid_0's tweedie: 138.153\n",
      "[96]\tvalid_0's tweedie: 138.153\n",
      "[97]\tvalid_0's tweedie: 138.151\n",
      "[98]\tvalid_0's tweedie: 138.152\n",
      "[99]\tvalid_0's tweedie: 138.152\n",
      "[100]\tvalid_0's tweedie: 138.151\n",
      "[101]\tvalid_0's tweedie: 138.151\n",
      "[102]\tvalid_0's tweedie: 138.151\n",
      "[103]\tvalid_0's tweedie: 138.151\n",
      "[104]\tvalid_0's tweedie: 138.151\n",
      "[105]\tvalid_0's tweedie: 138.151\n",
      "[106]\tvalid_0's tweedie: 138.15\n",
      "[107]\tvalid_0's tweedie: 138.15\n",
      "[108]\tvalid_0's tweedie: 138.15\n",
      "[109]\tvalid_0's tweedie: 138.15\n",
      "[110]\tvalid_0's tweedie: 138.15\n",
      "[111]\tvalid_0's tweedie: 138.15\n",
      "[112]\tvalid_0's tweedie: 138.15\n",
      "[113]\tvalid_0's tweedie: 138.15\n",
      "[114]\tvalid_0's tweedie: 138.15\n",
      "[115]\tvalid_0's tweedie: 138.149\n",
      "[116]\tvalid_0's tweedie: 138.15\n",
      "[117]\tvalid_0's tweedie: 138.15\n",
      "[118]\tvalid_0's tweedie: 138.149\n",
      "[119]\tvalid_0's tweedie: 138.15\n",
      "[120]\tvalid_0's tweedie: 138.149\n",
      "[121]\tvalid_0's tweedie: 138.15\n",
      "[122]\tvalid_0's tweedie: 138.149\n",
      "[123]\tvalid_0's tweedie: 138.149\n",
      "[124]\tvalid_0's tweedie: 138.149\n",
      "[125]\tvalid_0's tweedie: 138.149\n",
      "[126]\tvalid_0's tweedie: 138.149\n",
      "[127]\tvalid_0's tweedie: 138.149\n",
      "[128]\tvalid_0's tweedie: 138.149\n",
      "[129]\tvalid_0's tweedie: 138.149\n",
      "[130]\tvalid_0's tweedie: 138.149\n",
      "[131]\tvalid_0's tweedie: 138.149\n",
      "[132]\tvalid_0's tweedie: 138.149\n",
      "[133]\tvalid_0's tweedie: 138.149\n",
      "[134]\tvalid_0's tweedie: 138.149\n",
      "[135]\tvalid_0's tweedie: 138.149\n",
      "[136]\tvalid_0's tweedie: 138.149\n",
      "[137]\tvalid_0's tweedie: 138.149\n",
      "[138]\tvalid_0's tweedie: 138.147\n",
      "[139]\tvalid_0's tweedie: 138.146\n",
      "[140]\tvalid_0's tweedie: 138.146\n",
      "[141]\tvalid_0's tweedie: 138.147\n",
      "[142]\tvalid_0's tweedie: 138.147\n",
      "[143]\tvalid_0's tweedie: 138.147\n",
      "[144]\tvalid_0's tweedie: 138.147\n",
      "[145]\tvalid_0's tweedie: 138.147\n",
      "[146]\tvalid_0's tweedie: 138.147\n",
      "[147]\tvalid_0's tweedie: 138.147\n",
      "[148]\tvalid_0's tweedie: 138.147\n",
      "[149]\tvalid_0's tweedie: 138.147\n",
      "[150]\tvalid_0's tweedie: 138.147\n",
      "[151]\tvalid_0's tweedie: 138.147\n",
      "[152]\tvalid_0's tweedie: 138.147\n",
      "[153]\tvalid_0's tweedie: 138.146\n",
      "[154]\tvalid_0's tweedie: 138.146\n",
      "[155]\tvalid_0's tweedie: 138.146\n",
      "[156]\tvalid_0's tweedie: 138.146\n",
      "[157]\tvalid_0's tweedie: 138.146\n",
      "[158]\tvalid_0's tweedie: 138.146\n",
      "[159]\tvalid_0's tweedie: 138.146\n",
      "[160]\tvalid_0's tweedie: 138.146\n",
      "[161]\tvalid_0's tweedie: 138.146\n",
      "[162]\tvalid_0's tweedie: 138.146\n",
      "[163]\tvalid_0's tweedie: 138.145\n",
      "[164]\tvalid_0's tweedie: 138.145\n",
      "[165]\tvalid_0's tweedie: 138.145\n",
      "[166]\tvalid_0's tweedie: 138.145\n",
      "[167]\tvalid_0's tweedie: 138.145\n",
      "[168]\tvalid_0's tweedie: 138.144\n",
      "[169]\tvalid_0's tweedie: 138.144\n",
      "[170]\tvalid_0's tweedie: 138.144\n",
      "[171]\tvalid_0's tweedie: 138.144\n",
      "[172]\tvalid_0's tweedie: 138.144\n",
      "[173]\tvalid_0's tweedie: 138.144\n",
      "[174]\tvalid_0's tweedie: 138.144\n",
      "[175]\tvalid_0's tweedie: 138.144\n",
      "[176]\tvalid_0's tweedie: 138.143\n",
      "[177]\tvalid_0's tweedie: 138.144\n",
      "[178]\tvalid_0's tweedie: 138.143\n",
      "[179]\tvalid_0's tweedie: 138.143\n",
      "[180]\tvalid_0's tweedie: 138.143\n",
      "[181]\tvalid_0's tweedie: 138.143\n",
      "[182]\tvalid_0's tweedie: 138.143\n",
      "[183]\tvalid_0's tweedie: 138.143\n",
      "[184]\tvalid_0's tweedie: 138.143\n",
      "[185]\tvalid_0's tweedie: 138.143\n",
      "[186]\tvalid_0's tweedie: 138.143\n",
      "[187]\tvalid_0's tweedie: 138.143\n",
      "[188]\tvalid_0's tweedie: 138.143\n",
      "[189]\tvalid_0's tweedie: 138.143\n",
      "[190]\tvalid_0's tweedie: 138.143\n",
      "[191]\tvalid_0's tweedie: 138.143\n",
      "[192]\tvalid_0's tweedie: 138.143\n",
      "[193]\tvalid_0's tweedie: 138.141\n",
      "[194]\tvalid_0's tweedie: 138.141\n",
      "[195]\tvalid_0's tweedie: 138.141\n",
      "[196]\tvalid_0's tweedie: 138.142\n",
      "[197]\tvalid_0's tweedie: 138.142\n",
      "[198]\tvalid_0's tweedie: 138.142\n",
      "[199]\tvalid_0's tweedie: 138.141\n",
      "[200]\tvalid_0's tweedie: 138.141\n",
      "[201]\tvalid_0's tweedie: 138.141\n",
      "[202]\tvalid_0's tweedie: 138.141\n",
      "[203]\tvalid_0's tweedie: 138.141\n",
      "[204]\tvalid_0's tweedie: 138.141\n",
      "[205]\tvalid_0's tweedie: 138.141\n",
      "[206]\tvalid_0's tweedie: 138.141\n",
      "[207]\tvalid_0's tweedie: 138.141\n",
      "[208]\tvalid_0's tweedie: 138.141\n",
      "[209]\tvalid_0's tweedie: 138.141\n",
      "[210]\tvalid_0's tweedie: 138.141\n",
      "[211]\tvalid_0's tweedie: 138.141\n",
      "[212]\tvalid_0's tweedie: 138.141\n",
      "[213]\tvalid_0's tweedie: 138.14\n",
      "[214]\tvalid_0's tweedie: 138.14\n",
      "[215]\tvalid_0's tweedie: 138.14\n",
      "[216]\tvalid_0's tweedie: 138.14\n",
      "[217]\tvalid_0's tweedie: 138.14\n",
      "[218]\tvalid_0's tweedie: 138.14\n",
      "[219]\tvalid_0's tweedie: 138.14\n",
      "[220]\tvalid_0's tweedie: 138.14\n",
      "[221]\tvalid_0's tweedie: 138.141\n",
      "[222]\tvalid_0's tweedie: 138.14\n",
      "[223]\tvalid_0's tweedie: 138.141\n",
      "[224]\tvalid_0's tweedie: 138.141\n",
      "[225]\tvalid_0's tweedie: 138.14\n",
      "[226]\tvalid_0's tweedie: 138.14\n",
      "[227]\tvalid_0's tweedie: 138.14\n",
      "[228]\tvalid_0's tweedie: 138.14\n",
      "[229]\tvalid_0's tweedie: 138.14\n",
      "[230]\tvalid_0's tweedie: 138.14\n",
      "[231]\tvalid_0's tweedie: 138.14\n",
      "[232]\tvalid_0's tweedie: 138.14\n",
      "[233]\tvalid_0's tweedie: 138.14\n",
      "[234]\tvalid_0's tweedie: 138.139\n",
      "[235]\tvalid_0's tweedie: 138.139\n",
      "[236]\tvalid_0's tweedie: 138.139\n",
      "[237]\tvalid_0's tweedie: 138.14\n",
      "[238]\tvalid_0's tweedie: 138.14\n",
      "[239]\tvalid_0's tweedie: 138.139\n",
      "[240]\tvalid_0's tweedie: 138.139\n",
      "[241]\tvalid_0's tweedie: 138.139\n",
      "[242]\tvalid_0's tweedie: 138.139\n",
      "[243]\tvalid_0's tweedie: 138.139\n",
      "[244]\tvalid_0's tweedie: 138.139\n",
      "[245]\tvalid_0's tweedie: 138.139\n",
      "[246]\tvalid_0's tweedie: 138.139\n",
      "[247]\tvalid_0's tweedie: 138.139\n",
      "[248]\tvalid_0's tweedie: 138.139\n",
      "[249]\tvalid_0's tweedie: 138.139\n",
      "[250]\tvalid_0's tweedie: 138.139\n",
      "[251]\tvalid_0's tweedie: 138.139\n",
      "[252]\tvalid_0's tweedie: 138.138\n",
      "[253]\tvalid_0's tweedie: 138.138\n",
      "[254]\tvalid_0's tweedie: 138.138\n",
      "[255]\tvalid_0's tweedie: 138.138\n",
      "[256]\tvalid_0's tweedie: 138.138\n",
      "[257]\tvalid_0's tweedie: 138.138\n",
      "[258]\tvalid_0's tweedie: 138.138\n",
      "[259]\tvalid_0's tweedie: 138.138\n",
      "[260]\tvalid_0's tweedie: 138.138\n",
      "[261]\tvalid_0's tweedie: 138.138\n",
      "[262]\tvalid_0's tweedie: 138.138\n",
      "[263]\tvalid_0's tweedie: 138.138\n",
      "[264]\tvalid_0's tweedie: 138.138\n",
      "[265]\tvalid_0's tweedie: 138.138\n",
      "[266]\tvalid_0's tweedie: 138.138\n",
      "[267]\tvalid_0's tweedie: 138.137\n",
      "[268]\tvalid_0's tweedie: 138.137\n",
      "[269]\tvalid_0's tweedie: 138.137\n",
      "[270]\tvalid_0's tweedie: 138.137\n",
      "[271]\tvalid_0's tweedie: 138.137\n",
      "[272]\tvalid_0's tweedie: 138.137\n",
      "[273]\tvalid_0's tweedie: 138.137\n",
      "[274]\tvalid_0's tweedie: 138.137\n",
      "[275]\tvalid_0's tweedie: 138.137\n",
      "[276]\tvalid_0's tweedie: 138.136\n",
      "[277]\tvalid_0's tweedie: 138.137\n",
      "[278]\tvalid_0's tweedie: 138.136\n",
      "[279]\tvalid_0's tweedie: 138.136\n",
      "[280]\tvalid_0's tweedie: 138.137\n",
      "[281]\tvalid_0's tweedie: 138.137\n",
      "[282]\tvalid_0's tweedie: 138.137\n",
      "[283]\tvalid_0's tweedie: 138.137\n",
      "[284]\tvalid_0's tweedie: 138.137\n",
      "[285]\tvalid_0's tweedie: 138.137\n",
      "[286]\tvalid_0's tweedie: 138.137\n",
      "[287]\tvalid_0's tweedie: 138.136\n",
      "[288]\tvalid_0's tweedie: 138.136\n",
      "[289]\tvalid_0's tweedie: 138.136\n",
      "[290]\tvalid_0's tweedie: 138.136\n",
      "[291]\tvalid_0's tweedie: 138.136\n",
      "[292]\tvalid_0's tweedie: 138.136\n",
      "[293]\tvalid_0's tweedie: 138.136\n",
      "[294]\tvalid_0's tweedie: 138.136\n",
      "[295]\tvalid_0's tweedie: 138.136\n",
      "[296]\tvalid_0's tweedie: 138.136\n",
      "[297]\tvalid_0's tweedie: 138.136\n",
      "[298]\tvalid_0's tweedie: 138.136\n",
      "[299]\tvalid_0's tweedie: 138.136\n",
      "[300]\tvalid_0's tweedie: 138.136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[296]\tvalid_0's tweedie: 138.136\n",
      "Training model for level 8 and step 26\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/26/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5495\n",
      "[LightGBM] [Info] Number of data points in the train set: 55380, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044449\n",
      "[1]\tvalid_0's tweedie: 148.689\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.81\n",
      "[3]\tvalid_0's tweedie: 145.259\n",
      "[4]\tvalid_0's tweedie: 143.973\n",
      "[5]\tvalid_0's tweedie: 142.916\n",
      "[6]\tvalid_0's tweedie: 142.049\n",
      "[7]\tvalid_0's tweedie: 141.338\n",
      "[8]\tvalid_0's tweedie: 140.756\n",
      "[9]\tvalid_0's tweedie: 140.285\n",
      "[10]\tvalid_0's tweedie: 139.897\n",
      "[11]\tvalid_0's tweedie: 139.577\n",
      "[12]\tvalid_0's tweedie: 139.316\n",
      "[13]\tvalid_0's tweedie: 139.096\n",
      "[14]\tvalid_0's tweedie: 138.922\n",
      "[15]\tvalid_0's tweedie: 138.779\n",
      "[16]\tvalid_0's tweedie: 138.665\n",
      "[17]\tvalid_0's tweedie: 138.574\n",
      "[18]\tvalid_0's tweedie: 138.496\n",
      "[19]\tvalid_0's tweedie: 138.437\n",
      "[20]\tvalid_0's tweedie: 138.384\n",
      "[21]\tvalid_0's tweedie: 138.344\n",
      "[22]\tvalid_0's tweedie: 138.31\n",
      "[23]\tvalid_0's tweedie: 138.282\n",
      "[24]\tvalid_0's tweedie: 138.263\n",
      "[25]\tvalid_0's tweedie: 138.244\n",
      "[26]\tvalid_0's tweedie: 138.226\n",
      "[27]\tvalid_0's tweedie: 138.214\n",
      "[28]\tvalid_0's tweedie: 138.205\n",
      "[29]\tvalid_0's tweedie: 138.198\n",
      "[30]\tvalid_0's tweedie: 138.19\n",
      "[31]\tvalid_0's tweedie: 138.186\n",
      "[32]\tvalid_0's tweedie: 138.182\n",
      "[33]\tvalid_0's tweedie: 138.179\n",
      "[34]\tvalid_0's tweedie: 138.177\n",
      "[35]\tvalid_0's tweedie: 138.175\n",
      "[36]\tvalid_0's tweedie: 138.173\n",
      "[37]\tvalid_0's tweedie: 138.17\n",
      "[38]\tvalid_0's tweedie: 138.168\n",
      "[39]\tvalid_0's tweedie: 138.167\n",
      "[40]\tvalid_0's tweedie: 138.166\n",
      "[41]\tvalid_0's tweedie: 138.164\n",
      "[42]\tvalid_0's tweedie: 138.162\n",
      "[43]\tvalid_0's tweedie: 138.161\n",
      "[44]\tvalid_0's tweedie: 138.16\n",
      "[45]\tvalid_0's tweedie: 138.158\n",
      "[46]\tvalid_0's tweedie: 138.159\n",
      "[47]\tvalid_0's tweedie: 138.158\n",
      "[48]\tvalid_0's tweedie: 138.158\n",
      "[49]\tvalid_0's tweedie: 138.157\n",
      "[50]\tvalid_0's tweedie: 138.156\n",
      "[51]\tvalid_0's tweedie: 138.158\n",
      "[52]\tvalid_0's tweedie: 138.157\n",
      "[53]\tvalid_0's tweedie: 138.157\n",
      "[54]\tvalid_0's tweedie: 138.157\n",
      "[55]\tvalid_0's tweedie: 138.159\n",
      "[56]\tvalid_0's tweedie: 138.158\n",
      "[57]\tvalid_0's tweedie: 138.158\n",
      "[58]\tvalid_0's tweedie: 138.157\n",
      "[59]\tvalid_0's tweedie: 138.158\n",
      "[60]\tvalid_0's tweedie: 138.158\n",
      "[61]\tvalid_0's tweedie: 138.158\n",
      "[62]\tvalid_0's tweedie: 138.158\n",
      "[63]\tvalid_0's tweedie: 138.158\n",
      "[64]\tvalid_0's tweedie: 138.158\n",
      "[65]\tvalid_0's tweedie: 138.158\n",
      "[66]\tvalid_0's tweedie: 138.158\n",
      "[67]\tvalid_0's tweedie: 138.157\n",
      "[68]\tvalid_0's tweedie: 138.157\n",
      "[69]\tvalid_0's tweedie: 138.157\n",
      "[70]\tvalid_0's tweedie: 138.157\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's tweedie: 138.156\n",
      "Training model for level 8 and step 27\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/27/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5494\n",
      "[LightGBM] [Info] Number of data points in the train set: 55350, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044635\n",
      "[1]\tvalid_0's tweedie: 148.687\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.815\n",
      "[3]\tvalid_0's tweedie: 145.263\n",
      "[4]\tvalid_0's tweedie: 143.97\n",
      "[5]\tvalid_0's tweedie: 142.914\n",
      "[6]\tvalid_0's tweedie: 142.048\n",
      "[7]\tvalid_0's tweedie: 141.329\n",
      "[8]\tvalid_0's tweedie: 140.743\n",
      "[9]\tvalid_0's tweedie: 140.275\n",
      "[10]\tvalid_0's tweedie: 139.885\n",
      "[11]\tvalid_0's tweedie: 139.575\n",
      "[12]\tvalid_0's tweedie: 139.316\n",
      "[13]\tvalid_0's tweedie: 139.104\n",
      "[14]\tvalid_0's tweedie: 138.929\n",
      "[15]\tvalid_0's tweedie: 138.782\n",
      "[16]\tvalid_0's tweedie: 138.668\n",
      "[17]\tvalid_0's tweedie: 138.572\n",
      "[18]\tvalid_0's tweedie: 138.496\n",
      "[19]\tvalid_0's tweedie: 138.434\n",
      "[20]\tvalid_0's tweedie: 138.384\n",
      "[21]\tvalid_0's tweedie: 138.34\n",
      "[22]\tvalid_0's tweedie: 138.309\n",
      "[23]\tvalid_0's tweedie: 138.28\n",
      "[24]\tvalid_0's tweedie: 138.259\n",
      "[25]\tvalid_0's tweedie: 138.241\n",
      "[26]\tvalid_0's tweedie: 138.224\n",
      "[27]\tvalid_0's tweedie: 138.212\n",
      "[28]\tvalid_0's tweedie: 138.202\n",
      "[29]\tvalid_0's tweedie: 138.195\n",
      "[30]\tvalid_0's tweedie: 138.189\n",
      "[31]\tvalid_0's tweedie: 138.183\n",
      "[32]\tvalid_0's tweedie: 138.178\n",
      "[33]\tvalid_0's tweedie: 138.175\n",
      "[34]\tvalid_0's tweedie: 138.172\n",
      "[35]\tvalid_0's tweedie: 138.171\n",
      "[36]\tvalid_0's tweedie: 138.169\n",
      "[37]\tvalid_0's tweedie: 138.168\n",
      "[38]\tvalid_0's tweedie: 138.166\n",
      "[39]\tvalid_0's tweedie: 138.166\n",
      "[40]\tvalid_0's tweedie: 138.164\n",
      "[41]\tvalid_0's tweedie: 138.163\n",
      "[42]\tvalid_0's tweedie: 138.161\n",
      "[43]\tvalid_0's tweedie: 138.161\n",
      "[44]\tvalid_0's tweedie: 138.161\n",
      "[45]\tvalid_0's tweedie: 138.159\n",
      "[46]\tvalid_0's tweedie: 138.159\n",
      "[47]\tvalid_0's tweedie: 138.158\n",
      "[48]\tvalid_0's tweedie: 138.156\n",
      "[49]\tvalid_0's tweedie: 138.155\n",
      "[50]\tvalid_0's tweedie: 138.154\n",
      "[51]\tvalid_0's tweedie: 138.155\n",
      "[52]\tvalid_0's tweedie: 138.154\n",
      "[53]\tvalid_0's tweedie: 138.154\n",
      "[54]\tvalid_0's tweedie: 138.155\n",
      "[55]\tvalid_0's tweedie: 138.154\n",
      "[56]\tvalid_0's tweedie: 138.154\n",
      "[57]\tvalid_0's tweedie: 138.153\n",
      "[58]\tvalid_0's tweedie: 138.153\n",
      "[59]\tvalid_0's tweedie: 138.153\n",
      "[60]\tvalid_0's tweedie: 138.153\n",
      "[61]\tvalid_0's tweedie: 138.153\n",
      "[62]\tvalid_0's tweedie: 138.153\n",
      "[63]\tvalid_0's tweedie: 138.153\n",
      "[64]\tvalid_0's tweedie: 138.153\n",
      "[65]\tvalid_0's tweedie: 138.153\n",
      "[66]\tvalid_0's tweedie: 138.153\n",
      "[67]\tvalid_0's tweedie: 138.153\n",
      "[68]\tvalid_0's tweedie: 138.153\n",
      "[69]\tvalid_0's tweedie: 138.152\n",
      "[70]\tvalid_0's tweedie: 138.152\n",
      "[71]\tvalid_0's tweedie: 138.152\n",
      "[72]\tvalid_0's tweedie: 138.152\n",
      "[73]\tvalid_0's tweedie: 138.152\n",
      "[74]\tvalid_0's tweedie: 138.152\n",
      "[75]\tvalid_0's tweedie: 138.152\n",
      "[76]\tvalid_0's tweedie: 138.153\n",
      "[77]\tvalid_0's tweedie: 138.153\n",
      "[78]\tvalid_0's tweedie: 138.153\n",
      "[79]\tvalid_0's tweedie: 138.153\n",
      "[80]\tvalid_0's tweedie: 138.153\n",
      "[81]\tvalid_0's tweedie: 138.153\n",
      "[82]\tvalid_0's tweedie: 138.153\n",
      "[83]\tvalid_0's tweedie: 138.153\n",
      "[84]\tvalid_0's tweedie: 138.153\n",
      "[85]\tvalid_0's tweedie: 138.153\n",
      "[86]\tvalid_0's tweedie: 138.153\n",
      "[87]\tvalid_0's tweedie: 138.153\n",
      "[88]\tvalid_0's tweedie: 138.153\n",
      "[89]\tvalid_0's tweedie: 138.153\n",
      "[90]\tvalid_0's tweedie: 138.153\n",
      "[91]\tvalid_0's tweedie: 138.153\n",
      "[92]\tvalid_0's tweedie: 138.153\n",
      "[93]\tvalid_0's tweedie: 138.153\n",
      "[94]\tvalid_0's tweedie: 138.153\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's tweedie: 138.152\n",
      "Training model for level 8 and step 28\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/8/28/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5493\n",
      "[LightGBM] [Info] Number of data points in the train set: 55320, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 7.044821\n",
      "[1]\tvalid_0's tweedie: 148.689\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 146.816\n",
      "[3]\tvalid_0's tweedie: 145.266\n",
      "[4]\tvalid_0's tweedie: 143.978\n",
      "[5]\tvalid_0's tweedie: 142.927\n",
      "[6]\tvalid_0's tweedie: 142.054\n",
      "[7]\tvalid_0's tweedie: 141.343\n",
      "[8]\tvalid_0's tweedie: 140.761\n",
      "[9]\tvalid_0's tweedie: 140.28\n",
      "[10]\tvalid_0's tweedie: 139.887\n",
      "[11]\tvalid_0's tweedie: 139.568\n",
      "[12]\tvalid_0's tweedie: 139.313\n",
      "[13]\tvalid_0's tweedie: 139.098\n",
      "[14]\tvalid_0's tweedie: 138.927\n",
      "[15]\tvalid_0's tweedie: 138.784\n",
      "[16]\tvalid_0's tweedie: 138.664\n",
      "[17]\tvalid_0's tweedie: 138.572\n",
      "[18]\tvalid_0's tweedie: 138.493\n",
      "[19]\tvalid_0's tweedie: 138.431\n",
      "[20]\tvalid_0's tweedie: 138.38\n",
      "[21]\tvalid_0's tweedie: 138.338\n",
      "[22]\tvalid_0's tweedie: 138.304\n",
      "[23]\tvalid_0's tweedie: 138.276\n",
      "[24]\tvalid_0's tweedie: 138.255\n",
      "[25]\tvalid_0's tweedie: 138.237\n",
      "[26]\tvalid_0's tweedie: 138.222\n",
      "[27]\tvalid_0's tweedie: 138.209\n",
      "[28]\tvalid_0's tweedie: 138.2\n",
      "[29]\tvalid_0's tweedie: 138.19\n",
      "[30]\tvalid_0's tweedie: 138.184\n",
      "[31]\tvalid_0's tweedie: 138.179\n",
      "[32]\tvalid_0's tweedie: 138.176\n",
      "[33]\tvalid_0's tweedie: 138.173\n",
      "[34]\tvalid_0's tweedie: 138.171\n",
      "[35]\tvalid_0's tweedie: 138.168\n",
      "[36]\tvalid_0's tweedie: 138.166\n",
      "[37]\tvalid_0's tweedie: 138.165\n",
      "[38]\tvalid_0's tweedie: 138.162\n",
      "[39]\tvalid_0's tweedie: 138.16\n",
      "[40]\tvalid_0's tweedie: 138.159\n",
      "[41]\tvalid_0's tweedie: 138.157\n",
      "[42]\tvalid_0's tweedie: 138.157\n",
      "[43]\tvalid_0's tweedie: 138.155\n",
      "[44]\tvalid_0's tweedie: 138.153\n",
      "[45]\tvalid_0's tweedie: 138.153\n",
      "[46]\tvalid_0's tweedie: 138.153\n",
      "[47]\tvalid_0's tweedie: 138.152\n",
      "[48]\tvalid_0's tweedie: 138.151\n",
      "[49]\tvalid_0's tweedie: 138.15\n",
      "[50]\tvalid_0's tweedie: 138.149\n",
      "[51]\tvalid_0's tweedie: 138.149\n",
      "[52]\tvalid_0's tweedie: 138.148\n",
      "[53]\tvalid_0's tweedie: 138.148\n",
      "[54]\tvalid_0's tweedie: 138.148\n",
      "[55]\tvalid_0's tweedie: 138.149\n",
      "[56]\tvalid_0's tweedie: 138.149\n",
      "[57]\tvalid_0's tweedie: 138.148\n",
      "[58]\tvalid_0's tweedie: 138.148\n",
      "[59]\tvalid_0's tweedie: 138.147\n",
      "[60]\tvalid_0's tweedie: 138.147\n",
      "[61]\tvalid_0's tweedie: 138.147\n",
      "[62]\tvalid_0's tweedie: 138.147\n",
      "[63]\tvalid_0's tweedie: 138.147\n",
      "[64]\tvalid_0's tweedie: 138.147\n",
      "[65]\tvalid_0's tweedie: 138.147\n",
      "[66]\tvalid_0's tweedie: 138.147\n",
      "[67]\tvalid_0's tweedie: 138.148\n",
      "[68]\tvalid_0's tweedie: 138.148\n",
      "[69]\tvalid_0's tweedie: 138.148\n",
      "[70]\tvalid_0's tweedie: 138.148\n",
      "[71]\tvalid_0's tweedie: 138.147\n",
      "[72]\tvalid_0's tweedie: 138.147\n",
      "[73]\tvalid_0's tweedie: 138.146\n",
      "[74]\tvalid_0's tweedie: 138.147\n",
      "[75]\tvalid_0's tweedie: 138.146\n",
      "[76]\tvalid_0's tweedie: 138.146\n",
      "[77]\tvalid_0's tweedie: 138.146\n",
      "[78]\tvalid_0's tweedie: 138.146\n",
      "[79]\tvalid_0's tweedie: 138.147\n",
      "[80]\tvalid_0's tweedie: 138.147\n",
      "[81]\tvalid_0's tweedie: 138.147\n",
      "[82]\tvalid_0's tweedie: 138.147\n",
      "[83]\tvalid_0's tweedie: 138.147\n",
      "[84]\tvalid_0's tweedie: 138.147\n",
      "[85]\tvalid_0's tweedie: 138.147\n",
      "[86]\tvalid_0's tweedie: 138.147\n",
      "[87]\tvalid_0's tweedie: 138.146\n",
      "[88]\tvalid_0's tweedie: 138.146\n",
      "[89]\tvalid_0's tweedie: 138.146\n",
      "[90]\tvalid_0's tweedie: 138.147\n",
      "[91]\tvalid_0's tweedie: 138.147\n",
      "[92]\tvalid_0's tweedie: 138.147\n",
      "[93]\tvalid_0's tweedie: 138.147\n",
      "[94]\tvalid_0's tweedie: 138.146\n",
      "[95]\tvalid_0's tweedie: 138.146\n",
      "[96]\tvalid_0's tweedie: 138.147\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's tweedie: 138.146\n",
      "Training model for level 9\n",
      "Training model for level 9 and step 1\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/1/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5524\n",
      "[LightGBM] [Info] Number of data points in the train set: 130969, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.193686\n",
      "[1]\tvalid_0's tweedie: 96.8067\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.079\n",
      "[3]\tvalid_0's tweedie: 93.6159\n",
      "[4]\tvalid_0's tweedie: 92.3805\n",
      "[5]\tvalid_0's tweedie: 91.3482\n",
      "[6]\tvalid_0's tweedie: 90.4818\n",
      "[7]\tvalid_0's tweedie: 89.761\n",
      "[8]\tvalid_0's tweedie: 89.1662\n",
      "[9]\tvalid_0's tweedie: 88.6706\n",
      "[10]\tvalid_0's tweedie: 88.2601\n",
      "[11]\tvalid_0's tweedie: 87.9206\n",
      "[12]\tvalid_0's tweedie: 87.6404\n",
      "[13]\tvalid_0's tweedie: 87.4085\n",
      "[14]\tvalid_0's tweedie: 87.2162\n",
      "[15]\tvalid_0's tweedie: 87.0578\n",
      "[16]\tvalid_0's tweedie: 86.929\n",
      "[17]\tvalid_0's tweedie: 86.8228\n",
      "[18]\tvalid_0's tweedie: 86.7391\n",
      "[19]\tvalid_0's tweedie: 86.6694\n",
      "[20]\tvalid_0's tweedie: 86.6124\n",
      "[21]\tvalid_0's tweedie: 86.5662\n",
      "[22]\tvalid_0's tweedie: 86.528\n",
      "[23]\tvalid_0's tweedie: 86.4965\n",
      "[24]\tvalid_0's tweedie: 86.4717\n",
      "[25]\tvalid_0's tweedie: 86.4509\n",
      "[26]\tvalid_0's tweedie: 86.4348\n",
      "[27]\tvalid_0's tweedie: 86.4218\n",
      "[28]\tvalid_0's tweedie: 86.4098\n",
      "[29]\tvalid_0's tweedie: 86.3988\n",
      "[30]\tvalid_0's tweedie: 86.3899\n",
      "[31]\tvalid_0's tweedie: 86.3839\n",
      "[32]\tvalid_0's tweedie: 86.3773\n",
      "[33]\tvalid_0's tweedie: 86.3728\n",
      "[34]\tvalid_0's tweedie: 86.3694\n",
      "[35]\tvalid_0's tweedie: 86.3665\n",
      "[36]\tvalid_0's tweedie: 86.3631\n",
      "[37]\tvalid_0's tweedie: 86.3611\n",
      "[38]\tvalid_0's tweedie: 86.3597\n",
      "[39]\tvalid_0's tweedie: 86.3582\n",
      "[40]\tvalid_0's tweedie: 86.3568\n",
      "[41]\tvalid_0's tweedie: 86.3561\n",
      "[42]\tvalid_0's tweedie: 86.3546\n",
      "[43]\tvalid_0's tweedie: 86.3528\n",
      "[44]\tvalid_0's tweedie: 86.3521\n",
      "[45]\tvalid_0's tweedie: 86.3515\n",
      "[46]\tvalid_0's tweedie: 86.3512\n",
      "[47]\tvalid_0's tweedie: 86.3503\n",
      "[48]\tvalid_0's tweedie: 86.3491\n",
      "[49]\tvalid_0's tweedie: 86.3488\n",
      "[50]\tvalid_0's tweedie: 86.3485\n",
      "[51]\tvalid_0's tweedie: 86.3483\n",
      "[52]\tvalid_0's tweedie: 86.3472\n",
      "[53]\tvalid_0's tweedie: 86.3466\n",
      "[54]\tvalid_0's tweedie: 86.3467\n",
      "[55]\tvalid_0's tweedie: 86.3468\n",
      "[56]\tvalid_0's tweedie: 86.3462\n",
      "[57]\tvalid_0's tweedie: 86.3461\n",
      "[58]\tvalid_0's tweedie: 86.346\n",
      "[59]\tvalid_0's tweedie: 86.3461\n",
      "[60]\tvalid_0's tweedie: 86.3461\n",
      "[61]\tvalid_0's tweedie: 86.3455\n",
      "[62]\tvalid_0's tweedie: 86.3455\n",
      "[63]\tvalid_0's tweedie: 86.3454\n",
      "[64]\tvalid_0's tweedie: 86.3455\n",
      "[65]\tvalid_0's tweedie: 86.3448\n",
      "[66]\tvalid_0's tweedie: 86.3444\n",
      "[67]\tvalid_0's tweedie: 86.3438\n",
      "[68]\tvalid_0's tweedie: 86.3435\n",
      "[69]\tvalid_0's tweedie: 86.3429\n",
      "[70]\tvalid_0's tweedie: 86.3428\n",
      "[71]\tvalid_0's tweedie: 86.3423\n",
      "[72]\tvalid_0's tweedie: 86.3424\n",
      "[73]\tvalid_0's tweedie: 86.342\n",
      "[74]\tvalid_0's tweedie: 86.3417\n",
      "[75]\tvalid_0's tweedie: 86.3417\n",
      "[76]\tvalid_0's tweedie: 86.3415\n",
      "[77]\tvalid_0's tweedie: 86.3413\n",
      "[78]\tvalid_0's tweedie: 86.341\n",
      "[79]\tvalid_0's tweedie: 86.3409\n",
      "[80]\tvalid_0's tweedie: 86.3409\n",
      "[81]\tvalid_0's tweedie: 86.3408\n",
      "[82]\tvalid_0's tweedie: 86.3408\n",
      "[83]\tvalid_0's tweedie: 86.3407\n",
      "[84]\tvalid_0's tweedie: 86.3403\n",
      "[85]\tvalid_0's tweedie: 86.3402\n",
      "[86]\tvalid_0's tweedie: 86.3402\n",
      "[87]\tvalid_0's tweedie: 86.3402\n",
      "[88]\tvalid_0's tweedie: 86.3401\n",
      "[89]\tvalid_0's tweedie: 86.3396\n",
      "[90]\tvalid_0's tweedie: 86.3396\n",
      "[91]\tvalid_0's tweedie: 86.3396\n",
      "[92]\tvalid_0's tweedie: 86.3396\n",
      "[93]\tvalid_0's tweedie: 86.3395\n",
      "[94]\tvalid_0's tweedie: 86.3392\n",
      "[95]\tvalid_0's tweedie: 86.3392\n",
      "[96]\tvalid_0's tweedie: 86.3392\n",
      "[97]\tvalid_0's tweedie: 86.3389\n",
      "[98]\tvalid_0's tweedie: 86.3389\n",
      "[99]\tvalid_0's tweedie: 86.3387\n",
      "[100]\tvalid_0's tweedie: 86.3387\n",
      "[101]\tvalid_0's tweedie: 86.3385\n",
      "[102]\tvalid_0's tweedie: 86.3385\n",
      "[103]\tvalid_0's tweedie: 86.3382\n",
      "[104]\tvalid_0's tweedie: 86.3381\n",
      "[105]\tvalid_0's tweedie: 86.3378\n",
      "[106]\tvalid_0's tweedie: 86.3378\n",
      "[107]\tvalid_0's tweedie: 86.3377\n",
      "[108]\tvalid_0's tweedie: 86.3376\n",
      "[109]\tvalid_0's tweedie: 86.3376\n",
      "[110]\tvalid_0's tweedie: 86.3376\n",
      "[111]\tvalid_0's tweedie: 86.3373\n",
      "[112]\tvalid_0's tweedie: 86.3372\n",
      "[113]\tvalid_0's tweedie: 86.3373\n",
      "[114]\tvalid_0's tweedie: 86.3373\n",
      "[115]\tvalid_0's tweedie: 86.3371\n",
      "[116]\tvalid_0's tweedie: 86.3371\n",
      "[117]\tvalid_0's tweedie: 86.3369\n",
      "[118]\tvalid_0's tweedie: 86.3369\n",
      "[119]\tvalid_0's tweedie: 86.337\n",
      "[120]\tvalid_0's tweedie: 86.337\n",
      "[121]\tvalid_0's tweedie: 86.337\n",
      "[122]\tvalid_0's tweedie: 86.337\n",
      "[123]\tvalid_0's tweedie: 86.337\n",
      "[124]\tvalid_0's tweedie: 86.3369\n",
      "[125]\tvalid_0's tweedie: 86.3369\n",
      "[126]\tvalid_0's tweedie: 86.3369\n",
      "[127]\tvalid_0's tweedie: 86.3369\n",
      "[128]\tvalid_0's tweedie: 86.3367\n",
      "[129]\tvalid_0's tweedie: 86.3367\n",
      "[130]\tvalid_0's tweedie: 86.3366\n",
      "[131]\tvalid_0's tweedie: 86.3366\n",
      "[132]\tvalid_0's tweedie: 86.3365\n",
      "[133]\tvalid_0's tweedie: 86.3364\n",
      "[134]\tvalid_0's tweedie: 86.3364\n",
      "[135]\tvalid_0's tweedie: 86.3363\n",
      "[136]\tvalid_0's tweedie: 86.3363\n",
      "[137]\tvalid_0's tweedie: 86.3362\n",
      "[138]\tvalid_0's tweedie: 86.3362\n",
      "[139]\tvalid_0's tweedie: 86.3358\n",
      "[140]\tvalid_0's tweedie: 86.3358\n",
      "[141]\tvalid_0's tweedie: 86.3358\n",
      "[142]\tvalid_0's tweedie: 86.3357\n",
      "[143]\tvalid_0's tweedie: 86.3356\n",
      "[144]\tvalid_0's tweedie: 86.3354\n",
      "[145]\tvalid_0's tweedie: 86.3354\n",
      "[146]\tvalid_0's tweedie: 86.3354\n",
      "[147]\tvalid_0's tweedie: 86.3354\n",
      "[148]\tvalid_0's tweedie: 86.335\n",
      "[149]\tvalid_0's tweedie: 86.335\n",
      "[150]\tvalid_0's tweedie: 86.3349\n",
      "[151]\tvalid_0's tweedie: 86.3349\n",
      "[152]\tvalid_0's tweedie: 86.3348\n",
      "[153]\tvalid_0's tweedie: 86.3347\n",
      "[154]\tvalid_0's tweedie: 86.3346\n",
      "[155]\tvalid_0's tweedie: 86.3346\n",
      "[156]\tvalid_0's tweedie: 86.3346\n",
      "[157]\tvalid_0's tweedie: 86.3346\n",
      "[158]\tvalid_0's tweedie: 86.3346\n",
      "[159]\tvalid_0's tweedie: 86.3345\n",
      "[160]\tvalid_0's tweedie: 86.3346\n",
      "[161]\tvalid_0's tweedie: 86.3345\n",
      "[162]\tvalid_0's tweedie: 86.3345\n",
      "[163]\tvalid_0's tweedie: 86.3344\n",
      "[164]\tvalid_0's tweedie: 86.334\n",
      "[165]\tvalid_0's tweedie: 86.3339\n",
      "[166]\tvalid_0's tweedie: 86.3338\n",
      "[167]\tvalid_0's tweedie: 86.3338\n",
      "[168]\tvalid_0's tweedie: 86.3338\n",
      "[169]\tvalid_0's tweedie: 86.3338\n",
      "[170]\tvalid_0's tweedie: 86.3336\n",
      "[171]\tvalid_0's tweedie: 86.3333\n",
      "[172]\tvalid_0's tweedie: 86.3333\n",
      "[173]\tvalid_0's tweedie: 86.3333\n",
      "[174]\tvalid_0's tweedie: 86.3332\n",
      "[175]\tvalid_0's tweedie: 86.3332\n",
      "[176]\tvalid_0's tweedie: 86.3332\n",
      "[177]\tvalid_0's tweedie: 86.3331\n",
      "[178]\tvalid_0's tweedie: 86.333\n",
      "[179]\tvalid_0's tweedie: 86.333\n",
      "[180]\tvalid_0's tweedie: 86.333\n",
      "[181]\tvalid_0's tweedie: 86.3329\n",
      "[182]\tvalid_0's tweedie: 86.3329\n",
      "[183]\tvalid_0's tweedie: 86.3329\n",
      "[184]\tvalid_0's tweedie: 86.3327\n",
      "[185]\tvalid_0's tweedie: 86.3326\n",
      "[186]\tvalid_0's tweedie: 86.3327\n",
      "[187]\tvalid_0's tweedie: 86.3325\n",
      "[188]\tvalid_0's tweedie: 86.3324\n",
      "[189]\tvalid_0's tweedie: 86.3324\n",
      "[190]\tvalid_0's tweedie: 86.3324\n",
      "[191]\tvalid_0's tweedie: 86.3324\n",
      "[192]\tvalid_0's tweedie: 86.3324\n",
      "[193]\tvalid_0's tweedie: 86.3323\n",
      "[194]\tvalid_0's tweedie: 86.3323\n",
      "[195]\tvalid_0's tweedie: 86.3322\n",
      "[196]\tvalid_0's tweedie: 86.3323\n",
      "[197]\tvalid_0's tweedie: 86.3322\n",
      "[198]\tvalid_0's tweedie: 86.3322\n",
      "[199]\tvalid_0's tweedie: 86.3321\n",
      "[200]\tvalid_0's tweedie: 86.3321\n",
      "[201]\tvalid_0's tweedie: 86.3321\n",
      "[202]\tvalid_0's tweedie: 86.3319\n",
      "[203]\tvalid_0's tweedie: 86.3318\n",
      "[204]\tvalid_0's tweedie: 86.3318\n",
      "[205]\tvalid_0's tweedie: 86.3317\n",
      "[206]\tvalid_0's tweedie: 86.3317\n",
      "[207]\tvalid_0's tweedie: 86.3317\n",
      "[208]\tvalid_0's tweedie: 86.3317\n",
      "[209]\tvalid_0's tweedie: 86.3316\n",
      "[210]\tvalid_0's tweedie: 86.3315\n",
      "[211]\tvalid_0's tweedie: 86.3315\n",
      "[212]\tvalid_0's tweedie: 86.3315\n",
      "[213]\tvalid_0's tweedie: 86.3315\n",
      "[214]\tvalid_0's tweedie: 86.3315\n",
      "[215]\tvalid_0's tweedie: 86.3315\n",
      "[216]\tvalid_0's tweedie: 86.3316\n",
      "[217]\tvalid_0's tweedie: 86.3319\n",
      "[218]\tvalid_0's tweedie: 86.3319\n",
      "[219]\tvalid_0's tweedie: 86.3318\n",
      "[220]\tvalid_0's tweedie: 86.3318\n",
      "[221]\tvalid_0's tweedie: 86.3318\n",
      "[222]\tvalid_0's tweedie: 86.3317\n",
      "[223]\tvalid_0's tweedie: 86.3316\n",
      "[224]\tvalid_0's tweedie: 86.3315\n",
      "[225]\tvalid_0's tweedie: 86.3315\n",
      "[226]\tvalid_0's tweedie: 86.3315\n",
      "[227]\tvalid_0's tweedie: 86.3315\n",
      "[228]\tvalid_0's tweedie: 86.3314\n",
      "[229]\tvalid_0's tweedie: 86.3314\n",
      "[230]\tvalid_0's tweedie: 86.3314\n",
      "[231]\tvalid_0's tweedie: 86.3313\n",
      "[232]\tvalid_0's tweedie: 86.3313\n",
      "[233]\tvalid_0's tweedie: 86.3312\n",
      "[234]\tvalid_0's tweedie: 86.3312\n",
      "[235]\tvalid_0's tweedie: 86.3312\n",
      "[236]\tvalid_0's tweedie: 86.3312\n",
      "[237]\tvalid_0's tweedie: 86.3313\n",
      "[238]\tvalid_0's tweedie: 86.3314\n",
      "[239]\tvalid_0's tweedie: 86.3314\n",
      "[240]\tvalid_0's tweedie: 86.3314\n",
      "[241]\tvalid_0's tweedie: 86.3313\n",
      "[242]\tvalid_0's tweedie: 86.3312\n",
      "[243]\tvalid_0's tweedie: 86.3313\n",
      "[244]\tvalid_0's tweedie: 86.3313\n",
      "[245]\tvalid_0's tweedie: 86.3313\n",
      "[246]\tvalid_0's tweedie: 86.3312\n",
      "[247]\tvalid_0's tweedie: 86.3312\n",
      "[248]\tvalid_0's tweedie: 86.3312\n",
      "[249]\tvalid_0's tweedie: 86.3312\n",
      "[250]\tvalid_0's tweedie: 86.3311\n",
      "[251]\tvalid_0's tweedie: 86.331\n",
      "[252]\tvalid_0's tweedie: 86.3311\n",
      "[253]\tvalid_0's tweedie: 86.3312\n",
      "[254]\tvalid_0's tweedie: 86.3312\n",
      "[255]\tvalid_0's tweedie: 86.3312\n",
      "[256]\tvalid_0's tweedie: 86.3313\n",
      "[257]\tvalid_0's tweedie: 86.3312\n",
      "[258]\tvalid_0's tweedie: 86.3312\n",
      "[259]\tvalid_0's tweedie: 86.3312\n",
      "[260]\tvalid_0's tweedie: 86.3311\n",
      "[261]\tvalid_0's tweedie: 86.3311\n",
      "[262]\tvalid_0's tweedie: 86.3311\n",
      "[263]\tvalid_0's tweedie: 86.3311\n",
      "[264]\tvalid_0's tweedie: 86.3311\n",
      "[265]\tvalid_0's tweedie: 86.3311\n",
      "[266]\tvalid_0's tweedie: 86.3311\n",
      "[267]\tvalid_0's tweedie: 86.3308\n",
      "[268]\tvalid_0's tweedie: 86.3308\n",
      "[269]\tvalid_0's tweedie: 86.3308\n",
      "[270]\tvalid_0's tweedie: 86.3308\n",
      "[271]\tvalid_0's tweedie: 86.3307\n",
      "[272]\tvalid_0's tweedie: 86.3307\n",
      "[273]\tvalid_0's tweedie: 86.3307\n",
      "[274]\tvalid_0's tweedie: 86.3307\n",
      "[275]\tvalid_0's tweedie: 86.3307\n",
      "[276]\tvalid_0's tweedie: 86.3307\n",
      "[277]\tvalid_0's tweedie: 86.3307\n",
      "[278]\tvalid_0's tweedie: 86.3306\n",
      "[279]\tvalid_0's tweedie: 86.3307\n",
      "[280]\tvalid_0's tweedie: 86.3307\n",
      "[281]\tvalid_0's tweedie: 86.3307\n",
      "[282]\tvalid_0's tweedie: 86.3307\n",
      "[283]\tvalid_0's tweedie: 86.3307\n",
      "[284]\tvalid_0's tweedie: 86.3307\n",
      "[285]\tvalid_0's tweedie: 86.3307\n",
      "[286]\tvalid_0's tweedie: 86.3305\n",
      "[287]\tvalid_0's tweedie: 86.3305\n",
      "[288]\tvalid_0's tweedie: 86.3304\n",
      "[289]\tvalid_0's tweedie: 86.3304\n",
      "[290]\tvalid_0's tweedie: 86.3304\n",
      "[291]\tvalid_0's tweedie: 86.3304\n",
      "[292]\tvalid_0's tweedie: 86.3304\n",
      "[293]\tvalid_0's tweedie: 86.3304\n",
      "[294]\tvalid_0's tweedie: 86.3304\n",
      "[295]\tvalid_0's tweedie: 86.3304\n",
      "[296]\tvalid_0's tweedie: 86.3304\n",
      "[297]\tvalid_0's tweedie: 86.3304\n",
      "[298]\tvalid_0's tweedie: 86.3304\n",
      "[299]\tvalid_0's tweedie: 86.3304\n",
      "[300]\tvalid_0's tweedie: 86.3304\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's tweedie: 86.3304\n",
      "Training model for level 9 and step 2\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/2/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5523\n",
      "[LightGBM] [Info] Number of data points in the train set: 130899, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.193677\n",
      "[1]\tvalid_0's tweedie: 96.8141\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1008\n",
      "[3]\tvalid_0's tweedie: 93.6415\n",
      "[4]\tvalid_0's tweedie: 92.412\n",
      "[5]\tvalid_0's tweedie: 91.3849\n",
      "[6]\tvalid_0's tweedie: 90.522\n",
      "[7]\tvalid_0's tweedie: 89.8035\n",
      "[8]\tvalid_0's tweedie: 89.207\n",
      "[9]\tvalid_0's tweedie: 88.7181\n",
      "[10]\tvalid_0's tweedie: 88.306\n",
      "[11]\tvalid_0's tweedie: 87.9671\n",
      "[12]\tvalid_0's tweedie: 87.6897\n",
      "[13]\tvalid_0's tweedie: 87.4525\n",
      "[14]\tvalid_0's tweedie: 87.2598\n",
      "[15]\tvalid_0's tweedie: 87.1041\n",
      "[16]\tvalid_0's tweedie: 86.9743\n",
      "[17]\tvalid_0's tweedie: 86.8648\n",
      "[18]\tvalid_0's tweedie: 86.7778\n",
      "[19]\tvalid_0's tweedie: 86.7057\n",
      "[20]\tvalid_0's tweedie: 86.6495\n",
      "[21]\tvalid_0's tweedie: 86.6011\n",
      "[22]\tvalid_0's tweedie: 86.5629\n",
      "[23]\tvalid_0's tweedie: 86.532\n",
      "[24]\tvalid_0's tweedie: 86.5063\n",
      "[25]\tvalid_0's tweedie: 86.4856\n",
      "[26]\tvalid_0's tweedie: 86.4672\n",
      "[27]\tvalid_0's tweedie: 86.4539\n",
      "[28]\tvalid_0's tweedie: 86.4428\n",
      "[29]\tvalid_0's tweedie: 86.4328\n",
      "[30]\tvalid_0's tweedie: 86.4255\n",
      "[31]\tvalid_0's tweedie: 86.4201\n",
      "[32]\tvalid_0's tweedie: 86.4117\n",
      "[33]\tvalid_0's tweedie: 86.4047\n",
      "[34]\tvalid_0's tweedie: 86.3989\n",
      "[35]\tvalid_0's tweedie: 86.3959\n",
      "[36]\tvalid_0's tweedie: 86.3918\n",
      "[37]\tvalid_0's tweedie: 86.3898\n",
      "[38]\tvalid_0's tweedie: 86.3886\n",
      "[39]\tvalid_0's tweedie: 86.3873\n",
      "[40]\tvalid_0's tweedie: 86.3855\n",
      "[41]\tvalid_0's tweedie: 86.3841\n",
      "[42]\tvalid_0's tweedie: 86.3834\n",
      "[43]\tvalid_0's tweedie: 86.3828\n",
      "[44]\tvalid_0's tweedie: 86.3823\n",
      "[45]\tvalid_0's tweedie: 86.3819\n",
      "[46]\tvalid_0's tweedie: 86.3819\n",
      "[47]\tvalid_0's tweedie: 86.3796\n",
      "[48]\tvalid_0's tweedie: 86.3796\n",
      "[49]\tvalid_0's tweedie: 86.3791\n",
      "[50]\tvalid_0's tweedie: 86.3783\n",
      "[51]\tvalid_0's tweedie: 86.3781\n",
      "[52]\tvalid_0's tweedie: 86.3781\n",
      "[53]\tvalid_0's tweedie: 86.3775\n",
      "[54]\tvalid_0's tweedie: 86.3776\n",
      "[55]\tvalid_0's tweedie: 86.3765\n",
      "[56]\tvalid_0's tweedie: 86.3757\n",
      "[57]\tvalid_0's tweedie: 86.3741\n",
      "[58]\tvalid_0's tweedie: 86.3738\n",
      "[59]\tvalid_0's tweedie: 86.3734\n",
      "[60]\tvalid_0's tweedie: 86.3734\n",
      "[61]\tvalid_0's tweedie: 86.3734\n",
      "[62]\tvalid_0's tweedie: 86.373\n",
      "[63]\tvalid_0's tweedie: 86.3726\n",
      "[64]\tvalid_0's tweedie: 86.3726\n",
      "[65]\tvalid_0's tweedie: 86.3727\n",
      "[66]\tvalid_0's tweedie: 86.3727\n",
      "[67]\tvalid_0's tweedie: 86.3724\n",
      "[68]\tvalid_0's tweedie: 86.3721\n",
      "[69]\tvalid_0's tweedie: 86.372\n",
      "[70]\tvalid_0's tweedie: 86.372\n",
      "[71]\tvalid_0's tweedie: 86.3718\n",
      "[72]\tvalid_0's tweedie: 86.3713\n",
      "[73]\tvalid_0's tweedie: 86.371\n",
      "[74]\tvalid_0's tweedie: 86.3709\n",
      "[75]\tvalid_0's tweedie: 86.3708\n",
      "[76]\tvalid_0's tweedie: 86.3708\n",
      "[77]\tvalid_0's tweedie: 86.3705\n",
      "[78]\tvalid_0's tweedie: 86.3695\n",
      "[79]\tvalid_0's tweedie: 86.3693\n",
      "[80]\tvalid_0's tweedie: 86.3692\n",
      "[81]\tvalid_0's tweedie: 86.3689\n",
      "[82]\tvalid_0's tweedie: 86.3687\n",
      "[83]\tvalid_0's tweedie: 86.3686\n",
      "[84]\tvalid_0's tweedie: 86.3682\n",
      "[85]\tvalid_0's tweedie: 86.3676\n",
      "[86]\tvalid_0's tweedie: 86.3666\n",
      "[87]\tvalid_0's tweedie: 86.3666\n",
      "[88]\tvalid_0's tweedie: 86.3666\n",
      "[89]\tvalid_0's tweedie: 86.3658\n",
      "[90]\tvalid_0's tweedie: 86.3655\n",
      "[91]\tvalid_0's tweedie: 86.3653\n",
      "[92]\tvalid_0's tweedie: 86.3651\n",
      "[93]\tvalid_0's tweedie: 86.365\n",
      "[94]\tvalid_0's tweedie: 86.365\n",
      "[95]\tvalid_0's tweedie: 86.3639\n",
      "[96]\tvalid_0's tweedie: 86.3638\n",
      "[97]\tvalid_0's tweedie: 86.3637\n",
      "[98]\tvalid_0's tweedie: 86.3637\n",
      "[99]\tvalid_0's tweedie: 86.3637\n",
      "[100]\tvalid_0's tweedie: 86.3637\n",
      "[101]\tvalid_0's tweedie: 86.3636\n",
      "[102]\tvalid_0's tweedie: 86.3634\n",
      "[103]\tvalid_0's tweedie: 86.3627\n",
      "[104]\tvalid_0's tweedie: 86.3625\n",
      "[105]\tvalid_0's tweedie: 86.3625\n",
      "[106]\tvalid_0's tweedie: 86.3623\n",
      "[107]\tvalid_0's tweedie: 86.3622\n",
      "[108]\tvalid_0's tweedie: 86.3623\n",
      "[109]\tvalid_0's tweedie: 86.3623\n",
      "[110]\tvalid_0's tweedie: 86.3625\n",
      "[111]\tvalid_0's tweedie: 86.3622\n",
      "[112]\tvalid_0's tweedie: 86.3621\n",
      "[113]\tvalid_0's tweedie: 86.3616\n",
      "[114]\tvalid_0's tweedie: 86.3614\n",
      "[115]\tvalid_0's tweedie: 86.3613\n",
      "[116]\tvalid_0's tweedie: 86.3613\n",
      "[117]\tvalid_0's tweedie: 86.3613\n",
      "[118]\tvalid_0's tweedie: 86.3608\n",
      "[119]\tvalid_0's tweedie: 86.3609\n",
      "[120]\tvalid_0's tweedie: 86.3605\n",
      "[121]\tvalid_0's tweedie: 86.3603\n",
      "[122]\tvalid_0's tweedie: 86.3603\n",
      "[123]\tvalid_0's tweedie: 86.3602\n",
      "[124]\tvalid_0's tweedie: 86.3608\n",
      "[125]\tvalid_0's tweedie: 86.3608\n",
      "[126]\tvalid_0's tweedie: 86.3606\n",
      "[127]\tvalid_0's tweedie: 86.3605\n",
      "[128]\tvalid_0's tweedie: 86.3603\n",
      "[129]\tvalid_0's tweedie: 86.3602\n",
      "[130]\tvalid_0's tweedie: 86.3601\n",
      "[131]\tvalid_0's tweedie: 86.36\n",
      "[132]\tvalid_0's tweedie: 86.36\n",
      "[133]\tvalid_0's tweedie: 86.36\n",
      "[134]\tvalid_0's tweedie: 86.3599\n",
      "[135]\tvalid_0's tweedie: 86.3598\n",
      "[136]\tvalid_0's tweedie: 86.36\n",
      "[137]\tvalid_0's tweedie: 86.3598\n",
      "[138]\tvalid_0's tweedie: 86.3598\n",
      "[139]\tvalid_0's tweedie: 86.3597\n",
      "[140]\tvalid_0's tweedie: 86.3595\n",
      "[141]\tvalid_0's tweedie: 86.3594\n",
      "[142]\tvalid_0's tweedie: 86.3594\n",
      "[143]\tvalid_0's tweedie: 86.3595\n",
      "[144]\tvalid_0's tweedie: 86.3595\n",
      "[145]\tvalid_0's tweedie: 86.3594\n",
      "[146]\tvalid_0's tweedie: 86.3594\n",
      "[147]\tvalid_0's tweedie: 86.3594\n",
      "[148]\tvalid_0's tweedie: 86.3593\n",
      "[149]\tvalid_0's tweedie: 86.3592\n",
      "[150]\tvalid_0's tweedie: 86.3592\n",
      "[151]\tvalid_0's tweedie: 86.3591\n",
      "[152]\tvalid_0's tweedie: 86.3591\n",
      "[153]\tvalid_0's tweedie: 86.3591\n",
      "[154]\tvalid_0's tweedie: 86.3591\n",
      "[155]\tvalid_0's tweedie: 86.3592\n",
      "[156]\tvalid_0's tweedie: 86.3589\n",
      "[157]\tvalid_0's tweedie: 86.3588\n",
      "[158]\tvalid_0's tweedie: 86.3588\n",
      "[159]\tvalid_0's tweedie: 86.3587\n",
      "[160]\tvalid_0's tweedie: 86.3587\n",
      "[161]\tvalid_0's tweedie: 86.3585\n",
      "[162]\tvalid_0's tweedie: 86.3584\n",
      "[163]\tvalid_0's tweedie: 86.3584\n",
      "[164]\tvalid_0's tweedie: 86.3584\n",
      "[165]\tvalid_0's tweedie: 86.3585\n",
      "[166]\tvalid_0's tweedie: 86.3585\n",
      "[167]\tvalid_0's tweedie: 86.3586\n",
      "[168]\tvalid_0's tweedie: 86.3585\n",
      "[169]\tvalid_0's tweedie: 86.3584\n",
      "[170]\tvalid_0's tweedie: 86.3591\n",
      "[171]\tvalid_0's tweedie: 86.3586\n",
      "[172]\tvalid_0's tweedie: 86.3585\n",
      "[173]\tvalid_0's tweedie: 86.3585\n",
      "[174]\tvalid_0's tweedie: 86.3585\n",
      "[175]\tvalid_0's tweedie: 86.3583\n",
      "[176]\tvalid_0's tweedie: 86.3583\n",
      "[177]\tvalid_0's tweedie: 86.3582\n",
      "[178]\tvalid_0's tweedie: 86.3582\n",
      "[179]\tvalid_0's tweedie: 86.3582\n",
      "[180]\tvalid_0's tweedie: 86.3582\n",
      "[181]\tvalid_0's tweedie: 86.3582\n",
      "[182]\tvalid_0's tweedie: 86.3582\n",
      "[183]\tvalid_0's tweedie: 86.358\n",
      "[184]\tvalid_0's tweedie: 86.358\n",
      "[185]\tvalid_0's tweedie: 86.3579\n",
      "[186]\tvalid_0's tweedie: 86.3577\n",
      "[187]\tvalid_0's tweedie: 86.3577\n",
      "[188]\tvalid_0's tweedie: 86.3576\n",
      "[189]\tvalid_0's tweedie: 86.3573\n",
      "[190]\tvalid_0's tweedie: 86.3573\n",
      "[191]\tvalid_0's tweedie: 86.3571\n",
      "[192]\tvalid_0's tweedie: 86.357\n",
      "[193]\tvalid_0's tweedie: 86.357\n",
      "[194]\tvalid_0's tweedie: 86.3569\n",
      "[195]\tvalid_0's tweedie: 86.3568\n",
      "[196]\tvalid_0's tweedie: 86.3568\n",
      "[197]\tvalid_0's tweedie: 86.3568\n",
      "[198]\tvalid_0's tweedie: 86.3568\n",
      "[199]\tvalid_0's tweedie: 86.3568\n",
      "[200]\tvalid_0's tweedie: 86.3567\n",
      "[201]\tvalid_0's tweedie: 86.3566\n",
      "[202]\tvalid_0's tweedie: 86.3565\n",
      "[203]\tvalid_0's tweedie: 86.3565\n",
      "[204]\tvalid_0's tweedie: 86.3565\n",
      "[205]\tvalid_0's tweedie: 86.3564\n",
      "[206]\tvalid_0's tweedie: 86.3563\n",
      "[207]\tvalid_0's tweedie: 86.3563\n",
      "[208]\tvalid_0's tweedie: 86.3563\n",
      "[209]\tvalid_0's tweedie: 86.3562\n",
      "[210]\tvalid_0's tweedie: 86.3563\n",
      "[211]\tvalid_0's tweedie: 86.3562\n",
      "[212]\tvalid_0's tweedie: 86.3562\n",
      "[213]\tvalid_0's tweedie: 86.3562\n",
      "[214]\tvalid_0's tweedie: 86.3561\n",
      "[215]\tvalid_0's tweedie: 86.356\n",
      "[216]\tvalid_0's tweedie: 86.356\n",
      "[217]\tvalid_0's tweedie: 86.356\n",
      "[218]\tvalid_0's tweedie: 86.3559\n",
      "[219]\tvalid_0's tweedie: 86.3558\n",
      "[220]\tvalid_0's tweedie: 86.3558\n",
      "[221]\tvalid_0's tweedie: 86.3558\n",
      "[222]\tvalid_0's tweedie: 86.3557\n",
      "[223]\tvalid_0's tweedie: 86.3558\n",
      "[224]\tvalid_0's tweedie: 86.3557\n",
      "[225]\tvalid_0's tweedie: 86.3557\n",
      "[226]\tvalid_0's tweedie: 86.3557\n",
      "[227]\tvalid_0's tweedie: 86.3556\n",
      "[228]\tvalid_0's tweedie: 86.3556\n",
      "[229]\tvalid_0's tweedie: 86.3556\n",
      "[230]\tvalid_0's tweedie: 86.3557\n",
      "[231]\tvalid_0's tweedie: 86.3557\n",
      "[232]\tvalid_0's tweedie: 86.3556\n",
      "[233]\tvalid_0's tweedie: 86.3555\n",
      "[234]\tvalid_0's tweedie: 86.3555\n",
      "[235]\tvalid_0's tweedie: 86.3554\n",
      "[236]\tvalid_0's tweedie: 86.3554\n",
      "[237]\tvalid_0's tweedie: 86.3552\n",
      "[238]\tvalid_0's tweedie: 86.3552\n",
      "[239]\tvalid_0's tweedie: 86.3551\n",
      "[240]\tvalid_0's tweedie: 86.3551\n",
      "[241]\tvalid_0's tweedie: 86.355\n",
      "[242]\tvalid_0's tweedie: 86.355\n",
      "[243]\tvalid_0's tweedie: 86.3551\n",
      "[244]\tvalid_0's tweedie: 86.3551\n",
      "[245]\tvalid_0's tweedie: 86.3551\n",
      "[246]\tvalid_0's tweedie: 86.3551\n",
      "[247]\tvalid_0's tweedie: 86.355\n",
      "[248]\tvalid_0's tweedie: 86.355\n",
      "[249]\tvalid_0's tweedie: 86.355\n",
      "[250]\tvalid_0's tweedie: 86.355\n",
      "[251]\tvalid_0's tweedie: 86.355\n",
      "[252]\tvalid_0's tweedie: 86.3549\n",
      "[253]\tvalid_0's tweedie: 86.355\n",
      "[254]\tvalid_0's tweedie: 86.3548\n",
      "[255]\tvalid_0's tweedie: 86.3548\n",
      "[256]\tvalid_0's tweedie: 86.3548\n",
      "[257]\tvalid_0's tweedie: 86.3548\n",
      "[258]\tvalid_0's tweedie: 86.3548\n",
      "[259]\tvalid_0's tweedie: 86.3548\n",
      "[260]\tvalid_0's tweedie: 86.3548\n",
      "[261]\tvalid_0's tweedie: 86.3549\n",
      "[262]\tvalid_0's tweedie: 86.3549\n",
      "[263]\tvalid_0's tweedie: 86.3548\n",
      "[264]\tvalid_0's tweedie: 86.3547\n",
      "[265]\tvalid_0's tweedie: 86.3547\n",
      "[266]\tvalid_0's tweedie: 86.3547\n",
      "[267]\tvalid_0's tweedie: 86.3547\n",
      "[268]\tvalid_0's tweedie: 86.3546\n",
      "[269]\tvalid_0's tweedie: 86.3545\n",
      "[270]\tvalid_0's tweedie: 86.3544\n",
      "[271]\tvalid_0's tweedie: 86.3544\n",
      "[272]\tvalid_0's tweedie: 86.3545\n",
      "[273]\tvalid_0's tweedie: 86.3543\n",
      "[274]\tvalid_0's tweedie: 86.3543\n",
      "[275]\tvalid_0's tweedie: 86.3543\n",
      "[276]\tvalid_0's tweedie: 86.3542\n",
      "[277]\tvalid_0's tweedie: 86.3542\n",
      "[278]\tvalid_0's tweedie: 86.3542\n",
      "[279]\tvalid_0's tweedie: 86.3542\n",
      "[280]\tvalid_0's tweedie: 86.3542\n",
      "[281]\tvalid_0's tweedie: 86.3542\n",
      "[282]\tvalid_0's tweedie: 86.3542\n",
      "[283]\tvalid_0's tweedie: 86.3543\n",
      "[284]\tvalid_0's tweedie: 86.3543\n",
      "[285]\tvalid_0's tweedie: 86.3543\n",
      "[286]\tvalid_0's tweedie: 86.3543\n",
      "[287]\tvalid_0's tweedie: 86.3543\n",
      "[288]\tvalid_0's tweedie: 86.3541\n",
      "[289]\tvalid_0's tweedie: 86.3541\n",
      "[290]\tvalid_0's tweedie: 86.354\n",
      "[291]\tvalid_0's tweedie: 86.3541\n",
      "[292]\tvalid_0's tweedie: 86.3541\n",
      "[293]\tvalid_0's tweedie: 86.3542\n",
      "[294]\tvalid_0's tweedie: 86.3542\n",
      "[295]\tvalid_0's tweedie: 86.3542\n",
      "[296]\tvalid_0's tweedie: 86.3542\n",
      "[297]\tvalid_0's tweedie: 86.3541\n",
      "[298]\tvalid_0's tweedie: 86.3541\n",
      "[299]\tvalid_0's tweedie: 86.3542\n",
      "[300]\tvalid_0's tweedie: 86.3541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[290]\tvalid_0's tweedie: 86.354\n",
      "Training model for level 9 and step 3\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/3/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5522\n",
      "[LightGBM] [Info] Number of data points in the train set: 130829, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.193645\n",
      "[1]\tvalid_0's tweedie: 96.8123\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.0944\n",
      "[3]\tvalid_0's tweedie: 93.6342\n",
      "[4]\tvalid_0's tweedie: 92.4064\n",
      "[5]\tvalid_0's tweedie: 91.3779\n",
      "[6]\tvalid_0's tweedie: 90.5146\n",
      "[7]\tvalid_0's tweedie: 89.7939\n",
      "[8]\tvalid_0's tweedie: 89.2016\n",
      "[9]\tvalid_0's tweedie: 88.7128\n",
      "[10]\tvalid_0's tweedie: 88.3064\n",
      "[11]\tvalid_0's tweedie: 87.9711\n",
      "[12]\tvalid_0's tweedie: 87.6936\n",
      "[13]\tvalid_0's tweedie: 87.4631\n",
      "[14]\tvalid_0's tweedie: 87.2704\n",
      "[15]\tvalid_0's tweedie: 87.11\n",
      "[16]\tvalid_0's tweedie: 86.9856\n",
      "[17]\tvalid_0's tweedie: 86.878\n",
      "[18]\tvalid_0's tweedie: 86.7917\n",
      "[19]\tvalid_0's tweedie: 86.7207\n",
      "[20]\tvalid_0's tweedie: 86.663\n",
      "[21]\tvalid_0's tweedie: 86.6151\n",
      "[22]\tvalid_0's tweedie: 86.5764\n",
      "[23]\tvalid_0's tweedie: 86.5417\n",
      "[24]\tvalid_0's tweedie: 86.5131\n",
      "[25]\tvalid_0's tweedie: 86.4904\n",
      "[26]\tvalid_0's tweedie: 86.4743\n",
      "[27]\tvalid_0's tweedie: 86.461\n",
      "[28]\tvalid_0's tweedie: 86.4499\n",
      "[29]\tvalid_0's tweedie: 86.4391\n",
      "[30]\tvalid_0's tweedie: 86.4314\n",
      "[31]\tvalid_0's tweedie: 86.4249\n",
      "[32]\tvalid_0's tweedie: 86.4198\n",
      "[33]\tvalid_0's tweedie: 86.4148\n",
      "[34]\tvalid_0's tweedie: 86.4114\n",
      "[35]\tvalid_0's tweedie: 86.4079\n",
      "[36]\tvalid_0's tweedie: 86.4063\n",
      "[37]\tvalid_0's tweedie: 86.4024\n",
      "[38]\tvalid_0's tweedie: 86.4006\n",
      "[39]\tvalid_0's tweedie: 86.3992\n",
      "[40]\tvalid_0's tweedie: 86.3953\n",
      "[41]\tvalid_0's tweedie: 86.3944\n",
      "[42]\tvalid_0's tweedie: 86.3919\n",
      "[43]\tvalid_0's tweedie: 86.3911\n",
      "[44]\tvalid_0's tweedie: 86.3906\n",
      "[45]\tvalid_0's tweedie: 86.39\n",
      "[46]\tvalid_0's tweedie: 86.3894\n",
      "[47]\tvalid_0's tweedie: 86.3874\n",
      "[48]\tvalid_0's tweedie: 86.3862\n",
      "[49]\tvalid_0's tweedie: 86.384\n",
      "[50]\tvalid_0's tweedie: 86.3826\n",
      "[51]\tvalid_0's tweedie: 86.3824\n",
      "[52]\tvalid_0's tweedie: 86.3818\n",
      "[53]\tvalid_0's tweedie: 86.3814\n",
      "[54]\tvalid_0's tweedie: 86.3809\n",
      "[55]\tvalid_0's tweedie: 86.3808\n",
      "[56]\tvalid_0's tweedie: 86.3806\n",
      "[57]\tvalid_0's tweedie: 86.3806\n",
      "[58]\tvalid_0's tweedie: 86.3802\n",
      "[59]\tvalid_0's tweedie: 86.3802\n",
      "[60]\tvalid_0's tweedie: 86.3802\n",
      "[61]\tvalid_0's tweedie: 86.3801\n",
      "[62]\tvalid_0's tweedie: 86.3802\n",
      "[63]\tvalid_0's tweedie: 86.3804\n",
      "[64]\tvalid_0's tweedie: 86.3805\n",
      "[65]\tvalid_0's tweedie: 86.3806\n",
      "[66]\tvalid_0's tweedie: 86.3804\n",
      "[67]\tvalid_0's tweedie: 86.3799\n",
      "[68]\tvalid_0's tweedie: 86.3801\n",
      "[69]\tvalid_0's tweedie: 86.38\n",
      "[70]\tvalid_0's tweedie: 86.3796\n",
      "[71]\tvalid_0's tweedie: 86.3789\n",
      "[72]\tvalid_0's tweedie: 86.3788\n",
      "[73]\tvalid_0's tweedie: 86.3786\n",
      "[74]\tvalid_0's tweedie: 86.3777\n",
      "[75]\tvalid_0's tweedie: 86.3776\n",
      "[76]\tvalid_0's tweedie: 86.3771\n",
      "[77]\tvalid_0's tweedie: 86.377\n",
      "[78]\tvalid_0's tweedie: 86.3761\n",
      "[79]\tvalid_0's tweedie: 86.3751\n",
      "[80]\tvalid_0's tweedie: 86.375\n",
      "[81]\tvalid_0's tweedie: 86.3747\n",
      "[82]\tvalid_0's tweedie: 86.3744\n",
      "[83]\tvalid_0's tweedie: 86.3736\n",
      "[84]\tvalid_0's tweedie: 86.3736\n",
      "[85]\tvalid_0's tweedie: 86.3736\n",
      "[86]\tvalid_0's tweedie: 86.3735\n",
      "[87]\tvalid_0's tweedie: 86.3732\n",
      "[88]\tvalid_0's tweedie: 86.3733\n",
      "[89]\tvalid_0's tweedie: 86.3731\n",
      "[90]\tvalid_0's tweedie: 86.373\n",
      "[91]\tvalid_0's tweedie: 86.3721\n",
      "[92]\tvalid_0's tweedie: 86.372\n",
      "[93]\tvalid_0's tweedie: 86.372\n",
      "[94]\tvalid_0's tweedie: 86.372\n",
      "[95]\tvalid_0's tweedie: 86.3719\n",
      "[96]\tvalid_0's tweedie: 86.3719\n",
      "[97]\tvalid_0's tweedie: 86.3718\n",
      "[98]\tvalid_0's tweedie: 86.3716\n",
      "[99]\tvalid_0's tweedie: 86.3716\n",
      "[100]\tvalid_0's tweedie: 86.3716\n",
      "[101]\tvalid_0's tweedie: 86.371\n",
      "[102]\tvalid_0's tweedie: 86.3709\n",
      "[103]\tvalid_0's tweedie: 86.3708\n",
      "[104]\tvalid_0's tweedie: 86.3706\n",
      "[105]\tvalid_0's tweedie: 86.3705\n",
      "[106]\tvalid_0's tweedie: 86.3705\n",
      "[107]\tvalid_0's tweedie: 86.3704\n",
      "[108]\tvalid_0's tweedie: 86.3708\n",
      "[109]\tvalid_0's tweedie: 86.37\n",
      "[110]\tvalid_0's tweedie: 86.3697\n",
      "[111]\tvalid_0's tweedie: 86.3694\n",
      "[112]\tvalid_0's tweedie: 86.3694\n",
      "[113]\tvalid_0's tweedie: 86.3693\n",
      "[114]\tvalid_0's tweedie: 86.369\n",
      "[115]\tvalid_0's tweedie: 86.3691\n",
      "[116]\tvalid_0's tweedie: 86.3691\n",
      "[117]\tvalid_0's tweedie: 86.369\n",
      "[118]\tvalid_0's tweedie: 86.3689\n",
      "[119]\tvalid_0's tweedie: 86.369\n",
      "[120]\tvalid_0's tweedie: 86.3689\n",
      "[121]\tvalid_0's tweedie: 86.3689\n",
      "[122]\tvalid_0's tweedie: 86.3695\n",
      "[123]\tvalid_0's tweedie: 86.3695\n",
      "[124]\tvalid_0's tweedie: 86.3695\n",
      "[125]\tvalid_0's tweedie: 86.3694\n",
      "[126]\tvalid_0's tweedie: 86.3693\n",
      "[127]\tvalid_0's tweedie: 86.3693\n",
      "[128]\tvalid_0's tweedie: 86.3693\n",
      "[129]\tvalid_0's tweedie: 86.3693\n",
      "[130]\tvalid_0's tweedie: 86.3692\n",
      "[131]\tvalid_0's tweedie: 86.3693\n",
      "[132]\tvalid_0's tweedie: 86.3687\n",
      "[133]\tvalid_0's tweedie: 86.3687\n",
      "[134]\tvalid_0's tweedie: 86.3686\n",
      "[135]\tvalid_0's tweedie: 86.3686\n",
      "[136]\tvalid_0's tweedie: 86.3686\n",
      "[137]\tvalid_0's tweedie: 86.3686\n",
      "[138]\tvalid_0's tweedie: 86.3685\n",
      "[139]\tvalid_0's tweedie: 86.3686\n",
      "[140]\tvalid_0's tweedie: 86.3683\n",
      "[141]\tvalid_0's tweedie: 86.3683\n",
      "[142]\tvalid_0's tweedie: 86.3683\n",
      "[143]\tvalid_0's tweedie: 86.3683\n",
      "[144]\tvalid_0's tweedie: 86.3678\n",
      "[145]\tvalid_0's tweedie: 86.3677\n",
      "[146]\tvalid_0's tweedie: 86.3677\n",
      "[147]\tvalid_0's tweedie: 86.3677\n",
      "[148]\tvalid_0's tweedie: 86.3673\n",
      "[149]\tvalid_0's tweedie: 86.3673\n",
      "[150]\tvalid_0's tweedie: 86.3673\n",
      "[151]\tvalid_0's tweedie: 86.3673\n",
      "[152]\tvalid_0's tweedie: 86.3673\n",
      "[153]\tvalid_0's tweedie: 86.3673\n",
      "[154]\tvalid_0's tweedie: 86.3676\n",
      "[155]\tvalid_0's tweedie: 86.3676\n",
      "[156]\tvalid_0's tweedie: 86.3675\n",
      "[157]\tvalid_0's tweedie: 86.3674\n",
      "[158]\tvalid_0's tweedie: 86.3674\n",
      "[159]\tvalid_0's tweedie: 86.3672\n",
      "[160]\tvalid_0's tweedie: 86.3672\n",
      "[161]\tvalid_0's tweedie: 86.3672\n",
      "[162]\tvalid_0's tweedie: 86.3672\n",
      "[163]\tvalid_0's tweedie: 86.3672\n",
      "[164]\tvalid_0's tweedie: 86.3672\n",
      "[165]\tvalid_0's tweedie: 86.3673\n",
      "[166]\tvalid_0's tweedie: 86.3673\n",
      "[167]\tvalid_0's tweedie: 86.3673\n",
      "[168]\tvalid_0's tweedie: 86.3673\n",
      "[169]\tvalid_0's tweedie: 86.3673\n",
      "[170]\tvalid_0's tweedie: 86.3673\n",
      "[171]\tvalid_0's tweedie: 86.3673\n",
      "[172]\tvalid_0's tweedie: 86.3673\n",
      "[173]\tvalid_0's tweedie: 86.3673\n",
      "[174]\tvalid_0's tweedie: 86.3673\n",
      "[175]\tvalid_0's tweedie: 86.3673\n",
      "[176]\tvalid_0's tweedie: 86.3673\n",
      "[177]\tvalid_0's tweedie: 86.3672\n",
      "[178]\tvalid_0's tweedie: 86.3672\n",
      "[179]\tvalid_0's tweedie: 86.3671\n",
      "[180]\tvalid_0's tweedie: 86.367\n",
      "[181]\tvalid_0's tweedie: 86.367\n",
      "[182]\tvalid_0's tweedie: 86.367\n",
      "[183]\tvalid_0's tweedie: 86.367\n",
      "[184]\tvalid_0's tweedie: 86.3671\n",
      "[185]\tvalid_0's tweedie: 86.3671\n",
      "[186]\tvalid_0's tweedie: 86.367\n",
      "[187]\tvalid_0's tweedie: 86.367\n",
      "[188]\tvalid_0's tweedie: 86.367\n",
      "[189]\tvalid_0's tweedie: 86.367\n",
      "[190]\tvalid_0's tweedie: 86.367\n",
      "[191]\tvalid_0's tweedie: 86.3669\n",
      "[192]\tvalid_0's tweedie: 86.3669\n",
      "[193]\tvalid_0's tweedie: 86.3668\n",
      "[194]\tvalid_0's tweedie: 86.3668\n",
      "[195]\tvalid_0's tweedie: 86.3667\n",
      "[196]\tvalid_0's tweedie: 86.3668\n",
      "[197]\tvalid_0's tweedie: 86.3668\n",
      "[198]\tvalid_0's tweedie: 86.3668\n",
      "[199]\tvalid_0's tweedie: 86.3667\n",
      "[200]\tvalid_0's tweedie: 86.3667\n",
      "[201]\tvalid_0's tweedie: 86.3667\n",
      "[202]\tvalid_0's tweedie: 86.3667\n",
      "[203]\tvalid_0's tweedie: 86.3667\n",
      "[204]\tvalid_0's tweedie: 86.3667\n",
      "[205]\tvalid_0's tweedie: 86.3667\n",
      "[206]\tvalid_0's tweedie: 86.3667\n",
      "[207]\tvalid_0's tweedie: 86.3667\n",
      "[208]\tvalid_0's tweedie: 86.3667\n",
      "[209]\tvalid_0's tweedie: 86.3667\n",
      "[210]\tvalid_0's tweedie: 86.3667\n",
      "[211]\tvalid_0's tweedie: 86.3667\n",
      "[212]\tvalid_0's tweedie: 86.3667\n",
      "[213]\tvalid_0's tweedie: 86.3667\n",
      "[214]\tvalid_0's tweedie: 86.3665\n",
      "[215]\tvalid_0's tweedie: 86.3665\n",
      "[216]\tvalid_0's tweedie: 86.3664\n",
      "[217]\tvalid_0's tweedie: 86.3661\n",
      "[218]\tvalid_0's tweedie: 86.3661\n",
      "[219]\tvalid_0's tweedie: 86.3661\n",
      "[220]\tvalid_0's tweedie: 86.3661\n",
      "[221]\tvalid_0's tweedie: 86.3661\n",
      "[222]\tvalid_0's tweedie: 86.3661\n",
      "[223]\tvalid_0's tweedie: 86.366\n",
      "[224]\tvalid_0's tweedie: 86.366\n",
      "[225]\tvalid_0's tweedie: 86.3659\n",
      "[226]\tvalid_0's tweedie: 86.3658\n",
      "[227]\tvalid_0's tweedie: 86.3657\n",
      "[228]\tvalid_0's tweedie: 86.3658\n",
      "[229]\tvalid_0's tweedie: 86.3657\n",
      "[230]\tvalid_0's tweedie: 86.3657\n",
      "[231]\tvalid_0's tweedie: 86.3656\n",
      "[232]\tvalid_0's tweedie: 86.3657\n",
      "[233]\tvalid_0's tweedie: 86.3657\n",
      "[234]\tvalid_0's tweedie: 86.3657\n",
      "[235]\tvalid_0's tweedie: 86.3656\n",
      "[236]\tvalid_0's tweedie: 86.3656\n",
      "[237]\tvalid_0's tweedie: 86.3657\n",
      "[238]\tvalid_0's tweedie: 86.3656\n",
      "[239]\tvalid_0's tweedie: 86.3656\n",
      "[240]\tvalid_0's tweedie: 86.3656\n",
      "[241]\tvalid_0's tweedie: 86.3655\n",
      "[242]\tvalid_0's tweedie: 86.3655\n",
      "[243]\tvalid_0's tweedie: 86.3654\n",
      "[244]\tvalid_0's tweedie: 86.3653\n",
      "[245]\tvalid_0's tweedie: 86.3648\n",
      "[246]\tvalid_0's tweedie: 86.3648\n",
      "[247]\tvalid_0's tweedie: 86.3648\n",
      "[248]\tvalid_0's tweedie: 86.3648\n",
      "[249]\tvalid_0's tweedie: 86.3648\n",
      "[250]\tvalid_0's tweedie: 86.3648\n",
      "[251]\tvalid_0's tweedie: 86.3648\n",
      "[252]\tvalid_0's tweedie: 86.3648\n",
      "[253]\tvalid_0's tweedie: 86.3644\n",
      "[254]\tvalid_0's tweedie: 86.3644\n",
      "[255]\tvalid_0's tweedie: 86.3641\n",
      "[256]\tvalid_0's tweedie: 86.3641\n",
      "[257]\tvalid_0's tweedie: 86.3639\n",
      "[258]\tvalid_0's tweedie: 86.3639\n",
      "[259]\tvalid_0's tweedie: 86.3639\n",
      "[260]\tvalid_0's tweedie: 86.3639\n",
      "[261]\tvalid_0's tweedie: 86.3638\n",
      "[262]\tvalid_0's tweedie: 86.3639\n",
      "[263]\tvalid_0's tweedie: 86.3639\n",
      "[264]\tvalid_0's tweedie: 86.3639\n",
      "[265]\tvalid_0's tweedie: 86.3638\n",
      "[266]\tvalid_0's tweedie: 86.3638\n",
      "[267]\tvalid_0's tweedie: 86.3637\n",
      "[268]\tvalid_0's tweedie: 86.3637\n",
      "[269]\tvalid_0's tweedie: 86.3637\n",
      "[270]\tvalid_0's tweedie: 86.3636\n",
      "[271]\tvalid_0's tweedie: 86.3637\n",
      "[272]\tvalid_0's tweedie: 86.3637\n",
      "[273]\tvalid_0's tweedie: 86.3637\n",
      "[274]\tvalid_0's tweedie: 86.3636\n",
      "[275]\tvalid_0's tweedie: 86.3636\n",
      "[276]\tvalid_0's tweedie: 86.3636\n",
      "[277]\tvalid_0's tweedie: 86.3636\n",
      "[278]\tvalid_0's tweedie: 86.3635\n",
      "[279]\tvalid_0's tweedie: 86.3635\n",
      "[280]\tvalid_0's tweedie: 86.3636\n",
      "[281]\tvalid_0's tweedie: 86.3635\n",
      "[282]\tvalid_0's tweedie: 86.3635\n",
      "[283]\tvalid_0's tweedie: 86.3635\n",
      "[284]\tvalid_0's tweedie: 86.3636\n",
      "[285]\tvalid_0's tweedie: 86.3636\n",
      "[286]\tvalid_0's tweedie: 86.3635\n",
      "[287]\tvalid_0's tweedie: 86.3635\n",
      "[288]\tvalid_0's tweedie: 86.3635\n",
      "[289]\tvalid_0's tweedie: 86.3635\n",
      "[290]\tvalid_0's tweedie: 86.3634\n",
      "[291]\tvalid_0's tweedie: 86.3634\n",
      "[292]\tvalid_0's tweedie: 86.3634\n",
      "[293]\tvalid_0's tweedie: 86.3632\n",
      "[294]\tvalid_0's tweedie: 86.3632\n",
      "[295]\tvalid_0's tweedie: 86.3633\n",
      "[296]\tvalid_0's tweedie: 86.3633\n",
      "[297]\tvalid_0's tweedie: 86.3633\n",
      "[298]\tvalid_0's tweedie: 86.3631\n",
      "[299]\tvalid_0's tweedie: 86.3632\n",
      "[300]\tvalid_0's tweedie: 86.3632\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[298]\tvalid_0's tweedie: 86.3631\n",
      "Training model for level 9 and step 4\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/4/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5521\n",
      "[LightGBM] [Info] Number of data points in the train set: 130759, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.193839\n",
      "[1]\tvalid_0's tweedie: 96.812\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.086\n",
      "[3]\tvalid_0's tweedie: 93.6267\n",
      "[4]\tvalid_0's tweedie: 92.398\n",
      "[5]\tvalid_0's tweedie: 91.3721\n",
      "[6]\tvalid_0's tweedie: 90.5088\n",
      "[7]\tvalid_0's tweedie: 89.7967\n",
      "[8]\tvalid_0's tweedie: 89.2039\n",
      "[9]\tvalid_0's tweedie: 88.7131\n",
      "[10]\tvalid_0's tweedie: 88.3078\n",
      "[11]\tvalid_0's tweedie: 87.9682\n",
      "[12]\tvalid_0's tweedie: 87.6867\n",
      "[13]\tvalid_0's tweedie: 87.4597\n",
      "[14]\tvalid_0's tweedie: 87.2702\n",
      "[15]\tvalid_0's tweedie: 87.112\n",
      "[16]\tvalid_0's tweedie: 86.9806\n",
      "[17]\tvalid_0's tweedie: 86.8765\n",
      "[18]\tvalid_0's tweedie: 86.7909\n",
      "[19]\tvalid_0's tweedie: 86.7227\n",
      "[20]\tvalid_0's tweedie: 86.6662\n",
      "[21]\tvalid_0's tweedie: 86.6205\n",
      "[22]\tvalid_0's tweedie: 86.5793\n",
      "[23]\tvalid_0's tweedie: 86.549\n",
      "[24]\tvalid_0's tweedie: 86.5218\n",
      "[25]\tvalid_0's tweedie: 86.5001\n",
      "[26]\tvalid_0's tweedie: 86.4824\n",
      "[27]\tvalid_0's tweedie: 86.466\n",
      "[28]\tvalid_0's tweedie: 86.4554\n",
      "[29]\tvalid_0's tweedie: 86.4435\n",
      "[30]\tvalid_0's tweedie: 86.4364\n",
      "[31]\tvalid_0's tweedie: 86.4298\n",
      "[32]\tvalid_0's tweedie: 86.4239\n",
      "[33]\tvalid_0's tweedie: 86.419\n",
      "[34]\tvalid_0's tweedie: 86.4129\n",
      "[35]\tvalid_0's tweedie: 86.4091\n",
      "[36]\tvalid_0's tweedie: 86.4046\n",
      "[37]\tvalid_0's tweedie: 86.4018\n",
      "[38]\tvalid_0's tweedie: 86.4005\n",
      "[39]\tvalid_0's tweedie: 86.3993\n",
      "[40]\tvalid_0's tweedie: 86.3982\n",
      "[41]\tvalid_0's tweedie: 86.397\n",
      "[42]\tvalid_0's tweedie: 86.3962\n",
      "[43]\tvalid_0's tweedie: 86.3954\n",
      "[44]\tvalid_0's tweedie: 86.3933\n",
      "[45]\tvalid_0's tweedie: 86.3914\n",
      "[46]\tvalid_0's tweedie: 86.3908\n",
      "[47]\tvalid_0's tweedie: 86.3908\n",
      "[48]\tvalid_0's tweedie: 86.3888\n",
      "[49]\tvalid_0's tweedie: 86.3887\n",
      "[50]\tvalid_0's tweedie: 86.3885\n",
      "[51]\tvalid_0's tweedie: 86.3884\n",
      "[52]\tvalid_0's tweedie: 86.3882\n",
      "[53]\tvalid_0's tweedie: 86.3885\n",
      "[54]\tvalid_0's tweedie: 86.3881\n",
      "[55]\tvalid_0's tweedie: 86.3879\n",
      "[56]\tvalid_0's tweedie: 86.3866\n",
      "[57]\tvalid_0's tweedie: 86.3867\n",
      "[58]\tvalid_0's tweedie: 86.3864\n",
      "[59]\tvalid_0's tweedie: 86.3867\n",
      "[60]\tvalid_0's tweedie: 86.3868\n",
      "[61]\tvalid_0's tweedie: 86.3867\n",
      "[62]\tvalid_0's tweedie: 86.3867\n",
      "[63]\tvalid_0's tweedie: 86.3867\n",
      "[64]\tvalid_0's tweedie: 86.3858\n",
      "[65]\tvalid_0's tweedie: 86.3859\n",
      "[66]\tvalid_0's tweedie: 86.3857\n",
      "[67]\tvalid_0's tweedie: 86.3859\n",
      "[68]\tvalid_0's tweedie: 86.3858\n",
      "[69]\tvalid_0's tweedie: 86.3855\n",
      "[70]\tvalid_0's tweedie: 86.3854\n",
      "[71]\tvalid_0's tweedie: 86.3852\n",
      "[72]\tvalid_0's tweedie: 86.3849\n",
      "[73]\tvalid_0's tweedie: 86.3848\n",
      "[74]\tvalid_0's tweedie: 86.3849\n",
      "[75]\tvalid_0's tweedie: 86.3847\n",
      "[76]\tvalid_0's tweedie: 86.3847\n",
      "[77]\tvalid_0's tweedie: 86.3846\n",
      "[78]\tvalid_0's tweedie: 86.3845\n",
      "[79]\tvalid_0's tweedie: 86.3844\n",
      "[80]\tvalid_0's tweedie: 86.3843\n",
      "[81]\tvalid_0's tweedie: 86.3842\n",
      "[82]\tvalid_0's tweedie: 86.3836\n",
      "[83]\tvalid_0's tweedie: 86.3833\n",
      "[84]\tvalid_0's tweedie: 86.3832\n",
      "[85]\tvalid_0's tweedie: 86.383\n",
      "[86]\tvalid_0's tweedie: 86.383\n",
      "[87]\tvalid_0's tweedie: 86.3831\n",
      "[88]\tvalid_0's tweedie: 86.3826\n",
      "[89]\tvalid_0's tweedie: 86.3823\n",
      "[90]\tvalid_0's tweedie: 86.3828\n",
      "[91]\tvalid_0's tweedie: 86.382\n",
      "[92]\tvalid_0's tweedie: 86.3819\n",
      "[93]\tvalid_0's tweedie: 86.3818\n",
      "[94]\tvalid_0's tweedie: 86.381\n",
      "[95]\tvalid_0's tweedie: 86.3807\n",
      "[96]\tvalid_0's tweedie: 86.3804\n",
      "[97]\tvalid_0's tweedie: 86.3803\n",
      "[98]\tvalid_0's tweedie: 86.3803\n",
      "[99]\tvalid_0's tweedie: 86.3802\n",
      "[100]\tvalid_0's tweedie: 86.3802\n",
      "[101]\tvalid_0's tweedie: 86.3794\n",
      "[102]\tvalid_0's tweedie: 86.3791\n",
      "[103]\tvalid_0's tweedie: 86.379\n",
      "[104]\tvalid_0's tweedie: 86.379\n",
      "[105]\tvalid_0's tweedie: 86.3791\n",
      "[106]\tvalid_0's tweedie: 86.3792\n",
      "[107]\tvalid_0's tweedie: 86.3791\n",
      "[108]\tvalid_0's tweedie: 86.3791\n",
      "[109]\tvalid_0's tweedie: 86.379\n",
      "[110]\tvalid_0's tweedie: 86.379\n",
      "[111]\tvalid_0's tweedie: 86.3792\n",
      "[112]\tvalid_0's tweedie: 86.3791\n",
      "[113]\tvalid_0's tweedie: 86.3791\n",
      "[114]\tvalid_0's tweedie: 86.3793\n",
      "[115]\tvalid_0's tweedie: 86.3792\n",
      "[116]\tvalid_0's tweedie: 86.3792\n",
      "[117]\tvalid_0's tweedie: 86.3792\n",
      "[118]\tvalid_0's tweedie: 86.3792\n",
      "[119]\tvalid_0's tweedie: 86.3792\n",
      "[120]\tvalid_0's tweedie: 86.379\n",
      "[121]\tvalid_0's tweedie: 86.3792\n",
      "[122]\tvalid_0's tweedie: 86.3792\n",
      "[123]\tvalid_0's tweedie: 86.379\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's tweedie: 86.379\n",
      "Training model for level 9 and step 5\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/5/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5520\n",
      "[LightGBM] [Info] Number of data points in the train set: 130689, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.193999\n",
      "[1]\tvalid_0's tweedie: 96.8111\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.0877\n",
      "[3]\tvalid_0's tweedie: 93.6282\n",
      "[4]\tvalid_0's tweedie: 92.4004\n",
      "[5]\tvalid_0's tweedie: 91.3764\n",
      "[6]\tvalid_0's tweedie: 90.5147\n",
      "[7]\tvalid_0's tweedie: 89.7995\n",
      "[8]\tvalid_0's tweedie: 89.207\n",
      "[9]\tvalid_0's tweedie: 88.713\n",
      "[10]\tvalid_0's tweedie: 88.3094\n",
      "[11]\tvalid_0's tweedie: 87.9717\n",
      "[12]\tvalid_0's tweedie: 87.6917\n",
      "[13]\tvalid_0's tweedie: 87.4607\n",
      "[14]\tvalid_0's tweedie: 87.2681\n",
      "[15]\tvalid_0's tweedie: 87.1129\n",
      "[16]\tvalid_0's tweedie: 86.9868\n",
      "[17]\tvalid_0's tweedie: 86.8829\n",
      "[18]\tvalid_0's tweedie: 86.7984\n",
      "[19]\tvalid_0's tweedie: 86.7275\n",
      "[20]\tvalid_0's tweedie: 86.6685\n",
      "[21]\tvalid_0's tweedie: 86.6215\n",
      "[22]\tvalid_0's tweedie: 86.5818\n",
      "[23]\tvalid_0's tweedie: 86.5487\n",
      "[24]\tvalid_0's tweedie: 86.5241\n",
      "[25]\tvalid_0's tweedie: 86.5008\n",
      "[26]\tvalid_0's tweedie: 86.4846\n",
      "[27]\tvalid_0's tweedie: 86.4689\n",
      "[28]\tvalid_0's tweedie: 86.4554\n",
      "[29]\tvalid_0's tweedie: 86.4465\n",
      "[30]\tvalid_0's tweedie: 86.4365\n",
      "[31]\tvalid_0's tweedie: 86.4286\n",
      "[32]\tvalid_0's tweedie: 86.4235\n",
      "[33]\tvalid_0's tweedie: 86.4199\n",
      "[34]\tvalid_0's tweedie: 86.4154\n",
      "[35]\tvalid_0's tweedie: 86.4137\n",
      "[36]\tvalid_0's tweedie: 86.4111\n",
      "[37]\tvalid_0's tweedie: 86.4075\n",
      "[38]\tvalid_0's tweedie: 86.4039\n",
      "[39]\tvalid_0's tweedie: 86.402\n",
      "[40]\tvalid_0's tweedie: 86.4008\n",
      "[41]\tvalid_0's tweedie: 86.3996\n",
      "[42]\tvalid_0's tweedie: 86.3985\n",
      "[43]\tvalid_0's tweedie: 86.398\n",
      "[44]\tvalid_0's tweedie: 86.3974\n",
      "[45]\tvalid_0's tweedie: 86.395\n",
      "[46]\tvalid_0's tweedie: 86.3948\n",
      "[47]\tvalid_0's tweedie: 86.3945\n",
      "[48]\tvalid_0's tweedie: 86.3941\n",
      "[49]\tvalid_0's tweedie: 86.3928\n",
      "[50]\tvalid_0's tweedie: 86.3923\n",
      "[51]\tvalid_0's tweedie: 86.3923\n",
      "[52]\tvalid_0's tweedie: 86.392\n",
      "[53]\tvalid_0's tweedie: 86.3915\n",
      "[54]\tvalid_0's tweedie: 86.3914\n",
      "[55]\tvalid_0's tweedie: 86.3914\n",
      "[56]\tvalid_0's tweedie: 86.3914\n",
      "[57]\tvalid_0's tweedie: 86.3913\n",
      "[58]\tvalid_0's tweedie: 86.3911\n",
      "[59]\tvalid_0's tweedie: 86.39\n",
      "[60]\tvalid_0's tweedie: 86.3898\n",
      "[61]\tvalid_0's tweedie: 86.3896\n",
      "[62]\tvalid_0's tweedie: 86.3895\n",
      "[63]\tvalid_0's tweedie: 86.3896\n",
      "[64]\tvalid_0's tweedie: 86.3894\n",
      "[65]\tvalid_0's tweedie: 86.3893\n",
      "[66]\tvalid_0's tweedie: 86.3894\n",
      "[67]\tvalid_0's tweedie: 86.3894\n",
      "[68]\tvalid_0's tweedie: 86.3883\n",
      "[69]\tvalid_0's tweedie: 86.3881\n",
      "[70]\tvalid_0's tweedie: 86.3869\n",
      "[71]\tvalid_0's tweedie: 86.3866\n",
      "[72]\tvalid_0's tweedie: 86.3867\n",
      "[73]\tvalid_0's tweedie: 86.3857\n",
      "[74]\tvalid_0's tweedie: 86.3856\n",
      "[75]\tvalid_0's tweedie: 86.3855\n",
      "[76]\tvalid_0's tweedie: 86.3847\n",
      "[77]\tvalid_0's tweedie: 86.3848\n",
      "[78]\tvalid_0's tweedie: 86.3847\n",
      "[79]\tvalid_0's tweedie: 86.3846\n",
      "[80]\tvalid_0's tweedie: 86.3845\n",
      "[81]\tvalid_0's tweedie: 86.3846\n",
      "[82]\tvalid_0's tweedie: 86.3846\n",
      "[83]\tvalid_0's tweedie: 86.3844\n",
      "[84]\tvalid_0's tweedie: 86.3842\n",
      "[85]\tvalid_0's tweedie: 86.384\n",
      "[86]\tvalid_0's tweedie: 86.3841\n",
      "[87]\tvalid_0's tweedie: 86.384\n",
      "[88]\tvalid_0's tweedie: 86.384\n",
      "[89]\tvalid_0's tweedie: 86.3844\n",
      "[90]\tvalid_0's tweedie: 86.3845\n",
      "[91]\tvalid_0's tweedie: 86.3845\n",
      "[92]\tvalid_0's tweedie: 86.3844\n",
      "[93]\tvalid_0's tweedie: 86.3844\n",
      "[94]\tvalid_0's tweedie: 86.3844\n",
      "[95]\tvalid_0's tweedie: 86.3849\n",
      "[96]\tvalid_0's tweedie: 86.3849\n",
      "[97]\tvalid_0's tweedie: 86.385\n",
      "[98]\tvalid_0's tweedie: 86.385\n",
      "[99]\tvalid_0's tweedie: 86.3849\n",
      "[100]\tvalid_0's tweedie: 86.3848\n",
      "[101]\tvalid_0's tweedie: 86.385\n",
      "[102]\tvalid_0's tweedie: 86.385\n",
      "[103]\tvalid_0's tweedie: 86.385\n",
      "[104]\tvalid_0's tweedie: 86.3849\n",
      "[105]\tvalid_0's tweedie: 86.3848\n",
      "[106]\tvalid_0's tweedie: 86.3847\n",
      "[107]\tvalid_0's tweedie: 86.3845\n",
      "[108]\tvalid_0's tweedie: 86.3846\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's tweedie: 86.384\n",
      "Training model for level 9 and step 6\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/6/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5519\n",
      "[LightGBM] [Info] Number of data points in the train set: 130619, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194200\n",
      "[1]\tvalid_0's tweedie: 96.8131\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.0901\n",
      "[3]\tvalid_0's tweedie: 93.6306\n",
      "[4]\tvalid_0's tweedie: 92.4026\n",
      "[5]\tvalid_0's tweedie: 91.3732\n",
      "[6]\tvalid_0's tweedie: 90.5134\n",
      "[7]\tvalid_0's tweedie: 89.8055\n",
      "[8]\tvalid_0's tweedie: 89.2121\n",
      "[9]\tvalid_0's tweedie: 88.7199\n",
      "[10]\tvalid_0's tweedie: 88.3155\n",
      "[11]\tvalid_0's tweedie: 87.9769\n",
      "[12]\tvalid_0's tweedie: 87.6911\n",
      "[13]\tvalid_0's tweedie: 87.4593\n",
      "[14]\tvalid_0's tweedie: 87.2681\n",
      "[15]\tvalid_0's tweedie: 87.1143\n",
      "[16]\tvalid_0's tweedie: 86.9876\n",
      "[17]\tvalid_0's tweedie: 86.882\n",
      "[18]\tvalid_0's tweedie: 86.7985\n",
      "[19]\tvalid_0's tweedie: 86.7281\n",
      "[20]\tvalid_0's tweedie: 86.6692\n",
      "[21]\tvalid_0's tweedie: 86.6226\n",
      "[22]\tvalid_0's tweedie: 86.5825\n",
      "[23]\tvalid_0's tweedie: 86.5501\n",
      "[24]\tvalid_0's tweedie: 86.5265\n",
      "[25]\tvalid_0's tweedie: 86.5042\n",
      "[26]\tvalid_0's tweedie: 86.4848\n",
      "[27]\tvalid_0's tweedie: 86.4687\n",
      "[28]\tvalid_0's tweedie: 86.4579\n",
      "[29]\tvalid_0's tweedie: 86.449\n",
      "[30]\tvalid_0's tweedie: 86.4401\n",
      "[31]\tvalid_0's tweedie: 86.4341\n",
      "[32]\tvalid_0's tweedie: 86.429\n",
      "[33]\tvalid_0's tweedie: 86.4243\n",
      "[34]\tvalid_0's tweedie: 86.4221\n",
      "[35]\tvalid_0's tweedie: 86.4179\n",
      "[36]\tvalid_0's tweedie: 86.4154\n",
      "[37]\tvalid_0's tweedie: 86.4109\n",
      "[38]\tvalid_0's tweedie: 86.4091\n",
      "[39]\tvalid_0's tweedie: 86.4078\n",
      "[40]\tvalid_0's tweedie: 86.4065\n",
      "[41]\tvalid_0's tweedie: 86.4051\n",
      "[42]\tvalid_0's tweedie: 86.4024\n",
      "[43]\tvalid_0's tweedie: 86.4002\n",
      "[44]\tvalid_0's tweedie: 86.3992\n",
      "[45]\tvalid_0's tweedie: 86.3989\n",
      "[46]\tvalid_0's tweedie: 86.3978\n",
      "[47]\tvalid_0's tweedie: 86.3962\n",
      "[48]\tvalid_0's tweedie: 86.395\n",
      "[49]\tvalid_0's tweedie: 86.3947\n",
      "[50]\tvalid_0's tweedie: 86.3943\n",
      "[51]\tvalid_0's tweedie: 86.3936\n",
      "[52]\tvalid_0's tweedie: 86.3934\n",
      "[53]\tvalid_0's tweedie: 86.3931\n",
      "[54]\tvalid_0's tweedie: 86.3924\n",
      "[55]\tvalid_0's tweedie: 86.3922\n",
      "[56]\tvalid_0's tweedie: 86.3923\n",
      "[57]\tvalid_0's tweedie: 86.3924\n",
      "[58]\tvalid_0's tweedie: 86.3922\n",
      "[59]\tvalid_0's tweedie: 86.3921\n",
      "[60]\tvalid_0's tweedie: 86.3922\n",
      "[61]\tvalid_0's tweedie: 86.3923\n",
      "[62]\tvalid_0's tweedie: 86.3925\n",
      "[63]\tvalid_0's tweedie: 86.3926\n",
      "[64]\tvalid_0's tweedie: 86.3925\n",
      "[65]\tvalid_0's tweedie: 86.3922\n",
      "[66]\tvalid_0's tweedie: 86.3922\n",
      "[67]\tvalid_0's tweedie: 86.3923\n",
      "[68]\tvalid_0's tweedie: 86.3923\n",
      "[69]\tvalid_0's tweedie: 86.3923\n",
      "[70]\tvalid_0's tweedie: 86.3923\n",
      "[71]\tvalid_0's tweedie: 86.3923\n",
      "[72]\tvalid_0's tweedie: 86.3922\n",
      "[73]\tvalid_0's tweedie: 86.3921\n",
      "[74]\tvalid_0's tweedie: 86.3921\n",
      "[75]\tvalid_0's tweedie: 86.3922\n",
      "[76]\tvalid_0's tweedie: 86.3922\n",
      "[77]\tvalid_0's tweedie: 86.3921\n",
      "[78]\tvalid_0's tweedie: 86.3909\n",
      "[79]\tvalid_0's tweedie: 86.3911\n",
      "[80]\tvalid_0's tweedie: 86.3911\n",
      "[81]\tvalid_0's tweedie: 86.3911\n",
      "[82]\tvalid_0's tweedie: 86.391\n",
      "[83]\tvalid_0's tweedie: 86.3908\n",
      "[84]\tvalid_0's tweedie: 86.3908\n",
      "[85]\tvalid_0's tweedie: 86.3908\n",
      "[86]\tvalid_0's tweedie: 86.3906\n",
      "[87]\tvalid_0's tweedie: 86.3906\n",
      "[88]\tvalid_0's tweedie: 86.3894\n",
      "[89]\tvalid_0's tweedie: 86.387\n",
      "[90]\tvalid_0's tweedie: 86.3869\n",
      "[91]\tvalid_0's tweedie: 86.3868\n",
      "[92]\tvalid_0's tweedie: 86.3867\n",
      "[93]\tvalid_0's tweedie: 86.3862\n",
      "[94]\tvalid_0's tweedie: 86.3862\n",
      "[95]\tvalid_0's tweedie: 86.3863\n",
      "[96]\tvalid_0's tweedie: 86.3863\n",
      "[97]\tvalid_0's tweedie: 86.386\n",
      "[98]\tvalid_0's tweedie: 86.3865\n",
      "[99]\tvalid_0's tweedie: 86.3865\n",
      "[100]\tvalid_0's tweedie: 86.3865\n",
      "[101]\tvalid_0's tweedie: 86.3864\n",
      "[102]\tvalid_0's tweedie: 86.3863\n",
      "[103]\tvalid_0's tweedie: 86.3862\n",
      "[104]\tvalid_0's tweedie: 86.3857\n",
      "[105]\tvalid_0's tweedie: 86.3857\n",
      "[106]\tvalid_0's tweedie: 86.3856\n",
      "[107]\tvalid_0's tweedie: 86.3856\n",
      "[108]\tvalid_0's tweedie: 86.3853\n",
      "[109]\tvalid_0's tweedie: 86.3846\n",
      "[110]\tvalid_0's tweedie: 86.3847\n",
      "[111]\tvalid_0's tweedie: 86.3845\n",
      "[112]\tvalid_0's tweedie: 86.3845\n",
      "[113]\tvalid_0's tweedie: 86.3845\n",
      "[114]\tvalid_0's tweedie: 86.3844\n",
      "[115]\tvalid_0's tweedie: 86.3843\n",
      "[116]\tvalid_0's tweedie: 86.3843\n",
      "[117]\tvalid_0's tweedie: 86.3842\n",
      "[118]\tvalid_0's tweedie: 86.384\n",
      "[119]\tvalid_0's tweedie: 86.384\n",
      "[120]\tvalid_0's tweedie: 86.3839\n",
      "[121]\tvalid_0's tweedie: 86.3838\n",
      "[122]\tvalid_0's tweedie: 86.3837\n",
      "[123]\tvalid_0's tweedie: 86.3837\n",
      "[124]\tvalid_0's tweedie: 86.3851\n",
      "[125]\tvalid_0's tweedie: 86.3851\n",
      "[126]\tvalid_0's tweedie: 86.3852\n",
      "[127]\tvalid_0's tweedie: 86.385\n",
      "[128]\tvalid_0's tweedie: 86.3849\n",
      "[129]\tvalid_0's tweedie: 86.3849\n",
      "[130]\tvalid_0's tweedie: 86.3849\n",
      "[131]\tvalid_0's tweedie: 86.3849\n",
      "[132]\tvalid_0's tweedie: 86.3848\n",
      "[133]\tvalid_0's tweedie: 86.3847\n",
      "[134]\tvalid_0's tweedie: 86.3846\n",
      "[135]\tvalid_0's tweedie: 86.384\n",
      "[136]\tvalid_0's tweedie: 86.384\n",
      "[137]\tvalid_0's tweedie: 86.3841\n",
      "[138]\tvalid_0's tweedie: 86.384\n",
      "[139]\tvalid_0's tweedie: 86.3841\n",
      "[140]\tvalid_0's tweedie: 86.3838\n",
      "[141]\tvalid_0's tweedie: 86.3837\n",
      "[142]\tvalid_0's tweedie: 86.3836\n",
      "[143]\tvalid_0's tweedie: 86.3836\n",
      "[144]\tvalid_0's tweedie: 86.3836\n",
      "[145]\tvalid_0's tweedie: 86.3836\n",
      "[146]\tvalid_0's tweedie: 86.3836\n",
      "[147]\tvalid_0's tweedie: 86.3836\n",
      "[148]\tvalid_0's tweedie: 86.3831\n",
      "[149]\tvalid_0's tweedie: 86.3831\n",
      "[150]\tvalid_0's tweedie: 86.3831\n",
      "[151]\tvalid_0's tweedie: 86.3831\n",
      "[152]\tvalid_0's tweedie: 86.3832\n",
      "[153]\tvalid_0's tweedie: 86.3831\n",
      "[154]\tvalid_0's tweedie: 86.3831\n",
      "[155]\tvalid_0's tweedie: 86.3828\n",
      "[156]\tvalid_0's tweedie: 86.3828\n",
      "[157]\tvalid_0's tweedie: 86.3828\n",
      "[158]\tvalid_0's tweedie: 86.3828\n",
      "[159]\tvalid_0's tweedie: 86.3828\n",
      "[160]\tvalid_0's tweedie: 86.3827\n",
      "[161]\tvalid_0's tweedie: 86.3826\n",
      "[162]\tvalid_0's tweedie: 86.3826\n",
      "[163]\tvalid_0's tweedie: 86.3821\n",
      "[164]\tvalid_0's tweedie: 86.382\n",
      "[165]\tvalid_0's tweedie: 86.3821\n",
      "[166]\tvalid_0's tweedie: 86.382\n",
      "[167]\tvalid_0's tweedie: 86.3821\n",
      "[168]\tvalid_0's tweedie: 86.3821\n",
      "[169]\tvalid_0's tweedie: 86.3814\n",
      "[170]\tvalid_0's tweedie: 86.3814\n",
      "[171]\tvalid_0's tweedie: 86.3813\n",
      "[172]\tvalid_0's tweedie: 86.3813\n",
      "[173]\tvalid_0's tweedie: 86.3815\n",
      "[174]\tvalid_0's tweedie: 86.3815\n",
      "[175]\tvalid_0's tweedie: 86.3816\n",
      "[176]\tvalid_0's tweedie: 86.3816\n",
      "[177]\tvalid_0's tweedie: 86.3815\n",
      "[178]\tvalid_0's tweedie: 86.3813\n",
      "[179]\tvalid_0's tweedie: 86.3813\n",
      "[180]\tvalid_0's tweedie: 86.3812\n",
      "[181]\tvalid_0's tweedie: 86.3812\n",
      "[182]\tvalid_0's tweedie: 86.3813\n",
      "[183]\tvalid_0's tweedie: 86.3812\n",
      "[184]\tvalid_0's tweedie: 86.3812\n",
      "[185]\tvalid_0's tweedie: 86.3811\n",
      "[186]\tvalid_0's tweedie: 86.3812\n",
      "[187]\tvalid_0's tweedie: 86.3811\n",
      "[188]\tvalid_0's tweedie: 86.3811\n",
      "[189]\tvalid_0's tweedie: 86.3811\n",
      "[190]\tvalid_0's tweedie: 86.3811\n",
      "[191]\tvalid_0's tweedie: 86.381\n",
      "[192]\tvalid_0's tweedie: 86.3811\n",
      "[193]\tvalid_0's tweedie: 86.381\n",
      "[194]\tvalid_0's tweedie: 86.381\n",
      "[195]\tvalid_0's tweedie: 86.3809\n",
      "[196]\tvalid_0's tweedie: 86.3809\n",
      "[197]\tvalid_0's tweedie: 86.3811\n",
      "[198]\tvalid_0's tweedie: 86.3811\n",
      "[199]\tvalid_0's tweedie: 86.381\n",
      "[200]\tvalid_0's tweedie: 86.3806\n",
      "[201]\tvalid_0's tweedie: 86.3806\n",
      "[202]\tvalid_0's tweedie: 86.3805\n",
      "[203]\tvalid_0's tweedie: 86.3802\n",
      "[204]\tvalid_0's tweedie: 86.3802\n",
      "[205]\tvalid_0's tweedie: 86.3802\n",
      "[206]\tvalid_0's tweedie: 86.3801\n",
      "[207]\tvalid_0's tweedie: 86.3801\n",
      "[208]\tvalid_0's tweedie: 86.3801\n",
      "[209]\tvalid_0's tweedie: 86.3803\n",
      "[210]\tvalid_0's tweedie: 86.3802\n",
      "[211]\tvalid_0's tweedie: 86.3801\n",
      "[212]\tvalid_0's tweedie: 86.3802\n",
      "[213]\tvalid_0's tweedie: 86.3801\n",
      "[214]\tvalid_0's tweedie: 86.3802\n",
      "[215]\tvalid_0's tweedie: 86.3802\n",
      "[216]\tvalid_0's tweedie: 86.38\n",
      "[217]\tvalid_0's tweedie: 86.38\n",
      "[218]\tvalid_0's tweedie: 86.38\n",
      "[219]\tvalid_0's tweedie: 86.3799\n",
      "[220]\tvalid_0's tweedie: 86.3799\n",
      "[221]\tvalid_0's tweedie: 86.3799\n",
      "[222]\tvalid_0's tweedie: 86.3799\n",
      "[223]\tvalid_0's tweedie: 86.3799\n",
      "[224]\tvalid_0's tweedie: 86.3799\n",
      "[225]\tvalid_0's tweedie: 86.3799\n",
      "[226]\tvalid_0's tweedie: 86.3799\n",
      "[227]\tvalid_0's tweedie: 86.3798\n",
      "[228]\tvalid_0's tweedie: 86.3798\n",
      "[229]\tvalid_0's tweedie: 86.3798\n",
      "[230]\tvalid_0's tweedie: 86.3797\n",
      "[231]\tvalid_0's tweedie: 86.3797\n",
      "[232]\tvalid_0's tweedie: 86.3809\n",
      "[233]\tvalid_0's tweedie: 86.3809\n",
      "[234]\tvalid_0's tweedie: 86.3809\n",
      "[235]\tvalid_0's tweedie: 86.3809\n",
      "[236]\tvalid_0's tweedie: 86.3808\n",
      "[237]\tvalid_0's tweedie: 86.3808\n",
      "[238]\tvalid_0's tweedie: 86.3808\n",
      "[239]\tvalid_0's tweedie: 86.3806\n",
      "[240]\tvalid_0's tweedie: 86.3807\n",
      "[241]\tvalid_0's tweedie: 86.3807\n",
      "[242]\tvalid_0's tweedie: 86.3807\n",
      "[243]\tvalid_0's tweedie: 86.3807\n",
      "[244]\tvalid_0's tweedie: 86.3807\n",
      "[245]\tvalid_0's tweedie: 86.3806\n",
      "[246]\tvalid_0's tweedie: 86.3806\n",
      "[247]\tvalid_0's tweedie: 86.3813\n",
      "[248]\tvalid_0's tweedie: 86.3813\n",
      "[249]\tvalid_0's tweedie: 86.3813\n",
      "[250]\tvalid_0's tweedie: 86.3813\n",
      "[251]\tvalid_0's tweedie: 86.3813\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's tweedie: 86.3797\n",
      "Training model for level 9 and step 7\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/7/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5518\n",
      "[LightGBM] [Info] Number of data points in the train set: 130549, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194418\n",
      "[1]\tvalid_0's tweedie: 96.811\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.0895\n",
      "[3]\tvalid_0's tweedie: 93.6274\n",
      "[4]\tvalid_0's tweedie: 92.3975\n",
      "[5]\tvalid_0's tweedie: 91.3606\n",
      "[6]\tvalid_0's tweedie: 90.5018\n",
      "[7]\tvalid_0's tweedie: 89.7805\n",
      "[8]\tvalid_0's tweedie: 89.1901\n",
      "[9]\tvalid_0's tweedie: 88.6999\n",
      "[10]\tvalid_0's tweedie: 88.2959\n",
      "[11]\tvalid_0's tweedie: 87.9655\n",
      "[12]\tvalid_0's tweedie: 87.685\n",
      "[13]\tvalid_0's tweedie: 87.4521\n",
      "[14]\tvalid_0's tweedie: 87.2582\n",
      "[15]\tvalid_0's tweedie: 87.1015\n",
      "[16]\tvalid_0's tweedie: 86.9729\n",
      "[17]\tvalid_0's tweedie: 86.8681\n",
      "[18]\tvalid_0's tweedie: 86.7827\n",
      "[19]\tvalid_0's tweedie: 86.7139\n",
      "[20]\tvalid_0's tweedie: 86.6584\n",
      "[21]\tvalid_0's tweedie: 86.6112\n",
      "[22]\tvalid_0's tweedie: 86.5705\n",
      "[23]\tvalid_0's tweedie: 86.5392\n",
      "[24]\tvalid_0's tweedie: 86.5107\n",
      "[25]\tvalid_0's tweedie: 86.4901\n",
      "[26]\tvalid_0's tweedie: 86.4729\n",
      "[27]\tvalid_0's tweedie: 86.4593\n",
      "[28]\tvalid_0's tweedie: 86.4489\n",
      "[29]\tvalid_0's tweedie: 86.4361\n",
      "[30]\tvalid_0's tweedie: 86.4292\n",
      "[31]\tvalid_0's tweedie: 86.4228\n",
      "[32]\tvalid_0's tweedie: 86.4156\n",
      "[33]\tvalid_0's tweedie: 86.411\n",
      "[34]\tvalid_0's tweedie: 86.4053\n",
      "[35]\tvalid_0's tweedie: 86.4025\n",
      "[36]\tvalid_0's tweedie: 86.3995\n",
      "[37]\tvalid_0's tweedie: 86.3978\n",
      "[38]\tvalid_0's tweedie: 86.3943\n",
      "[39]\tvalid_0's tweedie: 86.3933\n",
      "[40]\tvalid_0's tweedie: 86.3913\n",
      "[41]\tvalid_0's tweedie: 86.3889\n",
      "[42]\tvalid_0's tweedie: 86.3885\n",
      "[43]\tvalid_0's tweedie: 86.3866\n",
      "[44]\tvalid_0's tweedie: 86.3861\n",
      "[45]\tvalid_0's tweedie: 86.3857\n",
      "[46]\tvalid_0's tweedie: 86.3852\n",
      "[47]\tvalid_0's tweedie: 86.3851\n",
      "[48]\tvalid_0's tweedie: 86.3851\n",
      "[49]\tvalid_0's tweedie: 86.3843\n",
      "[50]\tvalid_0's tweedie: 86.3839\n",
      "[51]\tvalid_0's tweedie: 86.3838\n",
      "[52]\tvalid_0's tweedie: 86.3837\n",
      "[53]\tvalid_0's tweedie: 86.3834\n",
      "[54]\tvalid_0's tweedie: 86.3832\n",
      "[55]\tvalid_0's tweedie: 86.383\n",
      "[56]\tvalid_0's tweedie: 86.3819\n",
      "[57]\tvalid_0's tweedie: 86.3818\n",
      "[58]\tvalid_0's tweedie: 86.381\n",
      "[59]\tvalid_0's tweedie: 86.381\n",
      "[60]\tvalid_0's tweedie: 86.3805\n",
      "[61]\tvalid_0's tweedie: 86.3807\n",
      "[62]\tvalid_0's tweedie: 86.3807\n",
      "[63]\tvalid_0's tweedie: 86.3805\n",
      "[64]\tvalid_0's tweedie: 86.3805\n",
      "[65]\tvalid_0's tweedie: 86.3802\n",
      "[66]\tvalid_0's tweedie: 86.3804\n",
      "[67]\tvalid_0's tweedie: 86.3805\n",
      "[68]\tvalid_0's tweedie: 86.3794\n",
      "[69]\tvalid_0's tweedie: 86.3792\n",
      "[70]\tvalid_0's tweedie: 86.3785\n",
      "[71]\tvalid_0's tweedie: 86.3783\n",
      "[72]\tvalid_0's tweedie: 86.3784\n",
      "[73]\tvalid_0's tweedie: 86.3784\n",
      "[74]\tvalid_0's tweedie: 86.3782\n",
      "[75]\tvalid_0's tweedie: 86.3783\n",
      "[76]\tvalid_0's tweedie: 86.3782\n",
      "[77]\tvalid_0's tweedie: 86.3783\n",
      "[78]\tvalid_0's tweedie: 86.3783\n",
      "[79]\tvalid_0's tweedie: 86.3783\n",
      "[80]\tvalid_0's tweedie: 86.3782\n",
      "[81]\tvalid_0's tweedie: 86.3774\n",
      "[82]\tvalid_0's tweedie: 86.3773\n",
      "[83]\tvalid_0's tweedie: 86.3764\n",
      "[84]\tvalid_0's tweedie: 86.3764\n",
      "[85]\tvalid_0's tweedie: 86.3763\n",
      "[86]\tvalid_0's tweedie: 86.3761\n",
      "[87]\tvalid_0's tweedie: 86.3735\n",
      "[88]\tvalid_0's tweedie: 86.3734\n",
      "[89]\tvalid_0's tweedie: 86.3734\n",
      "[90]\tvalid_0's tweedie: 86.3732\n",
      "[91]\tvalid_0's tweedie: 86.3731\n",
      "[92]\tvalid_0's tweedie: 86.3731\n",
      "[93]\tvalid_0's tweedie: 86.3728\n",
      "[94]\tvalid_0's tweedie: 86.3727\n",
      "[95]\tvalid_0's tweedie: 86.3727\n",
      "[96]\tvalid_0's tweedie: 86.3718\n",
      "[97]\tvalid_0's tweedie: 86.3718\n",
      "[98]\tvalid_0's tweedie: 86.3715\n",
      "[99]\tvalid_0's tweedie: 86.3713\n",
      "[100]\tvalid_0's tweedie: 86.3714\n",
      "[101]\tvalid_0's tweedie: 86.3714\n",
      "[102]\tvalid_0's tweedie: 86.3713\n",
      "[103]\tvalid_0's tweedie: 86.371\n",
      "[104]\tvalid_0's tweedie: 86.371\n",
      "[105]\tvalid_0's tweedie: 86.3709\n",
      "[106]\tvalid_0's tweedie: 86.371\n",
      "[107]\tvalid_0's tweedie: 86.3708\n",
      "[108]\tvalid_0's tweedie: 86.3707\n",
      "[109]\tvalid_0's tweedie: 86.3707\n",
      "[110]\tvalid_0's tweedie: 86.3706\n",
      "[111]\tvalid_0's tweedie: 86.3705\n",
      "[112]\tvalid_0's tweedie: 86.3704\n",
      "[113]\tvalid_0's tweedie: 86.3705\n",
      "[114]\tvalid_0's tweedie: 86.3705\n",
      "[115]\tvalid_0's tweedie: 86.3701\n",
      "[116]\tvalid_0's tweedie: 86.37\n",
      "[117]\tvalid_0's tweedie: 86.3699\n",
      "[118]\tvalid_0's tweedie: 86.3699\n",
      "[119]\tvalid_0's tweedie: 86.37\n",
      "[120]\tvalid_0's tweedie: 86.3698\n",
      "[121]\tvalid_0's tweedie: 86.3697\n",
      "[122]\tvalid_0's tweedie: 86.3697\n",
      "[123]\tvalid_0's tweedie: 86.3708\n",
      "[124]\tvalid_0's tweedie: 86.3707\n",
      "[125]\tvalid_0's tweedie: 86.3707\n",
      "[126]\tvalid_0's tweedie: 86.3708\n",
      "[127]\tvalid_0's tweedie: 86.3707\n",
      "[128]\tvalid_0's tweedie: 86.3707\n",
      "[129]\tvalid_0's tweedie: 86.3705\n",
      "[130]\tvalid_0's tweedie: 86.3703\n",
      "[131]\tvalid_0's tweedie: 86.3702\n",
      "[132]\tvalid_0's tweedie: 86.3702\n",
      "[133]\tvalid_0's tweedie: 86.3699\n",
      "[134]\tvalid_0's tweedie: 86.3699\n",
      "[135]\tvalid_0's tweedie: 86.3698\n",
      "[136]\tvalid_0's tweedie: 86.3699\n",
      "[137]\tvalid_0's tweedie: 86.3699\n",
      "[138]\tvalid_0's tweedie: 86.3698\n",
      "[139]\tvalid_0's tweedie: 86.3699\n",
      "[140]\tvalid_0's tweedie: 86.3689\n",
      "[141]\tvalid_0's tweedie: 86.3689\n",
      "[142]\tvalid_0's tweedie: 86.3689\n",
      "[143]\tvalid_0's tweedie: 86.3688\n",
      "[144]\tvalid_0's tweedie: 86.3687\n",
      "[145]\tvalid_0's tweedie: 86.3686\n",
      "[146]\tvalid_0's tweedie: 86.3685\n",
      "[147]\tvalid_0's tweedie: 86.3685\n",
      "[148]\tvalid_0's tweedie: 86.3685\n",
      "[149]\tvalid_0's tweedie: 86.3685\n",
      "[150]\tvalid_0's tweedie: 86.3685\n",
      "[151]\tvalid_0's tweedie: 86.3684\n",
      "[152]\tvalid_0's tweedie: 86.3681\n",
      "[153]\tvalid_0's tweedie: 86.3681\n",
      "[154]\tvalid_0's tweedie: 86.368\n",
      "[155]\tvalid_0's tweedie: 86.368\n",
      "[156]\tvalid_0's tweedie: 86.368\n",
      "[157]\tvalid_0's tweedie: 86.368\n",
      "[158]\tvalid_0's tweedie: 86.3679\n",
      "[159]\tvalid_0's tweedie: 86.3679\n",
      "[160]\tvalid_0's tweedie: 86.3678\n",
      "[161]\tvalid_0's tweedie: 86.3679\n",
      "[162]\tvalid_0's tweedie: 86.3672\n",
      "[163]\tvalid_0's tweedie: 86.3671\n",
      "[164]\tvalid_0's tweedie: 86.367\n",
      "[165]\tvalid_0's tweedie: 86.3669\n",
      "[166]\tvalid_0's tweedie: 86.3669\n",
      "[167]\tvalid_0's tweedie: 86.3669\n",
      "[168]\tvalid_0's tweedie: 86.3666\n",
      "[169]\tvalid_0's tweedie: 86.3667\n",
      "[170]\tvalid_0's tweedie: 86.3667\n",
      "[171]\tvalid_0's tweedie: 86.3666\n",
      "[172]\tvalid_0's tweedie: 86.3665\n",
      "[173]\tvalid_0's tweedie: 86.3665\n",
      "[174]\tvalid_0's tweedie: 86.3664\n",
      "[175]\tvalid_0's tweedie: 86.3664\n",
      "[176]\tvalid_0's tweedie: 86.3664\n",
      "[177]\tvalid_0's tweedie: 86.3664\n",
      "[178]\tvalid_0's tweedie: 86.3662\n",
      "[179]\tvalid_0's tweedie: 86.3662\n",
      "[180]\tvalid_0's tweedie: 86.3662\n",
      "[181]\tvalid_0's tweedie: 86.3661\n",
      "[182]\tvalid_0's tweedie: 86.3661\n",
      "[183]\tvalid_0's tweedie: 86.3666\n",
      "[184]\tvalid_0's tweedie: 86.3665\n",
      "[185]\tvalid_0's tweedie: 86.3665\n",
      "[186]\tvalid_0's tweedie: 86.3665\n",
      "[187]\tvalid_0's tweedie: 86.3663\n",
      "[188]\tvalid_0's tweedie: 86.3662\n",
      "[189]\tvalid_0's tweedie: 86.3662\n",
      "[190]\tvalid_0's tweedie: 86.3662\n",
      "[191]\tvalid_0's tweedie: 86.3663\n",
      "[192]\tvalid_0's tweedie: 86.3663\n",
      "[193]\tvalid_0's tweedie: 86.3663\n",
      "[194]\tvalid_0's tweedie: 86.3663\n",
      "[195]\tvalid_0's tweedie: 86.3664\n",
      "[196]\tvalid_0's tweedie: 86.3664\n",
      "[197]\tvalid_0's tweedie: 86.3664\n",
      "[198]\tvalid_0's tweedie: 86.3664\n",
      "[199]\tvalid_0's tweedie: 86.3667\n",
      "[200]\tvalid_0's tweedie: 86.3668\n",
      "[201]\tvalid_0's tweedie: 86.3667\n",
      "[202]\tvalid_0's tweedie: 86.3667\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's tweedie: 86.3661\n",
      "Training model for level 9 and step 8\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/8/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5517\n",
      "[LightGBM] [Info] Number of data points in the train set: 130479, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194583\n",
      "[1]\tvalid_0's tweedie: 96.816\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1055\n",
      "[3]\tvalid_0's tweedie: 93.6604\n",
      "[4]\tvalid_0's tweedie: 92.4369\n",
      "[5]\tvalid_0's tweedie: 91.4098\n",
      "[6]\tvalid_0's tweedie: 90.5534\n",
      "[7]\tvalid_0's tweedie: 89.8294\n",
      "[8]\tvalid_0's tweedie: 89.2355\n",
      "[9]\tvalid_0's tweedie: 88.7399\n",
      "[10]\tvalid_0's tweedie: 88.3309\n",
      "[11]\tvalid_0's tweedie: 87.9926\n",
      "[12]\tvalid_0's tweedie: 87.7108\n",
      "[13]\tvalid_0's tweedie: 87.4756\n",
      "[14]\tvalid_0's tweedie: 87.2898\n",
      "[15]\tvalid_0's tweedie: 87.1301\n",
      "[16]\tvalid_0's tweedie: 86.9983\n",
      "[17]\tvalid_0's tweedie: 86.89\n",
      "[18]\tvalid_0's tweedie: 86.8018\n",
      "[19]\tvalid_0's tweedie: 86.7326\n",
      "[20]\tvalid_0's tweedie: 86.6778\n",
      "[21]\tvalid_0's tweedie: 86.6296\n",
      "[22]\tvalid_0's tweedie: 86.5924\n",
      "[23]\tvalid_0's tweedie: 86.5608\n",
      "[24]\tvalid_0's tweedie: 86.5354\n",
      "[25]\tvalid_0's tweedie: 86.5137\n",
      "[26]\tvalid_0's tweedie: 86.4972\n",
      "[27]\tvalid_0's tweedie: 86.4825\n",
      "[28]\tvalid_0's tweedie: 86.4718\n",
      "[29]\tvalid_0's tweedie: 86.4621\n",
      "[30]\tvalid_0's tweedie: 86.4559\n",
      "[31]\tvalid_0's tweedie: 86.4456\n",
      "[32]\tvalid_0's tweedie: 86.4385\n",
      "[33]\tvalid_0's tweedie: 86.4313\n",
      "[34]\tvalid_0's tweedie: 86.4276\n",
      "[35]\tvalid_0's tweedie: 86.4247\n",
      "[36]\tvalid_0's tweedie: 86.4213\n",
      "[37]\tvalid_0's tweedie: 86.4169\n",
      "[38]\tvalid_0's tweedie: 86.4143\n",
      "[39]\tvalid_0's tweedie: 86.4135\n",
      "[40]\tvalid_0's tweedie: 86.4105\n",
      "[41]\tvalid_0's tweedie: 86.4074\n",
      "[42]\tvalid_0's tweedie: 86.4065\n",
      "[43]\tvalid_0's tweedie: 86.4042\n",
      "[44]\tvalid_0's tweedie: 86.4035\n",
      "[45]\tvalid_0's tweedie: 86.4009\n",
      "[46]\tvalid_0's tweedie: 86.4003\n",
      "[47]\tvalid_0's tweedie: 86.3997\n",
      "[48]\tvalid_0's tweedie: 86.3979\n",
      "[49]\tvalid_0's tweedie: 86.3977\n",
      "[50]\tvalid_0's tweedie: 86.3972\n",
      "[51]\tvalid_0's tweedie: 86.3968\n",
      "[52]\tvalid_0's tweedie: 86.3968\n",
      "[53]\tvalid_0's tweedie: 86.3968\n",
      "[54]\tvalid_0's tweedie: 86.3969\n",
      "[55]\tvalid_0's tweedie: 86.397\n",
      "[56]\tvalid_0's tweedie: 86.3973\n",
      "[57]\tvalid_0's tweedie: 86.3968\n",
      "[58]\tvalid_0's tweedie: 86.3966\n",
      "[59]\tvalid_0's tweedie: 86.3964\n",
      "[60]\tvalid_0's tweedie: 86.3956\n",
      "[61]\tvalid_0's tweedie: 86.3959\n",
      "[62]\tvalid_0's tweedie: 86.3957\n",
      "[63]\tvalid_0's tweedie: 86.3949\n",
      "[64]\tvalid_0's tweedie: 86.3949\n",
      "[65]\tvalid_0's tweedie: 86.3943\n",
      "[66]\tvalid_0's tweedie: 86.3949\n",
      "[67]\tvalid_0's tweedie: 86.3948\n",
      "[68]\tvalid_0's tweedie: 86.3952\n",
      "[69]\tvalid_0's tweedie: 86.3954\n",
      "[70]\tvalid_0's tweedie: 86.3954\n",
      "[71]\tvalid_0's tweedie: 86.3954\n",
      "[72]\tvalid_0's tweedie: 86.3955\n",
      "[73]\tvalid_0's tweedie: 86.3956\n",
      "[74]\tvalid_0's tweedie: 86.3956\n",
      "[75]\tvalid_0's tweedie: 86.3956\n",
      "[76]\tvalid_0's tweedie: 86.3955\n",
      "[77]\tvalid_0's tweedie: 86.3956\n",
      "[78]\tvalid_0's tweedie: 86.3955\n",
      "[79]\tvalid_0's tweedie: 86.3954\n",
      "[80]\tvalid_0's tweedie: 86.3952\n",
      "[81]\tvalid_0's tweedie: 86.3951\n",
      "[82]\tvalid_0's tweedie: 86.3951\n",
      "[83]\tvalid_0's tweedie: 86.3952\n",
      "[84]\tvalid_0's tweedie: 86.395\n",
      "[85]\tvalid_0's tweedie: 86.395\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's tweedie: 86.3943\n",
      "Training model for level 9 and step 9\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/9/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5516\n",
      "[LightGBM] [Info] Number of data points in the train set: 130409, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194624\n",
      "[1]\tvalid_0's tweedie: 96.8155\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1055\n",
      "[3]\tvalid_0's tweedie: 93.6633\n",
      "[4]\tvalid_0's tweedie: 92.4475\n",
      "[5]\tvalid_0's tweedie: 91.4187\n",
      "[6]\tvalid_0's tweedie: 90.5571\n",
      "[7]\tvalid_0's tweedie: 89.845\n",
      "[8]\tvalid_0's tweedie: 89.2536\n",
      "[9]\tvalid_0's tweedie: 88.7675\n",
      "[10]\tvalid_0's tweedie: 88.3578\n",
      "[11]\tvalid_0's tweedie: 88.0149\n",
      "[12]\tvalid_0's tweedie: 87.7368\n",
      "[13]\tvalid_0's tweedie: 87.508\n",
      "[14]\tvalid_0's tweedie: 87.3187\n",
      "[15]\tvalid_0's tweedie: 87.1625\n",
      "[16]\tvalid_0's tweedie: 87.0312\n",
      "[17]\tvalid_0's tweedie: 86.9274\n",
      "[18]\tvalid_0's tweedie: 86.8376\n",
      "[19]\tvalid_0's tweedie: 86.7627\n",
      "[20]\tvalid_0's tweedie: 86.7036\n",
      "[21]\tvalid_0's tweedie: 86.6559\n",
      "[22]\tvalid_0's tweedie: 86.6147\n",
      "[23]\tvalid_0's tweedie: 86.583\n",
      "[24]\tvalid_0's tweedie: 86.5572\n",
      "[25]\tvalid_0's tweedie: 86.5366\n",
      "[26]\tvalid_0's tweedie: 86.5181\n",
      "[27]\tvalid_0's tweedie: 86.5033\n",
      "[28]\tvalid_0's tweedie: 86.4906\n",
      "[29]\tvalid_0's tweedie: 86.4812\n",
      "[30]\tvalid_0's tweedie: 86.4753\n",
      "[31]\tvalid_0's tweedie: 86.4682\n",
      "[32]\tvalid_0's tweedie: 86.4634\n",
      "[33]\tvalid_0's tweedie: 86.4573\n",
      "[34]\tvalid_0's tweedie: 86.4506\n",
      "[35]\tvalid_0's tweedie: 86.4461\n",
      "[36]\tvalid_0's tweedie: 86.4438\n",
      "[37]\tvalid_0's tweedie: 86.4415\n",
      "[38]\tvalid_0's tweedie: 86.4379\n",
      "[39]\tvalid_0's tweedie: 86.4369\n",
      "[40]\tvalid_0's tweedie: 86.4353\n",
      "[41]\tvalid_0's tweedie: 86.4345\n",
      "[42]\tvalid_0's tweedie: 86.4307\n",
      "[43]\tvalid_0's tweedie: 86.4275\n",
      "[44]\tvalid_0's tweedie: 86.4252\n",
      "[45]\tvalid_0's tweedie: 86.4245\n",
      "[46]\tvalid_0's tweedie: 86.4236\n",
      "[47]\tvalid_0's tweedie: 86.4233\n",
      "[48]\tvalid_0's tweedie: 86.4234\n",
      "[49]\tvalid_0's tweedie: 86.4232\n",
      "[50]\tvalid_0's tweedie: 86.4231\n",
      "[51]\tvalid_0's tweedie: 86.4222\n",
      "[52]\tvalid_0's tweedie: 86.4199\n",
      "[53]\tvalid_0's tweedie: 86.4202\n",
      "[54]\tvalid_0's tweedie: 86.4196\n",
      "[55]\tvalid_0's tweedie: 86.4194\n",
      "[56]\tvalid_0's tweedie: 86.4196\n",
      "[57]\tvalid_0's tweedie: 86.4191\n",
      "[58]\tvalid_0's tweedie: 86.4193\n",
      "[59]\tvalid_0's tweedie: 86.419\n",
      "[60]\tvalid_0's tweedie: 86.4187\n",
      "[61]\tvalid_0's tweedie: 86.4187\n",
      "[62]\tvalid_0's tweedie: 86.4185\n",
      "[63]\tvalid_0's tweedie: 86.4185\n",
      "[64]\tvalid_0's tweedie: 86.4165\n",
      "[65]\tvalid_0's tweedie: 86.4153\n",
      "[66]\tvalid_0's tweedie: 86.415\n",
      "[67]\tvalid_0's tweedie: 86.4151\n",
      "[68]\tvalid_0's tweedie: 86.4147\n",
      "[69]\tvalid_0's tweedie: 86.4146\n",
      "[70]\tvalid_0's tweedie: 86.4143\n",
      "[71]\tvalid_0's tweedie: 86.4143\n",
      "[72]\tvalid_0's tweedie: 86.4142\n",
      "[73]\tvalid_0's tweedie: 86.4132\n",
      "[74]\tvalid_0's tweedie: 86.4132\n",
      "[75]\tvalid_0's tweedie: 86.413\n",
      "[76]\tvalid_0's tweedie: 86.4128\n",
      "[77]\tvalid_0's tweedie: 86.4126\n",
      "[78]\tvalid_0's tweedie: 86.4124\n",
      "[79]\tvalid_0's tweedie: 86.4125\n",
      "[80]\tvalid_0's tweedie: 86.4125\n",
      "[81]\tvalid_0's tweedie: 86.412\n",
      "[82]\tvalid_0's tweedie: 86.4119\n",
      "[83]\tvalid_0's tweedie: 86.4117\n",
      "[84]\tvalid_0's tweedie: 86.4112\n",
      "[85]\tvalid_0's tweedie: 86.411\n",
      "[86]\tvalid_0's tweedie: 86.411\n",
      "[87]\tvalid_0's tweedie: 86.4109\n",
      "[88]\tvalid_0's tweedie: 86.4105\n",
      "[89]\tvalid_0's tweedie: 86.4101\n",
      "[90]\tvalid_0's tweedie: 86.41\n",
      "[91]\tvalid_0's tweedie: 86.4097\n",
      "[92]\tvalid_0's tweedie: 86.4095\n",
      "[93]\tvalid_0's tweedie: 86.4096\n",
      "[94]\tvalid_0's tweedie: 86.4089\n",
      "[95]\tvalid_0's tweedie: 86.4088\n",
      "[96]\tvalid_0's tweedie: 86.4086\n",
      "[97]\tvalid_0's tweedie: 86.4084\n",
      "[98]\tvalid_0's tweedie: 86.4083\n",
      "[99]\tvalid_0's tweedie: 86.4085\n",
      "[100]\tvalid_0's tweedie: 86.4084\n",
      "[101]\tvalid_0's tweedie: 86.4084\n",
      "[102]\tvalid_0's tweedie: 86.4082\n",
      "[103]\tvalid_0's tweedie: 86.4079\n",
      "[104]\tvalid_0's tweedie: 86.4079\n",
      "[105]\tvalid_0's tweedie: 86.408\n",
      "[106]\tvalid_0's tweedie: 86.408\n",
      "[107]\tvalid_0's tweedie: 86.4075\n",
      "[108]\tvalid_0's tweedie: 86.4076\n",
      "[109]\tvalid_0's tweedie: 86.4061\n",
      "[110]\tvalid_0's tweedie: 86.4059\n",
      "[111]\tvalid_0's tweedie: 86.4059\n",
      "[112]\tvalid_0's tweedie: 86.4058\n",
      "[113]\tvalid_0's tweedie: 86.4058\n",
      "[114]\tvalid_0's tweedie: 86.4057\n",
      "[115]\tvalid_0's tweedie: 86.4056\n",
      "[116]\tvalid_0's tweedie: 86.4057\n",
      "[117]\tvalid_0's tweedie: 86.4055\n",
      "[118]\tvalid_0's tweedie: 86.4052\n",
      "[119]\tvalid_0's tweedie: 86.4052\n",
      "[120]\tvalid_0's tweedie: 86.4039\n",
      "[121]\tvalid_0's tweedie: 86.404\n",
      "[122]\tvalid_0's tweedie: 86.4039\n",
      "[123]\tvalid_0's tweedie: 86.4037\n",
      "[124]\tvalid_0's tweedie: 86.4037\n",
      "[125]\tvalid_0's tweedie: 86.4032\n",
      "[126]\tvalid_0's tweedie: 86.4032\n",
      "[127]\tvalid_0's tweedie: 86.4031\n",
      "[128]\tvalid_0's tweedie: 86.4031\n",
      "[129]\tvalid_0's tweedie: 86.4031\n",
      "[130]\tvalid_0's tweedie: 86.403\n",
      "[131]\tvalid_0's tweedie: 86.4028\n",
      "[132]\tvalid_0's tweedie: 86.4027\n",
      "[133]\tvalid_0's tweedie: 86.4028\n",
      "[134]\tvalid_0's tweedie: 86.4029\n",
      "[135]\tvalid_0's tweedie: 86.403\n",
      "[136]\tvalid_0's tweedie: 86.4029\n",
      "[137]\tvalid_0's tweedie: 86.4028\n",
      "[138]\tvalid_0's tweedie: 86.4029\n",
      "[139]\tvalid_0's tweedie: 86.4029\n",
      "[140]\tvalid_0's tweedie: 86.4025\n",
      "[141]\tvalid_0's tweedie: 86.4023\n",
      "[142]\tvalid_0's tweedie: 86.4023\n",
      "[143]\tvalid_0's tweedie: 86.4023\n",
      "[144]\tvalid_0's tweedie: 86.4023\n",
      "[145]\tvalid_0's tweedie: 86.4023\n",
      "[146]\tvalid_0's tweedie: 86.4019\n",
      "[147]\tvalid_0's tweedie: 86.4019\n",
      "[148]\tvalid_0's tweedie: 86.4017\n",
      "[149]\tvalid_0's tweedie: 86.4016\n",
      "[150]\tvalid_0's tweedie: 86.4015\n",
      "[151]\tvalid_0's tweedie: 86.4017\n",
      "[152]\tvalid_0's tweedie: 86.4016\n",
      "[153]\tvalid_0's tweedie: 86.4016\n",
      "[154]\tvalid_0's tweedie: 86.4014\n",
      "[155]\tvalid_0's tweedie: 86.4013\n",
      "[156]\tvalid_0's tweedie: 86.4014\n",
      "[157]\tvalid_0's tweedie: 86.4013\n",
      "[158]\tvalid_0's tweedie: 86.4013\n",
      "[159]\tvalid_0's tweedie: 86.4013\n",
      "[160]\tvalid_0's tweedie: 86.4011\n",
      "[161]\tvalid_0's tweedie: 86.4012\n",
      "[162]\tvalid_0's tweedie: 86.401\n",
      "[163]\tvalid_0's tweedie: 86.401\n",
      "[164]\tvalid_0's tweedie: 86.401\n",
      "[165]\tvalid_0's tweedie: 86.4008\n",
      "[166]\tvalid_0's tweedie: 86.4008\n",
      "[167]\tvalid_0's tweedie: 86.4008\n",
      "[168]\tvalid_0's tweedie: 86.4007\n",
      "[169]\tvalid_0's tweedie: 86.4007\n",
      "[170]\tvalid_0's tweedie: 86.401\n",
      "[171]\tvalid_0's tweedie: 86.4009\n",
      "[172]\tvalid_0's tweedie: 86.4009\n",
      "[173]\tvalid_0's tweedie: 86.4008\n",
      "[174]\tvalid_0's tweedie: 86.4005\n",
      "[175]\tvalid_0's tweedie: 86.4005\n",
      "[176]\tvalid_0's tweedie: 86.4005\n",
      "[177]\tvalid_0's tweedie: 86.4005\n",
      "[178]\tvalid_0's tweedie: 86.4004\n",
      "[179]\tvalid_0's tweedie: 86.4004\n",
      "[180]\tvalid_0's tweedie: 86.4001\n",
      "[181]\tvalid_0's tweedie: 86.4\n",
      "[182]\tvalid_0's tweedie: 86.3997\n",
      "[183]\tvalid_0's tweedie: 86.3996\n",
      "[184]\tvalid_0's tweedie: 86.3997\n",
      "[185]\tvalid_0's tweedie: 86.3998\n",
      "[186]\tvalid_0's tweedie: 86.3998\n",
      "[187]\tvalid_0's tweedie: 86.3999\n",
      "[188]\tvalid_0's tweedie: 86.3998\n",
      "[189]\tvalid_0's tweedie: 86.3993\n",
      "[190]\tvalid_0's tweedie: 86.3991\n",
      "[191]\tvalid_0's tweedie: 86.3991\n",
      "[192]\tvalid_0's tweedie: 86.399\n",
      "[193]\tvalid_0's tweedie: 86.3988\n",
      "[194]\tvalid_0's tweedie: 86.3986\n",
      "[195]\tvalid_0's tweedie: 86.3987\n",
      "[196]\tvalid_0's tweedie: 86.3987\n",
      "[197]\tvalid_0's tweedie: 86.3987\n",
      "[198]\tvalid_0's tweedie: 86.3987\n",
      "[199]\tvalid_0's tweedie: 86.3987\n",
      "[200]\tvalid_0's tweedie: 86.3986\n",
      "[201]\tvalid_0's tweedie: 86.3986\n",
      "[202]\tvalid_0's tweedie: 86.3986\n",
      "[203]\tvalid_0's tweedie: 86.3986\n",
      "[204]\tvalid_0's tweedie: 86.3985\n",
      "[205]\tvalid_0's tweedie: 86.3984\n",
      "[206]\tvalid_0's tweedie: 86.3983\n",
      "[207]\tvalid_0's tweedie: 86.3984\n",
      "[208]\tvalid_0's tweedie: 86.3985\n",
      "[209]\tvalid_0's tweedie: 86.3983\n",
      "[210]\tvalid_0's tweedie: 86.3985\n",
      "[211]\tvalid_0's tweedie: 86.3985\n",
      "[212]\tvalid_0's tweedie: 86.3985\n",
      "[213]\tvalid_0's tweedie: 86.3985\n",
      "[214]\tvalid_0's tweedie: 86.3985\n",
      "[215]\tvalid_0's tweedie: 86.3983\n",
      "[216]\tvalid_0's tweedie: 86.3974\n",
      "[217]\tvalid_0's tweedie: 86.3974\n",
      "[218]\tvalid_0's tweedie: 86.3973\n",
      "[219]\tvalid_0's tweedie: 86.3973\n",
      "[220]\tvalid_0's tweedie: 86.3972\n",
      "[221]\tvalid_0's tweedie: 86.3972\n",
      "[222]\tvalid_0's tweedie: 86.3972\n",
      "[223]\tvalid_0's tweedie: 86.3972\n",
      "[224]\tvalid_0's tweedie: 86.3971\n",
      "[225]\tvalid_0's tweedie: 86.3972\n",
      "[226]\tvalid_0's tweedie: 86.3973\n",
      "[227]\tvalid_0's tweedie: 86.3972\n",
      "[228]\tvalid_0's tweedie: 86.3972\n",
      "[229]\tvalid_0's tweedie: 86.3973\n",
      "[230]\tvalid_0's tweedie: 86.3973\n",
      "[231]\tvalid_0's tweedie: 86.3972\n",
      "[232]\tvalid_0's tweedie: 86.3971\n",
      "[233]\tvalid_0's tweedie: 86.3971\n",
      "[234]\tvalid_0's tweedie: 86.3971\n",
      "[235]\tvalid_0's tweedie: 86.3966\n",
      "[236]\tvalid_0's tweedie: 86.3966\n",
      "[237]\tvalid_0's tweedie: 86.3965\n",
      "[238]\tvalid_0's tweedie: 86.3964\n",
      "[239]\tvalid_0's tweedie: 86.3962\n",
      "[240]\tvalid_0's tweedie: 86.3962\n",
      "[241]\tvalid_0's tweedie: 86.3962\n",
      "[242]\tvalid_0's tweedie: 86.3963\n",
      "[243]\tvalid_0's tweedie: 86.3961\n",
      "[244]\tvalid_0's tweedie: 86.3961\n",
      "[245]\tvalid_0's tweedie: 86.3961\n",
      "[246]\tvalid_0's tweedie: 86.3967\n",
      "[247]\tvalid_0's tweedie: 86.3968\n",
      "[248]\tvalid_0's tweedie: 86.3967\n",
      "[249]\tvalid_0's tweedie: 86.3967\n",
      "[250]\tvalid_0's tweedie: 86.3967\n",
      "[251]\tvalid_0's tweedie: 86.3966\n",
      "[252]\tvalid_0's tweedie: 86.3966\n",
      "[253]\tvalid_0's tweedie: 86.3967\n",
      "[254]\tvalid_0's tweedie: 86.3966\n",
      "[255]\tvalid_0's tweedie: 86.3965\n",
      "[256]\tvalid_0's tweedie: 86.3965\n",
      "[257]\tvalid_0's tweedie: 86.3965\n",
      "[258]\tvalid_0's tweedie: 86.3965\n",
      "[259]\tvalid_0's tweedie: 86.3964\n",
      "[260]\tvalid_0's tweedie: 86.3964\n",
      "[261]\tvalid_0's tweedie: 86.3964\n",
      "[262]\tvalid_0's tweedie: 86.3964\n",
      "[263]\tvalid_0's tweedie: 86.3964\n",
      "[264]\tvalid_0's tweedie: 86.3964\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's tweedie: 86.3961\n",
      "Training model for level 9 and step 10\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/10/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5515\n",
      "[LightGBM] [Info] Number of data points in the train set: 130339, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194703\n",
      "[1]\tvalid_0's tweedie: 96.813\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1013\n",
      "[3]\tvalid_0's tweedie: 93.6553\n",
      "[4]\tvalid_0's tweedie: 92.4393\n",
      "[5]\tvalid_0's tweedie: 91.4145\n",
      "[6]\tvalid_0's tweedie: 90.551\n",
      "[7]\tvalid_0's tweedie: 89.8404\n",
      "[8]\tvalid_0's tweedie: 89.2549\n",
      "[9]\tvalid_0's tweedie: 88.7645\n",
      "[10]\tvalid_0's tweedie: 88.3513\n",
      "[11]\tvalid_0's tweedie: 88.015\n",
      "[12]\tvalid_0's tweedie: 87.7415\n",
      "[13]\tvalid_0's tweedie: 87.5127\n",
      "[14]\tvalid_0's tweedie: 87.3222\n",
      "[15]\tvalid_0's tweedie: 87.1642\n",
      "[16]\tvalid_0's tweedie: 87.0369\n",
      "[17]\tvalid_0's tweedie: 86.9343\n",
      "[18]\tvalid_0's tweedie: 86.8486\n",
      "[19]\tvalid_0's tweedie: 86.7737\n",
      "[20]\tvalid_0's tweedie: 86.7145\n",
      "[21]\tvalid_0's tweedie: 86.6674\n",
      "[22]\tvalid_0's tweedie: 86.6272\n",
      "[23]\tvalid_0's tweedie: 86.5941\n",
      "[24]\tvalid_0's tweedie: 86.5699\n",
      "[25]\tvalid_0's tweedie: 86.5493\n",
      "[26]\tvalid_0's tweedie: 86.5322\n",
      "[27]\tvalid_0's tweedie: 86.5185\n",
      "[28]\tvalid_0's tweedie: 86.5075\n",
      "[29]\tvalid_0's tweedie: 86.4946\n",
      "[30]\tvalid_0's tweedie: 86.4886\n",
      "[31]\tvalid_0's tweedie: 86.4819\n",
      "[32]\tvalid_0's tweedie: 86.4741\n",
      "[33]\tvalid_0's tweedie: 86.4697\n",
      "[34]\tvalid_0's tweedie: 86.4624\n",
      "[35]\tvalid_0's tweedie: 86.4567\n",
      "[36]\tvalid_0's tweedie: 86.454\n",
      "[37]\tvalid_0's tweedie: 86.4515\n",
      "[38]\tvalid_0's tweedie: 86.4486\n",
      "[39]\tvalid_0's tweedie: 86.4469\n",
      "[40]\tvalid_0's tweedie: 86.4458\n",
      "[41]\tvalid_0's tweedie: 86.4436\n",
      "[42]\tvalid_0's tweedie: 86.4413\n",
      "[43]\tvalid_0's tweedie: 86.4396\n",
      "[44]\tvalid_0's tweedie: 86.4397\n",
      "[45]\tvalid_0's tweedie: 86.4391\n",
      "[46]\tvalid_0's tweedie: 86.4381\n",
      "[47]\tvalid_0's tweedie: 86.4379\n",
      "[48]\tvalid_0's tweedie: 86.4368\n",
      "[49]\tvalid_0's tweedie: 86.4348\n",
      "[50]\tvalid_0's tweedie: 86.4328\n",
      "[51]\tvalid_0's tweedie: 86.4321\n",
      "[52]\tvalid_0's tweedie: 86.4321\n",
      "[53]\tvalid_0's tweedie: 86.4312\n",
      "[54]\tvalid_0's tweedie: 86.4312\n",
      "[55]\tvalid_0's tweedie: 86.4313\n",
      "[56]\tvalid_0's tweedie: 86.4311\n",
      "[57]\tvalid_0's tweedie: 86.4303\n",
      "[58]\tvalid_0's tweedie: 86.4298\n",
      "[59]\tvalid_0's tweedie: 86.43\n",
      "[60]\tvalid_0's tweedie: 86.4295\n",
      "[61]\tvalid_0's tweedie: 86.4291\n",
      "[62]\tvalid_0's tweedie: 86.4284\n",
      "[63]\tvalid_0's tweedie: 86.4284\n",
      "[64]\tvalid_0's tweedie: 86.4288\n",
      "[65]\tvalid_0's tweedie: 86.4288\n",
      "[66]\tvalid_0's tweedie: 86.429\n",
      "[67]\tvalid_0's tweedie: 86.4289\n",
      "[68]\tvalid_0's tweedie: 86.4288\n",
      "[69]\tvalid_0's tweedie: 86.4289\n",
      "[70]\tvalid_0's tweedie: 86.4291\n",
      "[71]\tvalid_0's tweedie: 86.4289\n",
      "[72]\tvalid_0's tweedie: 86.4289\n",
      "[73]\tvalid_0's tweedie: 86.4287\n",
      "[74]\tvalid_0's tweedie: 86.4289\n",
      "[75]\tvalid_0's tweedie: 86.4291\n",
      "[76]\tvalid_0's tweedie: 86.4289\n",
      "[77]\tvalid_0's tweedie: 86.4288\n",
      "[78]\tvalid_0's tweedie: 86.4282\n",
      "[79]\tvalid_0's tweedie: 86.4279\n",
      "[80]\tvalid_0's tweedie: 86.4278\n",
      "[81]\tvalid_0's tweedie: 86.4275\n",
      "[82]\tvalid_0's tweedie: 86.4273\n",
      "[83]\tvalid_0's tweedie: 86.4277\n",
      "[84]\tvalid_0's tweedie: 86.4277\n",
      "[85]\tvalid_0's tweedie: 86.4273\n",
      "[86]\tvalid_0's tweedie: 86.4274\n",
      "[87]\tvalid_0's tweedie: 86.4272\n",
      "[88]\tvalid_0's tweedie: 86.4269\n",
      "[89]\tvalid_0's tweedie: 86.4265\n",
      "[90]\tvalid_0's tweedie: 86.4267\n",
      "[91]\tvalid_0's tweedie: 86.4266\n",
      "[92]\tvalid_0's tweedie: 86.4254\n",
      "[93]\tvalid_0's tweedie: 86.4253\n",
      "[94]\tvalid_0's tweedie: 86.425\n",
      "[95]\tvalid_0's tweedie: 86.4248\n",
      "[96]\tvalid_0's tweedie: 86.4249\n",
      "[97]\tvalid_0's tweedie: 86.4246\n",
      "[98]\tvalid_0's tweedie: 86.4246\n",
      "[99]\tvalid_0's tweedie: 86.4246\n",
      "[100]\tvalid_0's tweedie: 86.4245\n",
      "[101]\tvalid_0's tweedie: 86.4223\n",
      "[102]\tvalid_0's tweedie: 86.4225\n",
      "[103]\tvalid_0's tweedie: 86.4223\n",
      "[104]\tvalid_0's tweedie: 86.4221\n",
      "[105]\tvalid_0's tweedie: 86.4221\n",
      "[106]\tvalid_0's tweedie: 86.4197\n",
      "[107]\tvalid_0's tweedie: 86.4196\n",
      "[108]\tvalid_0's tweedie: 86.4197\n",
      "[109]\tvalid_0's tweedie: 86.4198\n",
      "[110]\tvalid_0's tweedie: 86.4199\n",
      "[111]\tvalid_0's tweedie: 86.4199\n",
      "[112]\tvalid_0's tweedie: 86.4199\n",
      "[113]\tvalid_0's tweedie: 86.42\n",
      "[114]\tvalid_0's tweedie: 86.4199\n",
      "[115]\tvalid_0's tweedie: 86.4199\n",
      "[116]\tvalid_0's tweedie: 86.42\n",
      "[117]\tvalid_0's tweedie: 86.4201\n",
      "[118]\tvalid_0's tweedie: 86.4204\n",
      "[119]\tvalid_0's tweedie: 86.4203\n",
      "[120]\tvalid_0's tweedie: 86.4205\n",
      "[121]\tvalid_0's tweedie: 86.42\n",
      "[122]\tvalid_0's tweedie: 86.42\n",
      "[123]\tvalid_0's tweedie: 86.4199\n",
      "[124]\tvalid_0's tweedie: 86.4198\n",
      "[125]\tvalid_0's tweedie: 86.418\n",
      "[126]\tvalid_0's tweedie: 86.4181\n",
      "[127]\tvalid_0's tweedie: 86.4179\n",
      "[128]\tvalid_0's tweedie: 86.4177\n",
      "[129]\tvalid_0's tweedie: 86.4174\n",
      "[130]\tvalid_0's tweedie: 86.4174\n",
      "[131]\tvalid_0's tweedie: 86.4167\n",
      "[132]\tvalid_0's tweedie: 86.4166\n",
      "[133]\tvalid_0's tweedie: 86.4164\n",
      "[134]\tvalid_0's tweedie: 86.4165\n",
      "[135]\tvalid_0's tweedie: 86.4161\n",
      "[136]\tvalid_0's tweedie: 86.4146\n",
      "[137]\tvalid_0's tweedie: 86.4145\n",
      "[138]\tvalid_0's tweedie: 86.4145\n",
      "[139]\tvalid_0's tweedie: 86.4145\n",
      "[140]\tvalid_0's tweedie: 86.4146\n",
      "[141]\tvalid_0's tweedie: 86.4146\n",
      "[142]\tvalid_0's tweedie: 86.4147\n",
      "[143]\tvalid_0's tweedie: 86.4143\n",
      "[144]\tvalid_0's tweedie: 86.4142\n",
      "[145]\tvalid_0's tweedie: 86.4142\n",
      "[146]\tvalid_0's tweedie: 86.4142\n",
      "[147]\tvalid_0's tweedie: 86.4142\n",
      "[148]\tvalid_0's tweedie: 86.4142\n",
      "[149]\tvalid_0's tweedie: 86.4143\n",
      "[150]\tvalid_0's tweedie: 86.4143\n",
      "[151]\tvalid_0's tweedie: 86.4145\n",
      "[152]\tvalid_0's tweedie: 86.4144\n",
      "[153]\tvalid_0's tweedie: 86.4125\n",
      "[154]\tvalid_0's tweedie: 86.4125\n",
      "[155]\tvalid_0's tweedie: 86.4124\n",
      "[156]\tvalid_0's tweedie: 86.4124\n",
      "[157]\tvalid_0's tweedie: 86.4124\n",
      "[158]\tvalid_0's tweedie: 86.4125\n",
      "[159]\tvalid_0's tweedie: 86.4123\n",
      "[160]\tvalid_0's tweedie: 86.412\n",
      "[161]\tvalid_0's tweedie: 86.412\n",
      "[162]\tvalid_0's tweedie: 86.412\n",
      "[163]\tvalid_0's tweedie: 86.4119\n",
      "[164]\tvalid_0's tweedie: 86.4119\n",
      "[165]\tvalid_0's tweedie: 86.4117\n",
      "[166]\tvalid_0's tweedie: 86.4117\n",
      "[167]\tvalid_0's tweedie: 86.4115\n",
      "[168]\tvalid_0's tweedie: 86.4115\n",
      "[169]\tvalid_0's tweedie: 86.4109\n",
      "[170]\tvalid_0's tweedie: 86.4105\n",
      "[171]\tvalid_0's tweedie: 86.4105\n",
      "[172]\tvalid_0's tweedie: 86.4103\n",
      "[173]\tvalid_0's tweedie: 86.4095\n",
      "[174]\tvalid_0's tweedie: 86.4094\n",
      "[175]\tvalid_0's tweedie: 86.4093\n",
      "[176]\tvalid_0's tweedie: 86.4093\n",
      "[177]\tvalid_0's tweedie: 86.4093\n",
      "[178]\tvalid_0's tweedie: 86.4094\n",
      "[179]\tvalid_0's tweedie: 86.4093\n",
      "[180]\tvalid_0's tweedie: 86.4092\n",
      "[181]\tvalid_0's tweedie: 86.4092\n",
      "[182]\tvalid_0's tweedie: 86.4092\n",
      "[183]\tvalid_0's tweedie: 86.409\n",
      "[184]\tvalid_0's tweedie: 86.4089\n",
      "[185]\tvalid_0's tweedie: 86.4089\n",
      "[186]\tvalid_0's tweedie: 86.4084\n",
      "[187]\tvalid_0's tweedie: 86.4085\n",
      "[188]\tvalid_0's tweedie: 86.4082\n",
      "[189]\tvalid_0's tweedie: 86.4084\n",
      "[190]\tvalid_0's tweedie: 86.4086\n",
      "[191]\tvalid_0's tweedie: 86.4086\n",
      "[192]\tvalid_0's tweedie: 86.4088\n",
      "[193]\tvalid_0's tweedie: 86.4088\n",
      "[194]\tvalid_0's tweedie: 86.4086\n",
      "[195]\tvalid_0's tweedie: 86.4084\n",
      "[196]\tvalid_0's tweedie: 86.4084\n",
      "[197]\tvalid_0's tweedie: 86.4083\n",
      "[198]\tvalid_0's tweedie: 86.4081\n",
      "[199]\tvalid_0's tweedie: 86.408\n",
      "[200]\tvalid_0's tweedie: 86.4077\n",
      "[201]\tvalid_0's tweedie: 86.4077\n",
      "[202]\tvalid_0's tweedie: 86.4076\n",
      "[203]\tvalid_0's tweedie: 86.4075\n",
      "[204]\tvalid_0's tweedie: 86.4076\n",
      "[205]\tvalid_0's tweedie: 86.4076\n",
      "[206]\tvalid_0's tweedie: 86.4076\n",
      "[207]\tvalid_0's tweedie: 86.4074\n",
      "[208]\tvalid_0's tweedie: 86.4073\n",
      "[209]\tvalid_0's tweedie: 86.4075\n",
      "[210]\tvalid_0's tweedie: 86.4074\n",
      "[211]\tvalid_0's tweedie: 86.4073\n",
      "[212]\tvalid_0's tweedie: 86.4072\n",
      "[213]\tvalid_0's tweedie: 86.4072\n",
      "[214]\tvalid_0's tweedie: 86.4071\n",
      "[215]\tvalid_0's tweedie: 86.4071\n",
      "[216]\tvalid_0's tweedie: 86.4071\n",
      "[217]\tvalid_0's tweedie: 86.407\n",
      "[218]\tvalid_0's tweedie: 86.407\n",
      "[219]\tvalid_0's tweedie: 86.4071\n",
      "[220]\tvalid_0's tweedie: 86.407\n",
      "[221]\tvalid_0's tweedie: 86.4071\n",
      "[222]\tvalid_0's tweedie: 86.4072\n",
      "[223]\tvalid_0's tweedie: 86.4071\n",
      "[224]\tvalid_0's tweedie: 86.4071\n",
      "[225]\tvalid_0's tweedie: 86.407\n",
      "[226]\tvalid_0's tweedie: 86.407\n",
      "[227]\tvalid_0's tweedie: 86.4069\n",
      "[228]\tvalid_0's tweedie: 86.4069\n",
      "[229]\tvalid_0's tweedie: 86.4068\n",
      "[230]\tvalid_0's tweedie: 86.4069\n",
      "[231]\tvalid_0's tweedie: 86.4067\n",
      "[232]\tvalid_0's tweedie: 86.4066\n",
      "[233]\tvalid_0's tweedie: 86.4066\n",
      "[234]\tvalid_0's tweedie: 86.4067\n",
      "[235]\tvalid_0's tweedie: 86.4065\n",
      "[236]\tvalid_0's tweedie: 86.4065\n",
      "[237]\tvalid_0's tweedie: 86.4066\n",
      "[238]\tvalid_0's tweedie: 86.4068\n",
      "[239]\tvalid_0's tweedie: 86.407\n",
      "[240]\tvalid_0's tweedie: 86.407\n",
      "[241]\tvalid_0's tweedie: 86.407\n",
      "[242]\tvalid_0's tweedie: 86.407\n",
      "[243]\tvalid_0's tweedie: 86.407\n",
      "[244]\tvalid_0's tweedie: 86.4069\n",
      "[245]\tvalid_0's tweedie: 86.4069\n",
      "[246]\tvalid_0's tweedie: 86.4068\n",
      "[247]\tvalid_0's tweedie: 86.4069\n",
      "[248]\tvalid_0's tweedie: 86.4069\n",
      "[249]\tvalid_0's tweedie: 86.4068\n",
      "[250]\tvalid_0's tweedie: 86.4068\n",
      "[251]\tvalid_0's tweedie: 86.4069\n",
      "[252]\tvalid_0's tweedie: 86.4068\n",
      "[253]\tvalid_0's tweedie: 86.4066\n",
      "[254]\tvalid_0's tweedie: 86.4066\n",
      "[255]\tvalid_0's tweedie: 86.4066\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's tweedie: 86.4065\n",
      "Training model for level 9 and step 11\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/11/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5514\n",
      "[LightGBM] [Info] Number of data points in the train set: 130269, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.194865\n",
      "[1]\tvalid_0's tweedie: 96.8123\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1031\n",
      "[3]\tvalid_0's tweedie: 93.6579\n",
      "[4]\tvalid_0's tweedie: 92.4418\n",
      "[5]\tvalid_0's tweedie: 91.4216\n",
      "[6]\tvalid_0's tweedie: 90.5574\n",
      "[7]\tvalid_0's tweedie: 89.8429\n",
      "[8]\tvalid_0's tweedie: 89.2525\n",
      "[9]\tvalid_0's tweedie: 88.7595\n",
      "[10]\tvalid_0's tweedie: 88.3475\n",
      "[11]\tvalid_0's tweedie: 88.01\n",
      "[12]\tvalid_0's tweedie: 87.7323\n",
      "[13]\tvalid_0's tweedie: 87.5029\n",
      "[14]\tvalid_0's tweedie: 87.3106\n",
      "[15]\tvalid_0's tweedie: 87.1572\n",
      "[16]\tvalid_0's tweedie: 87.0308\n",
      "[17]\tvalid_0's tweedie: 86.9234\n",
      "[18]\tvalid_0's tweedie: 86.8392\n",
      "[19]\tvalid_0's tweedie: 86.7679\n",
      "[20]\tvalid_0's tweedie: 86.7102\n",
      "[21]\tvalid_0's tweedie: 86.6623\n",
      "[22]\tvalid_0's tweedie: 86.6232\n",
      "[23]\tvalid_0's tweedie: 86.5912\n",
      "[24]\tvalid_0's tweedie: 86.5643\n",
      "[25]\tvalid_0's tweedie: 86.5433\n",
      "[26]\tvalid_0's tweedie: 86.5255\n",
      "[27]\tvalid_0's tweedie: 86.5109\n",
      "[28]\tvalid_0's tweedie: 86.5004\n",
      "[29]\tvalid_0's tweedie: 86.4903\n",
      "[30]\tvalid_0's tweedie: 86.4789\n",
      "[31]\tvalid_0's tweedie: 86.4721\n",
      "[32]\tvalid_0's tweedie: 86.4671\n",
      "[33]\tvalid_0's tweedie: 86.4623\n",
      "[34]\tvalid_0's tweedie: 86.4596\n",
      "[35]\tvalid_0's tweedie: 86.4559\n",
      "[36]\tvalid_0's tweedie: 86.4527\n",
      "[37]\tvalid_0's tweedie: 86.4488\n",
      "[38]\tvalid_0's tweedie: 86.4462\n",
      "[39]\tvalid_0's tweedie: 86.4439\n",
      "[40]\tvalid_0's tweedie: 86.4424\n",
      "[41]\tvalid_0's tweedie: 86.4414\n",
      "[42]\tvalid_0's tweedie: 86.4404\n",
      "[43]\tvalid_0's tweedie: 86.4385\n",
      "[44]\tvalid_0's tweedie: 86.4363\n",
      "[45]\tvalid_0's tweedie: 86.4356\n",
      "[46]\tvalid_0's tweedie: 86.4356\n",
      "[47]\tvalid_0's tweedie: 86.4349\n",
      "[48]\tvalid_0's tweedie: 86.4344\n",
      "[49]\tvalid_0's tweedie: 86.4345\n",
      "[50]\tvalid_0's tweedie: 86.4327\n",
      "[51]\tvalid_0's tweedie: 86.4311\n",
      "[52]\tvalid_0's tweedie: 86.4316\n",
      "[53]\tvalid_0's tweedie: 86.4309\n",
      "[54]\tvalid_0's tweedie: 86.4305\n",
      "[55]\tvalid_0's tweedie: 86.4304\n",
      "[56]\tvalid_0's tweedie: 86.4307\n",
      "[57]\tvalid_0's tweedie: 86.4301\n",
      "[58]\tvalid_0's tweedie: 86.4296\n",
      "[59]\tvalid_0's tweedie: 86.4288\n",
      "[60]\tvalid_0's tweedie: 86.4285\n",
      "[61]\tvalid_0's tweedie: 86.4275\n",
      "[62]\tvalid_0's tweedie: 86.4277\n",
      "[63]\tvalid_0's tweedie: 86.4274\n",
      "[64]\tvalid_0's tweedie: 86.4265\n",
      "[65]\tvalid_0's tweedie: 86.4268\n",
      "[66]\tvalid_0's tweedie: 86.4271\n",
      "[67]\tvalid_0's tweedie: 86.4271\n",
      "[68]\tvalid_0's tweedie: 86.4269\n",
      "[69]\tvalid_0's tweedie: 86.4266\n",
      "[70]\tvalid_0's tweedie: 86.426\n",
      "[71]\tvalid_0's tweedie: 86.4247\n",
      "[72]\tvalid_0's tweedie: 86.4247\n",
      "[73]\tvalid_0's tweedie: 86.4242\n",
      "[74]\tvalid_0's tweedie: 86.4241\n",
      "[75]\tvalid_0's tweedie: 86.424\n",
      "[76]\tvalid_0's tweedie: 86.4237\n",
      "[77]\tvalid_0's tweedie: 86.4235\n",
      "[78]\tvalid_0's tweedie: 86.4229\n",
      "[79]\tvalid_0's tweedie: 86.4225\n",
      "[80]\tvalid_0's tweedie: 86.4226\n",
      "[81]\tvalid_0's tweedie: 86.4226\n",
      "[82]\tvalid_0's tweedie: 86.4224\n",
      "[83]\tvalid_0's tweedie: 86.4222\n",
      "[84]\tvalid_0's tweedie: 86.4214\n",
      "[85]\tvalid_0's tweedie: 86.4216\n",
      "[86]\tvalid_0's tweedie: 86.4213\n",
      "[87]\tvalid_0's tweedie: 86.4211\n",
      "[88]\tvalid_0's tweedie: 86.4211\n",
      "[89]\tvalid_0's tweedie: 86.421\n",
      "[90]\tvalid_0's tweedie: 86.4212\n",
      "[91]\tvalid_0's tweedie: 86.421\n",
      "[92]\tvalid_0's tweedie: 86.421\n",
      "[93]\tvalid_0's tweedie: 86.4206\n",
      "[94]\tvalid_0's tweedie: 86.4203\n",
      "[95]\tvalid_0's tweedie: 86.4204\n",
      "[96]\tvalid_0's tweedie: 86.4198\n",
      "[97]\tvalid_0's tweedie: 86.4195\n",
      "[98]\tvalid_0's tweedie: 86.4195\n",
      "[99]\tvalid_0's tweedie: 86.4175\n",
      "[100]\tvalid_0's tweedie: 86.4167\n",
      "[101]\tvalid_0's tweedie: 86.4166\n",
      "[102]\tvalid_0's tweedie: 86.4165\n",
      "[103]\tvalid_0's tweedie: 86.4165\n",
      "[104]\tvalid_0's tweedie: 86.4163\n",
      "[105]\tvalid_0's tweedie: 86.4166\n",
      "[106]\tvalid_0's tweedie: 86.4163\n",
      "[107]\tvalid_0's tweedie: 86.4161\n",
      "[108]\tvalid_0's tweedie: 86.4161\n",
      "[109]\tvalid_0's tweedie: 86.4161\n",
      "[110]\tvalid_0's tweedie: 86.4161\n",
      "[111]\tvalid_0's tweedie: 86.416\n",
      "[112]\tvalid_0's tweedie: 86.4156\n",
      "[113]\tvalid_0's tweedie: 86.4158\n",
      "[114]\tvalid_0's tweedie: 86.4153\n",
      "[115]\tvalid_0's tweedie: 86.4153\n",
      "[116]\tvalid_0's tweedie: 86.415\n",
      "[117]\tvalid_0's tweedie: 86.4148\n",
      "[118]\tvalid_0's tweedie: 86.4148\n",
      "[119]\tvalid_0's tweedie: 86.4148\n",
      "[120]\tvalid_0's tweedie: 86.4144\n",
      "[121]\tvalid_0's tweedie: 86.4142\n",
      "[122]\tvalid_0's tweedie: 86.4142\n",
      "[123]\tvalid_0's tweedie: 86.4142\n",
      "[124]\tvalid_0's tweedie: 86.4142\n",
      "[125]\tvalid_0's tweedie: 86.414\n",
      "[126]\tvalid_0's tweedie: 86.414\n",
      "[127]\tvalid_0's tweedie: 86.4138\n",
      "[128]\tvalid_0's tweedie: 86.4138\n",
      "[129]\tvalid_0's tweedie: 86.4133\n",
      "[130]\tvalid_0's tweedie: 86.4132\n",
      "[131]\tvalid_0's tweedie: 86.4131\n",
      "[132]\tvalid_0's tweedie: 86.413\n",
      "[133]\tvalid_0's tweedie: 86.4132\n",
      "[134]\tvalid_0's tweedie: 86.4134\n",
      "[135]\tvalid_0's tweedie: 86.4133\n",
      "[136]\tvalid_0's tweedie: 86.4133\n",
      "[137]\tvalid_0's tweedie: 86.4123\n",
      "[138]\tvalid_0's tweedie: 86.4122\n",
      "[139]\tvalid_0's tweedie: 86.4122\n",
      "[140]\tvalid_0's tweedie: 86.4121\n",
      "[141]\tvalid_0's tweedie: 86.412\n",
      "[142]\tvalid_0's tweedie: 86.412\n",
      "[143]\tvalid_0's tweedie: 86.412\n",
      "[144]\tvalid_0's tweedie: 86.4119\n",
      "[145]\tvalid_0's tweedie: 86.4118\n",
      "[146]\tvalid_0's tweedie: 86.412\n",
      "[147]\tvalid_0's tweedie: 86.4121\n",
      "[148]\tvalid_0's tweedie: 86.4123\n",
      "[149]\tvalid_0's tweedie: 86.4121\n",
      "[150]\tvalid_0's tweedie: 86.4121\n",
      "[151]\tvalid_0's tweedie: 86.4121\n",
      "[152]\tvalid_0's tweedie: 86.4121\n",
      "[153]\tvalid_0's tweedie: 86.412\n",
      "[154]\tvalid_0's tweedie: 86.4119\n",
      "[155]\tvalid_0's tweedie: 86.4119\n",
      "[156]\tvalid_0's tweedie: 86.4119\n",
      "[157]\tvalid_0's tweedie: 86.4118\n",
      "[158]\tvalid_0's tweedie: 86.4118\n",
      "[159]\tvalid_0's tweedie: 86.4117\n",
      "[160]\tvalid_0's tweedie: 86.4117\n",
      "[161]\tvalid_0's tweedie: 86.4106\n",
      "[162]\tvalid_0's tweedie: 86.4104\n",
      "[163]\tvalid_0's tweedie: 86.4104\n",
      "[164]\tvalid_0's tweedie: 86.4103\n",
      "[165]\tvalid_0's tweedie: 86.4103\n",
      "[166]\tvalid_0's tweedie: 86.4101\n",
      "[167]\tvalid_0's tweedie: 86.4102\n",
      "[168]\tvalid_0's tweedie: 86.4104\n",
      "[169]\tvalid_0's tweedie: 86.4104\n",
      "[170]\tvalid_0's tweedie: 86.4104\n",
      "[171]\tvalid_0's tweedie: 86.4104\n",
      "[172]\tvalid_0's tweedie: 86.4104\n",
      "[173]\tvalid_0's tweedie: 86.4101\n",
      "[174]\tvalid_0's tweedie: 86.41\n",
      "[175]\tvalid_0's tweedie: 86.41\n",
      "[176]\tvalid_0's tweedie: 86.4099\n",
      "[177]\tvalid_0's tweedie: 86.4097\n",
      "[178]\tvalid_0's tweedie: 86.4098\n",
      "[179]\tvalid_0's tweedie: 86.4098\n",
      "[180]\tvalid_0's tweedie: 86.4096\n",
      "[181]\tvalid_0's tweedie: 86.4095\n",
      "[182]\tvalid_0's tweedie: 86.4084\n",
      "[183]\tvalid_0's tweedie: 86.4085\n",
      "[184]\tvalid_0's tweedie: 86.4084\n",
      "[185]\tvalid_0's tweedie: 86.4083\n",
      "[186]\tvalid_0's tweedie: 86.4083\n",
      "[187]\tvalid_0's tweedie: 86.4083\n",
      "[188]\tvalid_0's tweedie: 86.4082\n",
      "[189]\tvalid_0's tweedie: 86.408\n",
      "[190]\tvalid_0's tweedie: 86.4078\n",
      "[191]\tvalid_0's tweedie: 86.4078\n",
      "[192]\tvalid_0's tweedie: 86.4077\n",
      "[193]\tvalid_0's tweedie: 86.4078\n",
      "[194]\tvalid_0's tweedie: 86.4077\n",
      "[195]\tvalid_0's tweedie: 86.4077\n",
      "[196]\tvalid_0's tweedie: 86.4077\n",
      "[197]\tvalid_0's tweedie: 86.4078\n",
      "[198]\tvalid_0's tweedie: 86.4076\n",
      "[199]\tvalid_0's tweedie: 86.4076\n",
      "[200]\tvalid_0's tweedie: 86.4074\n",
      "[201]\tvalid_0's tweedie: 86.4074\n",
      "[202]\tvalid_0's tweedie: 86.4072\n",
      "[203]\tvalid_0's tweedie: 86.407\n",
      "[204]\tvalid_0's tweedie: 86.4071\n",
      "[205]\tvalid_0's tweedie: 86.407\n",
      "[206]\tvalid_0's tweedie: 86.407\n",
      "[207]\tvalid_0's tweedie: 86.4069\n",
      "[208]\tvalid_0's tweedie: 86.407\n",
      "[209]\tvalid_0's tweedie: 86.407\n",
      "[210]\tvalid_0's tweedie: 86.4069\n",
      "[211]\tvalid_0's tweedie: 86.4069\n",
      "[212]\tvalid_0's tweedie: 86.4068\n",
      "[213]\tvalid_0's tweedie: 86.4069\n",
      "[214]\tvalid_0's tweedie: 86.4072\n",
      "[215]\tvalid_0's tweedie: 86.4072\n",
      "[216]\tvalid_0's tweedie: 86.4074\n",
      "[217]\tvalid_0's tweedie: 86.4074\n",
      "[218]\tvalid_0's tweedie: 86.4073\n",
      "[219]\tvalid_0's tweedie: 86.4073\n",
      "[220]\tvalid_0's tweedie: 86.4072\n",
      "[221]\tvalid_0's tweedie: 86.4073\n",
      "[222]\tvalid_0's tweedie: 86.4072\n",
      "[223]\tvalid_0's tweedie: 86.4072\n",
      "[224]\tvalid_0's tweedie: 86.4072\n",
      "[225]\tvalid_0's tweedie: 86.4072\n",
      "[226]\tvalid_0's tweedie: 86.4074\n",
      "[227]\tvalid_0's tweedie: 86.4073\n",
      "[228]\tvalid_0's tweedie: 86.4073\n",
      "[229]\tvalid_0's tweedie: 86.4072\n",
      "[230]\tvalid_0's tweedie: 86.4072\n",
      "[231]\tvalid_0's tweedie: 86.4071\n",
      "[232]\tvalid_0's tweedie: 86.4068\n",
      "[233]\tvalid_0's tweedie: 86.4067\n",
      "[234]\tvalid_0's tweedie: 86.4066\n",
      "[235]\tvalid_0's tweedie: 86.4066\n",
      "[236]\tvalid_0's tweedie: 86.4066\n",
      "[237]\tvalid_0's tweedie: 86.4065\n",
      "[238]\tvalid_0's tweedie: 86.4055\n",
      "[239]\tvalid_0's tweedie: 86.4054\n",
      "[240]\tvalid_0's tweedie: 86.4054\n",
      "[241]\tvalid_0's tweedie: 86.4054\n",
      "[242]\tvalid_0's tweedie: 86.4053\n",
      "[243]\tvalid_0's tweedie: 86.4051\n",
      "[244]\tvalid_0's tweedie: 86.4051\n",
      "[245]\tvalid_0's tweedie: 86.4051\n",
      "[246]\tvalid_0's tweedie: 86.405\n",
      "[247]\tvalid_0's tweedie: 86.4048\n",
      "[248]\tvalid_0's tweedie: 86.4048\n",
      "[249]\tvalid_0's tweedie: 86.4048\n",
      "[250]\tvalid_0's tweedie: 86.4048\n",
      "[251]\tvalid_0's tweedie: 86.4049\n",
      "[252]\tvalid_0's tweedie: 86.4049\n",
      "[253]\tvalid_0's tweedie: 86.4048\n",
      "[254]\tvalid_0's tweedie: 86.4048\n",
      "[255]\tvalid_0's tweedie: 86.4048\n",
      "[256]\tvalid_0's tweedie: 86.4047\n",
      "[257]\tvalid_0's tweedie: 86.4046\n",
      "[258]\tvalid_0's tweedie: 86.4048\n",
      "[259]\tvalid_0's tweedie: 86.4044\n",
      "[260]\tvalid_0's tweedie: 86.4045\n",
      "[261]\tvalid_0's tweedie: 86.4044\n",
      "[262]\tvalid_0's tweedie: 86.4044\n",
      "[263]\tvalid_0's tweedie: 86.4044\n",
      "[264]\tvalid_0's tweedie: 86.4044\n",
      "[265]\tvalid_0's tweedie: 86.4043\n",
      "[266]\tvalid_0's tweedie: 86.4043\n",
      "[267]\tvalid_0's tweedie: 86.4043\n",
      "[268]\tvalid_0's tweedie: 86.4043\n",
      "[269]\tvalid_0's tweedie: 86.4043\n",
      "[270]\tvalid_0's tweedie: 86.4042\n",
      "[271]\tvalid_0's tweedie: 86.4043\n",
      "[272]\tvalid_0's tweedie: 86.4043\n",
      "[273]\tvalid_0's tweedie: 86.4044\n",
      "[274]\tvalid_0's tweedie: 86.4043\n",
      "[275]\tvalid_0's tweedie: 86.4043\n",
      "[276]\tvalid_0's tweedie: 86.4043\n",
      "[277]\tvalid_0's tweedie: 86.4043\n",
      "[278]\tvalid_0's tweedie: 86.4043\n",
      "[279]\tvalid_0's tweedie: 86.4043\n",
      "[280]\tvalid_0's tweedie: 86.4042\n",
      "[281]\tvalid_0's tweedie: 86.4043\n",
      "[282]\tvalid_0's tweedie: 86.4044\n",
      "[283]\tvalid_0's tweedie: 86.4044\n",
      "[284]\tvalid_0's tweedie: 86.4044\n",
      "[285]\tvalid_0's tweedie: 86.4044\n",
      "[286]\tvalid_0's tweedie: 86.4043\n",
      "[287]\tvalid_0's tweedie: 86.4043\n",
      "[288]\tvalid_0's tweedie: 86.4043\n",
      "[289]\tvalid_0's tweedie: 86.4042\n",
      "[290]\tvalid_0's tweedie: 86.4042\n",
      "[291]\tvalid_0's tweedie: 86.4041\n",
      "[292]\tvalid_0's tweedie: 86.4041\n",
      "[293]\tvalid_0's tweedie: 86.404\n",
      "[294]\tvalid_0's tweedie: 86.4039\n",
      "[295]\tvalid_0's tweedie: 86.4039\n",
      "[296]\tvalid_0's tweedie: 86.4037\n",
      "[297]\tvalid_0's tweedie: 86.4037\n",
      "[298]\tvalid_0's tweedie: 86.4037\n",
      "[299]\tvalid_0's tweedie: 86.4036\n",
      "[300]\tvalid_0's tweedie: 86.4036\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's tweedie: 86.4036\n",
      "Training model for level 9 and step 12\n",
      "[LightGBM] [Info] Load from binary file /home/ariel/Playground/m5-forecasting/data/processed/datasets/9/12/train.bin\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5513\n",
      "[LightGBM] [Info] Number of data points in the train set: 130199, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.195082\n",
      "[1]\tvalid_0's tweedie: 96.8114\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's tweedie: 95.1008\n",
      "[3]\tvalid_0's tweedie: 93.6551\n",
      "[4]\tvalid_0's tweedie: 92.4373\n",
      "[5]\tvalid_0's tweedie: 91.4217\n",
      "[6]\tvalid_0's tweedie: 90.5598\n",
      "[7]\tvalid_0's tweedie: 89.8473\n",
      "[8]\tvalid_0's tweedie: 89.2603\n",
      "[9]\tvalid_0's tweedie: 88.7673\n",
      "[10]\tvalid_0's tweedie: 88.3566\n",
      "[11]\tvalid_0's tweedie: 88.02\n",
      "[12]\tvalid_0's tweedie: 87.7383\n",
      "[13]\tvalid_0's tweedie: 87.509\n",
      "[14]\tvalid_0's tweedie: 87.3217\n",
      "[15]\tvalid_0's tweedie: 87.1652\n",
      "[16]\tvalid_0's tweedie: 87.0376\n",
      "[17]\tvalid_0's tweedie: 86.9311\n",
      "[18]\tvalid_0's tweedie: 86.8434\n",
      "[19]\tvalid_0's tweedie: 86.7744\n",
      "[20]\tvalid_0's tweedie: 86.7167\n",
      "[21]\tvalid_0's tweedie: 86.6709\n",
      "[22]\tvalid_0's tweedie: 86.6317\n",
      "[23]\tvalid_0's tweedie: 86.6017\n",
      "[24]\tvalid_0's tweedie: 86.5762\n",
      "[25]\tvalid_0's tweedie: 86.5535\n",
      "[26]\tvalid_0's tweedie: 86.5355\n",
      "[27]\tvalid_0's tweedie: 86.5209\n",
      "[28]\tvalid_0's tweedie: 86.5067\n",
      "[29]\tvalid_0's tweedie: 86.4992\n",
      "[30]\tvalid_0's tweedie: 86.4886\n",
      "[31]\tvalid_0's tweedie: 86.4808\n",
      "[32]\tvalid_0's tweedie: 86.4756\n",
      "[33]\tvalid_0's tweedie: 86.4711\n",
      "[34]\tvalid_0's tweedie: 86.4654\n",
      "[35]\tvalid_0's tweedie: 86.4621\n",
      "[36]\tvalid_0's tweedie: 86.4594\n",
      "[37]\tvalid_0's tweedie: 86.4565\n",
      "[38]\tvalid_0's tweedie: 86.4552\n",
      "[39]\tvalid_0's tweedie: 86.4543\n",
      "[40]\tvalid_0's tweedie: 86.4516\n",
      "[41]\tvalid_0's tweedie: 86.4484\n",
      "[42]\tvalid_0's tweedie: 86.4469\n",
      "[43]\tvalid_0's tweedie: 86.4466\n",
      "[44]\tvalid_0's tweedie: 86.4445\n",
      "[45]\tvalid_0's tweedie: 86.4412\n",
      "[46]\tvalid_0's tweedie: 86.4404\n",
      "[47]\tvalid_0's tweedie: 86.4401\n",
      "[48]\tvalid_0's tweedie: 86.4395\n",
      "[49]\tvalid_0's tweedie: 86.4363\n",
      "[50]\tvalid_0's tweedie: 86.4364\n",
      "[51]\tvalid_0's tweedie: 86.4363\n",
      "[52]\tvalid_0's tweedie: 86.4371\n",
      "[53]\tvalid_0's tweedie: 86.4364\n",
      "[54]\tvalid_0's tweedie: 86.4371\n",
      "[55]\tvalid_0's tweedie: 86.4366\n",
      "[56]\tvalid_0's tweedie: 86.4368\n",
      "[57]\tvalid_0's tweedie: 86.4365\n",
      "[58]\tvalid_0's tweedie: 86.4358\n",
      "[59]\tvalid_0's tweedie: 86.4358\n",
      "[60]\tvalid_0's tweedie: 86.4358\n",
      "[61]\tvalid_0's tweedie: 86.4361\n",
      "[62]\tvalid_0's tweedie: 86.4362\n",
      "[63]\tvalid_0's tweedie: 86.4362\n",
      "[64]\tvalid_0's tweedie: 86.4361\n",
      "[65]\tvalid_0's tweedie: 86.4355\n",
      "[66]\tvalid_0's tweedie: 86.4352\n",
      "[67]\tvalid_0's tweedie: 86.435\n",
      "[68]\tvalid_0's tweedie: 86.4354\n",
      "[69]\tvalid_0's tweedie: 86.4353\n",
      "[70]\tvalid_0's tweedie: 86.4353\n",
      "[71]\tvalid_0's tweedie: 86.4353\n",
      "[72]\tvalid_0's tweedie: 86.4352\n",
      "[73]\tvalid_0's tweedie: 86.4352\n",
      "[74]\tvalid_0's tweedie: 86.435\n",
      "[75]\tvalid_0's tweedie: 86.4349\n",
      "[76]\tvalid_0's tweedie: 86.4348\n",
      "[77]\tvalid_0's tweedie: 86.4349\n",
      "[78]\tvalid_0's tweedie: 86.4349\n",
      "[79]\tvalid_0's tweedie: 86.435\n",
      "[80]\tvalid_0's tweedie: 86.4349\n",
      "[81]\tvalid_0's tweedie: 86.435\n",
      "[82]\tvalid_0's tweedie: 86.4348\n",
      "[83]\tvalid_0's tweedie: 86.4347\n",
      "[84]\tvalid_0's tweedie: 86.4346\n",
      "[85]\tvalid_0's tweedie: 86.4349\n",
      "[86]\tvalid_0's tweedie: 86.4352\n",
      "[87]\tvalid_0's tweedie: 86.4355\n",
      "[88]\tvalid_0's tweedie: 86.4352\n",
      "[89]\tvalid_0's tweedie: 86.4348\n",
      "[90]\tvalid_0's tweedie: 86.4347\n",
      "[91]\tvalid_0's tweedie: 86.4344\n",
      "[92]\tvalid_0's tweedie: 86.4343\n",
      "[93]\tvalid_0's tweedie: 86.4343\n",
      "[94]\tvalid_0's tweedie: 86.4334\n",
      "[95]\tvalid_0's tweedie: 86.4305\n",
      "[96]\tvalid_0's tweedie: 86.4305\n",
      "[97]\tvalid_0's tweedie: 86.4305\n",
      "[98]\tvalid_0's tweedie: 86.4301\n",
      "[99]\tvalid_0's tweedie: 86.4302\n",
      "[100]\tvalid_0's tweedie: 86.4285\n",
      "[101]\tvalid_0's tweedie: 86.4282\n",
      "[102]\tvalid_0's tweedie: 86.4281\n",
      "[103]\tvalid_0's tweedie: 86.4282\n"
     ]
    }
   ],
   "source": [
    "train(cfg.DATA_DIR, cfg.MODEL_DIR, cfg.FH, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cdb58-c9eb-4839-b1c6-5e6d44b4a36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_level(cfg.DATA_DIR, cfg.MODEL_DIR, cfg.FH, level, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ac891-458d-41f4-bfce-39ac4544f544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e40d6d12-d2da-4317-8bf1-1395e76d2d0c",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421b4a57-9391-45c2-9b78-55e1e5482cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling forecast level 1\n",
      "Compiling forecast level 2\n",
      "Compiling forecast level 3\n",
      "Compiling forecast level 4\n",
      "Compiling forecast level 5\n",
      "Compiling forecast level 6\n",
      "Compiling forecast level 7\n",
      "Compiling forecast level 8\n",
      "Compiling forecast level 9\n",
      "Compiling forecast level 10\n",
      "Compiling forecast level 11\n"
     ]
    }
   ],
   "source": [
    "compile_fcst(cfg.FCST_DIR, cfg.FH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda29454-75bb-4a4b-bbfb-d6f960be2424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy for level 1\n",
      "Calculating accuracy for level 2\n",
      "Calculating accuracy for level 3\n",
      "Calculating accuracy for level 4\n",
      "Calculating accuracy for level 5\n",
      "Calculating accuracy for level 6\n",
      "Calculating accuracy for level 7\n",
      "Calculating accuracy for level 8\n",
      "Calculating accuracy for level 9\n",
      "Calculating accuracy for level 10\n",
      "Calculating accuracy for level 11\n"
     ]
    }
   ],
   "source": [
    "accuracy_all_levels(cfg.DATA_DIR, cfg.FCST_DIR, cfg.METRICS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c991c62-03ef-4457-b172-3a96cdd58bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           wmrsse\n",
      "1        0.390541\n",
      "2        0.430238\n",
      "3        0.572372\n",
      "4        0.455612\n",
      "5        0.553134\n",
      "6        0.577809\n",
      "7        0.667025\n",
      "8        0.682591\n",
      "9        0.765033\n",
      "10       0.861726\n",
      "11       0.857380\n",
      "Average  0.619406\n"
     ]
    }
   ],
   "source": [
    "collect_metrics(cfg.METRICS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b77caf-76ae-41e5-a2ac-91df9742fad9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n",
      "Making predictions for level 1\n",
      "Making predictions for level 1 and step 1\n",
      "Making predictions for level 1 and step 2\n",
      "Making predictions for level 1 and step 3\n",
      "Making predictions for level 1 and step 4\n",
      "Making predictions for level 1 and step 5\n",
      "Making predictions for level 1 and step 6\n",
      "Making predictions for level 1 and step 7\n",
      "Making predictions for level 1 and step 8\n",
      "Making predictions for level 1 and step 9\n",
      "Making predictions for level 1 and step 10\n",
      "Making predictions for level 1 and step 11\n",
      "Making predictions for level 1 and step 12\n",
      "Making predictions for level 1 and step 13\n",
      "Making predictions for level 1 and step 14\n",
      "Making predictions for level 1 and step 15\n",
      "Making predictions for level 1 and step 16\n",
      "Making predictions for level 1 and step 17\n",
      "Making predictions for level 1 and step 18\n",
      "Making predictions for level 1 and step 19\n",
      "Making predictions for level 1 and step 20\n",
      "Making predictions for level 1 and step 21\n",
      "Making predictions for level 1 and step 22\n",
      "Making predictions for level 1 and step 23\n",
      "Making predictions for level 1 and step 24\n",
      "Making predictions for level 1 and step 25\n",
      "Making predictions for level 1 and step 26\n",
      "Making predictions for level 1 and step 27\n",
      "Making predictions for level 1 and step 28\n",
      "Making predictions for level 2\n",
      "Making predictions for level 2 and step 1\n",
      "Making predictions for level 2 and step 2\n",
      "Making predictions for level 2 and step 3\n",
      "Making predictions for level 2 and step 4\n",
      "Making predictions for level 2 and step 5\n",
      "Making predictions for level 2 and step 6\n",
      "Making predictions for level 2 and step 7\n",
      "Making predictions for level 2 and step 8\n",
      "Making predictions for level 2 and step 9\n",
      "Making predictions for level 2 and step 10\n",
      "Making predictions for level 2 and step 11\n",
      "Making predictions for level 2 and step 12\n",
      "Making predictions for level 2 and step 13\n",
      "Making predictions for level 2 and step 14\n",
      "Making predictions for level 2 and step 15\n",
      "Making predictions for level 2 and step 16\n",
      "Making predictions for level 2 and step 17\n",
      "Making predictions for level 2 and step 18\n",
      "Making predictions for level 2 and step 19\n",
      "Making predictions for level 2 and step 20\n",
      "Making predictions for level 2 and step 21\n",
      "Making predictions for level 2 and step 22\n",
      "Making predictions for level 2 and step 23\n",
      "Making predictions for level 2 and step 24\n",
      "Making predictions for level 2 and step 25\n",
      "Making predictions for level 2 and step 26\n",
      "Making predictions for level 2 and step 27\n",
      "Making predictions for level 2 and step 28\n",
      "Making predictions for level 3\n",
      "Making predictions for level 3 and step 1\n",
      "Making predictions for level 3 and step 2\n",
      "Making predictions for level 3 and step 3\n",
      "Making predictions for level 3 and step 4\n",
      "Making predictions for level 3 and step 5\n",
      "Making predictions for level 3 and step 6\n",
      "Making predictions for level 3 and step 7\n",
      "Making predictions for level 3 and step 8\n",
      "Making predictions for level 3 and step 9\n",
      "Making predictions for level 3 and step 10\n",
      "Making predictions for level 3 and step 11\n",
      "Making predictions for level 3 and step 12\n",
      "Making predictions for level 3 and step 13\n",
      "Making predictions for level 3 and step 14\n",
      "Making predictions for level 3 and step 15\n",
      "Making predictions for level 3 and step 16\n",
      "Making predictions for level 3 and step 17\n",
      "Making predictions for level 3 and step 18\n",
      "Making predictions for level 3 and step 19\n",
      "Making predictions for level 3 and step 20\n",
      "Making predictions for level 3 and step 21\n",
      "Making predictions for level 3 and step 22\n",
      "Making predictions for level 3 and step 23\n",
      "Making predictions for level 3 and step 24\n",
      "Making predictions for level 3 and step 25\n",
      "Making predictions for level 3 and step 26\n",
      "Making predictions for level 3 and step 27\n",
      "Making predictions for level 3 and step 28\n",
      "Making predictions for level 4\n",
      "Making predictions for level 4 and step 1\n",
      "Making predictions for level 4 and step 2\n",
      "Making predictions for level 4 and step 3\n",
      "Making predictions for level 4 and step 4\n",
      "Making predictions for level 4 and step 5\n",
      "Making predictions for level 4 and step 6\n",
      "Making predictions for level 4 and step 7\n",
      "Making predictions for level 4 and step 8\n",
      "Making predictions for level 4 and step 9\n",
      "Making predictions for level 4 and step 10\n",
      "Making predictions for level 4 and step 11\n",
      "Making predictions for level 4 and step 12\n",
      "Making predictions for level 4 and step 13\n",
      "Making predictions for level 4 and step 14\n",
      "Making predictions for level 4 and step 15\n",
      "Making predictions for level 4 and step 16\n",
      "Making predictions for level 4 and step 17\n",
      "Making predictions for level 4 and step 18\n",
      "Making predictions for level 4 and step 19\n",
      "Making predictions for level 4 and step 20\n",
      "Making predictions for level 4 and step 21\n",
      "Making predictions for level 4 and step 22\n",
      "Making predictions for level 4 and step 23\n",
      "Making predictions for level 4 and step 24\n",
      "Making predictions for level 4 and step 25\n",
      "Making predictions for level 4 and step 26\n",
      "Making predictions for level 4 and step 27\n",
      "Making predictions for level 4 and step 28\n",
      "Making predictions for level 5\n",
      "Making predictions for level 5 and step 1\n",
      "Making predictions for level 5 and step 2\n",
      "Making predictions for level 5 and step 3\n",
      "Making predictions for level 5 and step 4\n",
      "Making predictions for level 5 and step 5\n",
      "Making predictions for level 5 and step 6\n",
      "Making predictions for level 5 and step 7\n",
      "Making predictions for level 5 and step 8\n",
      "Making predictions for level 5 and step 9\n",
      "Making predictions for level 5 and step 10\n",
      "Making predictions for level 5 and step 11\n",
      "Making predictions for level 5 and step 12\n",
      "Making predictions for level 5 and step 13\n",
      "Making predictions for level 5 and step 14\n",
      "Making predictions for level 5 and step 15\n",
      "Making predictions for level 5 and step 16\n",
      "Making predictions for level 5 and step 17\n",
      "Making predictions for level 5 and step 18\n",
      "Making predictions for level 5 and step 19\n",
      "Making predictions for level 5 and step 20\n",
      "Making predictions for level 5 and step 21\n",
      "Making predictions for level 5 and step 22\n",
      "Making predictions for level 5 and step 23\n",
      "Making predictions for level 5 and step 24\n",
      "Making predictions for level 5 and step 25\n",
      "Making predictions for level 5 and step 26\n",
      "Making predictions for level 5 and step 27\n",
      "Making predictions for level 5 and step 28\n",
      "Making predictions for level 6\n",
      "Making predictions for level 6 and step 1\n",
      "Making predictions for level 6 and step 2\n",
      "Making predictions for level 6 and step 3\n",
      "Making predictions for level 6 and step 4\n",
      "Making predictions for level 6 and step 5\n",
      "Making predictions for level 6 and step 6\n",
      "Making predictions for level 6 and step 7\n",
      "Making predictions for level 6 and step 8\n",
      "Making predictions for level 6 and step 9\n",
      "Making predictions for level 6 and step 10\n",
      "Making predictions for level 6 and step 11\n",
      "Making predictions for level 6 and step 12\n",
      "Making predictions for level 6 and step 13\n",
      "Making predictions for level 6 and step 14\n",
      "Making predictions for level 6 and step 15\n",
      "Making predictions for level 6 and step 16\n",
      "Making predictions for level 6 and step 17\n",
      "Making predictions for level 6 and step 18\n",
      "Making predictions for level 6 and step 19\n",
      "Making predictions for level 6 and step 20\n",
      "Making predictions for level 6 and step 21\n",
      "Making predictions for level 6 and step 22\n",
      "Making predictions for level 6 and step 23\n",
      "Making predictions for level 6 and step 24\n",
      "Making predictions for level 6 and step 25\n",
      "Making predictions for level 6 and step 26\n",
      "Making predictions for level 6 and step 27\n",
      "Making predictions for level 6 and step 28\n",
      "Making predictions for level 7\n",
      "Making predictions for level 7 and step 1\n",
      "Making predictions for level 7 and step 2\n",
      "Making predictions for level 7 and step 3\n",
      "Making predictions for level 7 and step 4\n",
      "Making predictions for level 7 and step 5\n",
      "Making predictions for level 7 and step 6\n",
      "Making predictions for level 7 and step 7\n",
      "Making predictions for level 7 and step 8\n",
      "Making predictions for level 7 and step 9\n",
      "Making predictions for level 7 and step 10\n",
      "Making predictions for level 7 and step 11\n",
      "Making predictions for level 7 and step 12\n",
      "Making predictions for level 7 and step 13\n",
      "Making predictions for level 7 and step 14\n",
      "Making predictions for level 7 and step 15\n",
      "Making predictions for level 7 and step 16\n",
      "Making predictions for level 7 and step 17\n",
      "Making predictions for level 7 and step 18\n",
      "Making predictions for level 7 and step 19\n",
      "Making predictions for level 7 and step 20\n",
      "Making predictions for level 7 and step 21\n",
      "Making predictions for level 7 and step 22\n",
      "Making predictions for level 7 and step 23\n",
      "Making predictions for level 7 and step 24\n",
      "Making predictions for level 7 and step 25\n",
      "Making predictions for level 7 and step 26\n",
      "Making predictions for level 7 and step 27\n",
      "Making predictions for level 7 and step 28\n",
      "Making predictions for level 8\n",
      "Making predictions for level 8 and step 1\n",
      "Making predictions for level 8 and step 2\n",
      "Making predictions for level 8 and step 3\n",
      "Making predictions for level 8 and step 4\n",
      "Making predictions for level 8 and step 5\n",
      "Making predictions for level 8 and step 6\n",
      "Making predictions for level 8 and step 7\n",
      "Making predictions for level 8 and step 8\n",
      "Making predictions for level 8 and step 9\n",
      "Making predictions for level 8 and step 10\n",
      "Making predictions for level 8 and step 11\n",
      "Making predictions for level 8 and step 12\n",
      "Making predictions for level 8 and step 13\n",
      "Making predictions for level 8 and step 14\n",
      "Making predictions for level 8 and step 15\n",
      "Making predictions for level 8 and step 16\n",
      "Making predictions for level 8 and step 17\n",
      "Making predictions for level 8 and step 18\n",
      "Making predictions for level 8 and step 19\n",
      "Making predictions for level 8 and step 20\n",
      "Making predictions for level 8 and step 21\n",
      "Making predictions for level 8 and step 22\n",
      "Making predictions for level 8 and step 23\n",
      "Making predictions for level 8 and step 24\n",
      "Making predictions for level 8 and step 25\n",
      "Making predictions for level 8 and step 26\n",
      "Making predictions for level 8 and step 27\n",
      "Making predictions for level 8 and step 28\n",
      "Making predictions for level 9\n",
      "Making predictions for level 9 and step 1\n",
      "Making predictions for level 9 and step 2\n",
      "Making predictions for level 9 and step 3\n",
      "Making predictions for level 9 and step 4\n",
      "Making predictions for level 9 and step 5\n",
      "Making predictions for level 9 and step 6\n",
      "Making predictions for level 9 and step 7\n",
      "Making predictions for level 9 and step 8\n",
      "Making predictions for level 9 and step 9\n",
      "Making predictions for level 9 and step 10\n",
      "Making predictions for level 9 and step 11\n",
      "Making predictions for level 9 and step 12\n",
      "Making predictions for level 9 and step 13\n",
      "Making predictions for level 9 and step 14\n",
      "Making predictions for level 9 and step 15\n",
      "Making predictions for level 9 and step 16\n",
      "Making predictions for level 9 and step 17\n",
      "Making predictions for level 9 and step 18\n",
      "Making predictions for level 9 and step 19\n",
      "Making predictions for level 9 and step 20\n",
      "Making predictions for level 9 and step 21\n",
      "Making predictions for level 9 and step 22\n",
      "Making predictions for level 9 and step 23\n",
      "Making predictions for level 9 and step 24\n",
      "Making predictions for level 9 and step 25\n",
      "Making predictions for level 9 and step 26\n",
      "Making predictions for level 9 and step 27\n",
      "Making predictions for level 9 and step 28\n",
      "Making predictions for level 10\n",
      "Making predictions for level 10 and step 1\n",
      "Making predictions for level 10 and step 2\n",
      "Making predictions for level 10 and step 3\n",
      "Making predictions for level 10 and step 4\n",
      "Making predictions for level 10 and step 5\n",
      "Making predictions for level 10 and step 6\n",
      "Making predictions for level 10 and step 7\n",
      "Making predictions for level 10 and step 8\n",
      "Making predictions for level 10 and step 9\n",
      "Making predictions for level 10 and step 10\n",
      "Making predictions for level 10 and step 11\n",
      "Making predictions for level 10 and step 12\n",
      "Making predictions for level 10 and step 13\n",
      "Making predictions for level 10 and step 14\n",
      "Making predictions for level 10 and step 15\n",
      "Making predictions for level 10 and step 16\n",
      "Making predictions for level 10 and step 17\n",
      "Making predictions for level 10 and step 18\n",
      "Making predictions for level 10 and step 19\n",
      "Making predictions for level 10 and step 20\n",
      "Making predictions for level 10 and step 21\n",
      "Making predictions for level 10 and step 22\n",
      "Making predictions for level 10 and step 23\n",
      "Making predictions for level 10 and step 24\n",
      "Making predictions for level 10 and step 25\n",
      "Making predictions for level 10 and step 26\n",
      "Making predictions for level 10 and step 27\n",
      "Making predictions for level 10 and step 28\n",
      "Making predictions for level 11\n",
      "Making predictions for level 11 and step 1\n",
      "Making predictions for level 11 and step 2\n",
      "Making predictions for level 11 and step 3\n",
      "Making predictions for level 11 and step 4\n",
      "Making predictions for level 11 and step 5\n",
      "Making predictions for level 11 and step 6\n",
      "Making predictions for level 11 and step 7\n",
      "Making predictions for level 11 and step 8\n",
      "Making predictions for level 11 and step 9\n",
      "Making predictions for level 11 and step 10\n",
      "Making predictions for level 11 and step 11\n",
      "Making predictions for level 11 and step 12\n",
      "Making predictions for level 11 and step 13\n",
      "Making predictions for level 11 and step 14\n",
      "Making predictions for level 11 and step 15\n",
      "Making predictions for level 11 and step 16\n",
      "Making predictions for level 11 and step 17\n",
      "Making predictions for level 11 and step 18\n",
      "Making predictions for level 11 and step 19\n",
      "Making predictions for level 11 and step 20\n",
      "Making predictions for level 11 and step 21\n",
      "Making predictions for level 11 and step 22\n",
      "Making predictions for level 11 and step 23\n",
      "Making predictions for level 11 and step 24\n",
      "Making predictions for level 11 and step 25\n",
      "Making predictions for level 11 and step 26\n",
      "Making predictions for level 11 and step 27\n",
      "Making predictions for level 11 and step 28\n"
     ]
    }
   ],
   "source": [
    "predict(cfg.DATA_DIR, cfg.MODEL_DIR, cfg.FCST_DIR, cfg.FH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40387698-a478-4d41-90ec-889a8401b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcst = predict_level(cfg.DATA_DIR, cfg.MODEL_DIR, cfg.FCST_DIR, cfg.FH, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "823123f9-5669-413f-b547-db69f273faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>fcst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>1886</td>\n",
       "      <td>36041</td>\n",
       "      <td>35437.815248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         d  sales          fcst\n",
       "1885  1886  36041  35437.815248"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d599bc0-cb3c-460b-8e26-efb287ecef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fcst(fcst_dir, fh):\n",
    "    for level in range(1, 12 + 1):\n",
    "        print(f\"Compiling forecast level {level}\")\n",
    "        fcst_list = []\n",
    "        for step in range(1, fh + 1):\n",
    "            fcst_step = pd.read_parquet(cfg.FCST_DIR / f\"{level}/{step}/fcst.parquet\")\n",
    "            fcst_step = fcst_step.iloc[[step-1]]\n",
    "            fcst_list.append(fcst_step)\n",
    "        fcst_level = pd.concat(fcst_list, axis=0)\n",
    "        fcst_level.to_parquet(cfg.FCST_DIR / f\"{level}/fcst-{level}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5fd6d48-52f5-4bd4-b558-9a44e8e82424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['d'],\n",
       " 2: ['state_id', 'd'],\n",
       " 3: ['store_id', 'd'],\n",
       " 4: ['cat_id', 'd'],\n",
       " 5: ['dept_id', 'd'],\n",
       " 6: ['state_id', 'cat_id', 'd'],\n",
       " 7: ['state_id', 'dept_id', 'd'],\n",
       " 8: ['store_id', 'cat_id', 'd'],\n",
       " 9: ['store_id', 'dept_id', 'd'],\n",
       " 10: ['item_id', 'd'],\n",
       " 11: ['item_id', 'state_id', 'd'],\n",
       " 12: ['item_id', 'store_id', 'd']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGG_LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "800911bc-c25b-4e45-88b7-64d507b4b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fcst(fcst_dir, fh):\n",
    "    for level in range(1, 10 + 1):\n",
    "        print(f\"Compiling forecast level {level}\")\n",
    "        fcst_list = []\n",
    "        for step in range(1, fh + 1):\n",
    "            fcst_step = pd.read_parquet(cfg.FCST_DIR / f\"{level}/{step}/fcst.parquet\")\n",
    "            if level == 1:\n",
    "                fcst_step = fcst_step.iloc[[step-1]]\n",
    "            else:\n",
    "                fcst_step = fcst_step.groupby(AGG_LEVEL[level][:-1], group_keys=False).apply(lambda df: df.iloc[[step-1]])\n",
    "            fcst_list.append(fcst_step)\n",
    "        fcst_level = pd.concat(fcst_list, axis=0).sort_values(by=AGG_LEVEL[level])\n",
    "        fcst_level.to_parquet(cfg.FCST_DIR / f\"{level}/fcst-{level}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "939b5bb9-3955-440d-bc1d-c6c3cb486a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling forecast level 1\n",
      "Compiling forecast level 2\n",
      "Compiling forecast level 3\n",
      "Compiling forecast level 4\n",
      "Compiling forecast level 5\n",
      "Compiling forecast level 6\n",
      "Compiling forecast level 7\n",
      "Compiling forecast level 8\n",
      "Compiling forecast level 9\n",
      "Compiling forecast level 10\n"
     ]
    }
   ],
   "source": [
    "compile_fcst(cfg.FCST_DIR, cfg.FH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e49d947-161f-4951-8e0c-06a601bf4451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>fcst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4710258</th>\n",
       "      <td>0</td>\n",
       "      <td>1886</td>\n",
       "      <td>5</td>\n",
       "      <td>6.159899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713307</th>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>2</td>\n",
       "      <td>6.357816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716356</th>\n",
       "      <td>0</td>\n",
       "      <td>1888</td>\n",
       "      <td>3</td>\n",
       "      <td>5.007182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719405</th>\n",
       "      <td>0</td>\n",
       "      <td>1889</td>\n",
       "      <td>5</td>\n",
       "      <td>5.761373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722454</th>\n",
       "      <td>0</td>\n",
       "      <td>1890</td>\n",
       "      <td>5</td>\n",
       "      <td>7.632164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783433</th>\n",
       "      <td>3048</td>\n",
       "      <td>1909</td>\n",
       "      <td>1</td>\n",
       "      <td>1.304029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786482</th>\n",
       "      <td>3048</td>\n",
       "      <td>1910</td>\n",
       "      <td>2</td>\n",
       "      <td>1.305409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789531</th>\n",
       "      <td>3048</td>\n",
       "      <td>1911</td>\n",
       "      <td>1</td>\n",
       "      <td>1.615593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792580</th>\n",
       "      <td>3048</td>\n",
       "      <td>1912</td>\n",
       "      <td>0</td>\n",
       "      <td>1.944173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795629</th>\n",
       "      <td>3048</td>\n",
       "      <td>1913</td>\n",
       "      <td>1</td>\n",
       "      <td>1.976238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85372 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id     d  sales      fcst\n",
       "4710258        0  1886      5  6.159899\n",
       "4713307        0  1887      2  6.357816\n",
       "4716356        0  1888      3  5.007182\n",
       "4719405        0  1889      5  5.761373\n",
       "4722454        0  1890      5  7.632164\n",
       "...          ...   ...    ...       ...\n",
       "4783433     3048  1909      1  1.304029\n",
       "4786482     3048  1910      2  1.305409\n",
       "4789531     3048  1911      1  1.615593\n",
       "4792580     3048  1912      0  1.944173\n",
       "4795629     3048  1913      1  1.976238\n",
       "\n",
       "[85372 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(cfg.FCST_DIR / f\"{10}/fcst-{10}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f24eb72-31f1-4e06-83fa-5602dbfba141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>fcst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>39585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1886</td>\n",
       "      <td>1048</td>\n",
       "      <td>1520.637747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>39586</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1886</td>\n",
       "      <td>1885</td>\n",
       "      <td>1750.588601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>39587</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1886</td>\n",
       "      <td>6888</td>\n",
       "      <td>7930.980263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>39588</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1886</td>\n",
       "      <td>1630</td>\n",
       "      <td>1515.774368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>39589</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1886</td>\n",
       "      <td>124</td>\n",
       "      <td>145.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>39590</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1886</td>\n",
       "      <td>3075</td>\n",
       "      <td>3156.918893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>39591</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1886</td>\n",
       "      <td>832</td>\n",
       "      <td>869.108152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>39592</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1886</td>\n",
       "      <td>635</td>\n",
       "      <td>882.288640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>39593</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1886</td>\n",
       "      <td>1169</td>\n",
       "      <td>1063.022273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>39594</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1886</td>\n",
       "      <td>4781</td>\n",
       "      <td>5094.360063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>39595</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1886</td>\n",
       "      <td>824</td>\n",
       "      <td>791.373507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>39596</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1886</td>\n",
       "      <td>96</td>\n",
       "      <td>121.325059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>39597</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1886</td>\n",
       "      <td>2266</td>\n",
       "      <td>2133.722457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>39598</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1886</td>\n",
       "      <td>532</td>\n",
       "      <td>565.777349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <th>39599</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1886</td>\n",
       "      <td>578</td>\n",
       "      <td>892.802918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>39600</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1886</td>\n",
       "      <td>1644</td>\n",
       "      <td>1580.361457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>39601</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1886</td>\n",
       "      <td>4657</td>\n",
       "      <td>4848.148361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>39602</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1886</td>\n",
       "      <td>777</td>\n",
       "      <td>663.658981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>39603</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1886</td>\n",
       "      <td>104</td>\n",
       "      <td>80.128396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>39604</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1886</td>\n",
       "      <td>2059</td>\n",
       "      <td>1692.893172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>39605</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1886</td>\n",
       "      <td>437</td>\n",
       "      <td>388.254219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        state_id  dept_id     d  sales         fcst\n",
       "state_id dept_id                                                   \n",
       "0        0       39585         0        0  1886   1048  1520.637747\n",
       "         1       39586         0        1  1886   1885  1750.588601\n",
       "         2       39587         0        2  1886   6888  7930.980263\n",
       "         3       39588         0        3  1886   1630  1515.774368\n",
       "         4       39589         0        4  1886    124   145.030928\n",
       "         5       39590         0        5  1886   3075  3156.918893\n",
       "         6       39591         0        6  1886    832   869.108152\n",
       "1        0       39592         1        0  1886    635   882.288640\n",
       "         1       39593         1        1  1886   1169  1063.022273\n",
       "         2       39594         1        2  1886   4781  5094.360063\n",
       "         3       39595         1        3  1886    824   791.373507\n",
       "         4       39596         1        4  1886     96   121.325059\n",
       "         5       39597         1        5  1886   2266  2133.722457\n",
       "         6       39598         1        6  1886    532   565.777349\n",
       "2        0       39599         2        0  1886    578   892.802918\n",
       "         1       39600         2        1  1886   1644  1580.361457\n",
       "         2       39601         2        2  1886   4657  4848.148361\n",
       "         3       39602         2        3  1886    777   663.658981\n",
       "         4       39603         2        4  1886    104    80.128396\n",
       "         5       39604         2        5  1886   2059  1692.893172\n",
       "         6       39605         2        6  1886    437   388.254219"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(cfg.FCST_DIR / f\"7/1/fcst.parquet\").groupby([\"state_id\", \"dept_id\"]).apply(lambda df: df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fd774-4639-4f1c-9490-d5fe13acb18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc586413-c3f3-45b6-91e1-0ecd5ceca83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fcst(cfg.DATA_DIR, cfg.FCST_DIR, 9, key=(3, 5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea9e5cc8-6e7a-4571-bda2-b5377e543ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling forecast level 1\n",
      "Compiling forecast level 2\n",
      "Compiling forecast level 3\n",
      "Compiling forecast level 4\n",
      "Compiling forecast level 5\n",
      "Compiling forecast level 6\n",
      "Compiling forecast level 7\n",
      "Compiling forecast level 8\n",
      "Compiling forecast level 9\n",
      "Compiling forecast level 10\n",
      "Compiling forecast level 11\n",
      "Compiling forecast level 12\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ariel/Playground/m5-forecasting/fcst/12/1/fcst.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6397/2478190390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompile_fcst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFCST_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6397/1437055866.py\u001b[0m in \u001b[0;36mcompile_fcst\u001b[0;34m(fcst_dir, fh)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfcst_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mfcst_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFCST_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{level}/{step}/fcst.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mfcst_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcst_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfcst_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcst_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/merlion/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/merlion/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/merlion/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/merlion/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ariel/Playground/m5-forecasting/fcst/12/1/fcst.parquet'"
     ]
    }
   ],
   "source": [
    "compile_fcst(cfg.FCST_DIR, cfg.FH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb27d6e3-00ef-4fef-87f0-4fde2bbf9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = pd.read_parquet(cfg.FCST_DIR / f\"{level}/fcst-{level}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ee7d2a0-6bf2-40d7-b81c-16d0454eddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(cfg.DATA_DIR / f\"processed/levels/level-{level}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dece8176-e082-47c3-988f-1d176811d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1750.0, 1920.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAD8CAYAAABASvRiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACQF0lEQVR4nO3deXhbZ5X48e+r3Zb33YmdOHuatW3SpPu+0dIpUFp2ChTKUmBgmBlgNuYHzAwwDDsDdCilQKG0bC0FutB9S5qlzb47cbzvuy3Zkt7fH/deRYllW7J1Jcc5n+fJE+dKsq5vZOmee857jtJaI4QQQgghhBBifI5M74AQQgghhBBCzHQSOAkhhBBCCCHEJCRwEkIIIYQQQohJSOAkhBBCCCGEEJOQwEkIIYQQQgghJiGBkxBCCCGEEEJMIqHASSlVoJT6jVJqv1Jqn1LqAqVUkVLqSaXUIfPvQvO+Sin1HaXUYaXUTqXUuTHf53bz/oeUUrfHbF+nlNplPuY7SimV+h9VCCGEEEIIIaYm0YzTt4HHtNbLgbXAPuBzwFNa6yXAU+a/Ad4ALDH/3An8AEApVQR8AdgIbAC+YAVb5n0+FPO466f3YwkhhBBCCCFE6kwaOCml8oFLgXsAtNYjWuse4GbgPvNu9wFvMr++GfiZNmwCCpRSlcB1wJNa6y6tdTfwJHC9eVue1nqTNqbx/izmewkhhBBCCCFExrkSuM8CoB24Vym1FtgG/C1QrrVuNu/TApSbX88F6mMe32Bum2h7Q5ztEyopKdE1NTUJ7L4QQgghhBDiTLRt27YOrXVpKr5XIoGTCzgX+ITWerNS6tucKMsDQGutlVI6FTs0EaXUnRjlf8ybN4+tW7fa/ZRCCCGEEEKI05RSqi5V3yuRNU4NQIPWerP5799gBFKtZpkd5t9t5u2NQHXM46vMbRNtr4qzfQyt9d1a6/Va6/WlpSkJHIUQQgghhBBiUpMGTlrrFqBeKbXM3HQVsBd4BLA6490OPGx+/QjwXrO73vlAr1nS9zhwrVKq0GwKcS3wuHlbn1LqfLOb3ntjvpcQQgghhBBCZFwipXoAnwDuV0p5gFrg/RhB14NKqTuAOuA2875/Bm4ADgND5n3RWncppb4EbDHv90WtdZf59ceAnwJZwF/MP0IIIYQQQggxIyijkd3pZ/369VrWOAkhhBBCCCHGo5TaprVen4rvlegcJyGEEEIIIYQ4Y0ngJIQQQgghhBCTkMBJCCGEEEIIISYhgZMQQgghTnvPHmjjaMdgpndDCDGLSeAkhBBCiNPa8EiYO3++jR89dyTTuyKEmMUkcBJCCCHEae3VY12MhCJ0DAQzvStCiFlMAichhBBCnNZePNQOQNfgSIb3RGRKx0CQT/zqtbS9Bg619rO5tjMtzyVmDgmchBBCCHFae+FQByCB05nswa31/HFHE9vqutPyfF97/AC33/sqbX2BtDyfmBkkcBJCCCHEaautL8D+ln48TocETmewh19rAqBrMD3lmi29AQKjEb791KG0PJ+YGSRwEkIIIcRp68XDRrbp8mWl9AVCjIYjGd4jkW77mvs40NoPQMdAeoLn1r4ADgUPbKmXbo5nEAmchBBCCHHaeuFQB8V+DxcvKQGge0iyTmeah19vwulQeFzpyTqGwkYjkredV43H6eDrTxyw/TnFzCCBkxBCiNNK1+AIl//3M+xu7M30rogM01rzwqEOLlpcQrHfC0D34GiG90qkUySieeT1Ri5dUkJ5njctgVPn4AgRDSvn5PPBSxbwp53N7GqQ96MzgQROQgghTiuHWvs51jnES2aJljhz7W/pp2MgyCVLSij0uwHoTNMaFzEzbDnWRVNvgJvPnkuR35uWlvStZkOI8jwfd166kMJsN199bL/tzysyTwInIYQQpxVrDcOhtoEM74nItBfNbnqXLCmVjNMZ6uEdTWS5nVyzopxivyctGafWPiM4K8/zkutzc9cVi3nxcEf09ShmLwmchBBCnFasK8oSOInnD7WzpCyHinxfNOOUrq5qIvNGQhH+vKuZa1eW4/e60hg4ncg4Abz7/PnMLcjiq4/tJxLRtj+/yBwJnIQQQpxWrMDpSNsAWmfmJGXLsS56hySzkUmB0TCvHu2KNoUozPYA0CUZJ9tFIpr33LOZJ/a0ZHQ/njvYTs/QKG86ey4ARTkeOgdHbH9faOsLoBQU+43XnM/t5NPXLGVXYy9P7W+z9blFZkngJIQQ4rRiBU4DwRAtGRg+OTwS5h13b+K7T8v8lkzaeqybYCjCpUtKAXA7HeT5XJJxSoOm3mFeONTBYxkOnB5+vZGimI6KxX4PI6EIA8GQrc/b2hekJMeLy3niNPrms+fgULBLmtbMahI4CSGEOK20958oxTnUmv5yvbquQUIRzSu1nWl/bnHCC4facTsVGxcWRbcV+T10SSbQdofNMtkDLf0Z24eBYIi/7mvlxtWVuJ0O0JoFoVpA216u19ofoDzPe9I2t9NBWa6Ppp5hW59bZJYETkKI087LhzvY29SX6d0QGdIxEOSsyjwgM+ucjnUMAbC3uY/eYTlJz5QXDnWwbn4h2R5XdFuR30N3Gta4nOmswOlQ2wChDA0cfnx3C4HRCG86Z46xYd8fueb5t7JOHaTT7sCpL0h5rm/M9jkFEjjNdhI4CSFOO5/73S6++OieTO+GyJCOgSDLynMozHZzuC39V7yPdw0CoDVsOdqV9ucX0N4fZG9zH5eYZXqWIr/H9pNmgN2NvVz9jefYVndm/v9bgdNIKMKxzsGM7MMjO5qoKszi3HmFxoZNPwBgruqga8De10BbX4CyvHiBU5YETrOcBE5CiNOK1prWvgCvHe8hGApnendEmmmt6Rgw1hcsKcvNSKnesc4hcn0uPE4Hm49KuV4mvHzEakNectL2dGWcttV1c7htgPfc8yqbzsCSzcNtAxRkG10M92egXC8S0Wyr6+aKZWUopaB5Bxx/GYBi1WfrLK+RUITOwZExpXoAcwuyaOoNZKxpjbCfBE5CiNNKXyBEMBQhGIqwWxbhnnEGR8IERiOU5HpZXJ7DoQx01qvrHGRxWQ5nVxeweYZknA609HPXL7enZfjnTLCnqQ+Py8HKOfknbS8021Hb/Zpo6h3G7VTMLcjiffe+yguH2m19vplEa82htgGuWl6O06HY35z+wKm+e4iBYIiVc4ySXTbfDe5stHKagZN9wXP7gDXDKX7GyQqsxOwkgZMQ4rTS3n/ixHCmnLSK9Okw//+NjFMOvcOj0YG46XKsY4j5Rdmcv7CI3Y299AUyu85pW10Xt/7wZf60s5ntdd0Z3Zd0aekNUJHnw+lQJ20v9nsYCUcYHLE3G93SG6Ai38ev7jyfmmI/d9y3laf3t9r6nDNFx8AIvcOjrJyTx4ISf0YyTtYa1xVz8mCwA3Y9BGvfjvKXUu7st7VUry06w2lsxqky3wimMlWu194fZNjm1/6ZTgInIcRppa3f+NBSCl6VwOmMY2VUSnI8LCnLBeBQGtc5BUNhmnqHmV/sZ+PCYiIath3LXLDyzIE23vXjzWR5nABpDyIzpbVvbFcziJnlZPNxaO4JUJmfRUmOl1996HyWlefy4Z9v46l9sz94stY3LS7LYXlFLgda09+oZ29zHw4FS8tzYft9EA7Chg+Dv5QKZ7+tXfVa+4z3oLK4zSGygMwEToHRMG/49vP8zxMH0v7cZxIJnIQQpxUr43ReTRHbjnUTzsCU9t2Nvbx0uCPtzytOBAYlOV4Wl+UAJ07k0qG+axitoaYkm3PnFeJ2KjZlaJ3Tw6838qH7trKoNIfff+wigDOmVK+tPxh3cX6ROZC0a8jewKmpd5g5Znah0O/hFx/cyPxiP9/66+yf7XW4/eTAqb5r2Pa5Safa19zHotIcfI4IbLkHFlwGZcvBX0ypo58OGwMn6+JdvFK9uWbg1NiT/vlyf97VTMfASMaadZwpJHASQpxWrMDppjWV9AdD7GtO/9XO/378AJ/81WuyADjG7sbetLSItwKD0lwv5Xlecr2utAZOdeZJyfxiP1keJ2urCthcm/7M56+3HOdTv36ddfML+dWd5zOnIIv8LHfGAqeRUIR//cNuDrban/2zGsRUTBQ42dgcIBIxnr/SPEkGyM9yc9GiYo51DM7694UjbQP4PU4q830srzDWGKV7ntPepj6jTG//o9DXCBs/YtzgL6WQPlv//1v7AjgdimLztRarINtNlttJcwYyTvdvPg4YFxWEfRIKnJRSx5RSu5RSryultprbipRSTyqlDpl/F5rblVLqO0qpw0qpnUqpc2O+z+3m/Q8ppW6P2b7O/P6HzceqsXshhBBG4ORxObjqrHIgM+V6RzsG6RwcobZDruyBcTzecfcmPv/7XbY/lxUYFPk9KKWMBhFp7KxX12nMcKop9gOwcWERuxp7037F/TtPHeac6gLu+8AG8nxGd7OSHE/GAqc/72rm55vqeHKv/aVqA8EQQyPhuKV6JwIn+9addQwEGQ3r6HoWy/xiP/3BkO3DVzPtUFs/i8tyUEqxrMIol93fkr4LWN2DIzT1BlhRmQebfwQF82HpdcaN/lLyIz22lmq29gUpy/XieP3n8MS/nHSbUorKAh9NvekNnPY197Gtrhuvy0FrX/qzXWeSZDJOV2itz9Zarzf//TngKa31EuAp898AbwCWmH/uBH4ARqAFfAHYCGwAvmAFW+Z9PhTzuOun/BMJIWa19v4gpTle5hRkUV2UlfbAaSQUoaHbOHneekzWWA2PhPnoL7bRHwxR225/h7uOgSCF2W7cTuPja0lZTlqH4NZ1DpLrc1FotmLeuKCYsNkaOV1GQhGae4e5eHEJPrczur0kx3tS85R00Vpzz4tHgRML5+3U2jd+qZQVONnZkry513j+yvysk7bXlGQDRrv62exw2wCLzDLZqsIscryutGacrCqD9d56OP4KbLgTHObvQXYxvsgQfYP2vRe1WjOcdvwaXv4uNL1+0u1zC7LSXqr3y83H8bgc3LKuio6BkYyUsJ8pplOqdzNwn/n1fcCbYrb/TBs2AQVKqUrgOuBJrXWX1robeBK43rwtT2u9SRuv8p/FfC8hhDhJW3+Q0lzjSvOGmmK2HOtKa2lMQ/cQ1mfSq0fPjA5m49Fa8y9/2M2B1n6uWl5GfyBkexvejv4RSnJOZBoWl+XQMRBMy+weME6K5xdnYxVGrJtfiMuh2JzGWT7NvcNENFQVZp+0vSTXm5HmEFvrutlljgZIR5nQRIvzc7wu3E5l6+uw2cwmnJpxsrKQx2ZxJrovMEprXzC6vtDKOqWzs95eM3BaUf8AuLPhnHefuNFvDETODfXa1lmxrS9Iea4Xuo8ZG174n5Nun5Of3iG4g8EQv3+tkTeurmRpWQ7hiM5o1nMkFMnYc6dDooGTBp5QSm1TSt1pbivXWjebX7cA5ebXc4H6mMc2mNsm2t4QZ/sYSqk7lVJblVJb29tPzEx45kAb331q9i/IFEKYGSczcNq4oIjOwRGOtKfvRMUq1SrL9bLlDM84PbClnt9ub+CTVy7h3efPB+w/aewYCFKcc2JtgdVZz1qwbre6zkHmmyfIAH6vi9VV+WkdgtrQbZyUVRWdnPEozfFG27Wn009ePEp+lpuzqwvSFDiN3w5aKWX7ENwmM5swp+Dk419VmI1DnVgHNxsdsTrqleZEty2ryGV/c1/aLmDtbe6jLNdLVt0zsPyNkFVw4kYzcCpWvbaV67X2B5iT4zDWVvkKYN8foW1/9PY5BVm09wfTNqD9kR1NDARDvOv8edGGKVYDi3Rq6Q3wkZ9v4zMP7Uj7c6dTooHTxVrrczHK8O5SSl0ae6OZKbL9N0ZrfbfWer3Wen1pqfHLMRgM8Q8P7eS7zxye9QsyhRDG8MEyM3A6b0ERkN51TlbHorecW8XxrqEztp58d2MvX3hkD5csKeGTVy2hpsQIJo6mIXA6NeME6emsNxqO0NA9TE3xyZmejQuK2dnQy9BIetY51XcZwXv1qRmnHA/9wRCB0fTNcanvGuLxPS28c+M85hdnp6VU0Mo4xSvVA6Mlud0ZJ6/LES3XtHhcDuYWZs3qUj2rLHZJeW502/KKXPoCIVrS9F64t6mPc8udMNAC5StPvtFfAkCJ6qPThgYRgdEwPUOjLPZ0ARou+0dwZ8GL34jeZ06B8bps7U3PRYxfbj7O8opczp1XGP1sTGeDiHBEc9/Lx7j6G8/xzIE2zqrMndXn4wkFTlrrRvPvNuD3GGuUWs0yO8y/28y7NwLVMQ+vMrdNtL0qzvaE3P18LR0DQUZCEfoC6V2cK4RIr5FQhK7BkWjGqaY4m9JcL6+msR30sY5Bcr0url9VAXBGZp16h0f56P3bKPF7+Pbbz8HpUFQVZuF0qDQETieX6s0tyCLL7UxLg4imnmFCEX1Sxgng/IVFhCKa7XU9tu8DQH33EE6HGlMqZh2XdDaIuO/lYziU4r0XzKcs10tbf8D2k6bWvgC5Xhd+ryvu7cU5HrptbEfe1BugMt9HvD5WNcX+Wd0O+kjbAB6ng+rCE9k2q7NeOsr1RkIRjrQPcGG++Z5fsvTkO5iBUxF9dNqQcbIuDMxzmFVPc9fB+g/Art9Al7HOb060Jbn95Xo7G3rY1djLuzbOQykVLV9t70vPe8Cepl7e8oOX+cIjezhnXgFPfPpSPnb54ri/G7PFpIGTUsqvlMq1vgauBXYDjwBWZ7zbgYfNrx8B3mt21zsf6DVL+h4HrlVKFZpNIa4FHjdv61NKnW9203tvzPeaUFtfgLufryU/y7jqk4lFsUKI9LGuIFofDkopNiwoSnPGaYj5JdmsnJNHltvJ1gwMP33pcAd3/HRLNPOQbk/ta6W+a5j/ue3s6GJ8t9PBvKJsW08aA6NhBoKhaOAM4HAoFpflpGUI7rFTOupZ1tcU4XQoNqcpgG/oHqYy34fLefJH+InAKT3rGwaCIX69pZ4bVldSmZ9Faa6XwGiEfps7DBqL88eW6VkKsz22rvFo6Q2MaQxhqSn2c3QWtyQ/3DbAghL/Sa+9ZWb2aX+z/b+Dh9r6GQ1rVnvNa/VjAierVK/PlteAVWFQGWkxNhTWwAUfN5pTvPQtIL1DcO/fdJwst5ObzzFWuFi/F+ko1Tv0+guU/mgNP2p/LzvLvsDP1BeY/9j74ekv2/7cmZRIxqkceFEptQN4FfiT1vox4CvANUqpQ8DV5r8B/gzUAoeB/wM+BqC17gK+BGwx/3zR3IZ5nx+bjzkC/CWRnf/mXw8SikT43BuWA5mp6RSG0fDsXgwoZoa2vhMzfCwbFxTR1BuIdrqz27HOQWqK/bidDs6dX5CRduiP72nhqf1t/M33Xkzr2hpLo7nG5px5BSdtrynO5miHff8P1sWxkpyT56csLstJS6necTMoPLVUL8frYtWcvLT9X9R3DVFVOPbEvcT8vUjXOqeHttbTHwzxgYsXACcuaLTZfLW7tS8wbpkeQLHf3sCpuWeYyoL4zz+/OJv+QIieIfvaoWfSobaBaHmsJT/bTWW+jwNpaEluzYqroREcbiNwieXJQbt8FKs+W8o1rTLRotEmcPkgpxzyKo0GFa/dD72N0Uyw3YFT71CQ53fs5+az50RHEvjcTvJ8rrSU6rXtfpYy1UP+8svIm7MM5XAZ5ZM9x21/7kyaNHDSWtdqrdeaf1Zqrf/D3N6ptb5Ka71Ea321FQSZ3fTu0lov0lqv1lpvjfleP9FaLzb/3BuzfavWepX5mI/rBC7VBEYj/HpLPe8+fz7r5xtdzSXjlBmvHOnk7P/3BH/e1Tz5nYWYBut3vCwmcDqvJn3rnE6scTEyDuvnF7GvpY++QHpPklp6jeGfhX4P7/7xZn65Ob0fVE29w5TkeE9qhQ1QU+K3dQCoVYIWW6oHRuDU3Bug3+b/h2OdQ2S5nScF7pbzFxazo743La+Fhu7hMeub4ERAmY5SvXBE89OXj7FufiFnVxcAxKyvsPciZmtfcMLAqdDvoXd41JYLeuGIprU/yJwJMk7ArCzXC4yGqe8eGhM4gbHOKR2lenub+/C5HRQM1kLxInCeUq6pFCq7hHJHvy1DcK2MU+5QoxG0WSVpF30KdARe/i4+t5OSHI/ts5wOP/wVXnF+iC8efSf8/qOw/efQecQomU1DqV6k6xhD+Mh62z3w9vvhfY/Ch5+Ht9xt+3Nn0nTakWdUS98wfq+LT1655ERNpwROabetrps77tvC4EiY/c3pG4AnzkztA2MzTsvKc8nzudISODV2DxOOaOabGYcNC4rQGrancYYPGB/eS8pz+MNdF3HR4hL+6fe7+MLDu9OW+W3sCUQXQMdaWOJneDQcvSqbalYJ2qmB0xLzRM7u7opGR73suPX7N62dw2gkwjeeOGjrPgRGw7T1B8e0Iof0rnF6al8rdZ1DfOCiBdFtVpmQnZ/FWmva+icu1bPKR+3I+rT1BwhHNBX58QO3E7OcMhM4RWyc31PbPojWxA2cllXkcaR9wPb3oH3NfSyvyEN1HIKSJfHv5C+h3DVgyxqn1v4AHqcDd1+dMXjXUjgf1rwNtv0UBtqZU5AV7b5ol+z6F2ijCE/12XDocXjk4/Ddc7mT36WlAss3UE+Hq+JE8HiGOG0Dp/5AiLuuWEyh30NelguP0xE9qRLpsbuxl/fd+ypluV7ys9xp66gjzlzWVbTYE2eHI33rnI6aJ0MLzA5y58wrwOVQaW8Q0dJnZJzyfG5+8r7z+NAlC7jvlTq+/8zhtDx/c89w3CvudnfWi2acTsn4WB2+DrXae8XbmuEUz6q5+bx743x+9sox9jT12rYP1oLz6qKxx9/ndpLrdaVljdMfXm+kPM/LdSvLo9tK01Cq1z00ymhYUzFBxik6BNeGBhHW8Nt4Fw4AqouyUQqO2ViyGo/Wms/9dic3fvdF257Davk/XsZpNKyptfHihdaavU19rKrMhu6jULIs/h39pZQ67CnVa+sLUprjQXXXjS0TvPjTEBqGXQ9Rme+zt1QvEmHu0D4O5J4Pb/sF/MMRuOtVKFrEysgB20v1tNYUjDQxmF01+Z1nmdM2cHI7HbzvwhrAWCBemutNWxcRAQdb+3nPPZvJ87m5/0PnM68o27arzEJY2gcCFGa78bhOfuvasKCI2o5B27POdWZAYHVVy/a4WDk3ny1pHIQbjmja+4PRK95Oh+Kfb1zB4rKctCzO1lrT1DM8ZoYNnAgobQuczP/fYv/Ja5yqC7PwuBy2rnMKRzTHO4fGNIaI9ffXLqPI7+Ff/rDbtiv/VkOQeBknMLKx6biIeLRjiBWVeSc1CcjzufC6HLZe7T4xw2mCwCnbeH3YkXFoNrMI4zWH8LqczMnPSvssp5+8dIwHttSzr7mPYZsGvx5u7cehTvyex1peaTaIsHGdU2PPMH2BEBvyeiASGtsYwuIvoVD32tYcYnFuEEb6xwZOpUvBXwatu82M07BtZcv9TfvJY4DRynXGBqWgdBmUr6Qi3Exbf9DWBiUd/UHm6DYiBfNse46Z6rQNnMpyT66vT9eHhTDaMb/rx5txOx3c/8GNzC3IojzPd8bOsxHp09YXjLu+5Nx5xjrHnQ09tj7/sc4h/B7nSc0JzptfyOsNPWkbdtgxECSix544lud501Ke0TccYnAkHPeK+5x8I4Cxq0ypYyBIrs81Zm2Vy+lgYYk/OmPGDi19AUbCkTGtyGPlZ7v5/BvO4rXjPTy4tX7c+02HNfw2XsYJjGys3c0htNY0dA1RXXRy8KaUoizPa+vV7pYJht9ainLszDgZx3+8NU5glOulc5bTS4c7+M8/74u+Nzb22PPch9sHmFeUPeb3D2BhSQ4uh7J1ndM+88LQSo/Z0W6CUr28SC+dNrwftvYFOMtnVhicGjgBlK+A1j3MLchicCRM37A9HSZb9hqZxdzFF5x8Q2ENBcEmRkMh254boK7hOH4VxFuy0LbnmKlO28Apy3PyL25prlfWOKXJ1x7fT3A0zP0f3BgtzSm3+cNSCLCG38ZZW2NOsbf7ZOVY5yA1Jf6T1rict6CIkVCEXQ32lWfFajFLhU4tVSrL9aXld9AqFYuXcXI4FPOLsu3LOA2OUJoT/4TZ7pbkVrbx1I56p3rLuXPZUFPEVx7bb8sV7/ruIdxOFff3AKAk12P7Gqfe4VH6gyHmFY09FmW5PltL9drMwGm8nx9iMk42HP+mngBZbid5WfFnSEF6Zzkd7xzirl9uZ1Gpn6/fuhaA+i57SsQOx+moZ/G4HCwqzeGAjYHT3qY+lILqcIOxYdzAqRSPDjI81J/yrEtbX5BFLrN7ZrzAqWwltO9nTr7xGrRrltPIsVfp11ksOuvck28oWoBTj1JBt60X0tqPHwCgcO44/wez2GkbOHlOmV8hgVP6HGjp58JFJSdNDi/P89E1OJK2q+7izDRexqkw202uz2V7eUxdnFItq6vnljTNc7KuuJ+6ON3qpGT3/JjoFfc4gRMYZTx2luqd2hjCsrDET2P3MCMhexan15klcvPjlCnFUkrxpTetYiAQ4qt/2Z/y/WjoHmZugTFsOJ6SHK/ta5yOT1AuaA3BtYtVEj7hHCdrjZMNgVNzr9GKfKIBnzXFfnqGRumxcQgvwGAwxJ0/30okorn7Pes5q8L4TLZjNEMoHOFoxyCLxgmcwCjXs7NJ1N7mXhYU+/F0H4a8ueDNjX/HbGMIbk64m6EUli0OBkP0B0NUq1ZjQ+H8sXcqXwmhADXKyIo129RZL7fzdQ44l1CUe8r7sBnMzVNttl5IG2w9YjydBE6nj1M/NEpzvHQOjsg8IZuFwhGOdw2xoPTkk4fyNHRTEmc2rbWZcRp7wqSUMq/y2pdxCoUj1HcNRbtmWYpzvCwq9aetQcR4azzK8nyMhCP0DtvbDtta8DxnnK5iC0r8HO8cImzDGp+OgSAluZ64t1UXZRPR9s1OOdY5iMfpmLApgWVZRS4fuHgBv95az7a61L4uGrqGxl3fBEbg1Ds8alsACScyGvHKBY3Ayb7Pgda+AEV+D17X2HIxi9vpINfnsiXj19wbmLBMD4g2EKmz8f1Ia80//GYHB1v7+d47z6WmxE9prhevy0F9d+p/B+q6hhgNaxaXjh84LavIpak3YFtL/r3NfZw1Jw86Do6fbYLoENwSUjsE13pdl4dbjLVMnjgXUcpXADA3eBSw6f1oZIg5wSN05K8ee1uh0eVynqPV1gsYka46ABzxgsdZ7rQNnE5lXX2yYzGoOKGhe5jRsGbhKVddy8yTiXSsczrQ0s9/P76fTlnTdkbpC4QYCUXiZpzAOFk5ZlOmA4ySi1BEx13jsmFBEVuPddnaCtjS0hvA7VRjGiScmKFj7+9FY4/x/ONlfmpK/IyEI7acMHQMjIz7vFbZWL1Ng5DrOoaoLho/03Oqv71qCaW5Xn74XG1K96Ohe3jc9U1wouNkpw0zbCzWMT51jRMYnwX9gRCBUXuqD1r74l88OZVdQ3Cbe4ejA07HY5Ww21mut6uxlz/vauEz1y7j0qVGoKCUYm5hli0ZJ6vxSmylyams84LjNgSMfYFR6ruGWVGRCx2Hxm8MAeA3Mk5Fqi+lZavW+U1hsCl+mR5A6XJQDvL6DuJ2KhptaEnef2wrLiJE5q4fe2N+FVo5jYyTjSWz3oF6+p0F4B0/kJ6tZk3gZNW9S8bDXrUdxpvnwlMzTrlW4GT/8f/l5jq+/8wRrv7Gc/x2W4PtpUliZmg3r56NFzgtKPHT0D1k25V2K5sVr6vaeTVF9AVCHLRxjY2lpS9AWa4Pxykn8NbJpN0XL4wTx6wxz2+xq7PeSMjIpo0XOFkn8VYZWaod6xycsKPeqfxeFxtqilLaIn0wGKJzcGSSjJM5BLffvouI9V1DFGS7yfO5x9xm/X7addLW2heYsKOepdCGwGk0HKGtP0jlOGWqlnlpaEm+o74HgDedM/ek7dWF2bascbICp0Wl4/8OWK/Leht+B62OoWcXDBsd7RIInIqVPRkn/1DD+IGTOwuKFqLa9lKZn2XLBaT2fS8BULzswrE3Ot1QUM1Ch32lekMjIYpHmhjMnjv5nWeh2RM4pWli+ZnOmtGwsOTkqwzWeot0ZJzquoaoKsxiYWkOn3loB+++Z7OtmQYxM1gfAuNnnPxEtH2Lca3X2KmlemAETgBb07DOyThxHHsMrJNJuyfGN/VMfMV9gU1X260MyniBU3meD4/TYUvgpLWmrnNowo568Swq9XO8ayhl2RfrtV1VOEHGKdf+IbjHu4aoHid4K7P5s3i81/+pirJTHzi19gXQmkkzTj63k8o8n61rLnc29FLs94wpma0qzLIl63q0Y5CyXC+5cYJlS7WNWV+rzflyt9VRb4LAyVzjVEJqZzm19QVwEcI10Dh+4ARQZnTWm1NgzyynSP0WjkdKWb5oUdzbVWENC1zttp2P1bYPUq3aieSfeWV6MIsCJ6tULFMZpzMl61HbMUhBtju6+NZSmO3G7VRpyTjVdQ6xpiqfhz58AV960yp21vdy3bee5697W21/bpE51u/2eGU6Vrczu8pjjnUOku1xxu3qVlWYRUG2mz1N9i2MtrT0BsY0hoAT5cp2l+o19QSYO8EV97JcL9keZ8oHYVoZlOKc+GucnA5lnDTaEDi19wcZHg3HDZonsqgsh4hO3VoX62eLVyJnSUf1xUTlgla3Ozteh6FwhI6BYEIZpyIbMk5WR8vJAicwLuTYXaq3uip/TJOK6qJseoZG6U/xOqOmnmHmThCwA+RnucnzuWzJeNV3DeF1OSgaMtYOTRg4ebLRHj9FKc44tfYFWODuQunIxIFT+SroPkZN7omByalU1LOTg+7l5GePE8QWLqBKt9r2WXCkrZc5qhNv6ZnXihxmUeBklSdkInB6cGs9G//zKQaD9vXMnymOtg+OWd8E5vyOXF+0VaxdwhFNQ/cQ84r8OByK95w/n79+5jKK/R5+bdPcFDHWtrou9jT1pvWCQXs04xT/pCW6rsCm7KOVcYjXTUspxVkVeeyzsaOUpbUv/oljtsdFjtdla9Y3HNG09AXG7agHsY06Uhw4DUyccQLjpNGOkzarTDP5jJORmT/Snpr5UieG306+xsmuuYaRiKaxe3jcjJOVEbbjs7hzcCTuDLN4ivweuoZGUvoe1WSeBE/0+rfYOctpeCTMwdZ+1szNH3Ob9dpoSHGDiESaYoD5O2hDxqmh2wjcVMch8OZBbsWE91f+Usoc/SldC93aF2SNv8f4x4SB0wpAs8rdTEtfgFAqm5b1NVEUaqenaM349ymsIU/3MdRnT8Oitvpa3CpMXmX8jNdsN2sCJ6/LSX6WO+1DcNv6Anzpj3tp6w+m/ArrTFTbMcCCkviLAcvzvLTaXCrZ1GM0p4idpVKe5+OceYW2zo8QJwRGw7z97k3c+J0XufArT/PPv9/F0/tbbVsMbmnvD+JxOcjzxZ+fUuz3kON12dbJ6ljHIAsmyDicVZnH/pY+W7rJWQaCIQaCoXE7u5Xl2TuWoa0/QDiiqYwz/DbWghJ/ygNY6719vDlOYHR5m26pXudAkFt/+DKfeXAHD7/eSMdAMFpyNdkMp1NZa0GPpGgwb0P3MF6XY8JjkOVx4vc4bSvVa+03BgGPl/Uq9ntwOpQtpXrjdZSMp8jvYSQUSWk76maz7CqRjFNNsZ+uwRFbulzube4lomF1VcGY26yANpWBk9aapp7huEOv4z2/HVnfxh6jDX+0o94E7eAByC6hwtWf0lK91r4AyzzWDKcJytTKjM56izlOOKJTmvnpP/wKAM55G8a/U5HRWc/bfzxlzxvLakXuLl5gy/ef6WZN4ATGlS676/tP9f8e3Uu/mWmq65rdgdNgMERrX3BMYwhLeZ4vWspgF+ukeN4pJzDLKnI53jXE0Mjsz/plWmtfgNGw5s3nzGVtVQF/eK2RD/x0Kxf811MM2Jh1bes3ummNNz9FKWV01rOhPCYUjlDfPfEalxVz8giMRmwtz4kOvx3nxM3uGTpNEwy/jVVTkk1993BKx0NEM07jtCMHY1F+7/AovUNTP1l9en8bW45188SeFv72gddZ/+W/8uU/7cPpUAllGmJle1zMLcjicKoyTt3G+s6JZgiB8Vlo1ywnq2PaeIGTw6EoyfHY8llsvf4TWeNklZOnslSruTdAjtc14Tofi/VeYUeHuR31xrDtNVXjZ5xSGbwYMxojVCaUccqioXs45dUIjd3DRvOJjoMTl+lZ/KWU2NAcYoGzHZweyK0c/46FC8CdTdWI0VEzleucug++TFC7qFh23gTPXwNAaajFlkqoSNexk57nTDOrAqeyXG9aM07PHGjjTzub+chlRrrSzpkNM4HVJSteqR4YgZPdgasVnJ56ArvUbJF6sDU1JyhifFbN9lvXVfHD96xj+79dw7++cQXdQ6O2Dj9s748//DZWTXHqMx1grOsZDWsWTBA4nVVpvAbtLNezrriXjVOuWJbrs3WdodVad6I1TgALSnIIR3RKT946+kfI9jjJ9sTPOEJqWpK/UttJkd/Da/92DQ/fdRH/cN0yllXkctOaStzO5D8yF5XlpKxUz1hbNHnWqyTHS4dNmUdrRlD1BOWCZbk+W9ZXtFpzdBLIOBXbEDhN1hgllrUezo4LKbsaeynP88Y9DkV+D9keZ0ozTs3REsUEMk5F2QRDkZRmvodGjG6SC3LD0N+cYOBUQiF9KRtRo7WmtS/AXFqhYB44xp8jhsMBpcspGjwMpLZhkbNpO3t1DSvnlY1/JzOgma9Sv84pHNF4B+uJ4ID8qpR+79PFrAqcSnPtLVOJNTwS5l//sJtFpX4+fc0SSnK8tlxZmklqrcBpnAF45Xk++oMhW9d6He8cwuNyUHnKB8Zyc2L6gRb715jAmdMMJJ5Tsx5el5PrVpYDsN/Gcsm2/sCEJUpgnKw0pDjTASdOfuZPUKq1uCwHl0Ox18YGEZNlnMrzjIyTXa/PREuVFthw0tgxEJxwfRPEdPWaYsCmtWbTkU7OX1iEy+lgbXUBd12xmAc/fAHfevs5U/qei0r9HGkbTMmMr3qzo+hkSnK8tpXq1XcNoRQTNgqwawhuW18Ah2LMDLN47Mg4tfQFJm1FbplfZN+ay50NPayeWxD3NqVUyjvrJZpphhOlgnY8/1JnAh31LP4S8sI9dKXo92AgGGJoJExpqDmxTEv5SrK69gM6dQ0iwiFK+vdS6z0r7iiAKF8+o95Cc5ZTaisQGrqHmKPbGM6qMFqfn4FmV+CUYwRO6Tip/fZTh2joHuY/37war8vJvKKsWV+qV9s+gFLjnzyWp6Gr17HOQaoLx86QmVeUjc/tsPXE3fLq0S6W/stfeM89m/nd9oYzoilILOtDIHadzdyCLHK8Lg6mcGbNqdr7g9HOceOZX+wnFNEpbwEbXeMyTrYVjABycVmOrRmnlr6xxz5WWa6PwGgkWj6cak09w+T6Ji9VstZBpnLdpxE4TXzCPN1ZTse7hmjqDXDBwuIpPT6eRaU5DI+GaZ7mCUzv8Ch9gdC4TRlileR67AucuoeoyPPhdY1/xd1Ya2fPGqfSXC+uBDJ/9mScAmPaf48ny+OkIs+X8gYR/YFRajsG45bpWaoLs1OacWqKXjBJrFQPSGmTFutnmR8xG0AlWKrnJMzoUGoaJFiZ/PzABMNvY5WvRA13ssA3mLrPo7a9eHWAgdKzJ71rKH8+82zIOB1pHzBbkc9L6fc9ncyqwKksz8vwaNjWdRZgzBP48Qu13La+io3mB+z8Yr8t3ZxmkqMdg8wtyMLnjv+BaZUN2NnVa7xZKg6HYml5rq0n7pYtx7oYDWuOdgzydw/uYP2X/8rfPvBaWp7bbqFwhB8+d2TCYLCld5g8nwu/90TJlFKKpeU5tgWuI6EI3UOjlOZMfNJiDShN9cnK0Y4hstzOcVuhW1ZU5rGv2b7XQWtfgDyfiyxP/N/BaEtym34HGydpRW4pzDbaEqc745Tnc1OQ7Z5y4PTKEWPh9wWLUhc4LS4zO+tNs0FEQ7fVUS+xUr3uodGUZ17ByDhNFryV5vroHBxJbTcxxu8oGU+qM07BUJiOgeC42d545hdnp3yW056mPrSG1RMETlWFWTR0DaXsInJzbwCP05FQps+OIbhW4FQaPA4OV7T5wYT8pcZfod6UrH1u6B4ijwE8o32JBU5mg4jz/S0pC5z6jhiNIbw1Gye9r7NogZFxSnHgdLhtgHmqDU/pmdkYAmZZ4GRnG1SL1pp//v1u8rLcfP4NZ0W3zyvKpql3mGDI3s5imVTbPhgdbhmPlXGyK3DSWnO8a2jcjNey8ty0dNY70j5AeZ6XF/7xCn7zkQt4y7lzeWpfG//4m522P7fdXj3WxVf+sp+/7ht/JlZTb/x21Msq8jjY2m9Lxte6ej5Zxim6riDF5TF1nYPML86edFH+WZV5tPQFUj4/xjLeDCdLdIaOTeucmnuHEyrXUUqZnfVSuMZpYCQ63HUi84qypx441XZSmuuNthFPhVS1JLdOHsebnxTLCjDteB3Wdw1TNck+lOV60ZqUN6ho7QuMu77vVLleF26nomsoNfvQ2mv8TiXSkttiR1v+XQ1GY4jVcVqRW6qLsukPhugbTs1F5KbeAJUFvjGVHvH43E5Kc70pLdVr7BnG7VT4+2uhaGFiJWLZxsWPYnpTss7p1aNdLHB2GP9IMOMEcLanKbo2dLoGj2yiQ+exYNFZk97XXbqIuaqDjt7Urvuua+miTPXgLTkzW5HDbAuccuwfgnuobYBtdd188srFJw2BnV+cjdapn50wU2itqW0fmPCEoszmjFP7QJChkTDzx1kcvawil46BEdtKVCy17YMsLMlBKcX6miL+482reft51exrtrcVdTpYpVUTXS0c7+R9eUUuPUOjtpRqRmc4TZJxKM0xhq+m+mTlaOdgNJs1kRVz8gD7GkS09gUmvOJu9xDcZBbHLyjxRxvKTFcoHKF7aGTSjBMYJ41TeR/WWvPKkU7OX1g8aYCcjJIcD3k+17QDp+jw2wQzTpD6z8JgKExrfyDahGM8VmY21R0ejdf/5K8BMIL3wmwPXSkK3pp7zXK1BBokWGpK/HQMjKR0GO3Oxl7mFmRN+LsQ7ayXouClOYnfezAah6SyAqexe5jK/CxUoh31IJpxKlZ9KWlJ/vKRTi4uMX+HEwmc/CXgL2OJOp6yjJO3ZTuvRxazMk4b+lOpwhpcKsJoV2rnWw6YrcgnbMc+y82qwMnukwYgeiX++lUnt6K0siCztUFEe3+QwZHwhBmnXK+LLLfTtq5exycZQrm8wjhpPWhj1skKIE9tyb6sIpdgKJLysox0s050JzrxbO4NxP0QtTob2pH1a4sOv534pMloSe5PaYdLqzvcROubLGdV2hs4tfQFxl3fBCdOWO24eDE8EqZ7aDThltw1JX6aeodTMt/LGGQKpZOscQJrfcdQ0hcxajsGaesPpnR9ExivyUVlORyedqneMH6Pk4Lsya+2l5ot21N9EamxexitJw/erItoqcx8BkPG6y/RUj04MQQ3Fay1nYms87FYc79S+X60s6FnwvVNcKJcriFFgVNTz3BSmbZUD8Ft6B5iXr4bumqNGU6JMAMnoyX59F6HfYFRdjb0sLHAfF8vSDBoKF9J9egxeodHp38RabiHouFjHM9eQY53/M6iUWY5o6v32PSeN4bWmrDVijzRYzALzarAqdSmq2yxntrXxqq5eWOuuFuLkk/3E+fxHGm3OuqNf/KolKIi32dbxqkuGjjF/9BeWmFkw+xsENE5OEJfIDSms6B1wpyO5hR2st7cx/vQGwlFjDr/vHilevYFTtbv9GSlemCcrKQy4xRv6PJ4ivweyvO8tnTWC4WNFr8TlerleF1ke5y2XDxqMq+4J7LGCYyMk9ZTb9QQq6PfOPlNJOM0ryib0bCONtJIlB3rmyyLS3Oi76FT1dA9RHXR5OWicOI4pbpUzvq/nKwl+omMU+peh1YQNtGFg1MV+T10p6hc0Xr9J5N5sS62bD2WmgYFvUOj1HUOTbi+CWI626Ug6xOOaFr7g0nNMKsuzKa5N5CyNW6NPcOs8XdDJAQlyxJ7kFmqV5SCluSba7uIaFjq6TS+ry8vsQeWr6RkqBa3Q/PAlmkOo216DYBgeYLdPc2sWNZA6jJOXYMjFI00md9fAqdZIT/LjdupbJvl1DU4wvbj3Vy1vHzMbVaJ0PFZ2iDCOqGeKOMEZhtamzJOdZ2DONT4i6NLc7wU+T22rnOqHSeAXFyWg0PNosBpnNexFRTHO3ko8nsozfVywIYmGVbgVOxPIHAq8VPfNZSyD22rxCqRjBMYQfReGzJOHQMjRPTEM2yUUra1gm5KsBW5xXqvqE3BDKMTw28TC5wg+ez/K0c6qcz3JRQgJ2tRWQ7t/UF6h6destXQPZxQK3KIDZxS+zqoT3CdlfX8Uy3V01qPWStpfa9ELp5YCv2elK3zau4JjGmKM5ll5blsWFDE1584mJJmCbsazcG347Qit+Rnu8n1uVKScWrrDxCO6KRKFKuLsghHUtOGOxgK09oX5Cx3s7Eh0VI9lwfty09Jqd7LRzrwuhyUJdqK3FK2AhUO8PaFo/x2WwMjoal/JvUc3gRA3sIJBt/Gyp1DSLnJDzRM+TlPdaR9kGrVTtjphZyx58FnilkVOBkTy+2b5fTM/ja0hqvPGvuCUUqZi5JnZ8aptn0Ar8sxabq+PM9Hqw1taAHquoaozM/C44r/slVKsaw8l/02drezTgIXlZyccfK5nSwo8ds6ANZuo+EIx7uGcDoUTT3DcUudou2wxzl5Xl5hT4OOtv4ARX7PuP/3sWqKjYxDqmZnvHa8B4eClXMSu8q4ojKPI+0D0/qQjGeyVuQWYwhu6n8Hk5nlAicuJqSiy2A0cEow4wTJre/QWrOptpMLUry+yWKtDZ1qEKm1Nmc4JRbU+c2y6VQPwW3oGsLjdFA+SYMGj8tBkd8z5QD+Mw/u4C0/ePmkix9WCXgypXrFKS3VS6wxSiyHQ/E/t64F4DMP7Zj2GtidjT3AxI0hLFWF2dFAdzqiv/fJlOqlsLNes9lYYb5uNDaULE78wf5Syhx90w6eXz7cyXk1RTh66pILnMqNznpvm99Hx8DIhE2XJtN7eBNHIpVcuCrBn9/hoN83h/Jwc8qalkVbkefNAxveJ08XsypwAvsG7wE8tb+V8jwvq+bGP4GaV5Sd0lrmmeRoh9FRb7KuOuV5Xlr77BnAWdc5FO2aNp5lFbkcau1PybDJeGo7BvG4HHGHPy6vyLMl25Iu9V3GupBzqgsIReKXOp04eY5/8rK0PJdDbf0pb5LR3h+ctDGEZX60JXlqLmJsP97N0vLcSWcXWc6qzGM0rDnUltrXwmTDby3GDJ3Uvwc29gRQavLnt2R7XCwqzWFPU++0n/tE4DT5GqfKAh8OldxJ28HWAToHRzjfhjI9ONGSfKrrnHqGRhkcCSeccQJ7ZjnVdxsDeBPprjbV6oO6zkF+/3ojrx3v4acvH4tut17/yQROhdkeeoZGU5J9Hm9t52Sqi7L5wk0rePVoF/e8WDutfdjV0Mv84mzyE1jnVl2YlZKMU5MZuCRVqjeFixfjaTQ/cypG6iG3EnyTB40W5S+l3DkwtlQvmPh7c3t/kAOt/Vy0MB9665Nb21O6HJSDFc4G5uT7+NWrUy/Xy+3cxVHvskmrfmIN58xjnmpL2efB4bYB5jnacRWfua3IIYnASSnlVEq9ppR61Pz3AqXUZqXUYaXUr5VSHnO71/z3YfP2mpjv8Xlz+wGl1HUx2683tx1WSn1uOj9Qaa49Jw0joQjPH+zgyuVl416RnF9stMG166Q9k2o7Bidc32QpzzMGcKaqDWqsus5B5hVNvA/LKnIZGgnb1t2wtn2AmuJsnHFOHJZX5FLXOXTaDsS1yvQuXWosqo134nni5D3+h+iyilwCo5GUrGuJ1ZbA8FuL9cGSillOkYjm9eM9rJtfmPBjTjSISG3gZGWRJjtxLMv12TLHqblnmLJcL+4Eho9aVs3NZ3fj9LOwHQMjeF2OhBZFu50O5hRkJfUafOWI0WY41Y0hLNWFWbidasrrnKwT0MnWFsUqzfHassapKsF9MD6Lk38d3vvSMVwOxXk1hXzjyYPRizWt/cYsocIEggZLsRlo90yjRBIgMBrmeOdQ0hkny1vXVXHdynK+/vjBaTWO2dnQm1C2CcyMU9fwtC9iTqWbYGW+D6dDpWSNlRX85Q8m0RjCkl1MiaOfztjmEANt8I0V8PBdkMCxeaXWWPt4WcWoscYqmYyTOwuKFuFo28tt51XzwqGOKWXhelvrKIp0wtx1ST0uUlBjzHJK0efBkbZ+5qs21Bm8vgmSyzj9LbAv5t9fBb6ptV4MdAN3mNvvALrN7d8074dSagXwdmAlcD3wv2Yw5gS+D7wBWAG8w7zvlNgVOL16tIuBYCju+ibLvKJsgqGIrV39MsEq4VpYMvlsk+gQ3BSX6/UFRukeGp10/YHVoGB/iz0lc1Yr8ome+3QdhJtI4NTcGyDX6xr3BHaZTZ31ksk4leV68bkdKZnldKhtgP5giHPnJR44LSjx43M7Ut5Zr6UvgNupJh1CWZbnZXAk9YPAm6ZQqrRyjjHXarrvyR39xvDbRMvokp3l9EptJ1WFWUkFJslwOR3UFPun3JLcOgFNKuOU4019xqlrmOoE96F0CtUfvcOjPLS1npvWzOEbt51NRGu+8MgewGgOUZaX+GsAjIwTnCj3mqpfbKqjPxjib9bOmdLjlVL855tXk5fl5tO/fn1KpVOdA0Eae4ZZm0ArajDWGQ2PhqddptbUEyDH6yIvwYw7GK/3ynxfajJO3cM4lMbTczjx9U0WfymFupfWvuCJC9o7HoBgH7z2C3jua5N+i5cPd5Drc7GMo8aGRIbvxipfAW17uW19NQ4Fv96SfLOGfVufAWD+6kuSepyzeAG5apjujpaknzOe1rYW/AwlFzzOQgkFTkqpKuBG4MfmvxVwJfAb8y73AW8yv77Z/Dfm7VeZ978ZeEBrHdRaHwUOAxvMP4e11rVa6xHgAfO+U1Ka66NrMJjyUqG/7mvF63Jw0eKSce8zzywRSvQDu75riNeOd6dk/+x03CzhSiRFXG7TLKfjk3TUs1gtse0IXqIB5DiZN6sd+unaIKK2Y5Aiv4ezKnNRKn5L8skGsC4pz0Gp1AZOWmvaB4KTtiK3KKWoKfanpMPldvP389wkMk5Oh2JZRV7KO+u19hrDPxMplwVSnnVq6ok/+Hgiq8yr47unWa7XPhBMqEzPMq8oO+Gr3ZGIZvPRLtuyTZbFZTkcmWKp3p6mXhyKSecnxSpJ8UXEvsAovcOjCe9DWa6P9v5gUhUYv95ynMGRMB+4eAHVRdl86uqlPLm3lcf3tEw6wyyejQuL8Lgc/GoaHc2GRkL88LkjXLy4hI3TeI0U53j56i2r2d/SzzeePJj043eajSEm66hnsdbDTXedU1PP8Lil2ROpLsxOyRqnhp5hVuYOo4L9iXfUs/hLyY30cqC5hzf/70tsPtIBr98PVefB2nfCs/8Jr/9qwm/x0pEOzl9YjPPVuyF3Dsy7ILl9mHMOdNUyZ99PuGxJCQ9urU+6dLTn0CZGcbFo9flJPS6rwlgPFWw7nNTj4mnvD+LsNX+PJOOUkG8B/whY/9vFQI/W2rqk2QDMNb+eC9QDmLf3mvePbj/lMeNtn5LSXC8RbVydSRWtNU/tb+XixSVkeZzj3m9+ki3Jv/joXj7+y9dSso92OppAK3KLddKW6llO1nqVyUr1crwuqouybAlejncNEYroMa3ILVWFWfg9Tlu7+tmptn2ABSV+vC4nFXnxrxY2900cOGV7XMwryk5p4No3HGIkFEk4cAIjwE5Fqd62um6K/J6kO62tqMxlX0tfStf6tSQ4/LPMXLifysy31tqc5ZLcCZQ1EHhP49QDp0hEs7epL6na/uqibDoGggyNTJ5129fSR8/QqC1tyGMtKs2hrmso6aYhWmv+sruFCxYVJ7zODoyMU9fQSMq6S9Yn2IrcUpbrJRTRCZfJhcIR7nu5jo0LiqIB9x0XL2B5RS7//sge6jqHEh5+e2IffLx1XRW/2dow5QsJP3+ljo6BET59TZJlYnFcdVY5t66r4p4XjiadDdzV0ItKokmN1flwuuucjLVdyZcoVhdlpaQ5RUP3MOv97cY/ki3V85eg0Hz7b+bT1h/kv358P7Tvp23xrXDTt2HBpfDIx6H2ubgPr+8aor5rmJtK2+DYC3D+R8CZ+O8gABs+DGfdBI//E1903UNX/yBP729L+OGB0TD53btoy1qEw5Pc/0NuhXG8ItbspWnYcqyLamX+P5zBM5wggcBJKfVGoE1rvS0N+zPZvtyplNqqlNra3t4e9z6l0TaoqTtpONw2QH3XMFeeVTbh/eYWZuFQiWWctNZsq+umvT9oSyOFVKrtMK6SJlKqZ520pTrjNNkMp1jLyu3p7DZeK3KLw6FYWpFr2/BTu1kNQMAcIhrnin0iE+SXleemtFSyfcB4LSUTONWU+DnemfwQ1FNtP97NufMKku60tqIyj56h0aRnCU2kZZKg1WLHENyuwRGCoUjSGac8n5ua4uxprXPa22y0E7ZKSBMRXZyeQNbJzvlNsRaV+QlHdNKdV/c293G0Y5AbVydXJlaa40FrUtZVLho4JdjZ78RA+sReh4/taaGxZ5gPXrIwus3tdPAfb15NS1+Axp7h6OdLMu68ZCGhSIR7Xjqa9GMHgka26dKlpaybX5T04+Puz6ULCUU0f3itManH7WzoYWGJP+HguSpFs5ymk3Fq7w9OewB2Y/cwKz1mN7qkS/WMCqGbFrt55u8v58s1OxjWHq55ophPPrSHbed/F128BH79HmjbN+bhL5trHy/v+jV4cmHd+5L/ATzZcOvP4OJPU137a+7P+joPbxr7XON58WAbKzmCqkpufROAs6gGSM0Q3FePdrHIZZ53S8ZpUhcBf6OUOoZRRncl8G2gQCllLXSoAqx3gUagGsC8PR/ojN1+ymPG2z6G1vpurfV6rfX60tL4H6LWyVUqZzn9dZ9xdWCi9U1wYlFyIp31jnUO0TU4wkg4wuBIalpF2uVoxyDFfk9CnXyyPE7yfK6Ulwkd7xyiJMeb0AyNZRW5HO0YTFkLTst4rchjWZ31ZnowfKrBYIjWvmA0cKoqGtuRaTQcoX0gOOnVx2UVuRzrHJr2B6bF6syVzElTTbGfkXAkurB5KroHR6htH+ScJNY3WawGEaks12vtTaxUqcy8TyrLtKbSWcuyam7+hKV6X/nL/ugJSjzPHTQ+rC9ZknjgFJ3lNMlFrK7BEf64s5ma4uwpXVVPxuJSo4z4cFtygdOfdjbjdCiuW5nc3JToLKf+VAVOic1wskQznwlWH/z4haPUFGdz1fKTL1Cum1/IOzfMA5LrqGepKfFzw+pK7t90POk5Wve9fIzuoVE+ffX0s02WJeW5rK0u4KGtDQl/ToyGI2yu7eK8msSDtxyvi8Js97QyToHRMJ2DI1PMOBm/g9N5/lA4QktfgIWqCTw5kJfkGjO/+Z4x2I5PB1nV9SRq5c289cIVPHOgjVvu3cN7An/PEB4iv3grDJ78PvTS4U5W5fSRe/iPsO72pDr6ncThgKv/HW7+PuvZy6frPkZr3f6EHvra61vIU8OULb8o+ef1ZNOpisgenP4sp81Huzg7tw+yCqd+HGaJSQMnrfXntdZVWusajOYOT2ut3wU8A7zVvNvtwMPm14+Y/8a8/WltvDs8Arzd7Lq3AFgCvApsAZaYXfo85nM8MtUfyLra2p7CUrGn9rWyam5eQld75xdnU5dAxml73Ym1TV0p7nyUakfaB5MqkynP86X0SjsYpXqJZJsAllXkEYroaIYoVWrbJw8gl1fk0jM0mvJSRbtZjSEWWoFTYTbNfYGTyora+oNoPfkA1GUVuYQjesoL4U9lXQRJtlQPmNZ4gNfqjd/RZDrqWZZHO+ulJnDqDxjtqCeb4QSQ53PhdTlSmnVvMgPQuVMMnBq6h+mJk/k41jHID587wrf/emjcxz93sJ0VlXlJ/f9HZzmN816steZ32xu4+hvPsaexl49ctijh7z1VVqY6md8LrTV/2tXMhYuKKU6wOYrFGhacqgYR9d1D5Ppc5GcllvGwPosTeR1uq+vm9foePnDxgrhr+P7x+uVcfVY5lywZf43xRD5y2SIGgiF+saku4cf0B0a5+/larlxeNqWLJxO5dV0VB1r7owNtJ7O9rpv+YIjLlyV+8QCmP8vJ6qI6lQsmVoA9nYxXS585fDdUb5TpJTs7KCZwYv+jEOzDd97t/OsbV7D5n67iq7espttdzq19n2Kkr5XO+94NEeOCn9aal4908pncp1EAGz8y5Z8j6px30/nmX1Omuul/5LOT3j0c0fQd3gyAq3r9lJ6y0zOHwmBy2c1T9Q6Nsr+ljyWezjO+TA+mN8fps8DfKaUOY6xhusfcfg9QbG7/O+BzAFrrPcCDwF7gMeAurXXYXAf1ceBxjK59D5r3nZJUZ5y6BkfYfrx70myTZV6RP6EFkdtimkKc1CpzBjqaYCtyS0W+L+WBw/GuoYQDp+UV9nR2q+0YmPQ4LE+iq5/Wmm8+eZBtdV0p2b/psAKnBaVWqV4WWp+Y2wTQYp48T3YBYVmKG3TsbOjF6VAJzw8CI+ME05vltL2uB6dDsSbBxdixcrwu5hdnp6wleeskg4djKaUoM+eppYr1OpjKHJtVc4zjtydO9s0aCPnqsa64+9sfGGV7XTeXJXnCWJjtxu9xxs041XUO8p57XuXvHtzB/OJsHv3kxbzdzGjYye91UZnvS6pBxJ6mPuo6h7hxdWXSzxfNOKXos/B41xDVhdkJl60mU6p3z4u15Plc3HJuVdzb87Pc/Pj29dG1T8laNTefy5aWcu9LRxPOhN/70jF6h0f59NVJlocl4Ka1c/C6HDy0NbFMwDMH2nE51ITNqeKpjlM5kIwTw2+nVqoH05vl1GgGfUVDR5Mv0wPINo/XYKfRRa9gPsw3MjfZHhdvO28ej37iYr700XfxA//HKG57hZd//GlC4QiH2gYIDnRzcf+fYNVboKB6gidKXNmaq9nsv4q5na+gRycOKrfVdbNo9CAhV3by67tM/VlVlIaap/RYy9a6LrSGsnDLGV+mB0kGTlrrZ7XWbzS/rtVab9BaL9Za36q1DprbA+a/F5u318Y8/j+01ou01su01n+J2f5nrfVS87b/mM4P5HM7yfW5Ulam8uyBNiIarppkfZNlfnE2XYMj9AcmLgnYXtcdnUfRnaIadDv0B0Zp7w+yIIH1TZZUz5EJjIZp7g0wf5LGEJYFJX7cTpXyBhETtSK3JNNZ77fbG/n2U4f4zIM7GE1iAbfWmmcOtCX1mMlYgZMVcMQbYNhsXn2crGyjpsSPx+lIyfEfCIZ4cEs9N6yuTGiGj6Uiz4fXNb2W5NvqujmrMpdsT+LPG+usijz2pijj1NJrvJ8lWqpUnuub0vDR8TT1DON1OSiapBV6PNZi9nhX15/a10ax31iL8+ddYz/cXz7SSSiiuTSJMj0wgsfqorFdvZ7Z38a133ye1+t7+NLNK/nNRy6M/s6mw6LSnKQyTo9Gy/Qqkn4uqwthyjJOXUMJl+mBcWKa43VN+jqs6xzksd0tvGPjvIRKsafqo5cvomNghIe2TR6s9A6P8n8v1HLNivKEu9glIz/LzXUrK3j49caEArlnD7SxvqYwqeYgYGScGrqHpzxbssl6z59Cxqk014vX5ZhWZ73GnmH8DOMdapla4JBdBCho3AZHn4Nz3m2UzcVQSnHuvEI++qkv8GrRTVzYdB/f/N63+MNrjbzd+TTu0CBc8PEp/wzxuFbcQBZB6rY9PuH9ntjTwjmOI0ZnPsf4jckmEsydR5nuIhSc+v/Dq0e7KHUO4euvM4b6nuGmk3GascpS2Ib1+YPtlOR4o1dNJ3Ois974L9L+wCgHWvu5wqzlHjPVOoPa+4M8e6CN+zfX8d+P7+fvHtwBJNZRz1KeZ8zvSNUgYOuNN9GMk9vpYFFpTko7u/UOjdI5ODLpccjPdlOZ75s029U9OMJ//nkfFXk+jnUOJXzlEYzSyfffu4Ufv5D8YufxHO0YZG5BFj638eZ8oj49NuOUWNbD7XSwsNTPwRQETg9uqac/GOKOi5ObneFwqGl11guFI+xo6GHdNEp0VszJ41jnYErmKVmlr4mU6oFxtT+Vs9SaegLMLchKukkGQKHfw9yCLHafEjj1Do+y5VgXt51XzfKKXB7dOTZwev5gO36Pc0rlkqfOcjrWMcgnH3iNRaU5/PXvLuM9F9TEHWRtp8VlORxpH0xobYtRptfERYtLKJxCwJrjNUo2UzEEV2tNQ/dwwo0hLJN9Fkcims/+didZbifvvzDJ+ThJ2rigiHPmFXD380cm7DQYCkf4wsO76Q+E+FQK1zad6tb1VfQFQjy5t3XC+7X0Btjf0s/lyxK7eBurujCLkVBkyhU4zdPINCulqCrMmlapXkP3MAuU+b6QbCtyMIKN7GLY/RtAwdp3jHtXn9vJho/+mO78lXyk62s8/tzzfMjzONRcAnPOntL+j2ftJTcxqL10bX943PtorXlmTwMrHMenXKYHECmswaE0PQdfmvL32Hy0i3eXHETpCCy+ZsrfZ7aYlYGTMXgvNScN24/3cF5N4aSzUyzVCSxKfr2+B63h2hVG+d90M05aazbXdk67IYHWmrf84CXed+8W/vn3u/nhc7XsberjkiUlSS1KLc/zEYrolHVzSqajnmVZRWo76x2xOguO04r81OeebG3Lf/1lH33Do9z3gQ2sm1/It586mHAJiZXNvO/lYynLOtV2nLyOrSLPh8uhTrpa2NQTINts/jGZ5Sk4/uGI5t6Xj3JeTSFnVxck/fiaYj/7mvumFMAfaO1naCSc1PymU62uykdro43wdCVTqgfmDJ1UZpx6h6mcQmcty6q5eWNK9Z472E4oorn6rDLeuKaSbXXdJ5WGaq157mA7FywqweNK/qNqXlE29d1DaK0ZHgnzkV9sw6EUP3rPuqTKPlNpUamfAbMRy2R2NfZS3zXMG9ckX6YHxolrSY6XjhRcRGzvDxIMRZiXZFv+yT6Lf/LSUTbVdvGFm1ba/n+ilOKjly2ivmuYP8XJboJR3fCx+7fzh9eb+Ptrl7IywQumU3HhohLm5PsmzYA9d9BoTpXs+iY40VlvquV6Tb3DFPs90Qtqyao2fwenqrF7mHOyrVbkUyyZ9JdAJAQLL5+83M7to/D9D5Dt8/Kw798p051w4Sen9rwTKMrPY1/2eua2PYeOxP8MP9Daj79nP25GYc65U34u59JrqY+Uon57B1994HG2HutK6lxxMBhid2Mv17h3GKWPc6e+L7PFLA2cfCnJOHUMBDneNcS5SVx1TmRR+ra6bpSCCxcbJwSd05zs/ZfdLbzt7k3R7lNTtbuxj/quYf7+2qW8/LkrOfjlN/DS567k53dsTKpE58Qsp9QEr3XRjFPiWa9lFbk09gzTN0nJZKIma0Uea3lFHkfaB8YNajbXdvLg1gY+eMlCllXk8o/XLaO1L8jPXjmW0L4ERo3v29IXiFvelCytNbXtJ6/fcjoUcwpOnsPR0jdMRb4voazD0opcmnoD0zr+T+5tob5rmDsuXjj5neO4YXUlDd3DPHMg8ZkZFqt5SzK/+6daW1UAGG2Ep6ulN0B+ljvhE5iyPC/9wVBCc4wS0dg9PK2uc6vm5HO0Y/CkEua/7m2lyO/h7OpC3rjG6Jb1p5is09GOQRq6h7ls6dQaAlQXZRMYjdDeH+Sf/7CLA639fOvtZyc8h8gOi8uM9X/3b66b9OTlTzubcTsV161IvkzPUprrTcl631qz5DXpjFOeb9zmEAdb+/na4we4+qxybl0ff21Tql19VjlLynL4l9/v5jtPHTopGzwQDPH+e7fwxN5W/v2mFXz8SvuyTWC8x96yrooXDrVP2P3zmf3tVOb7omtHkzHdBg1NPYFpXTCZ7hDchp4hVntbQDmhaGqfA9EGEee8O7H7F8zDees95Oghoyxt8dVTe97JLH0D5XSyf0f8TNCTe1pZ6zBXusxNvhW55fyVi+m4+RdkOcLcsu/TfOCHf+Wy/36W321PrMpl+/FuIpEwS/o2w5JrplwyOJvMzsApJzWletbJ0znzChJ+TK7PTZHfM2HGafvxHpaV55Lnc1OU7Zl2V72HthrzgzcfnV6TgSf3tuBQ8M6N85lTkDXlMharHXLKAqfOQXJ9ruiasESsN2du/PPvd097lg8YrchdDhXt1jWR5RW5jIbjd/UbCUX45z/spqowi7+9yvhg3riwmMuWlvK/zx5JKNAImG3WPS4H97x4dNqZxs7BEfoDoTGdE09dWNzcG2BOgifPVpOM6ZTr/fiFo8wryuaaFcm1YbbcuKaSuQVZ/Oi52snvfIrtx3sozfVSVTj1YKHI76G6KIsdqQic+gIJl+lB8q2gJ9LYM0xbfzDaYn0qVpnrRKz27KPhCM8eaOOKZWU4HYqaEj+r5ubx6M6m6GOeNy8EXbY0+RIlONFZ7yuP7ed32xv526uWcMUUyp1SacOCIm4+ew7fffown//drnEvrmiteXRnMxcvLkloDMR4SlL0WfjbbQ1kuZ1JX0goyzWalJz6vjYSivCpB14n1+viK7esnlIJ6FQ4HIr/e+96LlxczDeePMilX3uGH79QS3PvMO/6v028eqyLb75tLe+7yN6yQctb11WhNfxue/yuZ6PhCC8d7uDyZaVTOkZzC4zfgX1TnKvX3Duc8Ht+PNVFWfQFQkm3gbc0dg+zxNEMRQvAlXy5KgC5lUb77OU3Jv6YxVfDux6Ct947Zk1Uqiy79BYiWtHy6h/G3DY0EuIXm+u4Kq8e/GWQP/ULC0opzll3PtnveYBFzjb+WvVjin3w2d/uTGi95atHu1jnOIR7pAeWXDvl/ZhNZmXgVJbnZXAkzOA01xZsP96D26mS7uRj1NbHX5QeiWheq+uOlgAV+T3TKtVr6wtEM03bjnVPcu+JPbG3lfXzi6a0ADxWRTRwSk2pUF2n0VEvmQ+ODQuK+Oz1y/njjiY+/7ud015vVds+yLyibNzOyX9llleO31nv7uePcLhtgC+9aRVZnhNXbv7humX0DI3y4+cnP8kPmiV9t62vYmdDL1um+f8e7ah3SuBUVZB90pXKlt7EBrACLDWvjh6Y4jqz1453s7Wum/dfNPV1KG6ngw9esoBXj3WxrS65Y7StbmqDb0+1tqqAHfWpKdUrT6KUKZlW0JOxBsRetHjqA2KtNaK7zcBp67Fu+gIhrllxIpB545o57Gjo5biZrX/+UAc1xdlJl4dZrMzS77Y3cvmyUj5pcwYhEU6H4ltvO5uPX7GYB7bUc8d9W+OugdvR0EtjzzA3rklybs0pVs/N50Br/7Su+ncMBHn49SZuWTc36SBu44IiAqMRLvvaM/zkxaPR2Xrf+utB9jb38V9vWR3t/pcuNSV+fvSe9fzhrotYOSePL/9pHxd+5Wn2t/Tzo3ev483npCf7BUYVxYYFRTy0tT7uBbBtZhvyqV48yPI4uXZFOfe+dGxKQ8mbegJTakVuiXbWm8LrLxLRNPUEqAo3TL1MD+Cqf4PbHwV3kj/HkmugfMXUn3cSucVzOOpbTnnLM2Mu7v7wuVpa+4Js9Bwzsk2puLCw4BLU33yXso7N/KryAXxuB//+yJ5JL7xuPtrFbfn7jKzfoiunvx+zwKwMnErNN+LpXmnbfrybFXPyk67vnV+cPW6p3qG2AfqDoeiVu+Icz7RK9f7weiMRDVcsK2VHQ89Jc3eSUd81xP6W/ilf3Y9ltYRPZcYp0Y56sT56+SI+eeViHtzawBcf3TutzEwircgtC0tycDnGdvWr6xzku08f5sbVlWOufK+am8+Nayr58YtHJ+2CZZXqvXPDfAqy3dzzYvIZlVhHrTLEUzoGVhdl0TEQZHgkTCgcoa0/mPAi4bkFWeR4XXFbUCfinhePkutzcev66bWAfdt51RRku/nRc0cSfoxVojuVhgSnOru6gMae4Wl3NmvpDVCRl/gJptV9LxVrPV8+0kGR38PSsuRLhSyluV7K87zsMRtEPLWvFY/TcdJQW6vl9qO7mgiGwrxypJNLlya/rsNSVZiFUsbf33rb2QmvU7WbUoq/v24ZX3nLal463MGtP3yFBnMtluVPO5twO9W0349vXV+FAn69pX7K3+P+TccZCUd4/xSyMNeurODRT1zMijl5fPHRvVz9jef43tOH+OFzR7h1XRXXTqFbYKqcXV3Az+/YyC8/tJEbVlXysw9s4OoUfP4l69Z1VRzrHGJrnIs7zxxow+1U07po8Z9vWU2ez8WnHng9qaHkfYFRBoKhKTWGsFQVZPFt9/fwP/fvST+2fSBIODxKUeD4lFtxA8a6pso1U3+8jUYWXccKfYTX9uyLbmvqGebu54/w1pV5ZPUeSe2aorPfAZd/Ht+eB/jp4hd44VAHj+1uGffugdEwr9f3cCnbYd4FkFWQun05jc3OwCkFs5xGwxF2NvRwbhJlepZ5Rdk09QzHDWK2Hz95qGZhtoeuKQZOWmt+u62Rc+YVcNv6aoKhCLubpnZ1+wmzs08qAie300FJjiclGadQOEJD93BSjSFiffqapXzw4gX89OVj/PfjB6b0PcIRzbHOoYQaQ4BRQreoNOek5gh7m/p45/9txuN08G83xb+K9XfXLCUYivD9Zw5P+P2tD7+CbDfv3jifJ/a2UjeNeUW1HYO4nYq5p5SlxU5+7xgYIRzRCWeclFJctrSUX2+p5/E9478xx9PYM8xfdrfwzg3zkmpBHk+2x8V7z5/Pk/taOZzg/JxUrG+yrEnBOqdQOELHQDDJUj3r4sX0fge11rxypJMLFhZPO/BYNSc/2pL8qf1tnL+o+KT209VF2ZxdXcCjO5rZeqyb4dEwl00jcPK5nXzjtrX87AMbKMieXhbdDm/fMI9733ce9V1DXPzVZ1j+r49xwX89xY3feYEHXq3n0iWlCQ+bHc+cgiwuX1bGg1vrJ+wkN55gKMzPN9VxxbJSFiX4/neqVXPz+cUdG7nvAxvI8br5+hMHmVOQNe77YLpduKiE77/rXDYunHpwMh3WqIX//PO+MYHNcwfaWT+/KOk25LFKcrz891vXsr+ln68n8RnY3DP14beW6uJsXIQoP/oHCCdXAdTQPUy1asOpQ1PrqHcaqLnwFgDqN/8+uu1rj+0nouGzawOATn0zhss+C6veyrlHfsAbS1r50qN7GR6JH1DvbOilJNRG+fBhWHpdavfjNDYrAydr8N50Mk4HWvoJjEamdPI0ryibiDZOAE+1ra6bIr+HGjMQKPJPPXDa3djHgdZ+bjm3inU1xn5OtVzvyb0tLC3PoaYk+cxOPKma5XSgtZ9QRCcctJxKKcU/33gW79w4j/999gg/eDbxzIOlsdsIghcl0ZJ9eWUu+83Oen/Z1cwtP3iZcERz/4c2jjuLZ1FpDm89t4r7Nx2nZ4LyTevD1ety8N4L5uNyKO596VjiP9ApjnYMML/YP6Yk7kRHpmGaepNvS/vVt65hTVU+n/jlazybRIOG+14+BsDtF9Yk/JiJ3H5hDR6ng/9LoAwSjOHUUynRjWfV3DwcCl6fRrne8a4hIjq5WSoF2W48Tse0M07HOodo7g1wwaLpn1SunJvPkfYBdjf2crRjkKvjzMZ745pK9jb38dOXj+F2Ks6f5snsm8+pmvJ7RzpcurSUhz9+EZ97w3Juv7CGCxeVUJbrZWlFLndckpp1Nu/YMI+2/iBP70++ScofdzTTMRDkA0mOAziVdSHlT5+4mB+9Zx33fWDDtIKB2cTvdfG1t67hteM9/NPvdkUzj829w2Yb8qlfPLBcsbyM95w/nx+/eJQXD3Uk9Jjo8NtpNIfIz3LzhONSske74OizST22sWeYRcpc8zidUr0ZLGvuajpd5RQ1PM1oOML249384fUm7rxkIaV9u407TaOjXlxKwY1fR/lL+ar7btp6B8a9WPvq0U6ucL5u/EMCp6hZGThZpXrTOXG3MkPJNIawWN3f4jWI2F7XzbnzCqNrJ4r8HvoDoSmV2P12ewMel4Ob1syhLNfHvKJsttYl3yCiZ2iELce6U5JtspSnaI7ME3taUYppXXlWSvHlm1dx45pK/vvx/eyo70nq8cm0IrcsM7vK/def9/HR+7ezvDKXRz5+UTQDMZ6Ll5QwEo5MGPQHzNeKz+2kLM/HTWvn8ODW+ikvwD16SityS7WZgarvHjoxwykv8ZP3HK+Ln75/A4vLcvjwz7dF18pMZDAY4lebj3PD6sppXemMVZzj5bb11fz+tcaEykdfq+th5RRKdOPJ9rhYWp6b9GsulrWG8YIkggillNFRbZoZp5ePGCdZF6YgcFo1J4+Ihu8+fQiAK5ePDZxuNFtvP2mut7RzIOpMsag0h49ctoh/uuEs/ue2tdz7/g389qMXcuGiqXUTPNUVy0opz/Pyq1ePJ/U4rTU/efEoS8pyuHhxavbFYQ7znWr2ara6YXUlf3fNUn73WiM/MMuKnz1g/N5fEef3ZCr+6YazWFTq5zMPvT7hhTnLiYtlU38fVkrRVHYJ/fgJ73gwqcc2dA/FBE6Lp7wPM5pSDNZcwwa9k1f2N/ClR/dSmuvlY+uy4fVfQdEic4hvimUVwhu/gb97H9+pfo67n6+NrnWOtfloFzdl7YKC+bM2eJ2KWRk4FWZ78Dgd0anXU7G9rpuyXC9zp3DyZpWVHT+lfKprcITajkHOnV8Q3WY1Yki2QcRIKMLDrzdyzYry6ILd9fML2VbXnfRanqf3txGOaK6ZRtvbU5Xn+VJSqvf4nhbOm18ULb+cKodD8Z9vXk1prpd/+M2O6CLlU/UHRscM6oy2Ik8iG3dWhdGB7EfP13LLuVX86kPnR7sNTiTLPFm31jHFExw9ETgB3HHxAoZGwjyQ5IkRxJQhxvnZYie/N/daZRvJXX3Mz3Lz8zs2MK8omzvu2zJpk4ZHdjTRHwzxvgvnJ/U8k/nQJQsJRSKTZuba+gNsO96dkkDBsraqgJ0NPVNeY/f0/jYWlvqTzganYgjuK0c6qcjzxQ2sk2Vl8B7f08ryitxoRjNWZX4W55nZ88tScKVdgMvp4G3rq3n2YHvcKojxbD7axd7mPj5w8YK0db07k33iysXctHYO//34AZ7Y08KzB9qYk+9jSVlqgswsj5Nvv/0cugZH+Nxvd016sba5J4DToaJlv1P1satX8GhoA+G9f4SRxJtENHYPs8LdYnSVy5p+2fRMVXHem8hSIzz68K947XgPX75Akf2z66GvEW74b/ueePmNsOoW3tD5M85yNfL//nhyo4hQOMLuulbODe80sk3yHhA1KwMnh0OxvDKXPVNc7wNGR73YzFAyyswTzlMbRLxmrW+KKf8rNgOnZMv1nt7fRvfQKG8990QHoHU1hXQMjEw4QyqeJ/e2Up7nZU0KSpMslflGY4HpNIio6xxkf0s/165MTSYsP8vNf71lNQdbB/je02NT012DI9z6w1d443df5N0/3hzNEtS2D5Cf5U6q2+A58wpYUZnHv9x4Fl+/dU3C2QvrfsMTLOINhMK4nSpaWrdyTj4XLCzm55smnw1zKmstXrwTY2vye0P3MC29w/jcjimtuSjO8XL/BzdSluvlffe+yrE4V7bAuML9i011LK/ITcn6oljzirO5YXUl92+qm7Dl+yOvNxGOaN5y7tyUPfea6ny6h0anNEtlMBhic20XV06hjXZZrnda7cij65sWFafkxLky3xd9v7v6rPF/p//mbOPYZ7p1+Gxy23lGk5VkmkT85MWjFGa7efM5qftdEONTSvHfb13Dmrn5fOrXr/PCoQ4uW1aW0qB11dx8/v7aZTy2p4WrvvEsv93WMO64jqbeYcpzvbgS6CQ7kSuWldEy7414wkN0bP9Dwo9r7BlmmasZSmfn+iaLZ9GlBBzZnD20iXeV1nLt5veBDsP7/wKLr7L3yd/wNZQvj//Lv5fnD7Ty9rs38Y0nD/L8wXY2H+1ibWgXHh2UMr1TzMrACYw2rDsbeqd0lTc6+DYmM5QMpRRLy3P53WuN/NVsugDG+iaXQ51UrlU4xcDpt9sbKM31csmSEyUU1uyieN15gLhXmAKjYZ472M7VZ5WntOvUm8+Zi8uh+M5Th6b8PaymAtelsPPSlcvLecu5c/nfZ4+clFnqGhzhnf+3iaMdg9x56UL2Nvdx8/df4sM/38q2um4WlvqT+gAryPbw57+9hA9esjCpx/ncxq/kRN2PAqNhfK6TA7Eb1hjDXpMNmq3BluOVIVqT35t7A1TmZ035Q7wsz8cvPriRUFjzzb8ejHufHQ297Gnq413nz7flCveHL11Ev1kKOJ7fbW9kbVV+dFBpKliDcKcyz+nFwx2MhCNxy9omUz7B8NFEHGwdoHNwJCXrm8B4X1xpXpy5Ks76Jss7N8zjT5+8mGUVqfs/ONNVFWZz6ZJSHkqwSURd5yBP7mvlnRvnpaRkVSTG53Zy93vXk+dzMzQSTsn6plPdeelC7n3/eeRnufnMQzu49pvP8aedzWNGdjT1DCe1rnIib7v1HbToIhqe/1nCj2noGmJepHF6HfVOBy4vg9WX8TfOV/jSwL+j8qvhg39NTydAfwm84WuU9e3mnmWvMhAM8b2nD/Hen7zKu368mSscr6FdWTD/Yvv35TQyawOnNVX59AdCSZ9IQuzg26lf9f7GbWspz/PxwZ9t5bO/2clAMMT2492snJN30vyeqWScOgeCPLO/zQhOYq4GLSnLIc/nYlucdU6tfQHO+4+/ctcvtzM0cqK7zctHOhgaCad0fRMYV/jfuWEeD2ypj1s7m4jHdrewck5etLtbqnzhjSsp9nv4+4d2MBKKnBQ03XP7efzTDWfx/D9ewaevXspLhzvZ39I/plW3XXzRUr2JAqcI3lNOZs5fYATNm49Ovo4o1lFzAN54pVhVhVnUdw2b7bCnvkjY+F7Z3H5hDY/saOJQnPlOv9hUh9/jtO0K9+qqfC5aXMxPXjoat1RzX3Mfe5v7eMu5qZ3jsqwiF6/LMaV1Ts/sbyPH62J9TfJ17mW5XnqHR5NqQRwrleubLFefVcbqufnRYDIep0Oxck7qst/C8I4N82juPTH3bzyhcIQfPHsEp1K894Ka9OyciCrP83HP+9bzlnPncumS1AdOSimuWFbGHz9+MT9897k4lOKuX27nTf/7UnRtN5gDz1MUOM0p9NM6/0ZWDr7Ks6/tn/T+kYgm0NOCP9J/RqytKT73zeSoYRwLLoEPPDatgbdJW3ULLLuBKxrv5k9XtLLzny/l53ds4JNXLubN/t2oRVeAe3qf/bPNrA2crHr6nY3Jl+u9Vt+Dy6FYPY3StSXlufzhrgv52OWLeGhbPW/49vO8Xt8zJhgrmkLg9PDrTYQimltOOcFzOBTnzi+MOxD1xy/U0h8Y5c+7mnnrD4y5IWCU6eV4XSm7qhzr41cuwety8D9PJN8GvK0vwPbjPSnNNlnys93855tXs7+ln//6y76TgqaLzQxejtfF3169hBf+8Qr+8fpl3DHNrlKJSqRULzgajmamLIvLcij2e9hcm1xzkKMdg+R6XZTkxC9DrC7Mpnd4lENtA9Oa52G589KFZLudfOuUTGTv0Ch/3NHEzefMnXYL8ol85LJFtPYFefi1pjG3/f61RlwOxU1rpzd09FRup4OVc/KSzjhprXnmQBuXLi3B40r+rbos1/j/mmp30ZePdDKvKDvuWqSpeu8FNfzxExfPmJlKZ5KrziqjNHf8JhFt/QG++9QhLvnaMzywpZ63rqsatwOosNfKOfl847azT7rImmpKKa5fVcljn7qUb9y2lta+AG/535f5zIM7aOsLGIFTCt7zLSuu+xBuFWbLn34ybvtry8M7GpkbajD+cQYETqy+Fd79W3jXQ+DLS+9zKwU3fgNyK+G3d5Dz3RVcsu+L/F3pVvKCzbDk2vTuz2lg1gZOS8tz8bgc7JpCecz2OiMzNN0SBa/LyT9ev5wHP3wBCkVgNML6mpMDp4JsD0qR1BDch3c0sWpuXtxSlvXzCzncNnBS15yeoRHu33ycm9bO4SfvO4/67iFu/t5LbKrt5Mm9bVy2tBSvK/Vv0KW5Xj548QIe3dnMrobkAlhrrtT1q+wZkHj1inLedPYc7n3p2JigKVah38PHLl/MijnpeTOzPiiDEzSHCITCY16bSik2LChi89HkAqfD7QMsmKAM0cr29Q6PJjzDaSJFfg/vv2gBf9rZfNIk+99sbyAYivDujaltCnGqixeXsKIyjx89f+Sk0pRwRPOH1xq5fFlZUmvZErW2uoDdjX1JzdLZ09RHa19wymt9FpmLymOvIicqHNFsru1MabZJZJbb6eC29VU8vb+Nx3a38OjOJu7fXMcPnj3CXfdv58L/epr/efIgi8ty+OG71/HlN63K9C6LNHA6FG85t4qnP3M5H718EY/saOTyrz/LSCiSkotlFvecNQznL+aykWf53jPjl/APjYT46l8OcFmR+b51JgRODgcsvhqcGWrRn1cJn9gG733YaBqx67fw8MeM22R90xizNnByOx2sqMxjZ5In7KFwhJ0NvdMq0zvV+poi/vK3l/Ddd5zDG1ZVnnSb06EoyHLTnWDgFBgNs7uxd9z23OvMdU6x3cvue7mOoZEwH718EVcsK+MPd11Efpabd/zfJjoGgilrvhDPBy9dSGG2m689PjY9r7WOZr5O9fieFhaU+FPWUSieL9y0khtWV3Dv++IHTZngMzMLEzaHGI3gjZOB2LigiMae4XGP6al2NvTw8pFOLpqg1XBVzFDcVNW7f/CSBeR6XXzrSePDU2vN/ZvrjIYaNgeoSik+fNlCjrQP8lTMXJuXDnfQ1h/klhQ2hYi1tqqA4dEwhxIcwgtGmR7A5VMMnM6pLqAiz8cfdzQn/di9TX30BUK2ZKJF5rz9vHkAfOQX2/j4L1/jn3+/m68+tp+Xj3TwvgtreObvL+fnd2zk+lUV024KIE4vfq+Lz16/nCc+fRkbzdLvZRUpfD9Wiqx1b2eD4wCPPr95TPdayw+fq6WlL8At84fAnQ150pwkLRxOWHg5vPmH8A+H4M13w03fhrzUVmDMBrN6SMaaqnx+u62BSEQnXBqyv6Wf4dEw585PbVcvv9c1bglQMkNw9zX3EY7occsIz64uwOVQbK3r5qqzyhkMhrj35aNcfVYZy803wUWlOfz+rov41AOvsf14D5cvta97VZ7PzV1XLObLf9rHy4c7uNA8Sd/V0Mu//3EP2+q6+dLNK3lPTC1979AorxzpTLqxQrIK/R7+913rbPv+U5HYGqexGScgOvl+c20XVesmLq+KRDT/+vAeSnK8fOzyRePerzqmTKsyRWU7Bdke3n/xAr7z1CH2NPXSOzxKbfsg/3Pr2pR8/8ncuLqS/378AD987kh0bd/vtjeQ53Nx5QRNC6ZjbXUBYASrZ1UmdjLy1P421lblT7kVv8OhuGF1Jb8wOwnmJTFw1FrflMzsKDHzVRdl88dPXMzQSJg8n5v8LOOPz+2QluMCMNa73vv+DbT2BVJfqrn6Vnj6y9zme5UP/HQuv/vYhSeVAjf2DPOj545w09o5lAfrjMYQDgng087jh7Vvy/RezFiz+hW5em4+gyPhaOewREQH35onOulQ5PfQOZjYOgTrKs2qcQKnLI+TlXPy2Gauc/rVq8fpGRrlY1ecPEAuP8vNT953Hps+f1V0DpRd3n3+fObk+/jq4wfoGAjy+d/t5G++/yLHOgY5d14BX3hkD0/tO9F98OkDrYQimutszITNVL5E5jiFImPWOAEsK88lP8udUIOIh7bVs6O+h3+6YTm5E5xQF2S7o2uOUlGqZ7nj4gXk+lx866+HuH/zcfKz3NHhp3ZzOR186JKFbKvrZuuxLgaCIR7b08JNa+fYUrIKUFOcTZ7Pxev1iWXAOweC7Gjo4crl0/sdeOPaSkbCkZO6eybi5SOdLC7LSWj2mDi9rJyTz3k1RSyryKUi30eWxylBkxjDlvVthTVQtYE78rcwPBrmfT95lZ7uTug6Ci27uP/3f2QltfzrOcPQtu/MKNMTp51ZnnEqAIxgY3GCJV/b67opzfWeVKJktyK/h2MdiZZX9VLk90w4mHfd/CLu31zHQDDE/71Qy/kLi+LOxVFK2br41OJzO/nUNUv5x9/s5OKvPk0orPnARQv45FVLcDsVb/vRJj7+y9d48MMXsLoqn8d2t1Ce552w89Zs5XQoPE7HJKV6YQrizFNyOBTn1Uy+zql3aJSvPnaA82oKedPZE5dBWLOc9rf0p7TePT/LzYcuWcg3njyI06F4/4U1aW17fOv6Kr7114P88LkjXLeygsBoJOXd9GIppVhbXZBwZ71nD7SjNVNqQx7rnOoC5hZk8ejO5oR/vpFQhC3HunjrujR2dhJCnBnW3Ibvz3/Ptqy7oK8Lz7dPfNb9IxhnpQ+YG8pXZmAHhZjYrA6cFpX6yXI72dnQy5sSbHFsDL4tSOsVuCK/l211PQndd1djL6vm5k+4f+trCvnJS0f58qN7ae0L8vU0lUBN5JZzq/jd9gZ8bif/cuNZJ83Jued963nz91/mA/dt4VcfOp/nDrZz2/rqM7bzls/tmFKpHsD5C4v4675Wo334OIHO/zx5gJ6hEf7f32xM6HVeVZhNbftgypsmvP+iGu558Si9w6O8Y+O8lH7vyWR7XNx+YQ3f+ushatsHqSnO5tx5BbY+55qqfH74XG30/y8S0Ty2p4Vn9rfxngvmnzTf7ekDbZTmelk5zTVfSiluWF3BT18+Ru/QaELZ5Z0NPQyNhKUxhBAi9dbcBo3b8TicHBrw8uDeIaqqqmkactI1HObLb16D1+0GhwvmX5jpvRVijFkdOLnMNsC7GnvGvU9gNExd5xBH2gc41DrA8a4h3pXmk7giv5vuoZFJ12IFzMXlEw2PBKOzHsADW+pZPTefiydY/J8uTofigTsviHtbWa6Pn77/PN7yg5d58/++RGA0Yksb8tOFz+1MYI5T/CrbjQvMdU5HO7k5TjZpT1Mvv9hUx3vOn59wI4Y3rKqgNNeT8osJuT43X7x5JQdb+1k0zgBeO733ghp++NwRajsG+btrltp+sWRtVQHhiGZPUy/9gRBff+IAuxv7cDkUv3utkbuuWMwnrjRKap8/2M4bVlWk5OLBG9fM4f9eOMoTe1u4dX31hPcdCUW496VjKHXitSSEECnjy4c3/wCAJUD5C7V84U/7AGP+pXelZLrFzDarAycw1gL9eks94YjGecpJyOd/t4sHthxHxwzMrirMmjQwSbUiv5dwRNMfCE14RXhvtDFEwYTfryzPR3WRMbj0risWnRb160vKc/nRu9dx+72vUpDtZsOC5Ad+zhaTBU7BOO3ILSvm5JHrdbH5aNeYwElrzRce3kNBtoe/u2ZZwvtzy7oqbrGpbCtecJcuRX4Pbz9vHj975ZhtQ3djnW2um/zwz7fTMRCkuiiLb9y2liuWlfGlR/fynacO8dS+Vt5+XjX9gdC01zdZ1lTlU1WYxZ92NU8YOHUPjvDR+7exqbaLT1+9lEIb2rILIUSsD16ykIFgiNr2wUlLx4WYCWZ94LSmKp+fvnyMI+0DLC0/UR52oKWfX716nBtWV3DdygoWleawoMSP38bhm+Mp8hvBUudgcMLAyWoMsbpq8sG8Vy0vZ2tdF9euOH0yNxcuLuG+928gGI7gPoNb4Wa5nRM2hwiMRvCN08TA6VCsrylkc+3YBhEPbW1ga103X71lte0NQU4Xn71+OW85d250XpWdyvJ8LCr10x8I8aU3reJt66ujg22/8bazuXZlBf/8+13868N7cDtVylrkK6W4cU0l97xwlO7BkbgB0eG2AT543xaaegJ8821refM5ctVXCJEen7pamkCI08cZETiB0VQhNnC658VafG4H//Gm1Rm/slrkN9oNdw9N3JJ8l9kYIpFp3l+4aQURzWm3TujCGVBWmGk+9+TNIcYr1QOjLfkzB9pp7w9GW1nXdw3xxUf3smFBEbeum7hc60yS5XGetLbIbg9//GLcThW3e9/1qyo4r6aQL/9pH4XZnmg3w1S4ac0cfvRcLU/sbeFt551civzioQ4+ev82PE4Hv7pzY3QWnBBCCCFONusv6y8oycHvcbKroSe6rb0/yB9ea+Kt66oyHjQBFJv70DkwSeDU2MvqSRpDWJRSY0oTxelholK9UDhCKKLHzTgB0eGFr5rd9SIRzd8/tAOA/7l17WkXTM8mOV7XhC3Pi3O8fPNtZ/NvN61I6fOunJPH/OJsHt15YhjuSCjC1x8/wO33vkplvo8/3HWRBE1CCCHEBGZ94OR0KFbOzWdnzJTqn2+qYyQc4QMXLcjgnp1gBW8TDcG1GkOMN/hWzB4TBU7BUMS8z/i/uqvm5pPtcUbnOf3kpaNsPtrFv920Ii0laWLmUUpx4+pKXj7SSedAkL1Nfdz8/Zf43jOHefM5c/ntRy+U14YQQggxiUkDJ6WUTyn1qlJqh1Jqj1Lq/5nbFyilNiulDiulfq2U8pjbvea/D5u318R8r8+b2w8opa6L2X69ue2wUupzqf4h18zNZ29TH6FwhMBomF9squPqs8pYmIFOXvFYGaeuCUr1rMYQ4w2+FbOH0Y48/honK6CaaOaR2+lg3fxCNtd2cbC1n689foCrzyrnVpnLc0Z745o5hCOaT/36dW7+/ou09wf58XvX8/Vb1044BFkIIYQQhkQyTkHgSq31WuBs4Hql1PnAV4Fvaq0XA93AHeb97wC6ze3fNO+HUmoF8HZgJXA98L9KKadSygl8H3gDsAJ4h3nflFldlU8wFOFQ2wC/f62RrsER7rh4YSqfYlp8bifZHiddE5Tq7WowMmZrEmgMIU5vWW4ngVD8jFMggYwTGOV6B1r7uev+7eR6XXzlltWnRXdFYZ+zKnNZWOLnhUMdXLeygic/fSlXr0hN5z4hhBDiTDDp6mOttQYGzH+6zT8auBJ4p7n9PuDfgR8AN5tfA/wG+J4yzthuBh7QWgeBo0qpw8AG836Htda1AEqpB8z77p3ODxbLKm/bUd/DPS8eZeWcPM5fOLNq+QuzPROW6u1q7KXY76EygcYQ4vTmczsZHhkncEog4wRGgwiAQ20D/Og96yjJ8aZ2J8VpRynFt95+Np2DI1yxLL0jF4QQQojZIKG2TWZWaBuwGCM7dATo0VqHzLs0AFYD/rlAPYDWOqSU6gWKze2bYr5t7GPqT9m+cZz9uBO4E2DevMSH1NYU+8n1urj7hVpq2wf55tvWzrir78U5nglL9XY39rIqwcYQ4vQ20Rona/tEDQbAyEwWZLu5dkX5GT1MWJwsnR0EhRBCiNkmocBJax0GzlZKFQC/B5bbuVMT7MfdwN0A69ev15PcPcrhUKyam88rtZ2U53m5cfUc2/Zxqor842echkfCHGzt5xopqzkj+CaY42Rtn6xUz+ty8uzfX06erF0RQgghhEiJpLrqaa17gGeAC4ACpZQVeFUBjebXjUA1gHl7PtAZu/2Ux4y3PaWstUG3X1gTHTo5kxRle8ZtR763uY+IRhpDnCF8bgcj4QjhyNhrA8EEM04ABdkeaT0uhBBCCJEiiXTVKzUzTSilsoBrgH0YAdRbzbvdDjxsfv2I+W/M258210k9Arzd7Lq3AFgCvApsAZaYXfo8GA0kHknBz3aS61ZVsH5+Ie/ckHiJXzoV+T3jDsDdbbZSl1bkZ4Ysc/1SME6DiETakQshhBBCiNRLpFSvErjPXOfkAB7UWj+qlNoLPKCU+jLwGnCPef97gJ+bzR+6MAIhtNZ7lFIPYjR9CAF3mSWAKKU+DjwOOIGfaK33pOwnNJ07r5DffPTCVH/blCnK8TA0EiYwGh6z8H9nQy8lOdIY4kxh/f8Pj4TJ9pz8K5pocwghhBBCCJFaiXTV2wmcE2d7LSe64sVuDwC3jvO9/gP4jzjb/wz8OYH9nbWKsk8MwZ1TkHXSbdIY4sxiZZys1uOxrDblEjgJIYQQQqSX1PvMEEX+E4FTrOGRMIfa+qVM7wziNcvw4rUkT7Q5hBBCCCGESC05+5ohrMCp85TAaW9zLxEt65vOJFY2KV5L8mipXgLNIYQQQgghROpI4DRDWIFT9ymB02vHewBYXSWB05liouYQJzJOEjgJIYQQQqSTBE4zRLHfC4zNOD22u4XlFblU5mfFe5iYhU40h4izxinajlx+dYUQQggh0knOvmaIXJ8Lp0PRNRiMbmvqGWZrXTdvXFOZwT0T6ZY1UaleKIzH5ZD5TEIIIYQQaSaB0wzhcCgKsz10DY5Gt/15VzMAN6yWwOlMYjV+GI4TOAVHI5JtEkIIIYTIADkDm0GK/Z6TMk5/2tXMiso8FpbmZHCvRLpN1BwiGBo750sIIYQQQthPAqcZpNDvjrYjb+ge4rXjPbxxrWSbzjS+ieY4jUakFbkQQgghRAbIGdgMUuz3RgOnv+xqAeBGKdM741iBUSDuHKewtCIXQgghhMgACZxmkCK/Jxo4PbqrmdVz85lf7M/wXol0m2yOk5TqCSGEEEKknwROM0ih30PP8Ch1nYPsqO/hRummd0ZyOx24HCpucwgp1RNCCCGEyAw5A5tBiv0etIb7Nx8HpEzvTOZzO6PDbmMFpDmEEEIIIURGSOA0gxT5PQA8uLWetVX5VBdlZ3iPRKb43M5xM05eWeMkhBBCCJF2EjjNIFbg1DM0yhvXzMnw3ohM8rkdBMdpR+6VUj0hhBBCiLSTM7AZxAqcAN6wuiKDeyIyLcvtJBCKPwBXuuoJIYQQQqSfBE4ziBU4nTOvgKpCKdM7k/ncTobHa0cuGSchhBBCiLSTM7AZpMjvYW5BFu/cMC/TuyIyzOd2xG8OIe3IhRBCCCEywpXpHRAnuJ0OXvzsFSilMr0rIsN8bif9gdCY7YGQtCMXQgghhMgEOQObYSRoEmC1Iz+5VG80HCEc0bLGSQghhBAiAyRwEmIGynI7CYZOLtWzAikp1RNCCCGESD8JnISYgXxux5jmENaaJynVE0IIIYRIPzkDE2IGiteOPGj+WwbgCiGEEEKknwROQsxA8dqRWxknGYArhBBCCJF+cgYmxAzkNdc4aa2j22SNkxBCCCFE5kjgJMQMlGUGR7ENIqxSPQmchBBCCCHSb9LASSlVrZR6Rim1Vym1Ryn1t+b2IqXUk0qpQ+bfheZ2pZT6jlLqsFJqp1Lq3Jjvdbt5/0NKqdtjtq9TSu0yH/MdJT25xRnOagARW64XbQ7hkusdQgghhBDplsgZWAj4jNZ6BXA+cJdSagXwOeAprfUS4Cnz3wBvAJaYf+4EfgBGoAV8AdgIbAC+YAVb5n0+FPO466f/owlx+rIyTrENIqRUTwghhBAicyYNnLTWzVrr7ebX/cA+YC5wM3Cfebf7gDeZX98M/EwbNgEFSqlK4DrgSa11l9a6G3gSuN68LU9rvUkbCzp+FvO9hDgjWcFR3IyTBE5CCCGEEGmXVM2PUqoGOAfYDJRrrZvNm1qAcvPruUB9zMMazG0TbW+Is12IM5ZVqmcFS8bX4ZNuE0IIIYQQ6ZPwGZhSKgf4LfAprXVf7G1mpkjHfWAKKaXuVEptVUptbW9vt/vphMgYX5xSPatRhMxxEkIIIYRIv4QCJ6WUGyNoul9r/Ttzc6tZZof5d5u5vRGojnl4lbltou1VcbaPobW+W2u9Xmu9vrS0NJFdF+K0FA2cRuKtcZKMkxBCCCFEuiXSVU8B9wD7tNbfiLnpEcDqjHc78HDM9vea3fXOB3rNkr7HgWuVUoVmU4hrgcfN2/qUUuebz/XemO8lxBkpbnMIaUcuhBBCCJExrgTucxHwHmCXUup1c9s/AV8BHlRK3QHUAbeZt/0ZuAE4DAwB7wfQWncppb4EbDHv90WtdZf59ceAnwJZwF/MP0KcsU40h4hd42SV6knGSQghhBAi3SYNnLTWLwLjzVW6Ks79NXDXON/rJ8BP4mzfCqyabF+EOFOcaA4Rs8ZpNIzX5UDGnAkhhBBCpJ9cuhZiBhpvjpOU6QkhhBBCZIYETkLMQN5x5jhJYwghhBBCiMyQszAhZiAr42S1IAcj+yQZJyGEEEKIzJDASYgZyO1UONTJGafgaEQaQwghhBBCZIichQkxAyml8LmdJzWHkIyTEEIIIUTmSOAkxAyV5XaObQ7hksBJCCGEECITJHASYobyuZ1j5jh5pTmEEEIIIURGyFmYEDOUz+2QduRCCCGEEDOEBE5CzFA+t5NAbHOIUEQCJyGEEEKIDJHASYgZyhd3jZP8ygohhBBCZIKchQkxQ2W5nQRGY9c4SameEEIIIUSmSOAkxAzlcztOnuMUiuCT5hBCCCGEEBkhZ2FCzFCxpXpaawKjYbzSjlwIIYQQIiMkcBJihoptDjEa1kQ0knESQgghhMgQOQsTYoYy2pEba5yszJOscRJCCCGEyAwJnISYoYzmEEbAZP3tlcBJCCGEECIjJHASYobyuZ0Mj4bRWhM0u+tJO3IhhBBCiMyQszAhZiif24nWMBKORDNOUqonhBBCCJEZEjgJMUNZQVJgJBKd5ySBkxBCCCFEZkjgJMQMZXXQC4TCBKPNIeRXVgghhBAiE+QsTIgZKsvKOI2GoxknmeMkhBBCCJEZEjgJMUNZZXnDo+GYNU7yKyuEEEIIkQlyFibEDHUi4xSROU5CCCGEEBkmgZMQM5TXzC4Nj5wo1fNJqZ4QQgghREZI4CTEDBXtqheSUj0hhBBCiEyTszAhZiirVC8Ys8bJK6V6QgghhBAZMWngpJT6iVKqTSm1O2ZbkVLqSaXUIfPvQnO7Ukp9Ryl1WCm1Uyl1bsxjbjfvf0gpdXvM9nVKqV3mY76jlFKp/iGFOB3FNocIhqw5TnKtQwghhBAiExI5C/spcP0p2z4HPKW1XgI8Zf4b4A3AEvPPncAPwAi0gC8AG4ENwBesYMu8z4diHnfqcwlxRoptDhEcDaMUeJwSOAkhhBBCZMKkZ2Fa6+eBrlM23wzcZ359H/CmmO0/04ZNQIFSqhK4DnhSa92lte4GngSuN2/L01pv0lpr4Gcx30uIM5ovtjlEKILX5UASskIIIYQQmTHVy9flWutm8+sWoNz8ei5QH3O/BnPbRNsb4myPSyl1p1Jqq1Jqa3t7+xR3XYjTw6nNIaQVuRBCCCFE5ky77sfMFOkU7Esiz3W31nq91np9aWlpOp5SiIzxuoxfz8BoxAicpBW5EEIIIUTGTDVwajXL7DD/bjO3NwLVMferMrdNtL0qznYhznhKKXxuB4FRY46TNIYQQgghhMicqZ6JPQJYnfFuBx6O2f5es7ve+UCvWdL3OHCtUqrQbApxLfC4eVufUup8s5vee2O+lxBnvCy30wycpFRPCCGEECKTXJPdQSn1K+ByoEQp1YDRHe8rwINKqTuAOuA28+5/Bm4ADgNDwPsBtNZdSqkvAVvM+31Ra201nPgYRue+LOAv5h8hBMY6p2hzCAmchBBCCCEyZtLASWv9jnFuuirOfTVw1zjf5yfAT+Js3wqsmmw/hDgT+dxOAiFrjZOU6gkhhBBCZIqciQkxg/nMUr1gKCKlekIIIYQQGSSBkxAzmNUcIjgajnbZE0IIIYQQ6SdnYkLMYNIcQgghhBBiZpDASYgZzOd2MiztyIUQQgghMk7OxISYwYxSvQiBkGSchBBCCCEySQInIWYwn5TqCSGEEELMCBI4CTGDRec4jUakHbkQQgghRAbJmZgQM1iW20l/IAQgA3CFEEIIITJIAichZjCf28FIOGJ+LYGTEEIIIUSmSOAkxAzmc50IlqSrnhBCCCFE5siZmBAzWJbnRODkdUnGSQghhBAiUyRwEmIGi13XJBknIYQQQojMkTMxIWawrNjASTJOQgghhBAZI4GTEDNYbJZJmkMIIYQQQmSOBE5CzGDSHEIIIYQQYmaQMzEhZrDY5hCScRJCCCGEyBwJnISYwU4u1ZNfVyGEEEKITJEzMSFmsNgsk7QjF0IIIYTIHAmchJjBTgqcJOMkhBBCCJExciYmxAzmc8saJyGEEEKImUACJyFmMJnjJIQQQggxM0jgJMQMZjWEcChwO1WG90YIIYQQ4swlgZMQM5iVZfK5nSglgZMQQgghRKZI4CTEDOZwKDwuh6xvEkIIIYTIMAmchJjhstxOfC75VRVCCCGEyCQ5GxNihvO5JeMkhBBCCJFpMyZwUkpdr5Q6oJQ6rJT6XKb3R4iZwud24pGMkxBCCCFERs2IszGllBP4PvAGYAXwDqXUiszulRAzQ5bbKRknIYQQQogMmxGBE7ABOKy1rtVajwAPADdneJ+EmBF8bme0LbkQQgghhMgMV6Z3wDQXqI/5dwOw8dQ7KaXuBO4EmDdvXnr2TIgM++jli2SGkxBCCCFEhs2UwCkhWuu7gbsB1q9frzO8O0KkxXUrKzK9C0IIIYQQZ7yZUv/TCFTH/LvK3CaEEEIIIYQQGTdTAqctwBKl1AKllAd4O/BIhvdJCCGEEEIIIYAZUqqntQ4ppT4OPA44gZ9orfdkeLeEEEIIIYQQApghgROA1vrPwJ8zvR9CCCGEEEIIcaqZUqonhBBCCCGEEDOWBE5CCCGEEEIIMQkJnIQQQgghhBBiEhI4CSGEEEIIIcQklNan5xxZpVQ7UJfp/ZiCEqAj0ztxhpBjnV5yvNNLjnd6yfFOLzne6SXHO73keKfXMq11biq+0YzpqpcsrXVppvdhKpRSW7XW6zO9H2cCOdbpJcc7veR4p5cc7/SS451ecrzTS453eimltqbqe0mpnhBCCCGEEEJMQgInIYQQQgghhJiEBE7pd3emd+AMIsc6veR4p5cc7/SS451ecrzTS453esnxTq+UHe/TtjmEEEIIIYQQQqSLZJyEEEIIIYQQYhISOE2TUuonSqk2pdTumG2/Vkq9bv45ppR6Pea2NUqpV5RSe5RSu5RSPnP7OvPfh5VS31FKqQz8ODNeMsdbKeVWSt1nHtd9SqnPxzzmeqXUAfN4fy4DP8ppYZzjfbZSapN5vLcqpTaY25X52j2slNqplDo35jG3K6UOmX9uz8TPcjpI8ni/yzzOu5RSLyul1sY8Rl7fCUjmeMfcfp5SKqSUemvMNnl9JyDZ462Uutzcvkcp9VzMdnl9JyDJ95N8pdQflVI7zOP9/pjHyOt7EuMc67Xm+d4u89jmxdz2efP1e0ApdV3MdnltJyCZ462UukYptc3cvk0pdWXMY5I/99Zay59p/AEuBc4Fdo9z+/8A/2Z+7QJ2AmvNfxcDTvPrV4HzAQX8BXhDpn+2mfgnyeP9TuAB8+ts4BhQAziBI8BCwAPsAFZk+mebiX/iHW/gCev1CdwAPBvz9V/M1/D5wGZzexFQa/5daH5dmOmfbSb+SfJ4X2gdR+ANMcdbXt82HO+YY/s08GfgreY2eX3bcLyBAmAvMM/8d1nM/4G8vlN/vP8J+Kr5dSnQZR5feX1P/VhvAS4zv/4A8CXz6xXm69YLLDBfz055bdt2vM8B5phfrwIaYx6T9Lm3ZJymSWv9PMYbzBhm5Hob8Ctz07XATq31DvOxnVrrsFKqEsjTWm/Sxv/kz4A32b7zp6Ekj7cG/EopF5AFjAB9wAbgsNa6Vms9AjwA3Gz3vp+OxjneGrCunOUDTebXNwM/04ZNQIH52r4OeFJr3aW17gaeBK63f+9PP8kcb631y+bxBNgEVJlfy+s7QUm+vgE+AfwWaIvZJq/vBCV5vN8J/E5rfdx8rHXM5fWdoCSPtwZyzc/RHPNxIeT1nZBxjvVS4Hnz6yeBW8yvb8a4qBvUWh8FDmO8ruW1naBkjrfW+jWttfU63wNkKaW8Uz33Pm0H4J4mLgFatdaHzH8vBbRS6nGMKzoPaK2/BswFGmIe12BuE8k59Xj/BuNNpxkj4/RprXWXUmouUB/zuAZgY1r39PT2KeBxpdTXMcp9LzS3xzuucyfYLhLzKeIf71h3YFwtg/jHW17fifsUcY63+b7xZuAK4LyY+8vre3o+RfzX91LArZR6FsgFvq21/hny+p6uTxH/eH8PeAQjkMoF3qa1jozzeSmv78TswTgH+QNwK1Btbp+LcbHLEntM5bU9deMd71i3ANu11kHztZ30ubdknOz1Dk5kP8AIVC8G3mX+/Wal1FWZ2LFZ6tTjvQEIA3Mw0uGfUUotzMSOzTIfxQhCq4FPA/dkeH9muwmPt1LqCozA6bMZ2LfZaLzj/S3gs1rrSKZ2bJYa73i7gHXAjRhZj39VSi3NzC7OKuMd7+uA1zE+L88Gvhe7JkdMyQeAjymltmEEoyMZ3p/ZbsLjrZRaCXwV+PB0nkQCJ5uY5WFvAX4ds7kBeF5r3aG1HsKokz8XaOREmQ3m143p2tfZYJzj/U7gMa31qFnm8RKwHuPYxl6JkOOdnNuB35lfP4QRoML4x1WO9/SMd7xRSq0BfgzcrLXuNDfL8Z6e8Y73euABpdQx4K3A/yql3oQc7+ka73g3AI9rrQe11h0YJThrkeM9XeMd7/djlEZqrfVh4CiwHDneU6a13q+1vlZrvQ7jou4R8yb5rLTBBMcbpVQV8HvgvVrr2P+HpM+9JXCyz9XAfq11bBrwcWC1UirbPNG/DNirtW4G+pRS55v1xe8FHk7/Lp/W4h3v48CVAEopP8YCwP0YCwiXKKUWKKU8wNsxShREYpowXrtgHF+rNPIR4L3KcD7Qa762HweuVUoVKqUKMdb6PZ7unT6NxT3eSql5GCdA79FaH4y5v7y+pyfu8dZaL9Ba12itazDKgD+mtf4D8vqervHeTx4GLlZKuZRS2RglS/uQ1/d0jXe8jwNXASilyoFlGI0g5PU9RUqpMvNvB/AvwA/Nmx4B3m6us1kALMFoUiCv7WkY73grpQqAPwGf01q/ZN1/yufednW8OFP+YES1zcAoxhWyO8ztPwU+Euf+78aow9wNfC1m+3pz2xGMWmOV6Z9tJv5J5nhjLHB9yDzee4F/iLntBuCgebz/OdM/10z9E+94Y5SZbsPo+LMZWGfeVwHfN4/pLmB9zPf5AMYC2MPA+zP9c83UP0ke7x8D3RjlNa8DW2O+j7y+U3y8T3ncTzG76pn/lte3Dccb+AfzvXs38KmY7fL6TvHxxijRe8J8794NvDvm+8jre2rH+m/N1+lB4CvEnNcB/2y+fg8Q08lNXtupP94YQdRgzGfl65zo0pn0ubf1TYUQQgghhBBCjENK9YQQQgghhBBiEhI4CSGEEEIIIcQkJHASQgghhBBCiElI4CSEEEIIIYQQk5DASQghhBBCCCEmIYGTEEIIIYQQQkxCAichhBBCCCGEmIQETkIIIYQQQggxif8Pa3rZPKrxXbgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"sales\"].plot()\n",
    "fcst[\"fcst\"].plot()\n",
    "plt.xlim(left=1750, right=1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c912374-2f4f-4994-8f9f-eef959e0da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_1_1 = pd.read_parquet(cfg.FCST_DIR / \"1/1/fcst.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a20e4e-1c6e-4253-a1d2-ff9d9b5ef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8033a2e6-5779-413e-a522-c01d86686772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d         1886.000000\n",
       "sales    36041.000000\n",
       "fcst     36752.014194\n",
       "Name: 1885, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst_1_1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b597f99-2385-4c62-8b50-e15b1d61869c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fcst(cfg.DATA_DIR, cfg.FCST_DIR, level=1, step=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3972a79-d2a6-4a4a-97d7-e4bdc0b17a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fcst(cfg.DATA_DIR, cfg.FCST_DIR, level=2, step=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198a0d79-8929-4099-87f2-b6c352394469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fcst(cfg.DATA_DIR, cfg.FCST_DIR, level=level, step=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfab3b-9cf9-41f0-a340-7c0363b7df0d",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7a2f7-996f-4a76-8adf-c77b27d83b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = accuracy(cfg.DATA_DIR, cfg.FCST_DIR, cfg.METRICS_DIR, level)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e4bc6-8e33-449a-9853-3cae4192d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df[\"weights\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0258800-c530-4b7c-98c5-2274bb70e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df[\"wrmsse\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb0cd5-c916-463f-a49b-4377d84f54ee",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d6cb9-66f8-4102-8e08-349557a780c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
